[
  {
    "year": "2016",
    "abstract": "While playing an important role in radio frequency (RF)-based wireless systems, multiple-input multiple-output (MIMO) techniques have also found viable applications in visible light communication (VLC) systems. However, how to effectively reduce the inherent strong correlations between optical MIMO channels remains a typical issue for VLC. In this paper, we propose an MIMO-aided multiuser optical orthogonal frequency division multiplexing VLC system employing an imaging receiver (ImR). The proposed new scheme efficiently mitigates the optical MIMO channel correlations across the multiple photodetectors (PDs) of the same user equipment (UE) or those between different UEs, through invoking a new technique called photodetector selection (PDS). Two possible PDS designs, namely random PDS and modified maximum minimum singular value PDS are investigated. Through both analytical analysis and numerical simulations, we show that the proposed PDS-aided ImR system is capable of outperforming its conventional non-imaging receiver and non-PDS ImR counterparts, especially when UEs are close to each other. Results demonstrate that the proposed system offers a stably low bit error rate in most areas of the room."
  },
  {
    "year": "2016",
    "abstract": "Industrial wireless networks (IWNs) are characteristically different from traditional wireless systems due to harsh radio frequency (RF) environments and applications that impose high real-time and reliability constraints. One of the promising technologies for enabling IWNs is the cognitive radio. This paper designs a novel subcarrier modulation-based cooperative spectrum sensing (SMCSS) scheme for cognitive industrial wireless networks (CIWNs). Based on the orthogonal frequency division multiplexing physical layer, the local decisions are sent to the fusion center orthogonally in the frequency domain via physical layer signaling with binary amplitude shift keying symbols, which significantly reduces the reporting delay of the SMCSS. Furthermore, a two-level decision fusion method is proposed to cope with the harsh control channel that suffers from strong Gaussian noise and Rayleigh fading. Sensing parameters of the two-level decision fusion are optimized for minimizing the total sensing error rate of CIWNs. Finally, a reputation updating mechanism is combined with the SMCSS to improve its robustness against unreliable subcarriers due to RF hostile industrial environments."
  },
  {
    "year": "2016",
    "abstract": "While relay-based cooperative networks (widely known in the literature as cooperative communication), where relays only forward signals from the sources to the destination, have been extensively researched, fully cooperative systems have not been thoroughly examined. Unlike relay networks, in a fully cooperative network, each node acts as both a source node sending its own data and a relay forwarding its partner's data to the destination. Mutual cooperation between neighboring nodes is believed to improve the overall system error performance, especially when space-time codes are incorporated. However, a comprehensive performance analysis of space-time-coded fully cooperative communication from all three perspectives, namel,y error performance, outage probability, and energy efficiency, is still missing. Answers to the commonly asked questions of whether, in what conditions, and to what extent the space-time-coded fully cooperative communication is better than direct transmission are still unknown. Motivated by this fact and inspired by the increasing popularity of healthcare applications in wireless body area networks (WBANs), this paper derives for the first time a comprehensive performance analysis of a decode-and-forward space-time coded fully cooperative communication network in Rayleigh and Rician fading channels in either identically or non-identically distributed fading scenario. Numerical analysis of error performance, outage probability, and energy efficiency, validated by simulations, show that fully cooperative communication is better than direct transmission from all three aspects in many cases, especially at a low-power and low signal-to-noise ratio regime, which is a typical working condition in WBANs."
  },
  {
    "year": "2016",
    "abstract": "In this paper, an attribute control chart using repetitive sampling is proposed when the lifetime of a product follows the Birnbaum-Saunders distribution. The number of failures is to be monitored by designing two pairs of upper and lower control limits. The necessary measurements are derived to assess the average run length (ARL). The various tables for ARLs are presented when the scale parameter and/or the shape parameter are shifted. The efficiency of the proposed control chart is compared with an existing chart. The proposed chart is shown to be more efficient than an existing control chart in terms of ARL. A real example is given for illustration purpose."
  },
  {
    "year": "2016",
    "abstract": "Cooperative Intelligent Transportation Systems, mainly represented by vehicular ad hoc networks (VANETs), are among the key components contributing to the Smart City and Smart World paradigms. Based on the continuous exchange of both periodic and event triggered messages, smart vehicles can enhance road safety, while also providing support for comfort applications. In addition to the different communication protocols, securing such communications and establishing a certain trustiness among vehicles are among the main challenges to address, since the presence of dishonest peers can lead to unwanted situations. To this end, existing security solutions are typically divided into two main categories, cryptography and trust, where trust appeared as a complement to cryptography on some specific adversary models and environments where the latter was not enough to mitigate all possible attacks. In this paper, we provide an adversary-oriented survey of the existing trust models for VANETs. We also show when trust is preferable to cryptography, and the opposite. In addition, we show how trust models are usually evaluated in VANET contexts, and finally, we point out some critical scenarios that existing trust models cannot handle, together with some possible solutions."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the system performance evaluation framework of systematic rateless-coded (SRCed) transmissions for user experience in future 5G systems. To this end, we define the application-layer information loss ratio (AILR), i.e., the ratio of the number of unsuccessfully decoded messages to that of the total transmitted messages, as a system performance index from the perspective over network application layer, which can be used as an evaluation framework on the users' experience in the viewpoint of 5G transmission systems. By using the integer partition theory, we analytically derive some theoretical results and then obtain an exact expression of the AILR for SRCed transmissions. Simulation and numerical results are provided to demonstrate the validness of our analytical results, which also show that the SRCed transmission achieves much better system performance than existing coded transmission methods in terms of AILR. Moreover, by using our presented AILR expression, the proper system configuration can be easily determined without a heavy burden of Monte Carlo simulations. It also illustrates some inherent relationships between system parameters by using SRCed transmission on application layer, which can be easily carried out to achieve a better performance in the viewpoint of users' experiences. First, for a given channel condition, the larger the message length is, the smaller the ratio of the message length to the source symbol length should be selected. Second, for a given message length, the better the channel condition is, the larger the ratio of the message length to the source symbol length should be selected."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a substrate integrated waveguide Butler matrix with a modified hybrid coupler, operating from 28 to 32 GHz. The modified hybrid coupler is realized by using 90° hybrid coupler followed by a -45° compensating phase shifter. Thus, 45°/135° output phase differences can be obtained using this type of coupler. Compared with the equal-length unequal-width phase shifter, the compensating phase shifter exhibits better phase characteristics, with only 3° phase error over 28-32 GHz. Because the phase of compensating phase shifter is not realized by taking the phase introduced by the crossover as a reference, it gives great flexibility to the design of compensating phase shifter. Adopting the modified hybrid coupler, the designed Butler matrix features the output phases with peak to peak error of 13° and wideband performance from 28 to 32 GHz. The slot array fed by the Butler matrix can radiate four slanted beams with acceptable measured gains, in the range of 9.7~12 dBi for port 1 excitation and 8.4~11.1 dBi for port 2 excitation. The radiated beams can reach a wide azimuthal coverage between ±61°."
  },
  {
    "year": "2016",
    "abstract": "Modern technologies of mobile computing and wireless sensing prompt the concept of pervasive social network (PSN)-based healthcare. To realize the concept, the core problem is how a PSN node can securely share health data with other nodes in the network. In this paper, we propose a secure system for PSN-based healthcare. Two protocols are designed for the system. The first one is an improved version of the IEEE 802.15.6 display authenticated association. It establishes secure links with unbalanced computational requirements for mobile devices and resource-limited sensor nodes. The second protocol uses blockchain technique to share health data among PSN nodes. We realize a protocol suite to study protocol runtime and other factors. In addition, human body channels are proposed for PSN nodes in some use cases. The proposed system illustrates a potential method of using blockchain for PSN-based applications."
  },
  {
    "year": "2016",
    "abstract": "Reliable data congestion analytics in crowdsourced eHealth networks becomes particularly important, especially in big data era, because of wide adaption of ubiquitous crowdsourced healthcare participants. Since a crowdsourced eHealth network has intermittent connectivity to its remote healthcare provider, researchers usually use some well-studied networks to model the novel network, but data congestion analytics is still a big problem in most intermittent connecting networks. In most cases, data congestion analytics may be realized by fixing the number of forwarded copies, but sometimes, it cannot suit the changing network environments well. This problem could be solved by modifying packet forwarding conditions dynamically through detecting real-time network environment. Based on this idea, in this paper, an optimized routing algorithm named RSW (reduced variable neighborhood search-based spray and wait) is proposed. In the algorithm, nodes will exchange and store each other's buffer status during their communication, based on which, current network environments will be evaluated and quantified as a real-time threshold. Then, spray and wait adapts the threshold for data congestion control. Simulation shows that the proposed algorithm increases data packet delivery probability, and optimize the overhead ratio dramatically, which can be up to ten times lower than that of standard algorithm."
  },
  {
    "year": "2016",
    "abstract": "In recent years, the migration of the computational workload to computational clouds has attracted intruders to target and exploit cloud networks internally and externally. The investigation of such hazardous network attacks in the cloud network requires comprehensive network forensics methods (NFM) to identify the source of the attack. However, cloud computing lacks NFM to identify the network attacks that affect various cloud resources by disseminating through cloud networks. In this paper, the study is motivated by the need to find the applicability of current (C-NFMs) for cloud networks of the cloud computing. The applicability is evaluated based on strengths, weaknesses, opportunities, and threats (SWOT) to outlook the cloud network. To the best of our knowledge, no research to date has been conducted to assist network forensics investigators and cloud service providers in finding an optimal method for investigation of network vulnerabilities found in cloud networks. To this end and in this paper, the state-of-the-art C-NFMs are classified and analyzed based on the cloud network perspective using SWOT analysis. It implies that C-NFMs have a suitable impact on cloud network, which further requires for reformation to ensure its applicability in cloud networks."
  },
  {
    "year": "2016",
    "abstract": "Software-defined networking (SDN) has emerged as a new network architecture, which decouples both the control and management planes from data plane at forwarding devices. However, SDN deployment is not widely adopted due to the budget constraints of organizations. This is because organizations are always reluctant to invest too much budget to establish a new network infrastructure from scratch. One feasible solution is to deploy a limited number of SDN-enabled devices along with traditional (legacy) network devices in the network of an organization by incrementally replacing traditional network by SDN, which is called hybrid SDN (Hybrid SDN) architecture. Network management and control in Hybrid SDN are vital tasks that require significant effort and resources. Manual handling of these tasks is error prone. Whenever network topology changes, network policies (e.g., access control list) configured at the interfaces of forwarding devices (switches/routers) may be violated. That creates severe security threats for the whole network and degrades the network performance. In this paper, we propose a new approach for Hybrid SDN that auto-detects the interfaces of forwarding devices and network policies that are affected due to change in network topology. In the proposed approach, we model network-wide policy and local policy at forwarding device using a three-tuple and a six-tuple, respectively. We compute graph to represent the topology of the network. By using graph difference technique, we detect a possible change in topology. In the case of topology change, we verify policy for updated topology by traversing tree using six-tuple. If there is any violation in policy implementation, then affected interfaces are indicated and policies that need to be configured are also indicated. Then, policies are configured on the updated topology according to specification in an improved way. Simulation results show that our proposed approach enhances the network efficiency in term of..."
  },
  {
    "year": "2016",
    "abstract": "Existing studies have contributed immensely to link prediction by identifying different types of network communities. In this paper, a new type of network community in online social networks (OSNs) is identified using the association between network nodes. This new network community is called “virtual community.” Virtual communities are based on either the real/ physical relationships of users that are connected to their constituency, social, and professional activities or their virtual interactions associated with their cognitive levels, choice selection, and ideology. Users belonging to the same virtual community exhibit similar behavior in linking to nodes of common interest. These nodes, which reflect the common interest of a community, are called “prime nodes.” Prime nodes are linked to the prediction problem in OSN completion and are generally recommended for OSN growth. Recent studies on ranking algorithms have shown that the incompleteness of OSNs contributes to the low accuracy of ranking algorithms in identifying top spreaders. Thus, in this paper, we propose an OSN completion method based on link prediction through association between prime nodes. An experiment on predicting new links in two real big data sets of two global OSNs, namely, Facebook and Twitter, is conducted. The effectiveness of the proposed method is also validated by applying prominent ranking algorithms to the newly predicted and original networks. Results show that the accuracy rates of the ranking algorithms are improved, thereby validating the importance of the proposed method in predicting vital links."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a new unbalanced steady-state model of doubly fed induction generator (DFIG) for the three-phase load flow analysis. The existing unbalanced DFIG steady-state model does not consider the effects of different rotor speeds. However, the steady-state model of DFIG changes significantly when it operates at supersynchronous or subsynchronous speeds. In this paper, a new unbalanced steady-state model for DFIG operating at different speeds is discussed in detail. Furthermore, the positive-sequence active power in this model is simulated more precise than the existing DFIG models. The proposed model is validated on CIGRE six-bus test system and can be used to initialize the transient simulation for unbalanced active distribution networks."
  },
  {
    "year": "2016",
    "abstract": "Due to the large-scale and distributed characteristics of increasing renewable energy resources, dynamic economic emission dispatch (DEED) of hybrid energy resource system becomes more and more important in the power system operation. This paper proposes a distributed model predictive control (DMPC) method for hybrid energy resources system of dynamic economic optimal dispatch with large-scale decomposition coordination approach. First, the DEED model of hybrid energy resources is converted into predictive control model, which can provide rolling optimization mechanism for dealing with intermittent energy resources optimization. Second, predictive control model is decomposed into several subsystems with Lagrangian multipliers for coordinating those subsystems, which can greatly decrease the computational complexity. Third, due to the randomness or uncertainty of intermittent power generation, model predictive control can dynamically optimize random or uncertainty problem with rolling optimization mechanism. Furthermore, adaptive dynamic programming is utilized to solve those subsystem optimization problems, which can optimize the random or uncertain problem in real-time condition. In the optimization process, probability constraint is converted into deterministic constraint with its probability density function, and system load balance can be properly handled with coupled coarse-fine constraint-handling technique. According to the obtained results in the case studies, the proposed DMPC can optimize the DEED of hybrid energy resources well combining with the large-scale decomposition-coordination approach, while greatly decreasing the optimization complexity and computation time, which reveals that the proposed method can provide an alternative way for solving the DEED problem of hybrid energy resources."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a novel mechanism to model a time series of block accesses for profiling block access patterns, to intentionally direct block data prefetching. The basic idea behind this scheme is that the block accesses within a certain offset domain may have some correlations that may contribute to classify an access pattern on the file system level. Moreover, the technique of adjacency matrix is employed to represent an access pattern for accelerating pattern matching, and then benefits I/O optimization eventually. Through a series of emulation experiments based on several realistic block traces on the disk, the experimental results show that the newly proposed prefetching mechanism outperforms other comparisons. Specifically, it can reduce average I/O response time by 14.6%-17.9% in contrast to the commonly used sequential prefetching scheme, and 4.1%-10.5% compared with frequent sequence mining-based prefetching but with less space and time overhead."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we propose a novel scheme for simplifying a surfel set with the resultant surfels computed and distributed to preserve prominent geometric and textural features. It works by iteratively collapsing local neighborhoods around surfels until a given data reduction ratio is reached. For optimized feature preservation, novel techniques are proposed in various steps of the scheme. The local neighborhood collapses are prioritized according to a cost metric that takes into account the local complexities of both the geometric and the textural information. Methods for surfel attribute computation are proposed for faithful representation of geometric and textural features in the simplified model. The proposed algorithm is further extended to support out-of-core simplification for large models by optimally determining the reduction ratios for different parts of the model in consideration of the surface features. Experimental results demonstrate the outstanding performance of the proposed scheme."
  },
  {
    "year": "2016",
    "abstract": "Network densification is foreseen as a potential solution to fulfill the 5G spectral efficiency requirements. The spectral efficiency is improved by shrinking base stations' (BSs) footprints, thus improving the spatial frequency reuse and reducing the number of users sharing the resources of each BS. However, the foreseen densification gains are achieved at the expense of increasing handover (HO) rates. Hence, HO rate is a key performance limiting factor that should be carefully considered in densification planning. This paper sheds light on the HO problem that appears in dense 5G networks and proposes an effective solution via topology aware HO skipping. Different skipping techniques are considered and compared with the conventional best connected scheme. To this end, the proposed schemes are validated via the average user rate in downlink single-tier and two-tier cellular networks, which are modeled using the Poisson point process and the Poisson cluster process, respectively. The proposed skipping schemes show up to 47% gains in the average throughput, which would maximize the benefit of network densification."
  },
  {
    "year": "2016",
    "abstract": "In this paper, distributed time-varying formation (TVF) control problems for general linear swarm systems with switching interaction topologies are investigated using an adaptive dynamic protocol. First, a TVF control protocol for switching interaction topologies is constructed using the states of neighboring agents. In the protocol, an adaptive controller that employs gain scheduling technique is provided to estimate the coupling weights among agents. Compared with the previous studies on formation control, the desired formation can be specified by piecewise continuously time-varying differentiable vectors, the interaction topology can be switching, and the disadvantage of requiring global information of the interaction topologies is removed in this paper. Then, an algorithm including a feasible formation condition is proposed to determine the gain matrices of the distributed adaptive formation protocol by solving a linear matrix inequality for swarm systems with switching interaction topologies. Moreover, under the designed distributed adaptive formation protocol, sufficient condition for general linear swarm systems with switching interaction topologies to achieve the given TVF is derived using the Lyapunov theory. Finally, numerical simulations are presented to demonstrate the obtained results."
  },
  {
    "year": "2016",
    "abstract": "Two novel blind equalization techniques for odd bit rectangular quadrature amplitude modulation (RQAM) signaling are proposed in this paper, namely, rectangular contour algorithm (RRECTCA) and improved rectangular contour algorithm (IRCA). The proposed RRECTCA algorithm minimizes the dispersion of constant with respect to a rectangular-shaped zero error contour. The algorithm exploits the geometry of the RQAM to correct phase error within 180°, thus enhancing the convergence rate while minimizing the equalizer mis-adjustments. On the other hand, the proposed IRCA algorithm employs the estimated output from the decision device into the cost function, thus guiding the equalizer output to reside on multiple zero error rectangular shaped moduli. This method of feeding back the slicer output further reduces the mis-adjustment between the transmitted constellation and the new cost function in an efficient manner, which leads to faster convergence and better intersymbol interference suppression. The proposed algorithms can also work for the square QAM by mere change of only two constellation dependent constants, thus facilitating the implementation in hardware to enable transmission of both even and odd number of bits per symbol based constellations. Steady-state error analysis, MSE, and residual ISI comparison through the simulation results confirm the good performance of the proposed algorithms. Furthermore, the convergence characteristics of the proposed IRCA scheme establish the supremacy of IRCA over RRECTCA, which is its parent algorithm."
  },
  {
    "year": "2016",
    "abstract": "This paper presents numerical simulation results to study the impact of the co-existence between a fixed service (FS) system and 5G small cell networks at 28-, 38-, and 60-GHz millimeter-wave (mmWave) frequency bands. For this paper, two scenarios are considered: aggregation of interference from small cells into an FS receiver from base stations (BSs) to their associated user equipment (UE) (downlink) and the aggregation of cellular interference at the FS receiver from UEs to their associated BSs (downlink). Moreover, mmWave-specific propagation characteristics and attenuation factors are considered for a more precise simulation study. The simulation results determine how much interference rejection is required to protect the operation of FS. In addition, currently available mmWave modular antenna array (MAA) architectures are introduced. Based on the information, additionalmmWave frequency sharing study is performed using the realistic MAA radiation patterns. Last, we compare and analyze the performance differences between ITU standard models and MAA solutions."
  },
  {
    "year": "2016",
    "abstract": "It is of significant importance for any classification and recognition system, which claims near or better than human performance to be immune to small perturbations in the dataset. Researchers found out that neural networks are not very robust to small perturbations and can easily be fooled to persistently misclassify by adding a particular class of noise in the test data. This, so-called adversarial noise severely deteriorates the performance of neural networks, which otherwise perform really well on unperturbed dataset. It has been recently proposed that neural networks can be made robust against adversarial noise by training them using the data corrupted with adversarial noise itself. Following this approach, in this paper, we propose a new mechanism to generate a powerful adversarial noise model based on K-support norm to train neural networks. We tested our approach on two benchmark datasets, namely the MNIST and STL-10, using muti-layer perceptron and convolutional neural networks. Experimental results demonstrate that neural networks trained with the proposed technique show significant improvement in robustness as compared to state-of-the-art techniques."
  },
  {
    "year": "2016",
    "abstract": "The essential idea behind physical-layer network coding (PNC) is to superimpose signals so as to improve throughput. Current studies focus mainly on PNC over the AWGN or Rayleigh channels without consideration of burst pulses. This paper aims to evaluate the bit error rate (BER) performance of classical PNC, over a mixed channel that considers the combined effects of Gaussian noise and burst pulses. Besides, this paper explores the use of the Reed-Solomon (RS) codes to improve the BER performance of PNC over the mixed channel. Simulation results show that burst pulses deteriorate the BER significantly, and the RS codes are able to compensate for substantial BER performance degradation."
  },
  {
    "year": "2016",
    "abstract": "This paper describes two ceramic-forming technologies based on 3-D printing. One technology forms the product with 3-D printing indirectly, while the other technology forms the product directly with 3-D printing. The whole 3-D printing technique, including computer-aided design, 3-D printing of a model with plastic filament, molding with plaster, and slip-casting, was shown to produce a pineapple cup. Compared with the traditional ceramic-forming technology, the new method is more efficient, and articles can be precisely made especially for mass production of complicated designs."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio (CR) represents the proper technological solution in case of radio resources scarcity and availability of shared channels. For the deployment of CR solutions, it is important to implement proper sensing procedures, which are aimed at continuously surveying the status of the channels. However, accurate views of the resources status can be achieved only through the cooperation of many sensing devices. For these reasons, in this paper, we propose the utilization of the Social Internet of Things (SIoT) paradigm, according to which objects are capable of establishing social relationships in an autonomous way, with respect to the rules set by their owners. The resulting social network enables faster and trustworthy information/service discovery exploiting the social network of “friend” objects. We first describe the general approach according to which members of the SIoT collaborate to exchange channel status information. Then, we discuss the main features, i.e., the possibility to implement a distributed approach for a low-complexity cooperation and the scalability feature in heterogeneous networks. Simulations have also been run to show the advantages in terms of increased capacity and decreased interference probability."
  },
  {
    "year": "2016",
    "abstract": "Two popular representation learning paradigms are dictionary learning and deep learning. While dictionary learning focuses on learning “basis” and “features” by matrix factorization, deep learning focuses on extracting features via learning “weights” or “filter” in a greedy layer by layer fashion. This paper focuses on combining the concepts of these two paradigms by proposing deep dictionary learning and show how deeper architectures can be built using the layers of dictionary learning. The proposed technique is compared with other deep learning approaches, such as stacked autoencoder, deep belief network, and convolutional neural network. Experiments on benchmark data sets show that the proposed technique achieves higher classification and clustering accuracies. On a real-world problem of electrical appliance classification, we show that deep dictionary learning excels where others do not yield at-par performance. We postulate that the proposed formulation can pave the path for a new class of deep learning tools."
  },
  {
    "year": "2016",
    "abstract": "The ever-increasing advancement in communication technologies of modern smart objects brings with it a newera of application development for Internet of Things (IoT)-based networks. In particular, owing to the contactless-ness nature and efficiency of the data retrieval of mobile smart objects, such as wearable equipment or tailored bio-sensors, several innovative types of healthcare systems with body sensor networks (BSN) have been proposed. In this paper, we introduce a secure IoT-based healthcare system, which operates through the BSN architecture. To simultaneously achieve system efficiency and robustness of transmission within public IoT-based communication networks, we utilize robust crypto-primitives to construct two communication mechanisms for ensuring transmission confidentiality and providing entity authentication among smart objects, the local processing unit and the backend BSN server. Moreover, we realize the implementation of the proposed healthcare system with the Raspberry PI platform to demonstrate the practicability and feasibility of the presented mechanisms."
  },
  {
    "year": "2016",
    "abstract": "In this paper, the energy recovery in microstrip passive circuits from the power losses into heat is studied. For this purpose, a thermoelectric generator (TEG) based on the Seebeck effect principle is used, which converts part of the power dissipated into heat to dc electrical power. A solution integrating the TEG with the microstrip circuit is proposed, and design guidelines in order to optimize the recovered power keeping a good isolation between the RF signal and the TEG system are provided. As will be shown, under moderate applied signal powers of just 1-5 W, the levels of recovered power in microstrip passive circuits can be notable. As a demonstrator circuit, an integration device formed by an embedded microstrip bandpass filter for WiMAX applications and a TEG is designed, fabricated, and characterized (thermal and electrically). Different scenarios are considered, depending on frequency and thermal loads. For an applied inband CW input signal power of 2 W at 3.48 GHz, a recovered power of around 250 μW has been continuously supplied to the electrical load. Several aspects, such as efficiency and future improvements, are also discussed."
  },
  {
    "year": "2016",
    "abstract": "In this paper, the output tracking problem for a large class of uncertain nonlinear systems with arbitrary integrator powers and nonlinearly parameterized unknown dynamics is addressed by employing an innovative tool called adding an universal power integrator (AUPI). By virtue of the AUPI methodology, flexible degrees of homogeneous are incorporated to mask rich diversities in integrator powers rather than simply positive odd integers involved in previous works. Moreover, a universal gain is adaptively updated according to the tracking error, which can converge into an arbitrarily small region including the origin, and thereby contributing to bounded but large enough controller gain and prescribed tracking accuracy. Numerical examples demonstrate the effectiveness of the proposed AUPI-based adaptive tracking control scheme."
  },
  {
    "year": "2016",
    "abstract": "Industrial wireless sensor networks (IWSNs) are required to provide highly reliable and real-time transmission. Moreover, for connected K-neighborhood (CKN) sleep scheduling-based duty-cycled IWSNs in which the network lifetime of IWSNs can be prolonged, the two-phase geographic greedy forwarding (TPGF) geographic routing algorithm has attracted attention due to its unique transmission features: multi path, shortest path, and hole bypassing. However, the performance of TPGF in CKN-based duty-cycled IWSNs with radio irregularity is not well investigated in the literature. In this paper, we first evaluate the impact of radio irregularity on CKN-based duty-cycled IWSNs. Furthermore, we investigate the routing performance of TPGF in CKN-based duty-cycled IWSNs with radio irregularity, in terms of the number of explored routing paths as well as the lengths of the average and shortest routing paths. Particularly, we establish the upper bound on the number of explored routing paths. The upper bound is slightly relaxed with radio irregularity compared with without radio irregularity; however, it is bounded by the number of average 1-hop neighbors in always-on IWSNs. With extensive simulations, we observe that the cross-layer optimized version of TPGF (i.e., TPFGPlus) finds reliable transmission paths with low end-to-end delay, even in CKN-based duty-cycled IWSNs with radio irregularity."
  },
  {
    "year": "2016",
    "abstract": "Healthcare data are becoming increasingly important in the life of people. By utilizing healthcare data in a proper and secure manner, the elderly may avoid some sudden diseases, whereas young people can monitor their health condition. In the hospital, for certain sizes of detection objects, an effective method of data transmission becomes very significant. In view of the movement of patients in the hospital, we introduce a type of network called incompletely predictable networks to describe such scenarios. The patients move in a certain trend or are only active in a certain limited range. To achieve high performance when transmitting healthcare data in such networks, a novel protocol called the direction density-based secure routing protocol is proposed in this paper. Both the moving direction and the influence of node group movement are considered. The novel protocol innovatively takes the density of the node moving direction into consideration, which makes full use of the relationships among the moving individuals. Moreover, the design of the secure routing with authenticated message transmission ensures secure healthcare data communication. The simulation shows that our protocol achieves a high packet delivery ratio with low overhead and end-to-end delay."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a novel planar dual-band coupled-line balun with impedance transformation and high isolation. Closed-form design equations are obtained based on the classical even-odd mode equivalent approach. For convenience of designing and synthesizing such a novel dual-band balun, the practical ranges of the frequency ratio, terminated impedances, and two free variables are provided under the conventional microstrip fabrication constraints. By adopting four coupled-line sections, six transmission-line stubs, and an isolation resistor, a microstrip prototype balun working at 1.0/2.6 GHz is designed, fabricated, and measured. There is a good agreement between the simulated and measured results. The wide bandwidths of 290 MHz from 0.83 to 1.12 GHz and 270 MHz from 2.44 to 2.71 GHz are obtained with the measured return losses (|S11|, |S22|, |S33|) and the isolation (|S23|) better than 10 dB, which effectively confirm the proposed theoretical predictions."
  },
  {
    "year": "2016",
    "abstract": "Different educational and didactic papers that allow students to experimentally validate linear controllers have been reported. However, generally, in those papers, procedure followed to select controller gains is not discussed. This lack of information renders difficult experimental implementation of controllers by students who, in general, do not have enough experience on controller tuning. Motivated by this situation, this paper introduces a methodology that provides important information on how to select controller gains for regulation in a Furuta pendulum. This methodology allows improving closed-loop system performance in a desired direction. Differential flatness is the Furuta pendulum property that is exploited. The main idea is to translate a linear state feedback control design problem into a scenario, where classical tools such as root locus can be used. As an example, controller design is directed toward reduction or even elimination of limit cycle effects. The proposal is experimentally tested on a built Furuta pendulum. These experimental results show that the closed-loop system performance is improved, and hence, the proposed methodology is successfully validated."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we first present the significance of information theory and several commonly referred concepts associated with it. Then, the communication channel models constructed by information theory are briefly introduced. Meanwhile, the channel capacity, as a key role in modeling a channel, is expatiated. In addition, source coding and channel coding are compared and explained with a number of simulations. By reading this paper, the readers are expected to understand the significance of information theory as well as the indispensable roles of source coding and channel coding in a communication system. Furthermore, most of the techniques and fundamentals introduced and analyzed in this paper are feasible for the big data analytics in cyber-physical systems, which pave the way for coding over these newborn systems."
  },
  {
    "year": "2016",
    "abstract": "When and why people change their mobile phones are important issues in mobile communications industry, because it will impact greatly on the marketing strategy and revenue estimation for both mobile operators and manufactures. It is a promising way to take use of big data to analyze and predict the phone changing event. In this paper, based on mobile user big data, first through statistical analysis, we find that three important probability distributions, i.e., power-law, log-normal, and geometric distribution, play an important role in the user behaviors. Second, the relationships between eight selected attributes and phone changing are built, for example, young people have greater intention to change their phones if they are using the phones belonging to the low occupancy phones or feature phones. Third, we verified the performance of four prediction models on phone changing event under three scenarios. Information gain ratio was used to implement attribute selection and then sampling method, cost-sensitive together with standard classifiers were used to solve imbalanced phone changing event. Experiment results show our proposed enhanced backpropagation neural network in the undersampling scenario can attain better prediction performance."
  },
  {
    "year": "2016",
    "abstract": "Receiver operating characteristic (ROC) curve is a plot traced out by pairs of false-positive rate and true-positive rate according to various decision threshold settings. The area under the ROC curve (AUC) is widely used as a figure of merit to summarize a diagnostic system's performance, a binary classifier's overall accuracy, or an energy detector's power. Exploiting the equivalent relationship between the sample version of AUC and Mann Whitney U statistic (MWUS), in this paper, we develop an efficient algorithm of linearithmic order, based on dynamic programming, for unbiased estimation of the mean and variance of MWUS. Monte Carlo simulations verify our algorithmic findings."
  },
  {
    "year": "2016",
    "abstract": "Named data networking (NDN) aims at efficient content delivery and reducing the redundancy of data transmission. In NDN, one of the most important issues is how to utilize the cached contents to reduce the user's response delay and improve the utilization of the cache resources. In this paper, an intelligent content discovery system to fully utilize the cache resources, called DENA, is proposed, which encompasses the deep exponential network-based cache announcement and cache exergy-based cache replacement algorithms. DENA provides shortcut paths for interest packets to access targeted data packets under instructions of AT (announcement table) constructed by a precision cached content announcement algorithm with low communication overhead. In the meantime, a cache replacement algorithm to assist the cache announcement is also proposed. The method uses a so-called cache exergy index to instruct the replacement of cached content. The simulation results indicate that the system improves the utilization of cache resources and the network capacity while keeping the network control traffic at a relatively low level."
  },
  {
    "year": "2016",
    "abstract": "The main objective of this paper is to design a dynamic surface adaptive fuzzy controller for a three-phase active power filter (APF). In order to deal with the nonlinearity of the APF, a fuzzy strategy combining an adaptive backstepping method is proposed where fuzzy controller is mainly responsible for the elimination of nonlinearities. Moreover, by adopting the dynamic surface method, the number of input variables of the fuzzy system in modeling could be reduced; therefore, the controller and design parameters can be implemented without complex calculation. The Lyapunov stability of closed-loop system with the fuzzy control, sliding control, and dynamic surface control could be assured. The simulation results prove that the dynamic surface adaptive fuzzy method has excellent performance in stability, robustness, adaptability, and total harmonic distortion (THD), which is confirmed to suppress harmonics effectively."
  },
  {
    "year": "2016",
    "abstract": "In the background of high-power propulsion application on ships and existing uncertain electromagnetic and vibration features of multiphase fractional-slot concentrated-winding permanent magnet (PM) motor, the electromagnetic design and analysis methods of six-phase fractional-slot concentrated-winding PM motor are presented. Four different pole and slot combination schemes are sifted out, and air-gap magnetic field and electromagnetic force of these four motors are studied in contrast. On the basis of the above, a 20-kW prototype of six-phase fractional-slot concentrated-winding PM motor with 48 slots and 44 poles is designed and manufactured, and its electromagnetic and vibration performances are tested through experiments. The test results are in good agreement with calculations, which could guide the development of high-power ship propulsion."
  },
  {
    "year": "2016",
    "abstract": "Wireless body area networks (BANs) have attracted enormous attention due to the promising applications in healthcare systems. Energy saving is one of the major challenges in wireless BANs, because the sensors operating on or inside a human body are energy limited. As the applying cooperative communications offers energy saving, it is necessary to utilize the sensor devices jointly in BANs to form cooperative communication. In this paper, the energy consumption models of cooperative transmission strategies are built over in- and on-body wireless communication links for direct and relay transmission scenarios. In relay cooperative strategy, the implantable and wearable devices work together by using a cooperative multiple input multiple output (MIMO) technique. In direct cooperative strategy, two wearable devices operate as the cooperative MIMO. In these ways, the energy savings of both direct and relay transmissions are achieved during the data transmission in BANs. Moreover, the closed-form expression of end-to-end average bit error ratio (BER) is derived toward minimizing the required transmission power for relay transmission scenario. In the results, it is demonstrated that the significant energy savings of the proposed cooperative transmission strategies can be obtained compared with the existing approaches under the same conditions."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we make an investigation of the problem of passive multi-satellite localization based on time differences of arrival (TDOA) with Earth constraint (EC). By utilizing TDOA measurements and EC, the problem of estimating target position is formulated as a quadratically constrained quadratic optimization. Following this, the approximate analytic solution of target position is obtained by using the method of Lagrange multipliers and deleting the infeasible roots of polynomial in the Lagrange multiplier. Simulation results show that the proposed method can achieve the Cramer-Rao lower bound (CRLB) with EC for three typical scenarios, even in the worst case, e.g., in the presence of large TDOA measurement errors with even target being far from the subastral point. However, the existing TDOA localization methods will deviate from the CRLB with EC as the measurement error of TDOA increases. Thus, the proposed method is more robust compared with the existing methods. In addition, the EC has a significant impact on the TDOA localization performance. Compared with the case of no EC, the EC can make a one-order-magnitude improvement in localization precision."
  },
  {
    "year": "2016",
    "abstract": "The increasing number of wireless devices, the high required traffic bandwidth, and power consumption will lead to a revolution of mobile access networks, which is not a simple evolution of traditional ones. Cloud radio access network technologies are seen as promising solution in order to deal with the heavy requirements defined for 5G mobile networks. The introduction of the common public radio interface (CPRI) technology allows for a centralization in BaseBand unit (BBU) of some access functions with advantages in terms of power consumption saving when switching off algorithms are implemented. Unfortunately, the advantages of the CPRI technology are to be paid with an increase in required bandwidth to carry the traffic between the BBU and the radio remote unit (RRU), in which only the radio functions are implemented. For this reason, a tradeoff solution between power and bandwidth consumption is proposed and evaluated. The proposed solution consists of: 1) handling the traffic generated by the users through both RRU and traditional radio base stations (RBS) and 2) carrying the traffic generated by the RRU and RBS (CPRI and Ethernet flows) with a reconfigurable network. The proposed solution is investigated under the lognormal spatial traffic distribution assumption. After proposing resource dimensioning analytical models validated by simulation, we show how the sum of the bandwidth and power consumption may be minimized with the deployment of a given percentage of RRU. For instance we show how in 5G traffic scenarios this percentage can vary from 30% to 50% according to total traffic amount handled by a switching node of the reconfigurable network."
  },
  {
    "year": "2016",
    "abstract": "Non-orthogonal multiple access (NOMA) is envisioned to be one of the essential technologies for the fifth generation mobile network. In this paper, we implement a practical downlink NOMA system based on an open-source software defined radio (SDR) platform named as OpenAirInterface (OAI). For comparison purpose, our SDR-based NOMA system follows the basic specifications of long term evolution (LTE). In this system, a codeword-level successive interference cancellation (SIC) receiver is implemented. To improve the efficiency of the baseband signal processing in an SIC receiver, a multi-thread processing method is also introduced. Due to the limitation of original downlink control information (DCI) formats in current LTE systems, a new DCI format is dedicatedly designed for signal reconstitution in our developed NOMA system. Furthermore, some parts of upper layer protocols in LTE systems are modified to support the application services over the developed NOMA system. Based on our NOMA system, a series of over-the-air experiments are carried out, and the experiment results demonstrate that the NOMA scheme has a significant throughput gain compared with an orthogonal multiple access (OMA) scheme."
  },
  {
    "year": "2016",
    "abstract": "The brain-computer interface (BCI) identifies brain patterns to translate thoughts into action. The identification relies on the performance of the classifier. In this paper, identification and monitoring of electroencephalogram-based BCI for motor imagery (MI) task is proposed by an efficient adaptive neuro-fuzzy classifier (NFC). The Jaya optimization algorithm is integrated with adaptive neuro-fuzzy inference systems to enhance classification accuracy. The linguistic hedge (LH) is used for proper elicitation and pruning of the fuzzy rules and network is trained using scaled conjugate gradient (SCG) and speeding up SCG (SSCG) techniques. In this paper, Jaya-based k-means is applied to divide the feature set into two mutually exclusive clusters and fire the fuzzy rule. The performance of the proposed classifier, Jaya-based NFC using SSCG as training algorithm and is powered by LH (JayaNFCSSCGLH), is compared with four different NFCs for classifying two class MI-based tasks. We observed a shortening of computation time per iteration by 57.78% in the case of SSCG as compared with the SCG technique of training. LH-based feature selecting capability of the proposed classifier not only reduces computation time but also improves the accuracy by discarding irrelevant features. Lesser computation time with fast convergence and high accuracy among considered NFCs make it a suitable choice for the real-time application. Supremacy of JayaNFCSSCGLH among the considered classifier is validated through Friedman test. Classification result is used to control switching of light emitting diode, turning thoughts into action."
  },
  {
    "year": "2016",
    "abstract": "Due to energy and throughput constraints of visual sensing nodes, in-node energy conservation is one of the prime concerns in visual sensor networks (VSNs) with wireless transceiving capability. To cope with these constraints, the energy efficiency of a VSN for a given level of reliability can be enhanced by reconfiguring its nodes dynamically to achieve optimal configurations. In this paper, a unified framework for node classification and dynamic self-reconfiguration in VSNs is proposed. The proposed framework incorporates quality-of-information (QoI) awareness using peak signal-to-noise ratio-based representative metric to support a diverse range of applications. First, for a given application, the proposed framework provides a feasible solution for the classification of visual sensing nodes based on their field-of-view by exploiting the heterogeneity of the targeted QoI within the sensing region. Second, with the dynamic realization of QoI, a strategy is devised for selecting suitable configurations of visual sensing nodes to reduce redundant visual content prior to transmission without sacrificing the expected information retrieval reliability. The robustness of the proposed framework is evaluated under various scenarios by considering: 1) target QoI thresholds; 2) degree of heterogeneity; and 3) compression schemes. From the simulation results, it is observed that for the second degree of heterogeneity in targeted QoI, the unified framework outperforms its existing counterparts and results in up to 72% energy savings with as low as 94% reliability."
  },
  {
    "year": "2016",
    "abstract": "With the advance of software receiver, multipath estimation becomes a key issue for high accuracy positioning systems. It is crucial for eliminating the multipath error and improving the positioning accuracy to estimate multipath parameters. The accessible multipath estimation algorithms are usually designed for Gaussian noise, and their performances degrade dramatically in non-Gaussian noise, since the mean square error criterion is adopted. To tackle the problem, a new filter based on centered error entropy criterion (CEEC) is proposed for multipath estimation. In the proposed filter, the CEEC is considered as a performance index, which is not limited to the assumption of Gaussian and linearity. According to a stochastic information gradient method, an optimal filer gain matrix is obtained by maximizing the performance function of centered error entropy. Meanwhile, a convergence analysis of the proposed filter is offered. Furthermore, a recursive estimation method based on modified Parzen windowing technique is proposed for practical implementation. The simulation results indicate that the proposed filter outperforms the filter based on minimum error entropy criterion for multipath estimation."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we demonstrate that the solid cylinder dielectric resonator antenna (CDRA) is a high radiation efficient device to generate orbital angular momentum (OAM) waves with different OAM modes at different frequencies. Theoretical formulations of its radiation fields are deduced in the cylindrical coordinate system, which shows that all components of the electric and magnetic fields have the azimuth dependence of ejmφ. A full-wave simulation on a practical size CDRA is then implemented to validate the theoretical derivations. The simulation results show that different separated OAM modes can be obtained at different frequencies. Specifically, the higher order OAM modes are generated at higher electron magnetic modes, which makes CDRA a promising method to overcome the narrow band and multiband issues existing in the design of current OAM devices. Furthermore, a maximum radiation efficiency of 97.1% at 13.3 GHz, and a minimum radiation efficiency of 72.4% at 19.45 GHz are obtained in our simulation, which is a high radiation efficiency feature at the OAM resonant frequencies."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a novel near-lossless color filter array (CFA) image compression algorithm based on JPEG-LS is proposed for VLSI implementation. It consists of a pixel restoration, a prediction, a run mode, and entropy coding modules. According to the information of the previous research, a context table and row memory consumed more than 81% hardware cost in a JPEG-LS encoder design. Hence, in this paper, a novel context-free and near-lossless image compression algorithm is presented. Since removing the context model causes decreasing of the compression performance, a novel prediction, run mode, and modified Golomb-Rice coding techniques were used to improve the compression efficiency. The VLSI architecture of the proposed image compressor consists of a register bank, a pixel restoration module, a predictor, a run mode module, and an entropy encoder. A pipeline technique was used to improve the performance of this. It contains only 10.9k gate count, and the core area is 30625 μm2, synthesized by using a 90-nm CMOS process. Compared with the previous JPEG-LS designs, this paper reduces the gate counts by 44.1% and 41.7%, respectively, for five standard and eight endoscopy testing images in CFA format. It also improves the average PSNR values by 0.96 and 0.43 dB, respectively, for the same test images."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we investigate the data delivery delay from source to destination for VANETs on bi-directional roadways. The topology includes bi-directional roadways, left-turn lane, straight through lane, right-turn lane with traffic lights deployed at the intersections. Due to the multi-hop feature of data delivery and the limited range of radio transmission, the roadways' topology and the switch operations of traffic lights will jointly affect the data delivery delay. By employing the queuing theory and analyzing the traffic lights operations, we propose the formulae of data delivery delay for different scenarios and extend the analysis to a more general scenario. We find that in the scenario of single intersection, the data delivery delay can be reduced by appropriately selecting the relay nodes. Specifically, in the case of green traffic light at the intersection, opposite lane vehicles can be used to reduce the delay, while for red traffic light, left-turn lane vehicles are used to reduce the delay in a similar approach, i.e., by using multi-hop transmission. The proposed algorithm is verified on single lane roadway, opposite-only, and left-turn-only lane for different simulation time slots, the number of mobile nodes and the value of R/W (R is the wireless communication range and W is the length of the road intersection) through VanetMobiSim and NS-2. Numerical results show that for single intersection, the data delivery delay can be reduced by choosing appropriate relay nodes. Besides, the successful packet delivery rate of bi-directional roadway is better than that of single line roadway scenario."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a novel scalable digit-serial inverter structure with low space complexity to perform inversion operation in GF(2m) based on a previously modified extended Euclidean algorithm. This structure is suitable for fixed size processor that only reuse the core and does not require to modulate the core size when m modified. This structure is extracted by applying a nonlinear methodology that gives the designer more flexibility to control the processing element workload and also reduces the overhead of communication between processing elements. Implementation results of the proposed scalable design and previously reported efficient designs show that the proposed scalable structure achieves a significant reduction in the area ranging from 83.0% to 88.3% and also achieves a significant saving in energy ranging from 75.0% to 85.0% over them, but it has lower throughput compared to them. This makes the proposed design more suitable for constrained implementations of cryptographic primitives in ultra-low power devices such as wireless sensor nodes and radio frequency identification (RFID) devices."
  },
  {
    "year": "2016",
    "abstract": "Caching popular contents at mobile devices can potentially improve the quality of service for mobile users and relieve traffic burden of base station in cellular networks. In this paper, we jointly consider the resource allocation, the cached contents, and the distance between two devices for the optimal device pairing problem in centralized and distributed cases, where the BS is the central controller in the centralized case. The joint optimization problem of device-to-device (D2D) caching with channel allocation is formulated as a weighted four-uniform hypergraph model. The optimal solution for the problem is 4-D maximum weighted matching (4-DMWM), which is NP-hard unfortunately. To approach the 4-DMWM with low-complexity, we adopt the greedy algorithm and the squareIMP algorithm in the centralized case. Moreover, distributed algorithms are also designed for the caching problem in both synchronous and asynchronous cases. The simulation results will illustrate that the squareIMP algorithm can be used to get a better transmission rate with the complexity of O(n5), while the greedy algorithm can be used in the case with stringent latency requirement for centralized 4-DMWM problem. The sum rate of distributed asynchronous algorithm is close to the centralized greedy algorithm with the complexity of O(n2) for each device. However, the simulation result of the synchronous algorithm is slightly lower than the centralized algorithm, where each device performs O(n2) computational operations in each iteration. Therefore, the algorithms proposed in this paper can be used in different cases for solving optimal D2D pairing and channel allocation problem."
  },
  {
    "year": "2016",
    "abstract": "Recently, position-patch-based face hallucination methods have received much attention, and obtained promising progresses due to their effectiveness and efficiency. A locality-constrained double low-rank representation (LCDLRR) method is proposed for effective face hallucination in this paper. LCDLRR attempts to directly use the image-matrix based regression model to compute the representation coefficients to maintain the essential structural information. On the other hand, LCDLRR imposes a low-rank constraint on the representation coefficients to adaptively select the training samples that belong to the same subspace as the inputs. Moreover, a locality constraint is also enforced to preserve the locality and the sparsity simultaneously. Compared with previous methods, our proposed LCDLRR considers locality manifold structure, cluster constraints, and structure error simultaneously. Extensive experimental results on standard face hallucination databases indicate that our proposed method outperforms some state-of-the-art algorithms in terms of both visual quantity and objective metrics."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes an effective method to improve the saliency detection performance of existing RGBD (RGB image with Depth map) saliency models. First, a progressive region classification method is proposed to collect training samples at coarse scale and fine scale via the inter-region hierarchical structure. A random forest regressor is then learned to predict the coarse saliency map and fine saliency map, respectively. Finally, the saliency maps at the two scales are integrated into the final saliency map under the constraint of the inter-region hierarchical structure. Experimental results on a RGBD image data set and a stereoscopic image data set with comparisons with the state-of-the-art saliency models validate that the proposed method consistently improves the saliency detection performance of various saliency models."
  },
  {
    "year": "2016",
    "abstract": "In the wake of the extensive application of the fourth generation system, investigations of new technologies have been moving ahead vigorously to embrace the next generation communications in 2020. Thereinto, the technique of ultra-dense networks (UDNs) serves as a key enabler in meeting the roaring mobile traffic demands. With the prevalence of mobile Internet services especially those involve the mobile payment, security has gained an unprecedented amount of attention and become a highlighted feature for the fifth generation. Resource allocation, one of the most significant tools on getting over the obstacle of ubiquitous interference as well as elevating the spectrum/energy efficiency, has attracted substantial efforts, whereas not much of them consider the information security. In a word, security-oriented resource allocation is a non-ignorable field in UDNs resource management, which still needs further study. This paper takes the safety performance as the pivotal issue and refers to the core idea of physical layer security, trying to pave a way for the security design under the framework of the densified networks. In particular, a review of the classical techniques in physical layer security is given from the perspective of resource allocation, which may enlighten the security-based resource management in UDNs. Besides, the challenges as well as potential problems are identified on the basis of the characteristics of UDNs, which can be favorable for targeting the future efforts. In a case study, it is shown that effective blockage of the eavesdropper in UDNs is achievable with the aid of physical layer security, and that the spectrum efficiency is also improved through the careful resource allocation."
  },
  {
    "year": "2016",
    "abstract": "Femtocells in two-tier femto-macro networks can enhance indoor coverage and improve overall network performance. Macro networks may share spectrum with overlaid femtocells so as to improve spectral efficiency. However, the deployment of femtocells also brings co-tier and cross-tier interferences, which will significantly degrade system performance. In order to solve this problem efficiently, we propose a distributed scheme to manage wireless resources in this heterogeneous networks. The feasible solution can be obtained by dividing the problem into two sub-problems. First, we propose a femtocells clustering scheme, which uses a mathematical modeling idea based on LINGO, an optimization software that can solve the joint clustering problem for the femtocell access points (FAPs). The proposed branch-and-bound algorithm and the simplex algorithm are used jointly to find the optimal solution by LINGO. The optimality of the proposed clustering algorithm is verified both theoretically and through simulations where the comparison with other algorithms is made. Second, a novel algorithm is proposed to allocate sub-channels to the femtocell users (FUEs). Compared with other related schemes, the proposed channel-allocation algorithm can reduce the interference more effectively and achieve higher data-rate fairness among FUEs. Specifically, according to the situation that the FUEs move in the room, the FUE mobility model is proposed to predict the change tendency of path loss values of the FUEs, which can guarantee the mobile service quality and improve system capacity effectively. Finally, the power of the FAPs is adjusted dynamically through setting the interference threshold to further improve the performance of the system."
  },
  {
    "year": "2016",
    "abstract": "Aging well consists of the following components: management of chronic conditions, maintenance of physical health and cognitive health, and active social engagement. However, the increasing life expectancy, rising healthcare costs, increasing number of older adults, and decreasing number of care providers pose challenges to the maintenance of different components for aging well. To that end, technological innovation can help to augment human need and capability along the different components, and help overcome the potential barriers in aging well. In this paper, we summarize the published studies for different tablet-based applications designed specifically for older adults targeting different components of aging well. We discuss the strengths and weaknesses of the applications for each component, and identify the opportunities to develop a cohesive application for addressing the different components of aging well."
  },
  {
    "year": "2016",
    "abstract": "Power consumption is one of the major concerns for the cloud providers. The issue of disorganized power consumption can be categorized into two main groups: one caused by server operations and one occurred during the network communications. In this paper, a platform for virtual machine (VM) placement/migration is proposed to minimize the total power consumption of cloud data centers (DCs). The main idea behind this paper is that with the collaboration of optimization scheduling and estimation techniques, the power consumption of DC can be optimally lessened. In the platform, an estimation module has been embedded to predict the future loads of the system, and then, two schedulers are considered to schedule the expected and unpredicted loads, respectively. The proposed scheduler applies the column generation technique to handle the integer linear/quadratic programming optimization problem. Also, the cut-and-solve-based algorithm and the call back method are proposed to reduce the complexity and computation time. Finally, numerical and experimental results are presented to validate our findings. Adaptation and scalability of the proposed platform result in a notable performance in VM placement and migration processes. We believe that our work advances the state of the art in workload estimation and dynamic power management of cloud DCs, and the results will be helpful to cloud service providers in achieving energy saving."
  },
  {
    "year": "2016",
    "abstract": "This paper discusses a novel conceptual formulation of the fractional-order Euler-Lagrange equation for the fractional-order variational method, which is based on the fractional-order extremum method. In particular, the reverse incremental optimal search of the fractional-order variational method is based on the fractional-order steepest descent approach. Fractional calculus has been applied to the solution of a necessary condition for the fractional-order fixed boundary optimization problems in signal processing and image processing mainly because of its inherent strengths in terms of long-term memory, non-locality, and weak singularity. At first, for the convenience of comparison, the first-order Euler-Lagrange equation for the first-order variational method is derived based on the first-order Green formula. Second, the fractional-order Euler-Lagrange equation for the fractional-order variational method is derived based on Wiener-Khintchine theorem. Third, in order to directly and easily achieve the fractional-order variational method in the spatial domain or the time domain, the fractional-order Green formula and the fractional-order Euler-Lagrange equation based on the fractional-order Green formula are derived, respectively. Fourth, the solution procedure of the fractional-order Euler-Lagrange equation is derived. Finally, a fractional-order inpainting algorithm and a fractional-order denoising algorithm based on the fractional-order variational method are illustrated, respectively. The capability of restoring and maintaining the edges and textural details of the fractional-order image restoration algorithm based on the fractional-order variational method is superior to that of the integer-order image restoration algorithm based on the classical first-order variational method, especially for images rich in textural details. The fractional-order Euler-Lagrange equation for the fractional-order variational method proposed by this paper is a necessary condition fo..."
  },
  {
    "year": "2016",
    "abstract": "Wireless caching at network edges (in user devices or in base stations) is considered to be a promising solution to alleviate backhaul overload in future wireless networks. Device-to-Device (D2D)-assisted caching emerges as an attractive option. Due to the nature of D2D communications, social networks and the characteristics within are intertwined with the challenges in mobile device caching, and it has become an active area of research. In this paper, we first introduce the structure and key concepts of mobile social device caching (MSDC), elaborating the connections and differences of it to traditional caching. Furthermore, we advocate several major areas of research challenges for MSDC, such as content placement, radio resource management and routing. Moreover, a demonstration is present to illustrate the modeling of the MSDC, and performance analysis is carried out to manifest its great potentials."
  },
  {
    "year": "2016",
    "abstract": "A kind of digitally designing and manufacturing system for the gradient heterogeneous 3-D printing was designed. The molar model of PLY format was composed based on the CT images, and a novel method for the gradient heterogeneous material model designing based on the material distribution control function and the sliced edge rings was proposed. The point color slicing algorithm based on the topological structure was achieved. Based on the system, a gradient heterogeneous dental model was prepared. The algorithm used for constructing and slicing of the molar model could store the geometry and material information effectively, and maintain the compatibility for the heterogeneous 3-D printer. The system supplied a fast and integrating method for the heterogeneous 3-D bio-model printing."
  },
  {
    "year": "2016",
    "abstract": "Kinship verification via facial images is an emerging problem in computer vision and biometrics. Recent research has shown that learning a kin similarity measurement plays a critical role in constructing a vision-based kinship measurement system. We propose in this paper a new similarity metric learning method for kinship measurement on human faces. To this end, we first extract multiple feature representations for each face image using different face descriptors. Then, multiple sparse bilinear similarity models (one for each view) are jointly learned by using joint structured sparsity-inducing norms, such that the similarity score of a pair of child-parent images is consistently higher than those of the pairs without kinship relations while leveraging the interactions and correlations among the multiview data to obtain the fused and higher level information. We also derive an efficient algorithm to solve the formulated nonsmooth objective. Experimental results on kinship data sets show that our method achieves competitive or better accuracy performance in comparison with the state-of-the-art multimetric learning-based kinship verification methods but enjoys the superiority in computational efficiency, making it more practical for vision-based kin measurement applications."
  },
  {
    "year": "2016",
    "abstract": "This paper mainly discusses an adaptive fuzzy sliding mode control problem for a microgyroscope system via a global fast terminal sliding mode approach. The fabrication imperfections, the time varying system parameters, and the external disturbances are taken into consideration synchronously, and the corresponding dynamic model is established. A global fast terminal sliding mode control scheme is designed to guarantee that the system can reach the sliding surface and converge to equilibrium point in a shorter finite time from any initial state surface. Furthermore, an adaptive fuzzy control is introduced to approximate the model uncertainties and external disturbances. The chattering caused by the sliding mode control is weakened as well. Both the stability analysis and the tracking performance of the gyroscope system are proved by the Lyapunov stability theory. The effectiveness of the invoked control schemes for microgyroscope system is illustrated through the simulation results."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a strip-shaped multi-hop ad hoc network is analyzed using a spatial Poisson point process (PPP) and stochastic geometry. The decode-and-forwardprotocol is considered for transmission over the multi-hop network where cooperative communications is employed at each hop. An analytical expression for the probability density function of the received power at an arbitrary node is derived, given a set of nodes transmits in the previous hop, which is further used to characterize the coverage performance of the network. The received power at a node becomes a doubly stochastic process owing to random path loss and a Rayleigh fading channel. The notions of one-hop success probability and coverage range are analyzed for various network parameters. An algorithm for conserving energy is also proposed by considering PPP thinning and its performance in terms of the fraction of energy saved is quantified. It is shown that the proposed algorithm is more energy efficient as compared with an independent thinning algorithm."
  },
  {
    "year": "2016",
    "abstract": "A chaotic neuron with hysteretic and creep characteristics is proposed based on the conventional chaotic neuron model, with which a neural network is constructed, and the synchronous control between the hysteretic creep chaotic neuron or neural network and the deterministic chaotic neuron or neural network is investigated by the sliding mode control. The hysteretic activation function of the neuron is constructed by shifting the sigmoid function. The hysteretic parameters have creep properties, which lead to the uncertain responses of the neurons. The equivalent sliding mode control law can be designed according to the error equation of the synchronous system, and the Lyapunov method is used to prove the stability of the system. Furthermore, fuzzy sliding mode control law is designed to restrain the chattering, to reduce the synchronous error, as well as to shorten the transition time. The validity of this method has been proved by simulation experiments."
  },
  {
    "year": "2016",
    "abstract": "In recent years, mobile sinks are used more and more efficiently in sensor networks to collect data for the mobility advantage in balancing energy consumption than static sinks. However, it is still a challenge in both efficiency and network cost to avoid generating large amounts of overheads and lots of unnecessary energy consumption, when data source forward sensing data to mobile sink proactively according to their location information broadcasted all over the network. To reduce the overhead and balance the energy consumption in a network, we propose a clue-based data collection routing (CBDCR) protocol for mobile sensor networks. In CBDCR, a mobile sink moves randomly other than the following predesigned trajectories, during which it only broadcasts its location messages by limited hops instead of the whole network. The nodes getting these messages are called watchers who can obtain the upstream or downstream relations and infer the hop(s) from them to the mobile sink, and then a watcher stores this information as a “clue” to the location of mobile sink for data forwarding. As the movement of the mobile sink, more and more nodes are becoming watchers, and so a sensing data can be efficiently forwarded to the mobile sink according to these clues. Numerous simulations are conducted with mobile sinks in network to evaluate the performance of CBDCR, which demonstrate that CBDCR can both reduce the redundant transmission messages significantly and balance the network energy consumption."
  },
  {
    "year": "2016",
    "abstract": "To alleviate the backhaul burden and reduce user-perceived latency, content caching at base stations has been identified as a key technology. However, the caching strategy design at the wireless edge is challenging, especially when both wired backhaul condition and wireless channel quality are considered in the optimization. In this paper, taking into account the conditions of the backhaul in terms of delay and wireless channel quality, joint design and optimization of the caching and user association policy to minimize the average download delay is studied in a cache-enabled heterogeneous network. We first prove the joint caching and association optimization problem is NP-hard based on a reduction to the facility location problem. Furthermore, in order to reduce the complexity, a distributed algorithm is developed by decomposing the NP-hard problem into an assignment problem solvable by the Hungarian method and two simple linear integer subproblems, with the aid of McCormick envelopes and the Lagrange partial relaxation method. Simulation results reveal a near-optimal performance that performs up to 22% better in term of delay compared with those in the literatures at a low complexity ofO(nm3/ε2)."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on the end-to-end signal-to-noise ratio (SNR) maximization for full-duplex massive multiple-input multiple-output (MIMO) amplify-and-forward (AF) relay systems in the presence of direct link. First, we rigorously prove the asymptotic optimality of the maximum-ratio combining/maximum-ratio transmission (MRC/MRT) relaying strategy by taking into account the massive MIMO setup. Then, concerning the equivalent optimization problem with respect to source beamformer, we advocate a two-tier iterative algorithm relying on bi-section search, which guarantees a globally optimal solution. As a byproduct of this approach, we show that the optimal source beamformer has an interesting generalized channel matching structure associated with both source-relay and source-destination links. In addition to the optimal design, we devise a high SNR approximation-based suboptimal scheme, which admits a closed-form solution. Simulation results verify the advantage of our full-duplex relaying designs, and also demonstrate a negligible performance gap between the proposed optimal and suboptimal methods."
  },
  {
    "year": "2016",
    "abstract": "Continuous k-nearest neighbor (CkNN) query processing is an important issue in spatial temporal databases. In real-world scenarios, query clients and data objects may move with uncertain speeds on the road networks, which makes retrieving the exact CkNN query result a challenge. This paper addresses the issue of processing probabilistic CkNN queries of uncertain data (CPkNN) for road networks, where moving objects and query points are restricted by the connectivity of the road network and the object-query distance updates affect the query result. A novel model is proposed to estimate network distances between moving objects and a submitted moving query in the road network. Then, a CPkNN query monitoring method is presented to continuously report the possible result objects within a given time interval. In addition, an efficient method is proposed to arrange all the candidate objects according to their probabilities of being a kNN of a query. The method then chooses the top-k objects as the final query result. In addition, we extend our method to large networks with high efficiency. Finally, extensive experiments are conducted to demonstrate the effectiveness of the proposed schema."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on a secrecy constrained massive multiple-input multiple-output (MIMO) relaying system in terms of the optimal design of system parameters such as the optimal total number of antennas at relay, where a more practical mixed analog-to-digital converters (ADCs) scheme, double-resolution ADCs scheme, is proposed. In the proposed double-resolution ADCs scheme, the total M antennas at relay are divided into two parts, one of which includes M0 antennas with medium-resolution ADCs only requiring 5~12 quantization bits and the remainder of which consists of M1 antennas with low-resolution ADCs. The transmission from relay to destinations is exposed to a passive eavesdropper. For such massive MIMO relaying systems, we first derive the total achievable ergodic rates of legitimate users as well as the corresponding secrecy outage rates. Then, a reasonable energy consumption model is modeled so that the secrecy energy efficiency (SEE) is derived, where the effect of the source power, the resolutions of ADCs, and the ratio of the antenna numbers with medium- and low-resolution ADCs are exploited perfectly. The presented numerical results show that replacing high-resolution ADCs with medium-resolution ADCs is beneficial for improving the system SEE while the effect on the total achievable rate is very small. Specially, three main insights are achieved: 1) there exists an optimal value of the source power at which the SEE is optimal; 2) with given ratio M0 :M1, the optimal value of quantization bits of medium-resolution ADCs is upper-bounded, under which the system has higher SEE, that is to say, we obtain the upper bound of the resolution of the medium-resolution ADCs; and 3) the optimal number of the total antennas is impacted jointly by the number b0 of the quantization bits of medium-resolution ADCs and the ratio M0 :M1. Specially, while the optimal number of the total antennas is 100 or so for the pure high-resolution ADCs systems, the one for the proposed d..."
  },
  {
    "year": "2016",
    "abstract": "Low-dose CT (LDCT) images tend to be degraded by excessive mottle noise and steak artifacts. In this paper, we proposed a novel fractional-order differentiation model that can be applied to LDCT image processing as a post-processing technique. The anisotropic diffusion model (proposed by Perona and Malik, i.e., PM model) has good performance in flat regions, total variation (TV) model works better in edge preservation, and fractional-order differentiation models can mitigate block effect while preserving fine details and more structure. The proposed model is based on the weighted combinations of the fractional-order PM model and the fractional-order TV model, which maintains the advantages of PM model, TV model, and fractional-order differentiation models. Moreover, the local intensity variance was added to both weighted coefficient and diffusion coefficient of the proposed model to properly preserve edges and details. A variety of simulated phantom data, including the Shepp-Logan head phantom, the pelvis phantom, and the actual thoracic phantom, were used for experimental validation. The results of numerical simulation and clinical data experiments demonstrate that the proposed approach has a better performance in both noise suppression and detail preservation, when compared with several other existing methods."
  },
  {
    "year": "2016",
    "abstract": "Networked music performance (NMP) is a potential game changer among Internet applications, as it aims at revolutionizing the traditional concept of musical interaction by enabling remote musicians to interact and perform together through a telecommunication network. Ensuring realistic performance conditions, however, constitutes a significant engineering challenge due to the extremely strict requirements in terms of network delay and audio quality, which are needed to maintain a stable tempo, a satisfying synchronicity between performers and, more generally, a high-quality interaction experience. In this paper, we offer a review of the psycho-perceptual studies conducted in the past decade, aimed at identifying latency tolerance thresholds for synchronous real-time musical performance. We also provide an overview of hardware/software enabling technologies for NMP, with a particular emphasis on system architecture paradigms, networking configurations, and applications to real use cases."
  },
  {
    "year": "2016",
    "abstract": "The issue of high system stability is one of the major obstacles for real-time computing over fluctuating big data streams. A stable scheduling is more important than an efficient scheduling for stream applications, especially when a scheduling is to be rescheduled dynamically at runtime. In this paper, a stable online scheduling strategy with makespan guarantee SOMG is discussed, which includes the following features: 1) profiling mathematical relationships between system stability, response time, and resource utilization, and indicating conditions to meet the high system stability and acceptable response time objectives; 2) optimizing the structure of a data stream graph by quantifying and adjusting vertices of the graph; and 3) scheduling a data stream graph with heuristic critical path scheduling mechanism, which is subject to response time constraints, rescheduling only key vertices on dynamically changing critical path of the graph, and considering the historical information of current scheduling to maximize system stability with response time aware. Experimental results conclusively demonstrate that the SOMG framework has higher potential of providing enhancement on efficient system stability and guaranteeing significant response time. It efficiently and effectively makes a tradeoff between high system stability and acceptable response time objectives in big data stream computing environments."
  },
  {
    "year": "2016",
    "abstract": "One of the main challenges for wide-scale deployment and timely adoption of ultra-dense networks (UDNs) in future 5G is the backhaul. Typically, mmW technologies for backhaul require line-of-sight conditions while high-capacity wired-based solutions need a significant investment in infrastructure. Such limitations pose practical constrains on the scalability of UDNs and increase the deployment cost of dense networks. In this paper, we consider in-band backhaul for UDNs based on massive MIMO systems in sub-6 GHz. In particular, we propose a scheme for allowing simultaneous downlink transmissions in backhaul and access network on a single frequency band that exploits a novel combination of the state-of-the-art practical transmit and receive beamforming techniques. A novel frame structure for allowing a co-existence between massive MIMO-based backhaul and UDNs is also proposed. Moreover, a solution for in-band uplink transmissions that exploits time-division-duplex (TDD) and spatial multiple-access is also provided. Extensive numerical results using a realistic system-level simulator are given. Results show that the performance of a UDN with the proposed in-band backhaul scheme reaches ~58% of the throughput of a similar access network with ideal (e.g., wired) backhaul. Our results also show that the proposed scheme provides an increase in the throughput of ~30% compared with a TDD scheme for in-band backhaul. Further advantages of the proposed massive MIMO-based in-band backhaul scheme for UDNs include reusing both the (scarce) spectrum in sub-6 GHz and acquired macro-sites, thus providing a seamless transition from LTE to 5G networks."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a new reaching law for uncertain discrete time systems is presented. The proposed reaching law is designed to ensure a limited sliding variable rate of change and at least asymptotic convergence of the variable to zero. The law is utilized to design a control strategy, which is then applied to an inventory management system with multiple suppliers and limited warehouse capacity. The strategy is proved to ensure all the desirable properties of the system. On the one hand, it guarantees that the suppliers are never forced to send more goods than they are capable of and that warehouse capacity is never exceeded. On the other hand, it ensures that the consumers' demand is always fully satisfied."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we propose joint angle-delay subspace based-channel estimation in single cell for broadband massive multiple-input and multiple-output systems employing orthogonal frequency division multiplexing modulation. Based on a parametric channel model, we present a new concept of the joint angle-delay subspace, which can be tracked by the low-complexity low-rank adaptive filtering algorithm. Then, we investigate an interference-free transmission condition that the joint angle-delay subspaces of the users reusing the same pilots are non-overlapping. Since the channel statistics are usually unknown, we develop a robust minimum mean square error (MMSE) estimator under the worst precondition of pilot decontamination, considering that the joint angle-delay subspaces of the interfering users fully overlap. Furthermore, motivated by the interference-free transmission criteria, we present a novel low-complexity greedy pilot scheduling algorithm to avoid the problem of initial value sensitivity. Simulation results show that the joint angle-delay subspace can be estimated effectively, and the proposed pilot reuse scheme combined with robust MMSE channel estimation offers significant performance gains."
  },
  {
    "year": "2016",
    "abstract": "With the advent of big data era, clients lack of computational and storage resources tends to outsource data mining tasks to cloud computing providers in order to improve efficiency and save costs. Generally, different clients choose different cloud companies for the sake of security, business cooperation, location, and so on. However, due to the rise of privacy leakage issues, the data contributed by clients should be encrypted under their own keys. This paper focuses on privacy-preserving k-nearest neighbor (kNN) computation over the databases distributed among multiple cloud environments. Unfortunately, existing secure outsourcing protocols are either restricted to a single key setting or quite inefficient because of frequent client-to-server interactions, making it impractical for wide application. To address these issues, we propose a set of secure building blocks and outsourced collaborative kNN protocol. Theoretical analysis shows that our scheme not only preserves the privacy of distributed databases and kNN query but also hides access patterns in the semi-honest model. Experimental evaluation demonstrates its significant efficiency improvements compared with existing methods."
  },
  {
    "year": "2016",
    "abstract": "This paper examines a triple band cylindrical dielectric resonator antenna (CDRA) with three different radiating modes, i.e., HEM118, TM018, and HEM128. Excitation of all these radiating modes simultaneously, in CDRA, is the most challenging task, which have been accomplished by using composite feeding structure [combination of vertical strip and psi-shaped (ψ) microstrip line]. Out of three radiating mode, two hybrid modes (i.e., HEM118 and HEM128) radiate in broadside direction, while remaining one (TM018) creates monopole like radiation pattern. Diversified radiation patterns make the proposed CDRA suitable for different wireless applications. Simulated outcomes of the proposed antenna design have been practically confirmed with the help of archetype of proposed antenna. The proposed CDRA is working in three different frequency bands: 2.5-3.02, 3.76-3.86, and 4.38-4.72 GHz. The proposed radiator is quite suitable for WiMAX (2.5 GHz) and vehicular applications."
  },
  {
    "year": "2016",
    "abstract": "Many communities have researched the application of novel network architectures, such as content-centric networking (CCN) and software-defined networking (SDN), to build the future Internet. Another emerging technology which is big data analysis has also won lots of attentions from academia to industry. Many splendid researches have been done on CCN, SDN, and big data, which all have addressed separately in the traditional literature. In this paper, we propose a novel network paradigm to jointly consider CCN, SDN, and big data, and provide the architecture internal data flow, big data processing, and use cases which indicate the benefits and applicability. Simulation results are exhibited to show the potential benefits relating to the proposed network paradigm. We refer to this novel paradigm as data-driven networking."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a wind-wave farm system with a self-energy storage capability and a smoothed total power output. The fluctuating electrical power from wave is smoothed by utilizing the rotor inertias of the wind turbines as short-term energy storage devices, thus without extra energy storage hardware the investment and maintenance cost of the wave energy conversion is reduced. This is achieved based on the fact that the wind power can be viewed as constant during a typical wave period (5~12 s). The proposed integral compensation control of the wind turbines can optimize two conflicting objectives: maximizing wind energy capture at different wind speeds and regulating the rotor speeds of wind turbines as kinetic energy storage devices. It enables the turbine speed to swing around its optimum points at different wind speeds. Consequently, the total power output of the wind-wave farm is well smoothed at a marginal cost of the power take-off efficiency loss. RTDS simulations and quantitative analysis are presented to demonstrate the proposed system. To demonstrate its superiority, the proposed control method is compared with the direct compensation of the wave power based on the existing maximum power point tracking method."
  },
  {
    "year": "2016",
    "abstract": "In today’s highly intertwined network society, the demand for big data processing frameworks is continuously growing. The widely adopted model to process big data is parallel and distributed computing. This paper documents the significant progress achieved in the field of distributed computing frameworks, particularly Apache Hama, a top level project under the Apache Software Foundation, based on bulk synchronous parallel processing. The comparative studies and empirical evaluations performed in this paper reveal Hama’s potential and efficacy in big data applications. In particular, we present a benchmark evaluation of Hama’s graph package and Apache Giraph using PageRank algorithm. The results show that the performance of Hama is better than Giraph in terms of scalability and computational speed. However, despite great progress, a number of challenging issues continue to inhibit the full potential of Hama to be used at large scale. This paper also describes these challenges, analyzes solutions proposed to overcome them, and highlights research opportunities."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a wearable inertial measurement system and its associated spatiotemporal gait analysis algorithm to obtain quantitative measurements and explore clinical indicators from the spatiotemporal gait patterns for patients with stroke or Parkinson's disease. The wearable system is composed of a microcontroller, a triaxial accelerometer, a triaxial gyroscope, and an RF wireless transmission module. The spatiotemporal gait analysis algorithm, consisting of procedures of inertial signal acquisition, signal preprocessing, gait phase detection, and ankle range of motion estimation, has been developed for extracting gait features from accelerations and angular velocities. In order to estimate accurate ankle range of motion, we have integrated accelerations and angular velocities into a complementary filter for reducing the accumulation of integration error of inertial signals. All 24 participants mounted the system on their foot to walk along a straight line of 10 m at normal speed and their walking recordings were collected to validate the effectiveness of the proposed system and algorithm. Experimental results show that the proposed inertial measurement system with the designed spatiotemporal gait analysis algorithm is a promising tool for automatically analyzing spatiotemporal gait information, serving as clinical indicators for monitoring therapeutic efficacy for diagnosis of stroke or Parkinson's disease."
  },
  {
    "year": "2016",
    "abstract": "Topology control is one of the significant research topics in traditional wireless networks. The primary purpose of topology control ensures the connectivity of wireless nodes participated in the network. Low-power Internet of Things communication networks look like wireless network environments in which the main communication devices are wireless devices with limited energy like battery. In this paper, we propose a distributed topology control algorithm by merging the combinatorial block design from a design theory with the multiples of 2. The proposed technique especially focuses on asynchronous and asymmetric neighbor discovery. The concept of block design is used to generate the neighbor discovery schedule when a target duty cycle is given. In addition, the multiples of 2 are applied to overcome the challenge of the block design and support asymmetric operation. We analyze the worst case discovery latency and energy consumption numerically by calculating the total number of slots and wake-up slots based on the given duty cycle. It shows that our proposed method has the smallest total number of slots and wake-up slots among existing representative neighbor discovery protocols. The numerical analysis represents the proposed technique find neighbors quickly with minimum battery power compared with other protocols for distributed topology control. For future research direction, we could perform a simulation study or real experiment to investigate the best parameter for choosing the multiple of a certain number."
  },
  {
    "year": "2016",
    "abstract": "A low-complexity iterative channel estimation and Reed-Solomon (RS) decoding receiver is developed. The joint channel estimation and decoding receiver is based on the linear minimum mean square error (LMMSE) channel estimation technique and the recently proposed RS parity-check transformation algorithm (PTA). A key feature of this joint receiver is the simple symbol remapping process used to refine the initial LMMSE estimate of the channel after each iterative RS-PTA decoding. The performance of the joint iterative receiver is compiled through computer simulation assuming a rectangular M-ary quadrature amplitude modulation as the underlying modulation scheme. Simulation results show significant symbol error rate (SER) improvement in the iterative receiver in comparison with the receiver without iterative feedback. Besides, the RS-PTA iterative receiver outperforms the recently proposed RS Koetter and Vardy (RS-KV) iterative receiver structure both in terms of the SER performance and the computational time complexity. Of particular interest, results verify that the computational time complexity of the RS-PTA iterative receiver can be reduced without compromising the SER performance of the receiver."
  },
  {
    "year": "2016",
    "abstract": "The device-to-device (D2D) communication has been regarded as an effective technique for complementing and enhancing the conventional cellular systems owing to its capability of substantially improving both the spectral and power efficiencies of wireless networks. However, the severe interference imposed on the conventional cellular users (CUs) by the geographically close-by D2D pairs may cause a significant performance erosion in the D2D-aided underlaying cellular networks (CNs). In this paper, performance analysis for the D2D-aided underlaying CNs in terms of throughput is provided. We first derive the closed-form expressions of the coverage probability for both the conventional cellular links and the D2D links, followed by giving out the approximated expressions of the ergodic data rate for both an individual cellular/D2D link and the whole underlaying network. Furthermore, the key parameters (e.g., the density of D2D users (DUs) or CUs, and the average geographical distance between a pair of D2D peers) significantly impacting the channel capacity are adaptively adjusted for maximizing the sum data rate of the proposed underlaying networks. In addition, both theoretical analysis and simulation results reveal the attainability of the maximal throughput by optimizing the critical parameters, such as the density of DUs, provided that the scale factor between the DUs and sum users (i.e., comprising both conventional CUs and DUs) can be effectively balanced subject to the constraints specified in the proposed scheme."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the downlink of a single-cell base station (BS) equipped with a large-scale antenna array system while considering a non-negligible transmit circuit power consumption. This consumption involves that activating all RF chains does not always necessarily achieve the maximum sum-rate when the total BS transmit power is limited. This paper formulates a sum-rate maximization problem when a low complexity linear precoder, such as conjugate beamforming or zero forcing beamforming, is used. The problem is first relaxed by assuming arbitrary antenna selection. In this case, we derive analytically the optimal number of activated RF chains that maximizes the sum-rate under either optimal power allocation or equal received power constraint for all users. Also, user scheduling algorithms are proposed when users require a minimum received signal-to-interference-plus-noise ratio. Two iterative user scheduling algorithms are designed. The first one is efficient in terms of fairness and the second one achieves the optimal performance. Next, the antenna selection is investigated and we propose iterative antenna selection algorithms that are efficient in terms of instantaneous sum-rate. Simulation results corroborate our analytical results and demonstrate the efficiency of the proposed algorithms compared with arbitrary and optimal brute force search antenna selection."
  },
  {
    "year": "2016",
    "abstract": "Emotion recognition represents the position and motion of facial muscles. It contributes significantly in many fields. Current approaches have not obtained good results. This paper aimed to propose a new emotion recognition system based on facial expression images. We enrolled 20 subjects and let each subject pose seven different emotions: happy, sadness, surprise, anger, disgust, fear, and neutral. Afterward, we employed biorthogonal wavelet entropy to extract multiscale features, and used fuzzy multiclass support vector machine to be the classifier. The stratified cross validation was employed as a strict validation model. The statistical analysis showed our method achieved an overall accuracy of 96.77±0.10%. Besides, our method is superior to three state-of-the-art methods. In all, this proposed method is efficient."
  },
  {
    "year": "2016",
    "abstract": "Over the last decade, many pairwise-constraint-based metric learning algorithms have been developed to automatically learn application-specific metrics from data under similarity/dissimilarity data-pair constraints (weak labels). Nevertheless, these existing methods are designed for the centralized learning case, in which all the data and constraints are supposed to be gathered together in one source, and the algorithms utilize the whole data and constraints information during the learning process. However, in many real applications, large amounts of data (constraints) are dispersedly generated/stored in geographically distributed nodes over networks. Thus, it might be impractical to centralize the whole data information to one fusion node. Besides, in such cases, it is often hard to have every data pair labeled due to the huge data-pair amounts, resulting in numerous unlabeled data pairs. Given these situations, in this paper, we propose two types, namely, a diffusion type and an alternating-direction-method-of-multipliers type, of distributed semi-supervised metric learning frameworks, which make use of both labeled and unlabeled data pairs. The proposed frameworks can be easily used to extend centralized metric learning methods of different objective functions to distributed cases. In particular, we apply our frameworks on a well-behaved centralized semi-supervised metric learning method called SERAPH and yield two new distributed semi-supervised metric learning algorithms. Our simulation results show that the metrics learned by the proposed distributed algorithms are very close to that of the corresponding centralized method in most cases."
  },
  {
    "year": "2016",
    "abstract": "This paper presents an approach to determine the pose of a robot manipulator by using a single fixed camera. Conventionally, the pose determination is usually achieved by using the encoders to sense the joint angles, and then the pose of the end effector is obtained by using the direct kinematics of the manipulator. However, when the encoders or the manipulators are malfunctioning, the pose may not be accurately determined. This paper presents an approach based on machine vision, where a single camera is fixed away from the base of the manipulator. Besides, based on the kinematics of the manipulator and a calibrated camera, the pose of the manipulator can be determined. Furthermore, a graphical user interface is developed, which is convenient for users to operate the entire system. Two examples are demonstrated, and the estimated results are compared with those from the encoders. The proposed approach does not compete with the encoders. Instead, the approach can be treated as a backup method, which can provide a reference solution."
  },
  {
    "year": "2016",
    "abstract": "New item or topic profiling and recommendation are useful yet challenging, especially in face of a “cold-start” situation with sparse user-item ratings for the new arrivals. In this paper, a method of acquiring review opinions of the “sentinel” users on the cold-start items is proposed to elicit those items' latent profiles, and thus both user-specific ratings and future popularity of the items can be predicted simultaneously. Specifically, such a joint prediction task is formulated as a two-stage optimization problem, and a sentinel user selection algorithm is devised to facilitate effective latent profiles extraction for both item ratings and popularity predictions. Experiments with microblogging and movie data sets corroborate that the proposed method is capable of mitigating the cold-start problem and it outperforms several competitive peer methods."
  },
  {
    "year": "2016",
    "abstract": "In recent years, the new achievements in the field of technology and data science allowed to gather detailed and well-structured information about electricity consumption behaviors of industrial enterprises. Such type of information can find numerous applications in the power distribution industry. The utilities often use the data from contracts to assign each industrial customer a class label according to this type defined in predetermined industry segmentation. Such type of fixed-chart segmentation is not able to satisfy the needs of modern enterprises for the flexible and dynamic determination of production modes. In this paper, we address this problem by proposing a new method for the segmentation of various types of factories based on their electricity consumption patterns represented in load profile data. It exploits the evolution-based characteristics of smart meter data of multiple types of factories to remove irrelevant features. We use data visualization to estimate the number of clusters and apply the well-known k-means algorithm on filtered data to generate segmentation. Experimental results on real load profile data collected with smart meters from manufacturing industries in Guangdong province of China have shown that the new clustering approach produced the meaningful segmentation of factories that reflect production operations."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we investigate the impact of self-interference on the performance of a joint partial RAKE (PRAKE) receiver and adaptive modulation over both independent and identically distributed and independent but non-identically distributed Rayleigh fading channels. To better observe the impact of self-interference, our approach starts from considering the signal to interference plus noise ratio. Specifically, we accurately analyze the outage probability, the average spectral efficiency, and the average bit error rate as performance measures in the presence of self-interference. Several numerical and simulation results are selected to present the performance of the joint PRAKE receiver and adaptive modulation subject to self-interference."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio (CR) techniques have been proposed for improving the spectral efficiency by exploiting the temporarily unoccupied segments of the licensed spectrum, provided that the transmission of primary users (PUs) is not hampered. In this paper, we propose a cognitive Go-Back-N Hybrid Automatic Repeat reQuest (CGBN-HARQ) scheme that enables the cognitive user (CU) to opportunistically transmit data over a primary radio (PR) channel. Based on the sensing decisions by the CU, it decides about the availability of the PU’s channel for its own transmission using the proposed CGBN-HARQ scheme. In addition, it enables the CR transmitter to receive feedback concerning the success/failure of its prior transmissions during the sensing and transmission phases of the time-slot (TS). A discrete time Markov chain model is invoked for the theoretical analysis of the proposed system, where we conceive an algorithm to generate all possible states of the CR transmitter. Both the throughput and delay of the CGBN-HARQ scheme is analyzed by deriving a range of closed-form formulas, which are validated by simulation results. The occupation of the channel by the PU and the reliability of the CU’s channel significantly affect both the achievable throughput and the delay of the CGBN-HARQ scheme. Finally, our studies show that the number of packets transmitted within a TS should be adapted according to the communication channel for attaining the maximum throughput and the lowest average transmission delay."
  },
  {
    "year": "2016",
    "abstract": "Hydraulic transformer can improve the transmission efficiency of the hydraulic system. As the manual hydraulic transformer cannot achieve automatic control and remote control in the hydraulic system, to meet this challenge, the electro-hydraulic servo plate-inclined plunger hydraulic transformer (EHHT) was proposed in this paper. First, through analyzing the principle of the EHHT, the structure of EHHT is designed based on the theoretical analysis; Secondly, the mathematical model and simulation model of output pressure were created. Finally, the fuzzy control strategy was designed and tested on the experiment bench. Both the simulated and experimental results show that the control strategy can effectively improve the pressure control performance of hydraulic transformer and the theoretical analysis is correct."
  },
  {
    "year": "2016",
    "abstract": "This paper describes a mixed-signal electrocardiogram (ECG) system for personalized and remote cardiac health monitoring. The novelty of this paper is fourfold. First, a low power analog front end with an efficient automatic gain control mechanism, maintaining the input of the ADC to a level rendering optimum SNR and the enhanced recyclic folded cascode opamp used as an integrator forΣΔADC. Second, a novel on-the-fly PQRST boundary detection (BD) methodology is formulated for finding the boundaries in continuous ECG signal. Third, a novel low-complexity ECG feature extraction architecture is designed by reusing the same module present in the proposed BD methodology. Fourth, the system is having the capability to reconfigure the proposed low power ADC for low (8 b) and high (12 b) resolution with the use of the feedback signal obtained from the digital block when it is in processing. The proposed system has been tested and validated on patient’s data from PTBDB, CSEDB, and in-house IIT Hyderabad Data Base (IITHDB) and we have achieved an accuracy of 99% upon testing on various normal and abnormal ECG signals. The whole system is implemented in 180-nm technology resulting in 9.47-μW(at 1 MHz) power consumption and occupying 1.74-mm2silicon area."
  },
  {
    "year": "2016",
    "abstract": "Attribute-based encryption (ABE) has emerged as a promising solution for access control to diverse set of users in cloud computing systems. Policy can just specify whether (or not) any specific user should be given access to data, but it lacks to provide data owner the privilege to specify (how much) fraction, or (which) specific chunk from that data to be accessed or decrypted. In this paper, we address this issue, and propose a scheme that will give data owner excessive access control, so that he can specify specific chunk out of total data to be accessed by user depending on his attributes. In our scheme, a data owner can encrypt data over attributes specified in a policy, but even if user's attributes satisfy the policy; he can decrypt data (partially or fully) fractionally based on his attributes specified by owner. The owner can also prioritize user's access based on his designation, or hierarchal role in a specific organization. We also address to resolve the issue of attributes repetition, due to which the cost of computations in encryption by owner and ciphertext size is reduced. Furthermore, we achieve it with a single ciphertext over policy for entire data, and proof our scheme to be secure in the generic group and random oracle model. Theoretical comparisons of computations with existing constructions, and performance of the scheme evaluated in the Charm simulator is reasonable enough to be adopted in practice."
  },
  {
    "year": "2016",
    "abstract": "This paper intends to answer the question how to achieve wireless data rates that can catch up with current Internet speed, from a basic physics point of view. It is shown that the traditional electric circuit theory and design methodology that have been used for generations are unfortunately not adequate for wireless communications in the future. Instead, disruptive approaches, such as six-port modulators for processing of electromagnetic waves and optical pulses, should be employed to push up the wireless data rate above 100 Gb/s. The key variables to consider for high-speed digital communications are bandwidth, modulation order, and signal-to-noise ratio. In principle, it should be possible to achieve a wireless data rate at 100 Gb/s within the frequency spectrum below 20 GHz."
  },
  {
    "year": "2016",
    "abstract": "Internet-of-Things (IoT) will connect billions of smart devices and generate inundant data through prominent solutions, such as machine type communication. The Third Generation Partnership Project has launched the corresponding standards for multiple heterogeneous wireless smart devices in the long term evolution (LTE)/LTE-advanced. In the forthcoming years, the valuable information hidden in the deluge of data will be extracted and utilized in every field to improve quality and efficiency. However, the bottleneck of realizing this magnificent vista of future intelligent lives lies in how to satisfy the practical demands to transmit huge data volume through efficient wireless communication in diverse scenarios. Herein, multi-scenario wireless communication triggers critical problems in wireless channel modeling and soundings for 5G IoT, which by far, are understudied. In this paper, we introduce a general wireless channel model and its multiple up-to-date corresponding channel sounding methods for future 5G IoT green wireless communication. Through adopting the perspective of wireless big data excavation, the smart channel sounder transforms the traditional passive wireless communication scheme into an active expectation-guaranteed wireless communication scheme, which helps achieve efficient and green communication. To demonstrate the validity and efficiency of this smart sounder scheme, we make a compatible prototype testified in multiple scenarios. The multiple real-scenario experiments demonstrate that the smart sounder can function effectively, especially in those scenarios where traditional channel state information is not available or imperfect."
  },
  {
    "year": "2016",
    "abstract": "This paper considers joint power control and subchannel allocation for co-tier interference mitigation in extremely dense small cell networks, which is formulated as a combinatorial optimization problem. Since it is intractable to obtain the globally optimum assignment policy for existing techniques due to the huge computation and communication overheads in ultra-dense scenario, in this paper, we propose a hierarchical resource allocation framework to achieve a desirable solution. Specifically, the solution is obtained by dividing the original optimization problem into four stages in partially distributed manner. First, we propose a divide-and-conquer strategy by invoking clustering technique to decompose the dense network into smaller disjoint clusters. Then, within each cluster, one of the small cell access points is elected as a cluster head to carry out intra-cluster subchannel allocation with a low-complexity algorithm. To tackle the issue of inter-cluster interference, we further develop a distributed learning-base coordination mechanism. Moreover, a local power adjustment scheme is also presented to improve the system performance. Numerical results verify the efficiency of the proposed hierarchical scheme, and demonstrate that our solution outperforms the state-of-the-art methods, especially for hyper-dense networks."
  },
  {
    "year": "2016",
    "abstract": "The high precision ranging using ultra wideband (UWB) signals is expected for various applications. However, UWB requires mitigation of narrowband interference (NBI) from other wireless systems. There have been many studies of adaptive notch filters to cope with NBI at various frequencies. This paper proposes a novel NBI mitigation method which utilizes frequency dependence characteristics in array antennas. We use power inversion to direct nulls to large-power input, which realizes NBI only suppression with a small calculation cost. The results show that the proposed method can obtain lower bit error rate. The proposed method can cope with variously directional and multiple-frequency NBIs without a priori knowledge of the incident waves."
  },
  {
    "year": "2016",
    "abstract": "To improve tracking and synchronization control precision of electro-hydraulic shaking tables system, this paper presents a novel adaptive reaching law sliding mode controller (ARLSMC) for double shaking tables system with parameter uncertainty and disturbance. The ARLSMC combined a sliding mode controller based on a novel adaptive reaching law to improve dynamic performance with an adaptive controller to estimate the uncertain parameters online in order to reduce the system chattering. Besides, the proposed ARLSMC is introduced into the cross-coupled controller of double shaking tables. The stability of the control system is analyzed applying Lyapunov theory, and it is proven that both the tracking errors and synchronization error can converge to zero in finite time. The co-simulation model is built using MATLAB/Simulink and Adams for verification of the proposed control strategy. Various simulation tests are performed and simulation results demonstrate that the proposed method has a fast dynamic response performance, high control precision, and strong robustness."
  },
  {
    "year": "2016",
    "abstract": "We consider a multisensor network fusion framework for 3-D data registration using inertial planes, the underlying geometric relations, and transformation model uncertainties. We present a comprehensive review of 3-D reconstruction methods and registration techniques in terms of the underlying geometric relations and associated uncertainties in the registered images. The 3-D data registration and the scene reconstruction task using a set of multiview images are an essential goal of structure-from-motion algorithms that still remains challenging for many applications, such as surveillance, human motion and behavior modeling, virtual-reality, smart-rooms, health-care, teleconferencing, games, human-robot interaction, medical imaging, and scene understanding. We propose a framework to incorporate measurement uncertainties in the registered imagery, which is a critical issue to ensure the robustness of these applications but is often not addressed. In our test bed environment, a network of sensors is used where each physical node consists of a coupled camera and associated inertial sensor (IS)/inertial measurement unit. Each camera-IS node can be considered as a hybrid sensor or fusion-based virtual camera. The 3-D scene information is registered onto a set of virtual planes defined by the IS. The virtual registrations are based on using the homography calculated from 3-D orientation data provided by the IS. The uncertainty associated with each 3-D point projected onto the virtual planes is modeled using statistical geometry methods. Experimental results demonstrate the feasibility and effectiveness of the proposed approach for multiview reconstruction with sensor fusion."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a novel security architecture for protecting the integrity of iris images and templates using watermarking and visual cryptography (VC). The proposed scheme offers a complete protection framework for the iris biometrics which consists of two stages: the first stage is for iris image protection, while the second is for the iris template. First, for protecting the iris image, a watermark text which carries personal information is embedded in the middle band frequency region of the iris image using a novel watermarking algorithm that randomly interchanges multiple middle band pairs of the discrete cosine transform. Second, for iris template protection, the binary iris template is divided into two shares using VC, where one share is stored in the database and the other is kept with the user on a smart card. In addition, the SHA-2 hash function is utilized to maintain the integrity of the stored iris template in both the database and smart card. The experimental and comparison results on the CASIA V4 and UBIRIS V1 iris databases demonstrate that the proposed framework preserves the privacy of the iris images and templates and retains robustness to malicious attacks, while it does not have a discernible effect on the recognition performance."
  },
  {
    "year": "2016",
    "abstract": "Long-Term Evolution (LTE) communication systems feature advanced frequency reuse and interference coordination techniques providing faster and more secured mobile services. However, the network capacity in licensed spectrum is still behind market demands. Dynamic spectrum access or spectrum sharing in other frequently vacant or unlicensed frequency bands is considered an effective means to boost system throughput. Different from operations in licensed spectrum with exclusive access, LTE deployment needs to take into account the distinct regulations on channel access to each shared frequency band, in order to avoid interference to incumbent users, and to maintain fair play with peer operators in heterogeneous networks. This paper presents an overview on LTE spectrum sharing technologies on three popular spectrums, including the TV white-space channels, the frequently unused service-dedicated 3.5-GHz citizens broadband radio service spectrums, and the 5-GHz unlicensed bands. Existing spectrum usage in these frequency bands is analyzed, and the proposed methodologies on compliant operations are discussed for the reference of potential solutions to more efficient spectrum sharing mechanisms in the next generation mobile networks."
  },
  {
    "year": "2016",
    "abstract": "Owing to the vulnerability of relay-assisted communications, improving wireless security from a physical layer signal processing perspective is attracting increasing interest. Hence, we address the problem of secure transmission in a relay-assisted network, where a pair of legitimate user equipments (UEs) communicate with the aid of a multiple-input multiple output (MIMO) relay in the presence of multiple eavesdroppers (eves). Assuming imperfect knowledge of the eves' channels, we jointly optimize the power of the source UE, the amplify-and-forward relaying matrix, and the covariance of the artificial noise transmitted by the relay, in order to maximize the received signal-to-interference-plus-noise ratio at the destination, while imposing a set of robust secrecy constraints. To tackle the resultant non-convex optimization problem with tractable complexity, a new penalized difference-of-convex (DC) algorithm is proposed, which is specifically designed for solving a class of non-convex semidefinite programs. We show how this penalized DC framework can be invoked for solving our robust secure relaying problem with proven convergence. In addition, to benchmark the proposed algorithm, we subsequently propose a semidefinite relaxation-based exhaustive search approach, which yields an upper bound of the secure relaying problem, however, with significantly higher complexity. Our simulation results show that the proposed solution is capable of ensuring the secrecy of the relay-aided transmission and significantly improving the robustness toward the eves' channel uncertainties as compared with the non-robust counterparts. It is also demonstrated the penalized DC-based method advocated yields a performance close to the upper bound."
  },
  {
    "year": "2016",
    "abstract": "Cloud computing technology has become an integral trend in the market of information technology. Cloud computing virtualization and its Internet-based lead to various types of failures to occur and thus the need for reliability and availability has become a crucial issue. To ensure cloud reliability and availability, a fault tolerance strategy should be developed and implemented. Most of the early fault tolerant strategies focused on using only one method to tolerate faults. This paper presents an adaptive framework to cope with the problem of fault tolerance in cloud computing environments. The framework employs both replication and checkpointing methods in order to obtain a reliable platform for carrying out customer requests. Also, the algorithm determines the most appropriate fault tolerance method for each selected virtual machine. Simulation experiments are carried out to evaluate the framework's performance. The results of the experiments show that the proposed framework improves the performance of the cloud in terms of throughput, overheads, monetary cost, and availability."
  },
  {
    "year": "2016",
    "abstract": "In this paper, two mixed control charts are designed for process monitoring when the quality characteristic of interest follows a normal distribution. The mixed control chart starts with monitoring the number of non-conforming items but switches to monitoring using exponentially weighted moving average (EWMA) statistic or hybrid EWMA statistic when the decision is indeterminate with the attribute data. The average run lengths are calculated to evaluate the performance of the proposed control charts according to the mean shift. The performance of both control charts is compared with each other and with the existing control chart. Simulation study is given to demonstrate the efficiency of the proposed control charts."
  },
  {
    "year": "2016",
    "abstract": "Network function virtualization (NFV) has already been a new paradigm for network architectures. By migrating NFs from dedicated hardware to virtualization platform, NFV can effectively improve the flexibility to deploy and manage service function chains (SFCs). However, resource allocation for requested SFC in NFV-based infrastructures is not trivial as it mainly consists of three phases: virtual network functions (VNFs) chain composition, VNFs forwarding graph embedding, and VNFs scheduling. The decision of these three phases can be mutually dependent, which also makes it a tough task. Therefore, a coordinated approach is studied in this paper to jointly optimize NFV resource allocation in these three phases. We apply a general cost model to consider both network costs and service performance. The coordinate NFV-RA is formulated as a mixed-integer linear programming, and a heuristic-based algorithm (JoraNFV) is proposed to get the near optimal solution. To make the coordinated NFV-RA more tractable, JoraNFV is divided into two sub-algorithms, one-hop optimal traffic scheduling and a multi-path greedy algorithm for VNF chain composition and VNF forwarding graph embedding. Last, extensive simulations are performed to evaluate the performance of JoraNFV, and results have shown that JoraNFV can get a solution within 1.25 times of the optimal solution with reasonable execution time, which indicates that JoraNFV can be used for online NFV planning."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a novel transmission protocol is proposed based on the classical selective-repeat hybrid automatic repeat to access a primary user (PU) channel, which is referred to as the CSR-HARQ. We assume that the PU transmits information based on time-slots (TSs). During a TS, the cognitive radio transmitter first senses the PU channel. Once a free TS is found, it transmits a number of packets to the CU receiver based on the principles of the SR-HARQ. In this paper, we analyze the throughput, average packet delay, and end-to-end packets delay of the CSR-HARQ. We proposed a pair of analytical approaches. The first one is probability based, while the second one relies on the classic discrete time markov chain principles. Finally, we study the throughput, average packet delay, and the end-to-end packet delay of the CSR-HARQ both by simulations and by evaluating our formulas. The simulation-based studies agree well with the analytical results. The performance of the CSR-HARQ systems is significantly impacted by the activity of the PU channel and by the reliability of the spectrum sensing."
  },
  {
    "year": "2016",
    "abstract": "Spectrum data, which are usually characterized by many dimensions, such as location, frequency, time, and signal strength, present formidable challenges in terms of acquisition, processing, and visualization. In practice, a portion of spectrum data entries may be unavailable due to the interference during the acquisition process or compression during the sensing process. Nevertheless, the completion work in multi-dimensional spectrum data has drawn few attention to the researchers working in the field. In this paper, we first put forward the concept of spectrum tensor to depict the multi-dimensional spectrum data. Then, we develop a joint tensor completion and prediction scheme, which combines an improved tensor completion algorithm with prediction models to retrieve the incomplete measurements. Moreover, we build an experimental platform using Universal Software Radio Peripheral to collect real-world spectrum tensor data. Experimental results demonstrate that the effectiveness of the proposed joint tensor processing scheme is superior than relying on the completion or prediction scheme only."
  },
  {
    "year": "2016",
    "abstract": "Direction of arrival (DOA) estimation from the perspective of sparse signal representation has attracted tremendous attention in past years, where the underlying spatial sparsity reconstruction problem is linked to the compressive sensing (CS) framework. Although this is an area with ongoing intensive research and new methods and results are reported regularly, it is time to have a review about the basic approaches and methods for CS-based DOA estimation, in particular for the underdetermined case. We start from the basic time-domain CS-based formulation for narrowband arrays and then move to the case for recently developed methods for sparse arrays based on the co-array concept. After introducing two specifically designed structures (the two-level nested array and the co-prime array) for optimizing the virtual sensors corresponding to the difference co-array, this CS-based DOA estimation approach is extended to the wideband case by employing the group sparsity concept, where a much larger physical aperture can be achieved by allowing a larger unit inter-element spacing and therefore leading to further improved performance. Finally, a specifically designed uniform linear array structure with associated CS-based underdetermined DOA estimation is presented to exploit the difference co-array concept in the spatio-spectral domain, leading to a significant increase in degrees of freedom. Representative simulation results for typical narrowband and wideband scenarios are provided to demonstrate their performance."
  },
  {
    "year": "2016",
    "abstract": "The introduction of millimeter-wave (mm-wave) technologies in the future 5G networks poses a rich set of network access challenges. We need new ways of dealing with legacy network functionalities to fully unleash their great potential, among them the cell discovery procedure is one of the most critical. In this paper, we propose novel cell discovery algorithms enhanced by the context information available through a C-/U-plane-split heterogeneous network architecture. They rely on a geo-located context database to overcome the severe effects of obstacle blockages. Moreover, we investigate the coordination problem of multiple mm-wave base stations that jointly process user access requests. We show that optimizing the resource allocated to the discovery has a great importance in defining perceived latency and supported user request rate. We have performed complete and accurate numerical simulations to provide a clear overview of the main challenging aspects. The results show that the proposed solutions have an outstanding performance with respect to basic discovery approaches and can fully enable mm-wave cell discovery in 5G networks."
  },
  {
    "year": "2016",
    "abstract": "Matrix inversion is routinely performed in computational engineering, with coupling matrix filter synthesis considered here as just one of many example applications. When calculating the elements of the inverse of a matrix, the determinants of the submatrices are evaluated. The recent mathematical proof of the Desnanot-Jacobi (also known as the “Lewis Carol”) identity shows how the determinant of an N+2 order square matrix can be directly computed from the determinants of the N+1 order principal submatrices and N order core submatrix. For the first time, this identity is applied directly to an electrical engineering problem, simplifying N+2 order coupled matrix filter synthesis (general case, which includes lossy and asymmetrical filters). With the general two-port network theory, we prove the simplification using the Desnanot-Jacobi identity and show that the N+2 coupling matrix can be directly extracted from the zeros of the admittance parameters (given by N+1 order determinants) and poles of the impedance parameters (given by the N order core matrix determinant). The results show that it is possible to decrease the computational complexity (by eliminating redundancy), reduce the associated cost function (by using less iterations), and under certain circumstances obtain different equivalent solutions. Nevertheless, the method also proves its practical usefulness under constrained optimizations when the user desires specific coupling matrix topologies and constrained coefficient values (e.g, purely real/imaginary/positive/negative). This can lead to a direct coupling matrix constrained configuration where other similar methods fail (using the same optimization algorithms)."
  },
  {
    "year": "2016",
    "abstract": "The user-cell association mechanism is one of the important research topics for radio resource management in heterogeneous wireless networks. Existing studies mainly concerned the physical performance such as throughput and SINR, and ignore the upper layer users demand. For avoiding blindness of pursuing higher data rate and achieving more rational user-cell association, a novel method is proposed to associate users with heterogeneous traffic to small cell base stations (SBSs) based on user quality of experience (QoE). The user-cell association problem is formulated as a distributed transfer-matching game between SBSs and users to address the sum-QoE maximization problem. Furthermore, an effective distributed cooperative transfer-matching self-optimizing algorithm, roulette transfer matching algorithm, is designed for exploring the stable point of the game. It is proved that the proposed algorithm can converge to a stable solution and find the optimal two-sided transfer matching. Numerical experiments are presented to validate the proposed scheme and show the improvement for the system performance and fairness."
  },
  {
    "year": "2016",
    "abstract": "Recent developments in marine power systems, energy storage devices (ESDs) technology, and modification to rules and regulations increase the opportunities to improve efficiency and reduce emissions. One particular application is the strategic loading, where the ESD is charged and discharged cyclically, altering the instantaneous fuel consumption, thus aiming to reduce the average fuel consumption. Due to the ESD switching behavior, a hybrid simulation framework is an appropriate dynamic modeling tool. The hybrid simulation model is important in proper design and verification of control strategies for hybrid power plants. A hybrid model was derived, modeling transients as continuous-time events and modeling instantaneous behavior changes as discrete events. Due to the complexity of the system and its hybrid nature (continuous and discrete times), it is important to validate the derived model, such that are known its accuracy and limitations. The developed hybrid model was validated using experiments at the Hybrid Machinery Laboratory, Norwegian University of Science and Technology. The analyzed effects are the steady state, transient behavior, and losses. The transient behaviors include Generator-set (genset) dynamics and load ramps. The losses include the production losses, transmission losses, and ESD losses. The non-modeled effects include the load fluctuation, genset speed variation about the given set-point, and thermal effects on the genset and on the ESD. The results show good correlation between the hybrid model and the experiments. The fuel consumption estimation error stayed below 3% for all 15 analyzed cases, as well as having less than 9% deviation for the NOxgas emissions estimation. The model is considered as a good approximation for the real operation, enabling its use for design and research purposes."
  },
  {
    "year": "2016",
    "abstract": "The widespread use of mobile networking devices, such as smart phones and tablets, has substantially increased the number of nodes in the operational networks. These devices often suffer from the lack of power and bandwidth. Hence, we have to optimize their message routing for the sake of maximizing their capabilities. However, the optimal routing typically relies on a delicate balance of diverse and often conflicting objectives, such as the route's delay and power consumption. The network design also has to consider the nodes' user-centric social behavior. Hence, the employment of socially aware load balancing becomes imperative for avoiding the potential formation of bottlenecks in the network's packet-flow. In this paper, we propose a novel algorithm, referred to as the multi-objective decomposition quantum optimization (MODQO) algorithm, which exploits the quantum parallelism to its full potential by reducing the database correlations for performing multi-objective routing optimization, while at the same time balancing the teletraffic load among the nodes without imposing a substantial degradation on the network's delay and power consumption. Furthermore, we introduce a novel socially aware load balancing metric, namely, the normalized entropy of the normalized composite betweenness of the associated socially aware network, for striking a better tradeoff between the network's delay and power consumption. We analytically prove that the MODQO algorithm achieves the full-search based accuracy at a significantly reduced complexity, which is several orders of magnitude lower than that of the full search. Finally, we compare the MODQO algorithm to the classic non-dominated sort genetic algorithm II evolutionary algorithm and demonstrate that the MODQO succeeds in halving the network's average delay, while simultaneously reducing the network's average power consumption by 6 dB without increasing the computational complexity."
  },
  {
    "year": "2016",
    "abstract": "Ray tracing simulation results indicate that a high-resolution database is not needed to exploit user position knowledge in the 28-GHz band, even in the case of inexact information. A proposed antenna alignment algorithm (using maximum position errors and database resolutions of 10 and 4 m, respectively) that takes advantage of the propagation characteristics knowledge of database points located around the reported location is applied. The results show that the distance between the points can be increased up to 2 m with no considerable negative impact on performance. Simulations also indicate that this outcome is sustained when the maximum power level received at the user equipment varies. The algorithm provides the benefit of a higher initial power delivery and fewer steps, as long as the exact geographical position of the user is within the circular area containing the considered database points. The performance is similar to or better than that of a modified classical hierarchical procedure."
  },
  {
    "year": "2016",
    "abstract": "In this paper, closed-form expressions for the performance of the normalized matched filter (NMF) detector are developed specifically for the case of large time-bandwidth product, N. As a test case, the task of detecting underwater acoustic signals is considered. While the matched filter is the most common detector used, the NMF detector is used in cases where the ambient noise is fast time varying and is hard to estimate. While the performance of the NMF has been studied, no closed-form expressions are given for the detection and false alarm probabilities, and the accuracy of the available approximations greatly deteriorates with N. As a result, evaluating the detection threshold from the receiver operating characteristic requires significant, and sometimes untraceable, numerical calculations. This is specifically important for underwater acoustic signals, where due to the low signal-to-noise ratio, N is very large. The analysis performed in this paper solves this problem. The analysis is based on the probability distribution of the NMF to give an exact closed-form (tabulized) expression for the false alarm probability, and a relatively accurate approximation for the probability of detection, both for the large N case. These approximations are found accurate in numerical simulations. Results from an experiment conducted in the Mediterranean sea at the depth of roughly 1000 m validate the analysis."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we focus on the radio resource management (RRM) issues in the two-hop Orthogonal Frequency Division Multiple Access (OFDMA) system with heterogeneous quality of service (QoS) requirements. To solve the RRM problem, we first propose a new two-hop frame structure to support the data relay operation from the base station to the relay station and cooperative transmission for the edge users. Then, a two-hop coordinated scheduling algorithm is proposed, which utilizes the proposed two-hop frame structure and considers the corresponding interference status. The proposed two-hop coordinated scheduling algorithm solves the RRM problem of the two-hop OFDMA system with heterogeneous QoS requirements in an iterative manner, and so maximizes the system utility."
  },
  {
    "year": "2016",
    "abstract": "The detection of agents whose responses satisfy equilibrium play is useful for predicting the dynamics of information propagation in social networks. Using Afriat's theorem of revealed preferences, we construct a non-parametric detection test to detect if the responses of a group of agents is consistent with play from the Nash equilibrium of a concave potential game. For agents that satisfy the detection test, it is useful to learn the associated concave potential function of the game. In this paper, a non-parametric learning algorithm is provided to estimate the concave potential function of agents with necessary and sufficient conditions on the response class for the algorithm to be a probably approximately correct learning algorithm. In the case of response signals measured in noise, a statistical test to detect agents playing a concave potential game that has a pre-specified Type-I error probability is provided. The detection tests and learning algorithm are applied to real-world data sets from the Twitter social network and the Ontario power grid."
  },
  {
    "year": "2016",
    "abstract": "Some inherent shortcomings of the global positioning systems (GPSs), such as limited accuracy and availability, limit the positioning performance of a vehicular location system in urban harsh environments. This motivates the development of cooperative positioning (CP) methods based on emerging vehicle-to-anything communications. In this paper, we present a framework of vehicular positioning enhancement based on dedicated short range communications (DSRC). An interactive multiple model is first used to track the distributed manners of both the vehicle acceleration variations and the switching of the covariances of DSRC physical measurements such as the Doppler frequency shift and the received signal strength indicator, with which a novel CP enhancement method is presented to improve the distributed estimation performance by sharing the motion states and the physical measurements among local vehicles through vehicular DSRC. We have also presented an analysis on the positioning performance, and a closed-formed lower bound, named the modified square position error bound (mSPEB), is derived for bounding the positioning estimation performance of CP systems. Simulation results have been supplemented to compare our proposed method with the stand-alone GPS implementation in terms of the root-mean-square error (RMSE), showing that the obtained positioning enhancement can improve comprehensive positioning performance by the percentage varying between about 35% and about 72% under different traffic intensities and the connected vehicle penetrations. More importantly, the RMSE achieved by our method is shown remarkably closed to the root of the theoretical mSPEB."
  },
  {
    "year": "2016",
    "abstract": "Being a key computing element in cloud data center, virtual machines should be able to migrate from one location to another to meet the requirements of the cloud users and the defined policies of the cloud computing system. The mobility is an important issue when a virtual machine migrates across IP subnets. This paper focuses on the mobility management in cloud computing systems, and proposes a mobility-oriented cloud data center network architecture based on the identity/locator decoupling method of the mobility-driven networks. In cloud data center network, a mobile node refers to a virtual machine, and the mobility behavior mainly refers to virtual machine migration. In the proposed architecture, a virtual machine could implement live migration between IP subnets without service interruption. The evaluation shows that the proposed scheme can solve mobility issues effectively in virtual machine migration among IP subnets."
  },
  {
    "year": "2016",
    "abstract": "Wireless communication at near-capacity transmission throughputs is facilitated by employing sophisticated Error Correction Codes (ECCs), such as turbo codes. However, real-time communication at high transmission throughputs is only possible if the challenge of implementing turbo decoders having equally high processing throughputs can be overcome. Furthermore, in many applications, turbo decoders are required to have the flexibility of supporting a wide variety of turbo code parametrizations. This motivates the implementation of turbo decoders using networks-on-chip (NoCs), which facilitate flexible and high-throughput parallel processing. However, turbo decoders conventionally operate on the basis of the Logarithmic Bahl-Cocke-Jelinek-Raviv (Log-BCJR) algorithm, which has an inherently serial nature, owing to its data dependencies. This limits the exploitation of the NoC's computing resources, particularly as the size of the NoC is scaled up. Motivated by this, we propose a novel turbo decoder algorithm, which eliminates the data dependencies of the Log-BCJR algorithm and, therefore, has an inherently parallel nature. We show that by jointly optimizing the proposed algorithm with the NoC architecture, a significantly improved utility of the available computing resources is achieved. Owing to this, our proposed turbo decoder achieves a factor of up to 2.13 higher processing throughput than a Log-BCJR bench marker."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we address the consensus problem of second-order multi-agent system with sampled-data and packet losses. A Bernoulli stochastic variable is used to characterize the random packet losses in second-order multi-agent system with sampled-data information, in which packet losses are modeled in a successive way. Based on the matrix exponential and stochastic analysis techniques, several sufficient conditions are given to ensure the almost surely synchronization of second-order multi-agent networks with sampled-data and packet losses, where the graph among the agents is a directed network containing a directed spanning tree. Additionally, we further investigate the almost surely consensus for such system containing time-delays and packed dropouts. On this occasion, the communication graph among the agents is represented by an undirected connected graph. Furthermore, it is found that the probability of packet losses and the modulus of eigenvalues of the Laplace matrix play a vital role in achieving almost surely consensus. In the end, the developed results are applied to the coordination of multiple vehicles. Two examples are provided to illustrate the effectiveness of our results."
  },
  {
    "year": "2016",
    "abstract": "A wideband strip-helical antenna with a parasitic circular patch for circular polarization is designed in this paper. A strip-helix with 2.5 turns and a pitch angle of 5° is placed over a ground plane and coaxial probe-fed by a 50-Ω SMA connector. A parasitic patch is electromagnetic-coupled to the open end of the strip-helix with an extremely small distance. By combining the strip-helix with the parasitic patch, two nearby circularly polarized (CP) resonances are produced and a wide axial ratio (AR) bandwidth is obtained. The strip-helix can excite a CP resonance in axial mode, while the parasitic patch can generate another nearby one in fundamental mode. Radiation characteristics of the proposed design, including current distributions, reflection coefficient (S11), AR, and radiation patterns, are studied. Measured results shows that the proposed antenna has an impedance bandwidth (S11≤-10 dB) of 53%, an AR bandwidth (AR 3 dB) of 44%, and a peak gain of 9.4 dBi in its volume of 0.43λ0× 0.43λ0× 0.25λ0, where λ0is the wavelength in free space at the center operation frequency."
  },
  {
    "year": "2016",
    "abstract": "We have developed a robust sensor for mounting on bridges over rivers and streams. These bridge-mounted river stage sensors (BMRSS) make periodic measurements of the distance from the sensor to the water level below. Properly interpreted, these measurements provide river-stage information, data of great importance to society and crucial to effective flood forecasting. The traditional approach to river stage measurement is the installation of pipes in rivers, digging stilling wells, and the construction of attendant brick-and-mortar infrastructure. The cost of this approach limits the deployment to larger rivers. In most instances, river-stage data from smaller tributaries are few, even though such data can greatly enhance the quality of flood-forecasting models' outputs. In contrast, BMRSS units are an order of magnitude less expensive and allow for widespread deployment. BMRSS units incorporate an ultrasonic distance-measuring module, a solar panel/battery/charge controller, and a GPS receiver. In recent years, the Internet access through commercial cellular networks has become ubiquitous, even in most rural areas. BMRSS units incorporate cell modems and transmit data through the Internet to servers at the Iowa Flood Center. Here, the data are ingested into relational databases and made available to flood forecasting models and information systems. We have deployed and operated more than 220 BMRSS units across Iowa, many for several years continuously."
  },
  {
    "year": "2016",
    "abstract": "In the context of Industry 4.0, it is necessary to meet customization manufacturing demands on a timely basis. Based on the related concepts of Industry 4.0, this paper intends to introduce mobile services and cloud computing technology into the intelligent manufacturing environment. A customization manufacturing system is designed to meet the demands of personalization requests and flexible production mechanisms. This system consists of three layers, namely, a manufacturing device layer, cloud service system layer, and mobile service layer. The manufacturing device layer forms the production platform. This platform is composed of a number of physical devices, such as a flexible conveyor belt, industrial robots, and corresponding sensors. The physical devices are connected to the cloud via the support of a wireless module. In the cloud, the manufacturing big data are processed, and the optimization decision-making mechanism pertaining to customization manufacturing is formed. Then, mobile services running in a mobile terminal are used to receive orders from customers and to inquire the necessary production information. To verify the feasibility of the proposed customization manufacturing system, we also established a customizable candy production system."
  },
  {
    "year": "2016",
    "abstract": "The combination of tomographic imaging and deep learning, or machine learning in general, promises to empower not only image analysis but also image reconstruction. The latter aspect is considered in this perspective article with an emphasis on medical imaging to develop a new generation of image reconstruction theories and techniques. This direction might lead to intelligent utilization of domain knowledge from big data, innovative approaches for image reconstruction, and superior performance in clinical and preclinical applications. To realize the full impact of machine learning for tomographic imaging, major theoretical, technical and translational efforts are immediately needed."
  },
  {
    "year": "2016",
    "abstract": "Among the models that describe the dynamic behaviors of financial market, the discrete time microstructure model stands out because of its efficiency in considering the relationship between the price, excess demand, and liquidity of a market. However, the estimation problem of such a microstructure model is challenging, because the model is essentially a nonlinear state space model. A decent solution is to define a self-organizing state-space model by combining the unknown parameters and the state vector of the original model into a new state vector. Then, the sequential Monte Carlo method can be used to simultaneously estimate the parameters and states. To handle the difficulty in setting the initial distributions of parameters for the self-organizing state space model, we propose to use the results obtained by the Kalman filter on the original microstructure model. Finally, a dynamic asset allocation strategy is designed based on estimated excess demand using the self-organizing state space model. The proposed methodology is evaluated by the China SZSE (ShenZhen Stock Exchange) Composite Index time series, and the results show its effectiveness."
  },
  {
    "year": "2016",
    "abstract": "This multidisciplinary paper reports on a research application-led study for predicting atmospheric attenuation, and tries to bridge the knowledge gap between applied engineering and atmospheric sciences. As a useful comparative baseline, this paper focuses specifically on atmospheric attenuation under pristine conditions, over the extended terahertz spectrum. Three well-known simulation software packages (`HITRAN on the Web', MODTRAN®4, and LBLRTM) are compared and contrasted. Techniques used for modeling atmospheric attenuation have been applied to investigate the resilience of (ultra-)wide fractional bandwidth applications to the effects of molecular absorption. Two extreme modeling scenarios are investigated: horizontal path links at sea level and Earth-space path links. It is shown by example that a basic software package (`HITRAN on the Web') can give good predictions with the former, whereas sophisticated simulation software (LBLRTM) is required for the latter. Finally, with molecular emission included, carrier-to-noise ratio fade margins can be calculated for the effects of line broadening due to changes in macroscopic atmospheric conditions with sub-1-THz ultra-narrow fractional bandwidth applications. Outdoors can be far from pristine, with additional atmospheric contributions only briefly introduced here; further discussion is beyond the scope of this paper, but relevant references have been cited."
  },
  {
    "year": "2016",
    "abstract": "This paper establishes the asymptotic closed forms of the expectation and variance of the Gini correlation (GC) under a particular type of bivariate contaminated Gaussian model emulating a frequently encountered scenario in statistical signal processing. Monte Carlo simulation results verify the correctness of the theoretical results established in this paper. In order to gain further insight into GC, we also compare GC to Pearson's product moment correlation coefficient, Kendall's tau, and Spearman's rho by means of root mean squared error. The newly explored theoretical and simulational findings not only deepen the understanding of the rather new GC, but also shed new light on the topic of correlation theory, which is widely applied in statistical signal processing."
  },
  {
    "year": "2016",
    "abstract": "This paper is concerned with the problem of robust decentralized output-feedback control for a class of continuous-time large-scale nonlinear systems. Each nonlinear subsystem, described by a Takagi–Sugeno model, involves in the interconnections and parametric uncertainties of the large-scale systems. The main focus of this paper is to design a robust decentralized static output-feedback (SOF) fuzzy controller, such that the resulting closed-loop system is asymptotically stable with a prescribedH∞disturbance attenuation level. Based on some matrix inequality linearization techniques and the descriptor system approach, sufficient conditions for the existence of a robust decentralized SOFH∞fuzzy controller are presented in terms of linear matrix inequalities. From different perspectives, the desired controller is designed to analyze the degree of conservatism induced by considering various limitations. The effectiveness and superiority of the proposed method are finally demonstrated by two numerical examples."
  },
  {
    "year": "2016",
    "abstract": "Leaky coaxial cable (LCX) has long been used to cover blind and semi-blind zones in wireless communication. In this paper, we propose a novel system using a LCX. The key idea is to deploy LCX and use wireless information obtained through PHY layer wireless channel state information (CSI).The core application involves identifying multiple patients' postures in bed in order to reduce the formation of pressure ulcers or bedsores on the skin. The indoor installation and periodic recording of postures help monitor and prevent bedsores. The CSI registrations are collected using 802.11n Intel WLAN NICs. These CSI registration signatures are unique for particular posture. The amplitude variation is used for differentiating and classifying the postures for inference."
  },
  {
    "year": "2016",
    "abstract": "Based on grouping the pulses that compose the sub-carrier of the time-multiplexed binary offset carrier (TMBOC), we present an unambiguous correlation function that has no side-peaks causing the ambiguity in the TMBOC signal tracking, and also, that has a higher degree of the sharpness of the main-peak (DSM) over those of the conventional unambiguous correlation functions. Splitting the pulses composing the TMBOC sub-carrier into 12 groups, and, subsequently, forming the 12 group correlations corresponding to the 12 groups, we investigate the contribution of each of the 12 group correlations to the side peaks and main peak of the TMBOC autocorrelation function. Then, we propose a combining method of the 12 group correlations based on the investigation to remove the side peaks while improving the DSM. Numerical results demonstrate that the proposed unambiguous correlation function not only has no side-peaks, but also has a higher DSM, and, consequently, has a better tracking error performance than those of the conventional unambiguous correlation functions."
  },
  {
    "year": "2016",
    "abstract": "For a seamless deployment of the Internet of Things (IoT), there is a need for self-organizing solutions to overcome key IoT challenges that include data processing, resource management, coexistence with existing wireless networks, and improved IoT-wide event detection. One of the most promising solutions to address these challenges is via the use of innovative learning frameworks that will enable the IoT devices to operate autonomously in a dynamic environment. However, developing learning mechanisms for the IoT requires coping with unique IoT properties in terms of resource constraints, heterogeneity, and strict quality-of-service requirements. In this paper, a number of emerging learning frameworks suitable for IoT applications are presented. In particular, the advantages, limitations, IoT applications, and key results pertaining to machine learning, sequential learning, and reinforcement learning are studied. For each type of learning, the computational complexity, required information, and learning performance are discussed. Then, to handle the heterogeneity of the IoT, a new framework based on the powerful tools of cognitive hierarchy theory is introduced. This framework is shown to efficiently capture the different IoT device types and varying levels of available resources among the IoT devices. In particular, the different resource capabilities of IoT devices are mapped to different levels of rationality in cognitive hierarchy theory, thus enabling the IoT devices to use different learning frameworks depending on their available resources. Finally, key results on the use of cognitive hierarchy theory in the IoT are presented."
  },
  {
    "year": "2016",
    "abstract": "A novel on-demand cluster-based hybrid routing protocol for cognitive radio ad hoc network with non-uniform node distribution is proposed in this paper. At first, a novel spectrum-aware clustering mechanism is introduced. The proposed clustering mechanism divides node into clusters based on three values: spectrum availability, power level of node, and node stability. Therefore, clusters are formed with the highest stability to avoid frequent reclustering. Later, a routing algorithm is introduced to minimize the delay while achieving acceptable delivery ratio. In this paper, routing is defined as a multi-objective optimization problem to combine different individual routing metrics to form a global metric. Simulation results show that our proposed routing algorithm can guarantee a lower delay and a higher packet delivery ratio than conventional routing protocols for cognitive radio ad hoc networks. Due to our routing design specification, such as power consideration and low delay, it can be suitable to be adopted for Internet of Things applications."
  },
  {
    "year": "2016",
    "abstract": "Pilot contamination (PC) is a stumbling block in theway of realizing massive multi-input multi-output (MIMO) systems. This contribution proposes a location-aware channel estimation-enhanced massive MIMO system employing time-division duplexing protocol, which is capable of significantly reducing the inter-cell interference caused by PC and, therefore, improving the achievable system performance. Specifically, we present a novel location-aware channel estimation algorithm, which utilizes the property of the steering vector to carry out a fast Fourier transform-based post-processing after the conventional pilot-aided channel estimation for mitigating PC. Our asymptotic analysis proves that this post-processing is capable of removing PC from the interfering users with different angle-of-arrivals (AOAs). Since in practice the AOAs of some users may be similar, we further present a location-aware pilot assignment method to ensure that users utilizing the same pilot have distinguishable AOAs, in order to fully benefit from the location-aware channel estimation. Simulation results demonstrate that the proposed scheme can dramatically reduce the inter-cell interference caused by the re-use of the pilot sequence and improve the overall system performance significantly, while only imposing a modest extra computational cost, in comparison with the conventional pilot-aided channel estimation."
  },
  {
    "year": "2016",
    "abstract": "Imperceptibility and robustness are two complementary but fundamental requirements of any watermarking algorithm. Low strength watermarking yields high imperceptibility but exhibits poor robustness. High strength watermarking schemes achieve good robustness but often infuse distortions resulting in poor visual quality in host media. If distortion due to high strength watermarking can avoid visually attentive regions, such distortions are unlikely to be noticeable to any viewer. In this paper, we exploit this concept and propose a novel visual attention-based highly robust image watermarking methodology by embedding lower and higher strength watermarks in visually salient and non-salient regions, respectively. A new low complexity wavelet domain visual attention model is proposed that allows us to design new robust watermarking algorithms. The proposed new saliency model outperforms the state-of-the-art method in joint saliency detection and low computational complexity performances. In evaluating watermarking performances, the proposed blind and non-blind algorithms exhibit increased robustness to various natural image processing and filtering attacks with minimal or no effect on image quality, as verified by both subjective and objective visual quality evaluation. Up to 25% and 40% improvement against JPEG2000 compression and common filtering attacks, respectively, are reported against the existing algorithms that do not use a visual attention model."
  },
  {
    "year": "2016",
    "abstract": "This paper presents the first Keystroke Biometrics Ongoing Competition (KBOC) organized to establish a reproducible baseline in person authentication using keystroke biometrics. The competition has been developed using the BEAT platform and includes one of the largest keystroke databases publicly available based on a fixed text scenario. The database includes genuine and attacker keystroke sequences from 300 users acquired in four different sessions distributed in a four month time span. The sequences correspond to the user's name and surname, and therefore, each user comprises an individual and personal sequence. As baseline for KBOC, we report the results of 31 different algorithms evaluated according to accuracy and robustness. The systems have achieved EERs as low as 5.32% and high robustness to multisession variability with accuracy degradation lower than 1% for probes separated by months. The entire database is publicly available at the competition website."
  },
  {
    "year": "2016",
    "abstract": "With the rapid development of network technology and cloud computing, more and more organizations and users outsource their data into the cloud server. In order to protect data privacy, the sensitive data have to be encrypted, which increases the heavy computational overhead and brings great challenges to resource-constraint devices. In this paper, we propose secure index based on counting Bloom filter (CBF) for ranked multiple keywords search. In the proposed scheme, several algorithms are designed to maintain and lookup CBF, while a pruning algorithm is used to delete the repeated items for saving the space. Besides, the relevance scores are encrypted by the Paillier cryptosystem. It ensures that the same relevance scores are encrypted into different bits, which can resist the statistical analyses on the ciphertext of the relevance scores. Moreover, since the Paillier cryptosystem supports the homomorphic addition of ciphertext without the knowledge of the private key, the major computing work in ranking could be moved from user side to the cloud server side. Therefore, the proposed scheme has huge potentials in resource-constraint mobile devices such as 5G mobile terminals. Security analyses prove that the proposed scheme can prevent the information leakage. Experiment results guarantee that computation overhead of the proposed scheme in user side is low."
  },
  {
    "year": "2016",
    "abstract": "Due to the limited service capabilities of centralized controllers, it is difficult to process high volume of flows within reasonable time. This particularly degrades the strict quality of service (QoS) requirements of interactive media applications, which is non-negligible factor. To alleviate this concern, distributed deployments of software-defined network (SDN) controllers are inevitable and have gained a predominant position. However, to maintain application specific QoS requirements, the number of resources used in network directly impacts the capital and operational expenditure. Hence, in distributed SDN architectures, issues such as flow arrival rate, resources required and operational cost have significant mutual dependencies on each other. Therefore, it is essential to research feasible methods to maintain QoS and minimize resources provisioning cost. Motivated from this, we propose a solution in a distributed SDN architectures that provides flow-balancing (with guaranteed QoS) in pro-active operations of SDN controllers, and attempts to optimize the use of instance resources provisioning costs. We validate our solution using the tools of queuing theory. Our studies indicate that with our solution, a network with minimum resources and affordable cost with guaranteed application QoS can be set-up."
  },
  {
    "year": "2016",
    "abstract": "This paper jointly optimizes intra-cell time allocation and inter-cell load balancing to maximize the network sum-throughput in multi-cell wireless powered communication networks. Since the considered problem is a mixed integer programming problem, it is difficult to attain its global optimality. In this paper, we relax the zero-one integer user association variables into continuous ones. Then, the problem turns out to be a convex problem, which can be efficiently solved. After that, the optimal relaxed solution is rounded to integers. Analysis shows that the optimal solution to the relaxed problem has a highly sparse structure, which guarantees the effectiveness of the proposed approach. Simulation results indicate that the achieved sum-throughput is quite close to the upper bound resulted from the optimal relaxed solution and the proposed strategy significantly outperforms the pure intra-cell resource allocation without load balancing."
  },
  {
    "year": "2016",
    "abstract": "Recently, Mobile Ad hoc Networks (MANETs) have witnessed rapid development due to the low cost, diversity, and simplicity of mobile devices. Such devices can form a reliable network in a short time for use as a rescue information system after a natural disaster, where the communication infrastructure may no longer be available or accessible. Because the nodes in such a network are free to move at any time in the absence of centralized control, routing is considered to be the most challenging issue. Moreover, some routing protocols, such as Neighbor Coverage-Based Probabilistic Rebroadcast (NCPR), completely rely on preset variables, which are required to be set by the system administrator based on the scenario. Unfortunately, the setting that is proper for a specific scenario is not suitable for another scenario. In addition, some other routing protocols, such as Ad hoc On-demand Distance Vector (AODV), employ the Route REQuest message (RREQ) flooding scheme to find a path to a particular destination in the route discovery stage. Although the flooding scheme guarantees better reachability, it introduces undesirable routing overhead, which in turn leads to system performance degradation. Thus, this paper proposes a novel routing protocol, neighbor-based Dynamic Connectivity Factor routing Protocol (DCFP), that is able to dynamically probe the status of the underlying network without the intervention of a system administrator based on a novel connectivity metric, while reducing the RREQ overhead using a new connectivity factor. Furthermore, extensive simulation experiments are conducted to evaluate the performance of the proposed DCFP, where the NCPR and AODV are used as a benchmark. The proposed DCFP manages to address the need for preset variables in NCPR. Simulation results show that DCFP outperforms both NCPR and AODV in terms of end-to-end delay, normalized routing overhead, MAC collision, energy consumption, network connectivity, and packet delivery ratio due to..."
  },
  {
    "year": "2016",
    "abstract": "Cell switch-off (CSO) is recognized as a promising approach to reduce the energy consumption in the next-generation cellular networks. However, CSO poses serious challenges not only from the resource allocation perspective but also from the implementation point of view. Indeed, CSO represents a difficult optimization problem due to its NP-complete nature. Moreover, there are a number of important practical limitations in the implementation of CSO schemes, such as the need for minimizing the real-time complexity and the number of on-off/off-on transitions and CSO-induced handovers. This paper introduces a novel approach to CSO based on multiobjective optimization that makes use of the statistical description of the service demand (known by operators). In addition, downlink and uplink coverage criteria are included and a comparative analysis between different models to characterize intercell interference is also presented to shed light on their impact on CSO. The framework distinguishes itself from other proposals in two ways: 1) the number of on-off/off-on transitions as well as handovers are minimized and 2) the computationally-heavy part of the algorithm is executed offline, which makes its implementation feasible. The results show that the proposed scheme achieves substantial energy savings in small cell deployments, where service demand is not uniformly distributed, without compromising the quality-of-service or requiring heavy real-time processing."
  },
  {
    "year": "2016",
    "abstract": "Described in this paper is a method for improving higher harmonic cancellation in nuclear magnetic resonance transmitters, which are used in oil and gas well logging tools operating at 175 °C. Multi-module multi-level topology which combines the outputs of several identical power modules operating at 50% duty cycle at the fundamental frequency provides the versatility needed for both low harmonic sine voltage synthesis and amplitude control. Cancellation of the output voltage higher harmonics is achieved by creating fixed relative phase shifts between the individual modules of the multi-module converter. The amplitude control employs the Chireix-Doherty outphasing modulation principle with added feed forward correction circuitry. The possibilities of a 20% increase of the tool signal-to-noise ratio, as compared with that of a two-module transmitter has also demonstrated significant increase in the tool life expectancy."
  },
  {
    "year": "2016",
    "abstract": "This paper considers a heterogeneous network, which consists of one macro base station and numerous small cell base stations (SBSs) cooperatively serving multiple user terminals. The first objective is to design cooperative transmit beamformers at the base stations to maximize the network energy efficiency (EE) in terms of bits per joule subject to the users' quality of service (QoS) constraints, which poses a computationally difficult optimization problem. The commonly used Dinkelbach-type algorithms for optimizing a ratio of concave and convex functions are not applicable. This paper develops a path-following algorithm to address the computational solution to this problem, which invokes only a simple convex quadratic program of moderate dimension at each iteration and quickly converges at least to a locally optimal solution. Furthermore, the problem of joint beamformer design and SBS service assignment in the three-objective (EE, QoS, and service loading) optimization is also addressed. Numerical results demonstrate the performance advantage of the proposed solutions."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we consider a non-regenerative relay network supporting simultaneous wireless information and power transfer, in which the energy harvesting relay is powered by radio-frequency signals from the source node. Assuming imperfect channel state information from the source/relay to the destination/eavesdropper, we investigate the artificial noise-aided secure robust beamformer that minimize the transmission power at the relay, while guaranteeing the secrecy rate constraint and the transmit power constraint at the relay. In particular, two types of energy harvesting strategies are considered termed power splitting (PS) and time switching (TS), respectively. These constraints make the optimization problems formulated non-convex and challenging, which are efficiently solved by using the S-procedure and semidefinite relaxation techniques to formulate a tractable approximated version of the original problems. Numerical results show the effectiveness of the proposed robust beamforming schemes. Furthermore, the PS strategy performs better than the TS strategy."
  },
  {
    "year": "2016",
    "abstract": "Pattern mining has been widely used to uncover interesting patterns from data. However, one of its main problems is that it produces too many patterns and many of them are redundant. To reduce the number of redundant patterns and retain overlapping ones, delta-closed pattern pruning was introduced, yet it can only prune subpatterns if they are covered by superpatterns. Such unduly superpatterns need to be pruned. Furthermore, in order to improve the management and interpretation of patterns, pattern summarization is proposed. It renders a small number of patterns that retain the most crucial information. RuleCover algorithm was one of such algorithms. However, it tends to produce over trivial patterns, whereas more interesting and revealing ones may be pruned. To overcome these problems, this paper presents a new algorithm which integrates delta-closed, and RuleCover methods with our other two new algorithms: 1) statistically induced pattern pruning for pruning statistically induced superpatterns by strong subpatterns and 2) AreaCover algorithm for pruning overlapping patterns but retain higher order and high quality patterns with large coverage of the data “area.” Experimental results show that the proposed algorithms produce very compact yet comprehensive knowledge from patterns discovered from relational data sets."
  },
  {
    "year": "2016",
    "abstract": "The dynamic adaptive streaming technique flexibly adapts the video bit-rate to link fluctuations, which can improve the quality of experience (QoE). In this paper, we present a systematic framework of video streaming in the context of information-centric networking, in order to facilitate the large-scale deployment of the dynamic adaptive streaming technique. Specifically, we design the network as a two-layer coordinating structure, namely, the control layer and the transmission layer. The control layer employs the statistical data recorders to record the variations of the video popularity, link states, and user demands. On the other side, the network forwards user requests and caches data packets in the transmission layer, based on the statistical data which is obtained in the control layer. In addition, the network executes the real-time monitoring of link conditions in the transmission layer, and adjusts the video bit-rate accordingly. Under the above feedback circumstance, we first develop a distributed algorithm of joint dynamic forwarding and caching to theoretically maximize the total user demand rates within the network stability region. Then, we modify the distributed algorithm with a practical caching strategy to make the system applicable to real scenarios. Simulation results show the superior performance of the modified distributed algorithm in terms of low user delay and high QoE performance."
  },
  {
    "year": "2016",
    "abstract": "Mobile device identification techniques can be applied to secure authentication, and will be of particular importance for the security of mobile networks, such as avoiding spoofing attacks. For Android devices, explicit identifiers, e.g., Android ID, are used to uniquely identify a device. However, permissions are required to gain such identifiers, and this could cause the permission abuse and the leakage of user privacy. To address these issues, we use the combination of implicit identifiers that cannot identify a device individually. We first investigate 38 implicit identifiers that are acquired without requesting any permission. Then, a feature selection algorithm is used to choose effective identifiers as the device fingerprint, and three algorithms are designed to identify the devices. Finally, we conduct experimental evaluations on 50 830 fingerprints from 2239 different Android devices. The empirical results demonstrate the effectiveness and efficiency of our algorithms."
  },
  {
    "year": "2016",
    "abstract": "Television white space (TVWS) technology is approaching the potential roll-out phase for commercial deployment, supported by recent pilot projects being conducted globally. Undeniably, TVWS technology is faced with daunting challenges that require attention. To enable an ecosystem in which TVWS technology can flourish, there is a need for a complete analysis of the challenges, trends and future research direction related to this technology. Database-assisted TVWS technology is market driven, geared toward the spectrum reuse paradigm, and faces fewer technical hurdles. Our goal in this paper is to present a tutorial review of the challenges related to database-assisted TVWS networks using the SLEPT (social, legal, economic, political, and technological) analysis framework. The SLEPT framework is a management model that is extensively used for quantitative analysis. A brief review of TVWS technology using the SLEPT model reveals that the technology has been socially accepted, legal challenges are evident in some countries, economic models are the way forward and are main focus of current research trends, TVWS technology cannot be implemented without political will emanating from spectrum reforms, and there are many coexistence-motivated technological issues confronting TVWS technology. In summary, this paper provides an up-to-date survey on TVWS and presents current trends and future research directions in the TVWS context."
  },
  {
    "year": "2016",
    "abstract": "The fast-growing healthcare big data plays an important role in healthcare service providing. Healthcare big data comprise data from different structured, semi-structured, and unstructured sources. These data sources vary in terms of heterogeneity, volume, variety, velocity, and value that traditional frameworks, algorithms, tools, and techniques are not fully capable of handling. Therefore, a framework is required that facilitates collection, extraction, storage, classification, processing, and modeling of this vast heterogeneous volume of data. This paper proposes a healthcare big data framework using voice pathology assessment (VPA) as a case study. In the proposed VPA system, two robust features, MPEG-7 low-level audio and the interlaced derivative pattern, are used for processing the voice or speech signals. The machine learning algorithms in the form of a support vector machine, an extreme learning machine, and a Gaussian mixture model are used as the classifier. In the experiments, the proposed VPA system shows its efficiency in terms of accuracy and time requirement."
  },
  {
    "year": "2016",
    "abstract": "In many areas of the world accessing professional physicians “when needed/as needed” might not be always possible for a variety of reasons. Therefore, in such cases, a targeted e-Health solution to safeguard patient long-term health could be a meaningful approach. Today's modern healthcare technologies, often built around electronic and computer-based equipment, require an access to a reliable electricity supply. Many healthcare technologies and products also presume access to the high speed internet is available, making them unsuitable for use in areas where there is no fixed-line internet connectivity, access is slow, unreliable, and expensive, yet where the most benefit to patients may be gained. In this paper, a full mobile sensor platform is presented, based around readily-purchased consumer components, to facilitate a low cost and efficient means of monitoring the health of patients with prosthetic lower limbs. This platform is designed such that it can also be operated in a standalone mode, i.e., in the absence of internet connectivity, thereby making it suitable to the developing world. Also, to counter the challenge of power supply issues in e-Health monitoring, a self-contained rechargeable solution to the platform is proposed and demonstrated. The platform works with an Android mobile device, in order to allow for the capture of data from a wireless sensor unit, and to give the clinician access to results from the sensors. The results from the analysis, carried out within the platform's Raspberry Pi Zero, are demonstrated to be of use for remote monitoring. This is specifically targeted for monitoring the tissue health of lower limb amputees. The monitoring of residual limb temperature and gait can be a useful indicator of tissue viability in lower limb amputees especially those suffering from diabetes. We describe a route wherein non-invasive monitoring of tissue health is achievable using the Gaussian process technique. This knowledge will be useful in ..."
  },
  {
    "year": "2016",
    "abstract": "Geotechnical investigation is essentially a process of information acquisition, analysis, and application. Informatization is an attractive way to improve the efficiency of geotechnical investigation. Typical approaches divide the process of geotechnical investigation into isolated stages and only focus on the local informatization of the entire process. This leads to limitations in the improvement of geotechnical investigation efficiency, misuse of geotechnical data, and interpreted results that are incorrect. Therefore, a work flow and operational mode to address the informatization throughout the overall process of geotechnical investigation is particularly important in developing a software designed for efficient and precise geotechnical investigations. In this paper, we design a work flow and operational mode for geotechnical investigation based on a geotechnical BIM model and database. Within this work flow, the construction of a 3-D geotechnical information model and BIM-based database is taken as the main line. The constantly updated model and the database are the platform for working and analysis. As this strategy can link every stage in the whole process of geotechnical investigation, all the work can be done based on the BIM model and database in a 3-D environment, so improvement in the overall efficiency of geotechnical investigation is possible. Furthermore, the integrative center combined by the BIM model and database is targeted to reduce data errors, data conversions, and the abstractness of geotechnical data, which can improve the interpreted accuracy of these data. Finally, we use the process of geotechnical investigation at a hydropower station for experimental studies to verify the proposed work flow and operational mode. The result shows that it is feasible to design the software for an efficient and more accurate geotechnical investigation based on the proposed work flow and operational mode."
  },
  {
    "year": "2016",
    "abstract": "This paper develops an integrated theoretical framework that links visuo-spatial mental models of Web interface design to user satisfaction, and reports on a controlled experiment aimed at investigating the nature of these mental models. Using data from more than 500 subjects in conjunction with both graphical and statistical analyses, we find that Web users possess a strongly cohesive shared mental model of the way in which a Web interface should be designed. In addition to describing and quantifying this shared visuo-spatial mental model, this paper also shows how both experience and the physiological properties of the human visual system give rise to such models, and discusses the implications of the results for organizational website design, scientific theory, and future research in this area."
  },
  {
    "year": "2016",
    "abstract": "Since dynamic economic dispatch with wind power uncertainty poses great challenges for power system operation due to its non-linear and uncertain characteristics, this paper proposes a robust optimization model with different levels of uncertainty budget. The dynamic economic dispatch problem is converted into the robust optimization model with an uncertainty budget, which transforms the nondeterministic model into a deterministic optimization problem. Differential evolution is improved by the sequential quadratic programming method and utilized to solve the robust optimization model. Due to the complex-coupled constraints among thermal units, several constraint-handling procedures are proposed to address those constraint limits, which have a significant impact on the efficiency of the whole optimization. The robust optimization model with an adjustable uncertainty budget is implemented in two test systems. The results obtained for the first test system prove the efficiency of differential evolution-based sequential quadratic programming and the constraint-handling procedures; the performance of the second test system reveals that the robust optimization method with different levels of uncertainty budget provides a promising method for solving the dynamic economic dispatch problem with wind power uncertainty."
  },
  {
    "year": "2016",
    "abstract": "The ultimate goal of private function evaluation is the complete outsourcing of processing tasks to distrusted platforms (such as clouds), so that arbitrary functions can be evaluated without any leakage of secret information. Several successful concepts have been proposed in the past, the most striking one having been fully homomorphic encryption besides the well-known garbled circuits and multiparty computation. In this paper, we look at an idealized model of outsourced computation, which we call a cryptocomputer. This is a (theoretical) machine that works exactly like a real-life computer in the sense of understanding a standard assembly language, but retaining all its internal signals, registers, and memory encrypted at all times. The encryption is assumed under a key that is unknown to the attacker, and taken as secure (in any cryptographically meaningful way), so that no leakage of information from any ciphertext can be expected from programs with reasonable (polynomial) time complexity. Unfortunately, such a cryptocomputer is necessarily insecure, irrespectively of how the encryption looks like. In particular, we explicitly do not assume any specific form of security (chosen-ciphertext or other) or (a)symmetry of encryption; our attack works only on ciphertexts and makes no assumptions whatsoever on the encryption. We prove insecurity of the cryptocomputer by taking the encryption as a black box, and show how to decipher every signal in the computer by pure virtue of submitting proper instructions for execution. Our attack falls into the general category of side-channel attacks, however unlike other related attacks, does neither exploit physical nor any logical characteristics of the underlying platform (besides the execution flow being observable). Somewhat surprisingly, it turns out that although the problem that we consider is cryptographic, it seemingly has no cryptographic solution and apparently calls for an interdisciplinary approach from new direction..."
  },
  {
    "year": "2016",
    "abstract": "Under the case of exponentially growth of wireless services and the scarcity of spectrum resources, cognitive radio (CR) has been proposed to access licensed channels opportunistically, and thus improve spectrum utilization. In CR devices, accurate spectrum sensing is the prerequisite for opportunistic access. The current cooperative spectrum sensing still cannot effectively exploit the temporal correlations among sensing data, especially the correlations between the current sensing data and the historical data. This paper uses sticky hierarchical Dirichlet process-hidden Markov model to exploit the historical sensing data of multiple users, and classifies the historical sensing data into groups according to their latent spectrum states. The proposed spectrum sensing algorithm can fuse the historical sensing data into prior knowledge, which can be used to improve the accuracy in spectrum decision. Furthermore, a rejection process is proposed to filter out some sensing data with high uncertainty in classification, which guarantees the effectiveness of historical sensing data. The simulation results show that the proposed algorithm performs the best, compared with other three typical cooperative spectrum sensing algorithms, in terms of detection probability and false alarm probability. Specifically, when the false alarm probability is 0.2, the proposed algorithm has more than 10% and 60% detection probability improvement under channel signal-to-noise ratio as 0 and -5 dB, respectively."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on the driving steering load cycle stress-strain, shake, and transient temperature profiles in relation to failure in an automotive electric power steering (EPS) system. A compact EPS control system model was applied to construct a lookup table for the device power loss calculations. The lookup table was used to obtain the full electrothermal profile of a vehicle EPS system converter. An accurate thermal model was introduced using FLOTHERM software and compared with the results from EPS device temperature testing. The transient junction temperature profiles of the device were studied based on the operational cycles of the vehicle EPS system. Finally, an efficient rainflow cycle counting method was introduced to obtain the statistic random transient thermal stress cycles. Miner's rule was also explored, and the relationship between the accumulated thermal stress damage and material fatigue was used to predict the converter's reliability."
  },
  {
    "year": "2016",
    "abstract": "A dilemma in cloud radio access networks (C-RANs) is how to keep a balance between the performance and the efficiency of centralized processing. To solve this problem, the joint design of training-based channel estimation and cluster formation are studied in this paper. To provide efficient cooperation strategies in C-RANs, individual C-RAN clusters are formed by the remote radio heads (RRHs), and a data-assisted channel estimation scheme is studied, which can reduce the redundant cost of training sequences. To ensure the performance of channel estimation and data transmissions, the cluster formation and the channel estimation are optimized jointly. In particular, an iterative training-based channel estimation scheme is designed by using convex optimization and the Broyden-Fletcher-Goldfarb-Shanno algorithm jointly. Moreover, a utility function of cluster formation can be established based on the estimates and the mean squared error of our proposed channel estimation algorithm, and the cluster formation of RRHs can be formulated as a coalitional formation game. Furthermore, a sub-optimal algorithm is also proposed to reduce the computational complexity. Finally, the simulation results are shown to evaluate the performance of our proposed algorithms."
  },
  {
    "year": "2016",
    "abstract": "Fault diagnosis of inductions motors has received much attention recently. Most of the works use data obtained either from the time domain or by applying advanced techniques in the frequency domain. Some researchers have employed a considerable effort in designing sophisticated algorithms to achieve the best performance of the diagnosis system. However, some contributions in the field have not taken advantage of the benefits that a good evaluation stage can bring to the developing of classifiers for fault diagnosis. In this paper, novel insights for the classifier evaluation are presented to promote better assessment practices in the field of electric machine diagnosis based on supervised classification. A case of study consisting of a motor with a broken rotor bar is described to analyze the performance of two classifiers by using scores focused on the fault detection. Also, different error estimation methods are considered to obtain unbiased predictive performances. Two statistical tests are also discussed to confirm the significance of the results under a single data set."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes the advection-diffusion equation for modeling the bipolar memristor. The model identifies limiters to switching speed, reproduces general experimental results including those relating temperature dependence of I-V curves, and abstracts the contemporary dual variable resistor model. The model also reveals implicit complex resistors that cause the fleeting negative resistance characteristic in the memristor, as observed by Chua. Elegant closed-form solutions with remarkable scope are produced even under simplified modeling conditions. Numerical methods verify the closed form model. The proposed model uniquely derives all memristive behavior from a single governing advection-diffusion equation and bridges the vacancy and circuit domain abstractions."
  },
  {
    "year": "2016",
    "abstract": "The concept of smart home is widely favored, as it enhances the lifestyle of the residents involving multiple disciplines, i.e., lighting, security, and much more. As the smart home networks continue to grow in size and complexity, it is essential to address a handful among the myriads of challenges related to data loss due to the interference and efficient energy management. In this paper, we propose a smart home control system using a coordinator-based ZigBee networking. The working of the proposed system is three fold: smart interference control system controls the interference caused due to the co-existence of IEEE 802.11x-based wireless local area networks and wireless sensor networks; smart energy control system is developed to integrate sunlight with light source and optimizes the energy consumption of the household appliances by controlling the unnecessary energy demands; and smart management control system to efficiently control the operating time of the electronic appliances. The performance of the proposed smart home is testified through computer simulation. Simulation results show that the proposed smart home system is less affected by the interference and efficient in reducing the energy consumption of the appliances used in a smart home."
  },
  {
    "year": "2016",
    "abstract": "Customer retention is a major issue for various service-based organizations particularly telecom industry, wherein predictive models for observing the behavior of customers are one of the great instruments in customer retention process and inferring the future behavior of the customers. However, the performances of predictive models are greatly affected when the real-world data set is highly imbalanced. A data set is called imbalanced if the samples size from one class is very much smaller or larger than the other classes. The most commonly used technique is over/under sampling for handling the class-imbalance problem (CIP) in various domains. In this paper, we survey six well-known sampling techniques and compare the performances of these key techniques, i.e., mega-trend diffusion function (MTDF), synthetic minority oversampling technique, adaptive synthetic sampling approach, couples top-N reverse k-nearest neighbor, majority weighted minority oversampling technique, and immune centroids oversampling technique. Moreover, this paper also reveals the evaluation of four rules-generation algorithms (the learning from example module, version 2 (LEM2), covering, exhaustive, and genetic algorithms) using publicly available data sets. The empirical results demonstrate that the overall predictive performance of MTDF and rules-generation based on genetic algorithms performed the best as compared with the rest of the evaluated oversampling methods and rule-generation algorithms."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we consider an orthogonal frequency division multiplexing communication system that adopts frame-by-frame transmission in high-speed railway (HSR) scenario. Due to the increase in demand for the QoS sensitive services, an efficient QoS-aware transmission strategy that improves the system performance is required urgently. Many efforts have been devoted to addressing this problem with the assumption of block fading channel in a frame duration. However, due to the frequent channel quality variation in a frame duration and serious inter channel interference in HSR scenario, the throughput of the QoS sensitive services degrades severely. Hence, a robust cross-layer transmission strategy that combines adaptive modulation (AM) scheme with truncated automatic repeat request protocol is proposed. In this cross-layer formulation, the normalized average throughput is optimized subject to the average power and the packet loss rate (PLR) requirements. First, we derive the closed form average bit error rate that represents the PLR requirement at the physical layer. Second, we obtain the solution of robust AM scheme and power allocation policy in the case of continuous rate. Third, we present the adaptive bits and power allocation scheme in the case of discrete rate, which can be implemented in practice. Finally, the performance of the proposed transmission strategy is evaluated by extensive simulations. Comparing with the constant transmit power AM scheme, the throughput increases by 20%, which demonstrates that the proposed robust cross-layer design is suitable for the HSR communication systems."
  },
  {
    "year": "2016",
    "abstract": "User-centric network (UCN), which organizes a dynamic transmission point group (TPG) for each user, is regarded as a promising candidate to meet the exponential growth of mobile data traffic for 5G system. However, the severe interference under dense TP deployment in UCN from co-channel neighbor cell worsens the user performance. In this paper, to combat the fluctuation of user rate, a user-centric power control strategy is proposed, where TPs will take power control coefficient β to effectively mitigate the strong interference for each user within TPG of radius coefficient μ. Based on the strategy, semi-closed expressions of network downlink performance metric are first derived, including coverage probability and average achievable rate to the typical user, and average spectral efficiency of TP with the consideration of the impact of TPG overlapping on the signal link. The TPs and the users are modeled as independent 2-D Poisson point processes. The theoretical analysis confirms that the optimization of β and μ, which determine the area and intensity for power control, respectively, can realize the tradeoff between interference mitigation and resource utilization. Numerical results demonstrate significant performance gains of the user-centric power control strategy in coverage probability, average achievable user rate, and TP spectral efficiency, which can be improved at most by 30%, 15%, and 42%, respectively. In addition, the analysis gives the optimal values of β and μ according to the distance between TP and user."
  },
  {
    "year": "2016",
    "abstract": "How to design an effective and efficient double closed-loop proportional-integral (PI) controller for a three-phase inverter to obtain satisfied quality of output voltage waveform is of great practical significance. This paper presents a novel double closed-loop PI controller design method for a three-phase inverter based on a binary-coded extremal optimization (BCEO) algorithm. The basic idea behind the proposed method is first formulating the optimal design problem of double closed-loop PI controller for a three-phase inverter as a typical constrained optimization problem, where the total harmonic distortion and the integral of time weighted absolute error of output voltage waveform are weighted as the optimization objective function, and then a BCEO algorithm is designed to solve this formulated problem. The superiority of the proposed method to Z-N empirical method, binary-coded genetic algorithm, binary-coded particle swarm optimization is demonstrated by both simulation and experimental results on a 20-kW three-phase inverter with nominal and variable loads."
  },
  {
    "year": "2016",
    "abstract": "As green communication becomes an inevitable trend for future 5G wireless networks, how to maximize the energy efficiency (EE) of device-to-device (D2D) communication has drawn extensive attention recently. However, most of existing works only optimize the EE in the single-cell scenario, while little attention is paid to maximizing the EE of the whole cellular network underlaid with D2D communication with randomly distributed users on multiple bands. In this paper, we first consider the whole cellular network underlaid with D2D communication on multiple bands and derive the exact expressions of the successful transmission probabilities, the average sum rate and the EE based on stochastic geometry theory. Then, we formulate the optimization problem of maximizing the EE subject to four constraints regarding to transmission power and outage probabilities, and the non-convexity of this problem is also verified. After that, by exploiting the objective function property of being the sum of several functions, we propose a derivative-based algorithm to solve this non-convex optimization problem. Our theoretical analysis shows that the computational complexity of the proposed algorithm is significantly lower than that of the conventional branch and bound algorithm. Finally, simulation results demonstrate that the proposed algorithm can achieve the near-optimal EE with much better performance than the conventional algorithm."
  },
  {
    "year": "2016",
    "abstract": "There is an upsurge in applying fuzzy ontologies to represent vague information in the knowledge representation field. Current research in the fuzzy ontologies paradigm mainly focuses on developing formalism languages to represent fuzzy ontologies, designing fuzzy ontology editors, and building fuzzy ontology applications in different domains. Less focus falls on establishing a formal methodological approach for building fuzzy ontologies. Existing fuzzy ontology development methodologies, such as the IKARUS-Onto methodology and fuzzy ontomethodology, provide formalized schedules for the conversion from crisp ontologies into fuzzy ones. However, a formal guidance on how to build fuzzy ontologies from scratch still lacks in this paper. Therefore, this paper presents the first methodology, named fuzzy ontology development methodology (FODM), for developing fuzzy ontologies from scratch. The proposed FODM can provide a very good guideline for formally constructing fuzzy ontologies in terms of completeness, comprehensiveness, generality, efficiency, and accuracy. To explain how the FODM works and demonstrate its usefulness, a fuzzy seabed characterization ontology is built based on the FODM and described step by step."
  },
  {
    "year": "2016",
    "abstract": "Massive multiple-input multiple-output is a promising physical layer technology for 5G wireless communications due to its capability of high spectrum and energy efficiency, high spatial resolution, and simple transceiver design. To embrace its potential gains, the acquisition of channel state information is crucial, which unfortunately faces a number of challenges, such as the uplink pilot contamination, the overhead of downlink training and feedback, and the computational complexity. In order to reduce the effective channel dimensions, researchers have been investigating the low-rank (sparse) properties of channel environments from different viewpoints. This paper then provides a general overview of the current low-rank channel estimation approaches, including their basic assumptions, key results, as well as pros and cons on addressing the aforementioned tricky challenges. Comparisons among all these methods are provided for better understanding and some future research prospects for these low-rank approaches are also forecasted."
  },
  {
    "year": "2016",
    "abstract": "Energy-efficiency is a significant parameter contributing to the performance of coordinated cognitive radio networks (CCRNs). To estimate the average value of sensing and reporting energy efficiency of CCRN, a new metric is proposed. This paper presents a new metric based on the gain from the coordination of missed detection and false alarm probabilities that minimize the interference on the primary users and maximize the throughput for cognitive terminals (CTs), respectively. Furthermore, the proposed maximum metric is placed by analytically figuring out the optimum number of coordinated CTs. The global average value of energy efficiency of sensing and reporting process among coordinated CTs with various probabilities of missed detection and false alarm is formulated. In addition, a new iterative CTs assignment strategy is proposed. Finally, the average energy-efficiency results are significantly enhanced as shown by simulations."
  },
  {
    "year": "2016",
    "abstract": "This paper presents our research on secure and accurate targeted mobile coupon delivery. Our goal is to enable the secure delivery of targeted coupons to eligible users equipped with mobile devices, whose behavioral profiles accurately satisfy the targeting profile defined by the vendor. Our design well preserves user privacy, and further provides the strict security guarantee of vendor protection, by verifying user’s eligibility for a coupon without revealing the vendor’s targeting profile. We first show a basic approach which can effectively address the challenges posed by secure and accurate targeted coupon delivery, via properly leveraging Yao’s garbled circuits. In order to achieve practical performance for resource-limited mobile devices, we then present our proposed design, which imposes lightweight workload on the user side, via properly bridging together homomorphic encryption and Yao’s garbled circuits. We implement a preliminary user-side prototype and deploy it on an Android smartphone to evaluate the performance. Extensive experimental results demonstrate that our proposed design achieves practical performance for mobile devices."
  },
  {
    "year": "2016",
    "abstract": "Vehicular ad hoc network (VANET) is a technology that enables smart vehicles to communicate with each other and form a mobile network. VANET facilitates users with improved traffic efficiency and safety. Authenticated communication becomes one of the prime requirements of VANET. However, authentication may reveal a user's personal information such as identity or location, and therefore, the privacy of an honest user must be protected. This paper proposes an efficient and practical pseudonymous authentication protocol with conditional privacy preservation. Our protocol proposes a hierarchy of pseudonyms based on the time period of their usage. We propose the idea of primary pseudonyms with relatively longer time periods that are used to communicate with semi-trusted authorities and secondary pseudonyms with a smaller life time that are used to communicate with other vehicles. Most of the current pseudonym-based approaches are based on certificate revocation list (CRL) that causes significant communication and storage overhead or group-based approaches that are computationally expensive and suffer from group-management issues. These schemes also suffer from trust issues related to certification authority. Our protocol only expects an honest-but-curious behavior from otherwise fully trusted authorities. Our proposed protocol protects a user's privacy until the user honestly follows the protocol. In case of a malicious activity, the true identity of the user is revealed to the appropriate authorities. Our protocol does not require maintaining a CRL and the inherent mechanism assures the receiver that the message and corresponding pseudonym are safe and authentic. We thoroughly examined our protocol to show its resilience against various attacks and provide computational as well as communicational overhead analysis to show its efficiency and robustness. Furthermore, we simulated our protocol in order to analyze the network performance and the results show the feasibility..."
  },
  {
    "year": "2016",
    "abstract": "Remote sensing classification for volcanic ash cloud is a difficult task in the remote sensing application, and how to accurately obtain the volcanic ash cloud information from remote sensing image has become a key step in remote sensing classification of volcanic ash cloud. Aiming at the characteristics of the remote sensing images, via introducing the neighborhood pixels based on the classical fuzzy C-means clustering algorithm, this paper proposed a new fuzzy clustering remote sensing classification method with neighborhood distance constraint for volcanic ash cloud. This paper is tested from simulation texture image and moderate resolution imaging spectroradiometer remote sensing image, and finally explored the Sangeang Api volcanic ash cloud case on May 30, 2014. Our experiments show that the proposed method can effectively classify the volcanic ash cloud from remote sensing images, and the overall classification accuracy and Kappa coefficient reach 88.4% and 0.8064. To some extent, it overcomes the deficiency of the approaches in traditional volcanic ash cloud remote sensing classification."
  },
  {
    "year": "2016",
    "abstract": "This paper evaluates the secure energy efficiency (SEE) of a cooperative network subject to partial secrecy requirements, implemented through a fractional equivocation parameter θ ∈ (0, 1] that allows partial secrecy when θ <; 1. We assume that only the channel state information (CSI) of the legitimate channel is available, while the CSI with respect to the eavesdropper is unknown. Then, we propose a CSI-aided decode-and-forward (DF) scheme, in which the transmitter uses the available CSI in order to choose between direct and cooperative paths. Moreover, the relay employs either repetition coding (CSI-RC), i.e., source and relay use the same codebook, or parallel coding (CSI-PC), when different codebooks are used. By resorting to the Dinkelbach algorithm, we propose a joint power allocation scheme, which also optimizes θ to maximize the SEE. Our schemes are compared with the traditional DF, amplify- and-forward, and cooperative jamming (CJ). In most scenarios, CSI-RC performs best in terms of SEE. Nevertheless, we observe that CSI-PC achieves the highest SEE when θ → 1 and if the relay is close to either the transmitter or the receiver. Moreover, CJ also stands out to maximize the SEE if the relay is placed closer to the eavesdropper. In addition, the influence of θ in the system performance is evaluated, showing that a joint θ and power optimization considerably improves the SEE."
  },
  {
    "year": "2016",
    "abstract": "In bistatic multiple input multiple output (MIMO) radar, more number of detectable incident signals and a higher angle estimation performance can be obtained by using conjugate estimation of signal parameters via rotational invariance techniques (ESPRITs) with the characteristic of noncircularity. The result is achieved under the assumption that all the received signals are noncircular. When the incident signals are the coexistence of noncircular and circular signals, the conjugate ESPRIT will not valuable. Therefore, this paper proposes a method of the joint of direction of departure (DOD) and direction of arrival (DOA) estimation, which is appropriate for the coexistence of noncircular and circular signals in bistatic MIMO radar. First, the received data model of the bistatic MIMO radar is given. Second, we modify the received signal model by the use of noncircularity characteristic. Third, we derive out the equation of spatially rotational invariant containing the DOD and DOA information. Last, we solve the equation to obtain the DOD and DOA by means of total least squares technology. The proposed algorithm has the three advantages. One is that it has better angle estimation accuracy than that of method which does not use the noncircularity characteristic. Another one is that it has more number of detectable incident signals. The last one is that the more number of noncircular signals, the higher angle estimation accuracy will be. Results from numerical experiments are used to show the effectiveness of our proposed algorithm."
  },
  {
    "year": "2016",
    "abstract": "Complex event processing (CEP) is a technology that allows us to process and correlate large volumes of data by using event patterns, aiming at promptly detecting specific situations that could require special treatment. The event types and event patterns for a particular application domain are implemented by using an event processing language (EPL). Although some current model-driven tools allow end users to easily define these patterns, which are then transformed automatically into a particular EPL, the generated code is syntactically but not semantically validated. To deal with this problem, a prioritized colored Petri net (PCPN) model for CEP is proposed and conducted in this paper. This well-known graphical formalism together with CPNTools makes possible the modeling, simulation, analysis, and semantic validation of complex event-based systems. To illustrate this approach, a case study is presented, as well as a discussion on the benefits from using PCPN for modeling CEP-based systems."
  },
  {
    "year": "2016",
    "abstract": "As the living standards improve and the health consciousness enhances, the healthcare industry has become a hot spot in nowadays society and some health monitoring systems emerge one after another in recent years. However, the mostly existing systems only focus on the logic reasoning but ignore the factor of the user's emotion, which is regarded as an important factor to impact human health. In this paper, we design a system for big data application in emotion-aware healthcare (BDAEH), which pays attention to both the logic reasoning and the emotion computing. Meanwhile, the SDN the and 5G technologies are adopted in the BDAHE system to improve the resource utilization and the overall network performance of the system. The BDAEH system includes the following functions: healthcare data collection, healthcare data transmission, healthcare data storage, healthcare data analysis, and human-machine interaction. The healthcare data are generated by wearable devices or sensing-less sensors, and these healthcare data are regarded as the foundation to expand a series of data processing. The healthcare data transmission is performed through leveraging the SDN and the 5G technologies. In the data center, the related technologies based on cloud computing are utilized to store and analyze healthcare data, which obtains both the emotion and the health state of the users, and the relation between the emotion and the illness. Finally, the BDAEH system returns the analysis result to the users or the doctors for further treatment schemes or rehabilitation advice. The presented system is expected to validly improve the healthcare services by considering the emotion factor."
  },
  {
    "year": "2016",
    "abstract": "In cloud computing, data owners host their data on cloud servers, and users (data consumers) can access the data from the cloud servers. This new paradigm of data hosting service also introduces new security challenges that require an independent auditing service to check the integrity of the data in the cloud. Some existing methods for checking the integrity of the data cannot handle this problem efficiently and they cannot deal with the error condition. Thus, a secure and efficient dynamic auditing protocol should reject requests that are made with improper authentication. In addition, an excellent remote data authentication method should be able to collect information for statistical analysis, such as validation results. In this paper, first we design an auditing framework for cloud storage systems and propose an efficient and privacy-preserving auditing protocol. Then, we extend our auditing protocol to support dynamic data operations, which is efficient and has been proven to be secure in the random oracle model. We extended our auditing protocol further to support bidirectional authentication and statistical analysis. In addition, we use a better load distribution strategy, which greatly reduces the computational overhead of the client. Last, we provide an error response scheme, and our experiments show that our solution has good error-handling ability and offers lower overhead expenses for computation and communication than other approaches."
  },
  {
    "year": "2016",
    "abstract": "The aerospace-based communications can be managed more efficiently through the construction of an integrated space/air information network by the convergence of satellite (space) and unmanned aerial vehicle (air) networks. Such an integrated network would best fit the advent of delay- and disruption-tolerant networking, in which the data transmission can tolerate long delay and disruption under a store-carry-forward mechanism. Such a network, however, has some challenging research needs due to the network's high mobility of nodes and time-varying topology that may result in high error bit rate and long delay. In this paper, we propose a unified routing framework for this integrated network, where a Hybrid time-space Graph supporting Hierarchical Routing (HGHR) algorithm is achieved. More specifically, the HGHR performs on a hybrid time-space graph, including two subgraphs: a deterministic graph for the space network and a semi-deterministic one for the air network. This latter graph is based on a discrete time homogeneous semi-Markov prediction model. The hybrid time-space graph is then transformed into a state-space graph, based on which, a message forwarding rule under the store-carry-forward mechanism is adopted. Simulation results show that the proposed HGHR algorithm has good performance in terms of message delivery ratio, end-to-end delay, and power consumption."
  },
  {
    "year": "2016",
    "abstract": "Diffraction-based overlay (DBO) accuracy is critical to the intelligent nanolithography process control for producing advanced semiconductor fabrication nodes. Optical gratings located on various layers are commonly used as the targets for the detection of the overlay displacement offset in DBO measurement. The asymmetry in intensity between the 1st and -1st beams diffracted by the targets is used for the prediction of grating displacement offset. This paper describes the effect of grating targets with sidewall angles (SWAs) on asymmetry in intensity and proposes an artificial neural network (ANN) method for enhancing the accuracy of grating displacement offset prediction. Grating targets with a 1:3 line-to-pitch ratio and SWA profiles varying from 86° to 90° were employed in this paper. The asymmetry in the intensity of the designed targets was computed for incident beams with transverse-electric and transverse-magnetic polarization at visible wavelength. An ANN feed-forward model was developed for the displacement offset prediction. The ANN, the conventional linear model, and the regression models were evaluated using diffraction data calculated by a numerical electromagnetic solver. The mean square error and the mean of the residual indicated that using the ANN model and incident beams at wavelengths of 600, 650, and 750 nm is substantially more effective for prediction than the conventional linear model is."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the efficiency of Gini's mean difference (GMD) as a measure of variability in two commonly used process capability indices (PCIs), i.e., Cp and Cpk. A comparison has been carried out to evaluate the performance of GMD-based PCIs and Pearn and Chen quantile-based PCIs under low, moderate, and high asymmetry using Weibull distribution. The simulation results, under low and moderate asymmetric condition, indicate that GMD-based PCIs are more close to target values than quantile approach. Beside point estimation, nonparametric bootstrap confidence intervals, such as standard, percentile, and bias corrected percentile with their coverage probabilities also have been calculated. Using quantile approach, bias corrected percentile (BCPB) method is more effective for both Cp and Cpk, where as in case of GMD, both BCPB and percentile bootstrap method can be used to estimate the confidence interval of Cp and Cpk, respectively."
  },
  {
    "year": "2016",
    "abstract": "Wireless sensor networks (WSNs) can utilize the unlicensed industrial, scientific, and medical (ISM) band to communicate the sensed data. The ISM band has been already saturated due to the overlaid deployment of WSNs. To solve this problem, WSNs have been powered up by cognitive radio (CR) capability. By using CR capability, WSNs can utilize the spectrum holes opportunistically. The sensor nodes, which need large bandwidth to transmit their sensed data from source to destination require some scheme, which should be able to provide them a wide band channel whenever required. Channel bonding (CB) is a technique through which multiple contiguous channels can be combined to form a single wide band channel. By using CB technique, CR-based WSN nodes attempt to find and combine contiguous channels to avail larger bandwidth. In this paper, we show that by increasing the number of channels, the probability of finding contiguous channels decreases. Moreover, we then propose a primary-radio (PR) user-activity-aware CB algorithm and compare it with three state-of-the-art schemes: SWA, KNOWS, and AGILE. It has been demonstrated through extensive NS-2 simulations that intelligent CB decisions can reduce harmful interference to PR nodes. We find that CB in CR sensor networks attempts to provide greater bandwidth and utilizes the spectrum effectively."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a condition-based monitoring methodology based on novelty detection applied to industrial machinery. The proposed approach includes both the classical classification of multiple a priori known scenarios, and the innovative detection capability of new operating modes not previously available. The development of condition-based monitoring methodologies considering the isolation capabilities of unexpected scenarios represents, nowadays, a trending topic able to answer the demanding requirements of the future industrial processes monitoring systems. First, the method is based on the temporal segmentation of the available physical magnitudes, and the estimation of a set of time-based statistical features. Then, a double feature reduction stage based on principal component analysis and linear discriminant analysis is applied in order to optimize the classification and novelty detection performances. The posterior combination of a feed-forward neural network and one-class support vector machine allows the proper interpretation of known and unknown operating conditions. The effectiveness of this novel condition monitoring scheme has been verified by experimental results obtained from an automotive industry machine."
  },
  {
    "year": "2016",
    "abstract": "The most important linear precoding method for frequency-flat MIMO broadcast channels is block diagonalization (BD) which, under certain conditions, attains the same nonlinear dirty paper coding channel capacity. However, BD is not easily translated to frequency-selective channels, since space-time information must be included in the transceiver design. In this paper, we demonstrate that BD is possible in frequency-selective MIMO broadcast channels to eliminate inter-user interference and derive the conditions on the number of transmit antennas and the transmission block length (as functions of the number of users and channel delay spread) for the existence of BD precoders. We also propose three different approaches to mitigate/eliminate inter-symbol interference in block transmissions: time-reversal-based BD (TRBD), equalized BD (EBD), and joint processing BD (JPBD). We show that any transmit-processing-only method (including TRBD and EBD) yields zero diversity and multiplexing gains (high SNR regime). We also demonstrate that JPBD, which uses linear processing at the transmitter and the receiver, approximates full multiplexing gain for a sufficiently large transmit block length, and show its diversity-multiplexing tradeoff. Extensive numerical simulations show that the achievable rate and probability of error performance of all the proposed techniques remarkably improve that of conventional time-reversal beamforming. Moreover, JPBD provides the highest achievable rate region for frequency-selective MIMO broadcast channels."
  },
  {
    "year": "2016",
    "abstract": "A novel adaptive radial basis function neural network H-infinity control strategy with robust feedback compensator using linear matrix inequality (LMI) approach is proposed for micro electro mechanical systems vibratory gyroscopes involving parametric uncertainties and external disturbances. The proposed system is comprised of a neural network controller, which is designed to mimic an equivalent control law aimed at relaxing the requirement of exact mathematical model and a robust feedback controller, which is derived to eliminate the effect of modeling error and external disturbances. Based on the Lyapunov stability theorem, it is shown that H-infinity tracking performance of the gyroscope system can be achieved, all variables of the closed-loop system are bounded, and the effect due to external disturbances on the tracking error can be attenuated effectively. Numerical simulations are investigated to demonstrate that the satisfactory tracking performance and strong robustness against external disturbances can be obtained using the proposed adaptive neural H-infinity control strategy with robust feedback compensator by LMI technique."
  },
  {
    "year": "2016",
    "abstract": "Magnetically manipulated untethered robot, such as an active wireless capsule endoscope, has shown great potential for controlled inspection inside the gastrointestinal tract. To enable the effective manipulation of the robot, real-time pose (position and orientation) information of the robot must be obtained as an important sensory feedback. Usually, a magnetic tracking method is used to provide the pose information. Due to the magnetic disturbance, a traditional magnetic tracking method cannot work simultaneously with the magnetic manipulation system. In this paper, a simultaneously tracking and navigation method is proposed to realize a closed-loop control of the magnetically manipulated untethered robot. The main approach is to conduct a multi-object tracking of the involved magnetic objects. With the proposed method, real-time pose information can be estimated during the manipulation, and both the tracking and manipulation are carried out by a magnetic manner. Therefore, the mobile navigation of the magnetically manipulated untethered robot can be achieved by using a pre-defined map. Experimental results verified the proposed method, and a mean position error of 1.2 mm for the passive magnet has been obtained."
  },
  {
    "year": "2016",
    "abstract": "The mobile data traffic has risen exponentially in recent days due to the emergence of data intensive applications, such as online gaming and video sharing. It is driving the telecommunication industry as well as the research community to come up with new paradigms that will support such high data rate requirements within the existing wireless access network, in an efficient and effective manner. To respond to this challenge, device-to-device (D2D) communication in cellular networks is viewed as a promising solution, which is expected to operate, either within the coverage area of the existing eNB and under the same cellular spectrum (in-band) or separate spectrum (out-band). D2D provides the opportunity for users located in close proximity of each other to communicate directly, without traversing data traffic through the eNB. It results in several transmission gains, such as improved throughput, energy gain, hop gain, and reuse gain. However, integration of D2D communication in cellular systems at the same time introduces new technical challenges that need to be addressed. Containment of the interference among D2D nodes and cellular users is one of the major problems. D2D transmission radiates in all directions, generating undesirable interference to primary cellular users and other D2D users sharing the same radio resources resulting in severe performance degradation. Efficient interference mitigation schemes are a principal requirement in order to optimize the system performance. This paper presents a comprehensive review of the existing interference mitigation schemes present in the open literature. Based on the subjective and objective analysis of the work available to date, it is also envisaged that adopting a multi-antenna beamforming mechanism with power control, such that the transmit power is maximized toward the direction of the intended D2D receiver node and limited in all other directions will minimize the interference in the network. This could maximiz..."
  },
  {
    "year": "2016",
    "abstract": "Today, direct contacts between users are being facilitated by the network-assisted device-to-device (D2D) technology, which employs the omnipresent cellular infrastructure for the purposes of control to facilitate advanced mobile social applications. Together with its undisputed benefits, this novel type of connectivity creates new challenges in constructing meaningful proximity-based services with high levels of user adoption. They call for a comprehensive investigation of user sociality and trust factors jointly with the appropriate technology enablers for secure and trusted D2D communications, especially in the situations where cellular control is not available or reliable at all times. In this paper, we study the crucial aspects of social trust associations over proximity-based direct communications technology, with a primary focus on developing a comprehensive proof-of-concept implementation. Our recently developed prototype delivers rich functionality for dynamic management of security functions in proximate devices, whenever a new device joins a secure group of users or an existing one leaves it. To characterize the behavior of our implemented demonstrator, we evaluate its practical performance in terms of computation and transmission delays from the user perspective. In addition, we outline a research roadmap leveraging our technology-related findings to construct a holistic user perspective behind dynamic, social-aware, and trusted D2D applications and services."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we propose a virtual spatial modulation (VSM) scheme that performs index modulation on the virtual parallel channels resulting from the singular value decomposition of the multi-input-multi-output channels. The VSM scheme conveys information through both the indices of the virtual parallel channels and theM-ary modulated symbols. We derive a closed-form upper bound on the average bit error probability (ABEP), which considers the impact of imperfect channel estimation. Moreover, the asymptotic ABEP is also studied, which characterizes the error floor under imperfect channel estimation and the resulting diversity order as well as the coding gain under perfect channel estimation. Computer simulations verify the analysis and show that the VSM scheme can outperform the existing pre-coding aided spatial modulation schemes under the same spectral efficiency."
  },
  {
    "year": "2016",
    "abstract": "Energy consumed by network constitutes a significant portion of the total power budget in modern data centers. Thus, it is critical to understand the energy consumption and improve the power efficiency of data center networks (DCNs). In doing so, one straightforward and effective way is to make the size of DCNs elastic along with traffic demands, i.e., turning off unnecessary network components to reduce the energy consumption. Today, software defined networking (SDN), as one of the most promising solutions for data center management, provides a paradigm to elastically control the resources of DCNs. However, to the best of our knowledge, the features of SDN have not been fully leveraged to improve the power saving, especially for large-scale multi-controller DCNs. To address this problem, we proposeE3MC, a mechanism to improve DCN’s energy efficiency via the elastic multi-controller SDN. InE3MC, the energy optimizations for both forwarding and control plane are considered by utilizing SDN’s fine-grained routing and dynamic control mapping. In particular, the flow network theory and the bin-packing heuristic are used to deal with the forwarding plane and control plane, respectively. Our simulation results show thatE3MC can achieve more efficient power management, especially in highly structured topologies such as Fat-Tree and BCube, by saving up to 50% of network energy, at an acceptable level of computation cost."
  },
  {
    "year": "2016",
    "abstract": "In this paper, throughput improvement of device-to-device (D2D)-aided underlaying cellular networks is analyzed. The D2D devices are assumed to be capable of operating at the full duplex (FD) mode to enable the concurrent transmission and reception with a single frequency band. We analyze the impact of activating D2D users on the throughput of FD-based D2D (FD-D2D) aided underlaying network by considering non-ideal self-interference cancellation at the FD devices. Despite of an extra interference imposed on the cellular users (CUs) by the active D2D links, which may erode the signal-to-interference ratio of the former significantly, the FD-D2D mode is still shown to exhibit its superiority in terms of the throughput improvement. Furthermore, in order to avoid a severe FD-D2D-induced interference imposed on the CUs, a new mechanism called “dynamic cellular link protection (DCLP),” which prohibits the transmissions of FD-D2D users when they are located inside the pre-set guard areas, is proposed. Numerical results show that the proposed DCLP mechanism is capable of substantially improving the throughput of the underlaying cellular networks without seriously eroding the capacity of the conventional cellular links."
  },
  {
    "year": "2016",
    "abstract": "The device-to-device (D2D) channels allow content sharing when two devices are in close proximity, which can help improve resource utilization and network capacity. The data caching is introduced in D2D networks to enable the quick data access in mobile networks. Due to the selfish nature of users, they wish to get as much replication as possible in the opportunistic connections, seeking to maximize their own profits. However, caching data for other nodes may result in additional cost to the node serving as cache, where the cost is invoked by the cache placement of cache nodes and accessing cost of other nodes. In this paper, we propose a social-aware caching game to incentivize nodes to cache data for others. In the game, we consider the social ties and physical distance as the factors to formulate the caching cost. We obtain the Nash equilibrium of the game and propose a social-aware algorithm to minimize the total cost of getting object data in the network. The extensive simulation results show that our algorithm gains significant cache benefit."
  },
  {
    "year": "2016",
    "abstract": "A multiplication-based pulse integration method is proposed for sonar to detect underwater dim target under impulsive noise condition. The method multiplies the received signals in various returns from the target instead of summing them up. The random occurrence of the impulse interference and the nature that a small number near zero multiplies a big number equals to a small number can make huge difference between useful target echo and unwanted impulsive noise. By utilizing the Keystone transform, moving targets can also be detected by the proposed method. Computer simulations and real data analysis show that the proposed scheme is more resistant to impulsive noise, as compared with the conventional addition-based pulse integration scheme. The benefits of this scheme include the improved performance of detection under complex impulsive noise environment, implementation simplicity and flexibility, which indicates the effectiveness and robustness of the method."
  },
  {
    "year": "2016",
    "abstract": "Cyber-physical systems (CPS) are a collection of transformative technologies for managing interconnected physical and computational capabilities. Recent developments in technology are increasing the availability and affordability of sensors, data acquisition systems, and computer networks. The competitive nature of industry requires manufacturers to implement new methodologies. CPS is a broad area of engineering which supports applications across industries, such as manufacturing, healthcare, electric power grids, agriculture, and transportation. In particular, CPS is the core technology enabling the transition from Industry 3.0 to Industry 4.0 (I 4.0) and is transforming global advanced manufacturing. This paper provides a consolidated review of the latest CPS literature, a complete review of international standards, and a complete analysis of patent portfolios related to the 5C's CPS architecture model by Lee et al. The critical evaluation of international standards and the intellectual property contained in CPS patents is unaddressed by the previous research and will benefit both academic scholars and industry practitioners. The analysis provides a basis for predicting research and development future trends and helps policy makers manage technology changes that will result from CPS in I 4.0. This paper covers the emerging I 4.0 standards from the International Organization for Standardization, the International Electrotechnical Commission, and China's Guobiao standards followed by a patent analysis covering global patents issued in the U.S., Europe, China, and the World Intellectual Property Organization."
  },
  {
    "year": "2016",
    "abstract": "Systems based on wireless gas sensor networks offer a powerful tool to observe and analyze data in complex environments over long monitoring periods. Since the reliability of sensors is very important in those systems, gas classification is a critical process within the gas safety precautions. A gas classification system has to react fast in order to take essential actions in the case of fault detection. This paper proposes a low latency real-time gas classification service system, which uses a multi-layer perceptron (MLP) artificial neural network to detect and classify the gas sensor data. An accurate MLP is developed to work with the data set obtained from an array of tin oxide (SnO2) gas sensor, based on convex micro hotplates. The overall system acquires the gas sensor data through radio-frequency identification (RFID), and processes the sensor data with the proposed MLP classifier implemented on a system on chip (SoC) platform from Xilinx. Hardware implementation of the classifier is optimized to achieve very low latency for real-time application. The proposed architecture has been implemented on a ZYNQ SoC using fixed-point format and the achieved results have shown that an accuracy of 97.4% has been obtained."
  },
  {
    "year": "2016",
    "abstract": "Due to its attractive characteristics, the TV white space (TVWS) spectrum is considered the ideal candidate to enable the deployment of smart grid networks (SGNs) via cognitive radio paradigm. However, the intermittent availability of the TVWS spectrum as well as its scarcity in urban scenarios could compromise the tight smart grid requirements in terms of reliability, latency, and data rate. This degradation could be even more severe when mobile grid nodes, e.g., electric vehicles, are considered. Stemming from this, we first develop an analytical framework to account for the mobility in SG scenarios. Then, we design a switching procedure based on the use of two different bands: TVWS spectrum and Industrial, Scientific and Medical (ISM) spectrum. The switching procedure selects, among the available spectrum bands, the one maximizing the achievable throughput at an arbitrary SGN. Such a procedure accounts for the presence of interfering SGNs on the TVWS spectrum through both their traffic and mobility patterns. By wisely using both the ISM and the TVWS spectrum, the proposed switching procedure is able to: 1) increase the achievable data rate, and to 2) reduce the outage event rate, improving the reliability and the latency of the smart grid communications. Moreover, we show the performance of the proposed switching procedure depends largely on the time devoted to sense. Hence, the proper setting of such a parameter is critical for the performance of any SGN. For this, we derive an optimization criterion maximizing the throughput under the constraint of bounding the outage rate. The theoretical analysis is validated through extensive numerical simulations."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a novel joint continuous power and rate adaptation scheme is proposed fordoubly selective fading channels in orthogonal frequency division multiplexing (OFDM) systems, based on terminal velocity and perfect or imperfect channel state information (CSI). The analysis and simulation results show that the continuous power and rate adaptation scheme is very effective and improve the performance of OFDM systems substantially under time-varying fading channels, as compared with the traditional adaptation schemes operating without a priori knowledge of velocity and mobility adaptation without CSI."
  },
  {
    "year": "2016",
    "abstract": "An iterative turbo decoder-based cross layer error recovery scheme for compressed video is presented in this paper. The soft information exchanged between two convolutional decoders is reinforced both by channel coded parity and video compression syntactical information. An algorithm to identify the video frame boundaries in corrupted compressed sequences is formulated. This paper continues to propose algorithms to deduce the correct values for selected fields in the compressed stream. Modifying the turbo extrinsic information using these corrections acts as reinforcements in the turbo decoding iterative process. The optimal number of turbo iterations suitable for the proposed system model is derived using EXIT charts. Simulation results reveal that a transmission power saving of 2.28% can be achieved using the proposed methodology. Contrary to typical joint cross layer decoding schemes, the additional resource requirement is minimal, since the proposed decoding cycle does not involve the decompression function."
  },
  {
    "year": "2016",
    "abstract": "Patients in hospitals, particularly in critical care, are susceptible to many complications affecting morbidity and mortality. Digitized clinical data in electronic medical records can be effectively used to develop machine learning models to identify patients at risk of complications early and provide prioritized care to prevent complications. However, clinical data from heterogeneous sources within hospitals pose significant modeling challenges. In particular, unstructured clinical notes are a valuable source of information containing regular assessments of the patient's condition but contain inconsistent abbreviations and lack the structure of formal documents. Our contributions in this paper are twofold. First, we present a new preprocessing technique for extracting features from informal clinical notes that can be used in a classification model to identify patients at risk of developing complications. Second, we explore the use of collective matrix factorization, a multi-view learning technique, to model heterogeneous clinical data-text-based features in combination with other measurements, such as clinical investigations, comorbidites, and demographic data. We present a detailed case study on postoperative respiratory failure using more than 700 patient records from the MIMIC II database. Our experiments demonstrate the efficacy of our preprocessing technique in extracting discriminatory features from clinical notes as well as the benefits of multi-view learning to combine clinical measurements with text data for predicting complications."
  },
  {
    "year": "2016",
    "abstract": "This paper is concerned with the design and experimental assessment of, both, feedback linearization and sliding mode control techniques to the tracking trajectory problem of a flexible-joint robotic arm for a smooth rest to rest maneuver. The robust improvement of these controllers is analyzed by means of additional integral compensation, in which an alternative sliding surface was proposed for the control of the flexible arm. A feedback linearization of the nonlinear dynamic equation of the robot arm is computed in order to get a full-state non-linear feedback control law. On the other hand, it is proposed a second order sliding mode control with an integral term in the sliding surface, which improves the robustness of the controller sliding surface. Some experimental evaluations that include the addition of external unmodeled perturbations to test the enhancement of the robustness property show the improvements and effectiveness of the proposed control laws in disturbance rejection tasks. The controllers were implemented using exclusively position measurements and time derivatives approximations."
  },
  {
    "year": "2016",
    "abstract": "Energy consumption has become a crucial issue due to the large-scale deployment of small base stations (SBSs) in dense small cell networks (DSCNs). In this paper, a joint optimization problem involving sleep mode in subframes and power allocation to minimize the DSCN energy consumption while guaranteeing users' rate requirements is formulated as a mixed integer nonlinear programming. To address this problem, we propose a cooperative sleep and power allocation approach by decomposing it into two subproblems. First, we derive the optimum number of active subframes for each SBS and present a centralized heuristic coalition formation algorithm to manage SBSs to form coalitions. In such a case, SBSs can transmit data in active subframes and sleep in others. We then obtain the SBSs' optimum transmit power in the active subframes relying on a distributed price-based power allocation algorithm. System-level simulation results show that our proposed cooperative scheme can yield significant performance gains in terms of energy saving compared with the maximum power allocation and the non-cooperative power allocation (NCPA) approaches. In addition, the effects of target rates on coalition size and energy consumption are also analyzed."
  },
  {
    "year": "2016",
    "abstract": "Relational fuzzy clustering (RFC) algorithms prove very useful in Web user session clustering because Web user sessions may contain fuzzy, conflicting and imprecise information. Though RFC algorithms are very sensitive to cluster initialization and works only if the numbers of clusters are specified in advance. However, at all times, the prior initialization of a number of clusters is not feasible due to the dynamically evolving nature of user sessions. Therefore, estimating the number of clusters and initializing suitable cluster prototype are a significant performance bottleneck in this method. In this paper, the discounted fuzzy relational clustering (DFRC) algorithm is proposed to address the major constraint of RFC. The DFRC algorithm identifies Web user session clusters from Web server access logs, without initializing the number of clusters and prototypes of initial clusters. The DFRC algorithm works in two stages. In the first stage, DFRC automatically identifies the number of potential clusters based on the successively discounted potential density function value of each relational data and their respective centres. In the second stage, DFRC assigns fuzzy membership values to each data point and forms fuzzy clusters from the relational matrix. The DFRC algorithm is applied on an augmented session dissimilarity matrix obtained from a publicly accessed NASA Web server log data. The experimental results are evaluated using different fuzzy validity measures. The extensive experiments are performed to test the effect of various parameters, including accept/reject ratio and neighbourhood radius on the performance of DFRC algorithm. The results were also compared with fuzzy relational clustering algorithm using cluster quality measures. It is observed that the quality of generated clusters using DFRC is superior as compared with that of RFC."
  },
  {
    "year": "2016",
    "abstract": "An area of intensive research under the umbrella of the Internet of Things (IoT) has resulted in intensive proliferation of globally deployed sensor devices that provide a basis for the development of different use-case applications working with real-time data and demanding a rich user interface. Overcoming the lack of the standard HTML platform, HTML5 specifications WebSocket and Canvas graphics strongly supported the development of rich real-time applications. Such support has been offered by browser plug-ins such as Adobe Flash and Microsoft Silverlight for years. In order to provide a deep insight into IoT Web application performance, we implemented two test applications. In the first application, we measured latencies induced by different communication protocols and message encodings, as well as graphics rendering performance, while comparing the performance of different Web platform implementations. In the second application, we compared Web performance of IoT messaging protocols such as MQTT, AMQP, XMPP, and DDS by measuring the latency of sensor data message delivery and the message throughput rate. Our tests have shown that although Adobe Flash has the best performance at the moment, HTML5 platform is also very capable of running real-time IoT Web applications, whereas Microsoft Silverlight is noticeably behind both platforms. On the other hand, MQTT is the most appropriate messaging protocol for a wide set of IoT Web applications. However, IoT application developers should be aware of certain MQTT message broker implementation shortcomings that could prevent the usage of this protocol."
  },
  {
    "year": "2016",
    "abstract": "In order to satisfy the various requirements of future network services, 5G wireless network is proposed and becoming a hot topic in academic and industrial field. Location-based services are widely used with the development of wireless communication and mobile Internet technology. A number of popular spatial-temporal cloaking technologies have been proposed, and the number of users in an anonymizing spatial region (ASR) is uncontrollable. This paper, based on the semi-trusted server architecture proposes a location cloaking algorithm (LCA) based on combinatorial optimization. First, the semi-trusted server architecture divides the information of mobile users into three parts, so adversaries are unable to obtain the location and identity at the same time, then utilize the spatial k -anonymity algorithm LCA to hide the real locations of user, which controls the number of real users to around k in the anonymous result sets (Aset), so that both the number of users in ASR and the area of ASR are minimized, thereby improving query precision and decreasing the resources consumption. Finally, complete further improvement that the location is distinguishable in ASR and the query contents are diverse in Aset. Simulations show that the LCA performs well on cloaking success rate, query precision, and resources saving."
  },
  {
    "year": "2016",
    "abstract": "A four-element linear dielectric resonator antenna array for beamforming applications with mutual coupling compensation is proposed for long term evolution band 40 (2.3 GHz). The effect of mutual coupling on the array beamforming pattern has been studied for the inter-element spacing of0.32λ(wavelength), when the main beam is scanned in targeted directions with nulls placed toward unintended directions. Two mutual compensation methods, such as open-circuit voltage method and linear pattern correction method, are applied to compute mutual coupling matrices, which have been used to compute the compensated (coupling free) array elements weights to give the desired beamforming patterns. By applying the compensated complex feed coefficients, the various corrected beamforming patterns have been presented. It has been shown that the array element complex weights computed using the linear pattern correction method is more effective in compensating the effects of mutual coupling than open-circuit voltage method."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we investigate a wireless-powered dual-hop relaying multiple-input multiple-output system, which consists of a multi-antenna source (S) node, a multi-antenna destination (D) node, andN(N>1)single-antenna wireless-powered relaying nodes. At each relay, a power splitting receiver is applied to process the received signal for information decoding and energy harvesting simultaneously, and a decode-and-forward scheme is adopted to forward the processed information. Furthermore, the energy harvester at each relay is assumed to be non-linear with a saturation threshold to limit the power level of the energy. Assuming imperfect channel state information is available both at S and D, outage performance is investigated when S adopts transmit antenna selection in the presence of feedback delay and D performs maximal ratio combining technique to deal with the multiple copies of signals with channel estimation errors. Taking into account aKth best relay selection criterion, which results in theKth best performance in terms of outage probability for the source-relay-destination link, an analytical expression for OP is derived. Monte Carlo simulation results are presented to verify the accuracy of the derived analytical model."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we investigate the feasibility of recognizing human hand gestures using micro-Doppler signatures measured by Doppler radar with a deep convolutional neural network (DCNN). Hand gesture recognition using radar can be applied to control electronic appliances. Compared with an optical recognition system, radar can work regardless of light conditions and it can be embedded in a case. We classify ten different hand gestures, with only micro-Doppler signatures on spectrograms without range information. The ten gestures, which included swiping from left to right, swiping from right to left, rotating clockwise, rotating counterclockwise, pushing, double pushing, holding, and double holding, were measured using Doppler radar and their spectrograms investigated. A DCNN was employed to classify the spectrograms, with 90% of the data utilized for training and the remaining 10% for validation. After five-fold validation, the classification accuracy of the proposed method was found to be 85.6%. With seven gestures, the accuracy increased to 93.1%."
  },
  {
    "year": "2016",
    "abstract": "The objective of this paper is to improve the overall performance of distributed encoding, with a particular focus on encoding speed. The proposed scheme consists of content-aware video segmentation and scheduling that consists of two major parts. In the first part, segmentation is carried out with greater efficiency by considering changes in the video content, and in the second part, the segment assignment process is carried out using an efficient scheduling scheme that changes the encoding order of the segments. We measured the content similarity by using the sum of absolute difference algorithm and then applied a threshold to define the degree of change in similarity. The video was segmented based on the extent to which the similarity had changed, and the encoding order of the segments was rearranged to perform distributed encoding. Finally, this paper introduces the MapReduce-based distributed video encoding, using the content-aware video segmentation and scheduling described above, and presents the results of the performance using this scheme, which indicate that the proposed scheme increases the bitrate by a maximum of 2.9% over existing segmentation schemes, and also increases the speed by a maximum of 15.3%."
  },
  {
    "year": "2016",
    "abstract": "Plug-in hybrid electric vehicles (PHEVs) have emerged as an important tool in reducing greenhouse gas emissions, due to their lower dependency on fossil fuel. Since, for cost efficiency, PHEVs have a limited battery capacity, they must be recharged often and especially after trips. Thus, efficient battery charging plays an important role on the success of PHEVs commercial adoption. This paper surveys the state-of-the-art of existing PHEV battery charging schemes. We classify these schemes into four classes, namely, uncontrolled, indirectly controlled, smart, and bidirectional charging, and review various existing techniques within each class. For uncontrolled charging, existing studies focus on evaluating the impact of adding variable charging load on the smart grid. Various indirectly controlled charging schemes have been proposed to control energy prices, in order to indirectly influence the charging operations. Smart charging schemes can directly control a rich set of charging parameters to achieve various performance objectives, such as minimizing power loss, maximizing operator's profit, ensuring fairness, and so on. Finally, bidirectional charging allows a PHEV to discharge energy into smart grid, such that the vehicle can act as a mobile energy source to further stabilize the grid, which is partially supplied by intermittent renewable energy sources. This survey provides a comprehensive one-stop introductory reference to quickly learn about the key features and technical challenges, addressed by existing PHEV battery charging schemes in smart grid."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the detection and tracing problems in a multi-relay network, where a source wants to exchange the information with a destination through multiple potential malicious relay nodes. We find that the destination could probabilistically detect the maliciousness in a multi-relay network if and only if the network satisfies a non-manipulable condition. Notice that the non-manipulable condition of the whole network is complicated to be checked. We divide the whole network into several sub-networks, and check the non-manipulability of the small-scale sub-networks in turn, which finally constitutes to a simplified checking method of the non-manipulable condition for the whole relay network. Furthermore, we propose a tracing algorithm to pinpoint the malicious relays individually in a multi-relay network if a tracing condition is satisfied. No pre-shared secret is needed in our proposed detecting and tracing schemes. Numerical examples are presented to validate the effectiveness of the proposed schemes."
  },
  {
    "year": "2016",
    "abstract": "Preventing foreign fibers from being mixed with cotton is essential for producing high-quality cotton textile products. It remains a challenging task to accurately distinguish foreign fibers from cotton. This paper proposes an efficient recognition system to accurately recognize foreign fibers mixed in cotton. The core component of the proposed system is an efficient classifier based on the kernel extreme learning machine (KELM). A two-step grid search strategy, which integrates a coarse search with a fine search, is adopted to train an optimal KELM recognition model. The resultant model is compared with the support vector machine and extreme learning machine on a real data set using tenfold cross-validation analysis. The experimental results show that the proposed recognition system can achieve classification accuracy as high as 93.57%, which is superior to the other two state-of-the-art systems. The results clearly confirm the superiority of the developed model in terms of classification accuracy. Promisingly, the proposed system can serve as a new candidate of powerful foreign fiber recognition systems with excellent performance."
  },
  {
    "year": "2016",
    "abstract": "In orthogonal frequency division multiplexing relying on subcarrier index modulation (OFDM-SIM), the information is conveyed by both the indices of the activated subcarriers and the conventional amplitude-phase modulated (APM) symbols. It has been shown that OFDM-SIM is capable of striking a tradeoff between the attainable spectral efficiency (SE) and energy efficiency (EE). In order to further increase the EE of the OFDM-SIM system, while potentially increasing its SE, we propose a compressed sensing (CS)-assisted signaling strategy for the family of OFDM-SIM systems. Correspondingly, we first consider the joint maximum likelihood detection of the CS-assisted index-modulated (CSIM) and of the classic APM symbols, despite its high complexity. Then, we propose a low complexity detection algorithm, which is termed as the iterative residual check (IRC)-based detector. This is based on the greedy pursuit concept of CS, which makes locally optimal choices at each step. Finally, both analytical and simulation results are provided for characterizing the attainable system performance of our proposed OFDM-CSIM system. We demonstrate that in comparison to the conventional OFDM-SIM system, the proposed OFDM-CSIM arrangement is capable of achieving both a higher SE as well as an increased EE. We also show that the diversity gain provided by the OFDM-CSIM system is much higher than that of the OFDM-SIM system. Furthermore, our investigation of the detection performance shows that the proposed IRC detector is capable of providing an attractive detection performance at a low complexity."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the manufacturability-aware process of p-n junction formation for photovoltaic cells involving with Si nanoparticle layer. The furnace-based dopant diffusion process of forming a p-n junction consumes a substantial amount of energy. In addition, repetitive production steps prevent the possibility of Si ink-based cells integrating onto flexible substrates. This research examined the local heating dopant diffusion process by using a fiber laser at a wavelength of 1064 nm. The infrared beam is delivered onto the wafer stack with a nanoparticle carbon layer and n-type Si ink layer on p-type Si substrates. The nanoparticle carbon film absorbs infrared beam energy and converts photon energy as a thermal source to diffuse the n-type dopant in Si ink into the p-type Si wafer. The Si ink in this paper contains a mixture of Si nanoparticles and an n-type spin-on dopant solution. The TEM results show that Si nanoparticles are uniformly dispersed on the Si wafer surface. This research investigated sheet resistance as a function of laser parameters, including laser power, scanning speed, and pulse frequency for the samples coated with Si ink. Secondary ion mass spectroscopy measurements indicate the presence of an n-type dopant in p-type substrates, with an approximate diffusion depth of 100 nm. The results indicate that the proposed infrared laser treatment technique is promising for the formation of p-n junctions with Si ink-based photovoltaic cells."
  },
  {
    "year": "2016",
    "abstract": "This paper applied a radial basis function network (RBFN) in coherent Fourier scatterometry (CFS) to reconstruct the linewidth of periodic line/space (L/S) patterns. The fast, nondestructive, and repeatable measurement capability of CFS enables its integration with intelligent lithography systems. Two steps to reconstruct the linewidth of the L/S patterns were performed in this paper. The first step was to use the finite difference time domain numerical electromagnetic tool to rigorously establish the library of modeled diffraction signatures by using the L/S patterns. Each modeled signature was converted to an intensity vector as the training data to construct the RBFN. The trained RBFN has a simple architecture consisting of three layers: input, hidden, and output layers. The second step was to collect the experimental signatures and feed them into the trained RBFN model to predict the linewidth of L/S patterns. This paper used the transverse electric polarized incident beam at the wavelength of 632 nm in the experimental setup of the CFS. Five L/S patterns were used to test the constructed RBFN. The experimental results indicated that the maximal difference was 13 nm between the CFS and the atomic force microscopy (AFM) measurements for the sample D with an L/S of 200 nm. The minimum difference was 2 nm for the sample A with an L/S of 140 nm. The correlation coefficient between the CFS and AFM metrology measurement running through five samples was 0.972. The high correlation between the CFS with the proposed RBFN measurements and the AFM revealed the potential to implement the radial basis learning kernel in optical metrology to achieve intelligent lithography."
  },
  {
    "year": "2016",
    "abstract": "Semantic social engineering attacks are a pervasive threat to computer and communication systems. By employing deception rather than by exploiting technical vulnerabilities, spear-phishing, obfuscated URLs, drive-by downloads, spoofed websites, scareware, and other attacks are able to circumvent traditional technical security controls and target the user directly. Our aim is to explore the feasibility of predicting user susceptibility to deception-based attacks through attributes that can be measured, preferably in real-time and in an automated manner. Toward this goal, we have conducted two experiments, the first on 4333 users recruited on the Internet, allowing us to identify useful high-level features through association rule mining, and the second on a smaller group of 315 users, allowing us to study these features in more detail. In both experiments, participants were presented with attack and non-attack exhibits and were tested in terms of their ability to distinguish between the two. Using the data collected, we have determined practical predictors of users' susceptibility against semantic attacks to produce and evaluate a logistic regression and a random forest prediction model, with the accuracy rates of. 68 and. 71, respectively. We have observed that security training makes a noticeable difference in a user's ability to detect deception attempts, with one of the most important features being the time since last self-study, while formal security education through lectures appears to be much less useful as a predictor. Other important features were computer literacy, familiarity, and frequency of access to a specific platform. Depending on an organisation's preferences, the models learned can be configured to minimise false positives or false negatives or maximise accuracy, based on a probability threshold. For both models, a threshold choice of 0.55 would keep both false positives and false negatives below 0.2."
  },
  {
    "year": "2016",
    "abstract": "Recent growth in traffic and the resulting congestion and accidents has increased the demand for vehicle positioning systems. Existing global navigation satellite systems were designed for line of sight environments and thus accurately determining the location of a vehicle in urban areas with tall buildings or regions with dense foliage is difficult. Fifth generation (5G) cellular networks provide device-to-device communication capabilities which can be exploited to determine the real-time location of vehicles. Millimeter-wave (mmWave) transmission is regarded as a key technology for 5G networks. This paper examines vehicle positioning using 5G mmWave signals. Both a correlation receiver and an energy detector are considered for timing estimation. Furthermore, fixed and dynamic thresholds for energy detection are examined. It is shown that a correlation receiver can provide excellent ranging accuracy but has high computational complexity, whereas an energy detector has low computational complexity and provides good ranging accuracy. Furthermore, the Gaussian raised-cosine pulse (RCP), Gaussian pulse, and Sinc-RCP impulse radio waveforms provide the best performance."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a self-synchronization mechanism is embedded into the universal droop controller (UDC), which is applicable to inverters having an impedance angle between -π/2 rad and π/2 rad, to form a self-synchronized UDC (SUDC). Both the voltage loop and the frequency loop of the UDC are modified to facilitate the standalone and grid-connected operation of inverters. Importantly, the dedicated phase-locked-loop that is often needed for grid-connected or parallel-operated converters is removed. The inverter is able to achieve synchronization before and after connection without the need of a dedicated synchronization unit. Since the original structure of the UDC is kept in the SUDC, the properties of the UDC, such as accurate power sharing and tight output voltage regulation, are well maintained. Extensive experimental results are presented to demonstrate the performance of the proposed SUDC for a grid-connected single-phase inverter."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a vehicular cloud (VC) model is adopted where vehicles offer data as a service. We propose solutions for efficient data delivery based on transmission scheduling methods where vehicles gather data from their mounted sensors. This is done by first organizing vehicles into clusters, so that each cluster works as VC. A distributed D-hop cluster formation algorithm is presented to dynamically form vehicle clouds. The algorithm groups vehicles into non-overlapping clusters, which have adaptive sizes according to their mobility. VCs are created in such a way that each vehicle is at most D-hops away from a cloud coordinator (broker). Each vehicle chooses its broker based on relative mobility calculations within its D-hop neighbors. After cloud construction, a mathematical optimization scheduling algorithm is used to maximize throughput and minimize delay in delivering data from vehicles to their VC broker. Our proposed optimization model implements a contention-free-based medium access control where physical conditions of the channel are fully analyzed. Extensive simulations were performed for different scenarios to evaluate the performance of the proposed cloud formation and cloud-based transmission scheduling algorithms. Results show that VCs formed by our algorithms are more stable and provide higher data throughputs compared with others."
  },
  {
    "year": "2016",
    "abstract": "The synchronous reference frame phase-locked loop (SRF-PLL) is widely used for synchronization applications. However, it suffers from a poor performance under unbalanced and distorted grid conditions. To improve the filtering capability of SRF-PLL, moving average filter (MAF) is incorporated into its control loop at the cost of a slow transient response of PLL in recently published literature. To further improve their dynamic performance without compromising the disturbance rejection capability and stability, a novel PLL based on quasi-type-1 PLL structure is proposed in this paper. A complex notch filter is incorporated into the QT1-PLL to eliminate the fundamental frequency negative sequence voltage component. The window length of MAF in QT1-PLL is reduced. And MAF is responsible for rejecting the rest of harmonics. Parameter design guidelines are suggested to obtain the minimum settling time for both phase jump and frequency jump. The proposed PLL provides a faster transient response with higher stability margins. The effectiveness of the proposed PLL is confirmed through simulation and experimental results and comparison with advanced PLLs."
  },
  {
    "year": "2016",
    "abstract": "A new magneto-electric (ME) dipole antenna with a dynamic beamwidth control in the H-plane is presented. The design methodology uses tunable strip gratings placed on the sides of an ME dipole along its H-plane. Each strip is equally divided into 16 short parts and connected in series by using 15 PIN diodes; accordingly, by controlling the on/off-state of the PIN diodes, the strips can operate as a grating reflector or be transparent for the radiating wave. Therefore, the size of the reflector can be reconfigured, which leads to the tunable beamwidth. A fully functional prototype with an as wide as 40% impedance bandwidth (for SWR ≤ 1.5) is developed and tested, demonstrating the H-plane beamwidth with a tuning range from 81° to 153°. Radiation efficiencies are better than 90% in all the states of operation."
  },
  {
    "year": "2016",
    "abstract": "The analysis presented in this paper indicates that the FM radio spectrum is underutilized in the areas of the continental United States that have a population of 100000 or less. These locations have vacant FM radio spectrum of at least 13 MHz with sufficient spectrum spacing between adjacent FM radio channels. The spectrum spacing provides the required bandwidth for data transmission and provides enough bandwidth to minimize interference introduced by neighboring predicted and unpredicted FM radio stations and other low-power short-range Internet of Thing (IoT) devices. To ensure that low-power short-range IoT devices maintain reliable communications vacant radio spectrum, such as the FM radio spectrum in these areas, will need to be used through cognitive radio."
  },
  {
    "year": "2016",
    "abstract": "Spectrum efficiency and energy efficiency are two critical issues in the design of wireless communication networks. Recently, energy harvesting cognitive radio networks have been proposed to attempt to solve both the issues simultaneously. In this paper, we consider a cognitive radio network in which a primary transmitter mainly occupies the channel, and a secondary transmitter equipped with an energy harvesting device is allowed to opportunistically access the primary channel at any time if it is detected to be idle. Here, we assume that energy arrival process and primary channel state are random process and two-state time-homogenous discrete Markov process, respectively. Instead of the expected number of successful spectrum access attempts per time slot as a design criterion in current literature, we use the average channel capacity as the achievable throughput to jointly optimize energy harvesting and spectrum sensing subject to the constraints on the energy causality, collision, and temporal correlation of probability of sensing the idle/occupied channel, thus achieving or almost achieving both the energy efficiency and the spectrum efficiency in certain conditions. In addition, the corresponding optimum detection threshold and the maximum achievable throughput are obtained, which are substantiated by our comprehensive computer simulations."
  },
  {
    "year": "2016",
    "abstract": "Co-located mobile users have found several useful and real-world applications in proximity-based services. Aiming at unleashing the potential of these proximity-based services, it is essential to devise robust techniques enabling smart devices to know their proximity close neighbors and be able to communicate with each other. To this end, we propose, design, and evaluate a robust framework capable to successfully co-localize walking groups of mobile users, in real-time and in a centralized manner. It leverages Bluetooth low energy technology to achieve a high degree of co-location accuracy. From the collected radio signals, we construct a graph network in which the distance between pairwise vertices represents the connection strength between mobile users. Then, we propose a modified version of edge betweenness techniques, with an average path length, as a key enabler for a high clustering accuracy. We analyze the performance in terms of clustering accuracy of the proposed scheme. First, we assess its performance numerically. Then, we conduct analysis on the experimental data set to demonstrate the feasibility and the efficiency of our method. Through obtained results, we have shown that our method can be successfully applied to co-localize people walking as part of the same group."
  },
  {
    "year": "2016",
    "abstract": "Differential evolution algorithm is an effective and population-based global optimization algorithm, which has been successfully used in many different fields. In this paper, the proposed algorithm attempts to combine the advantage of the evolutionary algorithm and local search to find the global optimum solutions with the low computational cost for the single objective bilevel optimization problem. For the upper level optimization, a multi-population-based ensemble mutation method is proposed to enhance the convergence rate of the algorithm and diversity maintenance. For the lower level optimization, a local search based on sequential quadratic programming method is used to find the best solution and then return the final solution into the upper level optimization. To verify the performance of the proposed algorithm, eight benchmark functions chosen from the literature are employed. Compared with some previous evolutionary algorithms, the results show the superior performance of the proposed algorithm over other algorithms in handling single objective bilevel optimization problem."
  },
  {
    "year": "2016",
    "abstract": "The generalized integrator (GI)-based filters can be categorized into two types: one is related to quadrature signal generator (QSG), and the other is related to sequence filter (SF). The QSG is used for generating the in-quadrature sinusoidal signals and the SF works for extracting the symmetrical sequence components. The signals generated by QSG and SF are useful in many applications, such as grid synchronization and harmonic estimation. However, the principles of QSG and SF are usually explained by either differential equations or transfer functions, which are not appropriate for analyzing some extended structures and thus restrict their applications. To overcome the drawback, this paper uses the first-order-system concept to re-investigate the GI-based filters, with which their working principles can be intuitively understood and their structure correlations can be easily discovered. Moreover, the proposed analysis method also provides the convenience for developing improved structures. To illustrate it, two improved filters are presented to enhance the performance of the basic QSG and SF. Finally, experimental results verify the effectiveness of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "For the complex semantic features of objects in a geological map, maintaining a hierarchy between different geological objects is a big challenge when automatically generalizing the geological map. The typical methods focus on automation of geological map generalization or pay more attention to the hierarchical relation between geological objects, which reduces the accuracy of the geological map generalization result. Therefore, a conceptual framework that focuses on both the automated process and the geological objects is particularly important in developing an efficient software designed for automated generalization of geological maps. In this paper, we design a compound conceptual framework for automated generalization of geological maps based on multiple agents and workflow. In this framework, the process is divided into three stages: structure analysis, map generalization, and style standardization. The map objects in the source geological map are abstracted as diverse agents with different properties and behaviors, and the agents can communicate with each other when they are activated. Thus, the relationship of the map objects is coordinated in geological map generalization, avoiding the conflict between the different operation levels. The workflow technology is used to manage the automated process. We discuss the task, modeling method, and specific operation in every stage based on the current conceptual framework and the characteristics of a geological map. Finally, we use a simple geological map for experimental studies that verify the proposed conceptual framework. The result shows that it is advantageous to design the software for automated generalization of geological maps based on the proposed compound conceptual framework."
  },
  {
    "year": "2016",
    "abstract": "We assume a set of cognitive relay nodes that assists both primary and secondary transmissions in a time-slotted cognitive radio networks. To regulate the channel access of the various nodes in the network, we propose an overlapped spectrum sensing strategy for channel sensing, where the secondary source node senses the channel from the beginning of the time slot and the cognitive relay nodes sense the channel for double the sensing time used by the secondary source node to detect the activities of both the primary and secondary source nodes. Hence, the secondary source node has an intrinsic priority over the relay nodes. The relay nodes help both the primary user and the secondary user to deliver their unsuccessfully decoded packets at their destinations. In a given time slot, the scheduled relay node for data transmission starts its transmission when both the primary and secondary users are sensed to be inactive (i.e. have no data to transmit). We propose two optimization-based formulations with quality-of-service (QoS) constraints involving average queueing delay and average service rate requirements. We investigate both cases of perfect and imperfect spectrum sensing. To further enhance the users' QoS requirements, we propose three packet decoding strategies at the relay nodes and compare their performance. We derive an upper bound on the secondary queue average service rate to determine which decoding strategy can achieve that bound. Our numerical results show the benefits of relaying and its ability to enhance the performance of both the primary and secondary users. Moreover, the performance of the proposed schemes is close to the derived upper bound."
  },
  {
    "year": "2016",
    "abstract": "Unstructured clinical medical text, as an important part of the electronic health records, is characterized by large quantities and can store substantial disease-related information of patients. Currently, the disease risk assessment model based on the analysis of clinical medical text designs relevant characteristics aiming at certain diseases, and different characteristics are identified from the text using different methods. In this way, changes of disease performance characteristics are difficult to adapt. Furthermore, it is hard to use the risk assessment model in other disease applications. As a result, this paper establishes the universal disease risk assessment model using the data of clinical medical text, conducts the independent study, and extracts disease characteristics from substantial historical data to avoid the limitations designing disease characteristics. First, this paper analyzes the medial clinical text to determine the contents related to the disease characteristics of patients. Second, learn the representation of clinical text with unsupervised learning methods, and study and extract the disease characteristics from the substantial historical data of patients in the convolutional neural network to assess disease risks. Finally, make a contrast experiment of disease risk assessment using the clinical text data of patients with cerebral infarction, patients with pulmonary infection, and patients with coronary atherosclerotic heart disease from the data of a second grade-A hospital in China and related methods. The experiments show that the approach proposed in this paper achieves the disease risk assessment for different diseases with the same structure."
  },
  {
    "year": "2016",
    "abstract": "The dynamic response of the pitch angle slows down when the pitch actuator of wind turbines fails, and the fault leads to fluctuations in the generator speed and in the output power. According to identification and analytical theories, a fault-tolerant control combined with fault estimation is proposed to solve this problem. The simplified two-order transform function of the pitch actuator is transformed into the identification equation by means of the Euler transformation method. Next, the time-varying natural frequency and the damping ratio of pitch actuators are regarded as gradual change and abrupt change parameters; these two parameters are estimated using the proposed sliding data window least squares-based iterative (SDW-LSI) identification algorithm. The sliding data window length is adjusted when changes in the system parameters are detected. Then, according to analytical theory, a compensation equation is derived in the pitch actuator, and the estimated values are fed back to the compensation module to adjust the relations before and after fault occurrences in the pitch actuator to eliminate the effects caused by the pitch actuator failure. Finally, the feasibility of the SDW-LSI algorithm is validated by choosing the fault of high air content in the hydraulic oil."
  },
  {
    "year": "2016",
    "abstract": "This is a response to two critical comments on our 2014 paper in the IEEE Access. That paper reviewed numerical dosimetry/modeling studies on the exposure [in terms of specific absorption rate (SAR)] to the user of a mobile phone to radiofrequency energy, and possible differences in exposure to children versus adults. The main focus was on the peak spatial average SAR (psSAR) in the head, which is the relevant quantity for assessing compliance with national and international exposure limits for mobile phones. Morris et al. criticized this paper for not accurately presenting the conclusions of the studies that it reviewed, despite the fact that these conclusions were summarized in this paper by quoting the original authors. However, their critique reflects a simple misreading of our paper and confusion about different metrics of exposure. A second critique, by Gandhi, noted age- and gender-related differences in the absorption of RF energy in the head. We agree with his comments, if they are interpreted as referring to the psSAR in the brain (which is different from the psSAR for the head as a whole and is not used for compliance assessment). This response briefly reviews major factors that limit the relevance of numerical dosimetry/modeling studies under tightly controlled conditions used for compliance assessment to real-world exposures to users of mobile phones."
  },
  {
    "year": "2016",
    "abstract": "According to the International Technology Roadmap for Semiconductors, improving characteristics of metal wires will no longer satisfy performance requirements, and new interconnect paradigms are needed. Radio frequency interconnect (RF-I) enjoys better CMOS compatibility compared with other alternatives, and is exploited as express shortcuts overlaid traditional network-on-chip (NoC) topologies. However, the efficient utilization of on-chip communication bandwidth provided by RF interconnects still remains an open problem. To make effective use of scarce on-chip RF-I for different traffic patterns, system model of NoC with shared RF-I (SRFNoC) is constructed first time in this paper, along with detailed design methodology. A light-weighted arbitration mechanism is utilized for sharing resource allocation, and a new mapping algorithm communication weight and simulated annealing is proposed for topology distribution. Both static and dynamic routings for SRFNoC are also discussed in detail. The results of experiment showed that, compared with the NoC with long-range wired links and representative network-on-chip with exclusive allocated radio frequency interconnect, the proposed network can get better communication efficiency with less resource overhead."
  },
  {
    "year": "2016",
    "abstract": "Fuzzy entropy and image thresholding are the most direct and effective methods for image segmentation. This paper, taking fuzzy Kapur's entropy as the optimal objective function, with modified discrete Grey wolf optimizer (GWO) as the tool, uses pseudotrapezoid-shaped to conduct fuzzy membership initialization so as to achieve image segmentation finally by means of local information aggregation. Experiment results show that the proposed fuzzy-based GWO and aggregation algorithm and fuzzy-based modified discrete GWO and aggregation (FMDGWOA) algorithm can search out the optimal thresholds effectively and accurately. In this paper, electro-magnetism optimization based on Kapur's entropy, standard GWO and fuzzy entropy-based differential evolution algorithm are experimentally compared with the proposed method, respectively. It shows that FMDGWOA enjoys obvious advantages in segmentation quality, objective function, and stability."
  },
  {
    "year": "2016",
    "abstract": "Next-generation mobile networks (5G) are defined to provide access in the framework of heterogeneous systems where it is crucial to have “always on” and “everywhere connectivity” capabilities. This is of fundamental importance even in 4G mobile systems, down to 3G and also Wi-Fi and WiMAX. In order to guarantee access to users with handheld devices equipped with multiple radio interfaces, an automated and reconfigurable tool for selecting the best network to be connected with is needed. This should be achieved by avoiding service outages. Current vertical handovers, i.e., switching from a network to another, are essentially based on power received levels and often do not avoid temporary service outages. We propose in this paper a procedure to access mobile networks by sensing multiple performance parameters related to networks available in the considered area. We target at maximizing the probability of accessing the wireless medium despite the technology used. We develop an algorithm, based on dynamic programming, able to select the most suitable network. We present the performance of the proposed algorithm both on the basis of computer simulations and on tests performed in an Arduino-based hardware platform."
  },
  {
    "year": "2016",
    "abstract": "P300 speller-based brain-computer interface is a direct communication from human-brain to computer machine without any muscular movements. In conventional P300 speller, a display paradigm is used to present alphanumeric characters to users and a classification system is used to detect the target character from the acquired electroencephalographic signals. In this paper, we present an 8 × 8 matrix consisting of Devanagari characters, digits, and special characters as Devanagari script (DS)-based display paradigm. The larger size of the display paradigm as compared with conventional 6 × 6 English row/column (RC) paradigm, involvement of matras and ardha-aksharas and similar looking characters in DS increase the adjacency problem, crowding effect, fatigue, and task difficulty. This results in deteriorated performance at the classification stage. Binary differential evolution algorithm was employed for optimal channel selection and support vector machine was used to classify target verses non target stimuli for the data set collected from ten healthy subjects using the DS-based paradigm. In order to further improve the system reliability in terms of higher accuracy at word prediction level, this paper proposes a novel spelling correction approach based on weighted edit distance (WED). A custom-built dictionary was incorporated and each misspelled word was replaced by a correct word of minimum WED from it. The proposed work is based on the validation of hypothesis that most of the target-error pairs lie in the same RC. Using the proposed spelling correction approach with optimal channel selection, an average accuracy of 99% was achieved at the word prediction level. The statistical analysis carried out in this paper shows that the proposed WED-based method improves the system reliability by significantly increasing in the accuracy of word prediction. This paper also validates that the proposed method performs better as compared to the conventional edit distance-based spe..."
  },
  {
    "year": "2016",
    "abstract": "Pneumatic systems are clean and reliable actuators, presenting very high force to weight ratios. They further present some advantages, such as inherent compliance and suitability for fire hazard environments. However, their intrinsic nonlinearities have hindered a more wide range of applications, leading to the use of complex control laws that typically require the knowledge of velocity and acceleration. This means that the velocity and acceleration estimators might play a crucial role in servopneumatic systems control, since a difficult to achieve balance between differentiation noise and phase lag must be inferred by the control engineer. This paper experimentally compares the performance of several velocity and acceleration estimators, relying upon a digital encoder position signal. The comparison is performed not only regarding the quality of the actual estimates per se but also on their effect on the control error and control action obtained when using a nonlinear sliding mode-based controller."
  },
  {
    "year": "2016",
    "abstract": "Ultra-dense networks (UDNs), which can provide extremely high throughput and data rates, have been considered as one of the key techniques for the fifth generation mobile networks. However, it may cause severe inter-cell interference and significant energy consumption due to numerous base stations (BSs) being randomly deployed. To mitigate the interference and boost energy efficiency (EE) of the UDN effectively, we propose a cluster-based energy-efficient resource allocation scheme in this paper. The proposed scheme has two stages: clustering stage and resource allocation stage. In clustering stage, we use a modified K-means algorithm in BS-clustering process to dynamically adjust the number of BS-clusters based on the density of BSs. Then, in each BS cluster, we divide user equipments (UEs) into multiple UE-groups with minimum intra-cluster interference. In this way, the complexity of resource allocation can be greatly reduced. While in resource allocation stage, we design a two-step resource blocks assignment algorithm and an iterative energy efficient power allocation algorithm based on a non-cooperative game. Furthermore, we implement simulations under the realistic broadband channel propagation conditions and the simulation results show that the proposed approach can effectively mitigate the interference and improve the EE of UDN."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we first study the average sum rate of sparse code multiple access (SCMA) systems, where a general scenario is considered under the assumption that the distances between the mobile users and the base station are not necessarily identical. Closed-form analytical results are derived for the average sum rate based on which an optimal factor graph matrix is designed for maximizing the capacity of the SCMA systems. Moreover, we propose a low-complexity iterative algorithm to facilitate the design of the optimal graph matrix. Finally, Monte Carlo simulations are provided to corroborate the accuracy of the theoretical results and the efficiency of the proposed iterative algorithm."
  },
  {
    "year": "2016",
    "abstract": "A novel antenna design for implantable pacemakers is proposed. The housing of a pacemaker is utilized as an antenna to cover both the 402-405 MHz Medical Implant Communication Service band and the 433-MHz Industrial, Scientific and Medical band. This is achieved by exploiting radiating characteristic current modes of the housing case. These modes are excited using a capacitive coupling element with the help of a matching circuit. The radiation pattern of this antenna is optimized to be in a desirable direction away from the body (off-body direction). The ability of the proposed antenna for communications is demonstrated using a transceiver and a base station at 433 MHz. A communication range of 1 m is established when a transmitter with the proposed antenna is implanted in a rabbit and the power fed by the transceiver to the antenna is 25 μW. A longer range of up to 19 m can be established with the maximum allowable transmit power within the safety limits. Furthermore, the far field wireless power transfer through the proposed antenna is investigated by experiment. A received power of up to 22.38 μW by the proposed antenna is demonstrated when an equivalent isotropically radiated power of 140 mW is transmitted 1 m away from a transmitting antenna. From the same transmitting antenna in the same distance, a power of 4 mW can be received when the transmit power is within safety limits. This power can be used to recharge a small battery or a capacitor, which can potentially cover the communication power consumption of the pacemaker and hence extend the life span of the primary battery."
  },
  {
    "year": "2016",
    "abstract": "Radio propagation modeling and prediction play an important role in the understanding of electromagnetic (EM) wave propagation in complex environments, as well as in the design of wireless communications and radar systems."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a wideband filtering power divider (PD) with ultra-wideband harmonic suppression and isolation is proposed. The dual coupled-line sections are embedded to the conventional quarter-wavelength transmission lines, which helps to extend the passband of the PD. With the introduction of the short-circuit stubs shunted at the output ports and the coupled lines with the open-circuit stubs, the ultra-wide stopband can be implemented more efficiently, thus resulting in five transmission zeros from 2 to 6 GHz. Furthermore, the improved isolation structure with series connected a resistor and a capacitor can be utilized to realize the ultra-wide isolation frequency band. Using a single resistor between two output ports, we have achieved an excellent in-band isolation. For demonstration, a wideband filtering PD operating at 1 GHz with a 20-dB bandwidth of 50% and an ultra-wide stopband better than 20 dB from 2 to 6 GHz is designed, fabricated, and measured. The measured results agree well with the anticipation."
  },
  {
    "year": "2016",
    "abstract": "We are interested in optimizing transmit beamforming for a visible light communication multiuser system such that the achievable sum rate is maximized. We first derive a closed-form sum rate expression via information-theoretic tools. Then, by further including light-emitting diode optical power constraints, we formulate the rate maximization problem in a mathematical optimization form. To address this difficult non-convex problem, we establish an iterative algorithm that exploits sequential parametric convex approximation. Compared with the existing zero-forcing beamforming strategies, the proposed approach does not restrict the co-channel interference to be zero, and thus achieves a higher sum rate, as is validated by simulations."
  },
  {
    "year": "2016",
    "abstract": "Differential-chaos-shift-keying cooperative communication (DCSK-CC) has attracted a great deal of attention in the past five years, because it can overcome the negative effect of wireless multipath fading. However, the conventional DCSK-CC system suffers from a major disadvantage of low data rate due to the resource consumption in cooperation. To address the issue, this paper proposes an efficient cooperative scheme, called partial-sequence CC (PS-CC) scheme, for the DCSK-CC system. In the PS-CC framework, the source and relays only transmit a partial chaotic sequence corresponding to one bit to the destination, while consuming the same transmission energy as DCSK-CC. To validate the feasibility of the DCSK PS-CC system, this paper carries out the error performance, diversity order, and data rate analyses under different cooperative conditions over multipath fading channels. Both numerical and simulated results show that the proposed PS-CC system outperforms the DCSK-based non-cooperative system and DCSK-CC systems over the range of signal-to-noise ratio under study. Moreover, the proposed system can enhance data rate and reduce the computational overhead of the relays as compared with the DCSK-CC system. In addition, it will be demonstrated that the DCSK PS-CC system preserves its advantages in typical ultra-wideband (UWB) channels. Overall, the PS-CC appears to be a desirable cooperative scheme for those applications featured by high-data-rate, low-power, and low-complexity, such as wireless sensor networks using the transmitted reference UWB technique."
  },
  {
    "year": "2016",
    "abstract": "Digital signature schemes are widely used to protect information integrity in computer communications. However, conventional digital signature schemes are secure only in normal attack contexts. Technically, these schemes assume that the signing algorithm implementation is running in a perfectly secure platform protected from various kinds of attacks and intrusions. To complement existing studies, this paper studies how to securely generate identity-based signatures, key-insulated signatures, and fuzzy identity-based signatures in a more austere attack context, such as on a computing device that is potentially controlled by an attacker. We use program obfuscation for achieving a higher security level. Concretely, we give three specialized signature functions—encrypted identity-based signature, encrypted key-insulated signature, and encrypted fuzzy identity-based signature, and then propose an obfuscator for the three encrypted signature functions. The efficiency of the proposed obfuscator is theoretically analyzed, and the correctness and security are proved. Finally, we present experimental results that show the proposed scheme is efficient. As a result, the obfuscated implementations of these encrypted signature functions can be applied to many protocols and enhance their security."
  },
  {
    "year": "2016",
    "abstract": "Non-local choice mismatch is one of the most important problems in the Internet-scale and service-based workflow ecosystems. The state-of-the-art method can solve it by generating adaptors to check deadlock-freeness based on a reachability graph. The states in the reachability graph give clues to re-design the composition. Deadlocks are resolved via an iterative process. However, this method is inefficient due to the overlook of the future deadlock state and the requirement of many interactions with a developer. In this paper, an abnormity prevention strategy based on an optimal controller is proposed for collaboration services described by Web Services Choreography Description Language. To overcome the deficiencies of the previous work, we describe service choreography by using service workflow nets. Then, by combining structure and reachability analyses, we formulate a different reachability graph called controlled reduced one. We next develop a maximally permissive state feedback control policy to prevent abnormity. We finally construct an optimal controller for the administrator of service composition to avoid deadlocks in service choreography. The advantage of our methodology is verified via an example."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a new longitudinal-torsional (L&T) hybrid vibrator driven by two longitudinal ultrasonic transducers is proposed for ultrasonic-assisted wire drawing. The two identical transducers were vertically installed on the two side surfaces of a transformer, however, with an offset distance (Δx) and stagger angle (α) between their axes. Therefore, the transformer could synthesize and amplify the vibration of the two transducers to produce an L&T composite vibration. Harmonic and transient simulations were performed in ANSYS to investigate the dynamic characteristics and frequency-dependent sensitivity of the vibrator. Δx and α between the transducers were subsequently optimized to maximize the output amplitude. Based on the finite element analysis (FEA) results, a prototype was manufactured with an electrical circuit developed for impedance matching. The vibrator generates an L&T composite vibration with a measured longitudinal amplitude of about 20 μm when driven by a voltage of 400 Vp-p, 19.597 kHz. The result is consistent with the FEA prediction, which indicates a new method of combining two different forms of ultrasonic vibration."
  },
  {
    "year": "2016",
    "abstract": "With a trusted-third-party (TTP)-based key exchange protocol, when a user would like to transmit a message to another user, the transmitted data are encrypted by a session key exchanged between the two ends of the corresponding connection with the help of the TTP. Up to present, due to the assistance of a TTP, this type of protocols has performed well in protecting messages delivered between two authorized users. Even this, inflexibility, unreliability, and inefficiency problems still exist in these previously proposed protocols. Therefore, in this paper, a multi-key exchange protocol, named the TTP-based high-efficient multi-key exchange protocol (THMEP), is proposed to provide users with a secure and efficient protocol, which employs the elliptic curve cryptography, a 2-D operation, and a current time encryption key, to exchange their session keys. The proposed protocol not only effectively hides important encryption parameters, but also achieves fully mutual authentication between a user and his/her trusted server. It can resist known-key, impersonation, replay, eavesdropping, and forgery attacks. Besides, the THMEP generates 40 session keys in a key exchange process, meaning the proposed protocol can support 40 sessions simultaneously. It also shortens the processing time, which is 3.78 times faster than that of a specific previous study. Its security level and performance are higher than those of the compared state-of-the-art protocols. In other words, the THMEP is very suitable for IoT applications."
  },
  {
    "year": "2016",
    "abstract": "Recently, directional modulation has become an active research area in wireless communications due to its security. Unlike existing research work, we consider a multi-beam directional modulation (MBDM) scenario with imperfect desired direction knowledge. In such a setting, a robust synthesis scheme is proposed for MBDM in broadcasting systems. In order to implement the secure transmission of a confidential message, the beamforming vector of the confidential message is designed to preserve its power as possible in the desired directions by minimizing its leakage to the eavesdropper directions while the projection matrix of artificial noise (AN) is to minimize the effect on the desired directions and force AN to the eavesdropper directions by maximizing the average receive signal-to-artificial-noise ratio at desired receivers. Simulation results show that compared with conventional methods, the proposed robust scheme achieves much better bit error rate performance along desired directions for a given signal-to-noise ratio (SNR). From the secrecy-rate aspect, the proposed scheme performs better than conventional methods for almost all SNR regions. In particular, in the medium and high SNR regions, the rate improvement of the proposed scheme over conventional methods is significant."
  },
  {
    "year": "2016",
    "abstract": "Biometric systems are used for the verification and identification of individuals using their physiological or behavioral features. These features can be categorized into unimodal and multimodal systems, in which the former have several deficiencies that reduce the accuracy of the system, such as noisy data, inter-class similarity, intra-class variation, spoofing, and non-universality. However, multimodal biometric sensing and processing systems, which make use of the detection and processing of two or more behavioral or physiological traits, have proved to improve the success rate of identification and verification significantly. This paper provides a detailed survey of the various unimodal and multimodal biometric sensing types providing their strengths and weaknesses. It discusses the stages involved in the biometric system recognition process and further discusses multimodal systems in terms of their architecture, mode of operation, and algorithms used to develop the systems. It also touches on levels and methods of fusion involved in biometric systems and gives researchers in this area a better understanding of multimodal biometric sensing and processing systems and research trends in this area. It furthermore gives room for research on how to find solutions to issues on various unimodal biometric systems."
  },
  {
    "year": "2016",
    "abstract": "Generating large scale terrains that conform to the morphology of real scenes is a great challenge for terrain modeling, as simulating complex geometric details is time-consuming and the realistic geographical features are hard to be controlled. In this paper, we propose an efficient modeling method for large scale terrain visualization based on hydrology. To simulate real geographic features, we introduce the hydrology-based Tokunaga river network to guide the terrain generation, and propose a production rule set of river network using procedural modeling. The distribution and structure of river network can be adjusted by user interactions. Ridges are extracted based on river network to provide more skeleton features, and the enrichment method of skeleton features is presented to maintain the morphology of valleys and ridges. Based on the enriched features, diffusion equation is exploited to compute the full elevation field, which can achieve the nature transitions of the regions between skeleton features. Large scale terrain with real morphological features can be generated online through the parallel implementation of diffusion equation. According to user requirements, the augmented virtual terrain can be obtained by blending the selected real terrain with the synthesis terrain seamlessly. The experiments are conducted on digital elevation model, and the results show that the proposed methods can generate large scale terrains that conform to the morphology of real terrain and can well simulate various natural scenes."
  },
  {
    "year": "2016",
    "abstract": "Big data is one of the hottest research topics in science and technology communities, and it possesses a great application potential in every sector for our society, such as climate, economy, health, social science, and so on. Big data usually includes data sets with sizes beyond the ability of commonly used software tools to capture, curate, and manage. We can conclude that big data is still in its infancy stage, and we will face many unprecedented problems and challenges along the way of this unfolding chapter of human history."
  },
  {
    "year": "2016",
    "abstract": "The fault tolerant control problem is investigated for a class of uncertain networked control systems (NCSs) subject to actuator faults and actuator saturation in this paper. System parameter uncertainties are considered and a sector condition method is employed to deal with the saturation problem. Based on the network transmission environment, the NCSs can be modeled as a class of saturated discrete-time systems with time-varying delays and actuator faults. By using Lyapunov-Krasovskii (L-K) stability theory, a sufficient condition for the fault tolerant controller design of NCSs is derived in the form of linear matrix inequalities. Finally, simulation results are given to demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a discrete version of weighted centroid localization algorithm (dWCL) is proposed for a wireless-sensor-network-based indoor positioning system. Under this architecture, a wireless device can estimate its own position based on the location information of connected wireless sensor nodes in the network. Unlike other weighted centroid localization algorithms, dWCL classifies the sensor nodes into a number of groups and assigns them weights taken from a set of discrete values. With the weighting function and the range information decoupled, the dWCL framework is flexible to adjust its performance in accordance with the requirements. Its capability to generalize some existing weighted centroid localization algorithms is also demonstrated. In addition, the performance of dWCL is characterized by the error distribution in terms of accuracy and precision. Further enhancement is achieved by optimizing the system parameters. Finally, the simulation results are presented to validate the proposed scheme and analytical framework."
  },
  {
    "year": "2016",
    "abstract": "Optimal frames have been used in signal processing to minimize the reconstruction errors when erasures occurred during the frame coefficient transmission, and much of the recent work has been focused either on characterizations or on the constructions of optimal frames (or dual frames) prior to signal encoding. In this paper, we propose a new approach, based on the method of optimal directions, which can search adaptively optimal dual frames in the process of signal reconstruction. We provide concrete algorithms for constructing adaptive optimal dual frames and the reconstruction of signals. In addition, several numerical experiments are presented to demonstrate the efficiency and comparison of the new method with the existed methods."
  },
  {
    "year": "2016",
    "abstract": "Mobile devices are increasingly becoming an indispensable part of people's daily life, facilitating to perform a variety of useful tasks. Mobile cloud computing integrates mobile and cloud computing to expand their capabilities and benefits and overcomes their limitations, such as limited memory, CPU power, and battery life. Big data analytics technologies enable extracting value from data having four Vs: volume, variety, velocity, and veracity. This paper discusses networked healthcare and the role of mobile cloud computing and big data analytics in its enablement. The motivation and development of networked healthcare applications and systems is presented along with the adoption of cloud computing in healthcare. A cloudlet-based mobile cloud-computing infrastructure to be used for healthcare big data applications is described. The techniques, tools, and applications of big data analytics are reviewed. Conclusions are drawn concerning the design of networked healthcare systems using big data and mobile cloud-computing technologies. An outlook on networked healthcare is given."
  },
  {
    "year": "2016",
    "abstract": "The purpose of this paper is to survey and assess the state-of-the-art in automatic target recognition for synthetic aperture radar imagery (SAR-ATR). The aim is not to develop an exhaustive survey of the voluminous literature, but rather to capture in one place the various approaches for implementing the SAR-ATR system. This paper is meant to be as self-contained as possible, and it approaches the SAR-ATR problem from a holistic end-to-end perspective. A brief overview for the breadth of the SAR-ATR challenges is conducted. This is couched in terms of a single-channel SAR, and it is extendable to multi-channel SAR systems. Stages pertinent to the basic SAR-ATR system structure are defined, and the motivations of the requirements and constraints on the system constituents are addressed. For each stage in the SAR-ATR processing chain, a taxonomization methodology for surveying the numerous methods published in the open literature is proposed. Carefully selected works from the literature are presented under the taxa proposed. Novel comparisons, discussions, and comments are pinpointed throughout this paper. A two-fold benchmarking scheme for evaluating existing SAR-ATR systems and motivating new system designs is proposed. The scheme is applied to the works surveyed in this paper. Finally, a discussion is presented in which various interrelated issues, such as standard operating conditions, extended operating conditions, and target-model design, are addressed. This paper is a contribution toward fulfilling an objective of end-to-end SAR-ATR system design."
  },
  {
    "year": "2016",
    "abstract": "This paper is concerned with the exponential stability analysis for time-delay systems. First, two new weighted integral inequalities are presented based on the auxiliary function-based integral inequalities. In the new weighted integral inequalities, unlike previous studies, exponentially weighted integral vectors are used to find the lower bounds of the weighted integral quadratic terms. Then, by utilizing the new weighted integral inequalities, a new linear matrix inequality (LMI) condition is derived for the exponential stability of the considered time-delay systems. Finally, the numerical examples are conducted to validate the effectiveness of the new LMI condition. The example results show that the LMI condition derived in this paper is less conservative than existing ones in analyzing exponential stability of the considered systems."
  },
  {
    "year": "2016",
    "abstract": "To enable the intelligent management of Smart City and improve overall social welfare, it is desirable for the status of infrastructures detected and reported by intelligent devices embedded in them to be forwarded to the data centers. Using “SCmules” such as taxis, to opportunistically communicate with intelligent devices and collect data from the sparse networks formed by them in the process of moving is an economical and effective way to achieve this goal. In this paper, the social welfare data collection paradigm SWDCP-SCmules data collection framework is proposed to collect data generated by intelligent devices and forward them to data centers, in which “SCmules” are data transmitters picking up data from nearby intelligent devices and then store-carry-forwarding them to nearby data centers via short-range wireless connections in the process of moving. Because of the storage limitations, “SCmules” need to weigh the value of data and select some less valuable data to discard when necessary. To quantify the value of data and find a well-performed selection strategy, the concept of priority is introduced to the SWDCP-SCmules scheme, and then, the simulated annealing for priority assignment SA-PA algorithm is proposed to guide the priority assignment. The SA-PA algorithm is a universal algorithm that can improve the performance of SWDCP-SCmules scheme by finding better priority assignment with respect to various optimization targets, such as maximizing collection rate or minimizing redundancy rate, in which priority assignment problem is converted into an optimization problem and simulated annealing is used to optimize the priority assignment. From the perspective of machine learning, the process of optimization is equal to automatically learn social-aware patterns from past GPS trajectory data. Experiments based on real GPS trajectory data of taxis in Beijing are conducted to show the effectiveness and efficiency of SWDCP-SCmules scheme and SA-PA algorithm."
  },
  {
    "year": "2016",
    "abstract": "Proponents of deploying LTE in the 5 GHz band for providing additional cellular network capacity have claimed that LTE would be a better neighbour to Wi-Fi in the unlicensed band, than Wi-Fi is to itself. On the other side of the debate, the Wi-Fi community has objected that LTE would be highly detrimental to Wi-Fi network performance. However, there is a lack of transparent and systematic engineering evidence supporting the contradicting claims of the two camps, which is essential for ascertaining whether regulatory intervention is in fact required to protect the Wi-Fi incumbent from the new LTE entrant. To this end, we present a comprehensive coexistence study of Wi-Fi and LTE-in-unlicensed, surveying a large parameter space of coexistence mechanisms and a range of representative network densities and deployment scenarios. Our results show that, typically, harmonious coexistence between Wi-Fi and LTE is ensured by the large number of 5 GHz channels. For the worst-case scenario of forced co-channel operation, LTE is sometimes a better neighbour to Wi-Fi-when effective node density is low-but sometimes worse-when density is high. We find that distributed interference coordination is only necessary to prevent a “tragedy of the commons” in regimes where interference is very likely. We also show that in practice it does not make a difference to the incumbent what kind of coexistence mechanism is added to LTE-in-unlicensed, as long as one is in place. We therefore conclude that LTE is neither friend nor foe to Wi-Fi in the unlicensed bands in general. We submit that the systematic engineering analysis exemplified by our case study is a best-practice approach for supporting evidence-based rulemaking by the regulator."
  },
  {
    "year": "2016",
    "abstract": "With the rapid development of online social networks (OSN), the influence of rumor propagation on social life raises great concern. Traditional rumor-propagation models, which do not fully consider the features of OSN, are not suitable for use in OSN. In this paper, we focus on discovering a pattern of rumor-propagation phenomena in OSN, and propose a novel rumor-propagation model, inspired by a ball elastic-collision model, called the elastic collision-based rumor-propagation model (ECRModel). We investigate the dynamics of ball elastic collisions, which is similar to the dynamics of rumor propagation between nodes in OSN. We adopt the parameter relationships of the elastic collision model and apply them to rumor propagation in social networks. In the ECRModel, we do not directly adopt the node classification categories of “Ignorants, Spreaders, and Stiflers”, but divide the user nodes into three types: 1) inactive and never spread rumors; 2) active and spread rumors forward; and 3) inactive but have previously spread rumors. We mathematically model node interaction attributes, and analyze the spreading probabilities and the steady state, considering both individual perspectives with detailed attributes and integral perspectives with node-state densities. At last, we conduct a series of simulations, and the results verify the correctness of the analytical results. We further investigate the effects of detailed properties on rumor propagation, such as average out-degree of OSN, rumor confusingness degree, and each node’s comprehensive influence."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio (CR) enables unlicensed users to explore and exploit underutilized licensed channels (or white spaces). While multi-hop CR network has drawn significant research interest in recent years, majority work has been validated through simulation. A key challenge in multi-hop CR network is to select a route with high quality of service (QoS) and lesser number of route breakages. In this paper, we propose three route selection schemes to enhance the network performance of CR networks, and investigate them using a real testbed environment, which consists of universal software radio peripheral and GNU radio units. Two schemes are based on reinforcement learning (RL), while a scheme is based on spectrum leasing (SL). RL is an artificial intelligence technique, whereas SL is a new paradigm that allows communication between licensed and unlicensed users in CR networks. We compare the route selection schemes with an existing route selection scheme in the literature, called highest-channel (HC), in a multi-hop CR network. With respect to the QoS parameters (i.e., throughput, packet delivery ratio, and the number of route breakages), the experimental results show that RL approaches achieve a better performance in comparison with the HC approach, and also achieve close to the performance achieved by the SL approach."
  },
  {
    "year": "2016",
    "abstract": "Robots are meant to replace humans for a broad variety of everyday tasks, such as environmental monitoring or patrolling large public areas for security assurance. The main focus of researchers and practitioners has been on providing tailored software and hardware solutions for very specific and often complex tasks. On one hand, these solutions show great potential and provide advanced capabilities for solving the specific task. On the other hand, the polarized attention to task-specific solutions makes them hard to reuse, customize, and combine. In this paper we propose a family of domain-specific modeling languages for the specification of civilian missions of mobile multi-robot systems. These missions are meant to be described in terms of models that are: 1) closer to the general problem domain; 2) independent from the underlying technologies; 3) ready to be analyzed, simulated, and executed; and 4) extensible to new application domains, thus opening up the use of robots to even non-technical operators. Moreover, we show the applicability of the proposed family of languages in two real-world application domains: unmanned multicopters and autonomous underwater vehicles."
  },
  {
    "year": "2016",
    "abstract": "In the demand for protecting the increasing aged groups from heart attacks, the improvement of the mobile electrocardiogram (ECG) monitoring systems becomes significant. The limitations of the arrhythmia classification in these systems are the lack of ability to cope with motion state and the low accuracy in new users' data. This paper proposes a system which applies the impulse radio ultra wideband radar data as additional information to assist the arrhythmia classification of ECG recordings in the slight motion state. Besides, this proposed system employs a cascade convolutional neural network to achieve an integrated analysis of ECG recordings and radar data. The experiments are implemented in the Caffe platform and the result reaches an accuracy of 88.89% in the slight motion state. It turns out that this proposed system keeps a stable accuracy of classification for normal and abnormal heartbeats in the slight motion state."
  },
  {
    "year": "2016",
    "abstract": "Emerging fifth generation (5G) wireless networks require massive bandwidth in higher frequency bands, extreme network densities, and flexibility of supporting multiple wireless technologies in order to provide higher data rates and seamless coverage. It is expected that the utilization of the large bandwidth in the millimeter-wave (mmWave) band and deployment of heterogeneous networks (HetNets) will help address the data rate requirements of 5G networks. However, high pathloss and shadowing in the mmWave frequency band, strong interference in the HetNets due to massive network densification, and coordination of various air interfaces are challenges that must be addressed. In this paper, we consider a relay-based multiband orthogonal frequency division multiple access HetNet in which mmWave small cells are deployed within the service area of macro cells. In particular, we attempt to exploit the distinct propagation characteristics of mmWave bands (i.e., 60 GHz-the V-band and 70-80 GHz-the E-band) and the long term evolution band to maximize overall data rate of the network via efficient resource allocation. The problem is solved using a modified dual decomposition approach and then a low complexity greedy solution based on the iterative activity selection algorithm is presented. Simulation results show that the proposed approach outperforms conventional schemes."
  },
  {
    "year": "2016",
    "abstract": "This paper considers a multi-cell network with base stations (BSs) equipped with large dual-polarized antenna arrays. We derive closed-form expressions of network performance in terms of user signal-to-interference-and-noise ratio both with perfect channel state information and in the presence of pilot contamination. In general, a dual-polarized system enjoys the reduction in pilot contamination and multiuser interference due to orthogonal polarizations, while the available BS array dimension is reduced in each polarized direction compared with a monopole antenna setup. The derived results, however, reveal that the performance of a dual polarization system can be optimized by properly setting receive antenna polarizations, and fortunately, the optimal performance behaves identically to that of a monopole-antenna one in massive MIMO. We finally verify the observations by numerical simulations."
  },
  {
    "year": "2016",
    "abstract": "Today's best-effort (BE) Internet of Things (IoT) faces challenges in providing the end-to-end-performance, security, and energy efficiency needed for the Smart Systems of the 21st century. These future smart systems will include smart cities, smart transportation systems, and smart manufacturing. This paper surveys the security weaknesses of the BE IoT. The BE-IoT cannot be partitioned into distinct interference-free virtual networks, which compromises performance, cyber-security, and energy efficiency. The design of a secure deterministic industrial-tactile IoT core network, which can embed millions of distinct secure deterministic virtual networks (SD-VNs) in layer 2, is then presented. Deterministic communications, combined with low-jitter scheduling, offers several benefits: 1) the removal of all congestion, interference, and DOS attacks; 2) a significant reduction in IoT router buffer sizes; 3) a significant reduction in IoT energy use; 4) a reduction of end-to-end IoT delays to the speed of light in fiber; and 5) deterministic packet-switches are relatively easy to synthesize using FPGA technologies. These benefits apply to optical and 5G wireless networks. Future smart systems can reserve their own congestion-free SD-VNs in layer 2 to manage their traffic, with significantly improved performance, security, and energy efficiency. A speed-of-light deterministic IoT core network can transform cloud services in the 21st century by exploiting a new technology: FPGAs combined with silicon photonics transceivers to achieve terabits/second of optical bandwidth. To illustrate the transformational potential, Big Data green cloud computing over a secure deterministic IoT spanning the European Union is explored."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a novel and analytical approach to identifying a lightning strike after it has struck an overhead transmission line. The identification method is mainly based on the traveling waves' time-domain parameters, such as polarity, amplitude, and half-wavelength. The main differences in these parameters across different strike types are analyzed. Subsequently, a robust identification algorithm is proposed. An instrumentation system is implemented to verify the algorithm. The overall performances of the instrumentation system and the methodology are demonstrated using an on-site application with excellent results."
  },
  {
    "year": "2016",
    "abstract": "Epilepsy detection from electrical characteristics of EEG signals obtained from the brain of undergone subject is a challenge task for both research and neurologist due to the non-stationary and chaotic nature of EEG signals. As epileptic EEG signals contain huge fluctuating information about the functional behavior of the brain, it is hard to distinguish the fundamental dynamic, complex network of EEG signals without considering the strength among the nodes as they are connected with each other on the basis of these strengths. The prior research on natural visibility graph did not consider this issue in epileptic seizure, although it is a very important key point to have representative information from the signals. Hence, this paper aims to introduce a new idea for epilepsy detection using complex network statistical properties by measuring different strengths of the edges in natural visibility graph theory, which is considered as weight. Thus, the proposed method is named “weighted visibility graph”. In this proposed method, first, the epileptic EEG signals are transformed into complex network and then two important statistical properties of a network such as modularity and average weighted degree used for extracting the imperative characteristics from a network of EEG signals. After that, the extracted features are evaluated by two modern machine-learning classifiers such as, support vector machine with a different kernel function and k-nearest neighbor. The experimental results demonstrate that the combined effect of both features is valuable for network metrics to characterize the EEG time series signals in case of weighted complex network generating up to 100% classification accuracy."
  },
  {
    "year": "2016",
    "abstract": "Heterogeneous cellular networks (HetCNets) offer a promising solution to cope with the current cellular coverage crunch. Due to the large transmit power disparity, while following maximum power received (MPR) association scheme, a larger number of users are associated with macro-cell BS (MBS) than small-cell BSs (SBSs). Therefore, an imbalance load arrangement takes place across the HetCNets. Hence, using cell range expansion-based cell association, we can balance the load across the congested MBS. However, using MPR association scheme, users' offloading leads to two challenges: 1) macro-cell interference, in which the MBS interferes with the offloaded users, and 2) coupled downlink-uplink cell association, in which a random user associates with a single tier's base station (BS) both in uplink (UL) and downlink (DL) directions. This paper aims to address these problems while considering a two-tier scenario consisting of small-cell and macro-cell tiers. For the MBS interference mitigation, we employ a reverse frequency allocation (RFA) scheme. Besides coupled DL-UL association (Co-DUA), this paper also highlights the notion of decoupled DL-UL association (De-DUA). In De-DUA, a random user associates with two different tiers' BSs, i.e., with one tier's BS in the DL direction and with the other tier's BS in the UL direction. Our results illustrate that, in comparison with the Co-DUA, De-DUA with RFA employment achieves a better coverage performance."
  },
  {
    "year": "2016",
    "abstract": "The concept of physical layer security builds on the pivotal idea of turning the channel's imperfections, such as noise and fading, into a source of security. This is established through appropriately designed coding techniques and signal processing strategies. In this vein, it has been shown that fading channels can enhance the transmission of confidential information and that a secure communication can be achieved even when the channel to the eavesdropper is better than the main channel. However, to fully benefit from what fading has to offer, the knowledge of the channel state information at the transmitter (CSIT) is of primordial importance. In practical wireless communication systems, CSIT is usually obtained, prior to data transmission, through CSI feedback sent by the receivers. The channel links over which this feedback information is sent can be either noisy, rate-limited, or delayed, leading to CSIT uncertainty. In this paper, we present a comprehensive review of recent and ongoing research works on physical layer security with CSIT uncertainty. We focus on both information theoretic and signal processing approaches to the topic when the uncertainty concerns the channel to the wiretapper or the channel to the legitimate receiver. Moreover, we present a classification of the research works based on the considered channel uncertainty. Mainly, we distinguish between the cases when the uncertainty comes from an estimation error of the CSIT, from a CSI feedback link with limited capacity, or from an outdated CSI."
  },
  {
    "year": "2016",
    "abstract": "Monitoring human bodies and collecting physiological information are the major healthcare applications for wireless body area networks (WBANs). Due to the limited energy resource of body sensors, their energy depletions will cause severe network performance degradation, such as latency and energy efficiency. The heterogeneity of body sensors can result in different sensor energy consumption rates. Besides, the important degrees of monitored physiological data could vary hugely. Targeting at the above-mentioned problems, an energy-efficient data forwarding strategy (EDFS) is proposed in this paper to balance sensor energy consumption and improve network lifetime and collaborative operations of heterogeneous WBANs. Our major contributions include: 1) the original physiological data are processed by compressed sensing to reduce the data size to be transmitted and 2) the remaining energy levels, sampling frequency, and sensor importance are jointly considered by EDFS for the optimal relay sensor selection. With the EDFS, the energy-efficiency and reliability of WBAN data transmission can be improved. In addition, our simulation results demonstrate that the proposed EDFS can effectively deal with the frequently changing WBAN topologies while providing balanced energy consumption and energy efficiency."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a square-constellation-based M-ary differential chaos-shift-keying (M-DCSK) communication system framework is proposed. The symbol-error-rate expression of the proposed system is derived over additive white Gaussian noise as well as multipath Rayleigh fading channels. Moreover, the peak-to-average-power-ratio (PAPR) performance is carefully analyzed for the newly proposed system. Based on the square-constellation-based M-DCSK framework, a simple least-square estimator is designed to demodulate the information exploiting pilot-assistant symbols. Analytical and simulated results show that the proposed system benefits from a lower energy consumption, but suffers from a higher PAPR compared with the circle-constellation-based M-DCSK system."
  },
  {
    "year": "2016",
    "abstract": "It is of enormous significance to detect abnormal brains automatically. This paper develops an efficient pathological brain detection system based on the artificial intelligence method. We first extract brain edges by a Canny edge detector. Next, we estimated the fractal dimension using box counting method with grid sizes of 1, 2, 4, 8, and 16, respectively. Afterward, we employed the single-hidden layer feedforward neural network. Finally, we proposed an improved particle swarm optimization based on three-segment particle representation, time-varying acceleration coefficient, and chaos theory. This three-segment particle representation encodes the weights, biases, and number of hidden neuron. The statistical analysis showed the proposed method achieves the detection accuracies of 100%, 98.19%, and 98.08% over three benchmark data sets. Our method costs merely 0.1984 s to predict one image. Our performance is superior to the 11 state-of-the-art approaches."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the problem of fault detection for 2-D systems with lock-in-place sensor faults. Our attention is focused on detecting sensor faults in the presence of disturbances. To this end, a fault detection filter is designed, through which a residual signal is generated for both the fault-free and faulty cases. In light of the generalized Kalman–Yakubovich–Popov lemma for 2-D systems and matrix inequality techniques, convex filter design conditions are derived. Based on these conditions, an algorithm is proposed to calculate the parameters of a desired fault detection filter. Moreover, a residual evaluation function and a threshold are proposed for 2-D systems. Finally, an example is employed to illustrate the effectiveness of the proposed fault detection method."
  },
  {
    "year": "2016",
    "abstract": "As the latest video coding standard, High Efficiency Video Coding (HEVC) tremendously improves the encoding efficiency compared with the preceding H.264/AVC standard, but at the cost of higher encoding complexity. This huge encoding complexity makes the implementation of HEVC intractable on live videos. For coping with this problem, two major challenges need to be solved: 1) How to accurately reduce the encoding complexity to achieve the target complexity? and 2) How to maintain the video quality after encoding complexity reduction? To solve these two challenges, we propose, in this paper, a hierarchical complexity control approach of HEVC. For the first goal, the complexity control is implemented in two levels to assure the control accuracy. In the largest coding unit (LCU) level, we adjust the maximum depths of LCUs in a frame to reduce the encoding complexity to the target. Since each frame has numerous LCUs, and each LCU can choose its maximum depth from one of the four maximum depths, the large degree of freedom contributes to the high control accuracy. However, there may be still some errors. These errors can be compensated in the frame level by a proposed frame level complexity control algorithm. For the second goal, one objective weight map and one subjective weight map are proposed to use in the process of complexity control to keep the objective and subjective video quality simultaneously. Finally, The experimental results show that our approach outperforms other state-of-the-art approaches, in terms of both control accuracy and video quality."
  },
  {
    "year": "2016",
    "abstract": "Asynchronous network coding has the potential to improve wireless network performance compared with simple routing. However, to achieve the maximum network coding gain, the encoding node consumes a few computing and storage resources that may be unaffordable for wireless sensor networks such as CubeSats. An analogous threshold strategy, called best effort network coding (BENC), which requires only minimal storage resources and no computing resources, is investigated in this paper as an efficient and convenient method of network coding. In this strategy, a new packet arrival evicts the head packet when the queue is full to avoid excessively long waits. Moreover, in contrast to other methods that require a queue for each flow, the BENC uses only one queue for the two coded flows. In addition, the problem of time interval distribution for the output flow, which combines two independent flows, is investigated, and the network coding gain is then analyzed. While the maximum coding gain requires infinite buffer capacity under two independent Poisson arrivals with the same transmission rates, the calculation results show that the BENC needs only 4 buffers to achieve 90% of the maximum coding gain and can reach 99% of the maximum coding gain using 50 buffers. These results are verified by numerical simulations."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we introduce transmit antenna selection/maximal-ratio combining (TAS/MRC) scheme in dual-hop randomize-and-forward (RaF) cognitive multiple-input multiple-output (MIMO) wiretap networks with outdated channel state information (CSI). In this network, the secondary transmitter adopts the TAS scheme to choose the antenna with the maximal received signal-to-noise ratio (SNR), while the secondary receiver and the eavesdropper adopt the MRC scheme to combine the received signals. To thoroughly assess the secrecy performance achieved by the TAS/MRC scheme and the impact of outdated CSI on the secrecy performance, we derive a new closed-form expression for the secrecy outage probability of dual-hop RaF cognitive MIMO wiretap networks. In order to achieve more insights on the application of TAS/MRC scheme, we further present tractable asymptotic secrecy outage probability at high SNR regimes under two distinct scenarios. From our analysis, several important concluding remarks are obtained as follows: 1) the RaF relaying strategy achieves better secrecy performance than that of the decode-and-forward relaying strategy for dual-hop cognitive MIMO wiretap networks; 2) outdated CSI decreases the secrecy diversity gain of the TAS/MRC scheme fromNRmin(NA,NB)tomin(NR,NB); and 3) although TAS/MRC scheme cannot attain full secrecy diversity gain for the considered system with outdated CSI, it still can achieve an extra secrecy coding gain compared with the random antenna selection/MRC scheme."
  },
  {
    "year": "2016",
    "abstract": "Innovation diffusion is the process of adopting novel things, which is deemed as the diffusion of human behaviors. Previous studies mainly posit an unclear distinction with information diffusion. However, there exist critical differences in both social and economic areas. Inspired by this observation, we propose a practical method for innovation diffusion based on the process of behavior diffusion, which integrates threshold model with social imitation strategy. The primary goal of our proposed model is to combine individuals' economic as well as social characteristics to study innovation diffusion. The interplay of these two strategies is studied in the context of a coordination game. According to the simulation results on Erdös-Rényi random networks and small-world networks, we find that the conjunction of these two approaches can greatly improve the efficiency of innovation diffusion. In addition, we further study the impacts of varied initial seeds' selection strategies on the overall performance of innovation diffusion using our proposed model."
  },
  {
    "year": "2016",
    "abstract": "Given the emergence of mobile cloud computing (MCC), its associated energy implications are witnessed at larger scale. With offloading computationally intensive tasks to the cloud datacentres being the basic concept behind MCC, most of the mobile terminal resources participating in the MCC collaborative execution are wasted as they remain idle until the mobile terminals receive responses from the datacentres. This is an additional wastage of resources alongside the cloud resources are already being addressed as massive energy consumers. Though the energy consumed of the idle mobile resources is insignificant in comparison with the cloud counterpart, such consumptions have drastic impacts on the mobile devices causing unnecessary battery drains. To this end, this paper proposes Mobilouds which encompass a multi-tier processing architecture with various levels of process cluster capacities and a software application to manage energy efficient utilization of such process clusters. Our proposed Mobilouds framework encourages the mobile device participation in the MCC collaborative execution, thereby reduces the presence of idle mobile resources and utilizes such idle resources in the actual task execution. Our performance evaluation results demonstrate that the Mobilouds framework offers the most energy-time balancing process clusters for task execution by effectively utilizing the available resources, in comparison with an entire cloud offloading strategy using 5G/4G networks."
  },
  {
    "year": "2016",
    "abstract": "Background subtraction is a popular technique for detecting objects moving across a fixed camera view. The performance of this paradigm is influenced by various challenges, such as object relocation, illumination change, cast shadows, waving background, camera shake, bootstrapping, camouflage, and so on. In this paper, we present a synopsis on the evolution of the background subtraction techniques over the last two decades. The different ways of mathematical modeling are taken into consideration to categorize the methods. We also evaluate the performance of some of the state-of-the-art techniques vis-a-vis the challenges associated. Eleven different algorithms of background subtraction have been simulated on thirty-four image sequences collected from five benchmark datasets. For each image sequence, seven performance metrics are evaluated and an exhaustive comparative analysis has been made to derive inferences. The potential findings in the result analysis are presented for future exploration. The obtained image and video results are uploaded athttps://sites.google.com/site/soaBSevaluation."
  },
  {
    "year": "2016",
    "abstract": "The development of base stations (BSs) with large aperture antenna arrays, enabled partially by the utilization of cmWave and mmWave frequency bands, will require radiated testing in fading conditions. In this paper, the objective is to investigate the suitable measurement distances and physical dimensions of the over-the-air setups for the performance evaluation of massive multiple-input multiple-output (MIMO) BSs in anechoic chambers with multiple probes. Setup dimension is the major cost factor in the test systems and is thus the key issue to be investigated. The purpose is to determine whether the conventional far field criteria must be followed when determining the range of the setup or if they can be relieved. The impact of limited test setup dimension on various metrics, e.g., far field criteria, field performance within the test area, system link budget analysis, direction of arrival estimation algorithm as well as multi-user MIMO sum-rate capacity are investigated to determine the range of the test setup. It was found that the link budget does not support for the measurement distances claimed by the Fraunhofer distance. Most of the utilized metrics, especially the sum rate capacity, indicate that smaller setup sizes can still yield reasonable measurement accuracy. Simulations were performed at 2.6, 3.5, and 28 GHz frequencies."
  },
  {
    "year": "2016",
    "abstract": "With the applications heterogeneous of Internet of Things (IoT) technology, the heterogeneous IoT systems generate a large number of heterogeneous datas, including videos and images. How to efficiently represent these images is an important and challenging task. As a local descriptor, the texton analysis has attracted wide attentions in the field of image processing. A variety of texton-based methods have been proposed in the past few years, which have achieved excellent performance. But, there still exists some problems to be solved, especially, it is difficult to describe the images with complex scenes from IoT. To address this problem, this paper proposes a multi-feature representation method called diagonal structure descriptor. It is more suitable for intermediate feature extraction and conducive to multi-feature fusion. Based on visual attention mechanism, five kinds of diagonal structure textons are defined by the color differences of diagonal pixels. Then, four types of visual features are extracted from the mapping sub-graphs and integrated into 1-D vector. Various experiments on three Corel-datasets demonstrate that the proposed method performs better than several state-of-the-art methods."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we consider a network in which lower power nodes (LPNs) are deployed jointly within macrocells. However, there are significant differences between the transmit power levels, coverage areas, and deployment densities of these two types of base stations. Such disparities lead to an unfair load distribution, as well as a lower throughput for picocells'users equipments (UEs). A good solution to such issues is the exploitation of the cell range expansion (CRE) technique. Although CRE has widely proven its effectiveness, it may degrade the network capacity if the cell bias is not chosen properly. In fact, it may generate severe intercell interference at extended region cell (ERC) UEs, which leads to a deterioration of their throughput. We thus propose a downlink coordinated cell range expansion for mobility management (CCREMM) strategy that analytically computes the joint optimal bias at picocells and macrocells. CCREMM mitigates the interference at ERC-UEs by accounting for their maximum tolerable interference. Moreover, CCREMM reaches the load balancing and the UE QoS satisfaction by accounting for additional parameters. It will be proven that our strategy which is associated with the maximum throughput scheduling technique, results in a cell load-balancing improvement, fairness, and a 50-90% UE throughput enhancement. These performance figures are shown to surpass those achieved by alternative approaches proposed in the existing literature."
  },
  {
    "year": "2016",
    "abstract": "Systems engineering of a satellite based data communication baseline concept is presented to achieve terabit per second throughput. It uses a constellation of five Molniya satellites and one dimension electronic scanning phased array ground terminals. The result is a baseline concept that meets customer needs for internet of things (IoT) data connectivity and for consumer high data rate internet access. Molniya orbit satellites provide the benefits of available bandwidth, lack of interference with other satellite links, and less crowded orbital paths. A drawback is that they are not geostationary since they have highly elliptical orbits. This requires ground station terminals with the ability track the satellites as they pass overhead during their orbit. However, since Molniya satellites with a properly selected eccentricity pass along the same path at nearly constant elevations relative to a fixed position on the Earth, simple and low-cost single axis scanning antennas can be used for the consumer ground terminal. This is a distinct advantage compared with competing low earth orbit constellations. The proposed solution leverages advances in semiconductor technology and low-cost antenna laminate substrate materials for an affordable phased array tracking ground terminal antenna. This paper presents link budget trade studies, system concept, orbital dynamics simulation results, and ground station component trade study."
  },
  {
    "year": "2016",
    "abstract": "The paper proposes a novel approach for direction estimation of a moving pedestrian as perceived in a 2-D coordinate of field camera. The proposed direction estimation method is intended for pedestrian monitoring in traffic control systems. Apart from traffic control, direction of motion estimation is also very important in accident avoidance system for smart cars, assisted living systems, in occlusion prediction for seamless tracking in visual surveillance, and so on. The proposed video-based direction estimation method exploits the notion of perspective distortion as perceived in monocular vision of 2-D camera co-ordinate. The temporal pattern of change in dimension of pedestrian in a frame sequence is unique for each direction; hence, the dimensional change-based feature is used to estimate the direction of motion; eight discrete directions of motion are considered and the hidden Markov model is used for classification. The experiments are conducted over CASIA Dataset A, CASIA Dataset B, and over a self-acquired dataset: NITR Conscious Walk Dataset. The balanced accuracy of direction estimation for these experiments yields satisfactory results with accuracy indices as 94.58%, 90.87%, and 95.83%, respectively. The experiment also justifies with suitable test conditions about the characteristic features, such as robustness toward improper segmentation, partial occlusion, and changing orientation of head or body during walk of a pedestrian. The proposed method can be used as a standalone system or can be integrated with existing frame-based direction estimation methods for implementing a pedestrian monitoring system."
  },
  {
    "year": "2016",
    "abstract": "Blind interference alignment (BIA) can greatly improve the degree of freedom with the infinite signal-to-noise ratio (SNR) assumption. Under the finite SNR condition, noise accumulation can have a significantly negative impact on SNR, inducing severe performance deterioration. In particular, in multi-cell networks, the transmitter to which a user connects can further affect its received SNR and the BIA design. To address such problem, we present a user grouping scheme for reducing noise accumulation in a single cell and analyze the impact of transmitter connections on the user grouping scheme. SNR BIA in a multi-cell network is further proposed, which jointly optimizes the transmitter connection and the user grouping scheme. Extensive simulations demonstrate that the achievable sum rate of SNR BIA is 1.36 times, 1.66 times, and 2.68 times that of data shared BIA, standard BIA, and extended BIA reported in the literature, respectively, and SNR BIA is more robust to user mobility."
  },
  {
    "year": "2016",
    "abstract": "Although the field of automatic speaker or speech recognition has been extensively studied over the past decades, the lack of robustness has remained a major challenge. Feature warping is a promising approach and its effectiveness significantly depends on the relative positions of each of the features in a sliding window. However, the relative positions are changed due to the non-linear effect of noise. Aiming at the problem, this paper takes the advantage of ranking feature, which is obtained directly by sorting a feature sequence in descending order, to propose a method. It first labels the central frame in a sliding window as speech or noise dominant (“reliable” or “unreliable”). In the unreliable case, the ranking of the central frame is estimated. Subsequently, the estimated ranking is mapped to a warped feature using a desired target distribution for recognition experiments. Through the theoretical analysis and experimental results, it is found that autocorrelation of a ranking sequence is larger than that of the corresponding feature sequence. What is more, rank correlation is not easily influenced by abnormal data or data that are highly variable. Thus, this paper deals with a ranking sequence rather than a feature sequence. The proposed feature enhancement approach is evaluated in an open-set speaker recognition system. The experimental results show that it outperforms missing data method based on linear interpolation and feature warping in terms of recognition performance in all noise conditions. Furthermore, the method proposed here is a feature-based method, which may be combined with other technologies, such as model-based, scores-based, to enhance the robustness of speaker or speech recognition system."
  },
  {
    "year": "2016",
    "abstract": "With the appearance of Global Navigation Satellite Systems spoofers, anti-spoofing has become a pressing issue. Intermediate spoofing is performed at a power only slightly higher than that of an authentic signal; therefore, it is quite difficult to detect counterfeit signals in real time via current detection methods. Multimodal detection is a well-known method for detecting counterfeit signals. However, it is often used in the acquisition stage, and thus, its effective time is very short. In this paper, we define the searching process as when the acquisition module does not need to find new signals. In addition, we utilize multimodal detection to detect intermediate spoofing in the acquisition module when performing the searching process, which is almost real time and can address the condition of arbitrary signal intervals. The acquisition module is used to monitor the signals that are being tracked; if we find at least two peaks above a threshold, we declare that counterfeit signals are detected. Then, we define an evaluation standard and provide a theoretical performance calculation method. An empirical formula is proposed to calculate the method's performance. By analyzing the effect of five influencing factors, we better understand the empirical formula and obtain the conclusion that, by decreasing the code phase's search step, we can obtain better detection results. The results are desirable for designing anti-spoofing receivers."
  },
  {
    "year": "2016",
    "abstract": "Methods to overcome metal artifacts in computed tomography (CT) images have been researched and developed for nearly 40 years. When X-rays pass through a metal object, depending on its size and density, different physical effects will negatively affect the measurements, most notably beam hardening, scatter, noise, and the non-linear partial volume effect. These phenomena severely degrade image quality and hinder the diagnostic power and treatment outcomes in many clinical applications. In this paper, we first review the fundamental causes of metal artifacts, categorize metal object types, and present recent trends in the CT metal artifact reduction (MAR) literature. To improve image quality and recover information about underlying structures, many methods and correction algorithms have been proposed and tested. We comprehensively review and categorize these methods into six different classes of MAR: metal implant optimization, improvements to the data acquisition process, data correction based on physics models, modifications to the reconstruction algorithm (projection completion and iterative reconstruction), and image-based post-processing. The primary goals of this paper are to identify the strengths and limitations of individual MAR methods and overall classes, and establish a relationship between types of metal objects and the classes that most effectively overcome their artifacts. The main challenges for the field of MAR continue to be cases with large, dense metal implants, as well as cases with multiple metal objects in the field of view. Severe photon starvation is difficult to compensate for with only software corrections. Hence, the future of MAR seems to be headed toward a combined approach of improving the acquisition process with dual-energy CT, higher energy X-rays, or photon-counting detectors, along with advanced reconstruction approaches. Additional outlooks are addressed, including the need for a standardized evaluation system to compare MAR metho..."
  },
  {
    "year": "2016",
    "abstract": "People's pursuit of higher quality communication has never ceased, which challenges the layout of 5G networks. Physical-layer network coding (PNC), as a key technology for 5G, supplies a powerful platform through leveraging the broadcast nature of wireless media. However, the symbol error rate (SER) of PNC is not well investigated, which would seriously influence user's quality of experience due to packet loss in wireless environment. In this paper, considering both phase and symbol misalignments, we perform analysis on SER of asynchronous PNC. By assuming part of information is known to the relay, and we derive the lower bound for SER. Afterward, through applying the concept of error vector and eliminating redundant terms, we derive the upper bound for SER. Both the lower and upper bounds are applicable to either multiuser detection-based network coding or belief propagation-based maximum a posteriori decoding. Finally, Monte Carlo simulation verifies our results and demonstrates that the bounds are relatively tight. The analytical results derived in this paper can facilitate future studies of practical and theoretical issues on PNC."
  },
  {
    "year": "2016",
    "abstract": "Industrial process monitoring and modeling represent a critical step in order to achieve the paradigm of zero defect manufacturing. The aim of this paper is to introduce the neo-fuzzy neuron method to be applied in industrial time series modeling. Its open structure and input independence provide fast learning and convergence capabilities, while assuring a proper accuracy and generalization in the modeled output. First, the auxiliary signals in the database are analyzed in order to find correlations with the target signal. Second, the neo-fuzzy neuron is configured and trained accordingly by means of the auxiliary signal, past instants, and dynamics information of the target signal. The proposed method is validated by means of real data from a Spanish copper rod industrial plant, in which a critical signal regarding copper refrigeration process is modeled. The obtained results indicate the suitability of the neo-fuzzy neuron method for industrial process modeling."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a stable millimeter-wave power monitoring system for ECRH on EAST tokamak. The real-time power monitoring was realized based on power monitor miter bends. The “Exchange”method was proposed to monitor the reflection power for RF protection. A cRIO-based signal process unit was designed, it is robust and has the response time of 1 μs. The power monitoring system was tested and the experimental results were discussed."
  },
  {
    "year": "2016",
    "abstract": "Cloudlet is a new paradigm in mobile cloud computing to provide resources to nearby mobile users via one-hop wireless connections. In this paper, we leverage the social tie structure among mobile users to achieve mutually beneficial computation offloading decision making, and hence, enhance the system-wide performance. Drawing on a social group utility maximization (SGUM) framework, we cast users' decision making of whether to offload or not as a Socially aware computation offloading game (COG). We study the SGUM-based COG for both strong and weak information cases. For the strong information case, where each user has the knowledge of other users' actions and the perfect observation of its achieved social group utility, we show that there exists a socially aware Nash equilibrium (SNE). We then design a distributed algorithm to achieve the SNE and quantify its performance gap with respect to the social optimal solution. For the weak information case, where each user does not have the knowledge of other users' actions and observes a noise-corrupted social group utility, we develop a distributed reinforcement learning algorithm, which is shown to converge almost surely to an ϵ-SNE. The numerical results show that the computation offloading performance can be significantly enhanced by leveraging the social ties among the users."
  },
  {
    "year": "2016",
    "abstract": "Studies of the stimulating effect of ultrasound as a tactile display have recently become more intensive in the haptic domain. In this paper, we present the design, development, and evaluation of Haptogram; a system designed to provide point-cloud tactile display via acoustic radiation pressure. A tiled 2-D array of ultrasound transducers is used to produce a focal point that is animated to produce arbitrary 2-D and 3-D tactile shapes. The switching speed is very high, so that humans feel the distributed points simultaneously. The Haptogram system comprises a software component and a hardware component. The software component enables users to author and/or select a tactile object, create a point-cloud representation, and generate a sequence of focal points to drive the hardware. The hardware component comprises a tiled 2-D array of ultrasound transducers, each driven by an FPGA. A quantitative analysis is conducted to measure the Haptogram ability to display various tactile shapes, including a single point, 2-D shapes (a straight line and a circle) and a 3-D object (a hemisphere). Results show that all displayed tactile objects are perceivable by the human skin (an average of 2.65 kPa for 200 focal points). A usability study is also conducted to evaluate the ability of humans to recognize 2-D shapes. Results show that the recognition rate was well above the chance level (average of 59.44% and standard deviation of 12.75%) while the recognition time averaged 13.87 s (standard deviation of 3.92 s)."
  },
  {
    "year": "2016",
    "abstract": "With the coming of the Internet of Things (IoT) and the fifth generation (5G) wireless communication era, more and more lightweight user equipments (UEs) appear in our life. The private information they gather and transmit on the uplink will likely face security risks, since the lightweight UEs are probably with limited number of antennas, e.g., only one antenna, limited power and low signal processing and data computing capabilities, which may inherently weaken the corresponding secrecy performance. As a consequence, traditional cryptographic techniques and complex physical layer security techniques with favorable secrecy performance may not be suitable for lightweight UEs due to high implementation complexity. Moreover, it is highly plausible that the unauthorized nodes can utilize much more powerful large antenna array, i.e., massive multiple-input multiple-output (MIMO) technology, to intercept the uplink information sent by the lightweight UEs due to the maturity of massive MIMO technology by then. Considering the possibility of facing massive MIMO eavesdropper, we propose to adopt the uplink original symbol phase rotated (UOSPR) scheme to secure the uplink transmission for lightweight single-antenna UEs in this paper. By employing the UOSPR secure transmission scheme, the lightweight UEs will randomly rotate the original information bearing symbols before they are transmitted to the BS on the uplink. This can be viewed as a symbol encryption process. The BS is then assured to be able to infer the accurate phase rotation and recover the original symbols while the massive MIMO eavesdropper can learn little useful information about the randomly rotated phase. The corresponding secrecy analysis of the UOSPR scheme on the uplink transmission is presented in detail. Furthermore, we show that the UOSPR scheme is with low complexity from the perspective of the lightweight UEs, which potentially makes it a candidate uplink secure transmission scheme in IoT and 5G scena..."
  },
  {
    "year": "2016",
    "abstract": "The imminent arrival of the Internet of Things (IoT), which consists of a vast number of devices with heterogeneous characteristics, means that future networks need a new architecture to accommodate the expected increase in data generation. Software defined networking (SDN) and network virtualization (NV) are two technologies that promise to cost-effectively provide the scale and versatility necessary for IoT services. In this paper, we survey the state of the art on the application of SDN and NV to IoT. To the best of our knowledge, we are the first to provide a comprehensive description of every possible IoT implementation aspect for the two technologies. We start by outlining the ways of combining SDN and NV. Subsequently, we present how the two technologies can be used in the mobile and cellular context, with emphasis on forthcoming 5G networks. Afterward, we move to the study of wireless sensor networks, arguably the current foremost example of an IoT network. Finally, we review some general SDN-NV-enabled IoT architectures, along with real-life deployments and use-cases. We conclude by giving directions for future research on this topic."
  },
  {
    "year": "2016",
    "abstract": "The cutting efficiency in underground excavations relies on the optimum parameters of the cutting tool and the cutting process. However, the optimization of the cutting tool design and the cutting process is a challenge and requires knowledge about the tool-rock interaction. This paper aims to investigate the tool-rock interaction using a rock cutting mathematical model. The confining pressure was considered in the rock cutting model with conical cutters and the discrete element method was adopted to calculate the dynamics of the rock breakage of this model. Graded particle assemblies were created, calibrated, and compressed in the horizontal direction with a certain confining pressure. Afterwards, the initiation and propagation of cracks during the rock cutting processes were recorded. A series of small-scale rock cutting tests were also carried out to verify the numerical model. The analysis results demonstrate that: 1) the confining pressure induced larger cutting force than that in the unconfined condition; 2) with increase of the confining pressure, the rock failure mode experienced predominantly brittle to predominantly ductile failure; and 3) there was a critical confining pressure/compressive strength ratio of 0.53 when the transition of failure mode occurred."
  },
  {
    "year": "2016",
    "abstract": "Existing optimization methods to heterogeneous redundancy allocation problem often suffer from the local-trap problem in optimization, due to the rugged energy landscapes. In this paper, a new optimization paradigm based on the Markov chain Monte Carlo sampling is proposed for solving the heterogeneous redundancy allocation for multi-state systems. We address this in an optimization-by-sampling framework, and propose to sample the intricate distribution over the combinatorial space by a doubly adaptive sampling approach, where the target adaptation favors free random walk on the rugged energy landscape to substantially alleviate the local-trap problem by updating the target distribution on-the-fly, while the proposal adaptation helps improve the sampling efficiency by learning the proposal distribution based on chain history in optimization. Experimental results performed on a range of benchmark instances demonstrated the superiority of the proposed optimization approach compared with the state-of-the-art alternatives in terms of the solution quality or computational efficiency."
  },
  {
    "year": "2016",
    "abstract": "Community question answering (CQA) site is an online community to provide valuable information in wide variety of topics in question-answer form to users'. The major problem with CQA lies in identifying the authoritative users in the domain of the question so as to route the question to right experts and selecting the best answer etc. The existing work suffers from one or more limitations such as: 1) lack of automatic mechanism to distinguish between authoritative and non-authoritative users in specified topics; 2) the high dependence on its training data in supervised learning which is too time-consuming process to obtain labeled samples of data manually; and 3) some approaches rely on using some cutoff parameters to estimate an authority score. In this paper, a parameterless mixture model approach is proposed to identify topical authoritative users to overcome the above-mentioned limitations. The statistical framework based on multivariate beta mixtures is utilized on feature vector of users' which is composed of information related to user activities on CQA site. The probability density function is therefore devised and the beta mixture component that corresponds to the most authoritative user is identified. The suitability of the proposed approach is illustrated on real data of two CQA sites: StackOverflow and AskUbuntu. The result shows that the proposed model is remarkable in identifying the authoritative users in comparison with conventional classifiers and Gaussian mixture model."
  },
  {
    "year": "2016",
    "abstract": "Over the last decade, mobile communications have been witnessing a noteworthy increase of data traffic demand that is causing an enormous energy consumption in cellular networks. The reduction of their fossil fuel consumption in addition to the huge energy bills paid by mobile operators is considered as the most important challenges for the next-generation cellular networks. Although most of the proposed studies were focusing on individual physical layer power optimizations, there is a growing necessity to meet the green objective of fifth-generation cellular networks while respecting the user's quality of service. This paper investigates four important techniques that could be exploited separately or together in order to enable wireless operators achieve significant economic benefits and environmental savings: 1) the base station sleeping strategy; 2) the optimized energy procurement from the smart grid; 3) the base station energy sharing; and 4) the green networking collaboration between competitive mobile operators. The presented simulation results measure the gain that could be obtained using these techniques compared with that of traditional scenarios. Finally, this paper discusses the issues and challenges related to the implementations of these techniques in real environments."
  },
  {
    "year": "2016",
    "abstract": "A variety of Web-based applications, mobile apps, and other over the top data services with affordable 3G/4G enabled smart devices are major factors for enormous increase in heterogeneous data traffic at enterprise and mobile networks. This creates challenges regarding traffic management and requires traffic-aware intelligent network management to deliver sustained quality of experience for subscribers. Deep packet inspection and analysis (DPIA) provides base platform for development of traffic-aware intelligent network management and security systems. However, computationally complex DPIA-related packet processing for high speed data traffic makes these systems expensive. Furthermore, conventionally these traffic-aware network management and security systems are deployed in enterprise networks with independent and dedicated DPIA-related processing resources and require multiple copies of passively provisioned high speed data from network, while performing similar DPIA operations over the same data again and again. This duplicate deployment of expensive software and hardware resources for DPIA processing eventually results in higher capital expenditures as well as operational expenditures for network operators. We have proposed a novel service-oriented framework for heterogeneous deep packet inspection and analysis (SoDPI) that simultaneously provides diversified DPIA services to multiple client applications for network management and security operations in high-speed networks. Proposed framework provides flexible and comprehensive API-based service interface for client applications to register required DPIA services. SoDPI framework implementation is based on commodity hardware and deploys shared set of DPIA-related packet processing components, requiring only single copy of passive data provisioned from network. Experimental evaluations show that novel SoDPI framework requires considerably reduced amount of software and hardware resources to fulfill heterogeneous ..."
  },
  {
    "year": "2016",
    "abstract": "In this paper, based on fractional calculus, the arbitrary-order fractor is proposed to implement the analog circuit realization of the arbitrary-order Fractional Hopfield Neural Networks (FHNNs) and the fractor-based FHNNs are first proposed to apply to the hardware security of defense against chip cloning attacks. Since the fractor is the most important circuit component needed to implement the FHNNs, the hardware achievement of the arbitrary-order fractor is the primary task and crux for the state-of-the-art application of the FHNNs to defense against chip cloning attacks. Motivated by this need, based on fractional calculus, the arbitrary-order fractor is proposed to implement the analog circuit realization of the arbitrary-order FHNNs and the fractor-based FHNNs are proposed to apply to defense against chip cloning attacks. The first step is the proposal for the analog circuit realization of an arbitrary-order FHNN. In particular, the hardware achievement of the arbitrary-order net-grid-type capacitive scaling fractor of the arbitrary-order FHNNs is chiefly analyzed in detail. The circuit configuration of the arbitrary-order net-grid-type scaling fractor can be achieved more convenient than any other discovered approximate implementation of the arbitrary-order fractor. Finally, the approximation performance of the arbitrary-order fractor of the FHNNs is analyzed, the arbitrary-order FHNNs are achieved by analog circuit realization, and its ability of defense against chip cloning attacks is illustrated in detail experimentally. The main contribution of this paper is the proposal for the first preliminary attempt of a feasible hardware implementation of the arbitrary-order FHNNs for defense against chip cloning attacks. Different order FHNNs can be achieved and distributed for different users, respectively. Thus, in a similar way to frequency band, order band can also be allocated efficiently that is another emerging promising electronic resource."
  },
  {
    "year": "2016",
    "abstract": "This paper explains the importance of accessing modern smart homes over the Internet, and highlights various security issues associated with it. This paper explains the evolution of device fingerprinting concept over time, and discusses various pitfalls in existing device fingerprinting approaches. In this paper, we propose a two-stage verification process for smart homes, using device fingerprints and login credentials, which verifies the user device as well as the user accessing the home over the Internet. Unlike any other previous approaches, our Device Fingerprinting algorithm considers a device's geographical location while computing its fingerprint. In our device identification experiment, we were able to successfully identify 97.93% of the devices that visited our Webpage using JavaScript, Flash, and Geolocation."
  },
  {
    "year": "2016",
    "abstract": "The heterogeneity, large scale, and resource constraint of IoT environment raise some issues which hinder its development. We focus on two issues among them: 1) most of the existing IoT applications are “silos”, that is, wireless sensor and actuator network resources and applications are tightly coupled, applications cannot share and reuse resources and interact with each other and 2) how to efficiently disseminate the sensing information among the information providers and consumers, and rapidly respond to changes in the physical world. This paper proposes a multilevel and multidimensional model-based service provisioning platform, which can access large-scale heterogeneous resources and expose their capabilities as light-weighted services. Moreover, it presents a unified message space to facilitate the on-demand dissemination and sharing of sensing information in distributed IoT environment. The platform supports applications to share and reuse resources and provides the basic infrastructure for the IoT application pattern: inner-domain autonomy and inter-domain coordination."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we propose a low-complexity group alternate iterative list (GAIL) detection algorithm for MIMO systems. By utilizing the recursive interference suppression and successive interference cancellation techniques, the symbol vector can be partitioned into many subgroups. Subsequently, symbols in each subgroup are detected in terms of the K-best detector. The inter-group interference is effectively mitigated in the GAIL algorithm by creating a candidate list and iteratively correcting the unreliable symbols for the detection result. We provide the performance-complexity tradeoff based on different feasible parameter settings. The numerical results demonstrate that the GAIL algorithm can achieve close-to-optimal performance while maintaining low computational complexity. In addition, the running speed of the GAIL algorithm can be dramatically increased using parallel processing in real-time communication systems."
  },
  {
    "year": "2016",
    "abstract": "We study physical layer security in two-cell wireless networks in which a base station (Alice) intends to send a confidential message to a legitimate user (Bob) with the help of a cooperative base station (Charlie), in the presence of an eavesdropper (Eve). Adaptive base station cooperation is explored to secure communication between Alice and Bob, and ensure the desired quality of service (QoS) at Charlie’s user. In particular, we consider two different scenarios where the channel state information of Eve is perfectly and statistically known, respectively. In either scenario, we provide a cooperative transmission scheme for secrecy rate maximization, subject to both security and QoS constraints. Unlike the conventional cooperative security with a fixed transmission scheme, we propose a mechanism for transmit strategy adaptation with security protection. Specifically, the cooperative transmission is replaced by a cooperative jamming scheme if either security or QoS constraint is not satisfied. Our design enables adaptive secure transmission, and thus is flexible and environment-adaptive. Moreover, numerical results confirm that our scheme is efficient in power resource utilization."
  },
  {
    "year": "2016",
    "abstract": "High-accuracy attitude estimation plays an important role in gliding with long endurance for an underwater glider. Because microelectromechanical system (MEMS) inertial sensors have advantages, including small size and low power consumption, they are used as main sensors to determine navigation information. However, in the complicated and harsh underwater environment, the performances of MEMS sensors degrade and errors will become larger. Moreover, acceleration or deceleration while gliders going up and down, sudden vibration of gliders due to inevitable disturbances will bring larger errors for sensors. So it is difficult to acquire the high accuracy attitude calculated by inertial measurement unit. In order to solve the above problem, first, a novel weight self-adjustment extended Kalman filtering method, which can adjust the weight autonomously through estimating adaptively measurement noise, is proposed to perform the optimal error estimation. Moreover, a fusion method that integrates the Adams implicit formula with the weight self-adjustment filtering method is proposed to achieve the more improvement in attitude estimation accuracy. The performance of this proposed algorithm is evaluated by the theoretical proofs and simulations. Subsequently, it is tested by the ship experiments and the lake trials. The results show that this proposed algorithm has a better performance in terms of attitude estimation accuracy than extended Kalman filtering (EKF)-only and self-adjustment EKF in this paper. Meanwhile, this algorithm has good robustness for attitude calculation even though pitch angle changes large."
  },
  {
    "year": "2016",
    "abstract": "Recently, a framework was given for linear error-correcting network codes (LENCs) over cyclic networks on commutative rings. When the alphabet is considered as a rational power series ring, an LENC is referred to as a convolutional error-correcting network code (CENC). Recently, a metric was introduced for these codes based on the minimum rank distance. In this paper, a new metric is introduced for ring-based LENCs over cyclic networks based on the Hamming distance, which is referred to as the network Hamming distance. Then, some connections between maximum distance separable (MDS) LENCs and classical MDS codes are obtained. Finally, the network Hamming free distance is given for CENCs, which plays the role of the free distance for convolutional codes."
  },
  {
    "year": "2016",
    "abstract": "Employment of ground-based positioning systems has been consistently growing over the past decades due to the growing number of applications that require location information where the conventional satellite-based systems have limitations. Such systems have been successfully adopted in the context of wireless emergency services, tactical military operations, and various other applications offering location-based services. In current and previous generation of cellular systems, i.e., 3G, 4G, and LTE, the base stations, which have known locations, have been assumed to be stationary and fixed. However, with the possibility of having mobile relays in 5G networks, there is a demand for novel algorithms that address the challenges that did not exist in the previous generations of localization systems. This paper includes a review of various fundamental techniques, current trends, and state-of-the-art systems and algorithms employed in wireless position estimation using moving receivers. Subsequently, performance criteria comparisons are given for the aforementioned techniques and systems. Moreover, a discussion addressing potential research directions when dealing with moving receivers, e.g., receiver's movement pattern for efficient and accurate localization, non-line-of-sight problem, sensor fusion, and cooperative localization, is briefly given."
  },
  {
    "year": "2016",
    "abstract": "Traditional wireless sensor networks (WSNs) face the problem of a limited-energy source, typically batteries, resulting in the need for careful and effective utilization of the energy source. However, inevitable energy depletion will eventually disturb the operation of a WSN. Energy harvesting (EH) technology is acquiring particular interest, because it has the potential to provide a continuous energy supply in battery-powered WSNs. Solar energy is the most effective environmental energy for EH-WSNs because of its high energy intensity, which comes from a non-controllable source. Therefore, the prediction of future energy availability is a critical issue, as the amount of the harvestable energy may vary over time. In this paper, a novel solar energy prediction algorithm with Q-learning, called Q-learning-based solar energy prediction (QL-SEP), is proposed. Q-learning is an effective way of predicting future actions based on past observations. The distinctive feature of QL-SEP is that not only past days' observations but also the current weather conditions are considered for prediction. The performance of QL-SEP is simulated in this paper using real-world measurements obtained from a solar panel in comparison with the state-of-art approaches."
  },
  {
    "year": "2016",
    "abstract": "Nonnegative matrix factorization (NMF) is a hot topic in machine learning and data processing. Recently, a constrained version, non-smooth NMF (NsNMF), shows a great potential in learning meaningful sparse representation of the observed data. However, it suffers from a slow linear convergence rate, discouraging its applications to large-scale data representation. In this paper, a fast NsNMF (FNsNMF) algorithm is proposed to speed up NsNMF. In the proposed method, it first shows that the cost function of the derived sub-problem is convex and the corresponding gradient is Lipschitz continuous. Then, the optimization to this function is replaced by solving a proximal function, which is designed based on the Lipschitz constant and can be solved through utilizing a constructed fast convergent sequence. Due to the usage of the proximal function and its efficient optimization, our method can achieve a nonlinear convergence rate, much faster than NsNMF. Simulations in both computer generated data and the real-world data show the advantages of our algorithm over the compared methods."
  },
  {
    "year": "2016",
    "abstract": "It is well known that droop control is fundamental to the operation of power systems and now the parallel operation of inverters, while phase-locked loops (PLLs) are widely adopted in modern electrical engineering. In this paper, it is shown at first that droop control and PLLs structurally resemble each other. This bridges the gap between the two communities working on droop control and PLLs. As a result, droop controllers and PLLs can be improved and further developed via adopting the advancements in the other field. This finding is then applied to operate the conventional droop controller for inverters with inductive output impedance to achieve the function of PLLs, without having a dedicated synchronization unit. Extensive experimental results are provided to validate the theoretical analysis."
  },
  {
    "year": "2016",
    "abstract": "Internet of Things is smartly changing various existing research areas into new themes, including smart health, smart home, smart industry, and smart transport. Relying on the basis of “smart transport,” Internet of Vehicles (IoV) is evolving as a new theme of research and development from vehicular ad hoc networks (VANETs). This paper presents a comprehensive framework of IoV with emphasis on layered architecture, protocol stack, network model, challenges, and future aspects. Specifically, following the background on the evolution of VANETs and motivation on IoV an overview of IoV is presented as the heterogeneous vehicular networks. The IoV includes five types of vehicular communications, namely, vehicle-to-vehicle, vehicle-to-roadside, vehicle-to-infrastructure of cellular networks, vehicle-to-personal devices, and vehicle-to-sensors. A five layered architecture of IoV is proposed considering functionalities and representations of each layer. A protocol stack for the layered architecture is structured considering management, operational, and security planes. A network model of IoV is proposed based on the three network elements, including cloud, connection, and client. The benefits of the design and development of IoV are highlighted by performing a qualitative comparison between IoV and VANETs. Finally, the challenges ahead for realizing IoV are discussed and future aspects of IoV are envisioned."
  },
  {
    "year": "2016",
    "abstract": "For every simple connected graph, we present a polynomial time algorithm for computing a numerical index, which is composed of primary and secondary parts. Given a graph G = (V, E) where V and E are, respectively, vertex and edge sets, the primary part of the index is a set of |V | fractions and the secondary part of the index is a set of |B| x |V| fractions, where B is the partition of the vertex set V. Basically, each fraction in the primary and secondary parts is the electrical resistance between two vertices when every edge in the graph is replaced with a unit resistor (1 Ω). The experimental results show that our indexing algorithm produced a unique index for every simple connected graph with ≤10 vertices, including all graphs that are counterexamples for detecting graph isomorphism by resistance spectrum comparison. The strength of our indexing algorithm lies in its extreme simplicity. An index of a graph is solely derived from the determinants of reduced Laplacian matrices, which represent the graph. Therefore, the performance of our indexing algorithm only depends on how fast the matrix determinants can be computed."
  },
  {
    "year": "2016",
    "abstract": "Data missing in collections of time series occurs frequently in practical applications and turns out to be a major menace to precise data analysis. However, most of the existing methods either might be infeasible or could be inefficient to predict the missing values in large-scale coevolving time series. Also, the evolving of time series needs to be handled properly to adapt to the temporal characteristic. Furthermore, more massive volume of data is generated in many areas than ever before. In this paper, we have taken up the challenge of missing data prediction in coevolving time series by employing temporal dynamic matrix factorization techniques. First, our approaches are optimally designed to largely utilize both the interior patterns of each time series and the information of time series across multiple sources to build an initial model. Based on the idea, we have imposed hybrid regularization terms to constrain the objective functions of matrix factorization. Then, temporal dynamic matrix factorization is proposed to effectively update the initial already trained models. In the process of dynamic matrix factorization, batch updating and fine-tuning strategies are also employed to build an effective and efficient model. Extensive experiments on real-world data sets and synthetic data set demonstrate that the proposed approaches can effectively improve the performance of missing data prediction. Even when the missing ratio reaches as high as 90%, our proposed methods still show low prediction errors. Dynamic performance demonstrates that the methods can obtain satisfactory effectiveness and efficiency. Furthermore, we have also demonstrated how to take advantage of the high processing power of Apache Spark to perform missing data prediction in large-scale coevolving time series."
  },
  {
    "year": "2016",
    "abstract": "Ultra-dense network (UDN) is considered as one of the most promising techniques in achieving the increasingly explosive growth of data rates for future 5G system. However, a large number of small cells lead to the increased cell edges and the rugged inter-cell interference, which cause frequent handover events and more radio link failure. In this paper, a local anchor-based dual connectivity (DC) architecture is proposed for a user-centric network based on the analysis of mobility management challenges of UDN. Under the proposed architecture, the local anchor acts as the master eNodeB (MeNB) with neighboring small cells acting as slave eNodeBs (SeNBs) to provide DC transmission for user-centric service following each user's movement. Key procedures for mobility management are correspondingly provided and both the MeNBs and SeNBs are selected from the small cells to investigate the potential of them, which are different from the mobility management methods under the traditional cellular architecture. Performance evaluations are conducted under different parameter configurations to evaluate the maximum potential of the proposed scheme. Simulation results show that in our proposed scheme, the handover failure rate shows a maximum decrease of more than 53% and the average user spectrum efficiency achieves an increase of 5% gains over the current LTE system when the user equipment speed is 3 km/h."
  },
  {
    "year": "2016",
    "abstract": "Patients have been known to regain consciousness during surgery while still paralyzed by the anesthesia and unable to communicate their distress. Recently, electronic engineers have helped resolve this problem by improving the real-time monitoring of depth of anesthesia. Electronic measurements of the brain's activity are used for many clinical and research purposes. This is possible because the brain uses electrochemical phenomena in order to process data. Many researchers have taken this to mean that advances in computer science will eventually result in sentient computers. Some conflate artificial consciousness with artificial intelligence even though consciousness and intelligence are not positively correlated. Those not trained in neurology, or at least medicine, understandably fail to comprehend what the rich, complex word “consciousness” actually means as a term of art. Human consciousness can only be evaluated with surrogate markers and is a broad and complex spectrum that ranges from minimally conscious to waking consciousness (what the reader is experiencing right now). The necessary conditions for waking consciousness include a brain in just the right electrical, chemical, and thermal states with sufficient blood pressure. These conditions, in turn, require the brain to have a body that is maintained in the right environment. Hence, waking consciousness is a proper subset of spectrum consciousness and cannot be considered an independent phenomenon capable of being disembodied or sliced off of the spectrum. The Theory of Mind (TOM) from developmental psychology infers that a brain similar to that of humans is a sufficient condition for spectrum consciousness. But this theory is precluded for computers because a child would not recognize a computer as being a living organism that is just like the child. Although TOM could be applied to an ideal android, there is a classic mathematical theorem from systems science that makes such an android seem infeasible."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a double sample data fusion method based on combination rules to improve the classification of dimensionless indices in petrochemical rotating machinery equipment. This method first collects the original data and counts the mutual dimensionless index as the body of evidence. The reliability of the body of evidence is then determined using a distance calculation method. Finally, the evidence reasoning method is used to fuse the mutual dimensionless index data based on reliability, and the type of fault is detected using the K-S test. A real-time data collection experiment shows that this method can identify the fault type for mutual dimensionless indices that have the appearance of coincidences or evidence conflicts. The experimental results also show that this method has a stronger ability to diagnose faults when compared with the K-nearest neighbor method, and exhibits an accuracy improvement of 9.45%."
  },
  {
    "year": "2016",
    "abstract": "We developed a crowd sensing application to estimate road conditions (CRATER). CRATER is a smartphone application that opportunistically measures acceleration when it finds itself on the road in order to map and measure the locations of potholes and speedbumps. It does not require input from users, but can report detected potholes and speedbumps to a cloud-hosted application engine, which stores partially processed data received from smartphones of participating users and jointly processes it to obtain a better estimate of road conditions. The information is published in map form on the web. This map allows both citizens and municipal authorities to localize potholes, road segments in need of repair, and imbalances in infrastructure maintenance efforts across cities. Road tests demonstrate that CRATER succeeds in correctly detecting roughly 90% of potholes and 95% of speedbumps, while generating false alarms only about 10% and 5% of the time, respectively."
  },
  {
    "year": "2016",
    "abstract": "Fast emerging mobile edge computing, mobile clouds, Internet of Things, and cyber physical systems require many novel realistic real-time multi-layer algorithms for a wide range of domains, such as intelligent content provision and processing, smart transport, smart manufacturing systems, and mobile end-user applications. This paper proposes a low-cost open source platform, MODiToNeS, which uses commodity hardware to support prototyping and testing of fully distributed multi-layer complex algorithms over real-world (or pseudoreal) traces. MODiToNeS platform is generic and comprises multiple interfaces that allow real-time topology and mobility control, deployment and analysis of different self-organized and self-adaptive routing algorithms, real-time content processing, and real-time environment sensing with predictive analytics. Our platform also allows rich interactivity with the user. We show deployment and analysis of two vastly different complex networking systems: a fault and disconnection-aware smart manufacturing sensor network and cognitive privacy for personal clouds. We show that our platform design can integrate both contexts transparently and organically and allows a wide range of analysis."
  },
  {
    "year": "2016",
    "abstract": "In low-power wireless neural recording tasks, signals must be compressed before transmission to extend battery life. Recently, compressed sensing (CS) theory has successfully demonstrated its potential in neural recording applications. In this paper, a deep learning framework of quantized CS, termed BW-NQ-DNN, is proposed, which consists of a binary measurement matrix, a non-uniform quantizer, and a non-iterative recovery solver. By training the BW-NQ-DNN, the three parts are jointly optimized. Experimental results on synthetic and real datasets reveal that BW-NQ-DNN not only drastically reduce the transmission bits but also outperforms the state-of-the-art CS-based methods. On the challenging high compression ratio task, the proposed approach still achieves high recovery performance and spike classification accuracy. This framework is of great values to wireless neural recoding devices, and many variants can be straightforwardly derived for low-power wireless telemonitoring applications."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on the fault detection problem of 2-D systems described by the Roesser model. To detect faults effectively in the presence of disturbances, a fault detection filter is designed to satisfy a finite-frequencyH−index and a finite-frequencyH∞index simultaneously. The corresponding finite-frequency performance analysis conditions are obtained by the aid of the generalized Kalman–Yakubovich–Popov lemma. Then, convex filter design conditions are derived by constructing a hyperplane tangent combined with linear matrix inequality techniques. An algorithm is proposed to construct a desired fault detection filter. Finally, a numerical example is given to show the effectiveness of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "Medical image-based research requires heavy computational workload associated with image analysis and collaborative device independent platforms to incorporate expert opinions from multiple institutions. Cloud-based resources such as Microsoft Azure Machine Learning Studio (MAMLS) provide such a platform that is conducive to the medical-image-based data analysis. This paper fosters the advantages of the cloud-based computing frameworks (such as MAMLS) and presents a practical work-flow well-suited for the standard machine learning tasks seen in medical image research viz., binary classification, multi-class learning, regression and so on. The proposed automated generalized workflow allows medical researchers/practitioners to focus on data inferencing rather than dealing with the intricate details of predictive modeling, such as feature and model selection. The scalable architecture of the proposed flow utilizes the MAMLS framework to processes data sets that require partial core storage space in the virtual machine to one complete core storage space in a common flow. Also, the proposed flow invokes multiple feature ranking and predictive models in parallel for automated selection and parameterization of the optimal data model. The performance of the proposed flow is bench-marked on 14 public data sets and four local medical image data sets (~0.12 MB-1.22 GB) using a single common flow, while ensuring better (~8% improvement) or atleast similar generalization capability with respect to existing works."
  },
  {
    "year": "2016",
    "abstract": "Many evolutionary multi-objective optimization (EMOs) methodologies have been proposed and shown a great potential in approximating the entire Pareto front. While in real world, what decision makers (DMs) want is one or several solutions to satisfy their requirements. It has become a hot problem that dynamically using preference information provided by DMs during the optimization process guides the search of EMO algorithms. An interactive reference region-based evolutionary algorithm through decomposition is proposed, denoted as RR-MOEA/D in this paper, which focuses the search on the desire of DMs to save computational resources. MOEA/D, as a well-known multi-objective optimization algorithm, is used as a basic framework here. In MOEA/D, by dealing with the sub-problems in the preference region and ignoring uninterested ones, the solutions obtained can converge to the regions which the DM prefers on the Pareto front and the computational complexity can be saved to a great extent. At each interaction, a humanized and simple interactive condition is adopted so that the reference region can be changed in a very intuitive way if the DM is unsatisfied the results in the interactive process. A rapid interaction is designed and a set of rough solutions can be obtained quickly whenever the preference information is changed. The proposed algorithm is tested on several benchmark problems and the experimental results show that the proposed algorithm can take full use of preference information and successfully converge to the reference region due to its reasonable and simple interaction mechanism."
  },
  {
    "year": "2016",
    "abstract": "Device-to-device (D2D) communication is a promising technology for 5G networks, providing high data rates, increased spectral and energy efficiency, and reduced end-to-end delay and transmission power. However, in current cellular systems, the performance of cell edge devices suffers when multimedia content is directly uploaded toward the base station side due to poor link quality. This requires a greater number of resource blocks and additional upload time, thus degrading the quality of service. To reduce the number of resource blocks and upload time, this paper proposes an efficient resource management scheme that exploits D2D communication in the uplink case. This scheme consists of two phases. In the first phase, in the case of poor link quality, a novel relay selection scheme is used in the multihop (two-hop) communication strategy; in the second phase, an effective new resource allocation scheme is used in multihop communication. This scheme minimizes packet loss, upload time, and number of resource blocks, whereas it increases the throughput of the network. Simulation result demonstrates the superiority of the proposed scheme over other schemes in the literature."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we explore the physical-layer security in a wireless network consisting of multiple user pairs in the face of multiple eavesdroppers, which are deployed by an adversary for tapping the confidential transmissions of the user pairs deliberately. We propose a friendly jammer-assisted user-pair selection (FJaUPS) scheme to improve the security-reliability tradeoff (SRT). Conventionally, a friendly jammer is used to transmit the artificial noise that is specially designed onto the null space of the main channel (spanning from the source to legitimate destination) for the sake of not interfering with the destination. However, due to the presence of the channel state information estimation error, it is impossible to guarantee that the artificial noise perfectly lies in the null space of the main channel, resulting in a certain interference received at the legitimate destination caused by the friendly jammer. Hence, the impacts of the friendly jammer on the legitimate user transmissions and eavesdroppers are taken into account for evaluating the wireless SRT performance, which are quantified by the so-called self-interfering factor and jamming factor, respectively. Moreover, we derive the SRT of the proposed FJaUPS, as well as the traditional round-robin schemes over Rayleigh fading channels. For comparison purposes, we also provide the SRT result of the conventional pure user-pair selection (PUPS) in computer simulations. In addition, it is shown that the proposed FJaUPS schemes outperform both the traditional round-robin and PUPS methods in terms of their SRT."
  },
  {
    "year": "2016",
    "abstract": "This paper considers an energy-limited cognitive relay network, where a secondary transmitter (ST) assists to forward the traffic from a primary transmitter (PT) to a primary receiver (PR), in exchange for serving its own secondary receiver (SR) in the same frequency. The multiple-antenna ST is assumed to be energy-constrained and powered by both information flow from source (PT) and dedicated energy streams from destinations (PR and SR), which is called a destination-aided wireless power transfer (DWPT) scheme. Then, the relay processing matrix, cognitive beamforming vector, and power splitter are jointly designed to maximize the rate of secondary users under the energy causality constraint and the constraint that the demanded rate of primary users is satisfied. For the perfect channel state information (CSI) case, by adopting the semi-definite relax technique and the Charnes-Cooper transformation, the global optimal solution is given. To reduce the complexity, matrix decomposition, zero forcing scheme, and dual method are jointly employed to derive a suboptimal solution. For the imperfect CSI case, the S-procedure is used to transform the worst case robust problem into a tractable semi-definite program. Simulation results reveal that our proposed DWPT scheme is greatly preferred for both perfect and imperfect CSI cases when ST is close to PR/SR."
  },
  {
    "year": "2016",
    "abstract": "The problem of distributed fault detection and isolation is investigated for heterogeneous discrete-time multi-agent systems with disturbances. A full-order observer is designed at a special agent to monitor its neighbour agents using local information. Via the technology of linear matrix inequalities, the sufficient conditions are given to ensure the estimation-error residual is robust to the disturbances. By utilizing the full-order observer, detection of the fault occurring at a single agent can be handled. At last, numerical simulations are employed to verify the effectiveness of the theoretically analyzed results."
  },
  {
    "year": "2016",
    "abstract": "Lifetime is a critical parameter in ubiquitous, battery-operated sensors for machine-to-machine (M2M) communication systems, an emerging part of the future Internet of Things. In this paper, the performance of radio frequency (RF) to DC energy converters using transparent and flexible rectennas based on graphene in an ambient RF energy-harvesting scenario is evaluated. Full-wave electromagnetic (EM) simulations of a dipole antenna assuming the reported state-of-the-art sheet resistance for few-layer, transparent graphene yields an estimated ohmic efficiency of 5%. In the power budget calculation, the low efficiency of transparent graphene antennas is an issue because of the relatively low amount of available ambient RF energy in the frequency bands of interest, which together sets an upper limit on the harvested energy available for the RF-powered device. Using a commercial diode rectifier and an off-the-shelf wireless system for sensor communication, the graphene-based solution provides only a limited battery lifetime extension. However, for ultra-low-power technologies currently at the research stage, more advantageous ambient energy levels, or other use cases with infrequent data transmission, graphene-based solutions may be more feasible."
  },
  {
    "year": "2016",
    "abstract": "Model-driven engineering has got a foothold in industry as an effective way to tame the complexity of modern software, which is meant to run on embedded systems with real-time constraints by promoting abstraction, in terms of prescriptive models, and automation, in terms of model manipulations. In the plethora of modeling languages, the unified modeling language (UML) has emerged and established itself as a de facto standard in industry, the most widely used architectural description language and an ISO/IEC standard. In the SMARTCore project, we have provided solutions for the UML-based development of software to run on multicore embedded real-time systems with the specific focus of automating the generation of executable code and the optimization of task allocation based on a unique combination of model-based and execution-based mechanisms. In this paper, we describe the lessons learned in the research work carried out within SMARTCore and provide a set of perspectives that we consider to be highly relevant for the forthcoming future of this research area to enable a wider adoption of UML-based development in industry in general, and in the multicore embedded real-time domain in particular."
  },
  {
    "year": "2016",
    "abstract": "In this paper, the convergence analysis and the improvement of the chicken swarm optimization (CSO) algorithm are investigated. The stochastic process theory is employed to establish the Markov chain model for CSO whose state sequence is proved to be finite homogeneous Markov chain and some properties of the Markov chain are analyzed. According to the convergence criteria of the random search algorithms, the CSO algorithm is demonstrated to meet two convergence criteria, which ensures the global convergence. For the problem that the CSO algorithm is easy to fall into local optimum in solving high-dimensional problems, an improved CSO is proposed, in which the relevant parameters analysis and the verification of optimization capability are made by lots of test functions in high-dimensional case."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a novel technology, namely, device-to-device communications in the unlicensed spectrum (D2D-U) is proposed, which can allow D2D users to transmit on the unlicensed spectrum and coexist with the incumbent Wi-Fi networks. In D2D-U networks, D2D users can share the licensed spectrum with the existing cellular users or share the unlicensed spectrum with legacy Wi-Fi networks. Therefore, mutual interference across different networks and different users should be properly coordinated to optimize the system performance. In this paper, within the framework of D2D-U, we propose a joint mode selection and resource allocation algorithm to minimize the overall interference that cellular and Wi-Fi users suffer from the D2D communications while guaranteeing the signal-to-noise-and-interference ratio requirements of all users, including those of cellular, D2D, and Wi-Fi. Through theoretical analysis and numerical simulation, we show that using unlicensed spectrum can significantly mitigate the interference to both cellular and Wi-Fi users. Moreover, the duty cycle-based unlicensed spectrum access method achieves better system throughput than the listen-before-talk-based access method in most of the cases."
  },
  {
    "year": "2016",
    "abstract": "Gray code application in distributed video coding (DVC) has been studied in the literature and it was claimed that DVC performance could be improved by Gray code because of stronger bitplane correlation presented. However, two factors are ignored in the literature, which renders the aforementioned claim untenable. These factors are log-likelihood ratio (LLR) computation and robustness to wrongly decoded bits, which may influence the DVC performance when different bit representations are used. This paper comprehensively evaluates the performances of Gray code in different DVC schemes, such as feedback channel-based transform domain Wyner-Ziv (FC_TDWZ) video coding, parallel pixel domain Wyner-Ziv video coding, and encoder rate control-based TDWZ (ERC_TDWZ). Experimental results suggest that the Gray code does not always improve the DVC performance, although stronger bitplane correlation is presented. In particular, the performance of FC_TDWZ with Gray code is exactly the same as that with natural bit code, because the same magnitudes of LLRs are obtained. Moreover, the reconstruction quality of the WZ frames in ERC_TDWZ is improved by Gray code not because of stronger bitplane correlation but because Gray code is more robust to wrongly decoded bits induced by rate underestimation. However, these RD gains are quite limited when the rate is controlled accurately at the encoder."
  },
  {
    "year": "2016",
    "abstract": "Current generation mobile wireless communication networks are not suitable for real-time positioning applications because timing information is not readily available. Fifth generation (5G) cellular networks provide device to device real-time communications which can be used for real-time positioning. Millimeter-wave (mmWave) transmission is regarded as a key technology in 5G networks. In this paper, several 73-GHz mmWave waveforms are investigated. A new threshold selection algorithm for energy detector-based ranging is proposed which employs a dynamic threshold based on an artificial neural network. The positioning performance using this algorithm with mmWave waveforms is investigated."
  },
  {
    "year": "2016",
    "abstract": "Non-orthogonal multiple access (NOMA) has recently been considered as a key enabling technique for 5G cellular systems. In NOMA, by exploiting the channel gain differences, multiple users are multiplexed into transmission power domain and then non-orthogonally scheduled for transmission on the same spectrum resources. Successive interference cancellation (SIC) is then applied at the receivers to decode the message signals. In this paper, first, we briefly describe the differences in the working principles of uplink and downlink NOMA transmissions in a cellular wireless system. Then, for both uplink and downlink NOMAs, we formulate a sum-throughput maximization problem in a cell such that the user clustering (i.e., grouping users into a single cluster or multiple clusters) and power allocations in NOMA clusters can be optimized under transmission power constraints, minimum rate requirements of the users, and SIC constraints. Due to the combinatorial nature of the formulated mixed integer non-linear programming problem, we solve the problem in two steps, i.e., by first grouping users into clusters and then optimizing their respective power allocations. In particular, we propose a low-complexity sub-optimal user grouping scheme. The proposed scheme exploits the channel gain differences among users in an NOMA cluster and groups them into a single cluster or multiple clusters in order to enhance the sum-throughput of the system. For a given set of NOMA clusters, we then derive the optimal power allocation policy that maximizes the sum-throughput per NOMA cluster and in turn maximizes the overall system throughput. Using Karush-Kuhn-Tucker optimality conditions, closed-form solutions for optimal power allocations are derived for any cluster size, considering both uplink and downlink NOMA systems. Numerical results compare the performances of NOMA and OMA and illustrate the significance of NOMA in various network scenarios."
  },
  {
    "year": "2016",
    "abstract": "Free space optical (FSO) systems are capable of supporting high data rates between fixed points in the context of flawless video communications. Layered video coding facilitates the creation of different-resolution subset layers for variable-throughput transmission scenarios. In this paper, we propose historical information aware unequal error protection (HA-UEP) for the scalable high efficiency video codec used for streaming over FSO channels. In particular, the objective function (OF) of the current video frame is designed based on historical information of its dependent frames. By optimizing this OF, specific subset layers may be selected in conjunction with carefully selected forward error correction coding rates, where the expected video distortion is minimized and the required bitrate is reduced under the constraint of a specific throughput. Our simulation results show that the proposed system outperforms the traditional equal error protection (EEP) scheme by about 4.5 dB of Eb/N0at a peak signal-to-noise ratio of 33 dB. From a throughput-oriented perspective, HA-UEP is capable of reducing the throughput to about 30% compared with that of the EEP benchmarker, while achieving an Eb/N0gain of 4.5 dB."
  },
  {
    "year": "2016",
    "abstract": "We present the design and simulation of a frequency-diverse aperture for imaging of human-size targets at microwave wavelengths. Predominantly relying on a frequency sweep to produce diverse radiation patterns, the frequency-diverse aperture provides a path to all-electronic operation, sampling a scene without the requirement for mechanical scanning or expensive active components. Similar to other computational imaging schemes, the frequency diverse aperture removes many hardware constraints by placing an increased burden on processing and analysis. While proof-of-concept simulations of scaled-down versions of the frequency-diverse imager and simple targets can be performed with relative ease, the end-to-end modeling of a full-size aperture capable of fully resolving human-size targets presents many challenges, particularly if parametric studies need to be performed during a design or optimization phase. Here, we show that an in-house developed simulation code can be adapted and parallelized for the rapid design and optimization of a full-size, frequency-diverse aperture. Using files of human models in stereolithography format, the software can model the entire imaging scenario in seconds, including mode generation and propagation, scattering from the human model, and measured backscatter. We illustrate the performance of several frequency-diverse aperture designs using images of human-scale targets reconstructed with various algorithms and compare with a conventional synthetic aperture radar approach. We demonstrate the potential of one aperture for threat object detection in security-screening applications."
  },
  {
    "year": "2016",
    "abstract": "Applications of perceptual image quality assessment (IQA) in image and video processing, such as image acquisition, image compression, image restoration, and multimedia communication, have led to the development of many IQA metrics. In this paper, a reliable full reference IQA model is proposed that utilize gradient similarity (GS), chromaticity similarity (CS), and deviation pooling (DP). By considering the shortcomings of the commonly used GS to model the human visual system (HVS), a new GS is proposed through a fusion technique that is more likely to follow HVS. We propose an efficient and effective formulation to calculate the joint similarity map of two chromatic channels for the purpose of measuring color changes. In comparison with a commonly used formulation in the literature, the proposed CS map is shown to be more efficient and provide comparable or better quality predictions. Motivated by a recent work that utilizes the standard DP, a general formulation of the DP is presented in this paper and used to compute a final score from the proposed GS and CS maps. This proposed formulation of DP benefits from the Minkowski pooling and a proposed power pooling as well. The experimental results on six data sets of natural images, a synthetic data set, and a digitally retouched dataset show that the proposed index provides comparable or better quality predictions than the most recent and competing state-of-the-art IQA metrics in the literature, it is reliable and has low complexity. The MATLAB source code of the proposed metric is available athttps://dl.dropboxusercontent.com/u/74505502/MDSI.m."
  },
  {
    "year": "2016",
    "abstract": "As a promising paradigm for the fifth generation wireless communication (5G) system, the fog radio access network (F-RAN) has been proposed as an advanced socially aware mobile networking architecture to provide high spectral efficiency (SE) while maintaining high energy efficiency (EE) and low latency. Recent advents are advocated to the performance analysis and radio resource allocation, both of which are fundamental issues to make F-RANs successfully rollout. This paper comprehensively summarizes the recent advances of the performance analysis and radio resource allocation in F-RANs. In particular, the advanced edge cache and adaptive model selection schemes are presented to improve SE and EE under maintaining a low latency level. The radio resource allocation strategies to optimize SE and EE in F-RANs are, respectively, proposed. A few open issues in terms of the F-RAN-based 5G architecture and the social-awareness technique are identified as well."
  },
  {
    "year": "2016",
    "abstract": "We consider a multi-cell multiple-input multiple-output full-duplex (FD) system, where multiple FD capable base stations (BSs) serve multiple mobile users operating in FD mode. The self-interference at the BSs and users, and co-channel interference (CCI) between all the nodes (BSs and users) in the system are both taken into account. We consider the transmit and receive filter design for sum-rate maximization problem subject to sum-power constraints at the BSs and individual power constraints at each user of the system under the limited dynamic range considerations at the transmitters and the receivers. By reformulating this non-convex problem as an equivalent multi-convex optimization problem with the addition of two auxiliary variables, we propose a low complexity alternating algorithm that converges to a stationary point. Since this sum-rate maximization results in starvation of users in terms of resources depending on the power of the self-interference and CCI channels, we modify the sum-rate maximization problem by adding target data rate constraints on each user, and propose an algorithm based on Lagrangian relaxation of the rate constraints."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a thorough experimental study on key generation principles, i.e., temporal variation, channel reciprocity, and spatial decorrelation, through a testbed constructed by using wireless open-access research platform. It is the first comprehensive study through: 1) carrying out a number of experiments in different multipath environments, including an anechoic chamber, a reverberation chamber, and an indoor office environment, which represents little, rich, and moderate multipath, respectively; 2) considering static, object moving, and mobile scenarios in these environments, which represents different levels of channel dynamicity; and 3) studying two most popular channel parameters, i.e., channel state information and received signal strength. Through results collected from over a hundred tests, this paper offers insights to the design of a secure and efficient key generation system. We show that multipath is essential and beneficial to key generation as it increases the channel randomness. We also find that the movement of users/objects can help introduce temporal variation/randomness and help users reach an agreement on the keys. This paper complements existing research by experiments constructed by a new hardware platform."
  },
  {
    "year": "2016",
    "abstract": "Practically, no knowledge exists on the effects of speech coding and recognition for narrow-band transmission of speech signals within certain frequency ranges especially in relation to the recognition of paralinguistic cues in speech. We thus investigated the impact of narrow-band standard speech coders on the machine-based classification of affective vocalizations and clinical vocal recordings. In addition, we analyzed the effect of speech low-pass filtering by a set of different cut-off frequencies, either chosen as static values in the 0.5-5-kHz range or given dynamically by different upper limits from the first five speech formants (F1-F5). Speech coding and recognition were tested, first, according to short-term speaker states by using affective vocalizations as given by the Geneva Multimodal Emotion Portrayals. Second, in relation to long-term speaker traits, we tested vocal recording from clinical populations involving speech impairments as found in the Child Pathological Speech Database. We employ a large acoustic feature space derived from the Interspeech Computational Paralinguistics Challenge. Besides analysis of the sheer corruption outcome, we analyzed the potential of matched and multicondition training as opposed to miss-matched condition. In the results, first, multicondition and matched-condition training significantly increase performances as opposed to mismatched condition. Second, downgrades in classification accuracy occur, however, only at comparably severe levels of low-pass filtering. The downgrades especially appear for multi-categorical rather than for binary decisions. These can be dealt with reasonably by the alluded strategies."
  },
  {
    "year": "2016",
    "abstract": "Cooperative communication has used to be a hot topic and it has been studied extensively in the past 10 years, but in recent years, it becomes less likely to find substantial innovation in this field as before. In this paper, we propose a new hybrid decode-forward and amplify-forward with non-orthogonal multiple access (NOMA) (HDAF-NOMA) transmission scheme for a cellular system with multiple relays. To the best of our knowledge, this is the first work that attempts to integrate decode-forward (DF), amplify-forward, and NOMA into one strategy design to improve system performance. To verify the performance advantages, the proposed HDAF-NOMA scheme is compared with the other four traditional schemes in terms of channel capacity and average system throughput, and the optimal number of selected DF relays is also determined for the HDAF-NOMA scheme. Simulation results show that compared with the traditional schemes, the proposed HDAF-NOMA scheme can achieve larger sum channel capacity for the transmission of x1and x2, and it can also achieve larger average system throughput at high SNR region."
  },
  {
    "year": "2016",
    "abstract": "Sensors play a very important role in the Internet of Things. Error correction is of great significance to achieve sensor precision. Currently, accurately predicting the future dynamic measurement error is an effective way to improve sensor precision. Aiming to solve the problem of low model accuracy in traditional dynamic measurement error prediction, this paper employs the support vector machine (SVM) to predict the dynamic measurement error of sensors. However, the performance of the SVM depends on setting the appropriate parameters. Hence, the cuckoo search (CS) algorithm is adopted to optimize the key parameters to avoid the local minimum value which can occurs when using the traditional method of parameter optimization. To validate the predictive performance of the proposed CS-SVM model, the dynamic measurement error data for two sensors are applied to establish a predictive model. The root mean squared error and the mean absolute percentage error are employed to evaluate the models' performances. These results are also compared with those obtained from the SVM optimized by a grid search and the particle swarm optimization method. The experiments show that the SVM model based on the CS algorithm achieves more accurate prediction and is more effective in predicting dynamic measurement errors for sensors than the previous models."
  },
  {
    "year": "2016",
    "abstract": "A novel joint source and channel coding (JSCC) scheme is proposed, which we refer to as the reordered Elias gamma error correction (REGEC) code. Like the recently proposed unary error correction (UEC) code and EGEC code, the proposed code facilitates the practical near-capacity transmission of source symbol values that are randomly selected from a large or infinite alphabet. However, in contrast to the UEC code, both the EGEC and our proposed REGEC codes are universal codes, facilitating the transmission of source symbol values that are randomly selected using any monotonic probability distribution. However, the EGEC code has a complicated structure comprising two parts, where unequal error protection is required to balance the two parts with the aid of a specific parameterization that must be tailored to the source distribution, preventing its employment for unknown or non-stationary sources. By contrast, the proposed REGEC code does not need unequal error protection, and hence its parameterization does not have to be tailored to the particular source distribution, and thus the REGEC code is a more attractive scheme. More explicitly, our REGEC code has a simple structure comprising only a single part, which does not suffer from the delay and loss of synchronization that are associated with the two parts of the EGEC code. In a particular practical scenario, where the source symbols obey a specific Zeta probability distribution, our REGEC scheme is shown to offer gains of up to 0.9 dB over the best of JSCC and separate source and channel coding (SSCC) benchmarkers, when QPSK modulation is employed for transmission over an uncorrelated narrowband Rayleigh fading channel. In the scenario where the source symbols obey the distribution produced by the H.265 video codec, our REGEC scheme is shown to offer a gain of 0.7 dB over the SSCC benchmarker. These gains are achieved for free, without increasing the required transmit-duration, transmit-bandwidth, transmit-energy, or..."
  },
  {
    "year": "2016",
    "abstract": "The filter bank multicarrier with offset quadrature amplitude modulation (FBMC/OQAM) is being studied by many researchers as a key enabler for the fifth-generation air interface. In this paper, a hybrid peak-to-average power ratio (PAPR) reduction scheme is proposed for FBMC/OQAM signals by utilizing multi data block partial transmit sequence (PTS) and tone reservation (TR). In the hybrid PTS-TR scheme, the data blocks signal is divided into several segments, and the number of data blocks in each segment is determined by the overlapping factor. In each segment, we select the optimal data block to transmit and jointly consider the adjacent overlapped data block to achieve minimum signal power. Then, the peak reduction tones are utilized to cancel the peaks of the segment FBMC/OQAM signals. Simulation results and analysis show that the proposed hybrid PTS-TR scheme could provide better PAPR reduction than conventional PTS and TR schemes in FBMC/OQAM systems. Furthermore, we propose another multi data block hybrid PTS-TR scheme by exploiting the adjacent multi overlapped data blocks, called as the multi hybrid (M-hybrid) scheme. Simulation results show that the M-hybrid scheme can achieve about 0.2-dB PAPR performance better than the hybrid PTS-TR scheme."
  },
  {
    "year": "2016",
    "abstract": "Multi-focus image fusion is an important technique that extracts sharp regions from multiple images and composites them into a fully focused image. In this paper, a novel spatial domain-based fusion algorithm for multi-focus images through gradient-based decision map construction and mathematical morphology is proposed. The contributions of this paper are: 1) a weighted kernel based on image gradient is proposed to measure focus regions; 2) the boundaries between focus and defocus regions are adjusted by morphological operations and free boundary condition-based active contour model. Though the weighted kernel, the focus regions are roughly identified. Moreover, after the morphological operations and the adjustment of boundaries using active contour model, the true boundaries between the focused and defocused regions are extracted. The experimental results demonstrate that the proposed algorithm performs better than the other eight representative fusion algorithms in both the qualitative and quantitative evaluations."
  },
  {
    "year": "2016",
    "abstract": "This paper addresses the establishment of secure communication links between Alice and Bob in the presence of an eavesdropper (Eve). The proposed scenario assumes: 1) MIMOME wiretap channel; 2) transmit antenna selection at the Alice; 3) no channel state information at the transmitter; 4) fixed Wyner codes; and 5) guarantee of secure throughput by both quality of service and secrecy outage constraints. We propose a simple protocol to enhance security via transmit antenna selection, and then assess its performance in a closed form by means of secrecy outage and successful transmission probabilities. We assume these probabilities are our constraints and then maximize the secure throughput, establishing a security-reliability tradeoff for the proposed scenario. Our numerical results illustrate the effect of this tradeoff on the secure throughput as well as on the number of antennas at Alice, Bob, and Eve. Interestingly, a small sacrifice in reliability allows secrecy enhancement in terms of secure bps/Hz. We apply this idea in our smart grid application (where Alice represents a smart meter and Bob an aggregator) to exemplify that, although Eve may acquire some samples of the average power demand of a household, it is not enough to properly reconstruct such curve."
  },
  {
    "year": "2016",
    "abstract": "Mobile edge computing (MEC) is a promising paradigm to provide cloud-computing capabilities in close proximity to mobile devices in fifth-generation (5G) networks. In this paper, we study energy-efficient computation offloading (EECO) mechanisms for MEC in 5G heterogeneous networks. We formulate an optimization problem to minimize the energy consumption of the offloading system, where the energy cost of both task computing and file transmission are taken into consideration. Incorporating the multi-access characteristics of the 5G heterogeneous network, we then design an EECO scheme, which jointly optimizes offloading and radio resource allocation to obtain the minimal energy consumption under the latency constraints. Numerical results demonstrate energy efficiency improvement of our proposed EECO scheme."
  },
  {
    "year": "2016",
    "abstract": "Network coding (NC) constitutes a promising technique of improving the throughput of relay-aided networks. In this context, we propose a cross-layer design for both amplify-and-forward and decode-and-forward two-way relaying based on the NC technique invoked for improving the achievable throughput under specific quality of service requirements, such as the maximum affordable delay and error rate. We intrinsically amalgamate adaptive analog network coding (ANC) and network coded modulation (NCM) with truncated Automatic Repeat reQuest (ARQ) operating at the different open system interconnection layers. At the data-link layer, we design a pair of improved NC-based ARQ strategies based on the stop-and-wait and the selective-repeat ARQ protocols. At the physical layer, adaptive ANC/NCM are invoked based on our approximate packet error ratio. We demonstrate that the adaptive ANC design can be readily amalgamated with the proposed protocols. However, adaptive NC-QAM suffers from an SNR-loss, when the transmit rates of the pair of downlink channels spanning from the relay to the pair of destinations are different. Therefore, we develop a novel transmission strategy for jointly selecting the optimal constellation sizes for both of the relay-to-destination links that have to be adapted to both pair of channel conditions. Finally, we analyze the attainable throughput, demonstrating that our truncated ARQ-aided adaptive ANC/NCM schemes attain considerable throughput gains over the schemes dispensing with ARQ, while our proposed scheme is capable of supporting bidirectional NC scenarios."
  },
  {
    "year": "2016",
    "abstract": "The primary goal of this paper is the optimization of data transmissions and connections between 5G base stations (BSs) as well as the improvement of access technologies and transmission methods in consideration of massive multi-input multi-output, a key technology in 5G networks. In order to reach an access technology supported by multiple BSs and small cells, we use 5G millimeter wave (mmWave), due to its high directivity and sensitivity to blockage, to enhance the connection system. In the simulation, we will consider extremely high-frequency band and small angle of mmWave, and arrange obstructions in the environment in view of high attenuation characteristics in mmWave signals. After a wave beam penetrates through a wall, the power of the wave sharply decreases. For reduction of energy consumption, the wave therefore will select an mmWave BS with poor signal quality but without blockage to transmit data. Because the number of macro-cells will affect the communication quality and the computational complexity, this paper especially focuses on three factors of a network: delay, capacity, and path loss, and purposes to figure out the most energy-efficient BS densities for 5G-based green communications."
  },
  {
    "year": "2016",
    "abstract": "Machine-to-machine communication over long-term evolution advanced (LTE-A) network has emerged as a new communication paradigm to support a variety of applications of Internet of Things. One of the most effective techniques to accommodate a large volume of machine type communication (MTC) devices in LTE-A is clustering where devices (nodes) are grouped into number of clusters and forward their traffics to the base station (e.g., LTE eNodeB) through some special nodes called cluster heads (CHs). In many applications, the CHs change location with time that causes variation in distances between neighboring CHs. When these distances increase, the performance of data transmission may degrade. To address this issue, we propose to employ intermediate non-CH nodes as relays between neighboring CHs. Our solution covers many aspects from relay selection to cooperative formation to meet the user's QoS requirements. As the number of total relay plays a significant role in cooperative communications, we first design a rateless-coded-incremental-relay selection algorithm based on greedy techniques to guarantee the required data rate with a minimum cost. After that, we develop both source-feedback and non-source-feedback-based fountain coded cooperative communication protocols to facilitate the data transmission between two neighbor CHs. Numerical results are presented to demonstrate the performance of these protocols with different relay selection methods under Rayleigh fading channel. It shows that the proposed source-feedback-based protocol outperforms its non-source-feedbackprotocol counterpart in terms of a variety of metrics."
  },
  {
    "year": "2016",
    "abstract": "Interference management is one of the most critical issues in underlaying device-to-device (D2D) communication due to the coexistence of D2D pairs and cellular users that operate under the same spectrum. In this paper, we provide the interference management algorithm to maximize the performance of the D2D communication while satisfying the quality-of-service requirements of the cellular communications in both uplink and downlink phases. The proposed algorithm includes: 1) the admission control and power allocation to ensure that the interference from D2D communication does not affect to the cellular communications and 2) the shared channel assignment to maximize the total throughput of the D2D communication. We prove that our proposed algorithm can achieve at least half of the performance of optimal algorithm. The simulation results validate the feasibility, convergence, and optimality of our algorithm: it cannot only closely approximate the optimal throughput of D2D communication but also outperform existing algorithms."
  },
  {
    "year": "2016",
    "abstract": "The skyline path query is a novel extension of skyline queries. A skyline path query retrieves a set of non-dominated paths from origin s to destination t. On a road network using multiple path criteria, such as the distance, travel time, and number of travelers on a path, this paper extends the concept of skyline path query by considering a new type of criteria referred to as the aggregate attribute of paths. The method used for calculating this type of criteria is very different from that of existing criteria, and this can have a notable effect on the processing of ordinary skyline path queries. This paper defines the aggregate attributes of paths, discusses the impact of aggregate attributes on skyline path queries, and proposes a novel index tree with an intelligent algorithm to find the skyline path while taking aggregate attributes into account. Experiments demonstrate the effectiveness and efficiency of the proposed algorithm."
  },
  {
    "year": "2016",
    "abstract": "In X-ray computed tomography (CT), the presence of metallic parts in patients causes serious artifacts and degrades image quality. Many algorithms were published for metal artifact reduction (MAR) over the past decades with various degrees of success but without a perfect solution. Some MAR algorithms are based on the assumption that metal artifacts are due only to strong beam hardening and may fail in the case of serious photon starvation. Iterative methods handle photon starvation by discarding or underweighting corrupted data, but the results are not always stable and they come with high computational cost. In this paper, we propose a high-kVp-assisted CT scan mode combining a standard CT scan with a few projection views at a high-kVp value to obtain critical projection information near the metal parts. This method only requires minor hardware modifications on a modern CT scanner. Two MAR algorithms are proposed: dual-energy normalized MAR (DNMAR) and high-energy embedded MAR (HEMAR), aiming at situations without and with photon starvation respectively. Simulation results obtained with the CT simulator CatSim demonstrate that the proposed DNMAR and HEMAR methods can eliminate metal artifacts effectively."
  },
  {
    "year": "2016",
    "abstract": "A branch of robotics, variable impedance actuation, along with one of its subfields variable stiffness actuation (VSA), is gaining momentum recently. There have been many thorough studies earlier in the design and recently in the control of these systems. The performance of these systems is mainly limited by their physical constraints, such as actuator nominal torque and maximum elastic element stiffness. This paper discusses the integration of reaction wheels to VSA systems and using reactive torques to improve the performance of the combined system. Since the compliant nature of VSA mechanisms is often associated with cyclic motion, reactive torques can be used to amplify the robot motion and accumulate more energy in the elastic elements in a given period of time. After presenting our modeling and control framework for reaction wheel-integrated VSA robots, we benchmark the performance of a reaction wheel-integrated VSA system using an explosive ball throwing task. Specifically, extensive simulation and real-world experiments are conducted with three different configurations: VSA-only, reaction wheel-only, and reaction wheel-integrated VSA. The results of these experiments show the benefits of reaction wheel-integrated VSA robots compared with the two other configurations."
  },
  {
    "year": "2016",
    "abstract": "Massive expansion of wireless body area networks (WBANs) in the field of health monitoring applications has given rise to the generation of huge amount of biomedical data. Ensuring privacy and security of this very personal data serves as a major hurdle in the development of these systems. An effective and energy friendly authentication algorithm is, therefore, a necessary requirement for current WBANs. Conventional authentication algorithms are often implemented on higher levels of the Open System Interconnection model and require advanced software or major hardware upgradation. This paper investigates the implementation of a physical layer security algorithm as an alternative. The algorithm is based on the behavior fingerprint developed using the wireless channel characteristics. The usability of the algorithm is established through experimental results, which show that this authentication method is not only effective, but also very suitable for the energy-, resource-, and interface-limited WBAN medical applications."
  },
  {
    "year": "2016",
    "abstract": "Sarcasm is a sophisticated form of irony widely used in social networks and microblogging websites. It is usually used to convey implicit information within the message a person transmits. Sarcasm might be used for different purposes, such as criticism or mockery. However, it is hard even for humans to recognize. Therefore, recognizing sarcastic statements can be very useful to improve automatic sentiment analysis of data collected from microblogging websites or social networks. Sentiment Analysis refers to the identification and aggregation of attitudes and opinions expressed by Internet users toward a specific topic. In this paper, we propose a pattern-based approach to detect sarcasm on Twitter. We propose four sets of features that cover the different types of sarcasm we defined. We use those to classify tweets as sarcastic and non-sarcastic. Our proposed approach reaches an accuracy of 83.1% with a precision equal to 91.1%. We also study the importance of each of the proposed sets of features and evaluate its added value to the classification. In particular, we emphasize the importance of pattern-based features for the detection of sarcastic statements."
  },
  {
    "year": "2016",
    "abstract": "Several approaches have been proposed to anonymize relational databases using the criterion of k-anonymity, to avoid the disclosure of sensitive information by re-identification attacks. A relational database is said to meet the criterion of k-anonymity if each record is identical to at least (k - 1) other records in terms of quasi-identifier attribute values. To anonymize a transactional database and satisfy the constraint of k-anonymity, each item must successively be considered as a quasi-identifier attribute. But this process greatly increases dimensionality, and thus also the computational complexity of anonymization, and information loss. In this paper, a novel efficient anonymization system called PTA is proposed to not only anonymize transactional data with a small information loss but also to reduce the computational complexity of the anonymization process. The PTA system consists of three modules, which are the Pre-processing module, the TSP module, and the Anonymity model, to anonymize transactional data and guarantees that at least k-anonymity is achieved: a pre-processing module, a traveling salesman problem module, and an anonymization module. Extensive experiments have been carried to compare the efficiency of the designed approach with the state-of-the-art anonymization algorithms in terms of scalability, runtime, and information loss. Results indicate that the proposed PTA system outperforms the compared algorithms in all respects."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a distributed “Win-Win” reciprocal-selection-based medium access scheme (DWWRS-MAS) is designed for a cooperative spectrum leasing system hosting multiple licensed transmission pairs and multiple unlicensed transmission pairs. Based on the proposed DWWRS-MAS, the primary transmitter (PT) intends to lease its spectral resources to an appropriate secondary transmitter (ST) in exchange for cooperative transmission assistance for the sake of minimizing its transmit power and simultaneously satisfying its transmit rate requirement. The ST has an incentive to collaborate with the best PT for the sake of minimizing the ST's transmit power under the constraint of its Quality of Service (QoS) requirement, while simultaneously winning a transmission opportunity for its own traffic. Moreover, based on the matching theory and queueing theory, we analyze the algorithmic stability and the queueing stability of the cooperative spectrum leasing system exploiting our DWWRS-MAS, respectively. Simulation results demonstrate that our DWWRS-MAS is capable of providing both considerable energy savings and substantial rate improvements for the cooperative spectrum leasing system hosting multiple licensed transmission pairs and multiple unlicensed transmission pairs."
  },
  {
    "year": "2016",
    "abstract": "The design and real-time hardware-in-the-loop implementation of a hybrid synchrophasors and GOOSE-based automatic synchronization algorithm are presented in this paper. Automatic synchronization is performed by utilizing the synchrophasor measurements from two commercial phasor measurement units (PMUs), while the coordinated control commands to automatic voltage regulator and/or turbine governor control and trip command to the circuit breaker are issued using IEC 61850-8-1 GOOSE messages. The algorithm is deployed inside the PMU using the protection logic equations, and direct communication between the PMUs is established to minimize the communication latencies. In addition, the algorithm is tested using a standard protection relay test-set, and automatic test sequences are executed to validate its performance. It is concluded that the hybrid synchrophasor and GOOSE-based automatic synchronization scheme ensures minimum communication latencies, reduces equipment cost, facilitates interoperability, and performs automatic reconnection adequately."
  },
  {
    "year": "2016",
    "abstract": "A revolutionary effort to seek fundamental improvement of 802.11, known as IEEE 802.11ax, has been approved to deliver the next-generation wireless local area network (WLAN) technologies. In WLANs, medium access control protocol is the key component that enables efficient sharing the common radio channel while satisfying the quality of service (QoS) requirements for multimedia applications. With the new physical layer design and subsequent new medium access control functions under more demands on QoS and user experience, in this paper, we first survey the QoS support in legacy 802.11. Then, we summarize the IEEE 802.11ax standardization activities in progress and present an overview of current perspectives and expected features on medium access control protocol design to better support QoS and user experience in 802.11ax. We present the motivation behind, explain design principles, and identify new research challenges. To better satisfy customer needs on high bandwidth and low latency, emerging long-term evolution licensed-assisted access and its impacts to QoS provisioning in IEEE 802.11ax are further addressed given the collaboration between cellular and WLANs, and given the trend of 5G cellular over unlicensed bands."
  },
  {
    "year": "2016",
    "abstract": "A community question answering (CQA) site is a well-known online community, where user interacts on a wide variety of topics. To the best of our knowledge, the selection of a best answer for the question asked on the CQA site is done manually, which is traditional and tedious. In this paper, a model is developed for selecting best answer for the question asked on the CQA site. Instead of taking data related to question-answer only into account as done in manual process, this model takes both question-answer and answerers' data into account, which gives an insight view into the answers given by the experts that is more likely to be selected as the best answer. The presented approach analyzes StackOverflow Q&A posts with at least five answers to extract features for pattern identification using which the best answer is selected for the asked questions based on topic modeling and classifier. To evaluate correctness of the proposed model, a set of parameters are used, such as Receiver Operating Characteristics Area Under Curve, Precision Recall Area Under Curve, Gmean, and Accuracy. Results show that the proposed model is effective in predicting the best answer."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the uplink of multi-user massive multi-input multioutput (MIMO) systems with a mixed analog-to-digital converter (ADC) receiver architecture, in which some antennas are equipped with costly full-resolution ADCs and others with less expensive low-resolution ADCs. A closed-form approximation of the achievable spectral efficiency (SE) with the maximum-ratio combining detector is derived. Based on this approximated result, the effects of the number of base station (BS) antennas, the transmit power, the proportion of full-resolution ADCs in the mixed-ADC structure, and the number of quantization bits of the low-resolution ADCs are revealed. Results show case that the achievable SE increases with the number of BS antennas and quantization bits, and it converges to a saturated value in the high user power regime or the full ADC resolution case. Most important, this work efficiency verifies that for a massive MIMO, the mixed-ADC receiver with a small fraction of full-resolution ADCs can have comparable SE performance with the receiver with all full-resolution ADCs but at a considerably lower hardware cost."
  },
  {
    "year": "2016",
    "abstract": "Ultra wideband (UWB) technology is suitable for high data rate short range wireless communication, localization, and imaging techniques. However, UWB systems require high sampling rate and precise synchronization. In order to reduce the sampling rate, have precise synchronization, and for low power requirement, UWB systems are implemented using compressive or sub-Nyquist rate measured samples by exploiting the sparsity of the UWB signal. Compressive sensing (CS)-based UWB systems are being designed in two ways: 1) signal demodulation or detection is performed in the CS domain without full signal recovery at the front-end. Thus, demodulation or detection works on compressive measurements. However, system performance deteriorates in the CS domain as compared with full Nyquist rate sampling and 2) after, Nyquist rate signal is recovered using efficient algorithms at the front-end, the signal demodulation or detection is performed using the conventional receiver. Thus, one requires an efficient CS/sampling of signal measurement at the front-end for better system performance for both the cases stated earlier. In this paper, we propose a deterministic (partial) UWB waveform-matched measurement matrix. The proposed measurement matrix has a circulant structure and is sparse in nature. The proposed matrix is easy to implement in hardware and is operationally time efficient as needed in a practical system. The bit error rate performance of the corresponding UWB system and the operational time complexity with the proposed measurement matrix are better as compared with the existing measurement matrices in the CS domain for both the above receiver designs. The efficacy of the proposed measurement matrix is verified through extensive simulations in both the additive white Gaussian noise and multipath communication environments. In addition, we have also compared other desirable properties of the proposed measurement matrix with the existing measurement matrices."
  },
  {
    "year": "2016",
    "abstract": "With the prevalence of smart devices, such as smart phones, wearable equipments, and infrastructures, location-based service (LBS) has thrived in our daily life. In those practical LBS applications, group detection and tracking is a context-related research field in many scenarios, such as school yard, office building, shopping mall and so on. In this paper, we heuristically develop a temporal-spatial method for clustering and locating the groups, and then leverage a CRF-based event detection mechanism to improve the performance of recognizing contextual behaviors. The experimental results demonstrate that our system can achieve an impressive accuracy and precision of grouping and tracking."
  },
  {
    "year": "2016",
    "abstract": "Taking mining fleet constituted by a shearer, hydraulic supports and a scraper conveyor as the object, the mining fleet needs to move to the intended position in accordance with the functional requirements, such as machinery tracking of hydraulic supports and memory cutting of the shearer. This paper proposes a shearer wireless positioning method under the conditions of inaccurate anchor nodes. First, action rules for hydraulic supports and an adaptive height adjustment strategy for the shearer are arranged based on analyzing the cooperative movement of mining fleet. Second, the duality mapping between local strong signal sets and positioning spatial domain is revealed, and inaccurate anchor nodes can be refined using the memory cutting and motion constraints of mining fleet. Third, an extended Cramer-Rao lower bound is derived to seek the inherent relationships among shearer positioning accuracy, multi-source errors, and coordinate errors of anchor nodes. Finally, comprehensive experiments for the analytical accuracy assessment and node configuration of shearer positioning are achieved with the support of memory cutting technology. Research results indicate that the proposed shearer positioning can satisfy the requirements of mining fleet, which can provide the theoretical basis for the collaborative automation of mining fleet on fully mechanized mining face."
  },
  {
    "year": "2016",
    "abstract": "Time series analysis is an important data mining task in areas such as the stock market and petroleum industry. One interesting problem in knowledge discovery is the detection of previously unknown frequent patterns. With the existing types of patterns, some similar subsequences are overlooked or dissimilar ones are matched. In this paper, we define patterns with weak-wildcard gaps to represent subsequences with noise and shift, and design efficient algorithms to obtain frequent and strong patterns. First, we convert a numeric time series into a sequence according to the data fluctuation. Second, we define the pattern mining with weak-wildcard gaps problem, where a weak-wildcard matches any character in an alphabet subset. Third, we design an Apriori-like algorithm with an efficient pruning technique to obtain frequent and strong patterns. Experimental results show that our algorithm is efficient and can discover frequent and strong patterns."
  },
  {
    "year": "2016",
    "abstract": "Reduced heart rate variability (HRV) is an indicator of a malfunctioning autonomic nervous system. Resonant frequency breathing is a potential non-invasive means of intervention for improving the balance of the autonomic nervous system and increasing HRV. However, such breathing exercises are regarded as boring and monotonous tasks. The use of gaming elements (gamification) or a full gaming experience is a well-recognised method for achieving higher motivation and engagement in various tasks. However, there is limited documented knowledge on how to design a game for breathing exercises. In particular, the influence of additional interactive elements on the main course of training has not yet been explored. In this paper, we evaluated the satisfaction levels achieved using different game elements and how disruptive they were to the main task, i.e., paced breathing training. An Android flight game was developed with three game modes that differ in the degrees of multitasking they require. Design, development, and evaluation were conducted using a user-centred approach, including context analysis, the design of game principle mock-ups, the selection of game principles through a survey, the design of the game mechanics and GUI mock-up, and icon testing, and the performance of a summative study through user questionnaires and interviews. A summative evaluation of the developed game was performed with 11 healthy participants (ages 40-67) in a controlled setting. The results confirm the potential of video games for motivating players to engage in HRV biofeedback training. The highest training performance on the first try was achieved through pure visualisation rather than in a multitasking mode. Players had higher motivation to play the more challenging game and were more interested in long-term engagement. A framework for gamified HRV biofeedback research is presented. It has been shown that multitasking has considerable influence on HRV biofeedback and should be used wit..."
  },
  {
    "year": "2016",
    "abstract": "Epilepsy is a brain disorder, where patients' lives are extremely disturbed by the occurrence of sudden unpredictable seizures. This paper develops patient-independent signal processing techniques based on common spatial patterns and linear discriminant analysis to detect epileptic activities (spikes) from multi-channel brain signal recordings. In contrast to current existing studies which heavily rely on the analysis of electroencephalogram (EEG) data for the detection of epileptic activities, this research work considers magnetoencephalography (MEG) recordings for the detection of epileptic spikes. This requires careful development since unlike EEG spikes, MEG spikes do not have well-defined morphological characteristics. Due to the recent advances in MEG technology, it became possible to consider MEG signals to detect and analyze epileptic activities, but efforts to develop signal processing tools in this area are still in its outset, as compared with those devoted to EEG signal processing."
  },
  {
    "year": "2016",
    "abstract": "Correlation analysis is one of the most important tasks in the field of visualization research and data mining. This paper proposes a novel dissimilarity-preserving cluster algorithm that characterizes not only the time-varying patterns but also the spatial positions to summary the correlation connection in multi-variable and time-varying data sets. A temporal multi-variable structure is defined to express temporal information of a voxel in multi-dimensional space. Furthermore, a method based on structural similarity index measurement is proposed to compute the difference of time-varying pattern. In order to further explore some abnormal phenomena, spatial similarity is embedded as spatial distance metric by building the kernel density estimate for the neighborhood of each voxel. To verify the effectiveness of the method, the voxels are classified based on the time-varying similarity and spatial distance. Moreover, the combinations of two metrics are rebalanced to be suitable for the different datasets. The approach proposed in this paper is used on both synthetic and real-world data sets to demonstrate its usefulness and effectiveness."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a placement algorithm for fault location observability using phasor measurement units (PMUs) in the presence or absence of zero injection buses. The problem is formulated as a binary semidefinite programming (BSDP) model with binary decision variables, minimizing a linear objective function subject to linear matrix inequality (LMI) observability constraints. The model is extended to take into account the unavailability or limited capacity of communication links at some PMU installation buses. The BSDP problem is solved using an outer approximation scheme based on binary integer linear programming. The method is illustrated with a 6-bus test system. Numerical simulations are conducted on the IEEE 14-, 30-, and 57-bus standard test systems to verify the effectiveness of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "Accurate depth estimation is still an important challenge after a decade, particularly from stereo images. The accuracy comes from a good depth level and preserved structure. For this purpose, a depth post-processing framework is proposed in this paper. The framework starts with the “Adaptive Random Walk with Restart (2015)” algorithm. To refine the depth map generated by this method, we introduced a form of median solver/filter based on the concept of the mutual structure, which refers to the structural information in both images. This filter is further enhanced by a joint filter. Next, a transformation in image domain is introduced to remove the artifacts that cause distortion in the image. The proposed post-processing method is then compared with the top eight algorithms in the Middlebury benchmark. To explore how well this method is able to compete with more widely known techniques, a comparison is performed with Google's new depth map estimation method. The experimental results demonstrate the accuracy and efficiency of the proposed post-processing method."
  },
  {
    "year": "2016",
    "abstract": "Effective emergency (such as a hurricane, a building on fire, and so on) response requires accurate, relevant, timely, and location-aware information (e.g., environmental information, health records, and so on). Acquiring information in such critical situations encounters substantial challenges, such as large volume of data processing, unstructured data, privacy, authorized data access, and so forth. Among the issues, access authorization has received little attention. Existing solutions for data authorization either do not scale well or merely consider a Break-the-Glass concept in which a master key is provided to the first responders (FRs) to decrypt the corresponding ciphertext. This may not only enable unauthorized users to access information, but it may also overwhelm FRs by the large volume of accessible data. To jointly address the aforementioned issues, this paper proposes a location-aware authorization scheme that enables FRs to access information provided that they are within a predefined distance from data owners at the time of an emergency. We innovatively integrate attribute-based encryption with broadcast encryption to incorporate dynamic attributes (i.e., location and time) into an access policy. Such attributes act as filters to eliminate data irrelevant to an ongoing emergency. As a result, our scheme provides authorized access to accurate, relevant, timely, and location-aware information. We provide extensive security analysis and performance evaluations to demonstrate the effectiveness of our scheme. The analysis shows that the scheme imposes constant communication and decryption computation overheads. Furthermore, the proposed scheme is proven chosen plain-text attack selectively secure based on m-bilinear Diffie-Hellman exponent assumption. It also addresses the key escrow problem."
  },
  {
    "year": "2016",
    "abstract": "Internet use has seriously affected individual health in potential and subtle ways. Past research on the subject mainly concentrated on the mental health caused by addictive use, e.g., impulse control disorders and obsessive-compulsive disorder. With the constant development of cyber technology, Internet has been an indispensable element of living and working, which can provide more convenient and efficient support and help. At the same time, the effects of Internet use more than Internet addiction on individual health cannot be ignored in living and working. This paper aims to identify the most common physical complaints associated with Internet use, and further investigate the association between the frequency of Internet use and individual physical health. Five hundred and thirteen participants completed the questionnaires by online or offline manner, which covers demographic questions and questions concerning Internet use and physical complaints. The most common complaints were involving dry eyes, decreased vision, and cervical pain. The positive pearson correlation coefficient were found between the level of physical complaints and the frequency of Internet use, place of residence and education. Especially, the higher amount of time for the Internet use is strongly associated with a higher level of physical complaints."
  },
  {
    "year": "2016",
    "abstract": "The general-purpose networks-on-chip (GP-NoC) has recently attracted the attention of the research and industry as a way to support the growing demands of computing systems. The design and the development of the communications and networking functions for such a large-scale versatile systems require knowledge of the traffic exchanged between the computing nodes. The object of the study in this paper is the last-level shared cache interface that is likely to be a traffic bottleneck in future GP-NoC architectures. First, using the direct measurements, we report on the stochastic traffic properties at large-scales, provide first two moments and distribution functions. Complementing measurements with fine-grained cycle-accurate CPU simulations, we then analyze the small-scale traffic behavior. We show that even for the simplest applications such as reading or writing of data, the nature of the traffic is stochastic, depends on the number of active cores, and irrespective of the application type, has an explicit batch structure. We further reveal that the batch sizes and inter-batch intervals can be well approximated by geometric distribution and the approximation becomes better when the number of active cores increases. These properties identify a simple arrival model that can be used in the analytical or simulation-based performance evaluation studies of the shared interface technologies in prospective NoCs."
  },
  {
    "year": "2016",
    "abstract": "Collecting data via a questionnaire and analyzing them while preserving respondents' privacy may increase the number of respondents and the truthfulness of their responses. It may also reduce the systematic differences between respondents and non-respondents. In this paper, we propose a privacy-preserving method for collecting and analyzing survey responses using secure multi-party computation. The method is secure under the semi-honest adversarial model. The proposed method computes a wide variety of statistics. Total and stratified statistical counts are computed using the secure protocols developed in this paper. Then, additional statistics, such as a contingency table, a chi-square test, an odds ratio, and logistic regression, are computed within the R statistical environment using the statistical counts as building blocks. The method was evaluated on a questionnaire data set of 3158 respondents sampled for a medical study and simulated questionnaire data sets of up to 50 000 respondents. The computation time for the statistical analyses linearly scales as the number of respondents increases. The results show that the method is efficient and scalable for practical use. It can also be used for other applications in which categorical data are collected."
  },
  {
    "year": "2016",
    "abstract": "Stereo matching is one of the most important and challenging subjects in the field of stereo vision. The disparity obtained in stereo matching can represent depth information in 3-D world to a great extent and shows great importance in stereo field. In general, stereo-matching methods primarily emphasize static image. However, the information provided by dynamic scene can be used fully and effectively to improve the results of stereo matching for dynamic scene, such as video sequences. In this paper, we propose a dynamic scene-based local stereo-matching algorithm which integrates a cost filter with motion flow of dynamic video sequences. In contrast to the existing local approaches, our algorithm puts forward a new computing model which fully considers motion information in dynamic video sequences and adds motion flow to calculate suitable support weight for accurately estimating disparity. Our algorithm can perform as an edge-preserving smoothing operator and shows improved behavior near the moving edges. The experimental results show that the proposed method achieves a better depth map and outperforms other local stereo-matching methods in disparity evaluation."
  },
  {
    "year": "2016",
    "abstract": "The wireless sensor network (WSN) is one of the key enablers for the Internet of Things (IoT), where WSNs will play an important role in future internet by several application scenarios, such as healthcare, agriculture, environment monitoring, and smart metering. However, today's radio spectrum is very crowded for the rapid increasing popularities of various wireless applications. Hence, WSN utilizing the advantages of cognitive radio technology, namely, cognitive radio-based WSN (CR-WSN), is a promising solution for spectrum scarcity problem of IoT applications. A major challenge in CR-WSN is utilizing spectrum more efficiently. Therefore, a novel channel access scheme is proposed for the problem that how to access the multiple channels with the unknown environment information for cognitive users, so as to maximize system throughput. The problem is modeled as I.I.D. multi-armed bandit model with M cognitive users and N arms (M<;N). In order to solve the competition and the fairness between cognitive users of WSNs, a fair channel-grouping scheme is proposed. The proposed scheme divides these channels into M groups according to the water-filling principle based on the learning algorithm UCB-K index, the number of channels not less than one in each group and then allocate channel group for each cognitive user by using distributed learning algorithm fairly. Finally, the experimental results demonstrate that the proposed scheme cannot only effectively solve the problem of collision between the cognitive users, improve the utilization rate of the idle spectrum, and at the same time reflect the fairness of selecting channels between cognitive users."
  },
  {
    "year": "2016",
    "abstract": "Two-tier networks combining an operator-managed infrastructure of macrocell base stations combined with a user-deployed network of femtocells have recently emerged in the context of modern wireless standards as a solution to meet the ambitious performance requirements envisaged in 4G/5G architectures. Most often, these systems require interference coordination schemes that allow near universal frequency reuse while maintaining a considerably high signal-to-interference-plus-noise ratio levels across the coverage area. In particular, fractional frequency reuse (FFR) and its variants are deemed to play a fundamental role in the next generation of cellular systems. This paper develops an analytical framework targeting the downlink performance evaluation of FFR-aided orthogonal frequency division multiple access-based two-tier heterogeneous networks. In the considered scenario, macrocell and femtocell tiers are assumed to be uncoordinated and co-channel deployed, thus representing a worst-case scenario in terms of inter-tier interference. The proposed framework allows the evaluation of the impact produced by both inter- and co-tier interferences on the performance of either the macro-users (MUs) or the femto-users. Analytical results are used to optimize the FFR parameters as a function of, for example, the density of MUs per cell, the resource block scheduling policy, the density of femto base stations per area unit, or the degree of isolation provided by wall penetration losses. Moreover, different optimization designs of the FFR component are proposed that allow a tradeoff between throughput performance and fairness by suitably dimensioning the FFR inner and outer areas and the corresponding frequency allocation."
  },
  {
    "year": "2016",
    "abstract": "An algorithm is proposed for the detection and joint estimation of target parameters for a radar with a two-element rotating antenna. Rotation of the antenna introduces unwanted effects, which may cause inaccuracy in the parameter estimation. Target detection is performed by adding the processed data from two sensors. Joint estimation of range, Doppler, and direction of arrival (DOA) is carried while compensating the effects of antenna rotation. The detection performance is analyzed in terms of the receiver operating characteristics. Analytical expressions of Cramer-Rao Bound for Doppler, the range and DOA are derived. Computational complexity is also discussed. A simulation demonstrates and verifies the proposed algorithm and its analyses."
  },
  {
    "year": "2016",
    "abstract": "We present the design of a dual failure protected elastic optical network (EON) for different sharing capabilities of protection lightpaths. Routing and spectrum assignment (RSA) is considered for such a network so as to minimize the maximum number of frequency slots (FSs) used. The key principles for protection resource sharing among the first and the second protection lightpaths are identified for dedicated 1:1:1, mixed 1:1:1, 1+1:1, and 1+1+1 protection. Both integer linear programming (ILP) models and spectrum window plane (SWP)-based heuristic algorithms are proposed for RSA in dual failure protected EONs. Simulation results indicate that, apart from being efficient, the proposed SWP-based heuristic algorithm not only performs close to the ILP model but also does much better than a benchmark adaptive routing algorithm. We find that 1:1:1 protection technique performs better in terms of the maximum number of FSs used and the spare capacity redundancy than both the 1+1:1 and 1+1+1 techniques. In addition, the mixed 1:1:1 case outperforms the dedicated 1:1:1 case both in minimizing the maximum number of link FSs used and its spare capacity redundancy."
  },
  {
    "year": "2016",
    "abstract": "Heterogeneous networks (HetNets) supported with relays and device to device communication can be considered as a promising solution to realize the ambitious targets of the future fifth generation networks in terms of energy efficiency and capacity. HetNets necessitate optimal power allocation, spectrum resource allocation, and cell selection to meet the quality of service requirements. In this paper, we formulate energy efficiency maximization problem in terms of resource allocation and cell selection for HetNets, where objective is to maximize the network throughput per unit network power consumption. Formulated optimization problem is non-linear fractional programming problem. We use Charnes-Cooper transformation to convert proposed fractional programming problem into concave optimization problem. We propose outer approximation algorithm (OAA) to solve the converted concave optimization problem. The proposed algorithm is evaluated by extensive simulation work. The performance of ε-optimal solution obtained by OAA method is shown for different network parameters, such as number of users, required date rate, and capacity of network."
  },
  {
    "year": "2016",
    "abstract": "In this paper, radio-frequency (RF) electromagnetic field (EMF) exposure evaluations are conducted in the frequency range 10-60 GHz for array antennas intended for user equipment (UE) and low-power radio base stations in 5G mobile communication systems. A systematic study based on numerical power density simulations considering effects of frequency, array size, array topology, distance to exposed part of human body, and beam steering range is presented whereby the maximum transmitted power to comply with RF EMF exposure limits specified by the International Commission on Non-Ionizing Radiation Protection, the US Federal Communications Commission, and the Institute of Electrical and Electronics Engineers is determined. The maximum transmitted power is related to the maximum equivalent isotropically radiated power to highlight the relevance of the output power restrictions for a communication channel. A comparison between the simulation and measurement data is provided for a canonical monopole antenna. For small distances, with the antennas transmitting directly toward the human body, it is found that the maximum transmitted power is significantly below the UE power levels used in existing third and fourth generation mobile communication systems. Results for other conceivable exposure scenarios based on technical solutions that could allow for larger output power levels are also discussed. The obtained results constitute valuable information for the design of future mobile communication systems and for the standardization of EMF compliance assessment procedures of 5G devices and equipment."
  },
  {
    "year": "2016",
    "abstract": "A new joint spatial and classic symbol alphabet is designed for spatial modulation (SM)-based multiple-input multiple-output systems. The employment of multiple active antennas instead of a single active antenna is proposed for increasing the achievable throughput and the joint design of the antenna selection and classic transmit symbol is explored, while maintaining the compelling advantages of SM. This framework combines the bit-to-antenna mapping and classic bit-to-constellation mapping into a single function, which defines the joint-alphabet and the joint optimization of the amplitude-phase modulation and its constellation for transmission over multiple active antennas. The conventional SM system is also interpreted within our framework. An example design is proposed, which aims for a high spectral efficiency of 11 b per channel use, achieving a gain of up to 5 dB over generalized SM (GSM)."
  },
  {
    "year": "2016",
    "abstract": "Thousands of recipes, representing different national cuisines, from the siterecipesource.comwere analyzed with the aim of understanding the food culture of various countries by comparing the ingredients used in their food. The recipe analysis identified ingredients and their frequencies of use in the creation of unique recipes. Food analyzer, the program developed in this paper, used data from recipes to examine correlations between individual food ingredients in recipes. This paper found that: 1) each country or ethnic group used authentic ingredients that differed from others and 2) the groupings of these authentic ingredients were essentially location-dependent. The boundaries of food-relevant areas were closely related to levels of precipitation. Meaningful correlations characterizing the food culture of each area can be explained by these authentic ingredients in recipes."
  },
  {
    "year": "2016",
    "abstract": "In rechargeable or energy harvesting wireless sensor networks (WSNs), a key concern is the max flow or data rate at one or more sinks. However, this data rate is constrained by the available energy at each node as well as link capacity. To date, in order to increase the amount of data extracted from a WSN, past works have considered routing approaches or they optimize the location of sinks. In contrast, we take a novel approach whereby we aim to “upgrade” the recharging rate of a finite number of “bottleneck” nodes using the so called auxiliary chargers (ACs) equipped with wireless power transfer capability. We formulate a mixed integer linear program (MILP) for the NP-hard problem at hand and propose three novel solutions to place ACs: 1) Path, which preferentially upgrades nodes on the shortest path among paths from sources to sinks, 2) Tabu, a meta-heuristic that first uses Path as the initial solution. It then searches for a neighboring solution that yields a higher max flow rate, and 3) LagOP, which approximates the said MILP using Lagrangian and sub-gradient optimization. Our results show that Tabu has the best performance, where it is able to achieve 99.40% of the max flow rate derived by MILP in tested scenarios."
  },
  {
    "year": "2016",
    "abstract": "In wireless communication schemes, turbo codes facilitate near-capacity transmission throughputs by achieving reliable forward error correction. However, owing to the serial data dependencies imposed by the underlying logarithmic Bahl-Cocke-Jelinek-Raviv (Log-BCJR) algorithm, the limited processing throughputs of conventional turbo decoder implementations impose a severe bottleneck upon the overall throughputs of real-time wireless communication schemes. Motivated by this, we recently proposed a fully parallel turbo decoder (FPTD) algorithm, which eliminates these serial data dependencies, allowing parallel processing and hence offering a significantly higher processing throughput. In this paper, we propose a novel resource-efficient version of the FPTD algorithm, which reduces its computational resource requirement by 50%, which enhancing its suitability for field-programmable gate array (FPGA) implementations. We propose a model FPGA implementation. When using a Stratix IV FPGA, the proposed FPTD FPGA implementation achieves an average throughput of 1.53 Gb/s and an average latency of 0.56 μs, when decoding frames comprising N = 720 b. These are, respectively, 13.2 times and 11.1 times superior to those of the state-of-the-art FPGA implementation of the Log-BCJR long-term evolution (LTE) turbo decoder, when decoding frames of the same frame length at the same error correction capability. Furthermore, our proposed FPTD FPGA implementation achieves a normalized resource usage of 0.42 (kALUTs/Mb/s), which is 5.2 times superior to that of the benchmarker decoder. Furthermore, when decoding the shortest N = 40-b LTE frames, the proposed FPTD FPGA implementation achieves an average throughput of 442 Mb/s and an average latency of 0.18 μs, which are, respectively, 21.1 times and 10.6 times superior to those of the benchmarker decoder. In this case, the normalized resource usage of 0.08 (kALUTs/Mb/s) is 146.4 times superior to that of the benchmarker decoder."
  },
  {
    "year": "2016",
    "abstract": "This paper presents two new theories and a new current representation to explain the magnetic force between two filamentary current elements as a result of electric force interactions between current charges. The first theory states that a current has an electric charge relative to its moving observer. The second theory states that the magnetic force is an electric force in origin. The new current representation characterizes a current as equal amounts of positive and negative point charges moving in opposite directions at the speed of light. Previous work regarded electricity and magnetism as different aspects of the same subject. One effort was made by Johnson to unify the origin of electricity and magnetism, but this effort yielded a formula that is unequal to the well-known magnetic force law. The explanation provided for the magnetic force depends on three factors: representing the electric current as charges moving at the speed of light; considering the relative velocity between moving charges; and analyzing the electric field spreading in the space due to the movement of charges inside current elements. The electric origin of the magnetic force is proved by deriving the magnetic force law and Biot-Savart law using the electric force law. This paper is helpful for unifying the concepts of magnetism and electricity."
  },
  {
    "year": "2016",
    "abstract": "Sensing the crowds to understand crowd dynamics can be a challenging task. Passive sensing techniques such as camera-based sensing can provide flow detection, people counting, and density estimation, but they fail to provide accurate identification of individuals mobility patterns. Active techniques such as Radio Frequency Identification (RFID) tags given to people require expensive RFID readers deployed to perform sensing. In this paper, we propose to use Bluetooth low energy (BLE) tagging as an alternative method. When low-cost BLE tags are set in advertisement mode, they can be detected by smartphones. In this paper, we design an architecture for sensing the crowds by requiring a large population carrying relatively cheap off-the-shelf BLE proximity tags, and considerably fewer participants to run scanning application on their smartphones to collect data. We performed a large experimental deployment with 600 tags and ten smartphones conducted during the five days of the world largest annual gathering (The Hajj). We were able to achieve ~90% detectability rate while effectively reconstructing the routes of the participants."
  },
  {
    "year": "2016",
    "abstract": "In the booming era of online social media environment, community question answering (CQA) sites have become one of the popular resources for software engineers and software industries. Software engineers are increasingly sharing their questions and answers on CQA sites. Aims of the CQA sites are to provide useful and relevant information to the users. Analysis information of major programming languages using trend analysis can be useful for software engineers to understand the technological evolutions and popularity. Since most of the CQA sites consist of user assigned tags by which folksonomy can be efficiently utilized for developing suitable algorithm to find the trend of key programming technologies. In this paper, two techniques of trend analysis, namely, ARIMA time series model and fuzzy time series model have been applied on the tagging data to identify the trend. Trend analysis is being carried on key programming languages, namely, c#, Java, PHP, and python. In this paper, quality of the trend is measured by entropy,ZTrend, and quality of forecast is measured by MMRE, burst trend for key programming languages."
  },
  {
    "year": "2016",
    "abstract": "A new probe-fed patch antenna with polarization reconfiguration is presented in this paper. The antenna is composed of a circular radiating patch and a switchable feed network. By controlling the operating states of four pairs of PIN diodes in the feed network, the feed point of the circular patch can be switched. Therefore, a reconfiguration between four linear polarization directions at a 45° interval (22.5°, 67.5°, 112.5°, and 157.5°) can be realized. All the different polarization states own similar matching and radiation characteristics. Simulated and measured results indicate that the antenna can achieve reconfigurable quadri-polarization diversity features with an invariable operating frequency and excellent radiation performance, which are very attractive for wireless communications. In addition, the proposed design can offer more reconfigurable linear polarization directions by adding more switchable paths in the feed network."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio networks (CRNs) open up the underutilized parts of the licensed spectrum for secondary reuse, so long as this secondary access does not cause harmful interference to the licensed users. Being able to run CRNs in a completely decentralized manner, as opposed to centralized operation, can be quite advantageous, because it avoids the complexity and single point-of-failure issues that arise from the presence of a central controller, and also eliminates the difficult step of establishing and maintaining a common control channel, which can suffer from saturation and malicious attacks. To that end, we propose in this paper a novel decentralized spectrum allocation technique for CRNs that not only provides great performance in terms of high throughput, excellent fairness, and minimal interference between cognitive users but also provides very stable network operation, in which cognitive users do not have to switch their operating frequency quite regularly. This is achieved by systematically observing the history of the spectrum usage to determine the proper channel assignment in the CRN. Our proposed technique is intuitive, is completely decentralized, and allows for quick reaction to changes in the CRN, such as when the primary users licensed to use the spectrum are suddenly activated."
  },
  {
    "year": "2016",
    "abstract": "Due to a battery constraint in wireless sensor networks (WSNs), prolonging their lifetime is important. Energy-efficient routing techniques for WSNs play a great role in doing so. In this paper, we articulate this problem and classify current routing protocols for WSNs into two categories according to their orientation toward either homogeneous or heterogeneous WSNs. They are further classified into static and mobile ones. We give an overview of these protocols in each category by summarizing their characteristics, limitations, and applications. Finally, some open issues in energy-efficient routing protocol design for WSNs are indicated."
  },
  {
    "year": "2016",
    "abstract": "Can a robot think like a human being? Scientists in recent years have been trying to achieve this dream, and we are also committed to this same goal. In this paper, we use an example of throwing the ball into the basket to make the robots process with human-like thinking behavior. Such thinking behavior adopted in this paper is divided into two modes: fast and slow. The fast mode belongs to the intuitional reaction, and the slow mode represents the complicated cogitation in human brain. This fascinating human thinking concept is inspired by the book, Thinking, Fast and Slow, which explains the process of the human brain. In addition, the psychology theories proposed in this book are also adopted to realize the thinking algorithms, and our experiments verify that the thinking mode of human beings is reasonable and effective in robots."
  },
  {
    "year": "2016",
    "abstract": "Since the 1G of mobile technology, mobile wireless communication systems have continued to evolve, bringing into the network architecture new interfaces and protocols, as well as unified services, high data capacity of data transmission, and packet-based transmission (4G). This evolution has also introduced new vulnerabilities and threats, which can be used to launch attacks on different network components, such as the access network and the core network. These drawbacks stand as a major concern for the security and the performance of mobile networks, since various types of attacks can take down the whole network and cause a denial of service, or perform malicious activities. In this survey, we review the main security issues in the access and core network (vulnerabilities and threats) and provide a classification and categorization of attacks in mobile network. In addition, we analyze major attacks on 4G mobile networks and corresponding countermeasures and current mitigation solutions, discuss limits of current solutions, and highlight open research areas."
  },
  {
    "year": "2016",
    "abstract": "In this paper, downlink beamforming (BF) for hybrid non-orthogonal multiple access (NOMA) systems is considered, in order to combat inter and intra cluster interference. First, to minimize the inter- and intra-cluster interference, the projection hybrid NOMA (PH-NOMA) BF algorithm is introduced, by combining conventional zero-forcing BF (ZFBF) and hybrid NOMA (H-NOMA) precoding. Second, to further reduce the overall interference, two user pairing algorithms, termed projection-based pairing algorithm (PBPA) and inversion-based pairing algorithm (IBPA), are also proposed, by adopting the properties of quasi-degradation developed previously. Consequently, the proposed BF algorithm is obtained by combining PH-NOMA and PBPA/IBPA. Moreover, the system performance in terms of outage probability and diversity is analyzed for both the proposed BF algorithms and conventional ZFBF. Finally, computer simulations are conducted to demonstrate the efficiency of the proposed BF algorithms and to validate the correctness of the performance analysis."
  },
  {
    "year": "2016",
    "abstract": "Cloud computing is becoming an increasingly admired paradigm that delivers high-performance computing resources over the Internet to solve the large-scale scientific problems, but still it has various challenges that need to be addressed to execute scientific workflows. The existing research mainly focused on minimizing finishing time (makespan) or minimization of cost while meeting the quality of service requirements. However, most of them do not consider essential characteristic of cloud and major issues, such as virtual machines (VMs) performance variation and acquisition delay. In this paper, we propose a meta-heuristic cost effective genetic algorithm that minimizes the execution cost of the workflow while meeting the deadline in cloud computing environment. We develop novel schemes for encoding, population initialization, crossover, and mutations operators of genetic algorithm. Our proposal considers all the essential characteristics of the cloud as well as VM performance variation and acquisition delay. Performance evaluation on some well-known scientific workflows, such as Montage, LIGO, CyberShake, and Epigenomics of different size exhibits that our proposed algorithm performs better than the current state-of-the-art algorithms."
  },
  {
    "year": "2016",
    "abstract": "This paper has addressed the common monitoring problems in petrochemical companies, which are caused by fouling and clogging in the circulating water heat exchangers, and has introduced techniques to monitor the heat exchanger's wall vibrations for early failure detection. Due to the difficulties encountered in simulation caused by the large number of tubes inside the heat exchanger, such monitoring methods are discussed by studying the fouling of a fluid-conveying pipeline. ANSYS was used to establish the normal and fouling models of a fluid-conveying pipeline so as to analyze the changing rules of various parameters that are influenced by different inlet velocities. These parameters include flow velocity, direction, pipeline wall load, wall displacement, and the acceleration of fluid domain in a fluid-conveying pipeline. It is shown that, as the inlet velocity and fouling severity continuously increase, the wall load and the vibration acceleration increase as well, leading variations in wall vibration signals. This paper conducts extensive experiments by using straight pipes to compare the results from simulation with those from the normal fluid-conveying pipelines under the same working conditions. By such comparison, the efficacy of the simulation model has been demonstrated."
  },
  {
    "year": "2016",
    "abstract": "It is known that software-defined networking (SDN) can support effective traffic engineering (TE) with the global view of networks. Hence, OpenFlow was used to realize flow-based TE. However, there is a tradeoff between the volume of installed flow entries and the granularity of TE. Moreover, the protocol-dependent nature of OpenFlow might limit the flexibility and adaptivity of TE. In this paper, we leverage the protocol-oblivious forwarding technology that can make each switch work as a protocol-independent white box and utilize its forwarding plane programmability to design a novel flexible flow converging (F-FC) scheme for realizing SDN-based fine-grained TE. Specifically, we design both the network system and the F-FC algorithms running on it and conduct experiments to demonstrate that our proposed scheme can not only reduce the volume of installed flow entries in switches but also realize fine-grained TE to achieve better utilization on network bandwidth."
  },
  {
    "year": "2016",
    "abstract": "Rough set proposed by Pawlak in 1982 is an important tool to process uncertain information. As an extended model of rough set, an approximation set model of rough set was proposed and proved to be feasible to establish an approximation target set with existing knowledge base. However, there still is a lack of effective methods for knowledge acquisition based on the approximation set model. In this paper, related methods of attribute reduction based on approximation set model of rough set are discussed in algebraic view and information view, respectively. First, a distribution reduction method on the basic of discernibility matrix according to approximation set is proposed and discussed in algebraic view. Furthermore, an algorithm of attribute reduction based on conditional information entropy of approximation set model is presented in information view. Finally, many experimental results show that the proposed algorithm could acquire more effective knowledge from uncertain information system compared with other algorithms based on classical rough set theory."
  },
  {
    "year": "2016",
    "abstract": "Interference is one of the major obstacles to improving the performance in wireless communication systems. As the ever-growing data traffic is carried over extremely dense networks, how to deal with interference becomes even more relevant. In this paper, we investigate a network with N pairs of users transmitting on the same channel simultaneously from the energy efficiency (EE) perspective. For such an interference network, we aim to address two issues: what is the EE tradeoff between users and how to design energy-efficient resource allocation scheme? To answer these two questions, we formulate a non-concave multi-objective optimization problem (MOOP) to investigate the EE tradeoff, taking into account the minimum data rate requirement of each user. The weighted Tchebycheff method is utilized to solve the MOOP by converting it into a single-objective optimization problem, which is then solved by the Dinkelbach method and the concave-convex procedure method. Based on the above, a power control algorithm is developed for the interference network to achieve at least a local optimum. The proposed algorithm is compared with the orthogonal bandwidth sharing, where each user orthogonally shares the whole bandwidth without interfering each other. In this scenario, the weighted Tchebycheff and the Dinkelbach methods are also utilized to develop the optimal bandwidth allocation and power control algorithm. The performance of the proposed algorithms is verified by numerical results, which show that it is better to share the bandwidth orthogonally rather than non-orthogonally if the interference between each user pair is stronger than a given threshold."
  },
  {
    "year": "2016",
    "abstract": "A novel adaptive method for the micro-electro mechanical systems (MEMSs) gyroscope based on a dynamic surface control and combined with the approach of adaptive fuzzy and sliding mode control (SMC) was shown in this paper. The first-order filter was introduced to the conventional adaptive backstepping technique in the dynamic surface control, which not only maintains the advantage of original backstepping technique, but also reduces the number of parameters and avoids the problem of parameter expansion. The adaptive fuzzy logic system is employed to approximate the dynamic characteristics of the gyroscope; the SMC is a kind of compensation for the error of the fuzzy approximation, which reduced the chattering phenomenon in adaptive control significantly. The proposed control scheme has improved the dynamic characteristics of the gyroscope, reducing the chattering of inputs and improving the timeliness and effectiveness of tracking. Simulation results indicate that the proposed control scheme has superior performance compared with conventional SMC."
  },
  {
    "year": "2016",
    "abstract": "This paper addresses the issues of user association in multi-tier heterogeneous networks (HetNets) to reduce co-channel interference and provide load balancing for proactively offloading users onto mobile personal cells (mPC). Previously, much of the literature discussed the user' association problem for HetNets with conventional fixed small cells. The problem discussed in the existing literature is easy to analyze owing to fix nature of the small cells. In this paper, we focus on the mPC instead of fixed small cells, which complicates the user association problem due to its nature of mobility. In this paper, we propose the public safety (PS) users priority-based mPC user association (PS-UA) scheme for load balancing and interference reduction in highly fluctuating PS long-term evolution systems. The proposed scheme improves the user-association problem by minimizing call blocking probability (CBP) according to the network load conditions and PS user priority. Moreover, it further improves user signal-to-interference-and-noise ratio by implementing enhanced intercell interference coordination scheme to further reduce the interference to the offloaded users. System-level simulations confirmed the validity of the proposed PS-UA scheme, because it convincingly reduces the CBP for PS users as compared with the conventional static user association scheme."
  },
  {
    "year": "2016",
    "abstract": "Device-centric architecture is an aspect of fifth generation communication whereby devices/user equipment is able to directly communicate with other devices with minimal involvement by the base station (BS). However, devices that are not within their proximity area communicate with other devices (relay). In this paper, we propose a device-centric scheme for relay selection in a dynamic network scenario. In this scheme, once the communicating devices have reached the maximum distance threshold, they exchange neighbor tables and find common devices (relay) for further communication. In addition, we propose a new relay selection scheme for scenarios, where the devices have more than one device (relay) in common. The proposed relay selection scheme is based on several parameters, including signal-to-noise ratio (SNR), signal-to-interference plus noise ratio, residual battery power, buffer space, and reliability; this provides more reliable and efficient communication. The current relay schemes, including max-min and max-max, are network assisted; the network/BS decides the relay, which increases the load on the BS side. The BS selects relay based on channel state information or SNR, which does not provide efficient or reliable communication. Our proposed device-centric scheme depends less on the BS during relay selection, which reduces network overhead, and the relay selection scheme provides more efficient and reliable communication. A comparison with other relay selection schemes shows that our scheme is 30% more effective in each case."
  },
  {
    "year": "2016",
    "abstract": "Workflow nets (WF-nets) as a class of Petri nets are widely used to model and analyze workflow systems. Soundness is an important property of WF-nets, which guarantees that the systems are deadlock- and livelock-free and each task has a chance to be performed. Van der Aalst has proven that the soundness problem is decidable for WF-nets and we have also shown that it is PSPACE-complete for bounded ones. Since the definition of soundness is based on reachability and Van der Aalst has proven that a sound WF-net must be bounded, the soundness detection can be carried out via the reachability graph analysis. However, the state explosion problem is a big obstacle to this technique. The unfolding technique of Petri nets can effectively avoid/alleviate this problem. This paper proposes an algorithm to generate a finite prefix of the unfolding of a WF-net, called basic unfolding. Furthermore, a necessary and sufficient condition is proposed to decide soundness based on basic unfolding. In addition, some examples illustrate that the unfolding technique can save the storage space effectively."
  },
  {
    "year": "2016",
    "abstract": "Proton exchange membrane fuel cell (PEMFC) can be a significant eco-friendly alternative power source for vehicles. However, under subfreezing conditions, cell degradation and irreversible performance decay can occur because of ice formation and repetitive thaw/freeze cycles. These problems have limited the further commercialization of PEMFC in cold weather countries. Thus, many improvements have been made to repair the freeze protection and rapid cold startup problems in PEMFC vehicles. In this paper, a comprehensive review dedicated to engineers of the recent research progress on the PEMFC cold start problems is presented. Systems and methods for fuel cell shutdown are summarized and classified into two categories: purge solution and material to avoid freezing. Regarding the system and solutions for PEMFC cold startup, different heating solutions are classified into two main groups depending on their heating sources and categorized as internal and external heating methods. This paper concludes with a detailed review of cold startup strategies based on an exhaustive survey of journal papers and patents."
  },
  {
    "year": "2016",
    "abstract": "Mobile web traffic analytics helps mobile network operators to understand subscriber behaviors and network characteristics. With the increasing prevalence of mobile devices, people are prone to access Internet by mobile devices. Meanwhile, a large amount of applications and services are being moved to the mobile web. These changes have resulted in the elevated complexity of mobile web traffic. Consequently, original web traffic models require an adjustment, and network understanding methods also need to update. In this paper, we proposed a stream algorithm to identify user click requests, and reconstructed user-browser interactions by leveraging Spark Streaming framework. The proposed algorithm was tested by massive real HTTP traffic records, which were captured from a cellular core network by high-performance monitoring devices. A statistical analysis was made on the reconstructed data set, and the overall characteristics of mobile web traffic were presented as well. Finally, major improvements in mobile web traffic models were obtained, and the key factors affecting web performance were found. We believe that our models and findings can be useful for mobile network operators to exhaustively understand the mobile web traffic and effectively analyze subscriber behaviors."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we analyze the effect of different underground materials on very-low and low-frequency magnetic fields used in the contexts of magneto-inductive localization and communication applications, respectively. We calculate the attenuation that these magnetic fields are subject to while passing through most common rocks and minerals. Knowing the attenuation properties is crucial in the design of underground magneto-inductive communication systems. In addition, we provide means to predict the distortions in the magnetic field that impair localization systems. The proposed work offers basic design guidelines for communication and localization systems in terms of channel path loss, operation frequencies, and bandwidth. In order to make our results reproducible by other researchers, we provide the raw data and processing source code."
  },
  {
    "year": "2016",
    "abstract": "The rapid development of digital imaging and computer vision has increased the potential of using the image processing technologies in ophthalmology. Image processing systems are used in standard clinical practices with the development of medical diagnostic systems. The retinal images provide vital information about the health of the sensory part of the visual system. Retinal diseases, such as glaucoma, diabetic retinopathy, age-related macular degeneration, Stargardt's disease, and retinopathy of prematurity, can lead to blindness manifest as artifacts in the retinal image. An automated system can be used for offering standardized large-scale screening at a lower cost, which may reduce human errors, provide services to remote areas, as well as free from observer bias and fatigue. Treatment for retinal diseases is available; the challenge lies in finding a cost-effective approach with high sensitivity and specificity that can be applied to large populations in a timely manner to identify those who are at risk at the early stages of the disease. The progress of the glaucoma disease is very often quiet in the early stages. The number of people affected has been increasing and patients are seldom aware of the disease, which can cause delay in the treatment. A review of how computer-aided approaches may be applied in the diagnosis and staging of glaucoma is discussed here. The current status of the computer technology is reviewed, covering localization and segmentation of the optic nerve head, pixel level glaucomatic changes, diagonosis using 3-D data sets, and artificial neural networks for detecting the progression of the glaucoma disease."
  },
  {
    "year": "2016",
    "abstract": "Formal modeling of multi-agent systems is an active area of research. The use of precise and unambiguous notation of formal methods is used to accurately describe and reason about the system under consideration at the design time. Multi-agent systems deployed in dynamic and unpredictable environment needs to have the ability of self-adaptation, making them adaptable to the failures. State of the art encourages the use of MAPE-K feedback loop for the provision of self-adaptation in any system. There is a dire need of formal vocabulary that can be used for the conceptual design of any real-time multi-agent system with self-adaptation. In this paper, we have proposed a set of predefined interfaces for the provision of self-adaptation in real-time multi-agent systems. The interfaces are based on monitor, analyze, plan, and execute phases of the MAPE-K feedback loop. We formally specify our interfaces using timed-communicating object-Z language. The complete framework is elaborated using a trivial case-study of conveyor belt system based on a real-time agent architecture."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we derive new computational techniques for residue number systems (RNSs)-based Barrett algorithm (BA). The focus of this paper is an algorithm that carries out the entire computation using only modular arithmetic without conversion to large integers via the Chinese remainder theorem. It also avoids the computationally expensive scaling-rounding operation required in the earlier work. There are two parts to this paper. First, we set up a new BA using two constants other than powers of two. Second, an RNS-based BA is described. A complete mathematical framework is described including proofs of the various steps in the computations and the validity of results. Third, we present a computational algorithm for RNS-based BA. Fourth, the RNS-based BA is used as a basis for new RNS-based algorithms for MoM and MoE. The applications we are dealing with are in the area of cryptography."
  },
  {
    "year": "2016",
    "abstract": "Fringe projection profilometry (FPP) is a popular optical 3-D imaging approach, in which the images of deformed fringe patterns are analyzed to extract object surfaces (i.e., height maps of object surfaces). As an object surface normally does not change independently, height correlations of an object surface can be used to denoise and improve the measurement performance of the FPP. This paper investigates the issue of exploiting height correlations in FPP fringe pattern analysis. The challenge lies in that height correlations are unknown and they are different from object to object. In addition, the problem of interest is normally in a large scale. In this paper, we use autoregressive (AR) models with unknown parameters to model the unknown height correlations and formulate the FPP analysis problem (with height correlations exploited) under the framework of expectation maximization (EM). With EM, the unknown AR model parameters are determined based on observations, and the estimates of the heights with their correlations exploited can also be extracted. To deal with the large-scale problem, a message passing-based implementation of the formulated EM problem is studied and the relevant message updating rules are developed. The proposed approach has a linear complexity and it allows parallel processing due to the nature of message passing. Simulation and experimental results demonstrate a significant performance improvement by the proposed approach."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a novel broadband and ±45° slant orthogonal dual-polarized antenna element designed for LTE700 MHz/GSM850 MHz/GSM900 MHz applications. The proposed antenna element consists of an annular base, four couples of baluns, three kinds of parasitic plastic fasteners (3 × 4 = 12, four for each kind of fastener), and four dipoles that are orthogonal with each other. Compared with the prototype without parasitic plastic fasteners, the impedance bandwidth of the proposed antenna element can be significantly improved. Measured results show that the proposed antenna element can operate from 698 to 960 MHz with VSWR <;1.7 at both ports, high port-to-port isolation of >25 dB, a stable radiation pattern with half-power beamwidth of 65.92° ± 5.44° at H plane and V plane, and a relatively stable gain of 9.41 ± 0.48 (dBi). In addition, the size of the proposed antenna element is 0.469λ0× 0.469λ0× 0.22λ0(λ0is the free-space wavelength referring to the antenna center frequency). Good agreement is observed between simulated and measured results."
  },
  {
    "year": "2016",
    "abstract": "Vehicular ad hoc networks can be viewed as a typical context-aware system where the experienced context frequently varies as vehicles move along road, e.g., signal-to-noise ratio (SNR), velocity, and traffic flow. In particular, the adopted security protection mechanisms often depend on the node state, location, and/or surrounding risk, which need the capability of context-aware security quantification. This paper views the security level as a user's inherent property that is only correlated with the user's behaviours and the situated context and independent of the suffered attack ways. We propose a formalized methodology to especially quantify the security level in real time from the perspective of state transition probability through estimating the stable probability of staying in the security state in inhomogeneous continuous time Markov chain. This paradigm enables users to customize the security protection mechanisms for adapting to the frequently varying context. We conduct the extensive numerical calculations and empirical analysis to comprehensively investigate the response of the proposed security quantification framework to the various combinations of the concerned parameters, e.g., SNR, velocity, and traffic flow. The results show that the proposed framework is capable of capturing the real-time security level adaptively to the vehicular context and provides a dependable decision basis to security protection, which can restrict the security to a target value."
  },
  {
    "year": "2016",
    "abstract": "For heterogeneous network, which has been viewed as one pioneering technology for making cellular networks be evolved into 5G systems, reducing energy consumption by dynamically switching off base stations (BSs) has attracted increasing attention recently. With aiming at optimization on energy saving only or another energy-related performance tradeoffs, several BS switch-off strategies have been proposed from different design perspectives, such as random, distance-aware, load-aware, and auction-based strategies. Furthermore, work has been done to consider joint design for BS switch-off strategy and another strategies, such as user association, resource allocation, and physical-layer interference cancellation strategies. Finally, there have been research results about this topic in emerging cloud radio access networks. In this paper, we take an overview on these technologies and present the state of the art on each aspect. Some challenges that need to be solved in this research filed for future work are also described."
  },
  {
    "year": "2016",
    "abstract": "Cloud gaming is a new way to deliver high-quality gaming experience to gamers anywhere and anytime. In cloud gaming, sophisticated game software runs on powerful servers in data centers, rendered game scenes are streamed to gamers over the Internet in real time, and the gamers use light-weight software executed on heterogeneous devices to interact with the games. Due to the proliferation of high-speed networks and cloud computing, cloud gaming has attracted tremendous attentions in both the academia and industry since late 2000's. In this paper, we survey the latest cloud gaming research from different aspects, spanning over cloud gaming platforms, optimization techniques, and commercial cloud gaming services. The readers will gain the overview of cloud gaming research and get familiar with the recent developments in this area."
  },
  {
    "year": "2016",
    "abstract": "Node compromise attacks pose a serious threat to wireless sensor networks (WSNs). To launch an attack, an adversary physically captures a node and access data or software stored on the node. Even worse, the adversary may redeploy the captured node back into the network and use it to launch further attacks. To reduce the impact of a node compromise attack on network operations, the network should detect a node compromise as early as possible, ideally soon after a node is being captured, and then isolate the node from future network communications. Solutions for early node compromise detection are based on distributed monitoring of neighboring nodes' aliveness. Nodes regularly send notification (Heartbeat) messages to their one-hop neighbors to indicate their aliveness. If no message is received from a node (i.e., if a node is not heard) for a certain period of time, then the unheard node is said to have been compromised. This approach may have a large number of false positive errors when the message loss ratio in the network is high, as missing messages could be caused by message loss during transmission, in addition to node compromises. This paper proposes a novel scheme, called an adaptive early node compromise detection scheme, to facilitate node compromise attack detection in a cluster-based WSN. The scheme is designed to achieve a low false positive ratio in the presence of various levels of message loss ratios. To achieve this feature, two ideas are used in the design. The first is to use cluster-based collective decision making to detect node compromises. The second is to dynamically adjust the rate of notification message transmissions in response to the message loss ratio in the sender's neighborhood. The performance of the scheme, in terms of false positive ratio, false negative ratio, and transmission overheads, is evaluated using simulation. The results are compared against those from the most relevant scheme in the literature. The comparison results show..."
  },
  {
    "year": "2016",
    "abstract": "This paper studies the optimal synthesis design of adjustable six-linkage mechanisms in metal-mold die-casting systems. The synthesis process is extremely complex because of higher order structures, collision-free constraints, and multiple loci in the solution space. Therefore, a twin-space crowding genetic algorithm was used to solve the design problem with the multiplicity of solutions. To verify the effectiveness of the proposed approach, this paper first studied the function generation problems for adjustable four linkage-bar structures in the literature, and compared these with a numerical local optimization method. From the comparison result, multiple and more precise design solutions can be obtained with the proposed approach. The synthesis design problem for collision-free adjustable six-linkage bars was then solved and discussed. The simulated experiments demonstrated the promising result of the proposed approach."
  },
  {
    "year": "2016",
    "abstract": "The lp(0 <; p <; 1) regularization has attracted a great attention in the compressive sensing field, because it can obtain sparser solutions than the well-known l1regularization. Recently, we developed an approximate general analytic thresholding representation for any lp regularization with 0 <; p <; 1. The derived thresholding representations are exact for the well-known soft-threshold filtering for l1regularization and the hard-threshold filtering for l0regularization. Because the lp regularization is a nonconvex problem, an iterative algorithm can only converge to local optima instead of the global optimum. In this paper, we propose an alternating iteration algorithm for computed tomography reconstruction in a thresholding form based on our general analytic thresholding representation for better convergent properties. The alternating iteration algorithm alternatively minimizes one l1and one lp(0 <; p <; 1) regularized objective functions. While the lp regularization can help to find a sparser solution, the l1regularization can help to monitor the solution not away from the global optimum. Both numerical simulations and phantom experiments are performed to evaluate the proposed alternating iteration algorithm. Compared with the lp(0 <; p <; 1) regularization using a single p, the proposed alternating iteration algorithm reduces more data measurements for accurate reconstruction and is more robust for projection noise."
  },
  {
    "year": "2016",
    "abstract": "Eigenvalue-based algorithm is generally acknowledged to be a promising method for spectrum sensing. However, it possesses high computational complexity, because the sampled covariance matrix and the corresponding eigenvalues are calculated. Furthermore, the detection performance of eigenvalue-based algorithms experiences a huge decline when the received signals are uncorrelated. Therefore, compressed sensing is adopted to reduce the computational complexity and introduce the relevance for multiple received signals. First, the sampled covariance matrix and its eigenvalues are calculated under the non-reconstruction framework of compressed sensing. The corresponding standard condition number of the eigenvalues is employed as test statistic to perform spectrum sensing. Then, the impact of the measurement matrix on the detection performance is discussed, and the computational complexity is analyzed. Next, the measurement matrix is optimized to improve the detection performance. In addition, a novel method of setting decision threshold is proposed to maintain a stable false alarm probability for the proposed spectrum sensing algorithm, and its computational complexity is compared with some existing methods. Finally, the corresponding simulations are performed to testify the theoretical results. Theoretical analysis and simulation results certify the effectiveness and validity of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "The purpose of remote sensing image fusion is to sharpen a low spatial resolution multispectral (MS) image by injecting the detail map extracted from a panchromatic (PAN) image. In this paper, a novel remote sensing image fusion method based on adaptive intensity-hue-saturation (IHS) and multiscale guided filter is presented. In the proposed method, the intensity component is obtained adaptively from the upsampled MS image at first. Different from traditional IHS-based methods, we subsequently propose a multiscale guided filter strategy to filter the PAN image to achieve more detail information. Finally, the total detail map is injected into each band of the upsampled MS image to obtain the fused image by a model-based algorithm, in which an improved injection gains approach is proposed to control the quantity of the injected detail information. Experimental results demonstrated that the proposed method can provide more spatial information and preserve more spectral information compared with several state-of-the-art fusion methods in both subjective and objective evaluations."
  },
  {
    "year": "2016",
    "abstract": "Toward the era of mobile internet and Internet of Things (IoT), numerous sensors and devices are being introduced and interconnected. To support such amount of data traffic, traditional wireless communication technologies are facing challenges both in terms of increasingly shortage of spectrum resource and massive multiple access. In this paper, cognitive code division multiple access (Cognitive-CDMA) is proposed by combining the concept of cognitive radio with dynamic noncontinuous spectrum bands and code division multiple access. In order to suppress multiple access interference resulting from the non-orthogonality of partial available spectrum bins, carrier frequency offset, and spectrum sensing mismatch, an enhanced receiver design using frequency-domain oversampling (FDO) with linear minimum mean square error (MMSE) is considered in this paper for Cognitive-CDMA systems. By spectrum sensing to mitigate spectral interference in the transceiver and by utilizing FDO in the receiver to project received signal to a higher dimension, the proposed Cognitive-CDMA is able to support robust and massive multiple access for IoT applications. The simulation results show that the cognitive-CDMA with FDO-MMSE receiver outperforms that with conventional per-user MMSE receiver in the presence of multipath fading channels, carrier frequency offset, and spectrum sensing mismatch."
  },
  {
    "year": "2016",
    "abstract": "In this treatise, we evaluate the error-rate (ER) performance of turbo-coded multi-carrier code division multiple access scheme (MC-CDMA) for downlink (DL) transmission. The transmitter pre-processing (TP) technique is a promising signal processing technique, which is carried out at the transmitter side to reduce the burden of each mobile station (MS) in the context of DL communication. We formulate minimum mean-square-error-aided TP matrix using noisy feedback of vector-quantized estimated channel information (CI) for frequency-division duplexing system. Clearly, we estimate the CI and perform vector quantization (VQ) at each MS and transmit the index of the quantized value through dedicated low rate noisy channel. Finally, we acquire CI of all active users using known estimation algorithm in order to build TP. We realize time-frequency domain signature sequence to support more user population. In particular, we analyze the ER performance of coded MC-CDMA system with TP for Stanford University Interim channel model. The ER curve shows that coded MC-CDMA system based on TP approach provides better performance with less signal-to-noise ratio while offering low complexity of MS. In addition, performance curve shows that there is an improvement in the ER performance when perfect CI is utilized to build TP matrix compared with noise-contaminated VQ-CI."
  },
  {
    "year": "2016",
    "abstract": "The broadband spectrum contains significantly more information than what the human eye can detect, with different wavelengths providing unique information about the intrinsic properties of an object. Recently, compressive sensing-based strategies for multi-spectral imaging via wavelength filtering at the pixel level on the imaging detector have been proposed for simultaneous acquisition of multi-spectral imaging data greatly reducing the acquisition times. To utilize such compressive sensing strategies for multi-spectral imaging, strong reconstruction algorithms that can reconstruct dense multi-spectral image cubes from the sparse compressively sensed observations are required. This paper proposes a comprehensive inter-spectral multi-layered conditional random field (IS-MCRF) sparse reconstruction framework for multi-spectral compressively sensed data captured using such acquisition strategies. The IS-MCRF framework leverages the information between neighboring spectral bands to better utilize the available information for reconstruction. The proposed framework was evaluated using compressively sensed multi-spectral acquisitions ranging from visible to near infrared spectral bands obtained by a simulated compressive sensing-based multi-spectral imaging system. Results show noticeable improvement over the existing sparse reconstruction techniques for compressive sensing-based multi-spectral imaging systems in preserving spatial and spectral fidelity."
  },
  {
    "year": "2016",
    "abstract": "Cooperative spectrum sensing (CSS) has been well recognized as an effective method to improve spectrum sensing accuracy and decrease sensing devices' complexity. However, spectrum sensing data falsification attack, also known as Byzantine attack, poses critical threats on the reliability of CSS. Due to lack of the ground-truth spectrum state, a reliable defense reference is vital to identify malicious behaviors and perform effective data fusion. However, the existing defense references have strong assumptions such as the attackers are in minority and/or a trusted node exists for data fusion. This observation motivates this paper to propose a novel defense reference, which jointly exploits the cognitive process of spectrum sensing and spectrum access in a closed-loop manner, to provide the defense scheme a solid basis without requiring any prior knowledge. Moreover, this paper analyzes the proposed reference's favorable reliability and high robustness over the state-of-the-art references, from two perspectives of spectrum sensing performance and the capability of identifying malicious sensors, respectively. Next, we design an optimal cooperative spectrum sensing scheme based on the proposed defense reference. Remarkably, from an information theoretic perspective, it is observed that based on the proposed reference, the information value of falsified reports is also exploited to further improve the global sensing performance. Furthermore, numerical simulations verify the proposed scheme's favorable performance, even in critical cases when malicious sensors are in majority."
  },
  {
    "year": "2016",
    "abstract": "Deformable models and level set methods have been extensively investigated for computerized image segmentation. However, medical image segmentation is yet one of open challenges owing to diversified physiology, pathology, and imaging modalities. Existing level set methods suffer from some inherent drawbacks in face of noise, ambiguity, and inhomogeneity. It is also refractory to control level set segmentation that is dependent on image content and evolutional strategies. In this paper, a new level set formulation is proposed by using fuzzy region competition for selective image segmentation. It is able to detect and track the arbitrary combination of selected objects or image components. To the best of our knowledge, this new formulation should be one of the first proposals in a framework of region competition for selective segmentation. Experiments on both synthetic and real images validate its advantages in selective level set segmentation."
  },
  {
    "year": "2016",
    "abstract": "There has been an increasing demand for connectivity of the clusters of microgrids to increase their flexibility and security. This paper presents a framework for implementation, simulation, and evaluation of a novel power routing algorithm for clusters of microgrids. The presumed cluster is composed of multiple direct current (dc) microgrids connected together through multi-terminal dc system in a meshed network. In this structure, the energy is redirected from the microgrid with excessive power generation capacity to the microgrid which has power shortage to supply its internal loads. The key contribution of this paper is that each microgrid in the cluster is unaware of the current state and other flows of the cluster. In this approach, the optimal power flow problem is solved for the system while managing congestion and mitigating power losses. The proposed methodology works for both radial and non-radial networks regardless of the network topology, scale, and number of microgrids involved in the cluster. Therefore, it is also well suited for large-scale optimal power routing problems that will emerge in the future clusters of microgrids. The effectiveness of the proposed algorithm is verified by MATLAB simulation. We also present a comprehensive cloud-based platform for further implementation of the proposed algorithm on the OPAL-RT real-time digital simulation system. The communication paths between the microgrids and the cloud environment can be emulated by OMNeT++."
  },
  {
    "year": "2016",
    "abstract": "The performance of wireless cellular networks in indoor scenarios is in large parts characterized by the blockage objects such as walls. These objects can be included in the system model in several ways. We present in this paper different wall generation methods, ranging from approaches from random shape theory (in 1-D and 2-D) to semideterministic and heuristic approaches. To attain comparable results, we ensure that the average wall volume for each method is constant. This results in the same average attenuation for distinct paths, which is shown analytically as well as by simulations. We apply a regular transmitter grid, show the influence of the relative orientation between walls and transmitter-receiver path and also elaborate on the influence of interferers in different tiers around the desired transmitter. Based on the average attenuation, we introduce the necessary approximations to yield tractable expressions for average performance in terms of Signal-to-Interference Ratio (SIR). These approximations are necessary to reflect the fluctuations among the instantaneous SIR values for the individual realizations of the blockage scenario and also due to the spatial correlation of blockages influencing several transmitter-signals simultaneously. Our results show a good accordance among the analytical and simulation results. Furthermore, we find the random wall generation method in two dimensions as the worst case scenario and the regular wall generation method as the best case scenario under the constraint of constant average wall volume."
  },
  {
    "year": "2016",
    "abstract": "The rapid momentum in the realization of security solutions, availability of affordable hardware components, and computing devices has led to a tremendous rise in biometric research. However, the threat of spoofing has raised palpable security concerns. In this paper, we examined a recently introduced novel behavioral biometrics technique, namely, fingerprint dynamics. The technique exploits individual's behavioral characteristics observed from multi-instance finger scan events. The objective of this investigation was to study the spoof resistance capabilities of the fingerprint dynamics-based standalone identity verification system. We used a custom-built hardware unit to collect biometric samples from a total of 50 participants, in an environment that closely mimics the operational scenario. Data collection was done in several sessions per user, spread over a period of seven weeks. We performed an exhaustive analysis of several time-derived features, and selected a combination of best-performing features using genetic algorithm. We also conducted a systematic evaluation using support vector machine and k -nearest neighbor classifiers. We performed a series of verification experiments under three different and practically relevant attack scenarios, namely: 1) combined zero-effort and active imposter; 2) only zero-effort imposter; and 3) only active imposter. We find that the proposed technique exhibits promising results under all the three attack scenarios."
  },
  {
    "year": "2016",
    "abstract": "We propose a task-oriented multi-objective scheduling method based on ant colony optimization (MOSACO) to optimize the finite pool of public and private computing resources in a hybrid cloud computing environment according to deadline and cost constraints. MOSACO is employed to minimize task completion times and costs using time-first and cost-first single-objective optimization strategies, respectively, and to maximize user quality of service and the profit of resource providers using an entropy optimization model. The effectiveness of the MOSACO algorithm based on multiple considerations of task completion time, cost, number of deadline violations, and degree of private resource utilization is verified using simulation and three application examples. Comparisons with similar scheduling methods demonstrate that MOSACO provides the highest optimality, and that the time-first and cost-first strategies provide definite advantages for minimizing completion time and cost, respectively."
  },
  {
    "year": "2016",
    "abstract": "We investigate the application of non-orthogonal multiple access (NOMA) with successive interference cancellation (SIC) in downlink multiuser multiple-input multiple-output (MIMO) cellular systems, where the total number of receive antennas at user equipment (UE) ends in a cell is more than the number of transmit antennas at the base station (BS). We first dynamically group the UE receive antennas into a number of clusters equal to or more than the number of BS transmit antennas. A single beamforming vector is then shared by all the receive antennas in a cluster. We propose a linear beamforming technique in which all the receive antennas can significantly cancel the inter-cluster interference. On the other hand, the receive antennas in each cluster are scheduled on the power domain NOMA basis with SIC at the receiver ends. For inter-cluster and intra-cluster power allocation, we provide dynamic power allocation solutions with an objective to maximizing the overall cell capacity. An extensive performance evaluation is carried out for the proposed MIMO-NOMA system and the results are compared with those for conventional orthogonal multiple access (OMA)-based MIMO systems and other existing MIMO-NOMA solutions. The numerical results quantify the capacity gain of the proposed MIMO-NOMA model over MIMO-OMA and other existing MIMO-NOMA solutions."
  },
  {
    "year": "2016",
    "abstract": "We present an algorithm for estimating a sequence of articulated upper-body human pose in unconstrained videos. Most previous work often fails to locate forearms in those video scenes suffering from illumination varieties, background clutter, camera shake, or occlusion. In order to deal with such intractable cases, we propose a novel algorithm for addressing the problem of certain body parts localization. The proposed approach can be roughly divided into two steps: first, a spatial model is designed to capture the high-order relationship between adjacent parts and meanwhile to generate a set of configurations in each frame under the temporal context constraint; second, a competitive method is presented to select the best body parts among diverse pose configurations. In this paper, the proposed algorithm focuses on the unconstrained video scenes and improves the detection precision of certain body parts with high degree of freedom. Moreover, the proposed algorithm can be well applied to a very challenging dataset named Movies. Experimental results show that the proposed algorithm can dramatically improve performance compared with those related algorithms on two benchmark datasets (MPII and SHPED datasets) and on our Movies dataset."
  },
  {
    "year": "2016",
    "abstract": "Open data has attracted huge attention for the construction of smart city in terms of delivering useful city information to citizens and interacting with citizens from the city council perspective. In this paper, we present an overview of the current status and issues of open data opened by different seven Canadian cities. We start by presenting the characters of open data, followed by data format conclusion and detailed dataset explaination for each Canadian city (e.g., Calgary, Halifax, Surrey, Waterloo, Ottawa, Vancouver, and Toronto), including the different data catalogues and their detailed characteristics. Next, we discuss the state-of-the-art of the tools and applications developed over each city's open data. Here, we not only illustrate the most successful examples, but particularly consider the potential issues due to the characters of the city datasets. This paper is not only beneficial for a government, which can compare its open data status with that of the Canadian cities but also quite useful for users or companies interested in tool development over open city data."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we analyze the probabilistic cooperation of a full-duplex relay in a multiuser random-access network. The relay is equipped with on/off modes for the receiver and the transmitter independently. These modes are modeled as probabilities by which the receiver and the transmitter are activated. We provide analytical expressions for the performance of the relay queue, such as arrival and service rates, stability conditions, and the average queue size. We optimize the relay's operation setup to maximize the network-wide throughput while, simultaneously, we keep the relay's queue stable and lower the relay's receptions and transmissions. Furthermore, we study the effect of the SINR threshold and the self-interference coefficient on the per-user and network-wide throughput. For low SINR threshold, we show under which circumstances it is beneficial to switch off the relay completely, or switch off the relay's receiver only."
  },
  {
    "year": "2016",
    "abstract": "Wireless sensor networks (WSNs) are autonomous networks of spatially distributed sensor nodes that are capable of wirelessly communicating with each other in a multihop fashion. Among different metrics, network lifetime and utility, and energy consumption in terms of carbon footprint are key parameters that determine the performance of such a network and entail a sophisticated design at different abstraction levels. In this paper, wireless energy harvesting (WEH), wake-up radio (WUR) scheme, and error control coding (ECC) are investigated as enabling solutions to enhance the performance of WSNs while reducing its carbon footprint. Specifically, a utility-lifetime maximization problem incorporating WEH, WUR, and ECC, is formulated and solved using distributed dual subgradient algorithm based on the Lagrange multiplier method. Discussion and verification through simulation results show how the proposed solutions improve network utility, prolong the lifetime, and pave the way for a greener WSN by reducing its carbon footprint."
  },
  {
    "year": "2016",
    "abstract": "Wireless communication system is expected to provide service with low latency and high energy efficiency. To improve the energy efficiency, the transceiver prefers sending packets, when the channel states are good. However, such opportunistic transmission may induce undesirably large latency. Therefore, a fundamental tradeoff exists between the average transmission power and average queuing delay, and is studied in this paper via cross-layer probabilistic scheduling. In particular, we consider the delay-power tradeoff when the packet arrivals have arbitrary probabilistic distributions. A Markov reward model is adopted to model the queue of the backlogged packets. Based on that, we formulate a nonlinear optimization problem and convert it into a linear programming (LP) problem by using variable substitution. The optimal solution to the LP problem allows us to derive the optimal scheduling parameters. Based on the optimal solution, we can derive the optimal scheduling policy, which turns out to be threshold-based. Besides, we consider the source scheduling with the specific packet arrival distribution being unknown. Adaptive algorithms are proposed to achieve the corresponding delay-power tradeoff."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we address the energy harvesting tradeoff for minimizing the average packet delay in wireless energy harvesting multi-hop networks with inter-session network coding (NC) and successive interference cancellation. Unlike the previous works, conventionally making a tradeoff between the transmission delay and the energy consumption in a wireless network, here by minimizing the ratio of the scheduling length to the harvesting energy remained, we present a cross-layer formulation for a joint routing, network coding, and scheduling problem in a wireless energy transfer network to make the length-energy tradeoff while satisfying the traffic demands from the upper layer. With the realistic signal-to-interference-plus-noise ratio model, the formulation is also to address a conflict-free scheduling problem on the NC components, and to specify an energy harvesting and consuming model for these components in detail. Then, for the combinatorial nonlinear problem resulted, we develop a Lyapunov optimization-based scheme conducting a dynamic scheduling policy that can approach the optimal length-energy tradeoff while keeping the network stable. Specifically, the mixed integer nonlinear programming model, including, especially, the fractional objective is first transformed and decomposed into a master subproblem and a pricing subproblem with a column generation (CG) method to avoid enumerating all the possible configures, and then resolved iteratively through the Lyapunov optimization algorithm. To further reduce the complexity, the CG method on finding feasible configures is operated within a limited number of iteration and stopped when no significant improvements can be obtained. Finally, with the numerical results, we show that the proposed algorithm can effectively reduce the scheduling length, while reserving the time long enough to harvest the energy for the wireless networks with and without NC, and verify the tradeoff on the performance metrics as [O(V), O(1/V..."
  },
  {
    "year": "2016",
    "abstract": "This paper presents the design of approximate 15-4 compressor using 5-3 compressors as basic module. Four different types of approximate 5-3 compressors are used in a 15-4 compressor for less power consumption and high pass rate. We have analysed the results in all the cases. A 16 × 16 bit multiplier is simulated using the proposed 15-4 compressor. Simulation results show that the multipliers with proposed approximate compressors achieve significant improvement in power as compared to the multipliers with accurate 15-4 compressor. Pass rate of the proposed multipliers are high as compared to other existing approximate multipliers. Finally, the proposed multiplier is used in image processing applications, where the peak signal to noise ratio of the image is measured. Quality of the image is compared with an accurate multiplier and the obtained results show that our proposed multiplier performs better than existing approximate multiplier."
  },
  {
    "year": "2016",
    "abstract": "The evolution of the concept of cloud communications has posed a growing emphasis on virtual and abstract environments for the flow of information, structuring it in similitude to a natural cloud. The green symbiotic cloud communications (GSCCs) paradigm created on this concept facilitates the use of multiple communication mediums concomitantly creating a first of its kind communication cloud. This paper specifically corroborates a virtualized transport layer and network ports and an abstracted Internet protocol scheme in defining the GSCC architecture. We further address the issue of formulating a cognitive decision function based on utility theory, which allows users with GSCC enabled devices to intelligently distribute its bandwidth requirement amongst the available communication mediums. Considering the multiple criteria associated with different networks, we formulate an optimization problem to find the solution for this resource allocation problem for single user. We further address the multi-user scenario and formulate and solve the multi-objective optimization problem using goal attainment technique. Results in single and multiple user scenarios, demonstrate that by utilizing multiple mediums as per GSCC paradigm coupled with our proposed decision function improves the functionality of the communication cloud. The proposed architecture is dynamic and evolving, embedding greenness by efficiently utilizing the available resources as and when required. The multiple virtual links equate a linearly increasing relationship with the throughput achieved. Experimental results for both real time and static data through the proposed schematic are documented. The augmented paradigm enhances the quality of service, linearly increases throughput and increases the overall security in communications."
  },
  {
    "year": "2016",
    "abstract": "One serious problem that all the developed nations are facing today is death and injuries due to road accidents. The collision of an animal with the vehicle on the highway is one such big issue, which leads to such road accidents. In this paper, a simple and a low-cost approach for automatic animal detection on highways for preventing animal-vehicle collision using computer vision techniques are proposed. A method for finding the distance of the animal in real-world units from the camera mounted vehicle is also proposed. The proposed system is trained on more than 2200 images consisting of positive and negatives images and tested on various video clips of animals on highways with varying vehicle speed. As per the two-second rule, our proposed method can alert the driver when the vehicle speed is up to 35 km/h. Beyond this speed, though the animal gets detected correctly, the driver does not get enough time to prevent a collision. An overall accuracy of almost 82.5% is achieved regarding detection using our proposed method."
  },
  {
    "year": "2016",
    "abstract": "Dense cellular networks (DenseNets) are fast becoming a reality with the large scale deployment of base stations aimed at meeting the explosive data traffic demand. In legacy systems, however, this comes at the cost of higher network interference and energy consumption. In order to support network densification in a sustainable manner, the system behavior should be made “load-proportional” thus allowing certain portions of the network to activate on-demand. In this paper, we develop an analytical framework using tools from stochastic geometry theory for the performance analysis of DenseNets where load-awareness is explicitly embedded in the design. The proposed model leverages on a flexible cellular network architecture where there is a complete separation of the data and signaling communications functionalities. Using this stochastic geometric framework, we identify the most energy-efficient deployment solution for meeting certain minimum service criteria and analyze the corresponding power savings through dynamic sleep modes. According to state-of-the-art system parameters, a homogeneous pico deployment for the data plane with a separate layer of signaling macro-cells is revealed to be the most energy-efficient solution in future dense urban environments."
  },
  {
    "year": "2016",
    "abstract": "As mobile social networks grow rapidly, influential user identification has attracted much more attention. Previous studies either need large message overhead to achieve global maxima in influence computation or focus on relatively stable network topology. To tackle the dynamic topology, we present an influential user identification scheme that fully exploits the active mobile users, in which the stable-state property could be leveraged under information potential construction scheme. We also propose an efficient routing algorithm for reaching the global maxima without depending on specific routing protocols. The proposed scheme is validated with extensive simulations using both synthetic random-walk and real-world mobility traces. The results demonstrate that it achieves considerable performance on influential user identification and route construction with little overhead. Furthermore, we present a case of mobile data offloading, and the results show that our scheme could reduce the efficient data traffic by up to 79.2%, compared with a baseline without data offloading."
  },
  {
    "year": "2016",
    "abstract": "Caching is a promising technology to alleviate the transmission pressure of the 5G heterogeneous networks. To overcome the drawbacks of the existing caching schemes that ignore the heterogeneity or the cooperation characteristics of the heterogeneous networks, this paper proposes a cooperation-based caching scheme (CBCS). Based on the scheme, the average energy consumption incurred by a user equipment (UE) to obtain its desired content is formulated as an NP-hard optimization problem, and two greedy heuristic algorithms are developed to solve the problem. In addition, our simulation results show the gains of the proposed CBCS over the existing caching schemes with some parameters changing."
  },
  {
    "year": "2016",
    "abstract": "According to the model-driven engineering paradigm, one of the entry requirements when realizing a seamless tool chain for the development of software is the definition of metamodels, to regulate the specification of models, and model transformations, for automating manipulations of models. In this context, we present a metamodel definition for the Rubus component model, an industrial solution used for the development of vehicular embedded systems. The metamodel includes the definition of structural elements as well as elements for describing timing information. In order to show how, using model-driven engineering, the integration between different modeling levels can be automated, we present a model-to-model transformation between models conforming to EAST-ADL and models described by means of the Rubus component model. To validate our solution, we exploit a set of industrial automotive applications to show the applicability of both the Rubus component model metamodel and the model transformation."
  },
  {
    "year": "2016",
    "abstract": "In the modern days of Big Data, the curation of data has become more and more important, especially for handling high volume and complex data systems. With data volumes growing exponentially, along with the increasing variety and heterogeneity of data sources, acquiring the data you may need for analysis has become a costly and time-consuming process. Multiple data sets from various sources must be first processed and connected before they can be used by big data analytics tools. Publication and presentation of data analytics are also very important. However, traditional data curation systems are not designed for this purpose and there is no consideration on the chronological values. Another limitation is that they are usually designed for programmers, not for the ordinary users. In this paper, we propose Chronological Big data Curation system. In the proposed system, acquisition and care of data are processed on the basis of relations between specific topics and chronological order to ensure that data maintains its value over time. The system is implemented and experimental results show the goodness of the proposed system."
  },
  {
    "year": "2016",
    "abstract": "Due to the scarcity of the licensed spectrum allocated for mobile communication systems, licensed-assisted access long-term evolution (LAA-LTE) network is recently proposed to deploy in unlicensed spectrum, which is currently occupied by different Wi-Fi systems. It is a very challenging problem to ensure fair coexistence between LAA-LTE and Wi-Fi networks, in terms of spectrum sharing and traffic management. To solve this problem, a fair downlink traffic management (FDTM) scheme is proposed in this paper for hybrid LAA-LTE/Wi-Fi networks. FDTM aims to tune the minimum contention window (CWmin) values and assigns feasible weights for the LAA eNBs with different traffic loads, thus to achieve; 1) fair spectrum sharing with the coexisting Wi-Fi networks in unlicensed spectrum and 2) fair service differentiation for downlink LAA-LTE traffic. Numerical results show our FDTM scheme can guarantee the throughput performance of Wi-Fi networks in shared unlicensed spectrum while supporting proportional fairness for the LAA eNBs with different traffic loads."
  },
  {
    "year": "2016",
    "abstract": "Wireless energy harvesting can improve the performance of cognitive wireless sensor networks (WSNs). This paper considers radio frequency (RF) energy harvesting from transmissions in the primary spectrum for cognitive WSNs. The overall success probability of the energy harvesting cognitive WSN depends on the transmission success probability and energy success probability. Using the tools from stochastic geometry, we show that the overall success probability can be optimized with respect to: 1) transmit power of the sensors; 2) transmit power of the primary transmitters; and 3) spatial density of the primary transmitters. In this context, an optimization algorithm is proposed to maximize the overall success probability of the WSNs. Simulation results show that the overall success probability and the throughput of the WSN can be significantly improved by optimizing the aforementioned three parameters. As RF energy harvesting can also be performed indoors, hence, our solution can be directly applied to the cognitive WSNs that are installed in smart buildings."
  },
  {
    "year": "2016",
    "abstract": "The world is facing problems, such as uneven distribution of medical resources, the growing chronic diseases, and the increasing medical expenses. Blending the latest information technology into the healthcare system will greatly mitigate the problems. This paper presents the big health application system based on the health Internet of Things and big data. The system architecture, key technologies, and typical applications of big health system are introduced in detail."
  },
  {
    "year": "2016",
    "abstract": "The Wasserstein metric or earth mover's distance is a useful tool in statistics, computer science and engineering with many applications to biological or medical imaging, among others. Especially in the light of increasingly complex data, the computation of these distances via optimal transport is often the limiting factor. Inspired by this challenge, a variety of new approaches to optimal transport has been proposed in recent years and along with these new methods comes the need for a meaningful comparison. In this paper, we introduce a benchmark for discrete optimal transport, called DOTmark, which is designed to serve as a neutral collection of problems, where discrete optimal transport methods can be tested, compared with one another, and brought to their limits on large-scale instances. It consists of a variety of grayscale images, in various resolutions and classes, such as several types of randomly generated images, classical test images and real data from microscopy. Along with the DOTmark we present a survey and a performance test for a cross section of established methods ranging from more traditional algorithms, such as the transportation simplex, to recently developed approaches, such as the shielding neighborhood method, and including also a comparison with commercial solvers."
  },
  {
    "year": "2016",
    "abstract": "IP mutation is an effective moving target defense method against sniffer or hijacking attack. The mutation frequency is one of the most important parameters that influence the security of mutation method. However, higher frequency is inconsistent with data transmission that will decrease the efficiency and stability. Moreover, most of existing mutation methods have shortcomings under various conditions, such as address allocation or network architecture. In this paper, sliding window and full transparent (SWIFT) scheme for IPv6 address mutation is proposed. With the sliding window design, the SWIFT scheme can provide an address mutation with very high frequency. This scheme is transparent to both network side and user side so that the existing equipment and architecture need not to be changed. A prototype by the SWIFT scheme is designed and developed over an IPv6 network. The experiment result shows that our method can achieve high transmission efficiency with a high mutation frequency, which provides a good experience for most mutation methods."
  },
  {
    "year": "2016",
    "abstract": "Stability region is an important and practical measure of the transmission capacity of wireless networks with stochastic flows. On the other hand, an effective interference mitigation approach, realized in the physical layer model with the flexibility to utilize past receptions, began to emerge. Nevertheless, there is still a lack of the investigation on the stability region of the interference network in this physical layer model. Thus, in this paper, we concentrate on the stability region of the two-user interference network for the aforementioned physical layer model. To this end, we first design a physical layer linear coding scheme to fully utilize past receptions. Next, on the basis of the proposed coding scheme, a queue-based transmission strategy is presented. Then, by leveraging the virtual network mechanism, we derive the stability region of the system for the proposed transmission strategy. Meanwhile, a Lyapunov-function-based stabilizing policy is presented. Finally, we compare the stability region with the information-theoretical outer bound by a numerical method. The simulation results reveal that their relative difference is no larger than 3%, and is below 0.1% under the specific setting of the probability that packets successfully arrive at each receiver, implying that the transmission strategy could essentially achieve the outer bound from the practical perspective. In particular, the stability region of the system is almost identical to its information-theoretic throughput region under the specific setting."
  },
  {
    "year": "2016",
    "abstract": "Spam over Internet telephony (SPIT) is recognized as a new threat for voice communication services such as voice over Internet protocol (VoIP). Due to the privacy reason, it is desired to detect SPITters (SPIT callers) in a VoIP service without training data. Although a clustering-based unsupervised SPITters detection scheme has been proposed, it does not work well when the SPITters account for a small fraction of the entire caller. In this paper, we propose an unsupervised SPITters detection scheme by adding artificial SPITters data to solve the unbalanced situation. The key contribution is to propose a novel way to automatically decide how much artificial data should be added. We show that classification performance is improved by means of computer simulation with real and artificial call log data sets."
  },
  {
    "year": "2016",
    "abstract": "Soft set is a mathematical tool for dealing with vague and imprecise data. It is used in many applications and decision-making after representing the uncertain data in the Boolean-valued information system (BIS). BISs become incomplete because of various reasons, such as security, viral attack, and errors. Several soft set-based approaches exist to handle incomplete BISs for decision-making. These approaches are categorized into two categories: preprocessed (PP) and unprocessed (UP). UP approaches cannot be used for the recalculation of overall missing values. Meanwhile, PP approaches can be extended to calculate the entire missing values. This paper presents the basic concept of actual technique and initially applies it to the PP incomplete soft set. This novel concept will open a new chapter for researchers in the development of applications in the fields of mathematics, especially in Boolean data, discrete mathematics, and computer science."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on detecting inconsistencies within text corpora. It is a very interesting area with many applications. Most existing methods deal with this problem using complicated textual analysis, which is known for not being accurate enough. We propose a new methodology that consists of two steps, the first one being a machine learning step that performs multilevel text categorization. The second one applies conceptual reasoning on the predicted categories in order to detect inconsistencies. This paper has been validated on a set of Islamic advisory opinions (also known as fatwas). This domain is gaining a large interest with users continuously checking the authenticity and relevance of such content. The results show that our method is very accurate and can complement existing methods using the linguistic analysis."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we introduce a novel OFDM-aided multifunctional multiple-input multiple-output scheme based on multi-set space-time shift keying (MS-STSK), where the information transmitted over each subcarrier is divided into two parts: STSK codeword and the implicit antenna combination (AC) index. In MS-STSK, a unique combination of antennas can be activated at each subcarrier to convey extra information over the AC index while additionally transmitting the STSK codeword. Furthermore, inspired by the MS-STSK concept, this scheme is extended also to the frequency domain in the novel context of our multi-space-frequency STSK (MSF-STSK), where the total number of subcarriers is partitioned into blocks to implicitly carry the block's frequency index. The proposed MSF-STSK scheme benefits from the huge bandwidths available at mmWaves for partitioning the total number of OFDM subcarriers into blocks to convey more information over the frequency domain. Both proposed systems use STSK codewords as the basic transmission block, and they can achieve higher data throughput and better BER performance than STSK. Moreover, given that the system is meant to operate at mmWaves, antenna arrays relying on several antenna elements are employed at both the transmitter and receiver for analogue beamforming with the aid of phase shifters and power amplifiers to overcome the effect of high path loss."
  },
  {
    "year": "2016",
    "abstract": "In today's increasingly rich material life, people are shifting their focus from the physical world to the spiritual world. In order to identify and care for people's emotions, human-machine interaction systems have been created. The currently available human-machine interaction systems often support the interaction between human and robot under the line-of-sight (LOS) propagation environment, while most communications in terms of human-to-human and human-to-machine are non-LOS (NLOS). In order to break the limitation of the traditional human-machine interaction system, we propose the emotion communication system based on NLOS mode. Specifically, we first define the emotion as a kind of multimedia which is similar to voice and video. The information of emotion can not only be recognized, but can also be transmitted over a long distance. Then, considering the real-time requirement of the communications between the involved parties, we propose an emotion communication protocol, which provides a reliable support for the realization of emotion communications. We design a pillow robot speech emotion communication system, where the pillow robot acts as a medium for user emotion mapping. Finally, we analyze the real-time performance of the whole communication process in the scene of a long distance communication between a mother-child users' pair, to evaluate the feasibility and effectiveness of emotion communications."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a novel intelligent disease diagnosis method based on fuzzy concept lattice. Symptoms and the corresponding extents (e.g., frequency, severity, and duration) of each disease can be extracted to form a fuzzy concept lattice. The fuzzy concept lattice of the symptoms and their extents to be diagnosed needs to be constructed to match the fuzzy concept lattice of possible diseases. The similarity between the above two types of concept lattices can be calculated and used to aid for effective diagnosis. Naturally, the disease with the largest similarity is the finding of intelligent diagnosis. In the future, more efficient fuzzy concept lattice construction method and update algorithm will be explored, which are presumed to be very complicated."
  },
  {
    "year": "2016",
    "abstract": "Recently, the increasing popularity of local area services, such as YouTube, Facebook, and Twitter, on which thousands of clients subscribe and download popular contents all the while, has drawn more and more attention on the study of content dissemination networks. Device-to-device (D2D) communication, which allows two devices to directly communicate with each other, has become an effective content dissemination method. With the goal of reducing the delay of content dissemination process with D2D communication, we propose an evolutionary game (EG)-based distributed resource allocation scheme. Moreover, we theoretically prove the existence and stability of game equilibrium and further propose a global search algorithm to achieve equilibrium. In the algorithm, all D2D links will select resource adaptively based on the predicted contact duration. Aiming at improving the prediction accuracy of contact duration, we propose social trajectory similarity (STS) to represent the overlapping of history trajectory among all the mobile users by mining user behavior patterns. Numerical results show that our proposed STS increases nearly 20% correlation with history trajectory overlap compared with jaccard index. Furthermore, our EG-based scheme reduces the delay over 15% compared with the coalition game scheme, and over 30% compared with the random selection scheme. In addition, our proposed scheme also increases throughput efficiency with nearly 20% and achieves better fairness."
  },
  {
    "year": "2016",
    "abstract": "Facebook has now become the most popular and extensively used social networking site among students of institutions of higher education. This makes it a widespread tool for communication and exchange of ideas. Notable to that is an active research in determining the utility of Facebook as a complementary tool in teaching and learning. The uses of the social networking sites especially, Facebook has been reported in a wide variety of results with respect to factors, such as students’ learning performance, involvement, and acceptance, have been reported in the literature. This paper presents a comprehensive review of recent studies that employ Facebook as a tool for teaching and learning in institutions of higher education. We analyze the use of Facebook as a teaching and learning tool for various courses. Thereafter, its impacts on enhancing student learning outcomes as well as its negative impact on students’ performance are evaluated. We also highlight the main limitations of the existing and previous studies. Future research directions for incorporating Facebook into the teaching and learning at institutions of higher education are suggested. This review is helpful to educators who plan to integrate Facebook into their teaching as well as to the researchers for further exploration of Facebook as a tool in teaching and learning."
  },
  {
    "year": "2016",
    "abstract": "In an ambient intelligence (AmI) environment, electronic devices that comprise the Internet of things (IoT) network work together seamlessly to provide a wide variety of applications and intelligent services to users. Computer-assisted pronunciation training (CAPT), a widely used application in the traditional Internet environment that corrects user’s pronunciation, is a promising service for transition to the AmI environment. However, the migration of the CAPT to the AmI environment is challenging due to its high computational requirements that is at odds with the low computational capacity of IoT members. In this paper, we propose a smartphone-assisted pronunciation learning technique based on a lightweight word recommendation method that exploits built-in functions supported by IoT members and a computationally moderate word selection method. The experimental evaluation of the proposed method demonstrates that the user pronunciation is significantly improved without incurring unacceptable computational costs for a smartphone platform."
  },
  {
    "year": "2016",
    "abstract": "In visible light communications (VLCs) relying on intensity-modulation and direct detection (IM/DD), the conversion from electrical signals to optical signals and the limited dynamic range of the light-emitting diodes (LEDs) constitute the fundamental impediments in the way of high-integrity communications, especially when orthogonal frequency-division multiplexing (OFDM) is employed. In IM/DD VLCs, only real-valued positive signals are used for signal transmission. However, the Fourier transform of OFDM systems is operated in the complex domain. In order to meet the requirements of the IM/DD VLCs, the complex-to-real conversion is achieved at the cost of reducing the bandwidth efficiency. Moreover, OFDM signals experience a high peak-to-average power ratio; hence, typically clipping is used for confining the positive-valued signals within the LED's dynamic range. However, hard clipping leads to the loss of orthogonality for optical OFDM (O-OFDM) signals, generating inter-carrier interference. As a result, the performance of the clipping-based O-OFDM systems may be severely degraded. In this paper, the concept of piecewise companding transform (CT) is introduced into the O-OFDM system advocated, forming the CTO-OFDM arrangement. We first investigate the general principles and design criteria of the piecewise CTO-OFDM. Based on our studies, three types of piecewise companders, namely, the constant probability sub-distribution function, linear PsDF (LPsDF), and the non-LPsDF-based CT, are designed. Furthermore, we investigate the nonlinear effect of hard clipping and of our CT on O-OFDM systems in the context of different scenarios by both analytical and simulation techniques. Our investigations show that the CTO-OFDM constitutes a promising signaling scheme conceived for VLCs, which exhibits a high bandwidth efficiency, high flexibility, high reliability, as well as a high data-rate, despite experiencing nonlinear distortions."
  },
  {
    "year": "2016",
    "abstract": "Physical layer security has been recently recognized as a promising new design paradigm to provide security in wireless networks. In addition to the existing conventional cryptographic methods, physical layer security exploits the dynamics of fading channels to enhance secured wireless links. In this approach, jamming plays a key role by generating noise signals to confuse the potential eavesdroppers, and significantly improves quality and reliability of secure communications between legitimate terminals. This article presents theoretical limits and practical designs of jamming approaches for physical layer security. In particular, the theoretical limits explore the achievable secrecy rates of user cooperation-based jamming whilst the centralized and game theoretic-based precoding techniques are reviewed for practical implementations. In addition, the emerging wireless energy harvesting techniques are exploited to harvest the required energy to transmit jamming signals. Future directions of these approaches and the associated research challenges are also briefly outlined."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a robot peer reciprocal learning system in which robot peers can not only cooperatively accomplish a difficult task but also help each other to learn better. In this system, each robot is an independent individual and has the ability to make individual decisions. They can communicate about image information, individual decisions, and current state to formulate mutual decisions and motions. For learning a new concept, we propose a mutual learning method, which allows the robots to learn from each other by exchanging weights in their neural network concept learning system. The simulation results show that the robots can learn from each other to build general concepts from limited training, while improving both of their performances at the same time. Finally, we design two cooperative tasks, which require the robots to formulate mutual sequential motions and keep communicating to manage their motions. The robotic experiments demonstrate that the proposed robot peer reciprocal learning system can help robots achieve difficult tasks in appropriate and cooperative ways, just as humans do."
  },
  {
    "year": "2016",
    "abstract": "Wireless mediums, such as RF, optical, or acoustical, provide finite resources for the purposes of remote sensing (such as radar) and data communications. Often, these two functions are at odds with one another and compete for these resources. Applications for wireless technology are growing rapidly, and RF convergence is already presenting itself as a requirement for both users as consumer and military system requirements evolve. The broad solution space to this complex problem encompasses cooperation or codesigning of systems with both sensing and communications functions. By jointly considering the systems during the design phase, rather than perpetuating a notion of mutual interference, both system's performance can be improved. We provide a point of departure for future researchers that will be required to solve this problem by presenting the applications, topologies, levels of system integration, the current state of the art, and outlines of future information-centric systems."
  },
  {
    "year": "2016",
    "abstract": "Heterogeneous networks (HetNets), which consist of traditional macro-cells overlaid with newly envisioned small cells (e.g., femtocells, picocells, microcells, and nanocells), are conceived as an appealing technology to satisfy the ever-increasing capacity requirements in future mobile networks. The cross-tier interference management is a challenging problem in conventional HetNets due to the large-scale deployment of small cells in random locations, and the lack of complete coordination. However, cognitive HetNets, where small-cell base stations are with cognitive capabilities (e.g., achieved through spectrum sensing), can efficiently overcome the posed challenge. In this paper, considering a two-tier cognitive HetNet, we utilize the statistic tool of stochastic geometry to model and analyze the coverage performance for macro-cell and small-cells over general Nakagami-m fading channels. Specifically, the exact closed-form expressions of outage probability for per-tier cell-edge users with and without cognitive interference coordination are derived, respectively. More attractively, the theoretically analytical results can be used to help to design the constraints on the configurations of small cells considering the minimum requirements of coverage performance for macro-cell and small-cell. Simulation results validate our analysis."
  },
  {
    "year": "2016",
    "abstract": "OpenFlow enabled networks split and separate the data and control planes of traditional networks. This design commodifies network switches and enables centralized control of the network. Control decisions are made by an OpenFlow controller, and locally cached by switches, as directed by controllers. This can significantly impact the forwarding delay incurred by packets in switches, because controllers are not necessarily co-located with switches. Only very few studies have been conducted to evaluate the performance of OpenFlow in terms of end-to-end delay. In this paper, we develop a stochastic model for the end to end delay in OpenFlow switches based on measurements made in Internet-scale experiments performed on three different platforms, i.e., Mininet, the GENI testbed, and the OF@TEIN testbed."
  },
  {
    "year": "2016",
    "abstract": "Increased energy consumption becomes a major issue in 5G cellular networks, which inspires the network operators to deploy renewable energy sources. However, due to the fluctuating nature of renewable energy sources, the energy harvested by base stations (BSs) may not fit for their load conditions. The transmit power of the BS needs to be redesigned again. Hence, this paper considers power control in energy cooperation enabled millimeter wave networks, to alleviate the harvested energy imbalance problem and reduce the energy waste. Each BS is solely powered by renewable energy sources and the harvested energy is allowed to be transferred between BSs. Each BS needs to determine whether the energy should be stored in the battery or transferred to others at each time slot. In this paper, power control is formulated as a stochastic optimization problem, aiming at maximizing the time average network utility while keeping the network stable. An online algorithm called dynamic energy-aware power allocation is proposed based on Lyapunov optimization, which does not need to acquire any statistical knowledge of channels and traffic arrivals. Simulation results show that compared with the power control scheme without energy cooperation, the proposed algorithm with energy cooperation can achieve higher network sum rate while reducing the delay and the required battery capacity."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we address the problem of social image tagging using practical vocabulary for mobile users on the social media. On the social media, images usually have an incomplete or noisy set of social tags provided by the mobile users, and we consider this issue as defective tag assignments. Previous studies on social image tagging have mostly focused on multi-label classification without considering the defective tags. In these studies, the usage of multi-label classification techniques is expected to synergically exploit the linear relations between the image features and the semantic tags. However, these approaches usually aimed to capture the linear relations from the training data while ignoring the helpful information from the test data. In addition, they failed to incorporate the non-linear associations residing in the visual features as well as in the semantic tags. To overcome these drawbacks, we introduce a novel approach based on non-linear matrix completion for image tagging task with defective tags. Specifically, we first construct the entire feature-tag matrix based on the visual features with non-linear kernel mapping. Then, we present a formal methodology together with an optimization method under the matrix completion framework to jointly complete the tags of training and test images. Experimental evaluations demonstrate that our method shows promising results on image tagging task on two benchmark social image datasets with defective tags, and establishes a baseline for such models in this research domain."
  },
  {
    "year": "2016",
    "abstract": "Smart cities are a future reality for municipalities around the world. Healthcare services play a vital role in the transformation of traditional cities into smart cities. In this paper, we present a ubiquitous and quality computer-aided blood analysis service for the detection and counting of white blood cells (WBCs) in blood samples. WBCs also called leukocytes or leucocytes are the cells of the immune system that are involved in protecting the body against both infectious disease and foreign invaders. Analysis of leukocytes provides valuable information to medical specialists, helping them in diagnosing different important hematic diseases, such as AIDS and blood cancer (Leukaemia). However, this task is prone to errors and can be time-consuming. A mobile-cloud-assisted detection and classification of leukocytes from blood smear images can enhance accuracy and speed up the detection of WBCs. In this paper, we propose a smartphone-based cloud-assisted resource aware framework for localization of WBCs within microscopic blood smear images using a trained multi-class ensemble classification mechanism in the cloud. In the proposed framework, nucleus is first segmented, followed by extraction of texture, statistical, and wavelet features. Finally, the detected WBCs are categorized into five classes: basophil, eosinophil, neutrophil, lymphocyte, and monocyte. Experimental results on numerous benchmark databases validate the effectiveness and efficiency of the proposed system in comparison to the other state-of-the-art schemes."
  },
  {
    "year": "2016",
    "abstract": "The needs and the feasibility of simultaneous computed tomography (CT) and magnetic resonance imaging (MRI) were recently reported. In this paper, a spiral magnetic resonance X-ray CT (MRX) imaging system is proposed for head and extremities imaging, which serves as a simple, cost-effective solution on the path to a full-scale CT-MRI fusion. While MRI and X-ray radiography were integrated before, we propose novel designs to acquire simultaneous CT and MR views for synchronized radiographic imaging or joint tomographic reconstruction. Our preliminary permanent magnet configurations achieve a magnetic field strength between 0.1 and 0.2 T while keeping weight low enough for portability. We have also shown that a field strength up to 0.35 T is achievable with permanent magnets that maintain a compact profile, though increased weight would hinder ease of transportation. Simulation results of a joint tomographic reconstruction scheme show the advantage of simultaneously acquired images. The proposed MRX system performs double helical scans in CT and MRI mechanisms, and has multiple niche applications, such as medical imaging on disaster sites, in battle fields, and for under-developed regions."
  },
  {
    "year": "2016",
    "abstract": "The ongoing evolution of mobile wireless communications has resulted in the vision of a multiradio heterogeneous network (HetNet) that comprises cells of different scales controlled by various radio access technologies (RATs). These emerging architectures call for more advanced methods of cross-RAT radio resource allocation, which are the primary focus of this article. In this paper, based on network flow optimization techniques, we adapt the concept of weighted α-fairness for efficient resource management in future HetNets. The corresponding scheme relies on a certain degree of centralized control of the HetNet architecture and allows to achieve the desired balance between the overall system throughput and the fairness of the resulting resource allocations based on a single parameter. Our analytical findings, validated with detailed system-level simulations, are expected to further advance the understanding of feasible resource control strategies in intelligent multi-radio networks, as well as help optimize the performance of next-generation HetNets."
  },
  {
    "year": "2016",
    "abstract": "Adaptive decayed brain emotional learning (ADBEL) network is recently proposed for the online time series forecasting problems. As opposed to other popular learning networks, such as multilayer perceptron, adaptive neuro-fuzzy inference system, and locally linear neuro-fuzzy model, ADBEL network offers lower computational complexity and fast learning, which make it an ideal candidate for the time series prediction in an online fashion. In fact, these prominent features are inherited from the mechanism employed by the limbic system of the mammalian brain in processing the external stimuli, which also forms the basis of the ADBEL network. This paper aims at further enhancing the forecasting performance of the ADBEL network through its integration with a neo-fuzzy network. The selection of the neo-fuzzy network is made as it offers features required for online prediction in real time environments including simplicity, transparency, accuracy, and lower computational complexity. Furthermore, this integration is only considered in the orbitofrontal cortex section of the ADBEL network and only three membership functions are employed to realize the neo-fuzzy neuron. Thus, the resultant neo-fuzzy integrated ADBEL (NF-ADBEL) network is still simple and can be deployed in online prediction problems. Few chaotic time series namely the Mackey glass, Lorenz, Rossler, and the Disturbance storm time index as well as the Narendra dynamic plant identification problem are used to evaluate the performance of the proposed NF-ADBEL network in terms of the root mean squared error and correlation coefficient criterions using MATLAB®programming environment."
  },
  {
    "year": "2016",
    "abstract": "This paper employs human cognitive process to analyze the cascade phenomena of subjective Web knowledge. First, the cognitive sentiment calculation is summarized in three stages. Second, attributes of users' background knowledge are mined. Clustering phenomena exist in users' background knowledge, which means that users are interested in certain kind of topics. Moreover, they tend to review external information about these topics. Third, how users' background knowledge impacts emotion decision making is analyzed. The impact is illustrated as the induction of objective and objective information. At last, the cascade phenomena of emotion propagation in cyber space are explained with users' selective emotion expression. Methods are proposed to interrupt cascade phenomena to reduce the negative impacts of cyber space to human beings. This paper mainly focuses on the psychological space and cyber space, which highlights the propagation mechanism of social emotion in cyber space."
  },
  {
    "year": "2016",
    "abstract": "This paper presents a study on joint radio resource allocation and hybrid precoding in multi-carrier massive multiple-input multiple-output communications for 5G cellular networks. In this paper, we present the resource allocation algorithm to maximize the proportional fairness (PF) spectral efficiency under the per subchannel power and the beamforming rank constraints. Two heuristic algorithms are designed. The proportional fairness hybrid beamforming algorithm provides the transmit precoder with a proportional fair spectral efficiency among users for the desired number of radio-frequency (RF) chains. Then, we transform the number of RF chains or rank constrained optimization problem into convex semidefinite programming (SDP) problem, which can be solved by standard techniques. Inspired by the formulated convex SDP problem, a low-complexity, two-step, PF-relaxed optimization algorithm has been provided for the formulated convex optimization problem. Simulation results show that the proposed suboptimal solution to the relaxed optimization problem is near-optimal for the signal-to-noise ratio SNR ≤ 10 dB and has a performance gap not greater than 2.33 b/s/Hz within the SNR range 0-25 dB. It also outperforms the maximum throughput and PF-based hybrid beamforming schemes for sum spectral efficiency, individual spectral efficiency, and fairness index."
  },
  {
    "year": "2016",
    "abstract": "The detection and recognition of partial discharge (PD) is an important topic in insulation tests and diagnoses. Take advantage of the affluent results from random matrix theory (RMT), such as eigenvalue analysis, M-P law, the ring law, and so on, a novel methodology in RMT paradigm is proposed for fast PD pulse detection in this paper. Furthermore, a scheme of time series modeling as random matrix is also proposed to extend RMT for applications with non-Gaussian noise context. Based on that, the eigenvalue distribution property is used for PD pattern recognition, which is completely new compared with traditional phase resolved PD and time-resolved PD methods. The simulation and experimental results show that the proposed methods are efficient, reliable, and feasible for PD detection and recognition especially for online applications."
  },
  {
    "year": "2016",
    "abstract": "There are not many real-time public mood tracking frameworks over social media streams at present. Real-time public mood tracking over microblogs becomes necessary for further studies with low-latency requirements. To address this issue, we propose a hierarchical framework for real-time public mood time series tracking over Chinese microblog streams using complex event processing. Complex event processing is able to handle high-speed and high-volume data streams. First, we transform microblogs into emotional microblog events through the text sentiment analysis. Then, we apply an online batch window technique to summarize the public mood in different periods. For the public mood time series, we use smoothing and trend following methods to find the rising or falling trends of the public mood. Finally, we apply the method to 6606 microblogs to verify its feasibility. The result demonstrates that the proposed model is not only feasible but also effective."
  },
  {
    "year": "2016",
    "abstract": "Small heterogeneous cells have been introduced to improve the system capacity and provide the ubiquitous service requirements. In order to make flexible deployment and management of massive small cells, the utilization of self-powered small cell base stations with energy harvesting (EH-SCBSs) is becoming a promising solution due to low-cost expenditure. However, the deployment of static EH-SCBSs entails several intractable challenges in terms of the randomness of renewable energy arrival and dynamics of traffic load with spatio-temporal fluctuation. To tackle these challenges, we develop a tractable framework of the location deployment and mobility management of EH-SCBSs with various traffic load distributions an environmental energy models. In this paper, the joint optimization problem for location deployment and mobile management is investigated for maximizing the total system utility of both users and network operators. Since the formulated problem is a NP-hard problem, we propose a low-complex algorithm that decouples the joint optimization into the location updating approach and the association matching approach. A suboptimal solution for the optimization problem can be guaranteed using the iteration of two stage approaches. Performance evaluation shows that the proposed schemes can efficiently solve the target problems while striking a better overall system utility, compared with other traditional deployment and management strategies."
  },
  {
    "year": "2016",
    "abstract": "Named data networking (NDN) as a promising future network architecture has been widely considered as a very appropriate network protocol for multihop wireless network (MWN). In named-data MWN, congestion control, forwarding strategy, and power control are three coupled critical issues. There are already extensive works about cross-layer design for MWN with IP and they have demonstrated the advantage of cross-layer design. Enlightened by cross-layer designs for MWN with IP, in this paper, the joint congestion control, forwarding strategy, and power control problem for named-data MWN are studied, and it is modeled as a named-data network utility maximization (NDNUM) problem. In our NDNUM, we maximize data receiving rate related network utility minus power consumption, while consider NDN's communication characteristics that are different from IP. Then a distributed iterative algorithm based on subgradient method is proposed in order to solve NDNUM. To the best of our knowledge, our algorithm is the first cross-layer design for congestion control and power control for named-data MWN. We show that network utility maximization not only can be used to facilitate cross-layer design for networks with end-to-end protocols but also can be used to design cross-layer mechanisms for information-centric network. From simulation, our algorithm outperforms existing congestion control mechanism in network throughput, resource utilization efficiency, and stabilization PIT size."
  },
  {
    "year": "2016",
    "abstract": "The main role of control system for wind turbines is tracking the optimal power via regulating the rotor speed of the generator. A high performance controller, which can deal with unmodeled dynamics, uncertainties, and external disturbance, can effectively increase the captured power from the wind. This paper focuses on designing an advanced sliding mode control (SMC) scheme for wind energy conversion systems (WECSs). As the proposed SMC scheme includes a nonlinear disturbance observer (DOB) for estimating aerodynamic torque and wind speed, there is no requirement to measure aerodynamic torque or wind speed. The proposed control scheme considers not only the uncertainties and disturbance but also the random nature of wind speed and intrinsic nonlinear behavior of the WESCs. Via designing sliding surface based on estimated information, the proposed control system can avoid disadvantages associated with the robust control techniques. To totally remove chattering as well as improving other control criteria, a fuzzy-based variable switching gain scheme is introduced. Comparative simulation results are shown to verify the effectiveness and superior performance of the proposed DOB-based fuzzy SMC scheme."
  },
  {
    "year": "2016",
    "abstract": "High-level synthesis (HLS)-based design methodologies are extremely viable for industries that are sensitive to production costs. In order to have competitive advantage, the ability to have several different implementations of the same algorithm satisfying a diverse range of resolution, cost, and performance constraints is highly desirable. In this paper, we present multiple hardware implementations of the semi-global matching (SGM) algorithm, which is used in stereo vision systems, e.g., for automotive applications. The hardware platform considered in this paper is a Xilinx Zynq system-on-chip. A performance comparison of both HLS-based design and a manual register transfer level (RTL) design in terms of quality of results, flexibility, and design time is also presented. SGM mainly includes a sequence of three processing steps, i.e., the “cost cube calculation” followed by the “path cost computation” and finally the “disparity approximation and minimization”. The path cost processor further performs a pixel-wise processing of the cost cube data along eight distinct path orientations. The baseline algorithmic model usually called the “golden” model utilizes considerably large arrays that are required to be mapped to an external DRAM and brought into the on-chip RAM when required. This necessitates adding both the memory transfer loops as well as insertion of calls to the AXI transactors for accessing the DRAM through the on-chip DDR slave. Furthermore, the initial algorithm (typically single-threaded) must be parallelized to fully exploit the concurrency offered by the target hardware platform. The design space exploration was thus performed by making several considerably different micro-architectural choices. Eventually, we were able to obtain an implementation comparable with the manual RTL design. Both the manual RTL and the HLS designs achieved the target real-time performance of 30 frames/s for the image resolution of 640×480 with a disparity depth of 128 pixel..."
  },
  {
    "year": "2016",
    "abstract": "With the development of wireless sensing technologies, numerous sensing applications from the Internet of Things (IoT) are widely used in life and industry. Mobile peer-to-peer (MP2P) system is one of the typical IoT applications, in which peers share their sensing information. Reciprocity-based incentive mechanisms are widely used to encourage cooperation among peers and maintain robustness of MP2P systems. However, the effectiveness of different reciprocity-based mechanisms is difficult to compare theoretically. In this paper, we propose a general evaluating framework to help design and analyze incentive mechanisms for which reciprocal peers can have different reciprocal policies. Using our proposed framework, the evolution dynamics of multiple incentive policies that coexist in MP2P systems can be analyzed. The simulation results show the system robustness and best strategies in various circumstances. In addition, we consider a most common attack model, whitewashing, in MP2P systems and bring in a small entry fee to defeat whitewashers. The results show that this framework can well defend whitewashing and is more suited for real MP2P systems."
  },
  {
    "year": "2016",
    "abstract": "The meteorological observations from satellites in the microwave domain are currently limited to below 190 GHz. The next generation of European Organization for the Exploitation of Meteorological Satellites Polar System-Second Generation will carry an instrument, the ice cloud imager (ICI), with frequencies up to 664 GHz, to improve the characterization of the cloud frozen phase. In this paper, a statistical retrieval of cloud parameters for ICI is developed, trained on a synthetic database derived from the coupling of a mesoscale cloud model and radiative transfer calculations. The hydrometeor profiles simulated with the weather research and forecasting model (WRF) for 12 diverse European mid-latitude situations are used to simulate the brightness temperatures with the atmospheric radiative transfer simulator (ARTS) to prepare the retrieval database. The WRF+ARTS simulations have been compared with the special sensor microwave imager/sounder observations up to 190 GHz: this successful evaluation gives us confidence in the simulations at the ICI channels from 183 to 664 GHz. Statistical analyses have been performed on this simulated retrieval database, showing that it is not only physically realistic but also statistically satisfactory for retrieval purposes. A first neural network (NN) classifier is used to detect the cloud presence. A second NN is developed to retrieve the liquid and ice-integrated cloud quantities over sea and land separately. The detection and retrieval of the hydrometeor quantities (i.e., ice, snow, graupel, rain, and liquid cloud) are performed with ICI-only, and with ICI combined with observations from the microwave imager (MWI, also on board MetOp-SG). The ICI channels have been optimized for the detection and quantification of the cloud frozen phase. Adding the MWI channels improves the performances of the vertically integrated content mostly for the cloud liquid phase. The relative error for the retrieved integrated frozen water content (F..."
  },
  {
    "year": "2016",
    "abstract": "Two of the most promising candidate solutions for realizing the next-generation all-IP mobile networks are Mobile IPv6 (MIPv6), which is the host-based and global mobility supporting protocol, and Proxy MIPv6 (PMIPv6), which is the network-based and localized mobility supporting protocol. However, the unprecedented growth of mobile Internet traffic has resulted in the development of distributed mobility management (DMM) architecture by the Internet engineering task force DMM working group. The extension of the basic MIPv6 and PMIPv6 to support their distributed and scalable deployment in the future is one of the major goals of the DMM working group. We propose an all-IP-based mobility management architecture that leverages the concept of Named Data Networking (NDN), which is a distributed content management and addressing architecture. In the proposed solution, mobility support services are distributed among multiple anchor points at the edge of the network, thereby enabling a flat architecture that exploits name-based routing in NDN. Our approach overcomes some of the major limitations of centralized IP mobility management solutions, by extending existing routing protocol and mobility management architecture, to distribute the mobility management function of anchor points in the IP network and optimize the transmission path of mobile traffic."
  },
  {
    "year": "2016",
    "abstract": "Small-cell caching utilizes the embedded storage of small-cell base stations (SBS) to cache popular network contents, for the purpose of reducing duplicate transmissions in mobile networks and offloading the data traffic from macro-cell base stations. In this paper, we propose a random small-cell caching system, where each SBS randomly caches a subset of popular contents with a specified caching probability. We particularly focus on the probability that mobile users can successfully download their requested files from the SBSs, namely, successfully downloading probability (SDP). A sophisticated path-loss model incorporating both line-of-sight (LoS) and non-LoS (NLoS) transmissions is introduced into the SDP analysis. By modeling the distribution of the SBSs as a Poisson point process, we develop theoretical results of the SDP performance based on stochastic geometry theory. Additionally, we investigate the impacts of the parameters of the SBSs, i.e., transmission power and deployment intensity, on the SDP. Monte Carlo simulations show the consistency with our derived SDP. Also, numerical results validate our analysis on the related parameters and their impacts on the SDP performance."
  },
  {
    "year": "2016",
    "abstract": "Maximizing network lifetime is a major objective for designing and deploying a wireless sensor network. Clustering sensor nodes is an effective topology control approach helping achieve this goal. In this paper, we present a new method to prolong the network lifetime based on the improved particle swarm optimization algorithm, which is an optimization method designed to select target nodes. The protocol takes into account both energy efficiency and transmission distance, and relay nodes are used to alleviate the excessive power consumption of the cluster heads. The proposed protocol results in better distributed sensors and a well-balanced clustering system enhancing the network's lifetime. We compare the proposed protocol with comparative protocols by varying a number of parameters, e.g., the number of nodes, the network area size, and the position of the base station. Simulation results show that the proposed protocol performs well against other comparative protocols in various scenarios."
  },
  {
    "year": "2016",
    "abstract": "Non-orthogonal multiple access (NOMA) has been conceived as a breakthrough technology for the fifth generation (5G) wireless networks. With imperfect channel state information (ICSI) taken into account, we study an NOMA-based downlink amplify-and-forward (AF) relaying network under Nakagami-m fading in this paper. First, we investigate the system outage behavior, and close-form expressions for the exact and tight lower bounds of the outage probability are attained, respectively. By further evaluating the outage probability at the high SNR region, it is observed that an error floor exists in the outage probability due to the presence of ICSI. Finally, numerical results are presented to demonstrate the validity of our analysis and show the advantages of NOMA over conventional orthogonal multiple access. Moreover, simulation results verify that the optimal relay location for NOMA should be close to the source node."
  },
  {
    "year": "2016",
    "abstract": "In the wireless transmission of multimedia information, the achievable transmission throughput and latency may be limited by the processing throughput and latency associated with source and channel coding. Ultra-high throughput and ultra-low latency processing of source and channel coding are required by the emerging new video transmission applications, such as the first-person remote control of unmanned vehicles. The recently proposed unary error correction (UEC) code facilitates the joint source and channel coding (JSCC) of video information at transmission throughputs that approach the capacity of the wireless channel. In this paper, we propose the first hardware implementation of the UEC code that achieves the high processing throughputs as well as ultra-low processing latencies required. This is achieved by extending the application of the recently proposed fully parallel turbo decoder (FPTD) from pure stand-alone channel coding to JSCC. This paper also proposes several novel improvements to the FPTD, in order to increase its hardware efficiency and supported frame length. We demonstrate the application of these improvements to both the long term evolution turbo code and the UEC code. We synthesize the proposed fully parallel design on a mid-range field programmable gate array, achieving a throughput of 450 Mbps, as well as a factor of 2.4 hardware efficiency improvement over previous implementations of the FPTD."
  },
  {
    "year": "2016",
    "abstract": "An investigation considering the efficiency gains of electrical pulse-shaping for a two-stage reluctance accelerator system has been undertaken. An optimum gross efficiency of (1.36 ± 0.02)% was achieved, amounting to an increase of (290 ± 20)% relative to the performance of an equivalent single-stage accelerator. The performance increase due to pulse-shaping for a two-stage setup was found to surpass that achieved for this single-stage setup in terms of both efficiency and velocity. This investigation highlights the potential of pulse-shaping methods to increase the feasibility and flexibility of electrical acceleration for a variety of practical applications. The intention of this paper was to exhibit the potential of reluctance acceleration technology in multi-stage, initially by using a two-stage system. Possible avenues for further investigation are proposed, to build upon the results of this study."
  },
  {
    "year": "2016",
    "abstract": "This paper focuses on the abnormal nodes detection of poisonous gas in wireless sensor networks, namely, finding these nodes whose concentrations are higher than the threshold. In order to detect abnormal nodes, we had better collect sensory data from all nodes. However, this strategy requires much more energy consumption, so we should try to wake up these nodes near the abnormal filed. Based on this observation, we propose a novel energy-efficient method to wake them up. The main idea is to let abnormal nodes send out control packets to activate their one-hop neighbor nodes; then, neighbor nodes continue detecting, and finally, all abnormal nodes send information to the sink node through the shortest paths. Thereafter, we further propose to handle these information in the sink node, including extracting boundary nodes, drawing isolines, and estimating the location of leakage source. To extract boundary nodes, we divide all abnormal nodes into different intervals in an ascending or descending order, and then find two nodes with minimum and maximum in each interval, so these nodes are regarded as boundary nodes. As to the second point, we reuse the wide-adopted interpolation methods to draw isolines, such as cubic, nearest, and invdist. Besides, we use interpolation to find the coordinate of the peak, and then, it is deemed to be the leakage source. The experimental results show that our proposed method is feasible."
  },
  {
    "year": "2016",
    "abstract": "In this paper, global stabilization is addressed for a class of large-scale nonlinear systems with time delays and unmodeled dynamics. The unmodeled dynamics are coupled with outputs in the large-scale nonlinear system. The bounded time-varying delay terms are related with all states and inputs in subsystems. Both an adaptive observer and an adaptive controller are designed to deal with the time delays and unmodeled dynamics. A numerical example is given to illustrate the effectiveness of the proposed method on the large-scale nonlinear system."
  },
  {
    "year": "2016",
    "abstract": "This paper proposes a novel sliding mode control (SMC) strategy for load frequency and voltage control in a complex power system under electrically faulty conditions. The load frequency regulation is achieved by changing the valve position of generators, while the bus voltage regulation is realized with the utilization of a popular FACTS device, Static Var Controller. Inter-area tie-line power is taken into consideration in the load frequency control so as to maintain the obligations of importing/exporting active power from/to connecting areas. The proposed control method thus operates in a quasi-decentralized manner, utilizing local frequency and voltage signals, as well as inter-area tie-line power information. An improvement is then made to the originally proposed SMC scheme to suppress its inherent fluctuations. The proposed enhanced SMC is easy to implement, and compared with conventional PI controllers, it produces superior performances in regulating frequencies and magnitudes of bus-bar voltages."
  },
  {
    "year": "2016",
    "abstract": "This paper presents position-based optimization methods to schedule the production of automatic cells of a wheel manufacturing factory. Real-time schedule is challenging when a cell is interrupted by various order changes. Given a sequence of orders to be scheduled, it is sorted based on an earliest due day policy, a mixed integer linear programming model is formulated, and then rolling-horizon optimization methods are used to timely find the near-optimal schedule by minimizing earliness and tardiness penalties with setup times of a manufacturing cell. In addition, an original schedule can be partial rescheduled with the preset order sequence by using the linear programming model. Experimental results show that the proposed method enables a wheel manufacturing cell to reschedule its three to five daily orders within the cycle time of a rim when there exist order changes, e.g., rush orders and customized orders. Hence, these proposed methods are promising to promptly derive the near-optimal schedule for satisfying the objective of mass customization for industry 4.0."
  },
  {
    "year": "2016",
    "abstract": "The lateral imaging characteristic of an acoustic lens is similar to the well-known object-image relationship of an optical lens. In this paper, axial signal analysis is carried on and reconstruction methods for a sample's axial photoacoustic (PA) image are researched based on the acoustic-lens PA imaging system. The integral and envelope methods are both proposed to reconstruct a sample's axial PA image, which has only been achieved approximately by the PA signals' peak values obtained by a peak-holding circuit in previous reports. And the envelope method is proposed for the first time. Hilbert transform was used to obtain the envelope of the sample's PA signals and axial PA images. Simulation results show that the integral method is appropriate for low frequency samples, and that the envelope reconstruction method can provide low frequency information of the PA images of samples. So for a sample, it would be best to combine the two methods together."
  },
  {
    "year": "2016",
    "abstract": "Many recently built residential houses and factories are equipped with facilities for converting energy from green sources, such as solar energy, into electricity. Electricity consumers may input the extra electricity that they do not consume into the smart grid for sale, which is allowed by law in countries such as Japan. To reduce peak-time electricity usage, time-varying pricing schemes are usually adopted in smart grids, for both the electricity sold to consumers and the electricity purchased from consumers. Thanks to the development of cyber-physical systems and advanced technologies for communication and computation, current smart grids are typically networked, and it is possible to integrate information such as weather forecasts into such a networked smart grid. Thus, we can predict future levels of electricity generation (e.g., the energy from solar and wind sources, whose generation is predominantly affected by the weather) with high accuracy using this information and historical data. The key problem for consumers then becomes how to schedule their purchases from and sales to the networked smart grid to maximize their benefits by jointly considering the current storage status, time-varying pricing, and future electricity consumption and generation. This problem is non-trivial and is vitally important for improving smart grid utilization and attracting consumer investment in new energy generation systems, among other purposes. In this paper, we target such a networked smart grid system, in which future electricity generation is predicted with reasonable accuracy based on weather forecasts. We schedule consumers’ behaviors using a Markov decision process model to optimize the consumers’ net benefits. The results of extensive simulations show that the proposed scheme significantly outperforms the baseline competing scheme."
  },
  {
    "year": "2016",
    "abstract": "Recently, several privacy-preserving auction schemes are proposed for protecting the bid privacy and securing the auction. In this paper, a sealed-bid auction scheme focusing on multi-attribute is presented. And it mainly concentrates on the security issues of multi-qualitative-attribute auction and utilizes the Pedersen commitment scheme to bind the bid information into commitment for strong bid privacy. In order to accomplish the public verifiable correctness, the buyers and sellers construct the zero-knowledge signatures of knowledge and publish them to the bulletin board. In accordance with the security analysis, major properties, strong bid privacy and public verifiability, are provided under the semi-honest model. According to a comparison of computation, the proposal's computation cost is reasonable."
  },
  {
    "year": "2016",
    "abstract": "This paper investigates the problem of almost blank subframe (ABS)-slot access in the heterogeneous networks to optimize network performance under the ABS scheme. Since maximizing network throughput requires global information and is not feasible in large scale or dense networks, the problem is solved from an interference minimization perspective after investigating the inherent relationship between local interference and achievable throughput. Since traditional binary interference model does not consider accumulated interference and thus results in inaccuracy, we take the accumulated interference into account and propose a generalized interference model, in which small cells are classified into different distant neighborhoods. An interference minimization game is formulated and is then proved to be an exact potential game, which has at least one pure Nash equilibrium (NE), and the best pure strategy NE point is a global optimum of minimizing aggregate interference. Combining the relationship between throughput and interference, the throughput maximization problem is proved to be an ordinal potential game, which possesses nice properties as well. A distributed algorithm is proposed to reach the NE, which minimizes the aggregate interference and maximizes the network throughput globally or locally. Furthermore, simulation results show that the proposed generalized interference model outperforms the traditional binary interference model."
  },
  {
    "year": "2016",
    "abstract": "Non-coherent capacity bounds for theM-ary differential chaos shift keying (DCSK) modulation system are derived and analyzed over multipath Rayleigh fading channels, deriving conditions on the channel state information/non-channel state information (CSI/NonCSI) and soft-decision/hard-decision (SD/HD), respectively. Meanwhile, the inter-symbol interference is modeled and analyzed mathematically. Through numerical simulations and analyses, it is found that: 1) the influences of the spreading factorβ, multipath numberL, modulation dimensionM, CSI/NonCSI, and SD/HD on the non-coherent capacity bounds are significant; 2) there is a relatively broad range of code rates corresponding to the optimal system power in U-shaped capacity curves of the non-coherent reception; and 3) the U-shaped non-coherent capacity bounds are proven to exist by investigating the mechanism of the low density parity check coded theM-ary DCSK system. These results are useful as benchmarks for designing power-efficient codedM-ary DCSK systems."
  },
  {
    "year": "2016",
    "abstract": "Electrocardiogram (ECG) signal is a direct and effective way to find cardiovascular disease timely, which can intuitively reflect changes of the heart beat and activities of different parts. Due to the noise interference from surroundings, acquisition of real-time and high-quality ECG signal is a big challenge for portable mobile medical systems. Integer coefficients infinite impulse response (IIR) digital filter is suitable for portable mobile platform, but it will be a little bit of distortion. So, an improved integer IIR filter for portable ECG monitors is presented in this paper. The proposed IIR filter can instantaneously and effectively eliminate baseline drift of main interference frequency band and 50-Hz power frequency interference in ECG signal. The method is verified by a specific example and MIT/BIH Arrhythmia Database. The improved integer coefficients IIR filter was applied in a portable mobile medical system. It can meet the requirements of ECG filtering in real-time and filtering performance."
  },
  {
    "year": "2016",
    "abstract": "Load balancing is a critical problem within storage clusters. Existing algorithms often require high communication overhead, because they have to collect sufficient information that they can then use to dispatch requests for hotspot data fairly. We propose an efficient scheme to achieve approximately optimal load balancing while keeping communication overhead low, namely, self-adaptive replication management (SARM). Our approach estimates the access strength of hotspot data and establishes adequate number of replicas on nodes based on their load conditions. Each node uses a dynamic scheduling algorithm to address requests for hotspot data. If the load conditions of all dispatched nodes exceed the fair load estimate, a minimum scheduling algorithm is used to dispatch the requests; otherwise, a probabilistic scheduling algorithm is adopted instead. In another word, SARM automatically switches the scheduling algorithms according to fair load estimates and the load conditions on nodes. Consequently, it eliminates request burstiness while achieving stable load balancing. To avoid excessive communication overhead, the fair load estimates are updated within a fixed time interval. Moreover, when the load variations in a node exceed a specific threshold, their load conditions are dynamically updated to other nodes. Finally, we also consider data availability in SARM. We present simulations and analysis on the performance of our approach compared with other schemes under a variety of load conditions."
  },
  {
    "year": "2016",
    "abstract": "The service requests of intra-datacenter networks (intra-DCNs) are different from the traffic demands of traditional transport networks in the following features. First, the latter is typically generated between dedicated node pairs that only require sufficient transmission bandwidth. Intra-DCN service requests, in contrast, require IT resources, such as computational, memory and storage resources, in addition to the transmission bandwidth. Second, for a given intra-DCN service request, any intra-DCN node that can provide the required IT resources can serve as a destination node (i.e., anycast). Thus, this type of network poses an important research problem of routing and spectrum/IT resource assignment (RSIA). To support these features, we first develop an integer linear programming (ILP) model to address the static RSIA problem, and then to propose efficient heuristic algorithms to address the dynamic RSIA issues, subject to the intra-DCNs' limited network resources. The results of the proposed ILP model and heuristic algorithms are compared with the traditional network models and algorithms. It is found that the proposed ILP model and heuristic algorithms perform much better than the traditional approaches in terms of using intra-DCN network resources and reducing the service-request blocking probability."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio sensor networks (CRSNs) is the state-of-the-art communication paradigm for power constrained short range data communication. It is one of the potential technologies adopted for Internet of Things (IoT) and other futuristic machine-to-machine-based applications. Many of these applications are power constrained and delay sensitive. Therefore, CRSN architecture must be coupled with different adaptive and robust communication schemes to take care of the delay and energy efficiency at the same time. Considering the tradeoff that exists in terms of energy efficiency and overhead delay for a given data packet length, it is proposed to transmit the physical layer payload with an optimal packet size (OPS) depending on the network condition. Furthermore, due to the cognitive feature of CRSN architecture overhead energy consumption due to channel sensing and channel handoff plays a critical role. Based on the above premises, in this paper, we propose a heuristic exhaustive search-based Algorithm-1 and a computationally efficient suboptimal low complexity Karuh-Kuhn-Tucker (KKT) condition-based Algorithm-2 to determine the OPS in CRSN architecture using variable rate m-QAM modulation. The proposed algorithms are implemented along with two main cognitive radio assisted channel access strategies based on distributed time slotted-cognitive medium access control (DTS-CMAC) and centralized common control channel-based cognitive medium access control (CC-CMAC) and their performances are compared. The simulation results reveal that proposed Algorithm-2 outperforms Algorithm-1 by a significant margin in terms of its implementation time. For the exhaustive search-based Algorithm-1 the average time consumed to determine OPS for a given number of cognitive users is 1.2 s, while for KKT-based Algorithm-2, it is of the order of 5-10 ms. CC-CMAC with OPS is most efficient in terms of overall energy consumption but incurs more delay as compared to DTS-CMAC with OPS scheme."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we study the distributed energy-based detectors for spectrum sensing in cognitive radio networks. We assume that the sensing channel includes both small-scale and large-scale fading. The small-scale fading is modeled as Nakagami-m and independent for different cooperating cognitive users, while the large-scale fading is assumed to be known (or can be estimated) by the cognitive users, due to their slowly changing nature. Furthermore, we assume that the channel gains are constant in one observation interval and vary independently in different intervals. Based on the Bayesian rule, we derive the optimal energy combining rule, i.e., the average likelihood ratio (ALR) detector. We also suggest two solutions: 1) mixture of gamma (MoG)-based ALR detector and 2) generalized Gauss-Laguerre formula (GLF)-based ALR detector, to overcome the problem of the intractable integrals in the optimal rule, and we propose two novel suboptimal but practical combining rules: 1) GLF-based linear combining detector, which can be implemented by linear functions and a comparator with negligible performance degradation and 2) GLF-based weighted-energy detector applicable for the low SNR regime. The simulation results reveal that with MoG and GLF detectors, the ALR detector can be implemented almost precisely with lower complexity. Moreover, all the proposed detectors outperform the conventional ones, especially when large-scale channel gains differ for different cognitive users."
  },
  {
    "year": "2016",
    "abstract": "Locality preserving projection (LPP) is a classical tool for dimensionality reduction problems. However, it is sensitive to outliers because of utilizing the ℓ2-norm-based distance criterion. In this paper, we propose a new approach, termed Euler-LPP, by preserving the local structures of data under the distance criterion of the cosine-based dissimilarity. Euler-LPP is robust to outliers in that the cosine-based dissimilarity suppresses the influence of outliers more efficiently than the ℓ2-norm. An explicit mapping, defined by a complex kernel (euler kernel) is adopted to map the data from the input space to complex reproducing kernel Hilbert spaces (CRKHSs), in which the distance of the data pairs under the ℓ2-norm is equal to that in the input space under the cosine-based dissimilarity. Thus, the robust dimensionality problem can be directly solved in CRKHS, where the solution is guaranteed to converge to a global minimum. In addition, Euler-LPP is easy to implement without significantly increasing computational complexity. Experiment results on several benchmark databases confirm the effectiveness of the proposed method."
  },
  {
    "year": "2016",
    "abstract": "As more and more ontologies are defined with different terms, ontology matching plays a crucial role in addressing the semantic heterogeneity problem in many different disciplines. Many efforts have been made to discover correspondences among terms in different ontologies. Most studies directly match two ontologies by utilizing terminological and structural methods that rely on ontologies themselves only. However, the decentralized characteristic of ontologies raises the uncertainty in ontology matching. To address this problem, we propose a four-stage ontology matching framework (FOMF) to enhance ontology matching performance. It is built upon the commonly accepted claim that an external comprehensive knowledge base can be used as a semantic bridge between domain ontologies for ontology matching. First, FOMF semantically maps domain ontologies to a knowledge base and then produces different types of alignments, including equivalence, subclass, sameas, and instance alignments. Similarities between two domain ontologies are next employed to enhance the equivalence and sameas alignments discovery. Finally, based on acquired alignments, inferred alignments are deduced to guarantee the completeness of matching results. Our experimental results show the superiority of the proposed method over the existing ones."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we develop and put into practice an automatic optical inspection (AOI) system based on machine vision to check the holes on a printed circuit board (PCB). We incorporate the hardware and software. For the hardware part, we combine a PC, the three-axis positioning system, a lighting device, and charge-coupled device cameras. For the software part, we utilize image registration, image segmentation, drill numbering, drill contrast, and defect displays to achieve this system. Results indicated that an accuracy of 5 μm could be achieved in errors of the PCB holes allowing comparisons to be made. This is significant in inspecting the missing, the multi-hole, and the incorrect location of the holes. However, previous work only focuses on one or other feature of the holes. Our research is able to assess multiple features: missing holes, incorrectly located holes, and excessive holes. Equally, our results could be displayed as a bar chart and target plot. This has not been achieved before. These displays help users to analyze the causes of errors and immediately correct the problems. In addition, this AOI system is valuable for checking a large number of holes and finding out the defective ones on a PCB. Meanwhile, we apply a 0.1-mm image resolution, which is better than others used in industry. We set a detecting standard based on 2-mm diameter of circles to diagnose the quality of the holes within 10 s."
  },
  {
    "year": "2016",
    "abstract": "With the popularity of social network-based services, the unprecedented growth of mobile date traffic has brought a heavy burden on the traditional cellular networks. Device-to-device (D2D) communication, as a promising solution to overcome wireless spectrum crisis, can enable fast content delivery based on user activities in social networks. In this paper, we address the content delivery problem related to optimization of peer discovery and resource allocation by combining both the social and physical layer information in D2D underlay networks. The social relationship, which is modeled as the probability of selecting similar contents and estimated by using the Bayesian nonparametric models, is used as a weight to characterize the impact of social features on D2D pair formation and content sharing. Next, we propose a 3-D iterative matching algorithm to maximize the sum rate of D2D pairs weighted by the intensity of social relationships while guaranteeing the quality of service requirements of both cellular and D2D links simultaneously. Moreover, we prove that the proposed algorithm converges to a stable matching and is weak Pareto optimal, and also provide the theoretical complexity. Simulation results show that the algorithm is able to achieve more than 90% of the optimum performance with a computation complexity 1000 times lower than the exhaustive matching algorithm. It is also demonstrated that the satisfaction performance of D2D receivers can be increased significantly by incorporating social relationships into the resource allocation design."
  },
  {
    "year": "2016",
    "abstract": "With the rise and widespread deployment of a vast array of wireless radio access technologies (e.g., 3G, 4G/LTE, 802.11, Bluetooth, and Femto) and the growth of interest in potential 5G technologies such as millimeter-wave radio, coupled with the rapid increase in the number of network edge devices with multiple radio interfaces, the question of network control and client-to-base-station association becomes an important issue. Older, well-studied centralized control schemes where a single computational entity harvests channel information from individual clients in order to determine optimal resource allocations for each client is no longer tenable: such methods require significant signaling overhead which does not scale well with the expected number of hundreds of thousands of smart client devices with multiple radio interfaces capable of leveraging many different radio access technologies (RATs). With the rise of these smart devices, which come with significant computational power, it is now possible to ask the question: can the network allow the client control over RAT selection and association in order to meet some client-driven or network-driven objective, and to what degree does the network assist the client in making these choices? This question becomes particularly important given the increasing interest in standardization and deployment of client-controlled edge networking, or Fog networking. In this paper, we explore the spectrum of client-controlled HetNets for 5G networks: from the fully devolved distributed local control approach, where clients make local decisions without any assistance from the network, to the hybrid control approach where clients may make decisions given some global information provided by the network."
  },
  {
    "year": "2016",
    "abstract": "Social networking services are not limited to person-to-person communication, but extend to a wider range involving person-to-thing communication and thing-to-thing communication. Therefore, it is also called big social networking services. In order to motivate users of online social networks to share information and communicate with each other frequently, we first analyzed the activity statuses of users in one of famous social networks, Weibo, and then proposed a lurker game model for accumulating big data. In addition to the features of the public goods game, this model also introduces the factor of individual incentive depending on his degree. We found that the individual strategy to be chosen was not relevant to the user's degree, but to an incentive constant of the entire network. The simulation results showed that individual strategies asymptotically followed three different behaviors according to the dynamic organization of the individuals. Active users will emerge during the evolutionary process with an incentive. Without an incentive, active central users can hardly affect the states of their neighbors and may even become lurkers due to the large number of lurking neighbors. Large noise decreases the influence of the high incentive and causes the chaos of networks. If the continuous chaos exists, active users will gradually lose interest and leave the network."
  },
  {
    "year": "2016",
    "abstract": "On all continents, assessing efforts to make information and communication technologies available throughout a territory has become a necessity. As part of universal access and service, this paper aims at assessing the impact of radio access technologies on universal access indicator. To achieve this, a mathematical model has been developed to deal with locality coverage and broadband needs, based on a methodological approach consisting in integrating parameters linked to access index through radio technologies. This approach has been applied to a real case study of the state of Ouaddaï in Chad, which has contributed to highlight its relative simplicity of implementation."
  },
  {
    "year": "2016",
    "abstract": "Commonly, navigation uses global positioning system/network (GPS) signals to determine location. In addition, GPS data can be collected over time to determine the path taken. In spite of the ubiquity of GPS signals on the earth's surface, there are certain locations where GPS signals are not available, such as inside buildings or tunnels. Therefore, to determine accurate positioning in areas where the GPS signals are unavailable, an inertial measurement unit (IMU) can be used in conjunction with the GPS data. Modern IMUs are small enough to be contained in Microelectromechanical systems (MEMS) chips, including smartphone devices, such as iPhones. This paper studies the integration between the GPS signal and the collected data from smartphones' MEMS sensors. It also investigates the possibility of using the integrated GPS/MEMS information to estimate route when the GPS signal is missing. We propose estimating the missing GPS signal by sensor integration of smartphone data. This paper would enhance the GPS navigation to determine exact positions even in the case of signal failures. Modern IMUs are expensive, and this paper shows that GPS/IMU integration can be accomplished with off-the-shelf navigational components. This paper proposes a novel technique for estimating the missing GPS route by integrating data from the sensors available in modern smartphones."
  },
  {
    "year": "2016",
    "abstract": "Scheduling different types of data packets, such as high or low priority data packets at the sender node, is important for reducing energy and capacity consumptions and end-to-end delay. Current scheduling schemes of wireless sensor networks use preemptive and non-preemptive scheduling algorithms, which incur relatively long end-to-end transmission delay and high processing overhead. Besides, they do not consider the path capacity, which represents the capacity of the network for transferring as much as sensory data to the sink node(s). Consequently, sensory data are routed to the sink node(s), whatever they are more or less, important for supporting domain applications. To remedy this issue, we propose a method, which differentiates between high and low priority when routing sensory data to the sink node(s). Specifically, the priority of sensory data is determined through a novel capacity assignment mechanism. When the network capacity, which depends on the capacity of routing paths, may not be sufficient for supporting the sensory data routing requirement, sensory data with a relatively high priority should be routed to the sink node(s), while that with a relatively low priority may be decreased or prohibited. Experimental evaluation has been conducted, and the result shows that congestion and packets dropping are reduced, when sensory data can be differentiated in their priority and the network traffic is relatively heavy."
  },
  {
    "year": "2016",
    "abstract": "In this paper, we present the design and analysis of an energy-efficient 163-b elliptic curve cryptographic (ECC) processor suitable for passive ultrahigh frequency (UHF) radio frequency identification (RFID) tags that are usable for banknote authentication and anti-counterfeiting. Even partial public key cryptographic functionality has long been thought to consume too much power and to be too slow to be usable in passive UHF RFID systems. Utilizing a low-power design strategy with optimized register file management and an architecture based on the López-Dahab Algorithm, we designed a low-power ECC processor that is used with a modified ECC-DH authentication protocol. The ECC-DH authentication protocol is compatible with the ISO/IEC 18000-63 (“Gen2”) passive UHF RFID protocol. The ECC processor requires 12 145 gate equivalents. The ECC processor consumes 5.04 nJ/b at a frequency of 960 kHz when implemented in a 0.13-μm standard CMOS process. The tag identity authentication function requires 30 600 cycles to complete all scalar multiplication operations. This size, speed, and power of the ECC processor makes it practical to use within a passive UHF RFID tag and achieve up to 1500 banknote authentications per minute, which is sufficient for use in the fastest banknote counting machines."
  },
  {
    "year": "2016",
    "abstract": "A method for estimating Doppler velocities using ultra-wideband radar data is presented. Unlike conventional time-frequency analysis, the proposed method can directly obtain Doppler velocities without searching for peaks in a spectrum. By exploiting closed-form solutions for the Doppler velocities, it avoids the trade-off between time and frequency resolution, thus maintaining high time resolution. Both simulations and measurements are used to evaluate the proposed method versus conventional techniques."
  },
  {
    "year": "2016",
    "abstract": "The use of Markov random fields (MRFs) is a common approach for performing image segmentation, where the problem is modeled using MRFs that incorporate priors on neighborhood nodes to allow for efficient Maximum a Posteriori inference. These local MRF models often result in smoothed segmentation boundaries, since they penalize the assignment of different labels to neighboring pixels and are limited in the use of long-range interactions. Although recent work on fully connected random fields and deep random fields has shown to be very promising in addressing these issues, both streams of approaches face certain limitations, which could affect inference performance and computational tractability. In this paper, we introduce the concept of deep randomly connected conditional random fields DRCRF, which fuse fully-connected random fields and deep random fields together to obtain benefits from long-range interactions while allowing for efficient inference using arbitrary potential functions. Leveraging random graph theory, the concept of stochastic cliques is incorporated into a deep CRF structure to take better advantage of long-range interactions while maintaining computational tractability. The experimental results demonstrate that the proposed DRCRF framework outperforms existing fully connected CRF frameworks and provides results comparable to the principled deep random field framework, which is among the state of the art in random field frameworks for image segmentation."
  },
  {
    "year": "2016",
    "abstract": "Time-domain (TD) statistical features are frequently utilized in vibration-based pattern recognition (PR) models to identify faults in rotating machinery. Presence of possible fluctuations or spikes in random vibration signals can considerably affect the statistical values of the extracted features consequently. This paper discusses the sensitivity of TD features against the fluctuations occurred in vibration signals while classifying localized faults in ball bearing. Based on the sensitivity level, the features are statistically processed prior to employing a classifier in PR model. A central tendency-based feature pre-processing technique is proposed that enhances the diagnostic capability of classifiers by providing appropriate values. The feature processing reduces undesired impact of fluctuations on the diagnostic model. Several classifiers are utilized to evaluate the performance of the proposed method, and the results are evident of its effectiveness. The associated advantage of the feature pre-processing over the conventional pre-processing of raw data is its computational efficiency. It is worth mentioning that only few values in feature distributions are required to be processed rather than dealing with big TD vibration data set."
  },
  {
    "year": "2016",
    "abstract": "The active charge accumulator (ACA) is a pressure converter device in a water-hydraulic system that is able to increase and decrease pressure without using a pressure-regulating valve. The basic characteristics of ACAs, however, have not yet been sufficiently revealed. In this paper, we experimentally examined the basic characteristics of ACAs with focus placed on how ACAs reduce pressure. This examination has revealed that the piston stroke of ACAs depends on the load flow rate as well as the valve switching timing. We theoretically analyzed these phenomena using a mathematical model. With an analytic model built taking into consideration the compressibility of the working fluid, valve performance level, and other elements, we made a comparison between the analytic and experimental results to verify the validity of our analysis. This comparison revealed that the pressure waveforms in the low-pressure and pressure-conversion sections obtained through the analysis agreed with those obtained through the experiments, indicating that the analytic model was valid."
  },
  {
    "year": "2016",
    "abstract": "Index modulation has become a promising technique in the context of orthogonal frequency division multiplexing (OFDM), whereby the specific activation of the frequency domain subcarriers is used for implicitly conveying extra information, hence improving the achievable throughput at a given bit error ratio (BER) performance. In this paper, a dual-mode OFDM technique (DM-OFDM) is proposed, which is combined with index modulation and enhances the attainable throughput of conventional index-modulation-based OFDM. In particular, the subcarriers are divided into several subblocks, and in each subblock, all the subcarriers are partitioned into two groups, modulated by a pair of distinguishable modem-mode constellations, respectively. Hence, the information bits are conveyed not only by the classic constellation symbols, but also implicitly by the specific activated subcarrier indices, representing the subcarriers' constellation mode. At the receiver, a maximum likelihood (ML) detector and a reduced-complexity near optimal log-likelihood ratio-based detector are invoked for demodulation. The minimum distance between the different legitimate realizations of the OFDM subblocks is calculated for characterizing the performance of DM-OFDM. Then, the associated theoretical analysis based on the pairwise error probability is carried out for estimating the BER of DM-OFDM. Furthermore, the simulation results confirm that at a given throughput, DM-OFDM achieves a considerably better BER performance than other OFDM systems using index modulation, while imposing the same or lower computational complexity. The results also demonstrate that the performance of the proposed low-complexity detector is indistinguishable from that of the ML detector, provided that the system's signal to noise ratio is sufficiently high."
  },
  {
    "year": "2016",
    "abstract": "The tremendously large number of increasing Internet protocol (IP) packets call for quality of service (QoS) guaranteed packets transmission with low-delay, high throughput, and high energy efficiency (defined as the transmitted bits per unit energy consumption) in the fifth-generation (5G) networks. For this motivation, wavelength division multiplexing (WDM) networks and the next generation of wireless technologies are two major methods in the wired and wireless networks, respectively. However, the existing energy efficient switch fabric and wireless technologies have focused on either wired or wireless networks, only separately. The joint cross-networks optimization for energy efficiency in 5G remains unexplored. This does not fully facilitate the QoS guaranteed packets transmission and energy efficient networks planning from the viewpoint of cross networks. In this paper, we formulate a joint optimization model to enhance the performance of energy efficiency in 5G. In particular, each base station is equipped with a set of parallel tunable lasers for simultaneous transmission of multiple packets from the uplink users in the cell as well as the data center networks. We propose a novel joint cross-networks scheduling and routing (JCNSR) algorithm according to the wireless channel quality of users, user data rate, and the topology constraint. The IP packets are then delivered to the targeted cells via a transport layer in the WDM network and further transmitted to the targeted users via wireless channels under the constraint of delay. Based on the idea of the cross-networks tradeoff between the delay and the energy efficiency, JCNSR can achieve high-energy efficient transmission with performance guarantee. The effectiveness of the proposed framework is verified by extensive simulations."
  },
  {
    "year": "2016",
    "abstract": "The specific family of device-to-device (D2D) communication underlying downlink cellular networks eliminates the reliance on base stations for its transmission by allowing direct transmission between two devices in each other's close proximity that reuse the cellular resource blocks for enhancing the attainable network capacity and spectrum efficiency. By considering downlink resource reuse and energy harvesting (EH), our goal is to maximize the sum-rate of the D2D links, without degrading the quality-of-service requirement of the cellular users. We formulated a sum-rate maximization problem of joint resource block and power allocation for the D2D links, which resulted in a non-convex problem that was then transformed into a more tractable convex optimization problem. Based on the results of our Lagrangian constrained optimization, we propose joint resource block and power allocation algorithms for the D2D links, when there is non-causal (offline) and causal (online) knowledge of the EH profiles at the D2D transmitters. The performance of the algorithms is quantified using simulation results for different network parameters settings, where our online algorithm performs close to the upper bound provided by our offline algorithm."
  },
  {
    "year": "2016",
    "abstract": "We investigate the problem of multichannel allocation for small-cell users (SUs) in 5G heterogeneous cellular networks by taking users' quality of experience (QoE) into account. In most existing channel allocation approaches, they are assumed that each user can only transmit on one channel, and the optimization goal is the network throughput without considering users' QoE demands. Moreover, the individual QoE losses of macro-cell users (MUs), which are caused by the cross-tiered interference, are not considered. In this paper, considering SUs' QoE demands and the individual QoE losses of MUs, we propose a joint matching-coalitional game theoretical scheme to solve such a QoE-based multichannel allocation problem with individual cross-tiered interference constraint in each channel. Concretely, according to the different interference and competition relationships among users, we divide the complicated problem into two subproblems, i.e., Q1 : intra-cell channel allocation for SUs, and Q2: inter-cell channel allocation for small-cell base stations. We formulate the intra-cell channel allocation as a many-to-one selfish matching game and formulate the inter-cell channel allocation subproblem as an altruistical coalitional game separately. Then, the complicated problem can be solved based on the two proposed games iteratively. We propose a joint channel allocation algorithm for the matching-coalitional game theoretical scheme. We prove that the proposed algorithm converges to a stable channel allocation profile. Simulation results show that the proposed algorithm achieves higher global SUs' satisfaction than the smallest interference channel selection and random allocation."
  },
  {
    "year": "2016",
    "abstract": "To further boost the performance of LTE to meet the ever-increasing mobile traffic demand in a cost-effective way, applying LTE in unlicensed spectrum, known as LTE-U technology, is considered as a promising complementary solution for achieving the ultra-capacity foreseen in 5G and beyond. In the unlicensed spectrum, LTE-U will share the channel with other unlicensed networks, e.g., Wi-Fi. However, the centralized control architecture of LTE networks is inherently different from the distributed channel access of Wi-Fi network, which poses great challenges to achieve fair coexistence of the two networks. To this end, in this paper, we propose a cross-layer proportional fairness (PF)-based framework to jointly optimize the protocol parameters of the medium access control layer and physical layer of an LTE-U network. Specifically, to achieve throughput-oriented PF between the two heterogeneous networks, the cross-layer optimization framework can be decoupled into a device number weighted time occupation ratio-oriented PF optimization problem and a channel-power allocation-based instantaneous transmission rate-oriented PF optimization problem. Given that LTE-U base stations adopt a listen-before-talk-based channel access scheme, the interactions between the LTE-U and the Wi-Fi networks are modeled by two interactive Markov chains. The effectiveness and the superior performance of the proposed cross-layer PF-based optimization framework are demonstrated and verified by simulations."
  },
  {
    "year": "2016",
    "abstract": "There has been recently a growing trend of using live video feeds in mission-critical applications. Real-time video streaming from the front-end personnel or mobile agents is believed to substantially improve the situational awareness in mission-critical operations, such as disaster relief, law enforcement, and emergency response. Mobile ad hoc networks (MANETs) are a natural contender in such contexts. However, classical MANET routing schemes fall short in terms of scalability, bandwidth, and latency; all the three metrics being quite essential for mission-critical applications. As such, autonomous cooperative routing (ACR) has gained traction as the most viable MANET proposition. Nonetheless, ACR is also associated with a few implementation challenges. If they go unaddressed, will deem ACR practically useless. In this paper, efficient and low-complexity remedies to those issues are presented, analyzed, and validated. The validation is based on field experiments carried out using software-defined radio platforms. Compared with the classical MANET routing schemes, ACR was shown to offer up to two times better throughput, more than four times reduction in end-to-end latency, while observing a given target of transport rate normalized to energy consumption."
  },
  {
    "year": "2016",
    "abstract": "The explosive increasing of the social media data on the Web has created and promoted the development of the social media big data mining area welcomed by researchers from both academia and industry. The sentiment computing of news event is a significant component of the social media big data. It has also attracted a lot of researches, which could support many real-world applications, such as public opinion monitoring for governments and news recommendation for Websites. However, existing sentiment computing methods are mainly based on the standard emotion thesaurus or supervised methods, which are not scalable to the social media big data. Therefore, we propose an innovative method to do the sentiment computing for news events. More specially, based on the social media data (i.e., words and emoticons) of a news event, a word emotion association network (WEAN) is built to jointly express its semantic and emotion, which lays the foundation for the news event sentiment computation. Based on WEAN, a word emotion computation algorithm is proposed to obtain the initial words emotion, which are further refined through the standard emotion thesaurus. With the words emotion in hand, we can compute every sentence's sentiment. Experimental results on real-world data sets demonstrate the excellent performance of the proposed method on the emotion computing for news events."
  },
  {
    "year": "2016",
    "abstract": "Engagement is crucial to designing intelligent systems that can adapt to the characteristics of their users. This paper focuses on the automatic analysis and classification of engagement based on humans' and robot's personality profiles in a triadic human-human-robot interaction setting. More explicitly, we present a study that involves two participants interacting with a humanoid robot, and investigate how participants' personalities can be used together with the robot's personality to predict the engagement state of each participant. The fully automatic system is first trained to predict the Big Five personality traits of each participant by extracting individual and interpersonal features from their nonverbal behavioural cues. Second, the output of the personality prediction system is used as an input to the engagement classification system. Third, we focus on the concept of “group engagement”, which we define as the collective engagement of the participants with the robot, and analyze the impact of similar and dissimilar personalities on the engagement classification. Our experimental results show that: 1) using the automatically predicted personality labels for engagement classification yields an F-measure on par with using the manually annotated personality labels, demonstrating the effectiveness of the automatic personality prediction module proposed; 2) using the individual and interpersonal features without utilizing personality information is not sufficient for engagement classification, instead incorporating the participants and robots personalities with individual/interpersonal features increases engagement classification performance; and 3) the best classification performance is achieved when the participants and the robot are extroverted, while the worst results are obtained when all are introverted."
  },
  {
    "year": "2016",
    "abstract": "Collaborative filtering is now successfully applied to recommender systems. The availability of extensive personal data is necessary for generating high quality recommendations. However, traditional collaborative filtering methods suffer from sparse and sometimes cold-start problems, particularly for newly deployed recommenders. Currently, several recommender systems exist in good working order, and data collected from these existing systems should be valuable for newly deployed recommenders. This paper introduces a privacy preserving shared collaborative filtering problem in order to leverage the data from other parties (contributors) to improve its own (beneficiaries) collaborative filtering performance, with the privacy protected under a differential privacy framework. It proposes a two-step methodology to solve this problem. First, item-based neighborhood information is selected as the shared data from the contributor with guaranteed differential privacy, and a practical enforcement mechanism for differential privacy is proposed. Second, two novel algorithms are developed to enable the beneficiary to leverage the shared data to support improved collaborative filtering. The extensive experimental results show that the proposed methodology can increase the recommendation accuracy of the beneficiary significantly while preserving data privacy for the contributors."
  },
  {
    "year": "2016",
    "abstract": "Attribute-based encryption, especially for ciphertext-policy attribute-based encryption, can fulfill the functionality of fine-grained access control in cloud storage systems. Since users' attributes may be issued by multiple attribute authorities, multi-authority ciphertext-policy attribute-based encryption is an emerging cryptographic primitive for enforcing attribute-based access control on outsourced data. However, most of the existing multi-authority attribute-based systems are either insecure in attribute-level revocation or lack of efficiency in communication overhead and computation cost. In this paper, we propose an attribute-based access control scheme with two-factor protection for multi-authority cloud storage systems. In our proposed scheme, any user can recover the outsourced data if and only if this user holds sufficient attribute secret keys with respect to the access policy and authorization key in regard to the outsourced data. In addition, the proposed scheme enjoys the properties of constant-size ciphertext and small computation cost. Besides supporting the attribute-level revocation, our proposed scheme allows data owner to carry out the user-level revocation. The security analysis, performance comparisons, and experimental results indicate that our proposed scheme is not only secure but also practical."
  },
  {
    "year": "2016",
    "abstract": "Integrated analysis is an important method for data analysis. Aimed at improving the deficiencies of traditional integrated data stream analysis, a human-like remembering and forgetting mechanism is introduced into data stream analysis, and a deep data stream analysis model based on remembering (DSAR) is proposed. Through this remembering and forgetting mechanism, the model regards basic classifiers as system-obtained knowledge and not only stores useful basic classifiers in a “remembering library” to improve prediction stability but also selects good basic classifiers to participate in integrated prediction, thus improving its ability to accommodate conceptual variations. Based on the DSAR model, an integrated deep data stream analysis (DDSA) algorithm is proposed. The algorithm uses the forgetting curve and a selective ensemble classifier to simulate human thinking. Compared with four typical data stream analysis algorithms, the DDSA algorithm has a high classification accuracy and a strong capacity for accommodating concept drift features (CDFs) within data stream analysis. The DDSA is particularly adaptable to complex CDFs in practical applications. Experiments show that the proposed algorithm can not only adapt to new concept changes quickly but also effectively resist the impact of random fluctuations on system performance."
  },
  {
    "year": "2016",
    "abstract": "Pilot contamination (PC) is a major impediment of large-scale multi-cell multiple-input multiple-output systems. Hence, we propose an optimal pilot design for time-domain channel estimation, which is capable of completely eliminating PC. More specifically, a sophisticated combination of downlink training and “scheduled”uplink training is designed with the aid of the optimal pilot set. Given the optimal pilot set, every user acquires its unique downlink time-domain channel state information (CSI) through downlink training. The estimated downlink CSIs are then embedded in the uplink training. As a result, PC can be completely eliminated, at the cost of a slight increase in training computational complexity. Our simulation results demonstrate the power of the proposed scheme. Most significantly, our scheme imposes a modest training overhead of (L + 3), training-phase durations corresponding to the number of orthogonal frequency division multiplexing symbols, where L is the number of cells, which is substantially lower than that imposed by some of the existing PC elimination schemes. Therefore, it imposes a less stringent requirement on the channel's coherence time. Finally, our scheme does not need any information exchange between base stations."
  },
  {
    "year": "2016",
    "abstract": "Investigating the model ship dynamic positioning system by simulating the actual sea conditions in the laboratory can not only avoid the risks caused by the directly experiments on a true ship, but also reduce the costs. With the purpose of realizing the high accuracy control of the dynamic positioning, besides a high accuracy mathematical model of the ship, an important condition is that the position information provided by the position detection system must be accurate, reliable, and continuous. The global positioning system (GPS) signal is restricted when the model ship dynamic positioning system is set indoors. This paper describes a novel scheme for ship target tracking based on the multi-sensor data fusion techniques. To improve the accuracy of indoor positioning and ship target tracking, the characteristics of many sensors are systematically analyzed, such as radar, difference GPS, and ultrasonic sensors. Other important factors, including the indoor temperature, position, and environment, are also taken into account to further optimize the performance. Combining the Kalman filter method, the time alignment method, the coordinate transformation method, and the optimal fusion criterion method, the core algorithm of our framework employs the track correlation as the performance index of the optimal fusion. The experimental results indicate that our method outperforms the methods based on a single ultrasonic sensor. The maximum error between the estimated location and the real location is only 1.32 cm, which meets the standard for engineering applications."
  },
  {
    "year": "2016",
    "abstract": "Cognitive radio (CR) systems are potentially capable of mitigating the spectrum shortage of contemporary wireless systems. In this paper, we provide a brief overview of CR systems and the important research milestones of their evolution, along with their standardization activities, as a result of their research. This is followed by the detailed analysis of the interweave policy-based CR network (CRN) and by a detailed comparison with the family of underlay-based CRNs. In the interweave-based CRN, sensing of the primary user's (PU) spectrum by the secondary user's (SU) has remained a challenge, because the sensing errors prevent us from fulfilling the significant throughput gains that the concept of CR promises. Since missed detection and false alarm errors in real-time spectrum sensing cannot be avoided, based on a new approach, we quantify the achievable rates of the interweave CR by explicitly incorporating the effect of sensing errors. The link between the PU transmitter and the SU transmitter is assumed to be fast fading. Explicitly, the achievable rate degradation imposed by the sensing errors is analyzed for two spectrum sensing techniques, namely, for energy detection and for magnitude squared coherence-based detection. It is demonstrated that when the channel is sparsely occupied by the PU, the reusing techniques that are capable of simultaneously providing low missed detection and false alarm probabilities cause only a minor degradation to the achievable rates. Furthermore, based on the achievable rates derived for underlay CRNs, we compare the interweave CR and the underlay CR paradigms from the perspective of their resilience against spectrum sensing errors. Interestingly, in many practical regimes, the interweave CR paradigm outperforms the underlay CR paradigm in the presence of sensing errors, especially when the SNR at the SU is below 10 dB and when the SNR at the PU is in the range of 10-40 dB. Furthermore, we also provide rules of thumb that identif..."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a fuzzy logic controller is proposed to fulfill the objective of maximum power extraction based on a two-mass model. One of the crucial problems is that the effective wind speed cannot be measured directly due to the high disturbance of the wind speed and the high cost of sensors. Three algorithms are used to estimate the effective wind speed by solving power balance equations, and the estimated wind speed is used to determine the optimal speed reference for a generator control system. The control performance of the fuzzy logic controller is verified in the whole system and compared with a conventional PI controller. Simulation results are presented to illustrate the effectiveness and robustness against parameter variations of the proposed control design."
  },
  {
    "year": "2016",
    "abstract": "The demand for flexible network management has been growing significantly over the last several decades, which comes with a series of other related demands in network virtualization, stringent security, tenant isolation in cloud, and high performance and reliability for broadband access. To meet these demands from both users and enterprises, numerous networking protocols had been designed and developed. However, these protocols were usually defined independently targeting various specific problems using different systems and sub-systems, without a holistic approach. On the other hand, cloud computing brings many challenges to traditional networking, from naming and addressing to the traditional routing. In addition, companies seek to use more standard and vendor-independent equipment to reduce the Capital Expenditure (CAPEX) and Operational Expenditure (OPEX)."
  },
  {
    "year": "2016",
    "abstract": "With today’s computer networks becoming increasingly dynamic, heterogeneous, and complex, there is great interest in deploying artificial intelligence (AI) based techniques for optimization and management of computer networks. AI techniques—that subsume multidisciplinary techniques from machine learning, optimization theory, game theory, control theory, and meta-heuristics—have long been applied to optimize computer networks in many diverse settings. Such an approach is gaining increased traction with the emergence of novel networking paradigms that promise to simplify network management (e.g., cloud computing, network functions virtualization, and software-defined networking) and provide intelligent services (e.g., future 5G mobile networks). Looking ahead, greater integration of AI into networking architectures can help develop a future vision of cognitive networks that will show network-wide intelligent behavior to solve problems of network heterogeneity, performance, and quality of service (QoS)."
  },
  {
    "year": "2016",
    "abstract": "With the maturity of technologies, such as HTML5 and JavaScript, and with the increasing popularity of cross-platform frameworks, such as Apache Cordova, mobile cloud computing as a new design paradigm of mobile application developments is becoming increasingly more accessible to developers. Following this trend, future on-device mobile application ecosystems will not only comprise a mixture of native and remote applications, but also include multiple hybrid mobile cloud applications. The resource competition in such ecosystems and its impact over the performance of mobile cloud applications has not yet been studied. In this paper, we study this competition from a game theoretical perspective and examine how it affects the behavior of mobile cloud applications. Three offload decision models of cooperative and non-cooperative nature are constructed and their efficiency compared. We present an extension to the classic load balancing game to model the offload behaviors within a non-cooperative environment. Mixed-strategy Nash equilibria are derived for the non-cooperative offload game with complete information, which further quantifies the price of anarchy in such ecosystems. We present simulation results that demonstrate the differences between each decision model's efficiency. Our modeling approach facilitates further research in the design of the offload decision engines of mobile cloud applications. Our extension to the classic load balancing game broadens its applicability to real-life applications."
  },
  {
    "year": "2016",
    "abstract": "Our world is rapidly changing, and swiftly evolving towards so-called “smart worlds”. The smart worlds starting with smart things such as the smart objects, smart city, smart manufacturing, and smart systems, will eventually encompass all aspects of the cyber, physical, social and mental world. A cyber-enabled completely new digital space featured with ubiquitous interconnections, integrations and interactions of physical, social, mental and other spaces will continuously bring out more and more changes. Cyberspace is actually the combinational outcome of various technologies including computers, communications, materials, intelligence and studies in perception, cognition, biology, sociology, etc., as well as advanced computing like the Internet/Web, pervasive networks, ubiquitous sensing and computing, the internet of things, the cloud, big data and so forth. These smart worlds are set to be the next important stage in human history. We have to be aware of the essential problems and crucial issues affecting in building truly smart worlds that benefit humanity, and simultaneously safeguard the natural environment for sustainable development and evolution. Therefore, this is the time to foresee future trends and identify what the grand challenges for smart worlds are. This Special Section in IEEE ACCESS has ten papers, and a brief summary about each paper is presented as follows."
  },
  {
    "year": "2016",
    "abstract": "To satisfy the significant demand for wireless traffic growth in the near future, ultra-dense cellular networks have been extensively investigated recently in both academia and industry. Many techniques, such as massive MIMO (multiple-in multiple-out) antenna arrays, millimeter wave communication, small cells, and heterogeneous networks, have been proposed for the design of future ultra-dense cellular systems. For example, Massive MIMO technology enables the reduction of antenna transmission power, and millimeter wave channels are suitable for short distance communications in outdoor environments. Motivated by these new technologies, cell coverage has also been correspondingly reduced so as to improve the area spectrum usage. To realize seamless coverage, a large number of small cells will be deployed."
  },
  {
    "year": "2016",
    "abstract": "Unfortunately, we had mixed up some results when we plotted the graphs in Figure 7 of the above paper. This affected only the two blue curves in each of the three graphs, for2×2MIMO in Random-LOS with LP and CP incidences, and had no influence on the discussion and conclusions in the paper. The correct graphs of Figure 7 are given here, in addition to an explanation of how the best level of the curves are related to the directivity of the antenna under test."
  },
  {
    "year": "2016",
    "abstract": "Today research activity is strongly driven by non-invasive exploration of living bodies. Wide-band reflectometry using adequate antennas system represents a possible way, but sometimes more accuracy is required which can be achieved by the use of implantable sensors that can closely investigate the interested tissues and are able to communicate with the external systems. For some applications, this communication can be unidirectional for monitoring purposes, but even in these cases, the transceiver should be carefully designed to obtain the necessary data while generating as low as possible radiofrequency power within the tissues. Blood and/or soft/hard tissue analysis can be based on this technique. The received signal is processed locally or sent to a remote medical center for further processing. The algorithms to extract the information are quite complex, and the low signal to noise ratio makes the analysis even more challenging. A bi-directional communication on the other hand represents a considerable advancement, when the sensor nodes are remotely controlled based on the feedback of the received data, for controlled drug release applications, as an example. Nevertheless, the reduced transmitter-receiver distance and presence of different high-loss tissues introduce strong reflections."
  },
  {
    "year": "2016",
    "abstract": "In this paper, a channel measurement campaign is introduced, which utilizes direction-scan-sounding to capture the spatial characteristics of 28-GHz wave propagation channels with 500-MHz sounding bandwidth in office environments. Both line-of-sight and non-line-of-sight scenarios were considered. Measurements were performed by fixing a transmit pyramidal horn antenna, and rotating another one in the receiver site at 10° steps in azimuth. The antenna outputs are viewed as array signals, and a space-alternating generalized expectation-maximization (SAGE) algorithm is applied to estimate delay and angular parameters of multipath components. Benefiting from high resolution achieved by using the SAGE and deembedding of antenna radiation pattern and system responses, more multipath clusters with less spreads in delay and azimuth are found per channel compared with existing works on 28-GHz propagation. The statistics of channel parameters extracted here constitute a preliminary stochastic multipath-cluster spatial channel model."
  },
  {
    "year": "2016",
    "abstract": "With the availability of inexpensive biometric sensors, computing power, and memory, it is becoming increasingly clear that biometrics technology will have broader usage, and therefore broader scope of future research in addressing newer challenges and pushing the boundaries. If we perceive of biometrics as a fundamental technology with broad scientific and economic impact, then designing efficient algorithms and systems will require a multidisciplinary effort in signal/image processing, pattern recognition, machine learning, sensor design, embedded systems, and information fusion."
  },
  {
    "year": "2016",
    "abstract": "Recently, the dual mode logic (DML) family was introduced as a superior energy-delay alternative to CMOS. DML gates utilize two different modes of operation, dynamic and static, to selectively achieve either high-performance or low-energy operation. Custom designs of DML circuits have been shown to be very efficient. However, implementing DML circuits using the standard design flow and Electronic Design Automation (EDA) tools is very challenging, since DML gates operate in two different modes, each with its own characteristics and operating mechanisms. This paper shows, for the first time, that DML logic can be compatible with the standard design flow and optimized by various tools, such as synthesis and physical design. A DML cell library characterization methodology is also proposed to support the design flow. The methodology and flow were verified on a wide variety of benchmark designs with different gate counts and logic depths, and show that DML design is efficient under the standard design flow restrictions."
  },
  {
    "year": "2016",
    "abstract": "Cloud-based processing is expected to play a major role in the fifth generation (5G) wireless systems, which allows for a high-quality experience for mobile cellular access. Based on the idea of combining the cloud computing technology and cellular communications, the cloud base station architecture revolutionizes the design of cellular systems. In this Special Section, five papers are included, which investigate the cloud-based wireless communications and networks from various aspects, including the joint consideration of cloud radio access networks with, respectively, heterogeneous networks and fog networks, the issues of cloud offloading, and an Internet of Things (IoT) application taking advantage of the cloud-based wireless networks."
  },
  {
    "year": "2016",
    "abstract": "The pervasive nature of big data technologies as witnessed in industry services and everyday life has given rise to an emergent, data-focused economy stemming from many aspects of industrial applications. The richness and vastness of these services are creating unprecedented research opportunities in a number of industrial fields including public health, urban studies, economics, finance, social science, and geography. We are moving towards the era of Big Data Services, which are deployed in a multi-scale complex distributed architecture. These services can be formed a high-level computational intelligence based on emerging analytical techniques such as big data analytics and web analytics. In this context, computational intelligence employs software tools from advanced analytics disciplines such as data mining, predictive analytics, and machine learning. At the same time, it becomes increasingly important to anticipate technical and practical challenges and to identify best practices learned through experience. This special session has included nine papers, and a brief summary about each paper is presented as follows."
  },
  {
    "year": "2016",
    "abstract": "The smart grid is an important hub of interdisciplinary research where researchers from different areas of science and technology combine their efforts to enhance the traditional electrical power grid. Due to these efforts, the traditional electrical grid is now evolving. The envisioned smart grid will bring social, environmental, ethical, legal and economic benefits. Smart grid systems increasingly involve machine-to-machine communication as well as human-to-human, or simple information retrieval. Thus, the dimensionality of the system is massive. The smart grid is the combination of different technologies, including control system theory, communication networks, pervasive computing, embedded sensing devices, electric vehicles, smart cities, renewable energy sources, Internet of Things, wireless sensor networks, cyber physical systems, and green communication. Due to these diverse activities and significant attention from researchers, education activities in the smart grid area are also growing."
  }
]