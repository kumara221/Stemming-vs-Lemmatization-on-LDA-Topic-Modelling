[
  {
    "year": "2017",
    "abstract": "In this paper, we introduce a 3-D compressive phased array imaging method. The derived system model is general and can also be used in other array configurations. With its compressive sampling capability, the proposed method can recover images with far fewer samples than traditionally required in Fourier transform-based methods. This measurement strategy greatly reduces the data acquisition time at the expense of higher computational costs. Imaging results show increased resolving power in both range and cross-range directions. Moreover, the use of beam steered data enables better reconstruction quality in the presence of noise than its counterpart in switched array scheme. Sensing configurations, like array length and number of angles, which affect the reconstruction performance, are also analyzed."
  },
  {
    "year": "2017",
    "abstract": "In the 5G system, we foresee the use of LOS-dominated mm-wave radio links to moving users being subject to slow fading resulting from the users' random locations and orientations. We refer to this as a random-LOS channel. MIMO processing algorithms will be used in 5G to improve performance in slow fading, similar to how they are used in Rayleigh fading. To this end, we study the probability of detection in the random-LOS channel when there are dual-polarized antennas on both sides of the link. We introduce two polarization deficiencies: the polarization non-orthogonality and the amplitude imbalance between the ports of a two-port antenna. The MIMO efficiency is evaluated as a function of these deficiencies. In the analysis, we consider the MRC algorithm for one bitstream, and the ZF and SVD algorithms for two bitstreams. We also present two analytical formulas for the MIMO efficiency that can be used to determine performance. We use the formulas on two ideally orthogonal dipoles, and show by means of coverage plots how much the 1- and 2-bitstream performances degrade due to the polarization deficiencies in off-boresight directions."
  },
  {
    "year": "2017",
    "abstract": "The communication links of multi-agent systems (MASs) generate random time delays, which significantly affect accuracy and real-time control. A Markov chain is established at the input end and output end of a communication link to express this time delay and is introduced to asynchronous data fusion at an intelligent location. The influence of random time delays and data fusion on the positioning accuracy and real-time performance is investigated. A distributed fusion simulation system is established based on MASs and employed to simulate the random delay in the fusion of multi-sensor data. Different fusion algorithms are tested by changing the upper boundary of the time delay. The test results indicate the existence of a boundary between the data fusion and the time delay. The fusion accuracies on both sides of the boundary significantly differ. This difference is helpful for selecting sensors and fusion algorithms for different sampling frequencies in multi-agent collaborative control systems, improving the positioning accuracy of the system and effectively controlling computation costs."
  },
  {
    "year": "2017",
    "abstract": "Device-free localization (DFL) plays an increasingly important role in many security and military applications. It can realize localization without the requirement of equipping targets with any devices for signal transmitting or receiving. To reduce the number of measurements in DFL, compressive sensing (CS) theory has been applied. By exploiting the sparse nature of location finding problem, the target location vector can be estimated from a few measurements. However, in changing environments, measurements may diverge from those in a fixed dictionary (sensing matrix), and the mismatches between the dictionary and runtime measurements can significantly deteriorate the localization performance of CS-based DFL methods. To address this, we propose a novel dictionary refinement-based DFL method. It adopts the saddle surface model to characterize the shadowing effects caused by targets and parameterizes the dictionary with the shadowing rate of each link as the underlying parameters. Then, the variational expectation-maximization algorithm is adopted to realize joint localization and dictionary refinement. Simulation results show that the proposed approach achieves higher accuracy and robustness compared with the state-of-the-art fixed dictionary DFL methods."
  },
  {
    "year": "2017",
    "abstract": "Our world and our lives are changing in many ways. Communication, networking, and computing technologies are among the most influential enablers that shape our lives today. Digital data and connected worlds of physical objects, people, and devices are rapidly changing the way we work, travel, socialize, and interact with our surroundings, and they have a profound impact on different domains, such as healthcare, environmental monitoring, urban systems, and control and management applications, among several other areas. Cities currently face an increasing demand for providing services that can have an impact on people's everyday lives. The CityPulse framework supports smart city service creation by means of a distributed system for semantic discovery, data analytics, and interpretation of large-scale (near-)real-time Internet of Things data and social media data streams. To goal is to break away from silo applications and enable cross-domain data integration. The CityPulse framework integrates multimodal, mixed quality, uncertain and incomplete data to create reliable, dependable information and continuously adapts data processing techniques to meet the quality of information requirements from end users. Different than existing solutions that mainly offer unified views of the data, the CityPulse framework is also equipped with powerful data analytics modules that perform intelligent data aggregation, event detection, quality assessment, contextual filtering, and decision support. This paper presents the framework, describes its components, and demonstrates how they interact to support easy development of custom-made applications for citizens. The benefits and the effectiveness of the framework are demonstrated in a use-case scenario implementation presented in this paper."
  },
  {
    "year": "2017",
    "abstract": "Physical unclonable functions (PUFs) are increasingly used for authentication and identification applications as well as the cryptographic key generation. An important feature of a PUF is the reliance on minute random variations in the fabricated hardware to derive a trusted random key. Currently, most PUF designs focus on exploiting process variations intrinsic to the CMOS technology. In recent years, progress in emerging nanoelectronic devices has demonstrated an increase in variation as a consequence of scaling down to the nanoregion. To date, emerging PUFs with nanotechnology have not been fully established, but they are expected to emerge. Initial research in this area aims to provide security primitives for emerging integrated circuits with nanotechnology. In this paper, we review emerging nanotechnology-based PUFs."
  },
  {
    "year": "2017",
    "abstract": "The plethora of research, standardization and developments in Internet of Things (IoT) has increased enormously in recent years. This is due to the vast scope of IoT. Internet of Things refers to the worldwide network of interconnected objects, which allow people or things to be connected anytime, anyplace, with anything and anyone, using any path, any network and any service. The objects have different characteristics: mobile or static, with or without energy constraint, different computation and storage capabilities, equipped with different communication technologies and sensors, etc."
  },
  {
    "year": "2017",
    "abstract": "Prognostics and systems health management (PHM) is an enabling discipline that uses sensors to assess the health of systems, diagnoses anomalous behavior, and predicts the remaining useful performance over the life of the asset. The advent of the Internet of Things (IoT) enables PHM to be applied to all types of assets across all sectors, thereby creating a paradigm shift that is opening up significant new business opportunities. This paper introduces the concepts of PHM and discusses the opportunities provided by the IoT. Developments are illustrated with examples of innovations from manufacturing, consumer products, and infrastructure. From this review, a number of challenges that result from the rapid adoption of IoT-based PHM are identified. These include appropriate analytics, security, IoT platforms, sensor energy harvesting, IoT business models, and licensing approaches."
  },
  {
    "year": "2017",
    "abstract": "Connected vehicles are seen as the next frontier for the mobile revolution. By bringing Internet connectivity to vehicles, not only infotainment of the vehicles can be enriched, but also safety and driving experience of the drivers can be enhanced. Connected vehicles can access real-time information about traffic conditions to make the journey more time efficient. They can also share local traffic information in real-time to assist other vehicles making better route planning. Consolidating various transportation data from individual vehicles and other transportation infrastructure can further enhance Intelligent Transportation System (ITS)."
  },
  {
    "year": "2017",
    "abstract": "With the rapid growth of data in the past decades, information and communication technologies have made significant impacts on global environments on both positive and negative aspects. In recent years, international efforts have made advance green technology initiatives to support sustainable systems for technical, economic and societal developments [1], [2]. Generation of huge amounts of data, called big data, across different sectors such as banking, healthcare, retail, and education, among others, is creating the needs for efficient tools to manage the data [3]. Conventional database management tools do not have the capability to manage surging volumes of unstructured data. For example, more than 80% of data is unstructured in the form of videos, tweets, GPS (Global Positioning System) coordinates and emails, which means that decisions need to be made at high velocity. The amount of data is expected to exponentially grow through data collections via pervasive sensors and/or the Internet, which also leads to new emerging challenges that have the potential to create more accurate solutions for science and technologies. We believe that big data have significant impacts on green communications and computing, which aims to provide energy-sustainable, resource-saving, and environment-friendly solutions. Recently, as a panoramic investigations on this direction, two relevant works have been recently published to provide some in-depth understandings in this area [4], [5]. The goal of this Special Section is therefore to provide insights and views into the developments in the area of big data for green communications and computing, as well as to provide directions for research in the field."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a heuristic-based approach to self-adapt and reconfigures the wake-up schedule of the nodes in wireless body area networks (WBANs). A latency-energy-optimized traffic-aware dynamic medium access control protocol is presented. The protocol is based on an adaptive algorithm that allows the sensor nodes to adapt their wake-up and sleep patterns efficiently in static and dynamic traffic variations. The heuristic approach helps to characterize the algorithmic parameters with an objective to investigate the behavior of the convergence patterns of the WBAN nodes in a non-linear system. An open-loop form is developed by keeping the wake-up interval (Iwu) fixed followed by the closed-loop adaptive system which updatesIwuon every wake-up instant. An exhaustive search is conducted for different initial wake-up interval values which show that (on average) the algorithm parameters behave monotonically in open-loop systems, whereas a decaying function in the closed-loop form. Various performance metrics, such as energy consumption, packet delay, packet delivery ratio, and convergence speed (for reaching a steady state), are evaluated. It is observed that the convergence time varies from 8 to 72 s under fixed packet transmission rate, whereas the algorithm re-converges (within 8 s) whenever the transmission rate changes."
  },
  {
    "year": "2017",
    "abstract": "Data hiding is the science and art of imperceptibly embedding some secret data, e.g., marks or messages, into a host media. The secret data are detected and extracted at a receiving end for various purposes. Data hiding has received tremendous research efforts during the past decade from both academia and industry for a diverse range of applications such as media copyright protection, content authentication, digital rights management, media system monitoring, covert communications, and so on."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) consist of multiple sensor nodes, which communicate with each other under the constrained energy resources. Retransmissions caused by collision and interference during the communication among sensor nodes increase overall network delay. Since the network delay increases as the node's waiting time increases, the network performance is reduced. Thus, the link scheduling scheme is needed to communicate without collision and interference. In the distributed WSNs environment, a sensor node has limited information about its neighboring nodes. Therefore, a comprehensive link scheduling scheme is required for distributed WSNs. Many schemes in the literature prevent collision and interference through time division multiple access (TDMA) protocol. However, considering the collision and interference in TDMA-based schedule increases the delay time and decreases the communication efficiency. This paper proposes the distributed degree-based link scheduling (DDLS) scheme, based on the TDMA. The DDLS scheme achieves the link scheduling more efficiently than the existing schemes and has the low delay and the duty cycle in the distributed environment. Communication between sensor nodes in the proposed DDLS schemes is based on collision avoidance maximal independent link set, which enables to assign collision-free timeslots to sensor nodes, and meanwhile decreases the number of timeslots needed and has low delay time and the duty cycle. Simulation results show that the proposed DDLS scheme reduces the scheduling length by average 81%, the transmission delay by 82%, and duty cycle by over 85% in comparison with distributed collision-free low-latency scheduling scheme."
  },
  {
    "year": "2017",
    "abstract": "Cloud-based healthcare service with the Internet of Healthcare Things (IoHT) is a model for healthcare delivery for urban areas and vulnerable population that utilizes the digital communications and the IoHT to provide flexible opportunities to transform all the health data into workable, personalized health insights, and help attain wellness outside the traditional hospital setting. This model of healthcare Web services acts like a living organism, taking advantage of the opportunities afforded by running in cloud infrastructure to connect patients and providers anywhere and anytime to improve the quality of care, with the IoHT, acting as a central nervous system for this model that measures patients' vital statistics, constantly logging their health data, and report any abnormalities to the relevant healthcare provider. However, it is crucial to preserve the privacy of patients while utilizing this model so as to maintain their satisfaction and trust in the offered services. With the increasing number of cases for privacy breaches of healthcare data, different countries and corporations have issued privacy laws and regulations to define the best practices for the protection of personal health information. The health insurance portability and accountability act and the privacy principles established by the Organization for Economic Cooperation and Development (OECD) are examples of such regulation frameworks. In this paper, we assert that utilizing the cloud-based healthcare services to generate accurate health insights are feasible, while preserving the privacy of the end-users' sensitive health information, which will be residing on a clear form only on his/her own personal gateway. To support this claim, the personal gateways at the end-users' side will act as intermediate nodes (called fog nodes) between the IoHT devices and the cloud-based healthcare services. In such solution, these fog nodes will host a holistic privacy middleware that executes a two-stage c..."
  },
  {
    "year": "2017",
    "abstract": "Deep neural networks (DNNs) trained on large data sets have been shown to be able to capture high-quality features describing image data. Numerous studies have proposed various ways to transfer DNN structures trained on large data sets to perform classification tasks represented by relatively small data sets. Due to the limitations of these proposals, it is not well known how to effectively adapt the pre-trained model into the new task. Typically, the transfer process uses a combination of fine-tuning and training of adaptation layers; however, both tasks are susceptible to problems with data shortage and high computational complexity. This paper proposes an improvement to the well-known AlexNet feature extraction technique. The proposed approach applies a recursive neural network structure on features extracted by a deep convolutional neural network pre-trained on a large data set. Object recognition experiments conducted on the Washington RGBD image data set have shown that the proposed method has the advantages of structural simplicity combined with the ability to provide higher recognition accuracy at a low computational cost compared with other relevant methods. The new approach requires no training at the feature extraction phase, and can be performed very efficiently as the output features are compact and highly discriminative, and can be used with a simple classifier in object recognition settings."
  },
  {
    "year": "2017",
    "abstract": "To detect multiple sclerosis (MS) diseases early, we proposed a novel method on the hardware of magnetic resonance imaging, and on the software of three successful methods: biorthogonal wavelet transform, kernel principal component analysis, and logistic regression. The materials were 676 MR slices containing plaques from 38 MS patients, and 880 MR slices from 34 healthy controls. The statistical analysis showed our method achieved a sensitivity of 97.12±.14%, a specificity of 98.25±0.16%, and an accuracy of 97.76±0.10%. Our method is superior to five state-of-the-art approaches in MS detection."
  },
  {
    "year": "2017",
    "abstract": "During the past decade, the Internet of Things (IoT) has revolutionized the ubiquitous computing with multitude of applications built around various types of sensors. A vast amount of activity is seen in IoT based product-lines and this activity is expected to grow in years to come with projections as high as billions of devices with on average 6-7 devices per person by year 2020. With most of the issues at device and protocol levels solved during the past decade, there is now a growing trend in integration of sensors and sensor based systems with cyber physical systems and device-to-device (D2D) communications. 5thgeneration wireless systems (5G) are on the horizon and IoT is taking the center stage as devices are expected to form a major portion of this 5G network paradigm. IoT technologies such as machine to machine communication complemented with intelligent data analytics are expected to drastically change landscape of various industries. The emergence of cloud computing and its extension to fog paradigm with proliferation of intelligent `smart' devices is expected to lead further innovation in IoT. These developments excite us and form a motivation to survey existing work, design new techniques, and identify new applications of IoT. Researchers, scientists, and engineers face emerging challenges in designing IoT based systems that can efficiently be integrated with the 5G wireless communications."
  },
  {
    "year": "2017",
    "abstract": "Socially-aware mobile networks have become ubiquitous in our daily life, which create the phenomenon of the socially aware mobile big data. Due to the movement of mobile entities, traditional transmission mechanisms are not conducive to the spreading of information. Thus, how to improve the information diffusion performances in socially aware mobile networks has become a hot research topic. However, most of the existing works focus their attention on the information-spreading dynamics rather than on the network structure and nodes' social attributes. In this paper, we proposed the concept of the value strength, social strength as well as a time-varying graph (TVG)-based mobility model from the perspective of the network science, based on which a forwarding nodes' selection scheme was presented. It is beneficial in terms of improving the propagation efficiency and information coverage ratio of mobile networks. Furthermore, sufficient experiments were conducted to verify the diffusion performances both over a range of complex network topologies, such as the Watts-Strogatz small-world network, the Barabási-Albert scale-free network, the real-world Flickr network, and over a TVG-based mobile network. Indeed, the definition of the value/social strength plays a critical role in selecting forwarding links and nodes both for static-topology networks as well as for socially aware mobile networks."
  },
  {
    "year": "2017",
    "abstract": "Smart devices, such as tablets and phones, are revolutionizing access to healthcare services. They are bringing forth the mHealth and eHealth revolution, and are aiming to empower the consumers to make a difference to their health and wellbeing by connecting data to personalized analytics to timely insights. However, this consumer-centric journey for smart and connected health is presenting challenges and opportunities for big data analytics research, whether in integrating and developing machine learning algorithms for heterogeneous and longitudinal data or developing novel systems or applications or developing new user experience frameworks, and doing all this while ensuring privacy and security of user data."
  },
  {
    "year": "2017",
    "abstract": "Proxy Mobile IPv6 (PMIPv6) allows a mobile node to communicate directly to its peers while changing the currently used IP address. This mode of operation is called route optimization (RO). In the RO process, the peer node learns a binding between the home address and its current temporary care-of-address. Many schemes have been proposed to support RO in PMIPv6. However, these schemes do not consider the out-of-sequence problem, which may happen between the existing path and the newly established RO path. In this paper, we propose a scheme to solve the out-of-sequence problem with low cost. In our scheme, we use the additional packet sequence number and the time information when the problem occurs. We then run experiments on a reliable packet transmission (RPT) laboratory testbed to evaluate the performance of the proposed scheme, and compare it with the well-known RO-supported PMIPv6 and the out-of-sequence time period scheme. The experimental results show that for most of the cases, our proposed scheme guarantees RPT by preventing the out-of-sequence problem."
  },
  {
    "year": "2017",
    "abstract": "To quantify the perceptual quality of the color image, a novel reduced-reference computational model is proposed in this paper. The proposed metric, named regularity of color distribution measure, is designed to measure the difference of the color distribution regularity between the reference image and the distorted one. In particular, three kinds of channels (bright channel, median channel, and dark channel) are first extracted from the color image. Then, a fractal analysis is employed to characterize each channel by fractal dimension. Finally, we make use of fractal dimensions extracted from channels to predict the image quality. The proposed metric is evaluated on three largest color image databases (TID2013, CSIQ, and LIVE databases) and experimental results indicate that our metric achieves excellent performance."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we proposed a decentralized cooperative lane-changing decision-making framework for connected autonomous vehicles, which is composed of three modules, i.e., state prediction, candidate decision generation, and coordination. In other words, each connected autonomous vehicle makes cooperative lane-changing decision independently. In the state prediction module, we employed existing cooperative car-following models to predict the vehicles’ future state. In the candidate decision generation module, we proposed incentive based model to generate a candidate decision. In the candidate decision coordination module, we proposed an algorithm to avoid candidate lane-changing decision that may lead to a vehicle collision or traffic deterioration to be final decision. Moreover, the effects of decentralized cooperative lane-changing decision-making framework on traffic stability, efficiency, homogeneity, and safety are investigated in a numerical simulation experiment. Some stability, efficiency, homogeneity, and safety indicators are evaluated and show the high potential of our proposed framework in traffic dynamics."
  },
  {
    "year": "2017",
    "abstract": "As a significant application of energy, smart grid is a complicated interconnected power grid that involves sensors, deployment strategies, smart meters, and real-time data processing. It continuously generates data with large volume, high velocity, and diverse variety. In this paper, we first give a brief introduction on big data, smart grid, and big data application in the smart grid scenario. Then, recent studies and developments are summarized in the context of integrated architecture and key enabling technologies. Meanwhile, security issues are specifically addressed. Finally, we introduce several typical big data applications and point out future challenges in the energy domain."
  },
  {
    "year": "2017",
    "abstract": "In big-data-driven traffic flow prediction systems, the robustness of prediction performance depends on accuracy and timeliness. This paper presents a new MapReduce-based nearest neighbor (NN) approach for traffic flow prediction using correlation analysis (TFPC) on a Hadoop platform. In particular, we develop a real-time prediction system including two key modules, i.e., offline distributed training (ODT) and online parallel prediction (OPP). Moreover, we build a parallelk-nearest neighbor optimization classifier, which incorporates correlation information among traffic flows into the classification process. Finally, we propose a novel prediction calculation method, combining the current data observed in OPP and the classification results obtained from large-scale historical data in ODT, to generate traffic flow prediction in real time. The empirical study on real-world traffic flow big data using the leave-one-out cross validation method shows that TFPC significantly outperforms four state-of-the-art prediction approaches, i.e., autoregressive integrated moving average, Naïve Bayes, multilayer perceptron neural networks, and NN regression, in terms of accuracy, which can be improved 90.07% in the best case, with an average mean absolute percent error of 5.53%. In addition, it displays excellent speedup, scaleup, and sizeup."
  },
  {
    "year": "2017",
    "abstract": "In existing recommendation systems, there exist the issues of “cold start” and “excessively mature recommendation,” which cause the recommendation systems to have weak effectiveness; thus, a trust-based recommendation model with a small recommendation probability for unknown items (RM-UI) is proposed for social networks. In the RM-UI scheme, the recommendation values of items are primarily derived from the probabilities calculated by a similar mature recommendation system during the initiation stage of the recommendation system. Thus, the “cold start” phenomenon can be overcome. When the recommendation system enters the period of maturation, the recommendation probabilities mainly adopt the recommendation values computed by the self-system. However, in the existing recommendation systems, there remains the problem of “excessively mature recommendation,” which causes the system to lose the opportunity to recommend more optimized items. Thus, in the RM-UI scheme, except for recommending items with higher recommendation probabilities, we recommend items with lower recommendation probabilities with a small probability to enable those items that can bring greater welfare to recommendation systems to be recommended. This breaks the weakness of a confined recommendation that exists in previous recommendation systems, and it enlarges the welfare of the system. After theoretical analysis, it has been proven that the RM-UI scheme can achieve greater welfare than the previous recommendation scheme and gain more vitality. Experiments based on real social network data are conducted to show the effectiveness and efficiency of the RM-UI scheme: in the initiation stage, the performance criteria of precision ratio, recall ratio, and F1-measure are improved by approximately 21.08%, 21.57%, and 21.32%, respectively, over the previous schemes, and in the mature stage, although the three indications are similar to those of the previous schemes, the improvement in the overall revenue of ..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a multi-human detection algorithm based on impulse radio ultra-wideband radar system. With our proposed algorithm, the multi-human detection can be performed by repeatedly performing clustering and detecting processes. More specifically, the system detects an effective peak of the first single cluster which is composed of peaks adjacent to each other and then repeat this process until effective peaks of clusters caused by multiple people are successfully detected sequentially. As our performance metrics, we take into account the performance analysis in terms of the error probability based on the results of the statistical analysis. More specifically, we first cross-verify that the empirical result theoretically follows the Log-normal distribution by comparing the theoretical and empirical results obtained through laboratory experiments. Then, we statistically analyze the received signals under the Log-normal distribution assumption. After that, this statistical result is adopted to the performance analysis of the error probability in terms of the total error probability. Note that the performance of our proposed algorithm is affected by the threshold value. Based on it, the optimal threshold is analyzed and we provide the sample guidelines for optimally adjusting the threshold value under given various environment factors. Finally, some selected experimental results are presented to show the validity of our proposed algorithm by comparing the performance between the proposed algorithm and the conventional algorithm."
  },
  {
    "year": "2017",
    "abstract": "Constructing hypercubic lattices from convolutional codes based on Constructions A and D is investigated in this paper and their error performance in a point-to-point communication system is studied. Moreover, analogous to Construction A/D, single/multilayer code lattices are proposed. As Construction D requires certain minimum Euclidean distance criteria, we propose methods to guarantee the distance requirements of Construction D, which results in a superior lattice construction compared with Construction A. Due to the key role of soft input soft out decoding algorithms in improving the performance of a code, lattice decoding based on the Bahl, Cocke, Jelinek and Raviv (BCJR) algorithm for lattices constructed from convolutional codes is also proposed in this paper. Moreover, as the BCJR algorithm requires knowledge of the statistical characteristics of modulo lattice additive noise (MLAN), the probability density function of MLAN is derived in closed form."
  },
  {
    "year": "2017",
    "abstract": "We consider the joint WiFi offloading, admission control, and network management for the integrated WiFi and OFDMA-based cellular network. Specifically, we propose a quality-of-service (QoS) and mobility-aware admission control scheme that efficiently offloads macrocell traffic to WiFi and integrates a novel bandwidth borrow-return strategy while guaranteeing QoS requirements for users. These QoS constraints are explicitly modeled considering the throughput performance of carrier sense multiple access with collision avoidance scheme in the IEEE 802.11 WLAN and the fractional frequency reuse in the downlink cellular network. Then, we develop an analytical model to derive the blocking probabilities for calls in different service areas of a cell. Based on this analysis, we study the joint base station switching, power control, and traffic offloading problem for energy minimization under QoS constraints. We consider the time-varying call traffic and develop an algorithm to find the optimal solution of the problem. Numerical results are presented to demonstrate the performance of the proposed cross-layer resource management framework in the integrated network."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel probabilistic method for the task of text-independent speaker identification (SI). In order to capture the dynamic information during SI, we design super-mel-frequency cepstral coefficients (MFCCs) features by cascading three neighboring MFCCs frames together. These super-MFCC vectors are utilized for probabilistic model training such that the speaker's characteristics can be sufficiently captured. The probability density function (PDF) of the aforementioned super-MFCCs features is estimated by the recently proposed histogram transform (HT) method. To recede the commonly occurred discontinuity problem in multivariate histograms computing, more training data are generated by the HT method. Using these generated data, a smooth PDF of the super-MFCCs vectors is obtained. Compared with the typical PDF estimation methods, such as Gaussian mixture model, promising improvements have been obtained by employing the HT-based model in SI."
  },
  {
    "year": "2017",
    "abstract": "Simultaneous acquisition of electrooculogram, jaw electromyogram, electroencephalogram, and head movement via consumer-grade wearable devices has become possible. Such devices offer new opportunities to deploy practical biosignal-based interfaces for assistive robots; however, they also pose challenges related to the available signals and their characteristics. In this proof-of-concept study, we demonstrate the possibility of successful control of a 5 + 1 degrees-of-freedom robot arm based on a consumer wireless headband in the form of four control modes predicated on distinct signal combinations. We propose a control approach hybrid at two levels, which seeks a compromise between robot controllability and maintaining the user goal rather than being process-focused. First, robot arm steering combines discrete and proportional aspects. Second, after the robot has been steered toward the approximate target direction, a sparse approach is followed and the user only needs to issue a single command, after which steering adjustment and grasping are performed automatically under stereoscopic vision guidance. We present in detail the associated algorithms, whose implementation is publicly available. Within this framework, we also demonstrate the control of arm posture and grasping force based, respectively, on object visual features and user input. We regard the interface proposed herein as a viable blueprint for future work on controlling wheelchair-mounted and meal-assisting robot arms."
  },
  {
    "year": "2017",
    "abstract": "The issue of virtual network (VN) embedding constitutes an important aspect of network virtualization, which is considered to be one of the most crucial techniques to overcome the Internet ossification problem. The main purpose of VN embedding is to efficiently utilize the limited physical network resources to offer the supporting of virtual nodes and virtual links from the VNs. Due to the fact that the VN embedding problem is proved to be NP-hard, previous works have put forward some of heuristic algorithms to solve this VN embedding problem. However, most of the existing research works only consider the local resources of nodes, ignoring the topological attributes of its neighborhood nodes, and lead to lower resource utilization of the substrate network. To address this issue, we proposed an approach of VN embedding algorithm called VNE-DCC, which based on the node degree and the clustering coefficient information, we adopted the technique of node importance metric to rank the substrate nodes aim to select the node with the most embedding potential for every virtual node in each VN requests, and exploited the breadth-first-search algorithm to embed the virtual nodes aiming at reducing the resource utilization of substrate links so as to increase the acceptance ratio of VN requests and increase the revenues of operational providers. Extensive simulations have shown that the efficiency of our algorithm is better than the other state-of-the-art algorithms in terms of Revenue/Cost ratio and acceptance ratio."
  },
  {
    "year": "2017",
    "abstract": "Agile-SD is one of the latest versions of loss-based congestion control algorithm (CCA), which has been proposed to improve the total performance of transmission control protocol (TCP) over highspeed and short-distance networks. It has introduced a new mechanism, called agility factor mechanism, which shortens the epoch time to reduce the sensitivity to packet losses and in turn to increase the average throughput. Agile-SD has only been tested via simulation; however, it has not been mathematically proven or evaluated. The contribution of this paper is twofold. First, a new mathematical model for the throughput of NewReno and Agile-SD is proposed. This model is designed using the well-known Markov chains to validate the correctness of Agile-SD and to show the impact of buffer size, multiplicative decrease factor, and maximum limit of agility factor (λmax) on the total performance. Second, an automated algorithm configuration and parameter tuning (AACPT) technique is employed to optimize and automate the configuration of λmax. Furthermore, the numerical results for both NewReno and Agile-SD are compared with the simulation results, in which the validity of the proposed model is confirmed. Moreover, the output of the AACPT is exploited to formulate a new equation, which calculates the optimal λmax from a given β in order to conserve the standard interface of the TCP. This equation increases the scalability of Agile-SD and improves its total performance."
  },
  {
    "year": "2017",
    "abstract": "Low-density parity-check (LDPC) codes with very long block lengths are well known for their powerful error correction, but it is not always desirable to employ long codes in communication systems, where latency is a serious issue, such as voice and video communication between multiple users. Finite length analyses of LDPC codes have already been presented in the literature for the additive white Gaussian noise channel, but in this paper, we consider the finite length analysis of LDPC codes for channels that exhibit impulsive noise. First, an exact uncoded bit error probability (BEP) of an impulsive noise channel, modeled as a symmetric α-stable (SαS) distribution, is derived. Then, to obtain the LDPC-coded performance, density evolution is applied to evaluate the asymptotic performance of LDPC codes on SαS channels and determine the threshold signal-to-noise ratio. Finally, we derive closed-form expressions for the BEP and block error probability of short LDPC codes on these channels, which are shown to match closely with simulated results on channels with different levels of impulsiveness, even for block lengths as low as 1000 b."
  },
  {
    "year": "2017",
    "abstract": "We address a robust beamforming design and power allocation problem for a one-way multi-antenna relay network, where the multi-antenna source implements communication with the multi-antenna destination via a decode-and-forward (DF) relay in the presence of the multiple single-antenna eavesdroppers. The eavesdroppers can only overhear the information flowed from the relay to the destination in the second hop. We aim to maximize the worst-case secrecy rate in the condition that the global channel state information (CSI) is imperfect. To this end, we propose the joint beamforming and power allocation design for the worst-case secrecy rate maximization. However, our proposed design constitutes a non-convex problem, which involves an infinite number of constraints because of the imperfect CSI. To make the problem more tractable, we approximate the problem into several tractablesemidefinite programs by semidefinite relaxation, successive convex approximation, and S-procedure techniques, and we propose an iterative algorithm to solve the problem. Furthermore, we show that the proposed algorithm is also applicable for the case the Gaussian wiretap model, where only the eavesdroppers' CSI is imperfect. Simulation results validate the effectiveness of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Partial discharge (PD) detection has been proved as an effective tool for insulation condition monitoring of power equipment. The energy of PD pulses is valuable for studying the characteristics of PD activities. This paper proposes a method for estimating the energy of PD pulses in the presence of white noise and narrowband noise. First, a maximum likelihood (ML) estimator of the pulse energy is derived from the probability distribution of the energy spectral coefficients. To implement the ML method, the sampled data are divided into signal frames and noise frames. The noise frames are then utilized for extracting noise parameters using the 3F-C method. Eventually, these noise parameters are applied to the signal frames to find the ML estimate of the pulse energy. To verify the effectiveness of the proposed method, both simulated data and measured data have been processed using the proposed method and the conventional wavelet packet (WP) denoising method. Compared with the WP denoising method, the proposed method has a higher accuracy and is less susceptible to the lengths of the sampling time windows. The advantage of the method is more significant in unfavorable conditions where the signal-to-noise ratio is low and the accurate lengths of the PD pulses are difficult to determine."
  },
  {
    "year": "2017",
    "abstract": "Millimeter-wave (mmWave) communication operated in frequency bands between 30 and 300 GHz has attracted extensive attention due to the potential ability of offering orders of magnitude greater bandwidths combined with further gains via beamforming and spatial multiplexing from multi-element antenna arrays. mmwave system may exploit the hybrid analog and digital precoding to achieve simultaneously the diversity, array and multiplexing gain with a lower cost of implementation. Motivated by this, in this paper, we investigate the design of hybrid precoder and combiner with sub-connected architecture, where each radio frequency chain is connected to only a subset of base station antennas from the perspective of energy efficient transmission. The problem of interest is a non-convex and NP-hard problem that is difficult to solve directly. In order to address it, we resort to design a two-layer optimization method to solve the problem of interest by exploiting jointly the interference alignment and fractional programming. First, the analog precoder and combiner are optimized via the alternating-direction optimization method where the phase shifter can be easily adjusted with an analytical structure. Then, we optimize the digital precoder and combiner based on an effective multiple-input multiple-output channel coefficient. The convergence of the proposed algorithms is proved using the monotonic boundary theorem and fractional programming theory. Extensive simulation results are given to validate the effectiveness of the presented method and to evaluate the energy efficiency performance under various system configurations."
  },
  {
    "year": "2017",
    "abstract": "With the fuzzy set theory, the uncertainty of nonlinear systems can be modeled using fuzzy differential equations. The solutions of these equations are the model output, but they are very difficult to obtain. In this paper, we first transform fuzzy differential equations into four ordinary differential equations. Then, we construct neural models with the structure of these ordinary differential equations. Theory analysis and simulation results show that these new models are effective for modeling uncertain nonlinear systems."
  },
  {
    "year": "2017",
    "abstract": "Spurred by Web technologies and service computing paradigm, more and more Web services have been delivered via standardized interfaces on the Internet. Mashup is exactly an enabling technology for end-users to combine these services into applications. However, there are some issues of end-user service development with mashup techniques. It not only requires users that develop application logics equipped with more or less programming skills, but also lacks a lightweight mashup model and systematic development approach in the existing mashup tools. To address these issues, we propose a data-driven service creation approach to facilitate application development and deployment. In the approach, we propose the service data model (SDM) for adaptation of heterogeneous Web services, the service relation model (SRM) for representation and refinement of data interaction between services, and the service process graph (SPG) for describing business logics of mashup applications. We develop an IFrame implementation for SDM that can facilitate service providers to wrap heterogeneous Web services in a unified way and display a visual element for the service. Meanwhile, we implement a pipeline as an intuitive form of SRM that can be used by end-users to develop business logic more effectively. To adapt the dynamic application scenarios, we also construct an event-driven execution mechanism for SPG. A lightweight service creation environment is then implemented to support end-users to develop applications in a simulative way, and a corresponding development methodology is introduced for this tool. Finally, the end-user evaluation and performance evaluation are conducted to evaluate our platform."
  },
  {
    "year": "2017",
    "abstract": "Social network has extended its popularity from the Internet to mobile domain. Pervasive social networking (PSN) supports instant social activities based on self-organized mobile ad hoc networks. PSN is useful in reality when fixed networks are unavailable or inconvenient to access or when people are in vicinity. For supporting crucial PSN activities and enhancing user privacy, securing pervasive social communications becomes important. However, a solution based on a centralized server could be inapplicable in some specific situations (e.g., disasters and military activities) and suffers from DoS/DDoS attacks and internal attacks. How to automatically control data access in a trustworthy and efficient way in PSN is a challenge. In this paper, we propose two schemes to secure communication data in PSN purely based on local trust evaluated by PSN nodes in a distributed manner. Each node can control its data based on its trust in other nodes by applying attribute-based encryption. The advantages, security, and performance of the proposed scheme are evaluated and justified through serious analysis and implementation. The results show the efficiency and effectiveness of the schemes. In addition, we developed a mobile app based on Android platform to demonstrate the applicability and social acceptance of our schemes."
  },
  {
    "year": "2017",
    "abstract": "A novel empirical data analysis methodology based on the random matrix theory (RMT) and time series analysis is proposed for the power systems. Among the ongoing research studies of big data in the power system applications, there is a strong necessity for new mathematical tools that describe and analyze big data. This paper used RMT to model the empirical data which also treated as a time series. The proposed method extends traditional RMT for applications in a non-Gaussian distribution environment. Three case studies, i.e., power equipment condition monitoring, voltage stability analysis and low-frequency oscillation detection, illustrate the potential application value of our proposed method for multi-source heterogeneous data analysis, sensitive spot awareness and fast signal detection under an unknown noise pattern. The results showed that the empirical data from a power system modeled following RMT and in a time series have high sensitivity to dynamically characterized system states as well as observability and efficiency in system analysis compared with conventional equation-based methods."
  },
  {
    "year": "2017",
    "abstract": "Long term evolution-wireless local area network (LTE-WLAN) aggregation (LWA) has recently emerged as a promising third generation partnership project (3GPP) Release 13 technology to efficiently aggregate LTE and WLAN at the packet data convergence protocol layer, allowing uplink traffic to be carried on LTE and downlink on both LTE and WLAN. This removes all the contention asymmetry problems of WLAN and allows an optimum usage of both licensed and unlicensed band for downlink. In this paper, we present a new feature of LWA, its flow control scheme, which controls how to aggregate downlink traffic in licensed and unlicensed bands. This aggregation technique exploits user equipment-based flow control feedback in the form of LWA status reports, and can be expanded to work with any number of frequency bands and radio technologies. The same concepts apply to 5G networks, although the performance evaluation provided here is in the context of LTE-Advanced Pro. Simulation results in a typical enterprise scenario show that LWA can enhance user performance up to 8 times over LTE-only, and 3.7 times over WLAN only networks, respectively. The impact of the file size and LWA status report frequency on network performance is also investigated."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a new linear ultrasonic motor using hybrid mode of the first symmetric and anti-symmetric longitudinal modes. The stator is constructed by two Langevin transducers in combination with two isosceles triangular beams. The triangular beams can transform the displacement in axial direction into the displacement in perpendicular direction and generate the oval trajectory of the driving foot, which is the merit of the simple structure. For better mode degeneration result, the influence of the triangular beam dimensions on the vibration frequency difference of the stator was analyzed by Finite Element Method (FEM) analysis. The overall dimensions of the prototype stator are 70 mm (length)×15mm (width)×10 mm (thickness). Driven by ac signals with the driving frequency of 55 kHz and voltage 400Vp−p, the motor can provide the no-load speed 63.87 mm/s and maximum thrust force 3.14 N, respectively. The frequency matching process of ultrasonic motor is simplified by adjusting the structure dimensions of the triangular beams."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things allow massive number of uniquely addressable “things” to communicate with each other and transfer data over existing internet or compatible network protocols. This paper proposes a new concept which tackles the issues for supporting control and monitoring activities at deployment sites and industrial automations, where intelligent things can monitor peripheral events, induce sensor data acquired from a variety of sources, use ad hoc, local, and distributed “machine intelligence” to determine appropriate course of actions, and then act to control or disseminate static or dynamic position aware robotic things in the physical world through a seamless manner by providing a means for utilizing them as Internet of robotic things (IoRT). Although progressive advancements can be seen in multi-robotic systems, robots are constantly getting enriched by easier developmental functionalities, such vertical robotic service centric silos are not enough for continuously and seamlessly supporting for which they are meant. In this paper, a novel concept-IoRT is presented that highlights architectural principles, vital characteristics, as well as research challenges. The aim of this paper is to provide a better understanding of the architectural assimilation of IoRT and identify important research directions on this term."
  },
  {
    "year": "2017",
    "abstract": "Service level agreement (SLA) negotiations involving cloud-based information technology (IT) service providers and customers are now commonplace. Although historical research on negotiation has often relied on economic foundations, the important nature of IT service levels to organizations' operational effectiveness suggests that negotiation complexities in the context of cloud-based outsourcing (or cloudsourcing) cannot be well understood by relying on economic perspectives alone. To that end, this paper reports on experiments designed to determine the relevance of competing sociotheoretic frameworks as they pertain to IT cloudsourcing negotiations. Contributions include a rigorous examination of hypotheses derived from social exchange theory, equity theory, learning theory, and the win-win theories of negotiation. Additional contributions include the development of methodological constructs (using the Euclidean geometry) that reflect the complex nature of IT cloudsourcing SLAs, i.e., that they are composed of numerous service category contract clauses where negotiation tradeoffs within a service category as well as across service categories are possible. We find strong support for the relevance of the social exchange theory to IT cloudsourcing negotiations, as well as moderate support for the win-win theories of negotiation. Our conclusions provide clear directions for extending our work into the realm of negotiation support systems, and we rely on our findings to conjecture that IT cloudsourcing negotiation is a unique context for sociotheoretic negotiation research due to the inherent importance of information technologies to organizations' operational effectiveness."
  },
  {
    "year": "2017",
    "abstract": "In healthcare management, a large volume of multi-structured patient data is generated from the clinical reports, doctor's notes, and wearable body sensors. The analysis of healthcare parameters and the prediction of the subsequent future health conditions are still in the informative stage. A cloud-enabled big data analytic platform is the best way to analyze the structured and unstructured data generated from healthcare management systems. In this paper, a probabilistic data collection mechanism is designed and the correlation analysis of those collected data is performed. Finally, a stochastic prediction model is designed to foresee the future health condition of the most correlated patients based on their current health status. Performance evaluation of the proposed protocols is realized through extensive simulations in the cloud environment, which gives about 98% accuracy of prediction, and maintains 90% of CPU and bandwidth utilization to reduce the analysis time."
  },
  {
    "year": "2017",
    "abstract": "A collective action that considerably affects government management and public security, e.g., a mass demonstration, usually experiences a long development period, originating from small and uncertain variations called weak signals on social media. Researchers generally identify collective action by small changes in communication frequency, emerging key words, and sentiment. However, most studies only consider the present environment, which may not evolve into a collective action, or conduct a short-term prediction in which significant damage is already done when the collective action is identified. This paper proposes a predictive framework to identify potential collective actions, considering the future evolution as well as the present situation, and providing a reference for early decision making. In the framework, a future sign to describe events is improved and the enhanced gray system theory is used to predict the evolution of a future sign. Mentions of events surrounding the Arab Spring-using over 300000 different open-content Web sources crawled from social media in seven different languages-are analyzed, which suggests that the predictive framework can more precisely identify the weak signals of collective actions."
  },
  {
    "year": "2017",
    "abstract": "Electronic health records (EHRs) are providing increased access to healthcare data that can be made available for advanced data analysis. This can be used by the healthcare professionals to make a more informed decision providing improved quality of care. However, due to the inherent heterogeneous and imbalanced characteristics of medical data from EHRs, data analysis task faces a big challenge. In this paper, we address the challenges of imbalanced medical data about a brain tumor diagnosis problem. Morphometric analysis of histopathological images is rapidly emerging as a valuable diagnostic tool for neuropathology. Oligodendroglioma is one type of brain tumor that has a good response to treatment provided the tumor subtype is recognized accurately. The genetic variant, 1p-/19q-, has recently been found to have high chemosensitivity, and has morphological attributes that may lend it to automated image analysis and histological processing and diagnosis. This paper aims to achieve a fast, affordable, and objective diagnosis of this genetic variant of oligodendroglioma with a novel data mining approach combining a feature selection and ensemble-based classification. In this paper, 63 instances of brain tumor with oligodendroglioma are obtained due to prevalence and incidence of the tumor variant. In order to minimize the effect of an imbalanced healthcare data set, a global optimization-based hybrid wrapper-filter feature selection with ensemble classification is applied. The experiment results show that the proposed approach outperforms the standard techniques used in brain tumor classification problem to overcome the imbalanced characteristics of medical data."
  },
  {
    "year": "2017",
    "abstract": "Ultra-wideband (UWB) antennas with wide rectangular notched-band are proposed in this paper. The rectangular notched-band design is realized by placing dual mushroom-type electromagnetic-bandgap (EBG) structures on the CPW feeding line. The patches of the EBGs are laid on the back size of the substrate and dead against the CPW feeding line. Shorting pins are utilized to connect the patch and the feeding line. Then, the CPW feeding line operates as ground plane for the EBGs. By tuning the two resonant frequencies of the EBG structures and making them merge with each other, a rectangular notchedband is achieved. Research also found that design methodology has the ability to tune the width and the frequency of the rectangular notched-band by adjusting the EBG parameters. Then, three cases of rectangular notchedband designs to reject the wireless local-area network (WLAN, 5.150-5.825 GHz) interference band and the X -band downlink satellite communication band (660 MHz, 7.10-7.76 GHz) were designed by using different EBG parameters. The design methodology can also be utilized to design rectangular notchedband for other interference bands efficiently."
  },
  {
    "year": "2017",
    "abstract": "Fuzzy job-shop scheduling problems (FJSPs) with various imprecise factors are a category of combination optimization problems known as non-deterministic polynomial-hard problems. In this paper, a hybrid algorithm HICATS combining discrete imperialist competition algorithm (ICA) and Tabu search (TS) is proposed to solve FJSPs with fuzzy processing time and fuzzy due date. The objective function is maximizing the minimum agreement index, which is on the basis of the agreement index of fuzzy due date and fuzzy completion time. In the proposed algorithm, ICA conducts the global search and TS performs the local search. The imperialist is used to guide the colonies in the same empire. So, local search approach based on TS is applied to the imperialist to perform fine-grained exploitation. The6×6and10×10FJSPs with fuzzy processing time and fuzzy due date are tested to evaluate the performance of the proposed algorithm HICATS in this paper. The highly effective performance of HICATS is shown against the best performing algorithms from the literature. Experimental results demonstrate the advantages of our proposed algorithm HICATS on the feasibility and robustness compared with other algorithms."
  },
  {
    "year": "2017",
    "abstract": "The intensity value recorded by terrestrial laser scanning (TLS) systems is significantly influenced by incidence angles. Most existing models focus on the diffuse reflection of rough surfaces and ignore the specular reflection, despite that both reflections simultaneously exist in all natural surfaces. At large incidence angles, specular reflection can be neglected. However, laser detectors can receive a portion of specular reflection at small incidence angles. Specular reflection can lead to additional increase in the original intensity data and even highlight phenomenon on scanned targets, especially those with a relatively smooth or highly reflective surface. In this paper, a new empirical method is proposed to correct the intensities of highlight regions caused by the specular reflection. The intensity from the specular reflection is obtained by subtracting the intensity caused by diffuse reflection and instrumental effects from the original intensity. The proposed method is tested and validated on different targets scanned by Faro Focus3D120. Results imply that the proposed method can effectively eliminate the highlight phenomenon in TLS for 3-D point cloud representation by intensity and intensity image interpretation."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency division multiplexing (OFDM) is an efficient multi-carrier modulation technique for wireless communication. However, one of the main drawbacks encountered in implementing it is its resultant high peak-to-average power ratio (PAPR). Many techniques have been proposed in the literature to substantially decrease the peaks in the OFDM signal. The problem with these, however, is that their effects on other parameters are not always positive. These effects include a decrease in the bit error rate (BER), an increase in complexity, or a reduction in the bit rate. The objective of this paper is to describe the PAPR problem in a bid to reduce the peaks in the OFDM signal. The paper proposes a classification, performance evaluation and optimization of PAPR reduction techniques for commercial, public safety, and tactical applications. In the taxonomy proposed herein, we also include a new category, namely, hybrid techniques. Furthermore, we compare the principal characteristics through a complementary cumulative distribution function and BER evaluation, and conclude on the importance of hybrid techniques, when the goal is to both improve the BER and reduce the PAPR."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) technology has attracted much attention in recent years for its potential to alleviate the strain on healthcare systems caused by an aging population and a rise in chronic illness. Standardization is a key issue limiting progress in this area, and thus this paper proposes a standard model for application in future IoT healthcare systems. This survey paper then presents the state-of-the-art research relating to each area of the model, evaluating their strengths, weaknesses, and overall suitability for a wearable IoT healthcare system. Challenges that healthcare IoT faces including security, privacy, wearability, and low-power operation are presented, and recommendations are made for future research directions."
  },
  {
    "year": "2017",
    "abstract": "To avoid the drawbacks of a pricing mechanism in heterogeneous cloud environments that considers only single resources, we propose a multi-resource combinatorial pricing mechanism in this paper. This approach jointly considers the principal resources (i.e., CPU, memory, storage, and bandwidth) with the goal of minimizing the total cost. Then, a cost-optimized resource provisioning policy (CORPP) based on game theory is applied to this mechanism that considers the Nash equilibrium between cloud users as well as the Stackelberg equilibrium between users and the cloud provider. The experimental results show that the proposed combinatorial pricing mechanism is more suitable in a heterogeneous cloud environment when running various types of cloudlets. Moreover, CORPP is effective in reducing users’ total costs when using both random cloudlets and PlanetLab cloudlets."
  },
  {
    "year": "2017",
    "abstract": "In underwater wireless sensor networks, time synchronization and localization are basic requirements in many applications. A joint synchronization and localization framework is expected to provide better accuracy. In this paper, we propose a unified framework to execute synchronization and localization simultaneously taking stratification effect into account. In this method, the stratification effect of underwater medium is modeled using a ray tracing approach. The maximum likelihood (ML) estimator is derived, which is shown to be highly nonlinear and nonconvex. Therefore, we employ the Gauss-Newton algorithm to solve the original nonconvex ML problem in an iterative manner. Furthermore, the Cramér-Rao lower bound for this problem is derived as a benchmark. Simulation results indicate that the proposed method outperforms the existing methods in both accuracy and energy efficiency."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new compact canonical-based algorithm to solve the problem of single-output completely specified input negation and/or input permutation and/or output negation Boolean matching. We propose a new signature vector Boolean difference and cofactor signature vector. Our algorithm utilizes the Boolean difference, cofactor signature, and symmetry properties to search for canonical transformations. The use of symmetry and Boolean difference notably reduces the search space and speeds up the Boolean matching process compared with the algorithm proposed by Adbollahi and Pedram. We tested our algorithm on a large number of circuits. The experimental results showed that the average runtime of our algorithm 37% higher and its average search space 67% smaller compared with Adbollahi and Pedram, when tested on general circuits."
  },
  {
    "year": "2017",
    "abstract": "Harvesting energy from ambient environment is a promising technology to free electronic devices from electric wire and lifetime-limited battery, which have found many significant applications in sensor networks and body-area networks. This paper investigates the fundamental limit of information transmission in a wireless communication system with RF-based energy harvesting, where a master node acts both the information source and the energy source for a child node, while only information is transmitted back from the child node to the master node. In the systemic level viewpoint, we jointly investigate the two-way information transmission between the two nodes under the unique external power supply constraint at the master node. In particular, three typical receivers are considered, including the optimum receiver, the orthogonal receiver and the power splitting receiver. We explicitly characterize the achievable capacity-rate region and discuss the effect of signal processing power consumption at the child node. We also derive the boundary of the achievable capacity-rate region, which illustrates the most energy-efficient transmission strategy of the system. Simulation results confirm the substantial gain of employing capacity-rate region achieving transmission strategies and employing optimal receivers. Moreover, we present a typical application of our results, where the required transmit power is minimized to green the system."
  },
  {
    "year": "2017",
    "abstract": "Online social networks now play a prominent role in our daily lives and our decisions and behaviors in many areas. Of particular interest here is the application of social network data to give users access to tourist information. There is a growing need for information on tourism and tourist activities to satisfy user queries in this domain. Social networks, such as Facebook, Twitter, and Foursquare, among others, store substantial volumes of check-in data, which are a valuable resource for recommending tourism attractions. However, using Facebook check-in data has rarely been considered in conventional recommendation systems (RSs). This presents not only a new research challenge for the computer science and information technology fields but also an interesting opportunity for the tourism industry: knowing what kind of attractions tourists are interested in and how to acquire their user preferences without adding tasks to users of an RS. We propose a tourism RS that is based on its recommendations on data dynamically aggregated and extrapolated from the Facebook check-in data. In addition, the so-called “cold-start”problem has been resolved by using users' Friends' check-in data to analyze ongoing Facebook activity and update user profiles in the system. Most Facebook users have a well-extended list of Friends. Consequently, the proposed system can dynamically learn user behavior and appropriately adapt recommendations. This paper demonstrate the usefulness of the data available on Facebook through the example studies involving attraction recommendations, resolving the cold-start problem, and adapting the user model to improve recommendation quality in the tourism domain."
  },
  {
    "year": "2017",
    "abstract": "2-D-to-3-D conversion is one way to make full use of 2-D contents to produce 3-D contents. Real-time 2-D-to-3-D conversion is required for 3-D consumer electronic devices, which demands fast processing speed especially for high-definition videos. In this paper, we propose a reconfigurable VLSI architecture for real-time 2-D-to-3-D conversion. Two different depth-retrieval methods are implemented in this architecture in order to support the choice of a best method or combination of different methods. The proposed architecture can also support different resolutions (4K, 1080p, and 720p) and the original view can be configured as either left view or right view. In order to overcome the problem of “Memory Wall”, we propose a data reuse method to reduce memory traffic for the proposed architecture so that the overall performance is improved to realize real-time conversion. The experiment result shows that the implemented 2-D-to-3-D architecture can achieve state-of-the-art throughput (4K@30f/s)."
  },
  {
    "year": "2017",
    "abstract": "We compare three non-data-aided synchronization techniques for full-response continuous phase modulation (CPM) signals, which have feedforward structures and are suitable for burst-mode transmissions. All the schemes are based on the statistical characteristics of the full-response CPM signals with modulation index h = 1, for which the algorithms are investigated to estimate the carrier frequency offset, carrier phase, and symbol timing. For the CPM signal with an arbitrary modulation index, the phase unwrapping technique is used to convert the modulation index into 1, and then, the proposed algorithms could work. The performances of the synchronization algorithms are investigated by simulations and compared with the modified Cramer-Rao bounds. It turns out that the estimation performances of the frequency offset and timing offset are close to the theoretical limits in high signal-to-noise ratio."
  },
  {
    "year": "2017",
    "abstract": "The router's buffer accommodates transient packets to guarantee that the network's links do not become idle. However, buffer overflow causes packet loss, which is a signal of congestion. In content centric networking (CCN), the interest packet, which is used for requesting content, may be dropped due to such congestion. Each interest packet is assigned a specific lifetime, and when the lifetime expires without obtaining the requested content, the consumer needs to resend the Interest. However, waiting for the expiration of an Interest's lifetime for retransmission is only appropriate for best effort traffic rather than services that are delay sensitive. In order to provide delay-sensitive applications with better quality of service, we propose a congestion control mechanism for CCN, in which, we prevent congestion before it happens through monitoring buffer size. Upon reaching the buffer threshold, the node notifies its downstream node. On receiving the notification, the downstream node adjusts traffic rate by allocating new incoming Interests to other face(s). However, when the downstream node fails to reduce traffic rate, the same procedure continues until the consumer node reduces sending rate. The simulation results show that the proposed mechanism is capable of significant performance improvements, with higher throughput."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel approach for classifying incoming continuous data under a non-stationary environment. A class of estimators termed stochastic learning weak estimators has been generalized to include continuous time sampling and countable state categories. The method is founded on non-stationary Markov chain techniques and is useful in diverse applications, such as consumer behavior analysis, e-mail spam classification, or understanding drug effectiveness. In terms of tracking the true state probabilities, these weak estimators consistently outperform traditional competitors such as maximum likelihood estimates. Only one user defined parameter is necessary and the method is free of subjective “moving window”type algorithms. We have conducted extensive simulations and real data analyses for classification purposes."
  },
  {
    "year": "2017",
    "abstract": "A reconstruction method is provided to improve the measurement of the binocular vision. The image projections of the 3-D point on the 3-D reference are analyzed by the multiple view geometry. The Plücker coordinates of the two screw projection lines are constructed by the image points. The line segment perpendicular to two projection lines is generated from the direction vector and the end points of the line segment. As the bilinear products of the Plücker coordinates between the perpendicular line and the projection lines are zero, the end points of the perpendicular line segment are parameterized by the Cramer's Rule. The reconstruction error of the distance between two parameterized 3-D points is employed as the minimized objective of the cost function. The impact factors and the enhancements of the reconstruction accuracy are investigated by the experiments comparing with the original method. The method contributes the error descents of 27.19%, 38.29%, 19.01%,and 16.31% for the test lengths of 50, 100, 150, and 200 mm. Therefore, the results demonstrate that reconstruction method of the binocular vision provides the higher accuracy and application potentials."
  },
  {
    "year": "2017",
    "abstract": "User-based collaborative filtering is an important technique used in collaborative filtering recommender systems to recommend items based on the opinions of like-minded nearby users, where similarity computation is the critical component. Traditional similarity measures, such as Pearson's correlation coefficient and cosine Similarity, mainly focus on the directions of co-related rating vectors and have inherent limitations for recommendations. In addition, CF-based recommendation systems always suffer from the cold-start problem, where users do not have enough co-related ratings for prediction. To address these problems, we propose a novel similarity measure inspired by a physical resonance phenomenon, named resonance similarity (RES). We fully consider different personalized situations in RES by mathematically modeling the consistency of users' rating behaviors, the distances between the users' opinions, and the Jaccard factor with both the co-related and non-related ratings. RES is a cumulative sum of the arithmetic product of these three parts and is optimized using learning parameters from data sets. Results evaluated on six real data sets show that RES is robust against the observed problems and has superior predictive accuracy compared with the state-of-the-art similarity measures on full users', grouped users', and cold-start users' evaluations."
  },
  {
    "year": "2017",
    "abstract": "Reinforcement learning (RL) has distinguished itself as a prominent learning method to augment the efficacy of autonomous systems. Recent advances in deep learning studies have complemented existing RL methods and led to a crucial breakthrough in the effort of applying RL to automation and robotics. Artificial agents based on deep RL can take selective and intelligent actions comparable with those of a human to maximize the feedback reward from the interactive environment. In this paper, we survey recent developments in the literature regarding deep RL methods for building human-level agents. As a result, prominent studies that involve modeling every aspect of a human-level agent will be examined. We also provide an overview of constructing a framework for prospective autonomous systems. Moreover, various toolkits and frameworks are suggested to facilitate the development of deep RL methods. Finally, we open a discussion that potentially raises a range of future research directions in deep RL."
  },
  {
    "year": "2017",
    "abstract": "The deployment of heterogeneous networks (HetNets) can significantly boost the network capacity. However, the large number of small cell base stations (SBSs) deployed in HetNets can result in an increased total energy consumption. One of the promising techniques to reduce the energy consumption of networks is base station (BS) ON/OFF switching (sleeping) approaches. Due to device lifetime and energy waste by unnecessary switchings, the number of switchings is considered as an important problem. In this paper, we formulate the ON/OFF switching problem as a satisfaction game, where BSs seek to meet certain performance constraints in order to avoid the frequent BS switchings. Furthermore, BSs can choose their transmission power levels according to the network conditions in a distributed manner. The proposed satisfaction game involves a multi-step process. In the first step, we aim at satisfying the players with the high satisfaction threshold in a predefined time interval. To measure a BS's satisfaction, a utility function is used that includes BS's load and power consumption, in which the load of each BS is coupled with the load of other BSs. Since all players cannot be simultaneously satisfied, unsatisfied players decide to reduce their thresholds, and form a game with the redefined thresholds. To solve the game, a regret-based satisfaction algorithm and a satisfaction equilibrium search algorithm are applied. Simulation results show that the proposed schemes can achieve significant reductions in the number of switchings compared with the benchmark methods."
  },
  {
    "year": "2017",
    "abstract": "The electromagnetic fundamentals that govern the performance characteristics of dualpolarized tightly coupled cross-dipoles that are widely used in cellular base station applications are investigated. The mutual coupling effects and their impact on standard performance indices are stressed. A model is developed that considers this type of cross-dipole as an array. Links between the physical dimensions of the components of these model and key radiation characteristics, including directivity, half-power-beam width, and cross polarization discrimination levels, are established. The model guides the introduction and optimization of a simplified cross-dipole structure that exhibits excellent performance. A prototype was fabricated, assembled, and tested. The measured results are in good agreement with their simulated values, validating the model, and its governing principles."
  },
  {
    "year": "2017",
    "abstract": "A key requirement of an adaptive sensor array involves the ability to deterministically adjust the directional response of the array to reduce noise and reverberations, null interferences, and enhance the gain and recognition of the desired signal. This paper presents a low-carbon adaptive broadband beamforming algorithm called the regulated-element Frost beamformer. It enhances the desired signal based on the noise conditions of the individual omnidirectional sensors deployed in a complex dynamic environment that is prone to steering errors. The investigation of this algorithm was carried out in an interference-dominant, noisy automobile environment characterized by diffuse noise conditions. An embedded system measurement of real-time signals was carried out using omnidirectional acoustic sensors mounted in a model convertible F-Type car driven at speed limits of 20 to 50 mph. The simulation results indicate an array gain enhancement of 2 dB higher than the conventional Frost beamformer and it requires less sensors and filter taps for real-time reconfigurable implementations. The experimental results reveal that the average array gain of the regulated-element beamformer is 2.9 dB higher than the conventional Frost beamformer response. The minimum floor array gain of the regulated-element beamformer is 5 dB, representing 70% noise reduction than the conventional adaptive beamformers."
  },
  {
    "year": "2017",
    "abstract": "We demonstrate a series of nonlinear, active, and tunable metasurfaces for a variety of electromagnetic applications. The metasurfaces have achieved a range of exotic properties by populating nonlinear or active circuit components on a periodically patterned metallic surface. The circuit components such as diodes, varactors, transistors, and other devices can be controlled manually, actively, or self-adaptively. This allows nonlinear metasurfaces to have active tuning, power-dependent behavior, self-focusing, reconfigurable surface topology, or frequency self-tuning capabilities. The power-dependent metasurfaces can be applied to active RF absorbers that only absorb high-power surface waves to prevent malfunction or damages to sensitive devices. The rectifier-based waveform-dependent metasurface absorber can be specifically designed to absorb either high power pulsed waves or continuous waves. The transistor-based surface wave metasurface absorber provides another degree of freedom in that it can be manually switched to tune the absorber, or it can be tuned using computer controlled feedback. The self-focusing effect has been demonstrated for the first time at RF frequencies to automatically collimate high-power surface waves. The reconfigurable and self-tuning metamaterial surfaces can be implemented to support a broadband reconfigurable antenna system or to adapt to a wide range of incoming frequencies. In this paper, the concepts of nonlinear and active tunable metasurfaces are discussed, including results of full-wave simulation analysis, EM/circuit co-simulation, and experimental results in waveguides, using a near-field scanner, as well as far-field measurements in an anechoic chamber."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with the stochastic stability problem for discrete-time Markovian jump systems (DTMJSs) with time-varying delays. Two cases are discussed in the main results. On the one hand, it is assumed that the transition probability can be known. In this case, by constructing the Lyapunov-Krasovskii functional and using some summation inequalities to estimate its forward difference, a new stochastic stability criterion of DTMJSs can be obtained, which has less conservatism than existing results. On the other hand, by utilizing the homogeneous polynomial approach, the novel delay-dependent stability condition of DTMJSs with uncertain transition probability is proposed. Finally, the results of numerical simulations demonstrate the effectiveness of the proposed methods."
  },
  {
    "year": "2017",
    "abstract": "The CRISPR/Cas9 system is a creative and innovative gene editing biotechnology tool in genetic engineering. Although several achievements have been attained using the CRISPR/Cas9 system, it is still a challenge to avoid off-target effects and improve the editing efficacy. Previous efforts on evaluating the efficacy and designing the guide RNA mainly focused on DNA properties. However, some DNA features have not been characterized but can be reflected by protein properties, such as the disorder features and the sequence conservation. In this paper, we provided a computational framework to identify important features related to the efficacy of CRISPR/Cas9 focusing on the properties of the proteins encoded by the target DNA fragments. The feature selection method, maximal-relevance-minimal-redundancy, was adopted to analyze these features. And incremental feature selection together with support vector machine, were employed to extract optimal features, on which an optimal classifier can be constructed. As a result, 152 important features were extracted, with which an optimal classifier based on support vector machine was built. This classifier obtained the highest MCC value of 0.355. Finally, a series of detailed biological analyses were performed on the optimal features. From the results, we found that some key factors may differentially affect the binding activity of sgRNAs to their targets. Among them, the disorder status of the target protein sequences was found to be a major factor that is related to the efficacy of sgRNAs, suggesting the DNA features associated with the protein disorder status could also affect the CRISPR/Cas9 efficacy."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the downlink throughput capacity of hybrid wireless networks is mainly studied. Multiple-input multiple-output (MIMO) technology is assumed to be equipped on the base station and nodes to improve communication performance and increase the whole network throughput. A wireless network is also set up, with a wired network of base stations to support the remote communication of wireless nodes. In order to overcome the inter-cell interference, the frequency reuse technology is adopted. Under the favorable propagation condition, MIMO significantly mitigates the effect of fading between the node antenna and the base station antenna. We first analyze the downlink outage throughput capacity in slow fading scenarios and get the close-form outage capacity. Then, we analyze the ergodic throughput capacity over fast fading channel and get the ergodic capacity in both low SNR and high SNR scenarios. Finally, the availability of MIMO technology is proved by computer simulation."
  },
  {
    "year": "2017",
    "abstract": "Fog computing, being an extension to cloud computing has addressed some issues found in cloud computing by providing additional features, such as location awareness, low latency, mobility support, and so on. Its unique features have also opened a way toward security challenges, which need to be focused for making it bug-free for the users. This paper is basically focusing on overcoming the security issues encountered during the data outsourcing from fog client to fog node. We have added Shibboleth also known as security and cross domain access control protocol between fog client and fog node for improved and secure communication between the fog client and fog node. Furthermore to prove whether Shibboleth meets the security requirement needed to provide the secure outsourcing. We have also formally verified the protocol against basic security properties using high level Petri net."
  },
  {
    "year": "2017",
    "abstract": "Mobile users' service satisfaction plays a vital role in improving the revenue of telecom companies. When user data demands are uniform, satisfying the user requests is much easier than when demands are diverse. Yet, in a multicast scenario, each user may wish to view the same multicast data at different bit rates based on their own device capacities or resolutions. In this paper, we consider device-to-device (D2D) multicast users who may demand the multicast data at various rates, and in return, they offer different profits (revenue) to the telecom operator. Moreover, users may have different channel qualities from the base station, which will also affect the data rates. We show that satisfying the user requests to maximize the profit becomes NP-hard when the resource blocks are limited, and propose a greedy heuristic and two approximation algorithms to solve this problem. Besides, we consider an alternative objective of maximizing the number of satisfied users and propose a greedy heuristic algorithm for this variant. Our simulation results demonstrate that the proposed algorithms offer higher profit, throughput, and satisfy more users than the other candidate algorithms."
  },
  {
    "year": "2017",
    "abstract": "Visible light communication (VLC) is an emerging technique that uses light-emitting diodes to combine communication and illumination. It is considered as a promising scheme for indoor wireless communication that can be deployed at reduced costs, while offering high data rate performance. This paper focuses on the design of precoding and receiving schemes for downlink multi-user multiple-input multiple-output VLC systems using angle diversity receivers. Two major concerns need to be considered while solving such a problem. The first one is related to the inter-user interference, basically inherent to our consideration of a multi-user system, while the second results from the users' mobility, causing imperfect channel estimates. To address both concerns, we propose robust precoding and receiver that solve the max-min SINR problem. The performance of the proposed VLC design is studied under different working conditions, where a significant gain of the proposed robust transceivers over their non-robust counterparts has been observed."
  },
  {
    "year": "2017",
    "abstract": "Assistive robots have been developed to improve the living standards of older people. These assistive robots are intended to be operated by non-expert users. Hence, they should have the ability to interact with humans in a human-friendly manner. Humans prefer to use voice instructions, responses, and suggestions in their daily interactions. Such voice instructions and responses often include uncertain terms and lexical symbols rather than precise quantitative values. Therefore, the ability of robots to understand uncertain information is a crucial factor in the implementation of human-friendly interactive features in robots. This paper proposes a novel method of adapting the perception of the uncertain spatial information contents of navigational commands, such as “far” and “little”, based on environmental factors and user feedback. The proposed uncertain information understanding module has been implemented using fuzzy neural networks in such a way that the system can concurrently adapt to environmental factors while learning from user feedback. The proposed method has been implemented on the MIRob platform, and experiments have been conducted in an artificially created domestic environment to evaluate the performance and behaviors of the proposed concept. The experimental results validate the improvement of user satisfaction related to the understanding of uncertain information."
  },
  {
    "year": "2017",
    "abstract": "The emergence of social networking and proximity services is driving the Internet-ofThings (IoT) paradigms toward a location-aware connecting society. To prepare for such a booming paradigm, IEEE 802.15.8 standardizes peer-aware communication (PAC) within the strict consideration of infrastructureless property and fully distributed coordination features. Since no central entity exists in a PAC network for control and management purposes, every PAC device (PD) plays an equal role in terms of communication. This situation leads to a variety of security challenges, especially in authentication and key agreement for lightweight IoT-enabled PDs. Recently, there are some proposals aimed at the aforementioned problems, such as approaches with personal identification number, physical layer features. However, due to its inconvenience and computational complexity for the lightweight IoT-enabled PDs, authentication and key agreement are still open issues in PAC. From this view, this paper proposes a new approach that utilizes social networking features closely tied to the PAC in order to support authentication and key agreement procedures. A number of trusted PDs are delegated to authenticate the requesting PD on behalf of the requested PD when an association is established between them. Intensive analysis and evaluation show that the proposed protocol provides multiple security levels as well as user convenience with reasonable resource consumption."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the resource allocation problem for uplink non-orthogonal multiple access (NOMA) networks whose users represent power-restricted but high priority devices, such as those used in sensor networks supporting health and public safety applications. Such systems require high reliability and robust resource allocation techniques are needed to ensure performance. We examine the impact on system and user performance due to residual cancellation errors resulting from imperfect successive interference cancellation (SIC) and apply the chance-constrained robust optimization approach to tackle this type of error. In particular, we derive an expression for the user outage probability as a function of SIC error variance. This result is used to formulate a robust joint resource allocation problem that minimizes user transmit power subject to rate and outage constraints of critical applications. As the proposed optimization problem is inherently non-convex and NP-hard, we apply the techniques of variable relaxation and complementary geometric programming to develop a computationally tractable two-step iterative algorithm based on successive convex approximation. Simulation results demonstrate that, even for high levels of SIC error, the proposed robust algorithm for NOMA outperforms the traditional orthogonal multiple access case in terms of user transmit power and overall system density, i.e., serving more users over fewer sub-carriers. The chance-constrained approach necessitates a power-robustness tradeoff compared with non-robust NOMA but effectively enforces maximum user outage and can result in transmit power savings when users can accept a higher probability of outage."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency-division multiplexing with index modulation (OFDM-IM) has attracted much attention in recent years. In OFDM-IM, the information bits of a block are generally divided into several subblocks, each of which is further split into two parts, i.e., the index bits and the symbol bits. By performing a coordinate interleaving operation over each two constellation symbols, the bit-error-rate (BER) performance of the symbol bits is significantly improved in an existing OFDM-IM scheme, which is called coordinate-interleaved OFDM-IM (CI-OFDM-IM). In this paper, we propose a novel OFDM-IM scheme termed enhanced CI-OFDM-IM (ECI-OFDM-IM). In ECI-OFDM-IM, to improve the BER performance of the index bits, we adopt a special subcarrier-activation pattern (SAP) lookup table in which the Hamming distance of any pair of SAPs is at least four. To improve the BER performance of the symbol bits conveyed by the active subcarriers, the operations of rotating and coordinate interleaving are conducted twice over each four constellation symbols. Based on the maximum likelihood (ML) detection, a theoretical upper bound on the average bit-error probability of ECI-OFDM-IM is derived in closed form. By using the log-likelihood ratio method for SAP detection, a semi-ML detection scheme is proposed. Both the theoretical and simulation results show that ECI-OFDM-IM outperforms CI-OFDM-IM with additional diversity gains over frequency-selective Rayleigh fading channels."
  },
  {
    "year": "2017",
    "abstract": "A new fuzzy procedure for adaptive gray-level image contrast enhancement (CE) is presented in this paper. Starting from the pixels belonging to a normalized gray-level image, an appropriate smooth S-shaped fuzzy membership function (MF) is considered for gray-scale transformation and is adaptively developed through noise reduction and information loss minimization. Then, a set of fuzzy patches is extracted from the MF, and for each support of each patch, we compute four ascending-order statistics that become points inside a 4-D fuzzy unit hypercube after a suitable fuzzification step. CE is performed by computing the distances among the above points and the points of maximum darkness and maximum brightness (special vertexes in the hypercube), and by determining the rotation of the tangent line to the MF around a crucial point where fuzzy patches and the MF coexist. The proposed procedure enables high CE in all the treated images with performance that is fully comparable with that obtained by three more sophisticated fuzzy techniques and by standard histogram equalization."
  },
  {
    "year": "2017",
    "abstract": "The dynamic network topology and mobile nature of nodes can cause challenges regarding connectivity and routing. Clustering in mobile ad-hoc networks (MANETs) is one of the effective ways to organize a network according to the network topological changes. In this paper, we propose a self-organization-based clustering scheme in MANET using zone-based group mobility to improve scalability and stability of overall network. This proposed algorithm utilizes the bio-inspired behavioral study of birds flocking for the formation and maintenance of clusters in MANETs. A dynamic mechanism for cluster size management is taken into account to reduce network congestion and improve the performance of the MANETs in group mobility. For proper use of resources and to reduce extra energy consumption, an algorithm is also proposed to handle the isolated nodes. Simulation result shows that proposed algorithm reduces the energy consumption and improves the network lifetime along with more robustness."
  },
  {
    "year": "2017",
    "abstract": "The password-based authenticated key exchange (PAKE) protocol is one of most practical cryptographic primitives for trusted computing, which is used to securely authenticate devices' identities and generate shared session keys among devices in insecure environments by using a short, human-memorable password. With the fast development of the Internet of Things (IoT), new challenges regarding PAKE have emerged. The traditional PAKE protocols are completely insecure in IoT environments, since there are many kinds of side-channel attacks. Therefore, it is very important to model and design leakage-resilient (LR) PAKE protocols. However, there has been no prior work on modeling and constructing LR PAKE protocols. In this paper, we first formalize an LR eCK security model for PAKE based on the eCK-secure PAKE model and the only computation leakage model. Then, we propose the first LR PAKE protocol by using Diffie-Hellman key exchange, LR storage (LRS) and LR refreshing of LRS appropriately and formally present a security proof in the standard model."
  },
  {
    "year": "2017",
    "abstract": "Vibration energy harvesting by using piezoelectric materials provides a promising alternative solution for a wide range of self-powered systems. In this paper, performance dependence on initial freeend levitation position (IFLP) of a magnetically levitated piezoelectric vibration energy harvester (PVEH) with a composite cantilever beam is presented. A prototype consisting of a high-stiffness lead zirconate titanate beam with a proof mass and a flexible brass beam with a tip mass as well as an auxiliary structure adjusting repulsive magnetic force was fabricated to evaluate the IFLP effects. Experimental results showed that the performance of the magnetically levitated PVEH was varied with different IFLPs. With declining of the IFLP, the peak power output at the first resonance frequency decreased monotonically from 1541 to 343.2 μW, meanwhile, the power output initially decreased from 2735.6 to 904.5 μW and then constantly increased from 904.5 to 2220.9 μW at the second resonance frequency. The frequency variation at the first and second resonance points was 1.5 and 4 Hz, respectively. It was found that the IFLP had a stronger impact on the performance when it was above the horizontal orientation than below the horizontal orientation. Moreover, the IFLP brought a more significant influence on the second resonance frequency than the first one. In addition, the IFLP had a larger effect on the power output than the resonance frequency."
  },
  {
    "year": "2017",
    "abstract": "A depth camera-based novel method is proposed here for efficient facial expression recognition. For each pixel in a depth image, eight local directional strengths are obtained and ranked. Once the rank of all pixels is obtained, eight histograms are developed for the eight surrounding directions. The histograms are then concatenated to represent features for a depth image of a face. This approach is named local directional rank histogram pattern (LDRHP). To combine with LDRHP features, one more robust feature extraction technique named local directional strength pattern (LDSP) is proposed. Typical local directional pattern (LDP) considers only absolute values of edge strengths for a pixel. This generalization in LDP may generate the same patterns for two different kinds of edge pixels. LDSP can overcome this problem. It considers the binary values of the position with the directions representing the highest and lowest original strengths. The highest strength indicates the strongest direction on the bright side of a pixel and the lowest one indicates the strongest direction in the dark side of that pixel. Hence, combining binary positions of these two directions can generate more robust patterns than LDP. Besides, LDSP pattern of a pixel is of six bits, whereas traditional LDP-based patterns are of eight bits (e.g., local directional deviation-based pattern and local directional position pattern). Thus, LDSP reduces the dimension of features with the same time adding robustness. For a depth image in a depth video, LDSP features are augmented with LDRHP features followed by Kernel principal component analysis and generalized discriminant analysis to generate more robust features. At last, the features are trained with a deep learning approach and convolutional neural network for successful facial expression recognition. The proposed approach is compared and shown to outperform the traditional expression recognition methods."
  },
  {
    "year": "2017",
    "abstract": "A data-driven generalization of the crossover model is proposed, characterizing the human control of systems with both integer and fractional-order plant dynamics. The model is developed and validated using data obtained from human subjects operating in compensatory and pursuit tracking tasks. From the model, it is inferred that humans possess a limited but consistent capability to compensate for fractional-order plant dynamics. Further, a review of potential sources of fractionality within such man-machine systems suggests that visual perception, based on visual cues that contain memory, and muscular dynamics are likely sources of fractional-order dynamics within humans themselves. Accordingly, a possible mechanism for fractional-order compensation, operating between visual and muscular subsystems, is proposed. Deeper analysis of the data shows that human response is more highly correlated to fractional-order representations of visual cues, rather than directly to objective engineering variables, as is commonly proposed in human control models in the literature. These results are expected to underpin future design developments in human-in-the-loop cyber-physical systems, for example, in semi-autonomous highway driving."
  },
  {
    "year": "2017",
    "abstract": "Collaborative filtering algorithms, such as matrix factorization techniques, are recently gaining momentum due to their promising performance on recommender systems. However, most collaborative filtering algorithms suffer from data sparsity. Active learning algorithms are effective in reducing the sparsity problem for recommender systems by requesting users to give ratings to some items when they enter the systems. In this paper, a new matrix factorization model, called Enhanced SVD (ESVD) is proposed, which incorporates the classic matrix factorization algorithms with ratings completion inspired by active learning. In addition, the connection between the prediction accuracy and the density of matrix is built to further explore its potentials. We also propose the Multi-layer ESVD, which learns the model iteratively to further improve the prediction accuracy. To handle the imbalanced data sets that contain far more users than items or more items than users, the Item-wise ESVD and User-wise ESVD are presented, respectively. The proposed methods are evaluated on the famous Netflix and Movielens data sets. Experimental results validate their effectiveness in terms of both accuracy and efficiency when compared with traditional matrix factorization methods and active learning methods."
  },
  {
    "year": "2017",
    "abstract": "The recent interest in massive multiple in multiple out (MIMO) has spurred intensive work on massive MIMO channel modeling in the contemporary literature. However, current models fail to take the characteristics of terminal antennas into account. There is no massive MIMO channel model available that can be used for the evaluation of the influence of different antenna characteristics at the terminal side. In this paper, we provide a simulation framework that fills this gap. We evaluate the framework with antennas integrated into Sony Xperia handsets operating at 3.7 GHz as this spectrum is identified for the 5G new radio standard by 3rd Generation Partnership Project. The simulation results are compared with the measured terminal performance when communicating with the Lund University's massive MIMO testbed under the same loading conditions. Expressions are derived for comparison of the gain obtained from different diversity schemes computed from measured far-field antenna patterns. We conclude that the simulation framework yields the results close to the measured ones and that the framework can be used for antenna evaluation for terminals in a practical precoded massive MIMO system."
  },
  {
    "year": "2017",
    "abstract": "Cloud storage has been gaining tremendous popularity, which provides facilitative data storage and sharing services for distributed clients. To maximize the availability and reliability, some customers may store multiple replicas of critical data on cloud servers. However, cloud servers may collude to make it look like they are storing multiple copies of data, whereas in fact they only store a single copy. Currently, several multi-replica provable data possession schemes have been proposed to provide verifications to ensure that all the outsourced copies are actually stored and maintained intact. For these schemes with third-party verifications, correctly choosing public keys of data owners relies on the public key infrastructure (PKI), which is complicated and resource consuming. In this paper, we propose a novel identity-based public multireplica provable data possession scheme (IDPMR-PDP) to provide third-party verification of outsourced data with multiple replicas without PKI. We also introduce a formal security model of identity-based public multi-replica PDP schemes and prove that the IDPMR-PDP is secure against malicious cloud servers and privacy-preserving against curious verifiers under this model. Meanwhile, our analyses and simulation results demonstrate that the IDPMR-PDP realizes efficient integrity verification."
  },
  {
    "year": "2017",
    "abstract": "Cyber-physical manufacturing systems (CPMSs) are a new paradigm of manufacturing systems that integrate cyber systems and physical systems to aid smart manufacturing. CPMSs can improve the system's flexibility and productivity and adapt to new market demands. However, CPMSs are susceptible to cyber-attacks, which can modify manufacturing intents to produce parts incorrectly and cause hazards to equipment, employees, and consumers. Therefore, the trustworthiness of CPMSs is critical to the entire systems. In order to describe and analyze the trustworthiness of CPMSs, generalized stochastic Petri nets are adopted to model CPMSs and the trustworthiness is measured from three metrics, i.e., the reliability, availability and security. To study the trustworthiness evolution of CPMSs, a malicious software spreading dynamics model is presented, and its dynamic behaviors are analyzed. Finally, the CPMS trustworthiness evolution model is constructed depending on the proposed dynamics model. The simulation results demonstrate that the proposed approach is effective to model and analyze the CPMS trustworthiness."
  },
  {
    "year": "2017",
    "abstract": "In recent years, mobile devices are becoming an integrated part of our society, and this reinforces the need for security and privacy without incurring additional communication and computation costs. In this paper, we propose a new efficient privacy preserving time-key-based single sign-on (TK-SSO) authenticated key management protocol for mobile devices using elliptic curve cryptography. This allows us to achieve the desirable security properties along with significantly reduced computation and communication costs. TK-SSO also supports the revocation of mobile users and servers. We prove the security of TK-SSO in a widely accepted adversary real-or-random model, as well as using Burrows-Abadi-Needham (BAN) logic and the Automated Validation of Internet Security Protocols and Applications (AVISPA) simulation tool to demonstrate that TK-SSO can resist various known attacks. We then evaluate the performance of TK-SSO and three related protocols to demonstrate its utility."
  },
  {
    "year": "2017",
    "abstract": "Public social environments are hot beds of security leaks, either they are virtual or physical. The nature of social settings allows numerous people to co-exist in the same space. This close un-bounded proximity opens up the possibility of privacy compromise in such environments. In this paper, we explore a novel and practical multi-modal side-channel keystroke recognition system, named ClickLeak, which can infer the PIN code/password entered on numeric keypad by using the commodity Wi-Fi devices. Such numeric keypads are commonly available in many public social environments. ClickLeak is built on the observation that each key input makes unique pattern of hand and finger movements, and this generates unique distortions to multi-path Wi-Fi signals. Acceleration and microphone sensors of smart phones determine the starting and ending time of keystrokes, while the time series of channel state information are analyzed to determine the keystrokes. The evaluation results have shown that with large scale data collections from public social settings, the key recognition accuracy can reach higher than 83%."
  },
  {
    "year": "2017",
    "abstract": "Low-dose computed tomography (LDCT) images tend to be severely degraded by excessive mottle noise and steak artifacts. In this paper, an algorithm of modified smooth patch ordering (MSPO) is proposed to improve the LDCT images. In the MSPO method, the non-local means (NLM) algorithm is modified by replacing the Leclerc robust function with the modified bisquare robust function, to serve as weight function for the estimate of each pixel value. Then, the modified NLM algorithm is combined with smooth ordering of the pixels, patch classification, and subimage averaging scheme to denoise the LDCT image. Additionally, the prewhitening of the LDCT image is carried out to enhance image denoising, and the total-variation filter is utilized as a post-processing step to further remove the residual noise of the recovered image. Subjective and objective evaluations on the actual thoracic phantom and clinical data are carried out for validating the effectiveness of the proposed method. The results from computer experiments demonstrate that the proposed MSPO approach performs better in both artifact suppression and structure preservation, when compared with several existing methods. Especially, the MSPO approach can be directly applied to process digital imaging and communications in medicine (DICOM) images, and has great potential in most current CT systems."
  },
  {
    "year": "2017",
    "abstract": "In order to overcome the often encountered trouble in setting the controller parameters by trial and error, an attempt has been made to design the proportional-plus-integral (PI) controllers for a variable-speed direct-drive permanent magnet synchronous generator-based grid-connected wind energy system (WES). The characteristic equations for various control loops in WES have been developed, and the most stable zones have been identified in the parametric plane by means of the D-partition technique and frequency scanning check. To ensure high degree of relative system stability and good damping ratio, the PI controller parameters have been selected by comparing the step responses of the control loop plotted for different sets of controller parameters chosen from the identified stable zone. A simulation model using MATLAB/Simulink and SimPowerSystems toolbox has been built to examine the performance of the WES incorporated with the designed values of the parameters of the PI controllers under fluctuating wind speed condition."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an extension of research scope of the relationship between quality of service (QoS) and quality of experience (QoE), which is based on contribution of lower open system interconnection layers, such as physical and media access control, in overall QoS/QoE paradigm. Degradations that inevitably occur in transmission channel are an important reason for appearance of QoS distortion and therefore low values of video quality. Various channel quality indicators (CQIs) relating to domain of communication channel can be used for notification of different interferences in the channel. In order to extend the relationship between QoS and QoE to the transmission channel, the paper proposed the mathematical model that used CQI to estimate values of QoS indicators by using statistical analysis. The model was also expanded by objective video quality metrics in order to evaluate QoE. Verification of the model was checked by experimental method with consideration of Internet protocol television (IPTV) service delivery in Digital Subscriber Line network."
  },
  {
    "year": "2017",
    "abstract": "We experimentally demonstrated a diode-pumped femtosecond Yb:CaNb2O6disordered crystal laser. Pumping by a 978-nm fiber coupled laser diode and assisting by a semiconductor saturable absorber mirror, stable continuous-wave mode-locked laser pulses with a width of 170 fs at the central wavelength of about 1038 nm were obtained. The laser pulses had an average output power and a repetition rate of 135 mW and 80 MHz, respectively. To the best of our knowledge, this is the shortest laser pulses generated from Yb:CaNb2O6disordered crystal lasers."
  },
  {
    "year": "2017",
    "abstract": "Rockbursts occur frequently and cause serious damage in deep tunnels. Microseismic (MS) source location is of great importance and forms the foundation of the MS monitoring technology used in tunnel rockburst hazard mechanism analysis. A highly accurate method for locating MS events that occur during rockburst development in tunnels is proposed here. An anisotropic velocity model, rockburst event monitor, and a global optimization algorithm (particle swarm optimization) are used in tandem to make the proposed method feasible and the location accuracy better. Simulation results show the MS sources can be located more accurately using the proposed method. The average location error is reduced by 20.16 m. Our method was used to locate MS events associated with rockburst development processes occurring in the deep tunnels of the Jinping II hydropower station in China. The location accuracy of the MS events in the rockburst development process is significantly improved. The case study shows that the located MS events are clustered together more closely in the rockburst area. The average distance of all the MS events to the position of the rockburst is reduced from 23.77 to 13.43 m. The method is highly conducive to in-depth analysis of rockburst development processes and investigation of their mechanisms of formation."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an intelligent constant false alarm rate detector, which uses support vector machine (SVM) techniques to improve the radar detection performance in different background environments. The proposed detector uses the variability index statistic as a feature to train a SVM and recognizes the current operational environment based on the classification results. The proposed detector has the intelligence to select the proper detector threshold adaptive to the current operational environment. This detector provides a low loss performance in homogeneous backgrounds and also performs robustly in nonhomogeneous environments including multiple targets and clutter edges."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the frequency hit avoidance problem in distributed frequency hopping multiple access (FHMA) networks, in which each user intends to avoid the frequency hit with others by choosing the appropriate frequency set and frequency hopping sequence. First, we define the network hit degree as the metric for the hits, and formulate the frequency hit avoidance problem as an optimization problem of the network hit degree. Second, we formulate a non-cooperative game model to solve this optimization problem, and prove the game is an exact potential game, which illustrates that the Nash equilibria (NE) point of the game is the optimal solution of the optimization problem. Finally, we propose a fragment-based distributed hit avoidance (FDHA) learning algorithm and prove that the learning algorithm can converge to the NE point. The simulation results show that the proposed algorithm can converge to the optimal solution rapidly such that the FHMA network is hit-free."
  },
  {
    "year": "2017",
    "abstract": "Sparsity is a tough problem in a single domain collaborative filtering (CF) recommendation system as it is difficult to compute the similarities among users accurately. Recently, cross domain CF is a new way to alleviate this difficulty. In this paper, we propose a user-based cross domain CF algorithm based on a linear decomposition model. We pour the items together and learn a linear decomposition model to explore the relationship between the total similarity and the local similarities of different domains. We first construct training samples by computing the similarities of any two users in different domains. Then, we solve a linear least square problem to obtain the decomposition coefficients. Finally, we compute the local similarity in the target domain using the decomposition model. Since we compute the similarity in the target domain with the help of rich ratings in other domains, this similarity would be expected to be more accurate than the measured similarity computed by the sparse ratings in the target domain. We conduct extensive experiments to show that the proposed algorithm is effective in addressing the data sparsity problem, as compared with many state-of-the-art CF methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the channel estimation problem for multiple-input multiple-output wireless relay communication systems with multiple relay nodes. In particular, all individual channel matrices of the first-hop and second-hop links are estimated at the destination node by applying the superimposed channel training algorithm, where training sequences are superimposed at the relay nodes to assist the estimation of the relays-destination channel matrices. To improve the performance of channel estimation, we consider the estimation error inherited from the second-hop channel estimation and develop a new minimal mean-squared error-based algorithm to estimate the first-hop channel matrices. Furthermore, we derive the optimal power allocation and training sequences at the source and relay nodes. Numerical examples demonstrate a better performance of the proposed superimposed channel training algorithm."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an adaptive fractional sliding mode control scheme based on dual radial basis function (RBF) neural networks (NNs) to enhance the performance of a three-phase shunt active power filter (APF), where a conventional integer-order sliding surface is changed into a fractional-order one to speed up the system response and optimize the control performance. Furthermore, the control scheme adopts a class of dual RBF NNs, in which the network weights can be updated online to approximate the nonlinear system functions and the upper bound of estimated disturbances, respectively, improving the system stability and robustness. Meanwhile, the adaptive control laws obtained by Lyapunov analysis can guarantee the system a stable operation. Finally, by comparing with the integer-order control strategy, the simulation results verify that this proposed controller has a better performance in the suppression of the harmonic, elimination of system uncertainties, and the reduction of current tracking error."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we analyze the outage performance of different multicarrier relay selection schemes for two-hop orthogonal frequency-division multiplexing (OFDM) systems in a Poisson field of relays. In particular, special emphasis is placed on decode-and-forward relay systems, equipped with bulk and per-subcarrier selection schemes, respectively. The exact expressions for outage probability are derived in integrals for general cases. In addition, asymptotic expressions for outage probability in the high signal-to-noise ratio region in the finite circle relay distribution region are determined in closed forms for both relay selection schemes. In addition, the outage probabilities for free space in the infinite relay distribution region are derived in closed forms. Meanwhile, a series of important properties related to cooperative systems in random networks are investigated, including diversity, outage probability ratio of two selection schemes, and optimization of the number of subcarriers in terms of system throughput. All analyses are numerically verified by simulations. Finally, a framework for analyzing the outage performance of the OFDM systems with spatially random relays is constructed, which can be easily modified to analyze other similar cases with different forwarding protocols, location distributions, and/or channel conditions."
  },
  {
    "year": "2017",
    "abstract": "During the past few years, we are witnessing the emergence of 5G and its high-level performance targets. Waveform (WF) design is one of the important aspects for 5G that received considerable attention from the research community in recent years. To find an alternative to the classical orthogonal frequency division multiplexing (OFDM), several multicarrier approaches addressing different 5G technical challenges, have been proposed. In this paper, we focus on critical machine-type communications (C-MTC), which is one of the key features of the foreseen 5G system. We provide a comparative performance study of the most promising multicarrier WFs. We consider several C-MTC key performance indicators: out-of-band radiations, spectral efficiency, end-to-end physical layer latency, robustness to time and frequency synchronization errors, power fluctuation, and transceiver complexity. The investigated multicarrier WFs are classified into three groups based on their ability to keep the orthogonality: in the complex domain, e.g., most of the OFDM-inspired WFs, in the real domain like offset-quadrature amplitude modulation (QAM)-based techniques, and non-orthogonal WFs like generalized frequency division multiplexing and filter bank-based multicarrier-QAM. Finally, the performances of these WFs are thoroughly discussed in order to highlight their pros and cons and permit a better understanding of their capabilities in the context of C-MTC."
  },
  {
    "year": "2017",
    "abstract": "The massive number of the machine type communication terminals accessing the satellite network brings a new challenge for the random access (RA) system. To meet the challenge, by using the polarization transmission structure in the satellite uplink, we propose a new RA scheme dubbed polarized multiple input multiple output slotted ALOHA (PMSA). In PMSA, in one slot, one packet and two overlapped packets can be decoded successfully with the polarized MIMO detection algorithms, and some of three overlapped packets may be decoded successfully in consideration of the capture effect at the satellite node. For the new features of the proposed scheme in physical layer, the protocol of medium access control (MAC) is modified based on the slotted ALOHA (SA). Simulation results show that the normalized throughput of the PMSA can reach 0.84 and is consistent with the theoretical throughput. Moreover, it is also shown that the throughput of PMSA is about 2.3 times as large as that of the SA and 1.5 times as large as that of the contention resolution diversity slotted ALOHA (CRDSA), without the need for additional transmitted power and time slots to transmit the replicas of the packets. The received packets in the proposed PMSA are processed slot by slot, not as that processed frame by frame in the CRDSA with a large additional frame delay."
  },
  {
    "year": "2017",
    "abstract": "Chameleon authentication tree (CAT) is an important authenticated data structure for verifiable data streaming in 5G networks. But the typical CAT cannot support the dynamic scenario very well because it cannot expend freely since its height is fixed. Therefore, we proposed a dynamic CAT (DCAT) with the feature of adaptive expansion. We divided the algorithms of the DCAT with the following phases: setup, append, query, and verification. The DCAT removes the drawbacks of the static CAT. In the setup phase, it is not required for the scale of the tree to be determined, and the scale of the tree can be adaptively expanded during the data-appending phase. Therefore, the DCAT can suit the data stream environment better. During the data querying phase, the average authentication path length has been reduced, which leads to less space requirement and better verification efficiency. Finally, we performed theoretical analysis and drew a comparison between the static CAT and the DCAT in terms of performance. The result indicates that the DCAT provides improvements in the performance of the data-appending, data-querying, and data verification processes."
  },
  {
    "year": "2017",
    "abstract": "A four feet driving-type linear piezoelectric actuator, which achieves linear driving motion with step displacement of several microns by the alternating longitudinal motions of three bolt-clamped transducers, is designed and tested. The three transducers are located in I-shape, and the four end tips of the two horizontal transducers are used to drive the runner step-by-step. The horizontal displacements of the driving tips are used to lock the runner, whereas their vertical displacements push the runner linearly. The kinematics of the linear piezoelectric actuator is analyzed and discussed, and the deformations of the transducers are calculated. A prototype is fabricated and tested by an experimental platform. The output displacement has approximately a linear relationship with the amplitude of the voltage, and their ratio is tested to be about 0.01 μm/V. The steady displacement of the driving tip is tested to be about 1.85 μm for one step under voltage of 200 V, and a maximum speed of 141.2 μm/s is achieved under a frequency of 70 Hz."
  },
  {
    "year": "2017",
    "abstract": "Time-of-flight (ToF) 3-D cameras like the Microsoft Kinect, are prevalent in computer vision and computer graphics. In such devices, the power of an integrated laser is amplitude modulated at megahertz frequencies and demodulated using a specialized imaging sensor to obtain subcentimeter range precision. To use a similar architecture and obtain micrometer range precision, this paper incorporates beat notes. To bring telecommunications ideas to correlation ToF imaging, we study a form of “cascaded Time of Flight”which uses a hertz-scale intermediate frequency to encode high-frequency pathlength information. We show synthetically and experimentally that a bulk implementation of opto-electronic mixers offers: 1) robustness to environmental vibrations; 2) programmability; and 3) stability in frequency tones. A fiberoptic prototype is constructed, which demonstrates 3-μm range precision over a range of 2 m. A key contribution of this paper is to study and evaluate the proposed architecture for use in machine vision."
  },
  {
    "year": "2017",
    "abstract": "Visual object tracking is an essential technique for constructing intelligent livestock management systems. Behavior patterns estimated from the trajectories of animals provide substantial useful information related to estrus cycle, disease prognosis and so on. However, similar colors and shapes between animals often lead to the failure of tracking multiple objects, and the background clutter of the breeding space further makes the problem intractable. In this paper, we propose a novel method for tracking animals using a single thermal sensor. The key idea of the proposed method is to represent the foreground (i.e., animals) easily obtained by a simple thresholding in a thermal frame as a topographic surface, which is very helpful for finding the boundary of each object even in cases with overlapping. Based on the segmentation results derived from morphological operations on the topographic surface, the center positions of all the animals are consistently updated with an efficient refinement scheme that is robust to the abrupt motions of animals. Experimental results using various thermal video sequences demonstrate the efficiency and robustness of our method for tracking animals in a breeding space compared to previous approaches proposed in the literature."
  },
  {
    "year": "2017",
    "abstract": "The problem of sampled-data L2- L∞consensus control for the multi-agent systems with nonlinear dynamics and external disturbances is investigated via dynamic output feedback (DOF) strategy. Both the control input and the measured output are sampled. By employing the input/output delay approach, the multi-agent system with sampled-data DOF control protocol is transformed into the closed-loop system with bounded time-varying delays. Then, by using matrix theory, graph theory, Lyapunov stability theory, and some decoupling methods, sufficient conditions for the sampled-data L2- L∞consensus of the closed-loop system are derived under fixed and switching topologies, respectively. The desired gains can be obtained by solving a set of linear matrix inequalities. Finally, two numerical examples are provided to illustrate the effectiveness of the proposed DOF control protocol."
  },
  {
    "year": "2017",
    "abstract": "Over the decades, the immense growth has been reported in research publications due to continuous developments in science. To date, various approaches have been proposed that find similarity between research papers by applying different similarity measures collectively or individually based on the content of research papers. However, the contemporary schemes are not conceptualized enough to find related research papers in a coherent manner. This paper is aimed at finding related research papers by proposing a comprehensive and conceptualized model via building ontology named COReS: Content-based Ontology for Research Paper Similarity. The ontology is built by finding the explicit relationships (i.e., super-type sub-type, disjointedness, and overlapping) between state-of-the-art similarity techniques. This paper presents the applications of the COReS model in the form of a case study followed by an experiment. The case study uses InText citation-based and vector space-based similarity measures and relationships between these measures as defined in COReS. The experiment focuses on the computation of comprehensive similarity and other content-based similarity measures and rankings of research papers according to these measures. The obtained Spearman correlation coefficient results between ranks of research papers for different similarity measures and user study-based measure, justify the application of COReS for the computation of document similarity. The COReS is in the process of evaluation for ontological errors. In the future, COReS will be enriched to provide more knowledge to improve the process of comprehensive research paper similarity computation."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a multi-physics modeling of a switched reluctance motor (SRM) drive system. The proposed framework includes a 2-D finite element model to simulate the magnetic field characteristics, and a multi-physics mechatronic model to simulate its electric field and controller properties. The obtained magnetic characteristics are used in the analytical modeling in the form of a lookup table. Dynamic performance parameters for SRM are directly calculated from the co-simulation platform. Current, torque, flux, and radial force under various operational conditions can then be simulated to evaluate the dynamic performance of a switched reluctance drive system. The control algorithm is then realized based on the co-simulation platform. Methodology to evaluate the dynamic performance for the SRM is shown in this paper. A three-phase 12/8 1.5 Kw SRM is used in this paper. Static magnetic characteristics and dynamic performance parameters for the SRM are shown and discussed in this paper."
  },
  {
    "year": "2017",
    "abstract": "Simulation has become an established technique to support the design of complex, mechatronic or cyber-physical systems. Ideally, simulations should already be performed at an early design phase before high-cost design commitments are made, and the recent advances in the digitalization of design information open possibilities for automatic generation of simulation models. However, high-fidelity simulation model building depends on accurate data. In particular, first-principles models are desirable source information for simulations, but such models generally are not available at an early design stage. This paper investigates the automatic generation of first-principles 3-D models for piping intensive systems based on design information that is available at an early design stage, namely piping & instrumentation diagrams (P&ID). An algorithm is presented for the generation of such 3-D models based on machine-readable P&ID information. The main focus of the algorithm is the automatic generation of feasible pipelines into the 3-D models, so that the model has sufficient information, which can be exploited in further work to automatically generate high fidelity first-principles thermo-hydraulic simulations."
  },
  {
    "year": "2017",
    "abstract": "In recent years, fuzzy utility mining has become an area of interest due to advancement of human reasoning. With regards to real applications, transactions in a database often involve things, such as transaction time, stamp, and much more. It is also noted that not all products in a store are displayed on the shelf, especially the seasonal ones. This paper, therefore, addresses these issues by presenting an effective framework called temporal-based fuzzy utility mining to give more attention to the transaction period of given items according to the concept of fuzzy utility mining. The temporal-based fuzzy utility mining proposed here is, however, a more complex approach when compared with the traditional fuzzy utility mining. A more complicated model for non-lost upper-bound fuzzy utility is thus proposed for effective mining. Furthermore, based on this model, a two-phase algorithm is developed for temporal-based fuzzy utility mining. Finally, the difference of fuzzy utility item sets with and without consideration of the lifetime of the items is shown by the experimental results under various experimental conditions."
  },
  {
    "year": "2017",
    "abstract": "In future 5G communication systems, supporting high-quality wireless communications in high-mobility scenarios becomes very essential. Although many existing works indicate that increasing transmit power is able to reduce the handover failure probability (referred to as the power greedy scheme) through improving the radio condition or received signal strength, it goes against the requirement of green system design. In this paper, we investigate the effect of power adjustment on handover performance from the perspective of reducing the “uncertainty” in handover procedure in high-speed railway communications systems by embedding it into the existing handover procedure. It is shown that, with power adjustment, the handover performance can be improved without increasing extra energy consumption. The power adjustment-assisted handover scheme is applied to a high-speed railway scenario with distributed antenna system (DAS) cells. Both the blanket transmission-based handover scheme and the remote antenna unit selection transmission-based handover scheme are discussed for DAS cells. To evaluate the performance, the handover probability, handover failure probability, and communication interruption probability associated with two handover schemes are analyzed. Moreover, two new performance metrics, named handover occurrence probability and handover failure occurrence probability, are defined to efficiently evaluate the handover performance versus the position of the train. Both the analytical and the numerical results show that introducing power adjustment into handover gives ability to achieve a better performance compared with the current existing ones. Moreover, the power adjustment-assisted handover scheme is capable of achieving the similar system performance to existing power greedy scheme but without increasing energy consumption."
  },
  {
    "year": "2017",
    "abstract": "Community detection is one of the most important problems in social network analysis in the context of the structure of underlying graphs. Many researchers have proposed methods, which only consider the network structure of social networks, for discovering dense regions in social networks. However, increasing media information in networks, such as images, videos, user tags, and comments, are observed with the development and application of Web 2.0. Abundant content information is available to provide a different view for community detection process. In this paper, we propose an overlapping community detection method, namely, latent Dirichlet allocation-based link partition (LBLP), which uses a graphical model and considers network structure and content information. Two feature integration strategies are proposed to combine the influence of network structure and content information on the network generation process. Experimental results on synthetic and real-world networks show that the LBLP method is effective, and content information is beneficial in mining community structure."
  },
  {
    "year": "2017",
    "abstract": "Lightweight cryptography aims to address the security demands in resource-constrained hardware and software environments, such as the Internet of Things (IoT). These constraints severely limit solutions offered by conventional cryptographic primitives, which turn too expensive to achieve. In this paper, a lightweight pseudorandom number generator that fits the IoT demands is presented. It has a good performance on Atmel 8-bit AVR and Intel Curie 32-bit microcontrollers. The analysis of the hardware complexity in terms of gate equivalent confirms that it is suitable for the IoT."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an innovative generalized spatial modulation (GSM) scheme namely grouping GSM (gGSM) to improve the system performance against the high channel correlation in massive MIMO systems. In the proposed scheme, the transmit antennas are divided into several equal-sized groups, and each group conducts spatial modulation (SM) independently. Two grouping methods, i.e., block grouping and interleaved grouping are proposed. In block grouping, the adjacent antennas are gathered in the same group. While in interleaved grouping, the average distance between the antennas in the same group is maximized in order to minimize the impact of channel correlation. In consideration of the practical massive MIMO systems, we conduct the proposed scheme both in a linear antenna array and a 2-dimensional antenna array. To evaluate the performance, we derive a closed-form average bit error probability (ABEP) upper bound for the proposed scheme. According to the ABEP upper bound, we derive the coding gain and diversity order of the proposed scheme to gain insight into the system performance. Numerical results show the performance gain achieved by the proposed scheme compared with the conventional GSM in terms of bit error rate."
  },
  {
    "year": "2017",
    "abstract": "Smartphones are computationally constrained compared with server devices due to their size and limited battery-based power. Compute-intensive tasks are often offloaded from smartphones to high-performance computing opportunities provided by nearby high-end cloud and edge servers. ARM architectures dominate smartphones, while x86 dominate server devices. The difference in architectures requires dynamic binary translation (DBT) of compiled code migration, which increases the task execution time on the cloud servers. Multimedia applications contain a large number of vector instructions (single instruction multiple data) that are compute and resource intensive. Vector instructions optimize application execution by parallel processing multiple data points in a single instruction. However, DBT of vector instructions losses the parallelism and optimization due to vector-scalar translations. We present and analyze a framework for pre-compiled vector instruction translation and offloading in heterogeneous compute architectures that avoids the execution overhead of compiled code offloading. The framework maps and translates ARM vector intrinsics to x86 vector intrinsics such that an application programmed for ARM architecture can be executed on the x86 architecture without any modification. We analyze the code offloading framework with static code analysis to determine the optimal compilers and corresponding compilation parameters. Moreover, we analyze the overhead of the vector instruction translator and application profiler. Furthermore, the comparative analysis based on increasing computational sizes reveals that our framework provides 78.8% energy efficiency as compared with existing code translation and offloading frameworks."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a joint pilot and data power allocation problem with max-min fair energy efficiency (EE) guarantee in the uplink massive multiple-input multiple-output cognitive radio networks is investigated. Given the fractional objective function, channel estimation errors, and inter-user interference, the joint allocation problem is formulated as a nonconvex and NP-hard problem. To tackle this, we transform the original problem into its convex form by introducing auxiliary variables and variable substitution, and then address it with the help of the Lagrangian dual method. Since the optimization variables are interrelated and interact on each other, it is difficult to directly obtain the closed-form solution to this problem. To settle this issue, we propose an alternative iterative algorithm to achieve the optimal power policy by a gradient-based adaption method, with its corresponding optimal Lagrangian multipliers obtained by the subgradient method. Numerical results show that the proposed approach has the best minimum EE performance and decent spectral efficiency performance. Besides, compared with the other schemes, significant saving in total transmit power and good cognitive user fairness are achieved by the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Person re-identification refers to matching people across disjoint camera views. Most existing person re-identification methods use the same feature descriptors and similarity metrics for all pedestrian pairs. However, these methods ignore that image pairs with different visual consistency conditions are sensitive to different features and metrics. In this paper, we propose to optimally organize multiple similarity measures of global pedestrian and body part pairs with respect to different visual consistency measures (VCM). First, we compute multiple similarity measures for global image and body parts. Then, we group the global image and body part set into three classes based on their VCM value, respectively. Finally, the VCM-specific similarity measures of pedestrian as well as body part pairs are selected and optimally organized to form an ensemble by the reliability estimation and adaptively weighting combination. This method is termed as multiple similarity ensemble based on the visual consistency measure (MSE-VCM). Our contributions are 1) the visual consistency measure method which can select the most appropriate similarity measures for image pairs and 2) optimal organization of these VCM-specific features and metrics on global image and body parts. Extensive experiments on three challenging data sets are conducted. Results demonstrate that our method achieves the comparable performance versus the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "A low-power, low-frequency, ad hoc networking paradigm is considered for robust communications among mobile agents in complex non-line-of-sight (NLOS) indoor and urban-type scenarios. Compared with higher frequency, the lower portion of the very high frequency (VHF) band offers improved penetration and reduced multipath in such scenarios. Low VHF is underutilized for mobile ad hoc networking due to the lack of compact low-power systems and efficient miniature antennas. We investigate the proposed approach through experiments in realistic scenarios. In order to carry out the experiments, we leverage a compact, low-power ZigBee radio operating seamlessly in the low-VHF band by introducing a bi-directional frequency converter, which translates ZigBee signals into low-VHF carriers, along with a recently developed highly miniaturized efficient antenna. The experimental low-VHF radio system and a conventional ZigBee operating at 2.4 GHz are both integrated on a compact ground robotic platform for autonomous experimentation and comparison in NLOS indoor and outdoor settings. Measurements quantify the significant advantages of the low-VHF radio system in terms of packet error rate, fading, radio signal strength, and extended spatial coverage, in a number of complex communication environments."
  },
  {
    "year": "2017",
    "abstract": "2-D printed electronics have been the focus of intense research for the past two decades primarily focused on implementing electrical interconnect by dispensing conductive binder-based inks. More recently, traditional printed electronics processes have been leveraged within 3-D printed structures where components and interconnect are introduced during fabrication interruptions. The dielectric performance of 3-D printed materials compares well with traditional printed circuit board (PCB) dielectrics but one remaining challenge is the low conductivity of printed ink traces. The performance degradation is due to curing temperature limits imposed by the properties of the polymer substrates. Thermoplastics, such as ULTEM, can maintain form at over 200 °C, but production ink curing processes require 850 °C to provide an appropriate conductivity. Previous reports have described submerging wires with selective energy within a thermoplastic substrate upon which 3-D printing can continue uninhibited. As copper wires have the same conductivity as PCBs and can be implemented in a wide range of cross-sectional areas, 3-D printed electronics are now in a position to transform the electronics industry. This paper describes an inter-layer process to insert metal connection between layers-allowing for improved routing density and leveraging the geometries brought to bear by 3-D printing. Minimum placement distance between these 3-D printed vias was initially 1.5 mm, and the vias can connect layers separated by as much as 2.8 mm in the vertical build direction (z-axis). As the number of wires layers that can be fabricated is not as limited as traditional board lamination, complex routing can be realized within mass customized, arbitrary shapes."
  },
  {
    "year": "2017",
    "abstract": "Defected ground structure (DGS) with symmetrical geometry has been widely adopted in low-pass filter (LPF) designing, while asymmetrical geometry DGS can exhibit some specific features on transition band and stop-band. A novel asymmetrical Pi-shaped DGS with Koch fractal curve is proposed in this paper to design a low-pass filter (LPF). The designed LPF with a single resonator and two cascaded resonators are both simulated and tested. Simulation and experiment results demonstrate that the designed LPF has a very sharp transition and an ultra-wide stop-band performance compared with the existed similar symmetrical and asymmetrical DGS. The proposed LPF with two cascaded resonators is with a compact size of 36 × 22 mm2, a very low insertion loss of less than 0.7 dB from 0 Hz to 1.9 GHz, and a wide stop-band from 2.1 to 12 GHz with a rejection of greater than 25 dB."
  },
  {
    "year": "2017",
    "abstract": "Adaptive linear equalizer, whose coefficients are designed to be adjustable to the channel impulse response, has emerged as a simple and efficient technique to adaptively compensate for the channel fading. However, conventional adaptive linear equalizers suffer from performance degradation and slow convergence in the underwater acoustic channel with large delay spread. To solve this problem, in this paper, we propose a novel adaptive decision-feedback equalizer (DFE) based on the minimum symbol-error rate (MSER) criterion. Specifically, by taking the sample-by-sample adaptation into account, the problem is first formulated as minimizing the norm between two consecutive adaptations under the constraint that the latest adaptation will provide correct detection for both the current and past symbols. Then we solve the optimization problem by using the Lagrange multiplier method to obtain the adaptive DFE that minimizes the sequential symbol detection error with a fast convergence rate. Simulation results show that the proposed MSER-based adaptive DFE significantly outperforms the existing equalizers in terms of convergence speed and steady-state performance for underwater acoustic channels."
  },
  {
    "year": "2017",
    "abstract": "Airline disruption is universal phenomenon that block the originally scheduled flights, and the slow recovery scheduling causes a lot of losses to both the airline companies and the passengers. However, it is very difficult to generate a new recovery scheduling in a reasonable time by traditional methods, especially for large dimension airline disruption problem. To deal with this problem rapidly, the airline disruption problem will be reformulated as integer programmings and a distributed network, which is based on the fixed-point iterative method for integer programming, will be developed in this paper. In response to the airport closure, an airplane reschedule is constructed by these feasible flight lines. In the implementation of distributed network, a certain number of independent segments are obtained by dividing the solution space. As a feature of this fixed-point method, the number of partial feasible flight lines, which have to be calculated for finding an optimized airplane reschedule, is much fewer compared with the number needed by CPLEX CP Optimizer. This is the first distributed integer programming method to large airline disruption problems caused by airports closure. In the numerical results, the proposed distributed approach shows promising, especially for solving the large dimension airline disruption problem."
  },
  {
    "year": "2017",
    "abstract": "We present a new regularizer for image smoothing which is particularly effective for diminishing insignificant details, while preserving salient edges. The proposed regularizer relates in spirit to total variation which penalizes all the gradients, while our method just penalizes part of the gradients and leaves the significant edges unchanged. Though the proposed regularizer is a piecewise function, which is hard to optimize, we can unify it to a mathematically sound penalty. The unified penalty term is easy to optimize using recent fast solvers and hard thresholding operation. We show some potential applications of the proposed regularizer, including texture removal and compression artifact restoration. The results show the efficiency of the proposed regularizer."
  },
  {
    "year": "2017",
    "abstract": "A simple and effective method to design a dual-band bandpass filter with high isolation and wide stopband is presented and validated using symmetric open-circuited stub-loaded resonators. By adjusting the electric length and the ratio of characteristic admittance of the resonators, the first two resonant frequencies are identical, but the higher order resonant frequencies dispersed in the upper stopband to extent the bandwidth of stopband. Two transmission zeros are introduced to obtain high isolation and selectivity between the two passbands by placing them in the appropriate position. Proper feeding position is selected to further improve the attenuation of stopband. The measured results highly agree with the simulated one. Measured results demonstrate the isolation level of 40 dB, attenuation of larger than 28 dB, and a wide stopband."
  },
  {
    "year": "2017",
    "abstract": "Energy efficiency is a growing concern in every aspect of the technology. Apart from maintaining profitability, energy efficiency means a decrease in the overall environmental effects, which is a serious concern in today's world. Using a femtocell in Internet of Things (IoT) can boost energy efficiency. To illustrate, femtocells can be used in smart homes, which is a subpart of the smart grid, as a communication mechanism in order to manage energy efficiency. Moreover, femtocells can be used in many IoT applications in order to provide communication. However, it is important to evaluate the energy efficiency of femtocells. This paper investigates recent advances and challenges in the energy efficiency of the femtocell in IoT. First, we introduce the idea of femtocells in the context of IoT and their role in IoT applications. Next, we describe prominent performance metrics in order to understand how the energy efficiency is evaluated. Then, we elucidate how energy can be modeled in terms of femtocell and provide some models from the literature. Since femtocells are used in heterogeneous networks to manage energy efficiency, we also express some energy efficiency schemes for deployment. The factors that affect the energy usage of a femtocell base station are discussed and then the power consumption of user equipment under femtocell coverage is mentioned. Finally, we highlight prominent open research issues and challenges."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the distributed orbit synchronization control of spacecraft formation flying under an undirected connected graph and in the presence of unknown external disturbances and communication time-delay. A nonsingular fast terminal sliding mode (NFTSM) control strategy, which can solve the singularity and slow convergence to the equilibrium problems of terminal sliding mode (TSM) control, is developed for spacecraft formation. Considering only desired signals are needed for the basis functions of Chebyshev neural networks (CNN) implemented, a CNN is employed to approximate the nonlinear function and bounded external disturbances. Based on the NFTSM and CNN approximation, a distributed finite-time synchronization control law is designed and its finite-time convergence property is proven in theory. Moreover, in order to guarantee good performance for the spacecraft formation control with communication delay, a distributed finite-time synchronization control scheme with communication delay is also given and the uniform ultimate boundedness of all signals in the closed-loop control system is proven. Finally, a numerical example is illustrated to demonstrate the effectiveness of the proposed control strategies."
  },
  {
    "year": "2017",
    "abstract": "In global mobility networks, a mobile user can access roaming services using a mobile device at anytime and anywhere. However, mobile users can be vulnerable to various attacks by adversaries, because the roaming services are provided through public network. Therefore, an anonymous mobile user authentication for roaming services is an essential security issue in global mobility networks. Recently, Lee et al. pointed out the security weaknesses of a previous scheme and proposed an advanced secure anonymous authentication scheme for roaming services in global mobility networks. However, we found that the scheme proposed by Lee et al. is vulnerable to password guessing and user impersonation attacks, and that it cannot provide perfect forward secrecy and secure password altered phase. In this paper, to overcome the security weaknesses of the scheme proposed by Lee et al., we propose an improved secure anonymous authentication scheme using shared secret keys between home agent and foreign agent. In addition, we analyze the security of our proposed scheme against various attacks and prove that it provides secure mutual authentication using Burrows-Abadi-Needham logic. In addition, the formal security analysis using the broadly-accepted real-or-random (ROR) random oracle model and the formal security verification using the widely accepted automated validation of the Internet security protocols and applications tool show that the proposed scheme provides the session key security and protection against replay as well as man-in-the-middle attacks, respectively. Finally, we compare the performance of the proposed scheme with the related schemes, and the results show that the proposed scheme provides better security and comparable efficiency as compared with those for the existing schemes."
  },
  {
    "year": "2017",
    "abstract": "The performance of evolutionary algorithms (EAs), suitable for optimization on static functional landscapes, usually degrade in presence of noises with different statistical features. In this paper, we present a simple variant of the differential evolution (DE) algorithm, one of the most competitive EAs of recent interest, to tackle complex optimization problems in the presence of additive noise. The proposed DE variant is equipped with three new algorithmic components. A new population central tendency-based mutation scheme is proposed and it is switched in a probabilistic manner with the difference mean-based perturbation strategy in the mutation step. Instead of the regular binomial or exponential crossover of DE, we adopt a blending crossover during the recombination stage. Finally, a novel distance-based selection mechanism is incorporated to enable the occasional inclusion of a few inferior solutions to future generations, thus making the usual DE selection less greedy. Five different additive noise models namely Gaussian, Poisson, Rayleigh, Exponential, and Random are considered with a variety of noise amplitudes to simulate the noisy behavior of the objective functions. In total, 79 benchmark functions from traditional, as well as modern (IEEE CEC 2013 and 2017) test-suites, are used to extensively compare and contrast the proposed method with the other state-of-art evolutionary optimization algorithms, tailor-made for noisy function optimization. Experimental results, supported with the non-parametric statistical tests, indicate that our proposed method is very competitive against the noise-resilient variants of classical as well as very recent evolutionary optimizers, including the winners of the recent IEEE CEC competitions of real parameter optimization on the complex fitness landscapes."
  },
  {
    "year": "2017",
    "abstract": "Various approaches and perspectives have been presented in safety analysis during the last decade, but when some continuous outcome variables take on values within a bounded interval, the conventional statistical methods may be inadequate, and frequency distributions of bounded outcomes cannot be used to handle it appropriately. Therefore, in this paper, a logistic quantile regression (QR) model is provided to fill this gap and deal with continuous bounded outcomes with crash rate prediction. The crash data set from 2003 to 2005 maintained by the Nevada Department of Transportation is employed to illustrate the performance of the proposed model. The results show that average travel speed, signal spacing, driveway density, and annual average daily traffic on each lane are significantly influencing factors on crash rate, and logistic QR is verified as an alternative method in predicting crash rate."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a broadband receiver architecture with series and parallel channelization. The proposed architecture decomposes the broadband incident spectrum into multiple channels, and achieves fast switching time, while using the single synthesizer with a fixed local oscillator (LO) frequency. Channelized receiver is a good candidate for critical RF processing tasks, such as data conversion, broadband radio, and spectrum analysis. The key feature of the proposed channelized receiver is the decomposition of the broadband frequency spectrum through parallel band partition and series channel selection. Relevant design challenges of the channelization receiver are discussed. In addition, the radio impairments determining the key performance of the radio are analyzed. The prototype receiver front-end was designed and implemented in 45 nm CMOS technology to demonstrate the effectiveness of the proposed architecture. The receiver front-end prototype splits an input spectrum of dc-40 GHz into four sub-bands with 10 GHz IF bandwidth and dissipates the average power of 33 mA and 60 mA from RF and LO blocks, respectively, while achieving <;5 dB NF and <;-145 dBc/Hz phase noise."
  },
  {
    "year": "2017",
    "abstract": "One of the classic approaches to controlling power networks, as large-scale systems, has been the use of a centralized control architecture. This approach is currently used less frequently due to its computational complexity. Another possible approach is the use of a decentralized control architecture. However, this approach can lead to unacceptable global performance of the system due to the lack of knowledge about the available interactions among subsystems. A third approach is the application of a cooperatively distributed architecture. On the other hand, one technique that has proved to be quite efficient for the control of power system frequency is model predictive control (MPC). In this paper, the performance of cooperatively distributed MPC is compared with that of the centralized MPC and the classical automatic generation control methods. The main contribution of this paper is that the load variations are applied to the system in the form of consecutive pulses. Additionally, the disturbance levels considered here have higher values. Moreover, the range of control input variations is reduced; therefore, the constraints are chosen more strictly. Finally, the total error of the system is determined, and the discussed methods are evaluated by the newly defined indices. According to simulation results, a feasible cooperation-based MPC method leads to relatively desired performance and computational speed and so can be an appropriate practical option for controlling power systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel topology of a balanced diplexer is proposed. It is composed of a dualmode structure and two sets of resonators at distinct frequencies. The dual-mode structure has two resonances serving for two three-pole passbands, respectively, in differential mode (DM) and an intrinsic suppression for full stopband in common mode (CM). Thus, it is perfectly suited to design a filtering network in DM, and conserve suppression in CM. In order to obtain two close DM channels and good CM suppression in the meantime, two inner resonators are coupled together via a specific coupling scheme with intrinsic CM suppression to construct it. Two balanced diplexers utilizing the proposed dual-mode structures with varied configurations are proposed, designed, and fabricated, which have well verified the proposed diplexer topology and a design method."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the tracking-control problem of nonlinear strict-feedback system by utilizing neural networks. Combining a novel recurrent neural network and gradient-based neural network, we investigate, develop and design a new controller based on the synthesized neural network model (N–G model) to track the output trajectory performance of the nonlinear strict-feedback system. This presented control scheme could have a good output tracking performance for the nonlinear strict-feedback system. For comparing with the presented N-G model, the classic backstepping design method is also employed to design the control input for the nonlinear strict-feedback control system in this paper. The computer simulation results demonstrate that the controller based on the N–G model could be used to tackle the tracking-control problem with accuracy and effectiveness, together with the faster convergent speed than that based on the backstepping algorithm. Generally speaking, with the appropriate increase of design parameters, the controller based on the N–G model could improve convergence performance for nonlinear strict-feedback system."
  },
  {
    "year": "2017",
    "abstract": "Natural image matting is an important image processing task. How to leverage the advantages of both sampling matting and propagation matting is a challenge issue. In this paper, we propose a novel sampling-propagation matting method. First, in an overall framework, we propose a three-stage method for sampling-propagation matting, in which the sampling matting stage and propagation matting stage are bridged by a new stage (stage 2). Second, in the sampling matting stage (stage 1), a new gradient sampling matting is presented to cover more diversified samples, and a new equation is proposed to calculate the impact of sample-pair overlap. Third, in bridge stage (stage 2), we propose a judgment criterion to distinguish each pixel of matte after stage 1. For pixels that fail to meet the criterion, we propose an automatic labeling method. Fourth, in the propagation stage (stage 3), we discriminatingly process non-labeled pixels and labeled pixels with separate weight coefficients. The non-labeled pixels are smoothed by propagation, and the labeled pixels are solved by propagation matting. Finally, the proposed method is compared with other methods on public available benchmark. The results show that our method outperforms many other methods and achieves a good ranking."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the power allocation in millimeter-wave multiple-input multiple-output systems. The asymptotic concavity of the sum rate of the system is utilized to form the proposed power allocation approach. In contrast to the traditional approaches, the proposed approach utilizes a channel asymptotic orthogonality-based approximation which is more suitable, thus achieves higher spectral efficiency. The analysis demonstrates that the sum rate of the system increases as the number of antennas increases. Numerical results verify the analysis and show that the proposed approach can perform better than those traditional approaches."
  },
  {
    "year": "2017",
    "abstract": "In this paper, through an exact analysis of the outage probability, we investigate the impact of co-channel interference (CCI) on the outage performance of type II (or user equipment) relay under multiple-relay environments considering the selection combining-based relay selection scheme with the decode-and-forward protocol. We consider the signal to interference plus noise ratio (SINR) over both independent and identically distributed and independent but non-identically distributed fading channels. To fully take into account the effect of CCI, we adopt a more practical parameter such as the CCI coefficient. The major difficulty in the analysis resides in the determination of the statistics of the output SINR. To settle this problem, we first present the general but relatively simplified expressions for the statistics and then the related outage probability in closed-form. Furthermore, to consider more practical scenario, based on the fact that the number of participating relays can be random, we investigate the average outage probability by averaging the number of participating relays."
  },
  {
    "year": "2017",
    "abstract": "For grinding processes, optimal-setting control (OSC) is becoming a hot topic. However, there is no configurable platform to assist researchers and engineers to design such a controller. This paper proposes a novel software platform named OSC to address this problem. The major superiority is that the platform not only provides a configurable environment by developing a powerful controller design tool and a Petri net model to schedule algorithm modules for parallel computation but also integrates several mainstream intelligent and data-driven algorithms (e.g., case based reasoning, fuzzy logic, and neural network) within a unified framework. The overall framework and key technologies are introduced in detail. Using a hardware-in-the-loop experiment system, the platform is verified and validated through a case of application where an intelligent optimal-setting controller is developed for a classical grinding process."
  },
  {
    "year": "2017",
    "abstract": "We first review the fundamentals of directional modulation (DM) based on frequency diverse arrays (FDA), which is capable of achieving angle-range dependent point-to-point physical layer secure communications where the phase shifters of the FDA-based DM must be optimized continuously with time by complex algorithms like genetic algorithm (GA). Thereafter, in order to overcome the time-variant drawbacks of conventional FDA-based DM, we propose a time-invariant angle-range dependent DM based on time-modulated logarithmically increasing frequency offset FDA (TDM-log-FDA). Different from the conventional FDA-based DM, where the frequency offsets are linear and determinate, the frequency offsets of TDM-log-FDA are elaborately designed as time-modulated nonlinear logarithmically increasing values guaranteeing the time-invariant characteristic of TDM-log-FDA. Additionally, an improved dot-shaped time-invariant DM based on time-modulated multicarrier frequency offset FDA (DTDM-mc-FDA) is put forward to achieve time-invariant spatial fine focusing point-to-point physical layer secure communications, where multiple carriers instead of a single carrier are transmitted through each antenna element and the corresponding frequency offsets are also time-modulated. Using GA, we obtain the optimized phase shifters for the proposed two time-invariant DMs once and for all, which reduces the realization complexity of phase shifters greatly. Besides, a new metric called secure area is proposed to evaluate the security performance of DM systems. The simulated results demonstrate that the proposed TDM-log-FDA can realize time-invariant angle-range dependent secure communications, while the proposed DTDM-mc-FDA can further enhance the security with more accurately focusing secure area despite a small penalty of complexity."
  },
  {
    "year": "2017",
    "abstract": "After many years of rigid conventional procedures of production, industrial manufacturing is going through a process of change toward flexible and intelligent manufacturing, the so-called Industry 4.0. In this paper, human-robot collaboration has an important role in smart factories since it contributes to the achievement of higher productivity and greater efficiency. However, this evolution means breaking with the established safety procedures as the separation of workspaces between robot and human is removed. These changes are reflected in safety standards related to industrial robotics since the last decade, and have led to the development of a wide field of research focusing on the prevention of human-robot impacts and/or the minimization of related risks or their consequences. This paper presents a review of the main safety systems that have been proposed and applied in industrial robotic environments that contribute to the achievement of safe collaborative human-robot work. Additionally, a review is provided of the current regulations along with new concepts that have been introduced in them. The discussion presented in this paper includes multidisciplinary approaches, such as techniques for estimation and the evaluation of injuries in human-robot collisions, mechanical and software devices designed to minimize the consequences of human-robot impact, impact detection systems, and strategies to prevent collisions or minimize their consequences when they occur."
  },
  {
    "year": "2017",
    "abstract": "Energy harvesting (EH) from renewable energy sources is more environmental friendly and convenient than the conventional energy supplies. This paper considers a point-to-point channel with the transmitter powered by random energy harvester, for which the energy arrival process is stochastic, and the save-then-transmit scheme is adopted due to the battery half-duplex constraint: The transmitter first harvests energy for a certain time, and then stops EH to transmit information with all the accumulated energy at the battery. Obviously, it is crucial to determine a proper stopping time for EH, since larger EH duration provides more accumulated energy, while it may decrease the average throughput. In this paper, our goal is to compute the optimal stopping time to maximize the average throughput of the considered EH systems. First, considering the Gaussian channel scenario, this paper proves the existence of the optimal stopping rule and shows that this rule has a state-dependent\"threshold-based\" structure under the Markov energy arrival case. Then, for a special independent and identically distributed energy arrival case, this paper further proves that the corresponding stopping threshold is a constant, and can be efficiently computed by a proposed algorithm. Finally, this paper generalizes the above results to the fading channel scenario and obtains the corresponding optimal stopping rule, which can be computed by a recursive algorithm."
  },
  {
    "year": "2017",
    "abstract": "Translating linear temporal logic (LTL) formulas into Büchi automata is one of the most important aspects of LTL model checking. Certain successful algorithms, such as LTL2BA and SPOT, first translate an LTL formula into a transition-based generalized Büchi automaton (TGBA) and then degeneralize it into a Büchi automaton. This paper focuses on achieving a better translation from LTL to TGBA and analyzing the performance of every step of the algorithm. We decompose the translation into three steps to give a step-wise description and improve all three steps. The first step is the basic translation without acceptance conditions and simplifications, which combines the advantages of both LTL2BA and SPOT. Second, we introduce a new definition of acceptance conditions. Our proofs and experiments have shown that our technique is more efficient and improves the degeneralization ability. Finally, we introduce the simplifications of our algorithm. We focus on not only producing better final Büchi automata but also minimizing intermediate automata, which can reduce the execution time."
  },
  {
    "year": "2017",
    "abstract": "Diagnosability is a key factor in the analysis of reliability for a network system. t/s-diagnosability is a novel measurement for evaluating the reliability of a system. In this paper, we derive some properties, which have not been reported by previous literatures, for a star network. By using these properties, we prove that an n-dimensional star graph (denoted by Sn) is [ln - (((l + 2)2)/3)]/([ln - (((l + 2)2)/3)] + l - 2)-diagnosable, where (n ≥ 5), 2 ≤ l ≤ n - 2. Furthermore, we prove that given an integer n(n ) 5), and another integer l(2 ≤ l ≤ n - 2), for some positive integer β ∈ ([(l - 1)n - (((l + 1)2)/3)], [ln - (((l + 2)2)/3)]], Snis β/(β + l - 2)-diagnosable. In the last part of this paper, we propose an isolation-fast algorithm for Sn(n ≥ 5), and its time complexity is only O(N log2N), where N = n!."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an efficient and deterministic quantum key distribution protocol for establishing a secret key between two untrusted users. In this protocol, a secret key is distributed to a sender and a receiver who share entangled states with a third trusted party but not with each other. This secret key is distributed by the means of special pure quantum states using remote state preparation and controlled gates. In addition, we employ the parity bits of the entangled pairs and the ancillary states to assist in preparing and measuring the secret states. Distributing a state to two users requires two maximally entangled pairs as the quantum channel and a two-particle von Neumann projective measurement. The proposed protocol is exact and deterministic. It distributes a secret key of d qubits by the means of 2d entangled pairs and, on average, d bits of classical communication. We demonstrate the security of this protocol against entanglement attacks and present a method of privacy amplification."
  },
  {
    "year": "2017",
    "abstract": "This paper discusses object proposal generation, which is a crucial step of instance-level semantic segmentation (instance segmentation). Known as a challenging computer vision task, the instance segmentation requires jointly detecting and segmenting individual instances of objects in an image. A common approach to this task is first to propose a set of class-agnostic object candidates in the forms of segmentation masks, which represent both object locations and boundaries, and then to perform classification on each object candidate. In this paper, we propose an effective refinement process that employs image transformations and mask matching to increase the accuracy of object segmentation masks. The proposed refinement process is applied to three state-of-the-art object proposal methods (DeepMask, SharpMask, and FastMask), and is evaluated on two standard benchmarks (Microsoft COCO and PASCAL VOC). Both the quantitative and qualitative results show the effectiveness of the process across various experimental settings."
  },
  {
    "year": "2017",
    "abstract": "A novel pattern-reconfigurable cylindrical dielectric resonator antenna is presented. By the incorporation of four p-i-n diode switches and four parasitic elements, the mode of dielectric resonator excited by the probe changed. The antenna's radiation patterns can be shaped to concentrate energy in four specific directions, while minimizing the gain in other unwanted directions without affecting the impedance bandwidth of the antenna for its complete symmetry in structure. The antenna switches its radiation patterns among four reconfigurable modes with orthogonal directions at azimuth plane covering a bandwidth of several 870 MHz and exhibiting a high maximum gain of 9.74 dBi. A fully functional prototype has been designed, fabricated, and tested. The measured results of the reflection coefficient, radiation patterns, and realized gain verify the effectiveness of the proposed pattern switching concept for cylindrical dielectric resonator antenna. These capabilities make the antenna suitable for smart wireless devices in next generation communication systems as it can enhance the radio frequency front-end flexibility and performance by adding pattern diversity, especially for muti-input-muti-output systems in multipath environments."
  },
  {
    "year": "2017",
    "abstract": "Compositional analysis aims to reveal the underlying structures of a large-scale system or network by analyzing its constituent components and their relationships. Today’s mathematical modeling languages, such as Petri nets, are useful for describing distributed systems and complex networks. However, the flat model architecture of Petri nets makes it difficult for them to depict the compositional structures of a large-scale model. Therefore, an enhanced compositionality feature has become a significant demand in large-scale modeling with Petri nets. This paper explores the underlying compositional structures of a given Petri net model by using a proposed sorting algorithm. The algorithm analyses compositional structures by sorting an incidence matrix that is generated from the Petri net model. Finally, the proposed sorting algorithm is applied to a traffic network model that was built with Petri nets to analyze its compositional structures, which represent different traffic lines, with the aim of optimizing the traffic network."
  },
  {
    "year": "2017",
    "abstract": "The outstanding pattern recognition performance of deep learning brings new vitality to the synthetic aperture radar (SAR) automatic target recognition (ATR). However, there is a limitation in current deep learning based ATR solution that each learning process only handles one SAR image, namely learning the static scattering information, while missing the space-varying information. It is obvious that space-varying scattering information introduced in the multi-aspect joint recognition should improve the classification accuracy and robustness. In this paper, a novel multi-aspect-aware method is proposed to achieve this idea through the bidirectional long short-term memory (LSTM) recurrent neural networksbased space-varying scattering information learning. Specifically, we first select different aspect images to generate the multi-aspect space-varying image sequences. Then, the Gabor filter and three-patch local binary pattern are progressively implemented to extract comprehensive spatial features, followed by dimensionality reduction with the multi-layer perceptron network. Finally, we design a bidirectional LSTM recurrent neural network to learn the multi-aspect features with further integrating the softmax classifier to achieve target recognition. Experimental results demonstrate that the proposed method can achieve 99.9% accuracy for 10-class recognition. Besides, its anti-noise and anti-confusion performances are also better than the conventional deep learning-based methods."
  },
  {
    "year": "2017",
    "abstract": "Multicarrier faster-than-Nyquist (MFTN) signaling is a spectral efficient transmission scheme for future communication systems. Similar as general multicarrier signals, the high peak-to-average power ratio (PAPR) is also one of the main drawbacks of MFTN signals. Unfortunately, the PAPR problem in MFTN signaling system has rarely been considered in the literatures. In this paper, we investigate the PAPR reduction for MFTN signals. First, we derive an inverse fast Fourier transform (IFFT)-based implementation of the MFTN transmitter. Based on which, a novel partial transmit sequence (PTS) scheme is proposed for the PAPR reduction of MFTN signals. The proposed PTS scheme relies on a two-stage optimization of the phase weighting factors for the parallel IFFT blocks as well as the phase weighting factors for the information symbols before the summation operation. It is shown that the proposed scheme substantially outperforms the direct employment of conventional Nyquist multicarrier transmission systems-based PTS scheme and also robust to the overlap-add operation introduced by pulse shaping."
  },
  {
    "year": "2017",
    "abstract": "Mobile personal devices, such as smartphones, USB thumb drives, and sensors, are becoming essential elements of our modern lives. Their large-scale pervasive deployment within the population has already attracted many malware authors, cybercriminals, and even governments. Since the first demonstration of mobile malware by Marcos Velasco, millions of these have been developed with very sophisticated capabilities. They infiltrate highly secure networks using air-gap jumping capability (e.g., “Hammer Drill”and “Brutal Kangaroo”) and spread through heterogeneous computing and communication platforms. Some of these cross-platform malware attacks are capable of infiltrating isolated control systems which might be running a variety of operating systems, such as Windows, Mac OS X, Solaris, and Linux. This paper investigates cross-platform/heterogeneous mobile malware that uses removable media, such as USB connection, to spread between incompatible computing platforms and operating systems. Deep analysis and modeling of cross-platform mobile malware are conducted at the micro (infection) and macro (spread) levels. The micro-level analysis aims to understand the cross-platform malware states and transitions between these states during node-to-node infection. The micro-level analysis helps derive the parameters essential for macro-level analysis, which are also crucial for the elaboration of suitable detection and prevention solutions. The macro-level analysis aims to identify the most important factors affecting cross-platform mobile malware spread within a digitized population. Through simulation, we show that identifying these factors helps to mitigate any outbreaks."
  },
  {
    "year": "2017",
    "abstract": "Information-centric networking (ICN) is a promising solution for most of Internet applications where the content represents the core of the application. However, the proposed solutions for the ICN architecture are associated with many complexities including pervasive caching in the Internet and incompatibility with legacy IP networks, so the deployment of ICN in real networks is still an open problem. In this paper, we propose a backward-compatible ICN architecture to address the caching issue in particular. The key idea is implementing edge caching in ICN, using a coalition of end clients and edge servers. Our solution can be deployed in IP networks with HTTP requests. We performed a trace-driven simulation for analyzing peer-assisted information-centric networking (PICN) benefits using IRCache and Berkeley trace files. The results show that on average, PICN decreases the latency for 78% and increases the content retrieval speed for 69% compared with a direct download from the original Web servers. When comparing PICN with a solution based on central proxy servers, we show that the hit ratio obtained using a small cache size in each PICN client is almost 14% higher than the hit ratio obtained with a central proxy server using an unlimited cache storage."
  },
  {
    "year": "2017",
    "abstract": "Predictable message transmission is the primary requirement in networked safety critical embedded systems design. In these systems, delay jitter has been proven to be a critical factor that must be considered. For periodic messages, minimizing the delay jitter means messages should be transmitted at the expected time in every period. In this paper, we investigate the scheduling problem to reduce the delay jitter for periodic messages in networked safety critical embedded systems. Our approach is empirically assigning an expected completion time as a baseline for the periodic messages and minimizing the total deviation to them. It can be applied either in centralized control buses or in synchronized ones. This paper selects a novel bus protocol and UM-BUS, to evaluate the effectiveness of the proposed algorithm. UM-BUS is a multi-master bus with the capability of multi-lane concurrent transmission. Aiming at different operation mode of UM-BUS, we implemented two sets of experiments by configuring different parameters to change the bus utilization. The results show that the heuristic algorithm works effectively and can achieve a deviation within 0.35%, which is significantly smaller comparing with the existing scheduling algorithms."
  },
  {
    "year": "2017",
    "abstract": "Big-data is a challenging domain for high-throughput digital signal processing (DSP), especially in global-projects like the square kilometer array. The composite input data rate for correlator in this system is more than 11 Tb/s, which immensely increases the memory requirement, complexity of correlation implementation and the overall power dissipation. This paper is focused on computational minimization as well as the improvement of energy efficiency in the complex architectural X-part of an FX correlator employed in large array radio telescopes. A dedicated correlator-multiplier block termed, correlator-system-multiplier-and-accumulator (CoSMAC) cell architecture is proposed, which produces two 16-b integer complex multiplications within the same clock period. The novel hardware optimization is achieved by utilizing the flipped mirror relationship (conjugate complex symmetry) between discrete Fourier transform (DFT) samples owing to the symmetry and periodicity of the DFT coefficient vectors (twiddle factors). In addition, using the proposed CoSMAC architecture a new processing element (PE) is designed to calculate both the cross- and auto-correlation functions within the same clock period. This paper describes how the arithmetic processing of three baseline calculations will be minimized in the X-part using the proposed novel algorithm and hardware design (CoSMAC and PE). In addition to optimizing the core processing elements, it is possible to eliminate nearly 50% of the usual memory requirement. The design has been synthesized using global foundries 28-nm HPP CMOS standard cells."
  },
  {
    "year": "2017",
    "abstract": "In networked control system, such as WirelessHART that is characterized by stochastic delay, the use of proportional integral and differential (PID) controllers is inadequate. This is because PID performs poorly in handling time-delay processes. The main reason for this poor performance is the limitation in the range of stable gain of the controller. Time delay causes oscillatory response of the PID with large gain. Likewise, sluggish response is experienced with small gain of the PID. Also, dead time compensators like smith predictor and internal model controller are difficult to be implemented practically since they require exact model of the process to be controlled. Therefore, this paper proposes the application of setpoint weighting strategy to be used alongside PID controller in a WirelessHART network. This method extends significantly the range of the PID gain, while providing good set point tracking and load regulation. From the simulation and experimental results obtained, the capability of the approach to load regulation and tracking can be seen in its fast recovery from effect of disturbance with minimal overshoot. Thus, a two degree of freedom control is achieved. Results also showed that the method is robust to real-time random variable network delay and model mismatches."
  },
  {
    "year": "2017",
    "abstract": "In automatic map compilation, both the scale reduction and the geometric transformation of map features may give rise to spatial conflicts. Several generalization approaches have been established to resolve this problem, mainly for the displacement operator. This paper proposes one such approach that is based on the snake model and multiple agents. It focuses on the resolution of various spatial conflicts that emerge when generalizing the rural areas of medium density. In this approach, the map features are converted into map agent, object agent, group agent, and conflicting agent, and the spatial relationships between these features are managed by an auxiliary relationship agent. Each agent is assigned with tasks accordingly, and all agents collaborate with each other to complete the generalization. The snake-based algorithm is applied in the conflicting agent when it identifies a certain configuration. The experimental results indicate that the approach proposed in this paper can obtain good results."
  },
  {
    "year": "2017",
    "abstract": "Due to the tremendous growth in mobile data traffic, cellular networks are witnessing architectural evolutions. Future cellular networks are expected to be extremely dense and complex systems, supporting a high variety of end devices (e.g., smartphone, sensors, machines) with very diverse QoS requirements. Such an amount of network and end-user devices will consume a high percentage of electricity from the power grid to operate, thus increasing the carbon footprint and the operational expenditures of mobile operators. Therefore, environmental and economical sustainability have been included in the roadmap toward a proper design of the next-generation cellular system. This paper focuses on softwarization paradigm, energy harvesting technologies, and optimization tools as enablers of future cellular networks for achieving diverse system requirements, including energy saving. This paper surveys the state-of-the-art literature embedding softwarization paradigm in densely deployed radio access network (RAN). In addition, the need for energy harvesting technologies in a densified RAN is provided with the review of the state-of-the-art proposals on the interaction between softwarization and energy harvesting technology. Moreover, the role of optimization tools, such as machine learning, in future RAN with densification paradigm is stated. We have classified the available literature that balances these three pillars, namely, softwarization, energy harvesting, and optimization with densification, being a common RAN deployment trend. Open issues that require further research efforts are also included."
  },
  {
    "year": "2017",
    "abstract": "With the development of 3-D applications, such as 3-D reconstruction and object recognition, accurate and high-quality depth map is urgently required. Recently, depth cameras have been affordable and widely used in daily life. However, the captured depth map always owns low resolution and poor quality, which limits its practical application. This paper proposes a color-guided depth map super resolution method using convolutional neural network. First, a dual-stream convolutional neural network, which integrates the color and depth information simultaneously, is proposed for depth map super resolution. Then, the optimized edge map generated by the high resolution color image and low resolution depth map is used as additional information to refine the object boundary in the depth map. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "In the era of big data, reduced models capable of reducing big data graph to estimate personalized PageRank are limited. Personalized PageRank is a page rank calculation where random jumps are only allowed to a subset of start nodes. The resources of current process of calculation of personalized PageRank are highly prohibitive, thus in this paper we propose a novel fast accurate and less resource intensive algorithm to the personalized PageRank problem. FAST Personalized PageRank is utilized to find the target node set. Using the mentioned target set, the algorithm gives an estimation of the closeness of any pair of nodes in the graph. As the time taken by the estimation of personalized PageRank is directly proportional to the network size, in this paper a node reduction method is used to prune the graph. In this pruning model, most popular nodes also known as hubs are found using personalized page vector. To decrease the entropy and reduce the number of alternate paths to the target nodes, popular nodes are identified and flagged. The flagged nodes are, then, given a lower priority in the computation. This way the redundant path will being ignored in the computation process. After pruning the graph, estimation results achieve an improved time complexity. In our experiment, we compare our result with the benchmark FAST personalized PageRank approach. Our algorithm significantly reduces the computation time and outperforms the benchmark FAST personalized PageRank algorithm in highly dense graphs."
  },
  {
    "year": "2017",
    "abstract": "We propose a flow table management scheme for OpenFlow switches to minimize table-miss in a flow table. Commercial OpenFlow switches have one or more flow tables that consist of flow entries for processing packets. However, flow entries are managed based only on their timeout parameters, meaning they are expired and deleted by switches regardless of their reusability. The absence of the flow entry then causes table-misses in the future. We propose a solution for the problem of switches disregarding vacancies in the flow table when deleting expired flow entries. When a table-miss occurs, the corresponding switch must perform additional interactions with an OpenFlow controller to insert new flow entries, but this results in additional processing time and communication overhead. Previous studies aimed at solving this limitation have used sophisticated training sets or modified network architectures. In contrast, we propose a simple flow table management scheme with a least recently used-based caching algorithm to keep flow entries in an OpenFlow switch as long as possible. For this purpose, the switch continually adjusts its cache size according to the vacancy of each flow table and the controller determines the packet forwarding path through the switches by referring to the vacancies. We perform an experimental evaluation of the proposed scheme and demonstrate the performance gains in terms of the number of table-missed packets. We also analyze the effectiveness of the flow entry caching scheme using a mathematical model."
  },
  {
    "year": "2017",
    "abstract": "Recent studies have proven the potential of orthogonal frequency division multiplexing with index modulation in improving the bit error rate performance and the spectral efficiency, where its performance is evaluated under the assumption of ideal conditions. In this paper, the implementation of this novel transmission technique under realistic circumstances is thoroughly investigated. For this purpose, a new generalized system model that incorporates both imperfect channel state information and hardware impairments is employed and analytical pairwise error probability over correlated Rayleigh and Ricean fading channel is developed. The derived expression is then adapted to determine a tight upper bound of the average bit error probability. Furthermore, asymptotic expression analysis at high signal-to-noise ratio is included. Finally, simulation results are provided to illustrate the accuracy of the proposed theoretical analysis."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate link adaptation for an orthogonal frequency division multiplexing (OFDM)-based multiple-input multiple-output (MIMO) visible light communication (VLC) system. The proposed adaptive OFDM VLC system supports both repetition coding (RC) and spatial multiplexing (SM) as MIMO modes and allows spatial mode switching based on channel conditions. Regarding to the instantaneous signal-to-noise ratio for both RC and SM modes, the maximum constellation size that can be supported for each MIMO mode on each subcarrier is determined. The MIMO mode that gives the highest spectral efficiency (SE) is then selected. The proposed joint MIMO mode selection and bit loading scheme maximizes the SE while satisfying a target bit error rate. Our numerical results reveal that a peak data rate up to 18.3 Gb/sec can be achieved in a 16 × 16 MIMO setting using light emitting diodes with cut-off frequency of 10 MHz in typical indoor environments."
  },
  {
    "year": "2017",
    "abstract": "Finding the best signal constellation for different communication channels is one of the fundamental problems in digital communication. This problem has been studied widely from different angles and many methods have been proposed for designing good practical signal constellations. There has been a rejuvenated interest in designing good constellations during last decade, in part due to the advent of novel optimization techniques. Nevertheless, most of the recent work, similar to the older work in this area, aims to optimize the constellation within a presumed structure (such as points lying on concentric rings). In this paper, we develop a different approach: we aim to optimize constellations based on a Chernoff bound on the probability of error in the versatile Nakagami-m fading channel. We derive two general bounds on the symbol error rate and bit error rate performance of orthogonal transmission in a Nakagami-m fading channel for single-input single-output and orthogonal space-time block codes and we show that a substantial improvement in the error probability is achieved with the novel constellations that are optimized using these bounds."
  },
  {
    "year": "2017",
    "abstract": "Context-based method for classification has been successfully applied in image. However, most of these classifiers work in stages. This paper presents a novel discriminative model named context-based max-margin to perform the task of classification for polarimetric synthetic aperture radar (PolSAR) images. Based on the max-margin frame, support vector machine (SVM), and conditional random fields (CRF) are used to describe the spectral and spatial information of polarimetric synthetic aperture radar (PolSAR) image, respectively. First, the probabilistic result which is obtained from SVM can be applied as the spectral term of the discriminative classifier. Second, CRF is used to describe the spatial information of PolSAR image. The contextual information of both label and observation field are built as the spatial term, by which the smoother region is obtained and the spatial information is preserved. Finally, a discriminative classifier can be learned by means of integrating the spectral and spatial terms. Compared with other state-of-the-art classification methods, our method exhibits higher accuracy, which indicating the effectiveness of our scheme. Here, the total classification accuracy of the proposed model increases by about 10% and 3% compared with the other methods for two data sets."
  },
  {
    "year": "2017",
    "abstract": "Interaction testing can be used to effectively detect faults that are otherwise difficult to find by other testing techniques. However, in practice, the input configurations of software systems are subjected to constraints, especially in the case of highly configurable systems. Handling constraints effectively and efficiently in combinatorial interaction testing is a challenging problem. Nevertheless, researchers have attacked this challenge through different techniques, and much progress has been achieved in the past decade. Thus, it is useful to reflect on the current achievements and shortcomings and to identify potential areas of improvements. This paper presents the first comprehensive and systematic literature study to structure and categorize the research contributions for constrained interaction testing. Following the guidelines of conducting a literature study, the relevant data are extracted from a set of 103 research papers belonging to constrained interaction testing. The topics addressed in constrained interaction testing research are classified into four categories of constraint test generation, application, generation and application, and model validation studies. The papers within each of these categories are extensively reviewed. Apart from answering several other research questions, this paper also discusses the applications of constrained interaction testing in several domains, such as software product lines, fault detection and characterization, test selection, security, and graphical user interface testing. This paper ends with a discussion of limitations, challenges, and future work in the area."
  },
  {
    "year": "2017",
    "abstract": "The backscatter of X-band marine radar is contaminated by rain, which limits the estimation of wave parameters from radar images. A new method is proposed to correct the influence of rain on the gray level radar image, based on 1-D complex continuous wavelet transform. First, a suitable scale parameter is derived from the modulus of Gaussian wavelet coefficient, and then the wave crests are detected from the phase of the wavelet coefficient. Second, the gray levels of wave troughs are set to be a minimal constant, and the other gray levels are linearly interpolated for each radial. The method is validated by comparing the significant wave heights measured by buoy with those retrieved from X-band marine radar image sequences, the correlation coefficient and the root-mean-square error between them are 0.85 and 0.42 m with the correction of rain, which increases 0.34 and reduces 0.34 m compared with those estimated without the correction, respectively. The recognition of rain from gray level radar image and the limitations of the method are discussed."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a new spatial data resource for Internet geography. The idea is based on merging two up-to-now unrelated fields-the real estate market and Internet networking. The huge real estate market is present almost everywhere, and therefore, it is a valuable resource for trusted spatial data when connected to cyber space. We describe a method that gains spatial data from the real estate market and links this data to cyber space. We support the method by a real implementation. Based on the collected data, we identified the geographical scope of a set of Web servers. The new data in cyber geography may help in the Internet Web-related market competition."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we deal with the intersymbol interference (ISI) cancellation problem induced by the faster-than-Nyquist (FTN) signaling. In the traditional FTN signaling, the detection delay at the receiver depends on the number of states of the ISI trellis. In this case, the corresponding Viterbi algorithm or the BCJR algorithm would be far too complex and introduce a huge delay when the ISI tap set is large. In this paper, we propose a novel interference cancellation scheme to combat the ISI for the FTN communication system which enables the parallel computations. Our proposed scheme adopts a pre-coding at the transmitter and a decomposition detection at the receiver. Particularly, with the help of the parallel computations, the running time of our proposed scheme is independent of the ISI trellis, which allows the application of a more severe FTN system with a smaller time acceleration factor. Besides, based on the pre-coding scheme and the decomposition detection, an adaptive transmission strategy is developed, which can improve the performance of the proposed scheme dramatically. Finally, we compare our scheme with the offset BCJR algorithm and the offset Viterbi algorithm benchmarks. The simulation results verify that our scheme can outperform previous decoders with a better bit error rate and a much less delay."
  },
  {
    "year": "2017",
    "abstract": "This survey paper discusses the feasibility of sharing the spectrum between satellite telecommunication networks and terrestrial and other satellite networks on the basis of a comprehensive study carried out as part of the European Space Agency's Advanced Research in Telecommunications Systems programme. The main area of investigation is the use of spectrum databases to enable a controlled sharing environment. Future satellite systems can largely benefit from the ability to access spectrum bands other than the dedicated licensed spectrum band. Potential spectrum sharing scenarios are classified as: a) secondary use of the satellite spectrum by terrestrial systems, b) satellite system as a secondary user of spectrum c) extension of a terrestrial network by using the satellite network; and d) two satellite systems sharing the same spectrum. We define practical use cases for each scenario and identify suitable techniques. The proposed scenarios and use cases cover several frequency bands and satellite orbits. Out of all the scenarios reviewed, owing to the announcement of many different mega-constellation satellite networks, we focus on analyzing the feasibility of spectrum sharing between geostationary orbit (GSO) and non-geostationary orbit (NGSO) satellite systems. The performance is primarily analyzed on the basis of widely accepted recommendations of the Radiocommunications Sector of the International Telecommunications Union. Finally, future research directions are identified."
  },
  {
    "year": "2017",
    "abstract": "An outsourcing re-encryption program can help a ciphertext owner (delegator) transform his/her ciphertext into another ciphertext of delegatee. For example, an e-mail receiver can re-transfer an encrypted e-mail to his secretary while allowing the e-mail to be readable for her. For a multi-hop re-encryption, the delegatee can re-encrypt the ciphertext to another user in delegation chain, repeatedly. Traditionally, this transformation is usually conducted by a proxy or an outsourcing server. However, the proxy or outsourcing server needs a re-encryption key (i.e., re-key) and the re-encryption program must execute in a black-box manner (cannot trace into or debug and monitor the program), and thus the outsource server must be semi-trusted. Actually, as the outsource program was run and fully controlled by the server, in this paper, we consider a stronger attack in the case that the re-encryption program was run on an untrusted/malicious server and even the server can trace into the codes and monitor the variables during the executing. We design a secure multi-hop re-encryption scheme, and then convert the re-encryption program into an obfuscated version with constant-hiding to ensure no sensitive information be revealed. The obfuscator of multi-hop re-encryption is to faithfully hide the program and its sensitive data that takes a re-encryption program/circuit as input and outputs another program with the same functionality, while revealing no more sensitive information (i.e., sensitive key and plaintext) than learns from the blackbox oracle access to the original program. We also present a flexible and controllable construction of re-encryption scheme, functionality model and its obfuscation version in leveled multilinear groups, and exemplify some scenarios to deploy in various applications. Finally, we provide the performance analysis of the obfuscator, such as functionality preservation of consistency, polynomial slowdown of performance, and average-case virtual ..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an novel interactive outlier detection system called feature-rich interactive outlier detection (FRIOD), which features a deep integration of human interaction to improve detection performance and greatly streamline the detection process. A user-friendly interactive mechanism is developed to allow easy and intuitive user interaction in all the major stages of the underlying outlier detection algorithm which includes dense cell selection, location-aware distance thresholding, and final top outlier validation. By doing so, we can mitigate the major difficulty of the competitive outlier detection methods in specifying the key parameter values, such as the density and distance thresholds. An innovative optimization approach is also proposed to optimize the grid-based space partitioning, which is a critical step of FRIOD. Such optimization fully considers the high-quality outliers it detects with the aid of human interaction. The experimental evaluation demonstrates that FRIOD can improve the quality of the detected outliers and make the detection process more intuitive, effective, and efficient."
  },
  {
    "year": "2017",
    "abstract": "Clustering is an important approach in fault diagnosis. The dominant sets algorithm is a graph-based clustering algorithm, which defines the dominant set as a concept of a cluster. In this paper, we make an in-depth investigation of the dominant sets algorithm. As a result, we find that this algorithm is dependent on the similarity parameter in constructing the pairwise similarity matrix, and has the tendency to generate spherical clusters only. Based on the merits and drawbacks of this algorithm, we apply the histogram equalization transformation to the similarity matrices for the purpose of removing the influence of similarity parameters, and then use a density-based cluster expansion process to improve the clustering results. In experimental validation of the proposed algorithm, we use two criterions to evaluate the clustering results in order to arrive at convincing conclusions. Data clustering experiments on ten data sets and fault detection experiments on the Tennessee Eastman process demonstrate the effectiveness of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Finite-state model predictive control (FS-MPC) is computationally expensive, as it uses all voltage vectors available for prediction and estimation. This paper proposes a novel finite-state model-based predictive current control (MPCC) scheme to overcome the drawbacks of FS-MPC. A reference frame based on the prediction of the current locus when a zero-voltage vector is employed is established to reduce the computational requirements; specifically, only one zero-voltage vector must be predicted compared with the seven required in conventional FS-MPC. The selection of the optimal voltage vector is based on the direction of the current locus in the established reference frame instead of a cost function, which is necessary and time consuming in conventional FS-MPC. Zero-voltage vectors are also selected by contrasting the distance between the reference and predictive currents to reduce the torque ripple of the proposed method. Simulation and experimental results are presented and confirm the efficient performance of the proposed MPCC."
  },
  {
    "year": "2017",
    "abstract": "Standalone photovoltaic systems is a key technology for the increase of renewable energy sources share in electricity production worldwide. The power quality of those systems plays a fundamental role in avoiding volatile power supply. This calls for a concrete design in order to meet power quality specifications. In this context, a methodology has been developed in a previous work, in order to set the values of the parameters that optimize the power quality indices of the system. In this paper, an extensive sensitivity analysis is performed regarding the influence of the optimized parameters variation on the power quality indices. Throughout the outcomes of the sensitivity analysis a more insightful view of the system performance under the deviations of system parameters is revealed, which in combination with the aforementioned optimal design strategy becomes an essential tool that ensures high power quality level. The theoretical outcomes are validated by experimental results, highlighting the effectiveness of the proposed design strategy."
  },
  {
    "year": "2017",
    "abstract": "In vehicle-to-infrastructure visible light communication (V2IVLC) systems, the vehicle receives data from LED street lights that are placed along both sides of a street. At a certain time, a vehicle communicates with only one group of LEDs. As the vehicle moves, it needs to switch the communication from the current LED group to the next group. Because of the fast movement of the vehicle and the small coverage of each LED group, the handover between the LED groups is a difficult problem. This paper proposes an entire handover procedure for a V2IVLC system. The main point of this procedure is a distancebased probabilistic algorithm for the determining of the handover switching time. The switching time is chosen to maximize the signal quality subject to a constraint, so that the missing handover rate is lower than a predetermined threshold. The proposed algorithm is verified through simulations. The results show that the proposed handover algorithm can provide a high signal quality of the communication within a reasonable missing handover rate."
  },
  {
    "year": "2017",
    "abstract": "AADL along with its Behavior Annex is an architecture and behavior description language for safety-critical domains, e.g. avionics, aerospace, and defence. In order to formally analyze behavior properties of AADL models, it is necessary to transform the AADL language into formal languages supported by formal verification tools. Moreover, comprehensive formal verification of AADL models highly requires that the transformation supports larger subset of the AADL language, as well as verification tools are able to capture various behavior of AADL, such as concurrency and timing. As an extended communicating sequential process (CSP), stateful timed CSP with its model checker-PAT provide an strongly expressive language and verification tool for real-time systems, distributed systems, and concurrent systems. This paper introduces a model transformation approach from a comparatively complete subset of AADL to stateful timed CSP, in particular supporting major components of AADL Behavior Annex. We propose a comprehensive set of transformation rules for AADL to stateful timed CSP. Then, we perform formal verification in PAT to analyze concurrent behavior properties of AADL models, such as safety, liveness, and trace refinement with various fairness assumptions, in which we consider time capacities, deadlines, periods of AADL threads and durations of AADL processes. As a study case, we develop an AADL model of F-16 “Auto Pilot Controller”and transform the model into Stateful Timed CSP. We specify a set of critical properties of the model and perform formal verification in PAT."
  },
  {
    "year": "2017",
    "abstract": "Community detection is an important aspect of social network analysis, but social factors such as user intimacy, influence, and user interaction behavior are often overlooked as important factors. Most of the existing methods are single classification algorithms; multi-classification algorithms that can discover overlapping communities are still incomplete. In former works, we calculated intimacy based on the relationship between users, and divided them into their social communities based on intimacy. However, a malicious user can obtain the other user relationships, thus to infer other users interests, and even pretend to be the another user to cheat others. Therefore the information users concerned about needs to be transferred in the manner of privacy protection. In this paper, we propose an efficient privacy preserving algorithm to preserve the privacy of information in social networks. First, during expansion of communities on the base of mining seed, in order to prevent others from malicious users, we verify their identities after they send a request. We make use of the recognition and nontampering of the block chain to store the user's public key and bind to the block address, which is used for authentication. At the same time, in order to prevent the honest but curious users from illegal access to other users' information, we do not send plaintext directly after the authentication, but hash the attributes by mixed hash encryption to make sure that users can only calculate the matching degree rather than know specific information of other users. Analysis shows that our protocol would serve well against different types of attacks."
  },
  {
    "year": "2017",
    "abstract": "Cloud-assisted Internet of Things (IoT) is a popular system model to merge the advantages of both the cloud and IoT. In this model, IoT collects the real-world data, and the cloud maximizes the value of these data by sharing and analyzing them. Due to the sensitivity of the collected data, maintaining the security of these data is one of the main requirements in practice. Searchable public-key encryption is a fundamental tool to achieve secure delegated keyword search over ciphertexts in the cloud. To accelerate the search performance, Xu et al. propose a new concept of searchable public-key ciphertexts with hidden structures (SPCHSs), and it constructs a SPCHS instance to achieve search complexity that is sublinear with the total number of ciphertexts rather than the linear complexity as in the traditional works. However, this paper cannot achieve the parallel keyword search due to its inherent limitations. Clearly, the aforementioned instance is impractical. To address this problem, we propose a new instance of SPCHS to achieve fast and parallel keyword search over public-key ciphertexts. In contrast to the work by Xu et al., a new type of hidden relationship among searchable ciphertexts is constructed by the new instance, where every searchable ciphertext has a hidden relationship with a common and public parameter. Upon receiving a keyword search trapdoor, one can disclose all corresponding relationships in parallel and then find all matching ciphertexts. Hence, the new relationship allows a keyword search task to be performed in parallel. In addition, due to the limited capability of IoT, the new instance achieves a more efficient encryption algorithm to save time and communication cost."
  },
  {
    "year": "2017",
    "abstract": "It is well-known that ac power flows of a power system do not have a closed-form analytical solution in general. This paper proposes a multi-dimensional holomorphic embedding method that derives analytical multivariate power series to approach true power flow solutions. This method embeds multiple independent variables into power flow equations and hence, can, respectively, scale power injections or consumptions of selected buses or groups of buses. Then, via a physical germ solution, the method can represent each bus voltage as a multivariate power series about symbolic variables on the system condition so as to derive approximate analytical power flow solutions. This method has a non-iterative mechanism unlike the traditional numerical methods for power flow calculation. Its solution can be derived offline and then evaluated in real time by plugging values into symbolic variables according to the actual condition, so the method fits better into online applications, such as voltage stability assessment. The method is first illustrated in detail on a 4-bus power system and then demonstrated on the IEEE 14-bus power system considering independent load variations in four regions."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a novel approach to incorporate the time compression overlap-add (TC-OLA) technique used in communication systems into linear frequency modulation pulse compression (LFM-PC) radar systems. This technique significantly boosts the signal-to-noise ratio (SNR) and provides a robust processing gain compared with the traditional radar LFM-PC systems. In addition, TC-OLA provides a better immunity against powerful jamming techniques. At the transmitter side, we divide a digitized LFM chirp signal into a controlled number of overlapping segments. We then speed up each segment by increasing the sampling rate to account for the segment overlap. At the receiver side, we apply OLA to reconstruct the signal with a much higher gain. To simulate and evaluate the performance of the new system, we extend the conventional LFM-PC radar model, which includes matched filter (MF) processor, moving target detector (MTD), and two common constant false alarm rate (CFAR) algorithms, by suitably adding TC and OLA blocks at the transmitter and receiver, respectively. Using the TC-OLA-based LFM radar system, we have control over the SNR level and the spectrum spread while preserving the same Doppler shift and target time delay as the conventional LFM radar system. Furthermore, we transform LFM chirp signal into a novel TC signal that inherits LFM properties while possessing better immunity to jamming. Moreover, the proposed radar model relies on high sample rates only when needed and, therefore, does not require changing MF, MTD, and CFAR as is the case for a wideband LFM radar with the same processing gain. Detailed comparisons between the conventional LFM and the wideband LFM radars against the proposed model are also presented."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a machine learning-based approach to detect malicious mobile malware in Android applications. This paper is able to capture instantaneous attacks that cannot be effectively detected in the past work. Based on the proposed approach, we implemented a malicious app detection tool, named Androidetect. First, we analyze the relationship between system functions, sensitive permissions, and sensitive application programming interfaces. The combination of system functions has been used to describe the application behaviors and construct eigenvectors. Subsequently, based on the eigenvectors, we compare the methodologies of naive Bayesian, J48 decision tree, and application functions decision algorithm regarding effective detection of malicious Android applications. Androidetect is then applied to test sample programs and real-world applications. The experimental results prove that Androidetect can better detect malicious applications of Android by using a combination of system functions compared with the previous work."
  },
  {
    "year": "2017",
    "abstract": "This paper emphasizes on software effort estimation and knowledge management of practicing Scrum methodology that are challenging tasks in agile context. Proposed approach improves software effort estimation and knowledge management of software projects by focusing on Scrum process and practices using ontology model in a multiagent estimation system. It also motivates project key stakeholders to regularly save significant tacit knowledge of unique situations in the form of lessons learnt during the project development. Various agents of the estimation system access the existing knowledge base and autonomously perform their inferencing activities using description logic as per requirements specified by the scrum master and respond with suitable estimate to him/her in the form of time, resources, and lessons learnt for the success of future projects. To validate our approach, an experiment, based on twelve web projects, was conducted using proposed approach, delphi and planning poker estimation methods. The obtained results by applying MMRE, PRED(x) evaluation measures reveals that proposed approach delivers more accurate estimates as compared with delphi and planning poker methods."
  },
  {
    "year": "2017",
    "abstract": "For the purposes of technology planning and research and development strategy development, we present a semi-automated method that extracts text information from patent data, uses natural language processing to extract the key technical information of the patent, and then visualizes this information in a matrix form. We tried to support qualitative analysis of patent contents by extracting functions, components, and contexts, which are the most important information about inventions. We validated the method by applying it to patent data related to nanosensors. The matrix can emphasize technical information that have not been exploited in patents, and thereby identify development opportunities."
  },
  {
    "year": "2017",
    "abstract": "Slope failure and debris flow cause lots of casualties and property loss. An early-warning system for slope collapse and debris flow is essential to ensure safety of human beings and assets. Based on fiber optic sensing technology and Internet of Things, a new sensing transducer for internal earth pressure measurement in a soil slope is proposed, fabricated, and tested in this paper. The working principles, theoretical analysis, laboratory calibrations, and discussions of the proposed pressure transducers are elaborated. Extensive evaluations of the resolutions, physical properties, and response to the applied pressures have been performed through modeling and experimentations. The results show that the sensitivity of the designed pressure sensor is 0.1287 kPa/με across a pressure range of 140 kPa. Finally, a field soil slope was instrumented with the developed fiber optic sensors and other sensors. Through internet and cloud computing platform, the stability of the soil slope was analyzed. In the cloud computing platform, the numerical simulation is carried out by considering the slope internal deformations, rainfall infiltration, and limit force equilibrium. The factor of safety of the soil slope was calculated, which could be used to determine health condition of the instrumented slope. The performance was evaluated and classified into three categories. It proves that the proposed early-warning system has potential to monitor the health condition of the soil slopes."
  },
  {
    "year": "2017",
    "abstract": "Spectrum trading is an important aspect of television white space (TVWS) and it is driven by the failure of spectrum sensing techniques. In spectrum trading, the primary users lease their unoccupied spectrum to the secondary users for a market fee. Although spectrum trading is considered as a reliable approach, it is confronted with a spectrum transaction completion time problem, which negatively impacts on end-users Quality of Service and Quality of Experience metrics. Spectrum transaction completion time is the duration to successfully conduct TVWS spectrum trading. To address this issue, this paper proposes simple mechanism auction reward truthful (SMART), a fast and iterative machine learning-assisted spectrum trading model to address this issue. Simulated results indicate that SMART out-performs referenced VERUM algorithm in three key performance indicators: bit-error rate, instantaneous throughput, and probability of dropped packets by 10%, 5%, and 15%, respectively."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an effective approach for rock mass discontinuity extraction based on the terrestrial LiDAR scanning 3-D point clouds. First, a Quadtree-Octree index method that retained the adjacency relationship of rock point clouds was proposed to organize point cloud data in a high-efficiency manner. Second, the normal vector (NV) calculation was directly conducted by the local triangulated irregular networks together with eight neighborhood areas. Third, a double-clustering strategy was developed based on the Quadtree-Octree index and NV calculation discussed in Step one and two. The first clustering was conducted in the point cloud matrix at each station, whereas the second clustering among multiple stations. Fourth, an extended random sample consensus algorithm was designed with two separate checks (distance and angle) to detect whether the compliance with certain constraints occurred between rock point clouds and fitting planes. The proposed method were evaluated by a real field data set in China and a public data set from Rockbench. The feasibility of the proposed method were verified by these two data sets, which indicated a promising perspective for the field engineering survey."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new method to address issues associated with vehicle system state estimation using an unscented Kalman filter (UKF) with considering full-car system and nonlinear tire force under various international standards organization (ISO) road conditions. Due to the fact that practical road information is complex and noise covariance cannot be treated as a constant, the influence of varying vehicle system process noise variance and measurement noise covariance on the estimation accuracy of the UKF is first discussed. To precisely estimate road information, a novel road classification method using measured signals (vertical acceleration of sprung mass and unsprung mass) of vehicle system is proposed. According to road excitation levels, different road process variances are defined to tune the vehicle system's variance for application of UKF. Then, road classification and UKF are combined to form an adaptive UKF (AUKF) that takes into account the relationship of different road process noise variances and measurement noise covariances under varying road conditions. Simulation results reveal that the proposed AUKF algorithm has higher accuracy for state estimation of a vehicle system under various ISO road excitation condition."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the transceiver design in a two-hop amplify-and-forward (AF) multiple-input multiple-output (MIMO) relay system with the direct link and quality-of-service (QoS) constraint. The QoS criterion is specified by the upper bound of the mean-squared error of the signal waveform estimation at the destination node. To minimize the total system transmission power, we apply a new AF relay protocol where the source node transmits signals during both time slots. Two iterative algorithms are proposed to jointly optimize the source and relay precoding matrices for the general case with multiple concurrent data streams, and the special case where a single data stream is transmitted, respectively. Simulation results show the effectiveness of both proposed algorithms. Interestingly, for the single data stream case, the second algorithm converges faster than the first algorithm. Compared with conventional two-hop MIMO relay systems where the source node is silent at the second time slot, the new protocol reduces the system transmission power. Under a given system transmission power, the proposed algorithms yield a higher system mutual information thanks to a better utilization of the direct link. Simulation results in this paper shed lights on some fundamental questions in relay system design such as when direct communication between source and destination (without any relay nodes) is optimal, and when the new AF relay protocol provides a larger gain compared with the conventional single phase source power allocation."
  },
  {
    "year": "2017",
    "abstract": "Unlike the traditional analysis and synthesis approach of a switched system that requires a monotonic decrease of Lyapunov function (LF), this paper investigates an N-step-ahead LF approach. Such an approach allows a non-monotonic behavior both at the switching instants and during the running time of each subsystem but guarantees an average decrease at every N sampling steps. The asymptotic stability criterion is improved as well as the capability of disturbance attenuation. By introducing a series of auxiliary variables, the future knowledge of states and exogenous noises can be properly used to derive sufficient conditions for the existence of a robust H∞controller in the form of a set of numerical testable conditions. Note that N has direct impact on the number of inequality constraints. The essential difficulty is to construct an exponential damping law of the decreasing points of LF, i.e., to find the joint point between the switching interval and the predictive horizon. Moreover, the relationship between N-step time difference of LF and switching rate, i.e., the average dwell time constraint, is thoroughly discussed. An ecology system is employed to demonstrate practical potentials of the presented design framework."
  },
  {
    "year": "2017",
    "abstract": "Cross-project defect prediction (CPDP) is a field of study where a software project lacking enough local data can use data from other projects to build defect predictors. To support CPDP, the cross-project data must be carefully filtered before being applied locally. Researchers have devised and implemented a plethora of various data filters for the improvement of CPDP performance. However, it is still unclear what data filter strategy is most effective, both generally and specifically, in CPDP. The objective of this paper is to provide an extensive comparison of well-known data filters and a novel filter devised in this paper. We perform experiments on 44 releases of 14 open-source projects, and use Naive Bayes and a support vector machine as the underlying classifier. The results demonstrate that the data filter strategy improves the performance of cross-project defect prediction significantly, and the hierarchical select-based filter proposed performs significantly better. Moreover, when using appropriate data filter strategy, the defect predictor built from cross-project data can outperform the predictor learned by using within-project data."
  },
  {
    "year": "2017",
    "abstract": "Pedestrian path prediction is an emerging topic in the crowd visual analysis domain, notwithstanding its practical importance in many respects. To date, the few contributions in the literature proposed quite straightforward approaches, and only a few of them have taken into account the interaction between pedestrians as a paramount cue in forecasting their potential walking preferences in a given scene. Moreover, the typical trend was to evaluate the proposed algorithms on sparse scenarios. To cope with more realistic cases, in this paper, we present an efficient approach for pedestrian path prediction in densely crowded scenes. The proposed approach initiates by extracting motion features related to the target pedestrian and his/her neighbors. Second, in order to further increase the representativeness of the extracted motion cues, an autoencoder feature learning model is considered, whose outcome finally feeds a Gaussian process regression prediction model to infer the potential future trajectories of the target pedestrians given their walking records in the scene. Experimental results demonstrate that our framework scores plausible results and outperforms traditional methods in the literature."
  },
  {
    "year": "2017",
    "abstract": "With the explosive growth of smart terminals, access points (APs) are densely deployed in the buildings of enterprise, campus, hotel, and so on, to provide sufficient coverage and capacity for peak user demands. However, existing studies show that during the off-peak periods, not all the capacity is needed and a large fraction of low-utilization or idle APs cause a great deal of energy waste in these buildings. Although many solutions have been proposed to switch on/off the APs according to the user needs, few works consider the energy cost by state transition. In this paper, we propose a state transition-aware energy-saving mechanism for dense wireless local area networks, which can dynamically switch the APs' states to meet the user needs while controlling the switching frequency and balancing the number of associated users of each AP. First of all, we analyze the most recent user behaviors, which are used to design the energy-saving mechanism. Then, we model the proposed mechanism in order to set relevant parameters reasonably. Finally, evaluation results show that comparing with a typical static strategy, the energy consumption is reduced by 24.3%, and the average available bandwidth is increased by 27.8%. Meanwhile, the switching frequency is reduced by 14.3% as well."
  },
  {
    "year": "2017",
    "abstract": "With the recent rapid development of cloud computing technology, how to reduce the costs of a cloud data center effectively has become an important issue. The study on virtual machine deployment mainly aims at deploying virtual machine resources required by users on a physical server rationally and effectively. This paper proposes a multi-population ant colony algorithm to solve problems of virtual machine deployment. With resource wastage and energy consumption as optimization objectives, this algorithm uses multiple ant colonies for the solution and determines strategies for information exchange among ant colonies according to the information entropy of each population to guarantee the balance of its convergence and diversity. The simulation results show that this algorithm has better performance than the single-population ant colony algorithm and can reduce resource wastage and energy consumption effectively for high-demand virtual machine deployment."
  },
  {
    "year": "2017",
    "abstract": "Due to time and cost limitations, multi-stress accelerated life tests (ALTs) have been gradually applied in the fields of experimental design and reliability estimation for highly reliable and long-life products. To develop more efficient and concise test plans, it is necessary to study an equivalent experimental design method to create an equivalent conversion approach for different ALT plans. This paper presents the equivalent optimum design method combined with D-efficiency and asymptotic variance. In this method, the Fisher information matrix determinant is proposed as the equivalent feature variable. D-efficiency is a new equivalent criterion applied in the ALT design method and is measured using the ratio of Fisher information matrix determinants. The objective is to minimize the test time at a given efficiency and under asymptotic variance constraints without loss of test estimation accuracy. Based on the proposed equivalent method, a constant-stress ALT plan was successfully converted into its equivalent step-stress or ramp-stress ALT plan. Finally, an example is presented to demonstrate the equivalent ALT design of an electrical product with two stresses. The constant-stress ALT is equivalently designed for the ramp-stress ALT plan, and the sensitivity of the D-efficiency is analyzed. The results show that the proposed equivalent test scheme can shorten test time while achieving the same estimation accuracy."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the effects of imperfect texture shape and dimensional uncertainty on the surface texture performance (load-carrying capacity and coefficient of friction) by adopting numerical experiments, statistical models, and artificial neural network. The imperfect texture shape is regarded as a polygon, and the uncertain geometrical dimensions include the dimple diameter, the area density, and the dimple depth. Results reveal that the most critical geometric parameters that influence the friction force are manufacturing errors associated with the texture's area density. With respect to the load-carrying capacity and the coefficient of friction, manufacturing errors associated with the dimple diameter are more influential than those of the dimple depth and the area density. It is shown that insofar as the optimization of surface texture performance is concerned, the imperfect texture shape and the dimensional uncertainty associated with the laser texturing with three-sigma performance level are harmless, but manufacturing errors with the one-sigma level can dramatically reduce the load-carrying capacity and increase the coefficient of friction. Specifically, when the dimensions of the area density, the dimple depth, and the dimple diameter are set as 30%, 5.5 μm, and 100 μm, respectively, the imperfect texture shape at the three-sigma level can achieve higher performance than lower levels of control of machining precision."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency division multiplexing (OFDM) with index modulation (OFDM-IM) technique has been recently proposed to provide performance improvements over conventional OFDM. OFDM-IM includes a different data transmission mechanism, where additional data bits are transmitted over subcarrier patterns by specifically activating selected subcarriers and nulling the others. However, such a mechanism inherently causes some inefficiency due to the inactive subcarriers. To improve the spectral efficiency of the OFDM-IM technique, dual-mode OFDM with index modulation (DM-OFDM) is proposed, where nulled subcarriers are activated by using a second signal constellation. With DM-OFDM, a significant data rate improvement can be obtained. As an important missing issue in the literature, OFDM-IM and its effective variations, such as DM-OFDM, have only been studied in terms of computer simulations and theoretical analysis. Therefore, their real-time performance is not yet investigated to assess their potential for next-generation networks. Addressing this gap, in this paper, OFDM-IM and DM-OFDM techniques are implemented in real-time by using software defined radio technology. National Instruments USRP-2921 nodes are used in a single-input single-output configuration. With this implementation, detailed real-time results and performance observations are provided. Moreover, a hybrid OFDM-IM (H-OFDM-IM) scheme, which can be seen as the combination of OFDM-IM and DM-OFDM, is proposed by targeting the limitations of both OFDM-IM and DM-OFDM in terms of spectral containment and error performance. With H-OFDM-IM, noticeable improvements in spectral containment and error performance can be obtained, and these observations show its suitability for real-time use and next-generation networks. With comprehensive computer simulation and test results, these claims are verified."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the problem of recall mechanism in a dynamic spectrum auction system. The licensed spectrum holders (SHs) can auction their idle channels to the secondary wireless service providers (SWSPs) for economic incentive. However, the primary user (PU) of an SH has higher priority than the SWSPs for the spectrum access. To deal with a sudden increase in PUs' spectrum demands after auction and guarantee their quality of services (QoS), we propose a Local recall-based dYnamic double spectRum auctIon meChanism (LYRIC) for SHs' spectrum auction operation. Different from the most existing approaches about spectrum recall-based spectrum auction, the proposed spectrum auction method for heterogeneous spectrum transaction takes account of the joint effect of heterogeneous demand, spectrum spatial reusability, and the economic efficiency. Simulation results show that the proposed LYRIC algorithm can improve the auction process of SHs, the channels utilization efficiency and the average buyers' satisfactory level with guarantees on the QoS of PUs."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on Byzantine attack detection for Gaussian two-hop one-way relay network, where an amplify-and-forward relay may conduct Byzantine attacks by forwarding altered symbols to the destination. For facilitating attack detection, we utilize the openness of wireless medium to make the destination observe some secured signals that are not attacked. Then, a detection scheme is developed for the destination by using its secured observations to statistically check other observations from the relay. On the other hand, notice the Gaussian channel is continuous, which allows the possible Byzantine attacks to be conducted within continuous alphabet(s). The existing work on discrete channel is not applicable for investigating the performance of the proposed scheme. The main contribution of this paper is to prove that if and only if the wireless relay network satisfies a non-manipulable channel condition, the proposed detection scheme achieves asymptotic errorless performance against arbitrary attacks that allow the stochastic distributions of altered symbols to vary arbitrarily and depend on each other. No pre-shared secret or secret transmission is needed for the detection. Furthermore, we also prove that the relay network is non-manipulable as long as all the channel coefficients are non-zero, which is not essential restrict for many practical systems."
  },
  {
    "year": "2017",
    "abstract": "In current Monte Carlo (MC) simulations of the light propagation in biological tissues, the sources (S) or detectors (D) are mainly positioned in view of 2-D planes, leading to the rough accuracy, and low efficiency. This paper proposed a 3-D visualization platform with interactive view to determine the S-D coordinates as well as the incident direction of source light. Moreover, the proposed system permits implementation of the MC simulation in a flexible voxel spacing, beyond the original voxel of medical images. Validation studies on a realistic 3-D human head model show that the S-D pairs can be fast and accurately positioned on the tissue surface with assistance of the visualization platform, indicating its great potential for biomedical optical applications."
  },
  {
    "year": "2017",
    "abstract": "Due to atmospheric effects and secondary illumination, hyperspectral images (HSIs) usually suffer from system noises, stripes, and dead pixels, which greatly degrade the imaging quality and limit the precision of the subsequent processing. In this paper, a novel HSI mixed denoising method based on 3-D spectral-spatial cross total variation (TV) is proposed to overcome such problem. First, the HSI is treated as a 3-D cube, and the TV with 2-D spatial directions on the spectral difference images, which could be treated as cross TV of HSI cube, is minimized to enhance the spatial smoothness and exploit the spectral redundancy and correlation. Second, an adaptive mechanism for calculating the spectral-spatial weights is adopted to balance the fidelity term and the cross TV regularization according to different spatial structures. Alternating direction method of multipliers is finally extended to solve the proposed model by separating it into several simpler subproblems. Experimental results on simulated and real-HSI data sets validated the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "The back-end intelligent system of Internet of Things (IoT) needs the powerful computing ability to support its service, and therefore, IoT is often constructed on the cloud platform. However, the resources for cloud computing are limited, and different types of services will have different demands for the resources. This paper proposed a service-oriented virtual machine (VM) placement strategy in cloud data center and divided the roles of VM into Web role, worker role, and storage according to the function types. On the basis of service orientation and in consideration of communication overhead between VMs in the data center, the genetic algorithm was used to conduct the optimal configuration for different types of VMs under the situation of limited resources to achieve the minimum communication overhead and total power consumption. The proposed cloud VM placement strategy is also suitable for the intelligent computing platform of IoT back end."
  },
  {
    "year": "2017",
    "abstract": "The small cells have been equipped with caching and multicast capabilities to save energy and ease backhaul burden. However, given the increasing diversity of user association in heterogeneous networks, traditional schemes may fail to exploit the energy-saving potential of caching and multicast. In this paper, we propose the model to minimize total power consumption by jointly optimizing the user association and cache deployment. The formulated joint optimization problem is decomposed and reformulated as a NP-complete set partition problem. Motivated by the idea of the tactile networks, the devices can find the candidate user grouping based on its own utility. The utility function is judiciously designed to reduce the searching space without compromising optimality. Then, a heuristic caching algorithm is proposed by rigorously deriving the upper and lower bounds of cache placement. Simulation results show that our proposed scheme outperforms the other existing multicast and caching algorithms in terms of power consumption by up to 28%, while keeping the load among base stations balanced."
  },
  {
    "year": "2017",
    "abstract": "Resistance spot welding (RSW) is frequently employed in current industrial occasions. This paper reviewed recent advances of the electrical structure of the RSW system. Two types of electrical structures are used in RSW machines. Single-phase ac power source has a simple structure but low control frequency and power factor, and the measurement and control for the machine have some special operations. While three-phase medium frequency dc power source has a complex structure and high control frequency but high cost, and frequently switching the direction of the output welding current may induce many negative phenomena in the welding transformer. The characteristics of the two structures are presented in detail in this paper. Corresponding measures have been taken to deal with the phenomena during the process, respectively, for the two types of electrical structures, according to the previous works. Though many significant achievements have been gained in previous works, it is expected to be more improvements required in the future. This paper can provide references and enlightens for academic researches or actual production in RSW operations."
  },
  {
    "year": "2017",
    "abstract": "Vehicular edge computing (VEC) is introduced to extend computing capacity to vehicular network edge recently. With the advent of VEC, service providers directly host services in close proximity of mobile vehicles for great improvements. As a result, a new networking paradigm, vehicular edge networks is emerged along with the development of VEC. However, it is necessary to address security issues for facilitating VEC well. In this paper, we focus on reputation management to ensure security protection and improve network efficiency in the implementation of VEC. A distributed reputation management system (DREAMS) is proposed, wherein VEC servers are adopted to execute local reputation management tasks for vehicles. This system has remarkable features for improving overall performance: 1) distributed reputation maintenance; 2) trusted reputation manifestation; 3) accurate reputation update; and 4) available reputation usage. In particular, we utilize multi-weighted subjective logic for accurate reputation update in DREAMS. To enrich reputation usage in DREAMS, service providers optimize resource allocation in computation offloading by considering reputation of vehicles. Numerical results indicate that DREAMS has great advantages in optimizing misbehavior detection and improving the recognition rate of misbehaving vehicles. Meanwhile, we demonstrate the effectiveness of our reputation-based resource allocation algorithm."
  },
  {
    "year": "2017",
    "abstract": "Routing is one of the important topics in wireless sensor networks (WSNs), and has been attracting the research community in the last decade. Routing based on ant colony optimization (ACO) is a type of transmission method rich in characteristics. There are several survey papers that present and compare routing protocols from various perspectives, but the survey on ACO-based routing is still missing. This paper makes a first attempt to provide a comprehensive review on ACO-based routing protocols in WSNs. First, we offer a classification of these routing algorithms. Second, the most representative ACO-based routing protocols are described, discussed, and qualitatively compared. Finally, we put forward some open issues concerning the design of WSNs. This survey aims to provide useful guidance for system designers on how to evaluate and select appropriate routing schemes for specific applications."
  },
  {
    "year": "2017",
    "abstract": "Smart factory addresses the vertical integration of physical entities and information systems. Network and cloud are two essential infrastructures to achieve this goal. Among them, the network provides interconnection for communication and data flow, while the cloud provides powerful and elastic computing and storage abilities for big data and intelligent applications. This paper presents a cloud-centric framework for the implementation of the smart factory. Based on this framework, three high leveled protocols viz., EtherCAT, DDS, and OPC UA are selected to implement machine network (controller to sensors/actuators communication), machine to machine communication, and machine to cloud communication respectively, to satisfy diverse communication requirements of the smart factory. An integrated architecture for combining ontology knowledge and semantic data to support intelligent applications is also proposed. These network and data process schemes are verified in a smart factory prototype for personalized candy packing application."
  },
  {
    "year": "2017",
    "abstract": "Fractional repetition codes are a class of distributed storage codes dedicated to optimize the node repair performance, i.e., they enable uncoded exact repairs with minimum bandwidth consumption. Recent studies extend the application of such codes to heterogeneous storage networks, where the resultant codes are referred to as general fractional repetition (GFR) codes. In this paper, we propose some new constructions of GFR codes based on the combinatorial structures including packings, coverings, and pairwise balanced designs. Due to the mathematical properties of employed designs, the proposed constructions support a larger set of code parameters compared with existing construction methods."
  },
  {
    "year": "2017",
    "abstract": "Cloud-integrated cyber-physical system (CCPS) is playing an increasingly important role in our daily life. Unfortunately, how to dynamically make the reserved bandwidth allocation for CCPS is still a great challenge. To address this issue, we propose a novel strategy that systematically and dynamically allocates reserved bandwidth for multiple CPS services in CCPS with a nearly optimal method. By making a balance between the three key factors of crash cost, QoS loss and operating cost, the proposed strategy is able to minimize the operating cost, the influence of the discrepancy between the service-level agreement and the bandwidth actually delivered, while preserving essential QoS level. Then we develop an online algorithm based on the proposed strategy using the Lyapunov optimization theory. The online algorithm can approximate the optimal solution within provable bounds and is capable of processing the tasks within a preset delay. Theoretical analysis of performance proves advantages and shows that the algorithm has the ability to solve the complicated dynamic bandwidth allocation problems for multiple CPS services in practical CCPS. Extensive experiments validate its effectiveness as well as its superiority to five existing strategies (FM, MS + LB, MS + EF, DS + LB, DS + EF) in overall cost, crash cost, QoS loss, and operating cost."
  },
  {
    "year": "2017",
    "abstract": "Visible light communications (VLCs) have become an important and promising supplement to the Wi-Fi network for the coming 5G communications. Photodetectors with narrow field-of-view are essential for parallel data transmission, such as optical attocell networks and spatial multiple-input and multiple-output arrays. Here, we propose a design of sub-millimeter-scale flexible optical sheets with strong angular selectivity. They can be mounted to any photodetectors even with irregular surfaces and significantly narrow the field-of-view (down to 4ř or less) with a plug-and-play feature. These optical sheets pave the way toward unprecedented progress in cell densification and channel capacity for VLC-based 5G networks."
  },
  {
    "year": "2017",
    "abstract": "The purpose of signal restoration is to acquire a clean signal from the degraded signal which contains blur and noise. In this paper, a modified Tikhonov regularization method based on the standard Tikhonov regularization matrix is proposed, and the corresponding preconditioner is designed to accelerate the convergence of the proposed algorithm. The proposed method shows the best performance than several competitive methods. In addition, the convergence speed is improved significantly."
  },
  {
    "year": "2017",
    "abstract": "The rapid growth in the volume and importance of web communication throughout the Internet has heightened the need for better security protection. Security experts, when protecting systems, maintain a database featuring signatures of a large number of attacks to assist with attack detection. However used in isolation, this can limit the capability of the system as it is only able to recognize known attacks. To overcome the problem, we propose an anomaly-based intrusion detection system using an ensemble classification approach to detect unknown attacks on web servers. The process involves removing irrelevant and redundant features utilising a filter and wrapper selection procedure. Logitboost is then employed together with random forests as a weak classifier. The proposed ensemble technique was evaluated with some artificial data sets namely NSL-KDD, an improved version of the old KDD Cup from 1999, and the recently published UNSW-NB15 data set. The experimental results show that our approach demonstrates superiority, in terms of accuracy and detection rate over the traditional approaches, whilst preserving low false rejection rates."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an improved harmony search (ImHS) algorithm is presented. HS is a simple but efficient metaheuristic method explored in recent literature, that simulates the process of musical improvisation. Two modifications for parameter tuning are proposed to enhance the algorithm performance in the solution of constrained numerical optimization problems, maintaining the simplicity of its original design. Metaheuristics are methods for solving optimization problems, and are based in two processes: exploration (diversification) and exploitation (intensification). The proposed modifications improve both processes in HS, without breaking their balance. A well-known ideal problem set was used as a reference to compare the efficiency of the developed algorithm ImHS with HS and three of its most successful variants, and also with two other metaheuristics of different nature, artificial bee colony (ABC) and modified ABC (MABC). Various techniques were applied to evaluate the algorithm performance with the proposed modifications, in order to validate the reliability of the comparison. In most case studies, ImHS far surpassed the results of HS and ABC, also improving the performance of the selected variants. Additionally, its results reached a similar quality than the obtained with MABC but with a significantly lower computational cost, suggesting that it can be a useful tool for solving real-world optimization problems if they are modeled as constrained numerical cases."
  },
  {
    "year": "2017",
    "abstract": "We derive the probability of detection functions of 1- and 2-bitstreams for polarization multiple-input multiple-output antenna systems in random line-of-sight propagation conditions. The derivations are produced assuming that the angle-of-arrival of the field impinging at the receive antenna is fixed. Hence, randomness is only due to the direction of polarization of the incident field relative to the polarization of the far-field of the receiver antenna. Also, a general analytical orthogonalization transformation matrix has been derived for far-field functions of arbitrary dual-polarized antennas and used in the probability of detection derivations. Analytical results are obtained for the maximum ratio combining receiver diversity and the zero-forcing multiplexing receiver algorithms. These results provide a practical prediction tool of the impact of antennas on system performance due to polarization deficiencies of analytical, measured or simulated radiation field patterns of dual polarized antennas. This is illustrated by the provided numerical examples."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a convolutional neural network for thermal image enhancement by incorporating the brightness domain with a residual-learning technique, which improves the performance of enhancement and speed of convergence. Typically, the training domain uses the same domain as that of the target image; however, we evaluated several domains to determine the most suitable one for the network. In the analyses, we first compared the performance of networks that were trained by the corresponding regions of color-based and aligned infrared-based images, respectively, including thermal, far, and near spectra. Then, four RGB-based domains, namely, gray, lightness, intensity, and brightness were evaluated. Finally, the proposed network architecture was determined by considering the residual and brightness domains. The results of the analyses indicated that the brightness domain was the best training domain for enhancing the thermal images. The experimental results confirm that the proposed network, which can be trained in approximately one hour, outperforms the conventional learning-based approaches for thermal image enhancement, in terms of several image quality metrics and a qualitative evaluation. Furthermore, the results demonstrate that the brightness domain is effective as the training domain and can be used to increase the performance of existing networks."
  },
  {
    "year": "2017",
    "abstract": "We propose an object detection system that depends on position-sensitive grid feature maps. State-of-the-art object detection networks rely on convolutional neural networks pre-trained on a large auxiliary data set (e.g., ILSVRC 2012) designed for an image-level classification task. The image-level classification task favors translation invariance, while the object detection task needs localization representations that are translation variant to an extent. To address this dilemma, we construct position-sensitive convolutional layers, called grid convolutional layers that activate the object’s specific locations in the feature maps in the form of grids. With end-to-end training, the region of interesting grid pooling layer shepherds the last set of convolutional layers to learn specialized grid feature maps. Experiments on the PASCAL VOC 2007 data set show that our method outperforms the strong baselines faster region-based convolutional neural network counterpart and region-based fully convolutional networks by a large margin. Our method applied to ResNet-50 improves the mean average precision from 74.8%/74.2% to 79.4% without any other tricks. In addition, our approach achieves similar results on different networks (ResNet-101) and data sets (PASCAL VOC 2012 and MS COCO)."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study the channel-aware (CA) randomization for a simple physical-layer encryption scheme and show that the probability of successful attack becomes very low by CA randomization when the known plain-text attack is carried out. As CA randomization becomes vulnerable to the channel estimation attack, its impact on the performance is investigated in terms of the average number of known elements of a key subsequence when the known plain-text attack is performed together with the channel estimation attack."
  },
  {
    "year": "2017",
    "abstract": "False data injection cyber-physical threat is a typical integrity attack in modern smart grids. These days, data analytical methods have been employed to mitigate false data injection attacks (FDIAs), especially when large scale smart grids generate huge amounts of data. In this paper, a novel data analytical method is proposed to detect FDIAs based on data-centric paradigm employing the margin setting algorithm (MSA). The performance of the proposed method is demonstrated through simulation using the six-bus power network in a wide area measurement system environment, as well as experimental data sets. Two FDIA scenarios, playback attack and time attack, are investigated. Experimental results are compared with the support vector machine (SVM) and artificial neural network (ANN). The results indicate that MSA yields better results in terms of detection accuracy than both the SVM and ANN when applied to FDIA detection."
  },
  {
    "year": "2017",
    "abstract": "For linear systems, the original Kalman filter under the minimum mean square error (MMSE) criterion is an optimal filter under a Gaussian assumption. However, when the signals follow non-Gaussian distributions, the performance of this filter deteriorates significantly. An efficient way to solve this problem is to use the maximum correntropy criterion (MCC) instead of the MMSE criterion to develop the filters. In a recent work, the maximum correntropy Kalman filter (MCKF) was derived. The MCKF performs very well in filtering heavy-tailed non-Gaussian noise, and its performance can be further improved when some prior information about the system is available (e.g., the system states satisfy some equality constraints). In this paper, to address the problem of state estimation under equality constraints, we develop a new filter, called the MCKF with state constraints, which combines the advantages of the MCC and constrained estimation technology. The performance of the new algorithm is confirmed with two illustrative examples."
  },
  {
    "year": "2017",
    "abstract": "The massive MIMO channel is characterized by non-stationarity and fast variation, thereby the channel state information obtained by traditional methods will be outdated and the system performance will be degraded. In this paper, we propose a channel prediction algorithm in massive MIMO environments. First, considering the channel characteristics, we propose a first-order Taylor expansion-based predictive channel modeling method. Then, a channel prediction algorithm consisting of the estimation stage and prediction stage is proposed and the interval of effective prediction (IEP) is derived. The performance of the proposed algorithm is testified by numerical simulations. It is shown that, within the IEP, a reliable channel prediction can be obtained with low computational complexity."
  },
  {
    "year": "2017",
    "abstract": "The volume of adult content on the world wide web is increasing rapidly. This makes an automatic detection of adult content a more challenging task, when eliminating access to ill-suited websites. Most pornographic webpage-filtering systems are based on n-gram, naïve Bayes, K-nearest neighbor, and keyword-matching mechanisms, which do not provide perfect extraction of useful data from unstructured web content. These systems have no reasoning capability to intelligently filter web content to classify medical webpages from adult content webpages. In addition, it is easy for children to access pornographic webpages due to the freely available adult content on the Internet. It creates a problem for parents wishing to protect their children from such unsuitable content. To solve these problems, this paper presents a support vector machine (SVM) and fuzzy ontology-based semantic knowledge system to systematically filter web content and to identify and block access to pornography. The proposed system classifies URLs into adult URLs and medical URLs by using a blacklist of censored webpages to provide accuracy and speed. The proposed fuzzy ontology then extracts web content to find website type (adult content, normal, and medical) and block pornographic content. In order to examine the efficiency of the proposed system, fuzzy ontology, and intelligent tools are developed using Protégé 5.1 and Java, respectively. Experimental analysis shows that the performance of the proposed system is efficient for automatically detecting and blocking adult content."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a hybrid chaotic biogeography-based optimization (HCBBO) for solving the sequence dependent setup times flowshop scheduling problem with the objective of minimizing the total weighted tardiness. First of all, a largest-order-value rule is employed to transform continuous vectors into discrete job permutations. Second, the chaotic theory and the problem-specific Nawaz-Enscore-Ham heuristic are applied to compose the initial population with the property of intensification and diversification. Third, an improved biogeography-based optimization is introduced to improve the global search ability by designing new migration and mutation schemes. Meanwhile, a further local search is proposed and embedded in HCBBO to enhance the quality of the elite habitats. In addition, an effective perturbation is applied to avoid the solutions getting trapped in the local optima. Computation comparison experiments of seven benchmark algorithms on the Taillard benchmark problems are provided to verify the efficiency of the proposed algorithm. From the experiment results, it can conclude that HCBBO beats other compared algorithms effectively with higher quality and robustness solutions."
  },
  {
    "year": "2017",
    "abstract": "Multi-party video conferencing (MPVC) is the next big opportunity for Internet streaming. Commercial MPVC solutions are either server-based or peer-to-peer (P2P)-based, which both have performance limitations. P2P technology is expected to dominate the MPVC platform. There are four requirements for a robust MPVC system: 1) realistic network assumptions; 2) realistic system settings; 3) multi-rate support; and 4) any-view support. Existing academic works study the problem from a theoretical perspective, and none of them meets all four requirements simultaneously. We design CoolConferencing, an overlay network for robust P2P MPVC. The core operations follow the easy-to-implement, robust, and resilient data-driven principle, which does not maintain complex global structures such as dissemination trees and can adapt to network dynamic distributedly and quickly. CoolConferencing is a robust system that meets all four requirements simultaneously. In addition, to the best of our knowledge, there is no existing work which examines its MPVC approach under various realistic network environments. We have evaluated CoolConferencing via an event-driven simulation. Compared with state-of-the-art video conferencing solutions, CoolConferencing achieves around 25% gain than Mutualcast and around 9% gain than Celerity in performance. Moreover, when the helper mechanism is enabled, CoolConferencing can easily exploit all available bandwidth to get optimal video transmission performance."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel dual-mode time-domain single-carrier (SC) index modulation (DM-SCIM) scheme, where the combination of two constellation modes carries information bits further to modulated symbols, hence increasing the transmission rate. Accordingly, the proposed DM-SCIM scheme is capable of attaining a higher transmission rate than the conventional SC and SCIM schemes, without imposing any additional performance penalty. Furthermore, in order to maintain the detection complexity low enough to be tractable at the handset receiver, a successive detection algorithm, comprising minimum mean-square error (MMSE)-based frequency-domain equalization and log-likelihood ratio detection, is developed for both the conventional SCIM and the proposed DM-SCIM schemes. We also derive the error-rate bound of the proposed DM-SCIM scheme under the assumption of a channel-uncoded scenario. Moreover, in order to further increase bandwidth efficiency, the proposed DM-SCIM scheme is extended to the scenario supporting faster-than-Nyquist signaling, where the symbol interval in the time domain is set to be smaller than that defined by the Nyquist criterion. Our simulation results demonstrate the explicit performance advantage of the proposed schemes over the existing SC schemes. It is also revealed that our DM-SCIM scheme is capable of achieving a significantly lower peak-to-average power ratio than orthogonal frequency division multiplexing (OFDM) and OFDM with index modulation, while benefiting from a high reliability, which is achievable by multipath diversity."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel transmission scheme based on constellation rotation and weighted fractional Fourier transform (WFRFT) is proposed to enhance the physical-layer security in polarization modulation (PM)-based dual-polarized satellite communications. Typically, by appropriately selecting the WFRFT order, the distribution of the signals processed by WFRFT can be close to Gaussian, which makes them difficult to be detected by eavesdroppers. However, once the signals are captured, it is possible for eavesdroppers to recover the information through the WFRFT order scanning method. To overcome this problem, in the proposed scheme, the constellation points are randomly rotated before the WFRFT operation, making it almost impossible to crack the WFRFT order. In this manner, the constellations are distorted, which is difficult for the eavesdropper to demodulate the signals accurately. Furthermore, a robust nonzero secrecy capacity is guaranteed. In addition, the impairment to the PM from the polarization-dependent loss effect is discussed, and a zero-forcing prefilter is applied at the receiver side to mitigate this adverse effect. Finally, the security performance of the proposed scheme is evaluated in terms of the average secrecy capacity and symbol error rate by numerical simulations in dual-polarized satellite communications."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a secure index and data symbol modulation scheme for orthogonal frequency division multiplexing with index modulation (OFDM-IM) systems. By exploiting the notion of the channel reciprocity in time division duplexing mode over wireless channels for shared channel state information as a secret key, we investigate randomized mapping rules for index modulation as well as data symbol modulation. Due to the randomized mapping rules for index and data symbol modulation in OFDM-IM, an eavesdropper is not able to correctly decide message bits even though active subcarriers and their symbols are correctly estimated. In particular, we exploit a characteristic of OFDM-IM which uses a fraction of subcarriers for transmissions to enhance security of data symbol modulation. In addition, to design a set of mapping rules for data symbol modulation, we investigate both a random-selection-based set and a bit-mismatch-based set. Through the analysis and simulation results, we demonstrate that the proposed scheme based on the randomized mapping rules for index modulation and data symbol modulation has a better performance than an existing scheme (modified for OFDM-IM) in terms of bit error rate (BER) and successful attack probability. In particular, we can show that the BER at an eavesdropper is much higher if the bit-mismatch-based set of mapping rules is used."
  },
  {
    "year": "2017",
    "abstract": "Community structure is an important mesoscale topological characteristic of complex networks, which is significant for understanding structural features and organizational functions in networks. Local expansion methods have been proved to be efficient and effective for community detection. However, it has been shown that there are inherent drawbacks for these methods to uncover overlapping communities. Most methods are sensitive to initial seeds and built-in parameters, while others are inadequate to reveal the pervasive overlaps. In this paper, we propose a new local expansion method for uncovering overlapping communities based on structural centrality. The key idea of our approach is to locate structural centers of communities with the structural centrality and then expand these structural centers with a weighted strategy and a local search procedure. Experimental results both on artificial and real-world networks demonstrate that our method is effective and promising in term of finding overlapping community structures. We also show that our local expansion strategies are efficient in uncovering cohesive clusters and producing stable clustering results."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an underlay cognitive radio system, which consists of a primary-user (PU) transmitter (TX), a PU receiver (RX), a secondary-user (SU) TX, and a SU_RX, is considered. Benefitting from the underlay mode, SU_TX can deliver its information to SU_RX by sharing the spectrum resource authorized to PU. It is assumed that SUs are equipped with a single transmitting antenna and a single receiving antenna, which are isolated, and work in full-duplex (FD) mode. By considering that the information signal transmitted from PU_TX to PU_RX may be eavesdropped by SU_TX if SU_TX is malicious, we investigate the secrecy outage performance of the PU system. The approximated closed-form expression for secrecy outage probability (SOP) and the lower boundary of the asymptotic SOP have been derived and verified by simulation results. Our results reveal the impact of the eavesdropping of the SU and the FD mode adopted at the SU transmitter on the secrecy performance of the PU system in underlay spectrum sharing mode."
  },
  {
    "year": "2017",
    "abstract": "Automated analysis of broadcast soccer game video is a challenging computer vision problem. Prior to performing high-level analysis (such as event detection), accurate classification of shot views and play-break segmentation are required to analyze the structure of soccer video. A novel deep network called parallel feature fusion network (PFF-Net) combines local and full-scene features to produce accurate shot view classification based on camera zoom and out-of-field status. Then, a novel hidden-to-observable Markov model (H2O-MM) is introduced to determine play/break status of the shots. Testing is performed using a variety of professional broadcast soccer videos. Variations of the PFF-Net are considered and compared with four existing methods where the PFF-Net demonstrates superior performance (92.6%). The H2O-MM has the accuracy of 98.7% for play-break segmentation, which is an improvement over two existing hidden Markov models. The new methods provide improved temporal labeling of broadcast soccer videos, which can be used to further improve overall automated event detection."
  },
  {
    "year": "2017",
    "abstract": "The emerging of social networks, e.g., Facebook, Twitter, and Instagram, has eventually changed the way in which we live. Social networks are acquiring and storing a significant amount of profile information and daily activities of over billions of active users. The data sets, drawn from the social networks, are becoming great sources for exploring and attracting huge interests from different research communities. However, publishing social network data sets have also raised serious security and privacy risks; it is highly likely that they will be targeted by the hackers due to their substantially commercial values. To deal with the problem of privacy leakage, a number of attack models and corresponding privacy preserving solutions have been proposed recently. A common approach is to anonymize the identities of the users when publishing the data sets while we argue that the remaining relationship is sufficient to identify an anonymized user. In this paper, we define a new type of attack as attribute couplet attack. The attribute couplet attack facilitates the relationship of a couplet of anonymous nodes (i.e., a pair of users) and some limited background information to unveil the protected identities. To achieve privacy-preservation under attribute couplet attacks, we propose a new anonymity concept as k-couplet anonymity. A social network data set satisfies the k-couplet anonymity if, for any pair of nodes, there exist at least the other k - 1 couplets sharing the same attributes. Then, we design and implement two heuristic algorithms to promote the k-couplet anonymity. Furthermore, we design an approximate algorithm for multiple-attribute social networks to realize the k-couplet anonymity. The evaluation results on multiple data sets demonstrate that the privacy and utility of the social network data sets can be well preserved, when incorporating the proposed k-couplet anonymity and the associate heuristic algorithms."
  },
  {
    "year": "2017",
    "abstract": "Addressing global challenges, such as climate change and other related environmental concerns, requires a rethink in the organization of production and consumption processes. This also includes electricity production and consumption. The need for greater competitiveness in the provision of critical infrastructure (including electricity) is also a challenge. This has led to the liberalization of many electricity markets across the world. In this paper, following an exploratory study of nine countries across Africa, Asia, and South America, the common features that characterize the electricity market liberalization process, as well as the key drivers of electricity sector reforms across the world, were established. These features were then used to highlight the main challenges of the Nigerian electricity sector and to provide an explanation of the key milestones that characterize the Nigeria’s electricity sector liberalization process (2001–2017). This paper further discusses five possible future models by which most electricity supply markets will be organized in the future. It concludes by proposing a new model for the organization of the Nigerian electricity industry that would not only aid in addressing the current electricity deficit challenge but also pave the way for the creation of a market structure that can drive Nigeria toward a secure energy future."
  },
  {
    "year": "2017",
    "abstract": "Channel reciprocity is one of the primary superiorities of time-division duplexing-based massive multiple-input multiple-output systems. However, the reciprocity of uplink and downlink cannot be realized due to inevitable radio-frequency (RF) impairments in practice. In this paper, in the presence of carrier frequency offset (CFO), quasi-static RF mismatch and channel estimation error, we derive the closed-form expressions of achievable rate for matched filter (MF) and zero-forcing (ZF) precoders. Herein, we concentrate on two oscillator setups, where all base station antennas share the same oscillator, namely, the common oscillator setup, or employ independent oscillator, namely, the distributed oscillator (DO) setup. Performance comparisons between two precoders and two setups are studied, respectively, and the asymptotic behaviors are further investigated both with and without CFO compensation. It is indicated that, the DO setup is preferable in the cases without CFO compensation, and vice versa. As for the precoding schemes, we show that with high SNR and low level of reciprocity errors, ZF precoder is asymptotically more desirable in the cases of DO setup without CFO compensation, or of both setups with CFO compensation, whereas MF precoder is competitive in the opposite cases with slightly worse performance. Numerical results demonstrate the correctness of our analytical expressions."
  },
  {
    "year": "2017",
    "abstract": "This paper analyzes the delivery delay of safety messages in vehicular networks with interconnected roadside units (RSUs) and gives a suggestion which forward mechanism should we adopt to obtain a smaller delay. In this paper, we develop a mathematical model in a sparse bidirectional highway scenario with interconnected RSUs, and analyze the safety messages delivery delay with general “store-carry-forward”mechanism and decelerating “store-carry-forward”mechanism, respectively. By comparing the average messages delivery delay with two mechanisms, we can determine whether the vehicles in opposite direction need to perform the decelerating “store-carry-forward”mechanism to obtain the smaller delivery delay, when the accident occurs in some location between two neighbor RSUs. In addition, we analyze the impact of different parameters on the average delivery delay with two mechanisms and the critical location. The critical location is the location where the accident occurs, the average messages delivery delays with two mechanisms are the same. At the critical location, the average messages delivery delay is the maximum value, given the inter-RSU distance. Thus, it can be the guidance for the RSU deployment as well, considering the time-constraint safety messages. Finally, the simulation results verify that our analytical results are correct and accurate."
  },
  {
    "year": "2017",
    "abstract": "Communication in remote locations, specially in high-latitude regions, such as the Arctic, is challenged by the lack of infrastructures and by the limited availability of resources. However, these regions have high scientific importance and require efficient ways of transferring research data from different missions and deployed equipment. For this purpose, unmanned aerial vehicles (UAVs) can be used as data mules, capable of flying over large distances and retrieving data from remote locations. Despite being a wellknown concept, its performance has not been thoroughly evaluated in realistic settings. In this paper, such a solution is evaluated through a field-experiment, exploiting the obtained results to define and implement an emulator for intermittent links. This emulator was designed as a mission planning tool, where we further analyze the impact of different flight trajectories when retrieving data. Additionally, we study the overall performance of 4 well-known file-transferring protocols suitable for a UAV being used as a data mule. Our analysis shows that trajectories at higher altitudes, despite increasing distance between nodes, improves communication performance. Moreover, the obtained results demonstrate that DTN2, using the bundle protocol, outperforms FTP, Rsync, and SCP, and that all these protocols are affected by the size of the files being transferred. These results suggest that, in order for the scientific community to practically use UAVs as data mules, further studies are required, namely on how different UAV trajectories can be combined with efficient file-transferring network protocols and well organized data structures."
  },
  {
    "year": "2017",
    "abstract": "Side channel attacks have become a major threat to hardware systems. Most modern digital IC designs utilize sequential elements which dominate the information leakage. This paper reports the first unified analysis and comprehensive comparison of known secure flip-flop circuits. We present a device level analysis of the information leakage from these FFs and propose several evaluation metrics to quantify their security. We show that simulated PA attacks that utilize the information evaluated by these metrics at the gate-level extract more information at the module-level."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the modified quadrature rules for 1-D hypersingular integrals, and then constructs the quadrature formulas to numerically evaluate multi-dimensional hypersingular integrals in the form of f .p. f.Ωg(x)/(Πi=1s|xi-ti|1+γi) Πi=1sdxi(s ≥ 2) with Ω = Πi=1s[ai, bi], 0 <; γi≤ 1 and ti∈ (ai, bi). The multi-parameter asymptotic error estimates are derived for three different situations. The error estimates illustrate that, if g(x) is 2l + 1 (l ≥ (γ0- 1)/2) times differentiable on the Ω, the order of convergence is O(h02k) for γi= 1 (i = 1, · · · , s) or O(h02k-γ0) for some 0 <; γi<; 1, (i = 1, · · · , p, p 0 s) and γp+j= 1 (j = 1, · · · , s - p) with γ0= max{γ1, · · · , γp}, h0= max{h1, · · · , hs}, where k is a positive integer determined by the integrand. To obtain more accurate approximate solution, the splitting extrapolation algorithms are proposed. Numerical experiments are provided to verify the theoretical estimates."
  },
  {
    "year": "2017",
    "abstract": "Drivers often park their vehicles without consciously (physically or mentally) noting down the parked location which makes it hard and inconvenient for the users to later locate their vehicles. Existing solutions either require users to explicitly note down the parked position on their mobile device by performing a certain action, such as pressing a button to turn on their global positioning system, or are erroneous and inaccurate. This paper attempts to build ParkSense, a system that allows a smart phone to accurately and automatically “sense,”and later navigate to, the position at which the vehicle was parked. We propose to make use of the variations of magnetic fields and electromagnetic fields inside the vehicles to detect when a user stops and turns off his or her vehicle. Our evaluation with an actual implementation of the system on different mobile platforms and operating systems, tested on different mobile devices/phones and car models, shows the detection accuracy of more than 90%, confirming the feasibility of our approach."
  },
  {
    "year": "2017",
    "abstract": "The main goal of proactive security is to prevent attacks before they happen. In modern information systems it largely depends on the vulnerability management process, where prioritization is one of the key steps. A widely used prioritization policy based only upon a common vulnerability scoring system (CVSS) score is frequently criticised for bad effectiveness. The main reason is that the CVSS score alone is not a good predictor of vulnerability exploitation in the wild. Therefore, the aim of the research in this field is to determine in what way we can improve our prediction abilities. Clearly, software vulnerabilities are commodities used by attackers. Hence, it makes sense considering their characteristics in vulnerability prioritization. In contrast, one should be able to measure and compare the effectiveness of various policies. Therefore, an important goal of this paper was to develop an evaluation model, which would allow such comparisons. For this purpose, we developed an agent-based simulation model which measures the exposure of information system to exploitable vulnerabilities. Besides, some policies which take into account human threats were defined and then compared with the most popular existing methods. Experimental results imply that the proposed policy, which is based on CVSS vectors and attacker characteristics, achieves the highest effectiveness among existing methods."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the design of an event-driven energy trading system among microgrids. Each microgrid can be either a provider or a consumer depending on the status of its energy generation and local demands. Under this approach, an aperiodic market model is newly proposed such that trading occurs when one of the consumers requests energy from the trading market. To promote the trading system, a consumer-side reward concept is introduced. The consumer makes a decision on the size of the posted reward to procure energy depending on its required energy level. Providers then react to this posted reward by submitting their energy bid. Accordingly, the posted reward is allocated to the providers in proportion to their energy bids. Moreover, for practical concerns, a transmission and distribution loss factor is considered as a heterogeneous energy trading system. The problem is then formulated as a non-cooperative Stackelberg game model. The existence and uniqueness of Stackelberg equilibrium (SE) are shown and the closed form of the SE is derived. Using the SE, an optimal trading algorithm for microgrids is provided. The stability of the energy trading system is verified due to the unique SE. In this approach, no expected waiting time for trading is required for sustaining an energy trading market."
  },
  {
    "year": "2017",
    "abstract": "The performance optimization problem is investigated for discrete-time control systems on a multi-core platform. An integrated approach which considers both control performance and real-time scheduling aspects is applied to allocate optimal periods to controller tasks. A real-time control system is modeled as a set of directed acyclic graphs with weighted edges in this paper. The system allows producer/consumer relationship between tasks, and the data dependence relationships between tasks are uncoupled by attaching harmonic constraints to task periods. The period assignment problem is formulated as an optimization problem, which minimizes the system performance loss index under multi-core schedulability constraints. A heuristic search algorithm is proposed to solve this optimization problem and select periods for real-time tasks scheduled by rate-monotonic scheduling algorithm. Experimental results demonstrate that the proposed heuristic algorithm is capable of finding a high quality local optimal solution with fast computing speed. The proposed method is applicable to online failure recovery and reconfiguration in real-time control systems."
  },
  {
    "year": "2017",
    "abstract": "Efficient communications are of paramount importance to improve public safety (PS) operations allowing better coordination, higher situation awareness, lower response times, and higher efficiency during emergency. Consequently, the evolution of PS communication networks toward commercial broadband networks is widely well accepted. However, this evolution has to cope with several challenges, such as the provision of sufficient communication capacity, coverage, and resilience as well as deployment costs and efficient exploitation of radio resources. This has triggered the need of new architectural solutions. In this paper, we propose a heterogeneous network communication architecture where both infrastructures and spectrum are shared between PS and commercial operators thus reducing deployment costs and times, and addressing the main challenges of PS communications. The shared radio access network (RAN) is managed by means of network slicing and resources virtualization. The proposed architecture is based on a three-tier scheduler that allows to manage different network layers and different RAN slices. Numerical results derived by means computer simulations are provided in order to highlight the efficiency and flexibility of the proposed architecture in comparison with benchmark alternatives."
  },
  {
    "year": "2017",
    "abstract": "Periodic grounded dc trees in cross-linked polyethylene under various dc prestressing times are investigated in the temperature range of 20 °C-80 °C. Space charge behaviors in the samples during dc prestressing are simulated based on the bipolar charge transport model. The results reveal that the dc prestressing time has different effects on the tree growth at different temperatures, which is because that the space charge behavior in the sample during dc prestressing is closely related to the dc prestressing time and the temperature, and it has both promotion effect and impedance effect on the tree growth. The moderate promotion effect and impedance effect under 160 s dc prestressing at 20 °C, and the strongest promotion effect and the weakest impedance effect under 240 s dc prestressing at 40 °C result in the largest tree lengths, widths, and accumulated damages under each corresponding condition. At 60 °C and 80 °C, the lengths, widths, and accumulated damages are the largest under 240 s dc prestressing, smaller under 80 s dc prestressing, and the smallest under 160 s dc prestressing, and the reason is believed to be the growth rates reversal during the tree growth. Also it is found that the dc prestressing time has significant effects on the tree shape at 60 °C and 80 °C, which is believed to be related to the wider charge diffusion range under longer dc prestressing time. The electrical tree characteristics are discussed in detail combined with the space charge behaviors."
  },
  {
    "year": "2017",
    "abstract": "We propose a new scheme to secure a wireless-powered untrusted cooperative-communication network, where a legitimate source node (Alice) transmits her information messages to a legitimate destination node (Bob) through the multiple amplify-and-forward untrusted relays. The relay nodes are assumed to be honest but curious nodes; hence, they are trusted at the service level but are untrusted at the information level. To reduce the energy consumption of the network, only one relay node is selected in each time slot to forward Alice's information signal. We assume a power-splitting-based energy-harvesting scheme, where each relay node splits its received signal into information and energy streams. Since the relay nodes are assumed to be untrusted at the information level, they attempt to decode the information intended to Bob while harvesting energy at the same time. When the relaying mode is selected, the scheme is realized over two non-overlapping time phases. To prevent any information leakage to the untrusted relay nodes, Bob and a cooperative jammer (John) inject jamming (artificial noise) signals during the first phase. During the second phase, the untrusted relay nodes that will not be forwarding the information signal must harvest energy to accumulate more energy to help Alice in future time slots. Moreover, the cooperative jammer will jam the untrusted relays to further power their batteries and prevent them from decoding the information-forwarding relay signal in case they decided to cheat and decode it. We model the battery state transitions at each relay as a finite-state Markov chain and analyze it. Our numerical results show the security gains of our proposed scheme relative to two benchmark schemes."
  },
  {
    "year": "2017",
    "abstract": "GNSS multi-frequency multi-system carrier phase differential positioning has become the main technology used in high-precision positioning. Until recently, the fault detection and exclusion (FDE) methods for multi-frequency multi-system carrier phase differential positioning mostly focus on procession of errors in the carrier phase domain, which cannot exclude all the faults causing a faulted baseline resolution, e.g., a fault that occurs in resolution process. Besides, the multi-fault of multi-frequency in the carrier phase domain cannot be identified due to the multi-frequency carrier phase observation errors' high correlation. We present a method of autonomous FDE based on multi-frequency multi-system carrier phase differential positioning. It focuses on the procession of errors in the position domain, and detects and excludes the faults in different frequency baseline resolutions caused not only by measurement fault as traditional method, but also the resolution fault, which can enhance the robustness and accuracy of the differential positioning system. The experimental results show that the method can effectively detect and exclude the failure of different frequency baseline resolutions and then the accurate multi-frequency multi-system positioning results can subsequently be effectively fused. The proposed method improves the accuracy and robustness of the differential positioning system."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the transceiver beamforming problem is studied for multipair two-way distributed relay networks, particularly with multi-antenna user nodes and in the presence of channel state errors. With multi-antenna setting on the user nodes, some of the usual signal processing tasks are shifted from the relay nodes to the user nodes with the proposed transceiver beamforming designs. The transmit beamforming vectors, distributed relay coefficients, and the receive beamforming vectors are obtained by iteratively solving three sub-problems, each having a closed-form solution. The tasks of maximizing desired signal power, and reducing inter-pair interference and noise are thus allocated to different iteration steps. By this arrangement, the transmit and receive beamformers of each user are responsible for improving its own performance and the distributed relay nodes with simple amplify-and-forward protocol aim at creating a comfortable communication environment for all user pairs. With respect to the channel uncertainty, two relay strategies are proposed considering two different requirements from the communication network: sum relay output power and individual relay output power. Our simulation demonstrates that the performance improvement can be very significant through cooperation of the three components, especially when the number of relay nodes is large."
  },
  {
    "year": "2017",
    "abstract": "In a conventional energy storage system in a grid-connected solar power stations, solar power is transferred to the grid through a PV-Inverter, and the battery is charged and discharged through a bi-directional converter. In this paper, a novel grid energy storage system for large-scale PV systems is discussed. With the proposed configuration, the battery charging and discharging are carried out through an AC voltage regulator which is connected in series to the line. For this system, cascaded H-bridge (CHB)-based PV-Inverter which is suitable for a high power application is selected. In case of failure in one H-Bridge of a CHB inverter, it is difficult to integrate solar inverter with the grid as the voltages of inverter and grid are not matched. Fault tolerant operation of the CHB-based PV-Inverter can also be achieved through the proposed configuration. In this paper, basic operation and control of a voltage regulator, application of the voltage regulator in grid energy storage systems, fault tolerant operation of a CHB inverter through the voltage regulator are presented. To validate the performance of the controls proposed, Real-time simulations are carried out by interfacing the simulated power circuit with the real controller card with the help of an Opal-RT make real-time simulator. Performance of the proposed system is analyzed through presented results."
  },
  {
    "year": "2017",
    "abstract": "A wideband omnidirectional patch antenna with filtering response is investigated in this paper. The circular patch antenna is centrally fed by a probe, with its TM01, TM02, and TM03modes simultaneously excited. Two ring slots are meticulously introduced into the patch and ground plane to merge the three modes of a kind, realizing a wide omnidirectionally radiating passband. The introduction of the slots also generates two radiation minimums at the lower and upper band-edges, leading to an enhanced suppression level in the stopbands. Hence, a compact wideband filtering patch antenna with quasi-elliptic bandpass response is obtained, without using any extra circuit. The proposed antenna has a low profile of 0.027 λ0, a 10-dB impedance bandwidth of 19.5%, an average gain of 7.5 dBi within passband, and an out-of-band suppression level of over 23 dB within stopband."
  },
  {
    "year": "2017",
    "abstract": "A concurrent dual-band six-port receiver based on real-valued time-delay neural network (RVTDNN) is proposed in this paper to retrieve two baseband signals from a dual-band radio frequency signal, concurrently. Different from the traditional six-port correlator, the new passive circuit correlator, which is composed of one power divider and three quadrature couplers, has three inputs and three outputs, resulting in the decreased hardware complexity as well as circuit size, and a reduced power consumption for the system. The new six-port correlator, its output power as well as the baseband signal recovery theory are described and analyzed in detail. The calibration algorithm based on the RVTDNN is adopted to verify the feasibility of the concurrent dual-band receiver based on the proposed correlator circuit. Finally, a practical wideband six-port receiver test bench, which operates from 2 to 3 GHz, is built and tested using the common modulated signals. The calculated error vector magnitudes are all less than 2% verifying the correctness of this novel system implementation approach."
  },
  {
    "year": "2017",
    "abstract": "Considering a wireless social network, we investigate a cooperative jamming scheme based on the space power synthesis with unknown channel state information (CSI) of eavesdroppers. In particular, we provide a multiple jammers-based anti-eavesdropping model and formulate it by a superposition principle of various jamming signals in a free space. Based on the model, we analyze the superimposed effects of jammers with different locations in a fixed area, and then present corresponding jamming schemes to minimize synthetic jamming power at a legitimate receiver but satisfying basic interference in other locations. Furthermore, we also provide power allocation schemes to maximize the worst-case secrecy rate of a legitimate receiver. Numerical simulation results demonstrate that the secrecy performance of our cooperative jamming schemes can satisfy the requirements of secure transmission in a fixed area. Besides, our proposed power allocation schemes can further improve secrecy rate without known exact CSI of eavesdroppers."
  },
  {
    "year": "2017",
    "abstract": "Unlike conventional resources, unconventional resources, such as shale gas and coal bed methane, are situated horizontally under geological formations. To exploit these resources, directional drilling and hydraulic fracturing technologies are required. In directional drilling, the dog leg severity (DLS), which indicates how much the angle changes while drilling 100 ft, is a major issue with respect to the cost and time of drilling. In this paper, we briefly review different types of directional drilling methods and propose a new hybrid-type rotary steerable system (RSS). DLS calculations based on three-point geometry for these systems are suggested. This hybrid RSS combining two conventional types of RSSs: point-the-bit and push-the-bit systems, achieves better steerability. The hybrid mechanism is implemented using hybrid pads with hydraulic cylinders and a spherical joint. The advantages of the proposed system are demonstrated by performing small-scale prototype and cement block drilling tests."
  },
  {
    "year": "2017",
    "abstract": "An efficient physical layer security technique, referred to as OFDM with subcarrier index selection (OFDM-SIS), is proposed for safeguarding the transmission of OFDM-based waveforms against eavesdropping in 5G and beyond wireless networks. This is achieved by developing a joint optimal subcarrier index selection (SIS) and adaptive interleaving (AI) design, which enables providing two levels (sources) of security in time division duplexing (TDD) mode: one is generated by the optimal selection of the subcarrier indices that can maximize the signal-to-noise ratio at only the legitimate receiver, while the other is produced by the AI performed based on the legitimate user's channel that is different from that of the eavesdropper. The proposed scheme not only provides a remarkable secrecy gap, but also enhances the reliability performance of the legitimate user compared with the standard OFDM scheme. Particularly, a gain of 5-10 dB is observed at a bit error rate value of 10-3compared with standard OFDM as a result of using the adaptive channel-based subcarrier selection mechanism. Moreover, the proposed technique saves power, considers no knowledge of the eavesdropper's channel, and provides secrecy even in the worst security scenario, where the eavesdropper can know the channel of the legitimate link when an explicit channel feedback is used as is the case in frequency division duplexing systems. This is achieved while maintaining low complexity and high reliability at the legitimate user, making the proposed scheme a harmonious candidate technique for secure 5G ultra reliable and low latency communications (URLLC) services."
  },
  {
    "year": "2017",
    "abstract": "Multi-view feature learning aims at improving the performances of learning tasks, by fusing various kinds of features (views), such as heterogeneous features and/or homogeneous features. Current leading multi-view feature learning approaches usually learn features in each view separately while not uncovering shared information from multiple views. In this paper, we propose a multi-view feature learning framework, which can simultaneously learn separate subspace for each view and shared subspace for all the views, respectively; specifically, the separate subspace for each view can preserve the particular information within this view, meanwhile, the shared subspace can capture feature correlation among multiple views. Both the particularity and communality are essential for classification. Furthermore, we relax the labels of training samples within the concatenated subspaces, thus resulting in the retargeted least square regression (LSR) classifier. The transformation matrices tailored for each subspace within the corresponding view and the label relaxed LSR classifier are jointly learned in a unified framework, based on an efficient alternative optimization manner. Extensive experiments on four benchmark data sets well demonstrate the superiority of the proposed method, which has led to better performances than compared counterpart methods."
  },
  {
    "year": "2017",
    "abstract": "A printed omnidirectional dipole array antenna with a radiated load is proposed and analyzed, which is fed by a coplanar waveguide. Flying lines and via-holes are used to connect dipoles to achieve a balanced feed. Simulated results by CST microwave studio®indicate that the operating band is 4.6 to 4.9 GHz with its reflection coefficient less than -10 dB. The omnidirectional gain in this band is higher than 4.23 dB and the antenna size is only 103.4mm × 12.6mm × 1.5mm. As a result, its gain per wavelength can reach a high value of 3.1 dB/λ at 4.7 GHz, which is conducive to antenna miniaturization and batch production. In order to effectively decrease the outer surface current on the coaxial feeder outer conductor, a printed choke is introduced, so that the antenna performance would not be affected by an even longer coaxial line. The bandwidth and gain are improved achieving 4.63-5.45GHz and 5.8dB, respectively. There is a broad application of the designed antenna for it not only can be used independently, but also can be integrated on the printed circuit board."
  },
  {
    "year": "2017",
    "abstract": "The growing interest in human-computer interaction has prompted research in this area. In addition, research has been conducted on a natural user interface/natural user experience (NUI/NUX), which utilizes a user's gestures and voice. In the case of NUI/NUX, a recognition algorithm is needed for the gestures or voice. However, such recognition algorithms have weaknesses because their implementation is complex, and they require a large amount of time for training. Therefore, steps that include pre-processing, normalization, and feature extraction are needed. In this paper, we designed and implemented a hand-mouse interface that introduces a new concept called a “virtual monitor”, to extract a user's physical features through Kinect in real time. This virtual monitor allows a virtual space to be controlled by the hand mouse. It is possible to map the coordinates on the virtual monitor to the coordinates on the real monitor accurately. A hand-mouse interface based on the virtual monitor concept maintains the outstanding intuitiveness that is the strength of the previous study and enhances the accuracy of mouse functions. In order to evaluate the intuitiveness and accuracy of the interface, we conducted an experiment with 50 volunteers ranging from teenagers to those in their 50s. The results of this intuitiveness experiment showed that 84% of the subjects learned how to use the mouse within 1 min. In addition, the accuracy experiment showed the high accuracy level of the mouse functions [drag (80.9%), click (80%), double-click (76.7%)]. This is a good example of an interface for controlling a system by hand in the future."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT), which is the inter-networking of a wide variety of physical devices, is widely used in our daily life. The exponential increase in the number of diverse devices has resulted in a significant increase in the volume, variety, velocity, and veracity of data (i.e., big data). These data present a large requirement on modern storage systems both for capacity and scale, and energy cost has become a critical problem. For storage clusters, much research effort has been invested in alleviating this problem by providing suitable resource capacity (i.e., on-demand providing). However, it is challenging to match the offered resource capacity with the real system workloads, thus resulting in a violation of service level agreement. By considering a storage cluster as a queueing system, this paper proposes a QoS-oriented capacity provisioning mechanism. Based on workload features, the mechanism models the pattern of current workloads as a suitable queueing model. In accordance with the model, our mechanism can well forecast the actual resource capacity demand without violating the service level agreement, and then offer the required resource capacity in terms of the real workloads. Experimental results demonstrate that the proposed mechanism significantly reduces the energy consumption of a typical storage cluster, while meeting the QoS requirements. It also significantly outperforms two classic and two state-of-the-art capacity provisioning mechanisms."
  },
  {
    "year": "2017",
    "abstract": "There are a lot of mixed pixels in the remotely sensed imagery, which can seriously limit the utility of classification. Sub-pixel mapping (SPM) is a promising technique to solve this problem. It can generate a fine resolution land cover map from coarse resolution fractional images by predicting the spatial locations of different land cover classes at sub-pixel scale.However, the accuracy and detail are always limited. Especially when the scale factor is large among sub-pixels per pixel, the data volumes are amplified and the sub-pixel distribution becomes complex. The traditional methods are carried out only by the fractions of land cover and the spatial dependence theory, which cannot satisfy the requirement of the SPM. For avoiding the above flaw, a new SPM method based on maximum a posteriori (MAP) model with subpixel/pixel spatial attraction theory aimed at the largescale factor is proposed. First, MAP is proposed to improve the resolution of the fractional images and obtain the initial sub-pixel locations; after that, the pixel swapping algorithm is used to optimize and produce the final SPM result. In this paper, the proposed model is tested by a simple simulated font image and real remotely sensed imagery, which can both demonstrate that it can outperform traditional algorithm with a more accurate sub-pixel scale land cover map."
  },
  {
    "year": "2017",
    "abstract": "Due to the unique properties of field confinement and enhancement, spoof surface plasmon polaritons (SPPs) are considered as special modes to break many challenges in traditional electronic and microwave engineering. Ultrathin corrugated metallic structure offers an easy fabrication method to realize spoof SPP waveguides on substrate, and has been proved to have many merits in recent years. Lately, a programmable and coding spoof SPP waveguide loaded by active elements was presented, which makes it possible to control SPPs in real time. However, this programmable SPPs waveguide suffers from the limited loadable space and hence can hardly achieve more complex controlling functions. On the other hand, the existing methods to excite spoof SPPs require large conversion structures, which are unadoptable in modern integrated circuits. In this paper, we propose a new type of spoof SPP waveguide composed of a metallic strip and corrugated ground with an open loadable space for large-scale and complex controlling networks. A new conversion structure is presented to achieve high-efficiency transition from the traditional microstrip to the SPP waveguide without using extra space. Both numerical simulations and experiments indicate the outstanding performance of the new spoof SPP waveguide. The proposed structure is also convenient to connect with active devices due to its multi-conductor nature. Hence, the proposed structure may find wide applications in SPP-based integrated circuits and systems in the future."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the iterative learning control issue for multi-input multi-output singular distributed parameter systems (SDPSs) with parabolic and hyperbolic type, which described by coupled partial differential equations with singular matrix coefficients. Initially, applying the singular value decomposition theory to SDPSs, an equivalent dynamic decomposition form is derived. Then, the estimation of the relationship between the learning system substates and output tracking error are constructed in the light of P-type update learning scheme under some assumptions. Moreover, two sufficient conditions are presented to ensure that the tracking error is convergent in the sense of L2norm by employing the contracting mapping principle as well as some basic differential inequalities. Finally, two numerical examples are shown to demonstrate the validity of the developed theoretical results."
  },
  {
    "year": "2017",
    "abstract": "A delay/disruption tolerant network (DTN) architecture where a “store-carry-forward”strategy is adopted for data transmissions can be utilized in vehicular ad hoc networks (VANETs). The key point of routing in DTN-enabled VANETs is to choose the best node and determine the best time to forward messages. Time-space graph models provide an idea of converting the dynamic routing problems into static ones in deterministic DTNs. But it is a challenge to predict vehicles' future positions in order to obtain the time-space graph. In this paper, to achieve the cost-efficient and reliable routing in DTN-enabled VANETs, a novel timeliness-aware trajectory data mining algorithm is proposed to predict nodes' future positions. A sparse time-space graph is then obtained, based on which, two routing heuristics are proposed. Simulation results demonstrate that our proposed routing algorithms ensure low cost and high reliability over time."
  },
  {
    "year": "2017",
    "abstract": "Social users can be flexibly covered by a vehicle traveling along a certain trajectory in a city. This scenario provides opportunities for marketers to utilize vehicles as recommenders targeting potential customers. As a result, the vehicle social network (VSN) concept emerges. Since a marketer usually operates from a remote central office (CO), an effective communication system is urgently required to support data transmission between VSNs and COs. Orthogonal frequency division multiplexing (OFDM) is a modulation technique characterized by high spectral efficiency and dispersion resistance, and intensity modulation and direct detection (IM/DD) is an effective solution for optical OFDM (OOFDM) data transmission. Performing discrete Fourier transform (DFT) and discrete Hartley transform (DHT) operations can enable the satisfaction of various transmission requirements between a VSN and a CO. In this paper, we support the above claims through theoretical and simulation-based analyses. Moreover, a software-reconfigurable platform is established to achieve flexibility between DFT and DHT functionalities. Thus, diverse transmission requirements can be satisfied by modifying individual modules deployed in a single smart system instead of using multiple rigid network architectures. Simulated and experimental results both demonstrate the feasibility and effectiveness of our solutions."
  },
  {
    "year": "2017",
    "abstract": "After the vision and the overall objectives of future wireless networks for 2020 and beyond have been defined, standardization activities for fifth generation (5G) wireless networks have been started. Although it is expected that 5G new radio (NR) will be based on cyclicly prefixed orthogonal frequency division multiplexing (CP-OFDM)-based waveforms along with multiple waveform numerologies, the sufficiency of CP-OFDM-based NR is quite disputable due to the continuing massive growth trend in number of wireless devices and applications. Therefore, studies on novel radio access technologies (RATs) including advanced waveforms and more flexible radio accessing schemes must continue for future wireless networks. Generalized frequency division multiplexing (GFDM) is one of the prominent non-CP-OFDMbased waveforms. It has recently attracted significant attention in research because of its beneficial properties to fulfill the requirements of future wireless networks. Multiple-input multiple-output (MIMO)-friendliness is a key ability for a physical layer scheme to satisfactorily match the foreseen requirements of future wireless networks. On the other hand, the index modulation (IM) concept, which relies on conveying additional information bits through indices of certain transmit entities, is an emerging technique to provide better spectral and energy efficiency. In this paper, considering the advantages of non-CP-OFDMbased waveforms and the IM concept, we present a framework, which integrates GFDM with space and frequency IM schemes to provide flexible and advanced novel RATs for future wireless networks. Several MIMO-GFDM schemes are provided through the proposed framework and their bit error ratio performances, computational complexities, and spectral efficiencies are analyzed. Based on the obtained results, a guideline for selecting the proper MIMO-GFDM scheme considering target performance criterion is given. It has been demonstrated that the proposed framework has a ..."
  },
  {
    "year": "2017",
    "abstract": "Along with the adaptation of Internet of Things (IoT) to support various industrial applications, the cooperation and coordination of smart things is a promising strategy for satisfying requirements that are beyond the capacity of any single smart thing. To address this challenge, a two-tier IoT service framework is proposed, where the functionalities provided by smart things are encapsulated into IoT services, which are categorized into service classes. The service network is constructed by considering the invocation possibility between service classes, and service class chains are generated using traditional Web service composition techniques, where the functional specification of certain requirements is considered. Considering factors, such as spatial and temporal-constraints, energy efficiency, and the configurability of IoT services, selecting IoT services for the instantiation of service classes contained in chains is reduced to a multiobjective and multiconstrained optimization problem. Heuristic algorithms, such as the genetic algorithm (GA), ant colony optimization (ACO) and particle swarm optimization (PSO), are adopted to search for optimal IoT service compositions. An experimental evaluation shows that PSO performs better than the GA and ACO in searching for approximately optimal IoT service compositions and reduces the energy consumption, thus prolonging the network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Overlapped frequency division multiplexing (OVFDM) systems can obtain high spectral efficiency (SE), which is proportional to the constraint length. However, high decoding complexity imposes the main challenge on OVFDM systems. This paper proposes a low-complexity sliding window (SW) block decoding algorithm for OVFDM systems, where data symbols are estimated based on the reception of a SW instead of a date frame. Specifically, block code of each SW is decoded by bit-flipping algorithm where the bits to be flipped are selected according to the largest absolute value criterion. Using this criterion, the complexity to obtain the near optimal bit-flipping vector grows only linearly with the SW length. In addition, the study of the decoding algorithm is based on the design of OVFDM encoding structure, where symbols can occupy orthogonal in-phase and quadrature channels simultaneously to further improve SE by a factor of two. Simulation results show that OVFDM SW decoding with bit-flipping algorithm can be used when constraint length is relatively high (constraint length ≥ 20) because the complexity goes roughly linearly with the increase of constraint length."
  },
  {
    "year": "2017",
    "abstract": "Millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) with hybrid precoding is a promising technique for the future 5G wireless communications. Due to a large number of antennas but a much smaller number of radio frequency chains, estimating the high-dimensional mmWave massive MIMO channel will bring the large pilot overhead. To overcome this challenge, this paper proposes a super-resolution channel estimation scheme based on 2-D unitary ESPRIT algorithm. By exploiting the angular sparsity of mmWave channels, the continuously distributed angle of arrivals/departures (AoAs/AoDs) can be jointly estimated with high accuracy. Specifically, by designing the uplink training signals at both base station and mobile station, we first use low pilot overhead to estimate a low-dimensional effective channel, which has the same shift-invariance of array response as the high-dimensional mmWave MIMO channel to be estimated. From the low-dimensional effective channel, the super-resolution estimates of AoAs and AoDs can be jointly obtained by exploiting the 2-D unitary ESPRIT channel estimation algorithm. Furthermore, the associated path gains can be acquired based on the least squares criterion. Finally, we can reconstruct the high-dimensional mmWave MIMO channel according to the obtained AoAs, AoDs, and path gains. Simulation results have confirmed that the proposed scheme is superior to conventional schemes with a much lower pilot overhead."
  },
  {
    "year": "2017",
    "abstract": "Although particle swarm optimization (PSO) in its standard form performs extremely well for less complicated convex optimization problems involving reduced search space, it fails in finding global optimal solutions for more complicated nonconvex optimization problems with multiminima functions, thus exploring the promising search space less efficiently to ensure solution with superior quality. Guaranteeing the location of the global optimum through PSO becomes strenuous. The inherited premature convergence problem of PSO becomes more prominent while handling, especially the complex nonconvex problems. However, PSO has the ability to hybrid with other optimization techniques to ensure optimal global solution, better convergence characteristics, computational efficiency, and so on, while dealing with complex nonconvex problems. After presenting a detailed survey of the variants of PSO (involving variations in the basic structure of PSO) in part I, part II of this paper now comprehensively details all the hybrid forms (purely) of PSO applied to a constrained economic dispatch problem. How PSO overcomes its premature convergence problem while hybridizing with other optimization techniques is well-highlighted."
  },
  {
    "year": "2017",
    "abstract": "The problem of jointly estimating carrier frequencies and their corresponding two-dimension direction of arrivals (DOA) of band-limited source signals is considered in this paper for cognitive radio. The main problem of estimating carrier frequencies spread over a wideband spectrum is the requirement of high sampling rates. Thus, the Kalman filters are applied in the spatial domain instead of the temporal domain in the proposed algorithm to relax hardware complexity. The proposed algorithm exploits both the azimuth and elevation angles instead of a single DOA to increase the spatial capacity. Two approaches are proposed using two different types of nonlinear Kalman filter: extended Kalman filter (EKF) and unscented Kalman filter (UKF). Using simulations, the factors that affect the performance of both the filters are discussed. Scaling the estimated parameters to the same range and the proper tuning and initialization of the filters are crucial factors to prevent the filter divergence. Although UKF is supposed to have a better performance than EKF, reducing the inter-element spacing of the employed arrays and the proper filter initialization can make EKF approach the performance of UKF. On the other hand, UKF suffers from high processing time. Overall, both filters are able to converge to the true values of the unknown parameters using a number of relaxed analog-to-digital converters equal to the number of the array elements in the employed arrays. However, the approaches can detect a number of source signals higher than one-third of the total number of the array elements."
  },
  {
    "year": "2017",
    "abstract": "We deal with the problem of detecting frequent items in a stream under the constraint that items are weighted, and recent items must be weighted more than older ones. This kind of problem naturally arises in a wide class of applications in which recent data is considered more useful and valuable with regard to older, stale data. The weight assigned to an item is, therefore, a function of its arrival timestamp. As a consequence, whilst in traditional frequent item mining applications we need to estimate frequency counts, we are instead required to estimate decayed counts. These applications are said to work in the time fading model. Two sketch-based algorithms for processing time-decayed streams have been recently published independently near the end of 2016. The Filtered Space Saving with Quasi-Heap (FSSQ) algorithm, besides a sketch, also uses an additional data structure called quasi-heap to maintain frequent items. Forward Decay Count-Min Space Saving (FDCMSS), our algorithm, cleverly combines key ideas borrowed from forward decay, the Count-Min sketch and the Space Saving algorithm. Therefore, it makes sense to compare and contrast the two algorithms in order to fully understand their strengths and weaknesses. We show, through extensive experimental results, that FSSQ is better for detecting frequent items than for frequency estimation. The use of the quasi-heap data structure slows down the algorithm owing to the huge number of maintenance operations. Therefore, FSSQ may not be able to cope with high-speed data streams. FDCMSS is better suitable for frequency estimation; moreover, it is extremely fast and can be used in the context of high-speed data streams and for the detection of frequent items as well, since its recall is always greater than 99%, even when using an extremely tiny amount of space. Therefore, FDCMSS proves to be an overall good choice when considering jointly the recall, precision, average relative error and the speed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an efficient algorithm, termed as progressive sparse spatial consensus, for mismatch removal from a set of putative feature correspondences involving large number of outliers. Our goal is to estimate the underlying spatial consensus between the feature correspondences and then remove mismatches accordingly. This is formulated as a maximum likelihood estimation problem, and solved by an iterative expectation-maximization algorithm. To handle large number of outliers, we introduce a progressive framework, which uses matching results on a small putative set with high inlier ratio to guide the matching on a large putative set. The spatial consensus is modeled by a non-parametric thin-plate spline kernel; this enables our method to handle image pairs with both rigid and non-rigid motions. Moreover, we also introduce a sparse approximation to accelerate the optimization, which can largely reduce the computational complexity without degenerating the accuracy. The quantitative results on various experimental data demonstrate that our method can achieve better matching accuracy and can generate more good matches compared to several state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Data collection is the core function of underwater acoustic sensor networks (UASNs). Lately, ambulatory data gathering methods are being popularized in real applications. However, due to present mobile underwater data collection investigations that are on the basis of 2-D scenarios, the associated approaches are not suitable for 3-D UASNs. Additionally, mobile-element-assisted data collection usually brings special issues on obstacle avoidance. Accordingly, we propose a probabilistic neighborhood location-point covering set-based data collection algorithm with obstacle avoidance for 3-D UASNs. The proposed algorithm initially generates a space lattice set to establish the probabilistic neighborhood location-point covering set for data collection, so as to optimize the data collection latency. Then, an autonomous underwater vehicle traverses only location points in the constructed covering set with a hierarchical grid-based obstacle avoidance strategy. The simulation experiments are performed to verify the proposed algorithm compared with other existing underwater data collection algorithms. Simulations show that our proposed algorithm achieves better performance in terms of data collection latency, data collection efficiency, and obstacle avoidance."
  },
  {
    "year": "2017",
    "abstract": "Web conversational services are exposed to several threats in which the social context between communicating participants is manipulated. Cybercrimes based on identity misrepresentation to obtain sensitive information are on the rise. Various scams and frauds are conducted by distributing malicious content, viruses, and spam over established communication sessions. In order to maintain overall security and enhance privacy, methods of estimating trustworthiness and reputation should be built into Web calling services. In this paper, we propose “TrustCall”a reputation-based trust model for real-time Web conversational services. In our approach, the reputation of a caller is evaluated using Authenticity Trust and Behavioral Trust. Authenticity Trust describes the legitimacy of a caller by collecting recommendations from other members of the network, whereas Behavioral Trust determines a caller's popularity based on its communication behavior. Other contributions include a threat taxonomy for Web calling services, including social threats, that directly target users. A set of experiments are conducted in order to prove the feasibility and effectiveness of our model."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we devise a novel steganography algorithm that has a high capacity while still retaining the ability of adjusting the embedding distortion. A shifting strategy is explored to embed the secret data into a given 3-D model effectively. In order to reduce the embedding distortion, we propose a truncated space of data instead of directly working on the critical geometric information from vertices of the cover model. The truncated space confines the distortion of each component of the stego-model within the space that means the embedding distortion could be controlled within a very low threshold. In theory, we can set the length of data truncation to adjust the embedding distortion below a specified level, at the cost of losing certain embedding capacity. Moreover, the embedding capacity is irrelevant to the shape of models, and the quality of the stego-model is mostly dependent on the length of truncation rather than the quantity of embedded secret data. The proposed 3-D steganography method has the capability to control the level of embedding distortion, and at the same time, has a high embedding capacity. Various experiments have demonstrated the flexibility and high performance of our new approach."
  },
  {
    "year": "2017",
    "abstract": "Providing efficient anonymous authentication in vehicular ad hoc networks (VANETs) is a challenging issue. Identity-based signature schemes have been used to provide privacy-preserving authentication effectively for VANETs. In such scenario, mutual authentication between vehicles is critical to ensure only legitimate vehicles can involve in the inter-vehicle communication, and how to resist denial-of-service attack should be carefully addressed due to the regionally central signature verification in vehicle-road-side communications. In this paper, we propose a conditional privacy-preserving mutual authentication framework with denial-of-service attack resistance called MADAR. The authentication framework combines different identity-based signature schemes and distinguishes inner-region and cross-region authentications to increase efficiency. Beyond the privacy preservation and non-repudiation achieved by the existing framework, our authentication framework provides asymmetric inter-vehicle mutual authentication and strength-alterable computational DoS-attack resistance. We have formally proved the privacy preservation, unlinkability, mutual authenticity, and correctness of pseudonym with ProVerif, and analyzed other security objectives. The performance evaluations are conducted and the results demonstrate that our framework can achieve these security objectives with moderate computation and communication overheads."
  },
  {
    "year": "2017",
    "abstract": "The broadcast nature of energy harvesting wireless sensor networks (EH-WSNs) allows sensor nodes (SNs) within the coverage range of a transmitter to capture its signals. However, an EH-WSN is vulnerable to eavesdropping and signal interception; therefore, security in the EH-WSNs is of significant interest, and this issue has been addressed over many years. However, no work has studied the existence of a friendly jammer to mitigate the security impact. Thus, this paper proposes a model and optimization scheme that uses a wirelessly powered friendly jammer to improve secrecy in EH-WSNs. The considered EH-WSN model includes multiple power stations, multiple SNs (sources) and their base station, a friendly jammer, and multiple passive eavesdroppers. We divide the model into two phases: 1) the power stations transfer RF energy to the source SNs and 2) the source SNs transmit information to their base station, while a friendly jammer generates jamming signals against multiple eavesdroppers. Using statistical characteristics of the signal-to-noise ratio, the closed-form expressions of the existence probability of the secrecy capacity and secrecy outage probability are derived. We also propose an optimal sensor scheduling scheme to enhance physical layer secrecy (i.e., best-node scheduling), and we demonstrate our method's superior performance compared with a conventional round-robin scheduling scheme. The analysis of the simulation results supports our hypothesis, which is in line with Monte Carlo simulations."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) has been widely used in various application domains including smart city, environment monitoring and intelligent transportation systems. Thousands of interconnected IoT devices produce an enormous volume of data termed as big data. However, privacy protection has become one of the biggest problems with the progress of big data. Personal privacy is usually challenged by the development of technology. In this paper, we focus on privacy protection for location trajectory data, which is collected in intelligent transportation system. First, we demonstrate that the moving preference of individuals can be exploited to perform re-identification attacks, which may cause serious damage to the identity privacy of users. To address this re-identification problem, we present a new trajectory anonymity model, in which the degree of correlation between parking locations and individuals is precisely characterized by a concept of Location Frequency-inverse user frequency (LF-IUF, for short). We then propose an anonymizing method to replace parking locations by a k-correlation region. Our method provides a novel anonymity solution for publishing trajectory data, which achieves a better trade off between privacy and utility. Finally, we run a set of experiments on real-world data sets, and demonstrate the effectiveness of our method."
  },
  {
    "year": "2017",
    "abstract": "This paper describes the development of Pathfinder-an autonomous guided vehicle intended for the transportation of material in hospital environments. Pathfinder is equipped with the latest industrial hardware components and employs the most recent software stacks for simultaneous localization, navigation, and mapping. As the most significant contribution to the current robotics development, powerlink interface enabling direct data transfers between robot operating system and powerlink compatible hardware was developed. This combination is in our best knowledge reported here for the first time and the results with comprehensive tutorial were made publicly available as a GitHub repository. The capabilities of Pathfinder were explored during preliminary on-site tests in local hospital. From experimental results in a hospital it was confirmed that the robot can move along its global path, and reach the goal without colliding with static and moving objects."
  },
  {
    "year": "2017",
    "abstract": "An adaptive model predictive controller with a new scheduling scheme for turbofan engines is proposed, which can transfer engine from one working state to the others within the flight envelope. First, the flight envelope is divided into several sections according to the engine inlet parameters, and the nominal points in each section are determined, respectively. Then, considering the requirements of the turbofan engines, a constrained linear model predictive control algorithm is improved, and a series of constrained predictive controllers are designed based on the linear models at different nominal points. Furthermore, a novel scheduling scheme with two layers is constructed, where the first layer is the flight envelope scheduling layer that introduces fuzzy membership degree logic to distribute the weights of all nominal predictive controllers, and the second layer is the power scheduling layer by adopting a linear interpolation method. Simulation results show that the proposed scheduling scheme can coordinate these two layers to realize the steady-state and transition-state control of the turbofan engines at off-nominal points within the envelope, which provides an effective approach for the design of the adaptive controllers."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the problem of delay-dependent stability for discrete-time systems with time-varying delays. A novel augmented Lyapunov-Krasovskii functional is proposed in deriving stability criteria in which the feasible region is enhanced. Also, an improved summation inequality is developed and applied to find the lower bound of summation inequalities. Via two numerical examples, improved results will be shown by comparing with maximum delay bounds."
  },
  {
    "year": "2017",
    "abstract": "Cyber-physical systems (CPS) have the great potential to transform people's lives. Smart cities, smart homes, robot assisted living, and intelligent transportation systems are examples of popular CPS systems and applications. It is an essential but challenging requirement to offer secure and trustworthy real-time feedback to CPS users using spectrum sharing wireless networks. This requirement can be satisfied using collaborative spectrum sensing technology of cognitive radio networks. Despite its promising benefits, collaborative spectrum sensing introduces new security threats especially internal attacks (i.e., attacks launched by internal nodes) that can degrade the efficiency of spectrum sensing. To tackle this challenge, we propose a new transferring reputation mechanism and dynamic game model-based secure collaborative spectrum sensing strategy (TRDG). More specifically, a location-aware transferring reputation mechanism is proposed to resolve the reputation loss problem caused by user mobility. Furthermore, a dynamic game-based recommendation incentive strategy is built to incentivize secondary users to provide honest information. The simulation experiments show that the TRDG enhances the accuracy of spectrum sensing and defends against the internal attacks effectively without relying on a central authority."
  },
  {
    "year": "2017",
    "abstract": "The multi-tier heterogeneous network (HetNet) architecture can potentially address the massive connectivity and high throughput demands of the emerging fifth generation (5G) of wireless networks. However, the inter-tier interference in HetNets is considered to be a major performance bottleneck. This paper proposes a geometry-based three-dimensional (3-D) stochastic channel model for the spatial characterization of the sum interference in a two-tier HetNet with small cells in tier-1 overlaid with massive multiple-input-multiple-output equipped macro-cell base stations in tier-2. The angular spreads of the interference and the desired signals are analyzed by using the theory of 3-D multipath shape-factors and analytical expressions are derived for their second-order fading statistics, viz: level-crossing-rate (LCR), average-fade-duration (AFD), spatial autocovariance, and the coherence distance. Further, analytical expressions to investigate the second-order fading statistics against signal-to-interference ratio are also derived. The validation of the derived analytical expressions is established through a comparison with computer-based simulations. To provide insights into the network sum interference mechanism, the LCR and AFD expressions are derived for the special case when the rate of fluctuation of the desired signal is much higher than that of the interference signal and vice versa. Furthermore, the impact of the model's physical parameters, such as the link distance and the receiver's direction of motion as well as the fading distribution parameters such as its intensity and shape factors on the fading statistics of the interference are evaluated. These results demonstrate that the elevation angle has a significant impact on the interference characterization in HetNet architectures such that it cannot be ignored in modeling emerging 5G communication scenarios."
  },
  {
    "year": "2017",
    "abstract": "Most existing deadlock prevention studies on flexible manufacturing systems (FMSs) resort to Petri nets (PNs) by designing controllers for them. PNs are an effective tool for analyzing and modeling the dynamic behavior of FMSs. As an important subclass of PNs, the system of simple sequential processes with resources (S3PR) can be used to model many FMSs. This paper proposes a novel resource configuration method based on structural analysis to ensure the liveness of an S3PR. The restrictive relation between the initial marking of the process idle places and a special PN structure called strongly connected characteristic resource sunnets (SCCRSs) is first explored by employing the corresponding relation between SCCRSs and their related strict minimal siphons. With the structural properties of SCCRSs, functions invoked to compute the configuration marking for the resource places in an SCCRS are established. Then, an algorithm for computing a configuration marking in an S3PR is developed, and a resource configuration tree is correspondingly generated according to the execution of the developed algorithm. Thus, the liveness of the configured system is ensured, while the siphon enumerations are avoided. It is shown that the computational complexity of the developed algorithm is polynomial, which is more efficient than other existing ones. Examples are finally provided to illustrate the mentioned results."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with the optimal control problem for the zinc electrowinning (EW) process during the current switching period. A mathematical model is developed to reveal the dynamic characteristics of the whole plant of the zinc EW process and an energy consumption model is established to set the expected set points of the concentrations of the zinc ion and the sulfuric acid under different current. Furthermore, an optimal control problem is constructed in the light of free initial time, free terminal time, and fixed system switching time during the zinc EW process. A novel time-scaling transformation-based control parametrization method is introduced to transform the optimal control problem into a multiple parameters optimization selection problem, which can be effectively solved by the optimization algorithm. The applications on the EW process of a zinc hydrometallurgy plant demonstrate the validity of proposed method."
  },
  {
    "year": "2017",
    "abstract": "Software-defined networking (SDN) is a promising technology that can resolve the challenges faced by vehicular networks. However, the OpenFlow-based SDN implementations can only provide a protocol-dependent data plane. This can restrict the effectiveness of software-defined vehicular networks, since special-purpose protocols that have not been standardized in OpenFlow specifications are used frequently in vehicular networks. To address this issue, this paper studies how to realize a protocol-independent data plane by leveraging the protocol oblivious forwarding (POF). Specifically, we present the design of a software-based POF switch (PVS) that supports runtime protocol customization in principle. We implement PVS in a switch box, and propose a flow table management scheme to ensure high-throughput packet forwarding. The experimental results verify that PVS can achieve line-rate packet forwarding at 10 Gbps when the packets' size is 512 B, and the proposed flow table management scheme is effective."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a methodology for the joint capacity optimization of renewable energy (RE) sources, i.e., wind and solar, and the state-of-the-art hybrid energy storage system (HESS) comprised of battery energy storage (BES) and supercapacitor (SC) storage technology, employed in a grid-connected microgrid (MG). The problem involves multiple fields, i.e., RE, battery technology, SC technology, and control theory, and requires an efficient and precise co-ordination between sub-fields to harness the full benefits, making the problem labyrinthine. The optimization problem is formulated, and it involves a variety of realistic constraints from both hybrid generation and storage, and an objective function is proposed to: 1) minimize the cost; 2) improve the reliability; and 3) curtail greenhouse gases (GHG) emissions. The complex optimization problem is solved innovatively in piecewise fashion to decrease the complexity and computational time. First, sizes of solar photovoltaic (PV) and wind turbine (WT) are determined using an innovative search algorithm, and in the second step, the size of HESS is calculated, finally the optimal solution is determined. A comparison based upon cost, reliability, and GHG emissions is presented which plainly shows the effectiveness of the proposed methodology. The technique is also applied to determine the size of an MG employing PV, WT, and BES operating in grid-connected mode. And a brief cost analysis, reliability assessment, and emission reduction are given for three scenarios: 1) MG with HESS; 2) MG with BES; and 3) MG with conventional generation. It is shown that an MG with HESS is not only economical but also more reliable and has lower GHG emissions."
  },
  {
    "year": "2017",
    "abstract": "A compact filtering switch with wide-stopband responses is presented in this paper. The resonator is designed using microstrip transmission lines and lumped capacitors. It is utilized to shift up the second harmonic frequency for wide-stopband performance and miniaturize the circuit size. In the ON-state, the circuit is the same as the bandpass filter without signals passing through the p-i-n diode, which avoids additional loss introduced by p-i-n diode. Two transmission zeros are generated near the passband to enhance the skirt selectivity. In the off-state, the signals from port 1 to port 2 passing through different transmission path are cancelled out, resulting in high isolation. For demonstration, a filtering switch operating at 780 MHz is implemented with the compact size of 0.072λg×0.066λg. More than 20-dB suppression levels are measured from 0.89 to 5.3 GHz (6.8 f0), featuring wide-stopband responses."
  },
  {
    "year": "2017",
    "abstract": "In this paper we analyze the bounds on the reliability of RaptorQ codes under maximum likelihood decoding, especially in the finite-length regime. RaptorQ code ensembles by a high-order low density generator-matrix (LDGM) code as pre-code and an inner Luby transform (LT) code. By investigating the rank of the product of two random coefficient matrices of the high-order LDGM code and the inner LT code, we derive the expressions for the upper and lower bounds of decoding failure probability (DFP) on the RaptorQ code. Then, the accuracy of our derived theoretical bounds are verified through the Monte Carlo simulations with different degree distributions and short packets. The high accuracy bounds are then exploited to design near-optimum finite-length RaptorQ codes, enabling a tight control on the tradeoff between decoding complexity and DFP."
  },
  {
    "year": "2017",
    "abstract": "Photo privacy protection has recently received increasing attention from the public. However, the overprotection of photo privacy by hiding too much visual information can make photos meaningless. To avoid this, visual information with different degrees of privacy sensitivity can be filtered out using various image-processing techniques. Objects in a photo usually contain visual information that can potentially reveal private information; this potential depends on both the visual saliency of the objects and on the specific categories to which the objects belong. In this paper, we aim to quantitatively evaluate the influence of visual saliency information on privacy and objectively evaluate the levels of visual privacy that objects contain. Meeting this objective faces two challenges: 1) determining a method of effectively detecting generic objects in a photo for the extraction of saliency information and 2) determining a scientific method for assessing the visual private information contained in objects. To cope with these challenges, we first propose a hierarchical saliency detection method that combines a patch-based saliency detection strategy with an objectness estimation strategy to effectively locate salient objects and obtain the saliency information of each object. The proposed method results in a small set of class-independent locations with high quality and a mean average best overlap score of 0.627 at 1150 locations, which is superior to the score of other saliency detection methods. Second, we build a computational privacy assessment system to scientifically calculate and rank the privacy risks of objects in a photo by creating an improved risk matrix and using the Borda count method. The proposed computational privacy assessment method matches human evaluations to a relatively high degree."
  },
  {
    "year": "2017",
    "abstract": "Gravitational search algorithm (GSA) is a novel heuristic optimization algorithm which is used to search for the global optimal solution by iteration. However, GSA is easy to fall into local minima and convergence slowly. To improve the exploration and exploitation abilities of the GSA, a new hybrid GSA (HGSA) is proposed. In this algorithm, the local search technique (LST) is incorporated into the optimization process of the GSA. For each agent, GSA is performed with probability p, and LST is performed with probability 1 - p. The probability p is obtained using fuzzy logic. The strategy makes full use of the exploration ability of GSA and the exploitation ability of LST. The HGSA is tested on 23 benchmark functions. By comparing the HGSA with GSA and other algorithms that were published in recent studies, the numerical results demonstrate that the HGSA can improve the performance of GSA in terms of global optimality and solution accuracy."
  },
  {
    "year": "2017",
    "abstract": "Predictability in spectrum prediction refers to the degree to which a correct prediction of the radio spectrum state (RSS) can be made quantitatively. It is obvious that the possibility that the future RSS is accurately predicted will be different when using different spectrum prediction algorithms. However, the fundamental limits on the accuracy of various spectrum prediction algorithms should exist and be worthwhile to be paid attention to. In this paper, we define these fundamental limits as the performance bounds of predictability, which can be the important indexes when evaluating the performance of different spectrum prediction algorithms. Real-world spectrum data is involved to present comprehensive and profound analysis of the predictability. We first transform large amount of spectrum data into symbol sequences by sampling and quantization, to calculate the entropy of the symbol sequence, which represents the randomness of the RSS evolution. Then, we derive the upper bound and the lower bound of the predictability mainly from entropies of the symbol sequences. Further, we conduct the detailed analysis on the performance bounds of the predictability of the RSS. Based on real-world data analytics, the key insights among others include: 1) entropies almost have no relationship with selection of sampling intervals in the data preprocessing; 2) the upper and the lower bounds of the predictability will both decrease as the quantization level rises and tend to be stable around a value at last; and 3) two kinds of lower bounds of the predictability are proposed, and one of the lower bounds, the regularityR, can reveal the tidal effect of the evolution of the RSS."
  },
  {
    "year": "2017",
    "abstract": "Chipless radio frequency identification (RFID) technology recently observed a growing interest, mainly because of its wide area of applications, and huge potential market, with the advent of Internet of Things era. Recently, in the demonstration of high capacity chipless RFID tags, ultra-wideband technology has been proposed. It can enable development of robust chipless RFID systems with the promising features of low cost, compact, and lightweight. In response, we propose a novel scheme of broadband chipless RFID tagging that is based on slot coupled tapered slot antenna (TSA) loaded with a set of resonators, referred to as multi-resonators filters (MRF). Using numerical simulations, out of 256 combinations, randomly selected 14 different 8-bit MRF circuits operating over the frequency band 4 to 9 GHz are designed and their spectral and time domain responses under short and open terminations are recorded. The time domain signatures, generated due to high impedance mismatches along the microstrip lines of MRFs terminated with open and short circuits, are quantified by finding the cross-correlation among the signals and that is done by calculating the pulse fidelity factor. The designed MRFs are integrated with TSA to develop chipless RFID tags, referred to as MRF-TSA tags. Our designed TSA operates over 3.5-18 GHz band with an average gain that exceeds 6.5 dBi. The retransmitted time domain signals from the MRF-TSA tags are modulated by loading the antenna with MRFs terminated with either short or open loads. The recorded time domain signals are reasonably distinguishable since 85% (96%) of fidelity factor values among the 14 different MRF-TSA tags with open/short termination are less than 0.70 (0.8), respectively. Finally, for verification purposes, two different MRF-TSA based chipless tags are designed and fabricated. RFID monostatic measurements based on the use of vector network analyzer are also reported."
  },
  {
    "year": "2017",
    "abstract": "Made possible by the availability of spatio-temporal data collected by smart phones and other smart devices, understanding people's mobility patterns has become one of the most promising locationbased services in the past few years, providing various businesswise application possibilities. The simplest version of possibilities is to predict where a user will go next. In this paper, we present a novel approach that goes beyond predicting users' next location and is able to predict their entire mobility patterns. Building on previous work, our models are based on statistical Markov state-space models. In our approach, however, we add temporal information (“arrival profiles”and “probability of stay”profiles) explicitly to the models. Using Monte Carlo simulations on these models enables us to predict multiple future locations, including residence times. We evaluate the models on real-world data sets (1.5 year personally collected mobile phone raw GPS logs and a publicly available Nokia Mobile Data Challenge data set) using different evaluation metrics. An extensive evaluation shows that our proposed methods have better predictive power (higher recall) than standard state-space models."
  },
  {
    "year": "2017",
    "abstract": "Advanced correlation filters are an effective tool for target detection within a particular class. Most correlation filters are derived from a complex filter equation leading to a closed form filter solution. The response of the correlation filter depends upon the selected values of the optimal trade-off (OT) parameters. In this paper, the OT parameters are optimized using particle swarm optimization with respect to two different cost functions. The optimization has been made generic and is applied to each target separately in order to achieve the best possible result for each scenario. The filters obtained using standard particle swarm optimization (PSO) and hierarchal particle swarm optimization algorithms have been compared for various test images with the filter solutions available in the literature. It has been shown that optimization improves the performance of the filters significantly."
  },
  {
    "year": "2017",
    "abstract": "Message identification (M-I) divergence is an important measure of the information distance between probability distributions, similar to Kullback-Leibler (K-L) and Renyi divergence. In fact, M-I divergence with a variable parameter can make an effect on characterization of distinction between two distributions. Furthermore, by choosing an appropriate parameter of M-I divergence, it is possible to amplify the information distance between adjacent distributions while maintaining enough gap between two nonadjacent ones. Therefore, M-I divergence can play a vital role in distinguishing distributions more clearly. In this paper, we first define a parametric M-I divergence in the view of information theory and then present its major properties. In addition, we design a M-I divergence estimation algorithm by means of the ensemble estimator of the proposed weight kernel estimators, which can improve the convergence of mean squared error from O(Γ-j/d) to O(Γ-1) (j ∈ (0, d]). We also discuss the decision with M-I divergence for clustering or classification, and investigate its performance in a statistical sequence model of big data for the outlier detection problem."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the problem of spacecraft autonomous rendezvous control for elliptical target orbits with external disturbance and thruster faults. The Clohessy-Wiltshire equation of elliptical target orbits without linearization is employed to describe the relative dynamic model as a linear time-varying system, such that the model errors in traditional linearization modeling methods are avoided. By on-line estimating the thruster faults and external disturbance, an adaptive sliding mode control scheme is designed to eliminate the effects of the thruster faults and external disturbances, such that the reachability of the proposed integral sliding surface is ensured. Finally, a simulation example is provided to demonstrate the effectiveness of the controller design approach."
  },
  {
    "year": "2017",
    "abstract": "A distribution network is one of the main parts of a power system as it is connected directly to the load center and can act as a microgrid during an islanding operation. The concept of integrating both renewable and distributed energy sources at the distribution level is currently of great interest for power system engineers. Further research by power companies and engineers on applying better techniques to improve the power quality and stability of dynamic devices in a distribution network is ongoing. This paper presents a review of fundamental distribution network architectures, including radial, ring, and mesh ones, which considers their types of operation, control and management, growth model, and advantages and disadvantages. The existing networks suffer from various technical and quality issues while they are also vulnerable to the natural disaster and any type of fault in the system. To overcome the problems associated with present networks, a novel architecture of aromatic structure is proposed. Simulations carried out show that this new network can perform better than existing ones in terms of load flow, power quality, reliability, and islanding operations. It is also a perfect choice for both a distribution network and microgrid in a cyclone-prone area as it has both overhead and underground network facilities."
  },
  {
    "year": "2017",
    "abstract": "Traffic classification networks have various applications for data transmissions to ensure quality of service (QoS) for various classes of traffic at the routers. Multi-level random early detection (MRED) scheduling algorithm is used to manage resources at the routers guaranteeing QoS. However, the MRED queue mechanism is insensitive to traffic and difficult to set parameters, for the average queue is sensitive to high congestion level of multi-flow which is a major issue affecting the performance of the queue in the networks. This paper propose a new scheduling algorithm that manages congestion level by increasing the stability of parameters, using dynamic weighted traffic with redefining probability drop traffic in the MRED algorithm. The results present the performance algorithm while utilizing the reference algorithms, improving the bandwidth fairness and average throughput and reduce the average delay and packet drop."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider simultaneous wireless information and power transfer in a full-duplex (FD) communication system consisting of one FD access point A (FD-A) and one FD device B (FD-B), each being equipped with a pair of transmitter-receiver antennas for signal transmission and reception respectively. The power splitting (PS) scheme is adopted at FD-B to receive information and energy concurrently. In order to maximize the energy harvested by FD-B while considering the constraints of signal-to-interference-and-noise ratio (SINR) and maximum transmit power at both nodes, we jointly design the optimal transmit power of FD-A and FD-B, as well as the PS ratio of FD-B. Unfortunately, the primal problem is non-convex and is not always feasible with different parameters. Thus, we first present a set of conditions, under which the feasibility of the primal problem is guaranteed. Then, we derive the closed form of the optimal solution with the aid of analyzing the feasible region of the problem. Furthermore, the influences of the parameters on the maximum harvested energy are theoretically analyzed. Finally, simulation results are provided to verify the optimality of the proposed closed-form solution, to validate the analysis of the impact of parameters on the maximum harvested energy and to show the effectiveness of the proposed design, respectively."
  },
  {
    "year": "2017",
    "abstract": "Recently, increasing experimental studies have shown that microRNAs (miRNAs) involved in multiple physiological processes are connected with several complex human diseases. Identifying human disease-related miRNAs will be useful in uncovering novel prognostic markers for cancer. Currently, several computational approaches have been developed for miRNA-disease association prediction based on the integration of additional biological information of diseases and miRNAs, such as disease semantic similarity and miRNA functional similarity. However, these methods do not work well when this information is unavailable. In this paper, we present a similarity-based miRNA-disease prediction method that enhances the existing association discovery methods through a topology-based similarity measure. DeepWalk, a deep learning method, is utilized in this paper to calculate similarities within a miRNA-disease association network. It shows superior predictive performance for 22 complex diseases, with area under the ROC curve scores ranging from 0.805 to 0.937 by using five-fold cross-validation. In addition, case studies on breast cancer, lung cancer, and prostatic cancer further justify the use of our method to discover latent miRNA-disease pairs."
  },
  {
    "year": "2017",
    "abstract": "In wireless telephony and audio data mining applications, it is desirable that noise suppression can be made robust against changing noise conditions and operates in real time (or faster). The learning effectiveness and speed of artificial neural networks are therefore critical factors in applications for speech enhancement tasks. To address these issues, we present an extreme learning machine (ELM) framework, aimed at the effective and fast removal of background noise from a single-channel speech signal, based on a set of randomly chosen hidden units and analytically determined output weights. Because feature learning with shallow ELM may not be effective for natural signals, such as speech, even with a large number of hidden nodes, hierarchical ELM (H-ELM) architectures are deployed by leveraging sparse autoencoders. In this manner, we not only keep all the advantages of deep models in approximating complicated functions and maintaining strong regression capabilities, but we also overcome the cumbersome and time-consuming features of both greedy layer-wise pre-training and back-propagation (BP)-based fine tuning schemes, which are typically adopted for training deep neural architectures. The proposed ELM framework was evaluated on the Aurora-4 speech database. The Aurora-4 task provides relatively limited training data, and test speech data corrupted with both additive noise and convolutive distortions for matched and mismatched channels and signal-to-noise ratio (SNR) conditions. In addition, the task includes a subset of testing data involving noise types and SNR levels that are not seen in the training data. The experimental results indicate that when the amount of training data is limited, both ELMand H-ELM-based speech enhancement techniques consistently outperform the conventional BP-based shallow and deep learning algorithms, in terms of standardized objective evaluations, under various testing conditions."
  },
  {
    "year": "2017",
    "abstract": "Recommenders have proven to be useful means to support people in their activities and in making decisions. They evolved from online recommenders to context-aware and ubiquitous recommenders. Moving forward along this line, this paper introduces the new emerging class of smart physical recommenders: context-aware recommender systems that are embedded into physical everyday objects. This paper describes the features of these systems and presents a conceptual model to design them, by analyzing a number of issues that have to be addressed by a designer and discussing the consequences of different design choices with their impact on the smartness of the designed object. The model is structured in a number of layers corresponding to different conceptual design phases in which different requirements are analyzed. The contribution of this paper is to discuss and provide design guidelines for a new rising class of recommenders that combine the features of intelligent agents, cyber-physical objects, and recommender-support systems. The description of the model is complemented by an exemplary analysis of its application."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we design a novel architecture of distributed satellite cluster network (DSCN). In order to achieve a good trade-off between the energy consumption and the total capacity, we investigate the joint downlink power and time-slot allocation problem, taking into account the limitation of resource, collaborative coverage of multi-satellite, and dynamism, which is proved to be a Pareto optimization and NP-hard problem. Different from the existing 1-D multi-objective optimization algorithm (1D-MOA) based on meta-heuristics, such as immune clonal algorithm (ICA), we propose an improved 2-D dynamic immune clonal algorithm (TDICA) to search the solution space for approaching the Pareto front. From simulation results, several important concluding remarks are obtained as follows: 1) the proposed TDICA can obtain more non-dominated solutions in each iteration with better accuracy than existing algorithms; 2) with inter-satellite resource optimization, the total capacity can be improved; 3) compared with 1D-MOAs, the 2D-MOA can save more energy and achieve higher total capacity; d) MOAs can be transferred into multiple single-objective optimization algorithms (SOAs) under certain conditions."
  },
  {
    "year": "2017",
    "abstract": "Visible light communications (VLCs) have received extensive attention in the research community thanks to their advantages of high bandwidth, low cost, robustness to electromagnetic interference, operation in an unregulated spectrum, and high degree of spatial confinement in indoor scenarios. One of the main limitations for high data-rate transmission in VLC systems is the limited modulation bandwidth of commercial light emitting diodes. To circumvent this limitation, spectrally efficient modulation schemes should be used. Optical orthogonal frequency-division multiplexing (O-OFDM)-based schemes have become very popular and several proofs of concept have shown their ability to attain over gigabits per second transmission rates. We consider here the use of pulse amplitude modulation and carrier-less amplitude and phase modulation schemes together with frequency-domain equalization (FDE) at the receiver as interesting alternatives to O-OFDM. We show the advantages of the former schemes in terms of the peak-to-average-power ratio, and demonstrate through numerical results the merits of FDE-based signaling in attaining high data rates."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a method that can reliably monitor the adoption of existing technology by term frequency-inverse document frequency (TF-IDF) and K-means clustering using cited patents. TF-IDF and K-means clustering can extract patent information when the number of patents is sufficiently large. When the number of patents is too small for TF-IDF and K-means clustering to be reliable, the method considers patents that were cited by the originally set of patents. The mixed set of citing patents and cited patents is the new subject of analysis. As a case study, we have focused in agricultural tractor in which new technologies were adopted to achieve automated driving. TF-IDF and K-means clustering alone failed to monitor the adoption of new technology but the proposed method successfully monitored it. We anticipate that our method can ensure the reliability of patent monitoring even when the number of patents is small."
  },
  {
    "year": "2017",
    "abstract": "Location-based services (LBS) leveraged by ubiquitous mobile devices have brought great convenience to mobile users in various aspects, including communication, information exchange, social activities, and so on. However, privacy concerns arise at the same time, since the users need to submit their locations and query contents to the LBS servers. To this end, location privacy and query privacy have been recognized. In particular, this paper focuses on query privacy for preventing the leakage of users' query contents. Cloaking region-based techniques using untrusted servers and client-based k-anonymity approaches have been devised to preserve query privacy in LBS. However, these works suffer from single point of failure or insufficiency of query privacy. To address this issue, we investigate effective k-anonymity-based solutions for query privacy in LBS. We formulate a probabilistic framework PkA, under which k-anonymity-based mechanisms can be initiated, and analyze a recent proposed algorithm DLS as an instance of PkA. An algorithm circle segment is presented to provide effective query privacy when query interests have similar prior probability. To obtain more effective query privacy in general cases, we propose two algorithms MEE and MER, which optimize two individual privacy metrics, denoted expected entropy and expected max-min ratio, adopted in this paper. We recognize two practical properties - No More Leakage and k-Effectiveness for effective query privacy, and our proposed algorithms satisfy both of No More Leakage and k-Effectiveness. We conduct evaluation based on real-life data sets and synthetic distributions of query interests, and the evaluation results demonstrate that our proposed algorithms produce significantly improved query privacy."
  },
  {
    "year": "2017",
    "abstract": "Delivering real-time road-traffic information to the driver is a straightforward solution to the problem of road-traffic congestion. The information is more effective as it is fresh and more accurate. However, real-time road-traffic information delivery has a fundamental problem: an accuracy-freshness tradeoff. Unfortunately, real-time road-traffic information delivery has difficulty satisfying both requirements. To guarantee the freshness, the information needs to be delivered on the basis of the data received by a cloud or edge server before a predetermined deadline. However, only a limited amount of data is received due to bandwidth limitation and processing overhead in communication networks, which results in the poor accuracy of the delivered information. The only way to improve the accuracy is to make the deadline less strict, which results in deteriorating the freshness of information. The proposed system solves this tradeoff. The key idea is that data more “important” for the accuracy of information are more prioritized when the data are transferred in communication networks. In the proposed system, “importance” is determined by how helpful the data are when the system needs to estimate missing spatial information from a limited amount of received data by using the machine learning technique. In this paper, simulation results verify that the proposed system ensures the accuracy of road-traffic information while satisfying the freshness requirement."
  },
  {
    "year": "2017",
    "abstract": "Industry 4.0 can make a factory smart by applying intelligent information processing approaches, communication systems, future-oriented techniques, and more. However, the high complexity, automation, and flexibility of an intelligent factory bring new challenges to reliability and safety. Industrial big data generated by multisource sensors, intercommunication within the system and external-related information, and so on, might provide new solutions for predictive maintenance to improve system reliability. This paper puts forth attributes of industrial big data processing and actively explores industrial big data processing-based predictive maintenance. A novel framework is proposed for structuring multisource heterogeneous information, characterizing structured data with consideration of the spatiotemporal property, and modeling invisible factors, which would make the production process transparent and eventually implement predictive maintenance on facilities and energy saving in the industry 4.0 era. The effectiveness of the proposed scheme was verified by analyzing multisource heterogeneous industrial data for the remaining life prediction of key components of machining equipment."
  },
  {
    "year": "2017",
    "abstract": "The precise and timely prediction of program popularity is of great value for content providers, advertisers, and broadcast TV operators. This information can be beneficial for operators in TV program purchasing decisions and can help advertisers formulate reasonable advertisement investment plans. Moreover, in terms of technical matters, a precise program popularity prediction method can optimize the whole broadcasting system, such as the content delivery network strategy and cache strategy. Several prediction models have been proposed based on video-on-demand (VOD) data from YouKu, YouTube, and Twitter. However, existing prediction methods usually require a large quantity of samples and long training time, and the prediction accuracy is poor for programs that experience a high peak or sharp decrease in popularity. This paper presents our improved prediction approach based on trend detection. First, a dynamic time warping-distance-based K-medoids algorithm is applied to group programs' popularity evolution into four trends. Then, four trend-specific prediction models are built separately using random forests regression. According to the features extracted from an electronic program guide and early viewing records, newly published programs are classified into the four trends by a gradient boosting decision tree. Finally, by combining forecasting values from the trend-specific models and the classification probability, our proposed approach achieves better prediction results. The experimental results on a massive set of real VOD data from the Jiangsu Broadcasting Corporation show that, compared with the existing prediction models, the prediction accuracy is increased by more than 20%, and the forecasting period is effectively shortened."
  },
  {
    "year": "2017",
    "abstract": "In orthogonal frequency division multiplexing relay networks with in-phase and quadrature imbalances and full-duplex relay station (RS), how to optimize pilot pattern and power allocation using the criterion of minimizing the sum of mean square errors (Sum-MSE) for the frequency-domain least-squares channel estimator has a heavy impact on self-interference (SI) cancellation. First, the design problem of pilot pattern is casted as a convex optimization. From the Karush-Kuhn-Tucker conditions, the optimal analytical expression is derived when source and RS powers are given or fixed. Second, under the total transmit power sum constraint of source node and RS, an optimal power allocation (OPA) strategy is proposed to further alleviate the effect of Sum-MSE. Simulation results show that the proposed OPA performs better than equal power allocation (EPA) in terms of Sum-MSE, and the Sum-MSE performance gain increases with deviating ρ from the value of ρominimizing the Sum-MSE, where ρ is defined as the average ratio of the residual SI channel gain at RS to the intended channel gain from source to RS. For example, the OPA achieves approximately 5-dB signal-to-noise ratio gain over EPA by shrinking or stretching ρ with a factor 4. More importantly, the more ρ decreases or increases, the more the performance gain becomes significant."
  },
  {
    "year": "2017",
    "abstract": "Compared with conventional two-step localization algorithms which are implemented by initially estimating localization parameters and then calculating the target position, the performance of direct position determination (DPD) algorithm is superior in terms of high estimation accuracy and strong resolution capability. DPD algorithms can make full use of the characteristics of signals to improve positioning performance. Using this localization mechanism as basis, this study develops a novel DPD algorithm that profits from the characteristics of orthogonal frequency division multiplexing (OFDM) signals based on the time and angle of arrival. First, the DPD optimization model is constructed based on maximum likelihood criterion and the characteristic of multiple carrier modulation technique of OFDM signals. Then, an extended subspace data fusion-based DPD algorithm is developed by constructing and decomposing the extended covariance matrices. The algorithm fuses the extended subspace data to estimate the target position without calculating the intermediate variables, which is less complex and more efficient. These properties can avoid the limitations of two-step algorithms. The last but important result is a derivation of the closed-form expression of Cramer-Rao lower bound (CRLB) on the position estimation variance for OFDM sources. Simulation results show that, the algorithm proposed in this paper outperforms existing DPD algorithms and conventional two-step localization algorithms. Especially under the condition of low signal-to-noise ratio, its localization accuracy is close to the CRLB."
  },
  {
    "year": "2017",
    "abstract": "Using the loop transfer recovery (LTR) method to recover the linear quadratic Gaussian (LQG) robustness properties is a well-established procedure, as well as augmenting the system with integrators at the plant input to deal with steady-state error. However, when using the discrete version of the LQG/LTR controller, simply using integrators discretized by the forward Euler method does not guarantee recovery convergence. This paper presents a solution: augmenting the system with a PI controller. A control moment gyroscope is used to apply this technique, and its modeling process is showed, along with its linearization and discretization. Particularly, it presents a resonance due to nutation frequency, which is damped in an inner loop prior to the robust control design by simple velocity feedback. Particle swarm optimization is applied aiming to shape the target open loop and to guarantee set point, disturbance and measurement noise robustness. At last, real experiments are conducted to corroborate the presented method."
  },
  {
    "year": "2017",
    "abstract": "In order to overcome the bandwidth limitations of common control channels, we introduce a multibit quantization scheme to preprocess raw measurements in a collaborative spectrum sensing (CoSS) scheme. After quantifying the raw measurement, the cognitive sensors (CSs) send the multibit sensing information to a sink node (SN), which makes a final decision by using a soft decision fusion rule. In order to better understand the effects of quantization parameters on collaborative spectrum sensing in a cognitive sensor network (CSN), we discuss the following two problems: the average error probability minimum problem (AEPMP) and throughput maximum problem. By identifying the number of quantization bits, number of CSs, and global decision threshold, we can discuss some design considerations for the multibit-quantization-based CoSS scheme. A closed-form expression for the optimal global decision threshold is derived in the process of analyzing the AEPMP. Furthermore, an iterative algorithm with low complexity is proposed to find the optimal parameters for maximizing the throughput of a CSN under a target detection probability constraint. Finally, we investigate the impact of optimized parameters on the system performance of a CSN. Our theoretical analysis is verified through numerical simulations."
  },
  {
    "year": "2017",
    "abstract": "A social network contains a significant set of spreaders whose activities can lead to largescale activation of network members. In order to find the minimal set of spreaders, many methods based on traditional network topology have been proposed. However, search engines change the structure of traditional social networks. With the help of a search engine, each spreader has the potential to establish connections with disconnected spreaders. Thus, it is necessary to take the influences of search engines into account, in order to find a more accurate set of spreaders. In this paper, we aim to quantitatively characterize the impact of the collective influence of a search engine on a dynamic social network. First, we design a model to specially describe connections established by a search engine. Second, we improve a method based on collective influence theory to identify a more optimal set of super-spreaders, taking the influence of the search engine into consideration. We use the number of probably established subcritical paths attached to a node as this node's contribution in this social network. Third, we propose an algorithm based on collective influence that is applicable to networks with search engines to identify the optimal set of spreaders. The analysis results from both randomly generated networks and real-world networks indicate that our method can yield a more accurate set, which can cause a more large-scale cascade of information."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with the input-to-state stability (ISS) and integral input-to-state stability (iISS) of stochastic delayed systems with Markovian switching. By using the multiple Lyapunovlike function and Lyapunov-Krasovskii function methods, the ISS and iISS are considered for stochastic delayed systems with Markovian switching and external inputs. In addition, when there do not exist external inputs, the pth moment exponential stability and stochastically asymptotically stable in large are presented for stochastic delayed systems with Markovian switching. Two examples are presented to demonstrate the effectiveness of the proposed results."
  },
  {
    "year": "2017",
    "abstract": "Information security is of paramount importance yet significant challenge for wireless communications. In this paper, we investigate the power-efficient transmissions with security concerns in the presence of a full-duplex (FD) active eavesdropper. With FD capability, the eavesdropper can launch jamming attacks while eavesdropping, which affects the legitimate transmissions, such that the legitimate power allocation becomes more favorable for eavesdropping. However, the jamming attacks require additional power consumption and result in self-interference at the eavesdropper itself. The legitimate user intends for a power-efficient manner to effectively guarantee the secure transmissions to defend against the simultaneous eavesdropping and jamming attacks. We formulate the problem within a Stackelberg game framework, where the eavesdropper takes action first as the leader and the legitimate user acts as the follower. We analyze the security game model for both single-channel and multi-channel cases. Furthermore, by exploring the properties of the game equilibrium, we propose the optimal transmission strategy and jamming strategy for the legitimate transmission and eavesdropping, respectively. Finally, we provide extensive simulation results to corroborate our theoretical analysis and evaluate the security performance."
  },
  {
    "year": "2017",
    "abstract": "The determination of the complex permittivity of low-loss construction materials at frequency bands above 6 GHz that are being proposed to allocate forthcoming mobile radio services is of critical importance for the design and deployment of future wireless systems. In this paper, a simple free-space method for the electromagnetic characterization of construction materials that does not require multiple reflection or transmission coefficient measurements for different incidence angles or complex optimization procedures is proposed and tested. The method is shown to yield permittivity and conductivity values in agreement with the literature for some common-use materials using a relatively simple measurement setup and procedure."
  },
  {
    "year": "2017",
    "abstract": "Grid synchronization is one of the critical techniques used in grid-connected systems, such as distributed generation, energy storage, and harmonic compensation equipment. To acquire efficient grid-connection or harmonic compensation performance, the accurate and real-time information of phase, frequency and amplitude is required, especially when the grid voltage contains disturbed or other unexpected components. According to different application fields, two kinds of phase-locking structures exist-single- and three-phase phase-locked loop (PLL), which are not cross compatible. In this paper, a novel unified digital PLL with multiple complex resonators for both single- and three-phase systems is proposed. First, single-phase and three-phase voltage signal is transformed uniformly to a similar complex form that consists of positive and negative sequence components rotating in counterclockwise and clockwise directions, respectively. Then, synchronous rotating frame PLL with a generalized prefilter is introduced. The proposed filtering structure consists of multiple complex resonators that can filter out harmonic frequency components and maintain fundamental positive sequence components accurately. Furthermore, a simplified structure of the complex resonator for single-phase system and an operation method for resonant factor are introduced. Finally, the validity and effectiveness of the proposed method are proven by the simulated and experimental results of a three-phase four-leg shunt active power filter."
  },
  {
    "year": "2017",
    "abstract": "Given the rapid introduction of mobile phones and other portable wireless devices into society, and the increased possibility of young children using or being exposed to electromagnetic (EM) fields, a study of specific absorption rate (SAR) in the head of young children is becoming increasingly relevant. To accurately evaluate the exposure of children to electromagnetic fields, realistic head models, which consider the age-specific anatomical structure and age-dependent tissues dielectric properties, are developed. During postnatal development of human tissues, the number and size of cells increase while the proportion of water content decreases. Such changes result generally in significant changes in the dielectric properties of tissues. The SAR levels for different ages are investigated using the developed children's head models when young children or their parents use a standard mobile phone. The results show that the maximum SAR levels in brain tissues of young children (3 months) are higher by up to 61% and 78% than adults at the lowest (700 MHz) and highest (2600 MHz) investigated frequencies, respectively. The percentage absorption power in the heads of young children (3 months) is higher by up to 40.6% and 24% than the values for adults at 700 MHz and 2600 MHz, respectively. Our investigation shows that previous studies, which used scaled head models without considering the age-dependent variations in the head anatomy and/or age-dependent tissues' dielectric properties, underestimated SAR levels in the children's heads. The obtained results using the developed realistic head models indicate that for young children, a lower limit on radiated power might be required to meet the acceptable dosimetry levels."
  },
  {
    "year": "2017",
    "abstract": "The linearity of a stochastic flash analog-to-digital converter (ADC) with two groups of comparators is improved by reference swapping. If the input offset of a comparator is larger than the linear input range of its comparator group, the reference voltage of the comparator is swapped with the reference voltage of the other comparator group. The reference swapping doubles the number of comparators providing a meaningful result in determining the ADC output. A stochastic flash ADC linearized by the reference swapping has been implemented in a 65-nm CMOS process. The peak signal-to-noise + distortion ratio is 39 dB, which is 3-dB higher than that without the reference swapping."
  },
  {
    "year": "2017",
    "abstract": "Various new national advanced manufacturing strategies, such as Industry 4.0, Industrial Internet, and Made in China 2025, are issued to achieve smart manufacturing, resulting in the increasing number of newly designed production lines in both developed and developing countries. Under the individualized designing demands, more realistic virtual models mirroring the real worlds of production lines are essential to bridge the gap between design and operation. This paper presents a digital twin-based approach for rapid individualized designing of the hollow glass production line. The digital twin merges physics-based system modeling and distributed real-time process data to generate an authoritative digital design of the system at pre-production phase. A digital twin-based analytical decoupling framework is also developed to provide engineering analysis capabilities and support the decision-making over the system designing and solution evaluation. Three key enabling techniques as well as a case study in hollow glass production line are addressed to validate the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Inter-modulo operations are the most time consuming and costly operations of the residue number system (RNS), and one of the main obstacles to applying RNS in practice to the design of computing devices, namely for signed integer arithmetic. In this paper, we derive simplified and unified mathematical formulations for inter-modulo operations, such as sign detection, magnitude comparison, scaling signed integers, and signed reverse conversion, grounded on the pillars of reverse conversion. These formulations, which cover a whole range of sets, with 3 to 5 moduli, are used to design components that when integrated allow the design of efficient complete multifunctional units, reusing blocks to perform several RNS intermodulo operations. Not only have the proposed individual components been compared with related art, but a configuration of the proposed multifunctional unit has also been implemented in application specific integrated circuits. Experimental results show that the multifunctional unit is significantly more area and power effective than the other solutions proposed in the state of the art, and the performance of the individual components compare well with dedicated ones. The novel multifunctional units are thus a further step toward the integration of RNS systems on constrained systems."
  },
  {
    "year": "2017",
    "abstract": "Advanced engine control, such as active control, often involves controlling engine with more control variables at a wider frequency range. When the conventional successive-loop-closure technology is applied to design controller with more objectives and controls, it will lead to multi-loop interleaving, and prevent the responses of the lower frequency control loops from meeting the requirements and hence exploiting the potential of the engine. A modified multivariable decoupling method in frequency domain is presented to improve the robustness and decoupling of the system and proved that it is equivalent to Rosenbrock's modified method at a single frequency, and then extended to a weighted formulation on a certain frequency range. Finally, the modified method is used to design steady-state decoupling controller, and a multivariable gain-scheduling controller for large transient is formulated as the weighted function of a family of designed decoupling controllers, whose weights are chosen as transfer function of neural network optimized by BP algorithm. Computational results are presented for controlling the small and large transient of a military aircraft turbofan engine, and the simulations show that compared with standard Hawkins's method, the resultant compensated system designed by the modified method is of better good decoupling and robustness."
  },
  {
    "year": "2017",
    "abstract": "Fog computing (FC) is an emerging distributed computing platform aimed at bringing computation close to its data sources, which can reduce the latency and cost of delivering data to a remote cloud. This feature and related advantages are desirable for many Internet-of-Things applications, especially latency sensitive and mission intensive services. With comparisons to other computing technologies, the definition and architecture of FC are presented in this paper. The framework of resource allocation for latency reduction combined with reliability, fault tolerance, privacy, and underlying optimization problems are also discussed. We then investigate an application scenario and conduct resource optimization by formulating the optimization problem and solving it via a genetic algorithm. The resulting analysis generates some important insights on the scalability of the FC systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an integrated fault diagnosis method is proposed to deal with fault location and propagation path identification. A causality graph is first constructed for the system according to the a priori knowledge. Afterward, a correlation index (CI) based on the partial correlation coefficient is proposed to analyze the correlation of variables in causality graph quantitatively. To achieve accurate fault detection results, the proposed CI is monitored by probability principal component analysis. Moreover, the concept of weighted average value is introduced to identify fault propagation path based on reconstruction-based contribution and causality graph after detecting a fault. Finally, the new proposed scheme would be practiced with real industrial HSMP data, where the individual steps as well as the complete framework were extensively tested."
  },
  {
    "year": "2017",
    "abstract": "The concept of eServices originated in the early 2000s in the field of business and commerce. However, in recent years, eServices are being applied in many domains. Therefore, a thorough study on eServices is required to identify the areas in which eServices have been applied till date and to what extent. The main objective of this research is to perform a mapping study to provide an extensive review, gather trends, and identify the state of the art in the research on eServices to answer the research questions designed to conduct this research. A mapping study has been conducted employing an automatic search in digital repositories by developing a mapping protocol. Mapping studies are useful for categorizing and classifying the existing information concerning a particular research question in an unbiased manner. The search procedure identified 806 studies of which 318 were selected for full analysis during the years 2000 and 2016 in the field of computer science. No study was published before this time period. Research on eServices were recorded and classified into tabulated spread sheets, and finally analyzed. According to the study, the range of eService service and application domains is quite wide. Most studies conducted have focused on eService composition and eService Adoption. However, the most common application domains identified were eGovernment, eBusiness, eHealth, and eLearning. The study findings show that the research on eService composition, design, provision, and adoption is increasing with the passage of time. The literature not only discusses various domains of eServices but also provides the in-depth classification, review and trend of eService studies over time."
  },
  {
    "year": "2017",
    "abstract": "Solving a system of multivariate quadratic equations obtained through algebraic cryptanalysis is a nondeterministic polynomial time-complete problem. Owing to the trend of stream ciphers based on nonlinear update, the success of algebraic attacks has been limited to their reduced variants. On the other hand, side channel attacks (SCAs), although require a continued access to the target device for capturing leakages, are a potent threat against the stream ciphers. Algebraic SCA (ASCA) combines and solves equations obtained through algebraic cryptanalysis and partial SCA of cipher implementation. ASCA is successfully being applied against block ciphers since 2009; however, there is no existing published work on ASCA against stream ciphers as per our knowledge. In this paper, we propose an idea of mounting ASCA on stream ciphers, and we demonstrated it through the application of ASCA on trivium and grain stream ciphers."
  },
  {
    "year": "2017",
    "abstract": "Because the solid-state drive (SSD) shows high access performance, it is usually integrated into existing hard disk drive (HDD)-based storage hierarchy to form HDD/SSD hybrid storage systems. To further improve the performance of HDD/SSD hybrid storage systems, data migration schemes have been put forward to migrate the sequential data between HDD and SSD. However, the existing schemes cannot be aware of dirty data in the buffer and then incur a large number of unnecessary page migrations. In this paper, we devise an efficient data migration scheme considering dying data for HDD/SSD hybrid storage systems. In this scheme, a new liveness state, called the dying state, is utilized to identify the live data, which will become dead shortly due to its corresponding dirty version in the buffer. To decrease the page migration count, this scheme uses the benefit-to-cost ratio to select a block for data migration and copies the up-to-date version of dying data into the free space instead of migrating the dying data. Our experimental results show that our proposed scheme can perform better than existing data migration schemes that are not aware of dying data under various benchmarks."
  },
  {
    "year": "2017",
    "abstract": "A miniaturized ultra-wideband Vivaldi antenna is proposed in this paper. Optimized slots are inserted in the radiation patches to obtain a low frequency resonance. Two substrates with radiation patches are put back to back, forming a double-layered structure. Thus, the transverse E-field of the doublelayered structure is significantly reduced due to this symmetric treatment, which gives rise to very low cross polarization. The measured results show that an enhanced impedance bandwidth of approximately 126% in the range of 2.5-11 GHz (S11<; -10 dB) is achieved. The dimensions of the proposed antenna are 36 mm x 32 mm x 2 mm, and the relative dimensions are 0.3λ0x 0.26λ0x 0.02λ0, where λ0is the freespace wavelength at the lowest operating frequency. Furthermore, the cross polarization is -40 dB over the bandwidth. The time-domain behavior of the Vivaldi antenna is tested, and the results show a low cross polarization in the time domain and admirable time-domain responses."
  },
  {
    "year": "2017",
    "abstract": "Low-dose CT is an effective solution to alleviate radiation risk to patients, it also introduces additional noise and streak artifacts. In order to maintain a high image quality for low-dose scanned CT data, we propose a post-processing method based on deep learning and using 2-D and 3-D residual convolutional networks. Experimental results and comparisons with other competing methods show that the proposed approach can effectively reduce the low-dose noise and artifacts while preserving tissue details. It is also pointed out that the 3-D model can achieve better performance in both edge-preservation and noise-artifact suppression. Factors that may influence the model performance, such as model width, depth, and dropout, are also examined."
  },
  {
    "year": "2017",
    "abstract": "Recent studies show that pattern-recognition-based transient stability assessment (PRTSA) is a promising approach for predicting the transient stability status of power systems. However, many of the current well-known PRTSA methods suffer from excessive training time and complex tuning of parameters, resulting in inefficiency for real-time implementation and lacking the online model updating ability. In this paper, a novel PRTSA approach based on an ensemble of OS-extreme learning machine (EOSELM) with binary Jaya (BinJaya)-based feature selection is proposed with the use of phasor measurement units (PMUs) data. After briefly describing the principles of OS-ELM, an EOS-ELM-based PRTSA model is built to predict the post-fault transient stability status of power systems in real time by integrating OS-ELM and an online boosting algorithm, respectively, as a weak classifier and an ensemble learning algorithm. Furthermore, a BinJaya-based feature selection approach is put forward for selecting an optimal feature subset from the entire feature space constituted by a group of system-level classification features extracted from PMU data. The application results on the IEEE 39-bus system and a real provincial system show that the proposal has superior computation speed and prediction accuracy than other state-of-the-art sequential learning algorithms. In addition, without sacrificing the classification performance, the dimension of the input space has been reduced to about one-third of its initial value."
  },
  {
    "year": "2017",
    "abstract": "Urbanization and modernization accelerate the evolution of urban morphology with the formation of different functional regions. To develop a smart city, how to efficiently identify the functional regions is crucial for future urban planning. Differed from the existing works, we mainly focus on how to identify the latent functions of subway stations. In this paper, we propose a semantic framework (IS2Fun) to identify spatio-temporal functions of stations in a city. We apply the semantic model Doc2vec to mine the semantic distribution of subway stations based on human mobility patterns and points of interest (POIs), which sense the dynamic (people's social activities) and static characteristics (POI categories) of each station. We examine the correlation between mobility patterns of commuters and travellers and the spatio-temporal functions of stations. In addition, we develop the POI feature vectors to jointly explore the functions of stations from a perspective of static geographic location. Subsequently, we leverage affinity propagation algorithm to cluster all the stations into ten functional clusters and obtain the latent spatio-temporal functions. We conduct extensive experiments based on the massive urban data, including subway smart card transaction data and POIs to verify that the proposed framework IS2Fun outperforms existing benchmark methods in terms of identifying the functions of subway stations."
  },
  {
    "year": "2017",
    "abstract": "It is a challenging task to improve the performance of face recognition under complex illumination conditions. Illumination estimation-based illumination invariant extraction is widely used to alleviate the adverse effects of illumination variation on face recognition. Most existing methods only used slowly changing characteristics of lighting to achieve illumination estimation, thus resulting in inaccurate illumination estimation and illumination invariant extraction under complex illumination conditions. To alleviate this issue, on the basis of the Lambertian reflectance model, we propose an innovative method of directional illumination estimation to extract directional illumination invariant sets from a facial image. The directional illumination invariant sets not only better preserve essential features of the face, but also largely reduce adverse effects of rapid light changes. Moreover, we propose a multilevel matching metric for category classification by using an inner product measure and residual matching. Experimental results on Yale B+, CAS-PEAL-R1, uncontrolled and AR face databases validate that the proposed method can effectively improve the accuracy of face recognition under complex illumination conditions."
  },
  {
    "year": "2017",
    "abstract": "Software development is a set of activities which time, budget, and effort of the human resource. Over the years, the software development process has matured to enable the adaptation and integration of commercially available components. The availability of commercially-off-the-shelf and modifiable-off-the-shelf components has transferred the complexity from development and design phases to the integration phase and we can observe large- application development by integrating the available components. Often, due to the limitation of technological and other resources, developing a software application in-house may be less beneficial. In such circumstances, development firms opt to either buy software or outsource the development. In this paper, we identify the factors that govern the decision of making software applications in-house, outsourcing them, or buying them from the market. Since the concept of component integration is more common in large scale applications, in this paper we consider this case."
  },
  {
    "year": "2017",
    "abstract": "Visual traffic surveillance systems play important roles in intelligent transport systems nowadays. The first step of a visual traffic surveillance system usually needs to correctly detect objects from images or videos and classify them into different categories (e.g., car, truck, and bus). This paper aims to introduce a new vehicle type classification scheme on the images acquired from multi-view visual traffic surveillance sensors. Most image classification algorithms focus on maximizing the percentage of the correct predictions, which have a deficiency that the images from minority categories are prone to be misclassified as the dominant categories. To address this challenge of classifying imbalanced data acquired from visual traffic surveillance sensors, we propose a method, which integrates deep neural networks with balanced sampling in this paper. The proposed method consists of two main stages. In the first stage, data augmentation with balanced sampling is applied to alleviate the unbalanced data set problem. In the second stage, an ensemble of convolutional neural network models with different architectures is constructed with parameters learned on the augmented training data set. Experiments on the MIOvision traffic camera dataset classification challenge data set demonstrate that the proposed method is able to enhance the mean precision of all categories, in the condition of high overall accuracy, compared with the baseline algorithms."
  },
  {
    "year": "2017",
    "abstract": "Impulsive noise is one of the most challenging issues in digital subscriber lines (DSL). In order to mitigate the deleterious effects of impulsive noise, the conventional automatic repeat request invokes cyclic redundancy checking (CRC) in order to estimate the existence of impulsive noise and then triggers retransmission, which degrades the spectral efficiency attained. More straightforward techniques of mitigating impulsive noise, such as blanking and clipping, require specific design, which increases the implementation complexity. Against the background, we propose a novel two-stage joint impulsive noise estimation and data detection scheme conceived for low-density parity-check (LDPC) coded discrete multitone (DMT)-based DSL systems. More explicitly, first of all, we propose a semi-blind estimation method, which is capable of estimating the arrival of impulsive noise without using CRC and additionally evaluating the power of impulsive noise with an adequate accuracy. Second, in order to improve the accuracy of impulsive noise estimation in more advanced LDPC-coded DMT-based DSL systems, we propose a decision-directed method for the second stage of channel decoding and data detection with the aid of extrinsic information transfer (EXIT) charts. Our proposed two-stage scheme is capable of approaching the performance of the idealistic scenario of perfectly knowing both the arrival time and the instantaneous power of impulsive noise. Moreover, we analyze the mean square error of the proposed schemes in order to quantify the estimation accuracy and to reduce the estimation complexity. Our simulation results demonstrate that our proposed scheme is capable of achieving a near-capacity performance to using our LDPC coded DMT-based DSL system in the presence of impulsive noise."
  },
  {
    "year": "2017",
    "abstract": "Effective signal processing methods are essential for machinery fault diagnosis. Most conventional signal processing methods lack adaptability, thus being unable to well extract the embedded meaningful information. Adaptive mode decomposition methods have excellent adaptability and high flexibility in describing arbitrary complicated signals, and are free from the limitations imposed by conventional basis expansion, thus being able to adapt to the signal characteristics, extract rich characteristic information, and therefore reveal the underlying physical nature. This paper presents a systematic and up-to-date review on adaptive mode decomposition in two major topics, i.e., mono-component decomposition algorithms (such as empirical mode composition, local mean decomposition, intrinsic time-scale decomposition, local characteristic scale decomposition, Hilbert vibration decomposition, empirical wavelet transform, variational mode decomposition, nonlinear mode decomposition, and adaptive local iterative filtering) and instantaneous frequency estimation approaches (including Hilbert-transform-based analytic signal, direct quadrature, and normalized Hilbert transform based on empirical AM-FM decomposition, as well as generalized zero-crossing and energy separation) reported in more than 80 representative articles published since 1998. Their fundamental principles, advantages and disadvantages, and applications to signal analysis in machinery fault diagnosis, are examined. Examples are provided to illustrate their performance."
  },
  {
    "year": "2017",
    "abstract": "This paper reported a wireless controlled micro-actuator system for rapid heating and mixing of multiple droplets using integrated arrays of micro-fabricated 2.5 GHz solid-mounted thin-film piezoelectric resonators (SMRs) and a millimeter-scale omnidirectional antenna. An equivalent circuit is proposed to analyze the mechanism of the heating, mixing of the SMR, and the wireless communication system. The heating and mixing rate can be tuned by adjusting the input power as well as the transmission distance between the transmitting antenna and the receiving antennas. A heating rate up to 3.7 °C per second and ultra-fast mixing of the droplet was demonstrated with the wireless microsystem. In addition, two types of circuits, H-shaped and rake-shaped, were designed and fabricated for parallel operating actuator array and controlling the power distribution with the array. Both uniform and gradient heating of the multiple droplets are achieved, which can be potentially applied for developing high-throughput wireless micro-reactor system."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the new analysis of the applications of massive multiple-input-multiple-output (MIMO) in full-duplex (FD) cellular two-way relay networks, and sheds valuable insights on the interactions between massive MIMO, and relay and duplex modes. Practical scenarios are considered, where massive MIMO is deployed at the base station and the relay station. Based on generic relay modes, namely, antenna-selection-based decode-and-forward (DF) relay and signal-space alignment based amplify-and-forward (AF) relay, closed-form expressions for the asymptotic signal-to-interference-plus-noise ratios (SINRs) are derived. The difference between AF and DF in the FD mode is quantified, and so is that between FD and half-duplex (HD) under the two relay modes. With massive MIMO, the superiority of DF in the FD mode is confirmed in terms of spectral efficiency. The sufficient conditions for the FD mode to outperform the HD mode are identified. The effectiveness of massive MIMO in terms of self-loop interference cancellation and inter-user interference suppression is proved. All these insightful findings are corroborated by simulations."
  },
  {
    "year": "2017",
    "abstract": "Recently, the Internet of Things (IoT) has emerged as a significant advancement for Internet and mobile networks with various public safety network applications. An important use of IoT-based solutions is its application in post-disaster management, where the traditional telecommunication systems may be either completely or partially damaged. Since enabling technologies have restricted authentication privileges for mobile users, in this paper, a strategy of mobile-sink is introduced for the extension of user authentication over cloud-based environments. A seamless secure authentication and key agreement (S-SAKA) approach using bilinear pairing and elliptic-curve cryptosystems is presented. It is shown that the proposed S-SAKA approach satisfies the security properties, and as well as being resilient to nodecapture attacks, it also resists significant numbers of other well-known potential attacks related with data confidentiality, mutual authentication, session-key agreement, user anonymity, password guessing, and key impersonation. Moreover, the proposed approach can provide a seamless connectivity through authentication over wireless sensor networks to alleviate the computation and communication cost constraints in the system. In addition, using Burrows-Abadi-Needham logic, it is demonstrated that the proposed S-SAKA framework offers proper mutual authentication and session key agreement between the mobile-sink and the base station."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address underdetermined blind separation of N sources from their M instantaneous mixtures, where N > M, by combining the sparsity and independence of sources. First, we propose an effective scheme to search some sample segments with the local sparsity, which means that in these sample segments, only Q(Q <; M) sources are active. By grouping these sample segments into different sets such that each set has the same Q active sources, the original underdetermined BSS problem can be transformed into a series of locally overdetermined BSS problems. Thus, the blind channel identification task can be achieved by solving these overdetermined problems in each set by exploiting the independence of sources. In the second stage, we will achieve source recovery by exploiting a mild sparsity constraint, which is proven to be a sufficient and necessary condition to guarantee recovery of source signals. Compared with some sparsity-based UBSS approaches, this paper relaxes the sparsity restriction about sources to some extent by assuming that different source signals are mutually independent. At the same time, the proposed UBSS approach does not impose any richness constraint on sources. Theoretical analysis and simulation results illustrate the effectiveness of our approach."
  },
  {
    "year": "2017",
    "abstract": "Hyperspectral remote sensing image is a typical high-dimensional data with a large number of redundant informantion, which will impact the classification accuracy. Feature extraction is an effective method to reduce the redundancy of hyperspectral image (HSI) and improve the classification performance. However, most feature extraction methods just consider a single structure information of HSI that will lose some valuable information. To address the drawback, we proposed an unsupervised feature extraction method termed multi-structure manifold embedding (MSME) for HSI classification. First, MSME utilizes sparse representation to obtain the sparse coefficients of HSI data. Then, it constructs a sparse graph and a sparse hypergraph with the sparse coefficients. We use the sparse graph, the sparse hypergraph, and the local linear property to represent different intrinsic structures of HSI. Finally, we construct a feature learning method with these structures to achieve an optimal projection matrix for feature extraction. MSME makes full use of the complementarity of different structures to reveal the intrinsic properties of HSI and improve the discriminating power of features for classification. Experiments on the Salinas and PaviaU data sets show that the proposed MSME algorithm achieves the best classification results than other state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "The performances of plane spiral orbital angular moment (OAM)-based MIMO (PSOAM-MIMO) systems are investigated in a non-line-of-sight (NLoS) channel. Two analytical models, known as specular reflection model and circular scattering model, are applied to evaluate the reflection and scattering effects of wave propagating in the NLoS channels. The performances of the PSOAM-MIMO system in the NLoS channel are compared with those of the conventional MIMO system and in LoS channel. It is found that the capacity gain of the PSOAM-MIMO over MIMO is mainly determined by a direct path. In the NLoS channel, the capacity gain of PSOAM-MIMO over MIMO decreases compared with that in LoS, however, the multi-path effects improve the absolute capacity of PSOAM-MIMO system, and the worst case are comparable with those in an MIMO system. As a result, the PSOAM-MIMO system demonstrates the strong robustness in wireless communications."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing has become the de facto computing platform for application processing in the era of the Internet of Things (IoT). However, limitations of the cloud model, such as the high transmission latency and high costs are giving birth to a new computing paradigm called edge computing (a.k.a fog computing). Fog computing aims to move the data processing close to the network edge so as to reduce Internet traffic. However, since the servers at the fog layer are not as powerful as the ones in the cloud, there is a need to balance the data processing in between the fog and the cloud. Moreover, besides the data offloading issue, the energy efficiency of fog computing nodes has become an increasing concern. Densely deployed fog nodes are a major source of carbon footprint in IoT systems. To reduce the usage of the brown energy resources (e.g. powered by energy produced through fossil fuels), green energy is an alternative option. In this paper, we propose employing dual energy sources for supporting the fog nodes, where solar power is the primary energy supply and grid power is the backup supply. Based on that, we present a comprehensive analytic framework for incorporating green energy sources to support the running of IoT and fog computingbased systems, and to handle the tradeoff in terms of average response time, average monetary, and energy costs in the IoT. This paper describes an online algorithm, Lyapunov optimization on time and energy cost (LOTEC), based on the technique of Lyapunov optimization. LOTEC is a quantified near optimal solution and is able to make control decision on application offloading by adjusting the two-way tradeoff between average response time and average cost. We evaluate the performance of our proposed algorithm by a number of experiments. Rigorous analysis and simulations have demonstrated its performance."
  },
  {
    "year": "2017",
    "abstract": "Providing stable and fast data transmission service is challenging in a high mobility wireless communication system, where massive multiple-input multiple-output (MIMO) beamforming is deemed as a potential solution. In the literature, the majority of previous works focused on how to optimize the beamforming scheme with traditional side information like perfect or imperfect channel state information (CSI) in non-mobile or low mobility scenarios. However, it is hard to either track the channel or obtain perfect CSI in the high mobility scenario without large online computation, because the wireless channel appears to be fast time varying and double-selective in the spatial-temporal domain. In this paper, by exploiting the special characters in the high mobility scenario, we introduce an applicable low-complexity beamforming scheme with transmit diversity in the high mobility scenario with the aid of location information. The beam is generated and selected mainly based on the location information, where the beam weight is optimized to maximize the total service that one BS can provide. Moreover, to guarantee a full diversity gain in this joint scheme, an optimal beam selection algorithm is proposed. Besides, to maximize the total service competence of one base station, a closed-form power allocation solution for the multi-user scenario is derived. To solve the potential inter-beam interference in massive MIMO system, a location-aided algorithm is proposed to eliminate the interference and maximize the mobile service of the whole train at the same time. Theoretical analysis and multiple simulation results show that our scheme approaches the theoretical performance bound of adaptive beamforming scheme but with much lower complexity."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the power dispatch and direct voltage control in multiterminal high voltage direct current (MT-HVDC) systems. Generalized voltage droop (GVD) control is adopted for voltage source converters (VSC)s of a MT-HVDC system. A mechanism has been designed based on the power ratio within the GVD controlled stations to achieve flexible autonomous coordination control among VSC-HVDC stations, without need for communication. In this paper, several alternatives are considered to guarantee fault ride through of onshore converter stations. The performance of the proposed control strategy is analyzed with time-domain dynamic simulations, in an EMDTC/PSCAD platform, and experimentally validated. Results demonstrate the robust performance and capabilities of the proposed control strategy during changes in the power demand of the ac grids, unexpected change in wind power generation, and eventual permanent VSC-HVDC station disconnection."
  },
  {
    "year": "2017",
    "abstract": "Low rank representation (LRR) is powerful for subspace clustering due to its strong ability in exploring low-dimensional subspace structures embedded in data. LRR is usually solved by iterative nuclear norm minimization, which involves singular value decomposition (SVD) at each iteration. However, the multiple SVDs limit the application of LRR due to its high computational cost. In this paper, we propose fast generalized LRR to address the above issue. Specifically, the nuclear norm and L2,1 norm in LRR are generalized to be the Schatten-p norm and L2,q norm, respectively. The new model is more general and robust than LRR. Then, we decompose the data matrix by Qatar riyal decomposition and convert the new model into a small-scale L2,p norm minimization problem, which requires no SVD and thus has low computational cost. An efficient algorithm based on alternating direction method is designed to solve the proposed problem. Experimental results on both synthetic and real-world data sets demonstrate the superiority of the proposed method over the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Reconstruction of a hand's motion with electroencephalography (EEG) signals is a challenging problem that has not been solved yet. Most related studies rely on a motion tracking system to record a sequence of hand coordinate values paired with biosignals, in order to train a mapping function between them. For amputees, this approach is not possible. There are also only a few studies about how different training techniques may affect the accuracy of a motion reconstruction system. A virtual avatar for presenting different upper limb motions was developed. Subjects were asked to follow the avatar's motion, while the subject's EEG and electromyography (EMG) signals were recorded and paired with avatar's hand trajectory values. This task was performed under three conditions: repeating the motion by memory, repeating the motion while watching it on a screen, and repeating the motion while seeing it in virtual reality (VR). We did not find any significant difference between the three conditions in terms of correlation values. Still, we found that using both EEG and EMG at the same time led to a better result than using only one of them. Additionally, significant differences were found in the EEG activity, suggesting that even if the task (moving the arm) was the same for the three conditions, the brain dynamics were different. Specifically, we found that using the VR resulted in a higher alpha desynchronization during the motion. Finally, our results, when only EEG signals were used, were comparable with other studies that have used a motion tracking system."
  },
  {
    "year": "2017",
    "abstract": "Huge amounts of data that are geo-tagged and associated with text information are being generated at an unprecedented scale in road sensor networks. Publish/subscribe system is one kind of important applications for analyzing and processing these huge mounts of data in road sensor networks, which is required to support millions of subscriptions and filter a message in milliseconds. Since the messages arrive continuously at a high speed, rapid processing of the messages is definitely a challenge. This paper mainly addresses the issue of parameterized spatio-textual publish/subscribe problem in road sensor networks. First, with considering both the network distance and textual similarity of the subscriptions and messages, the road network structure, together with the subscriptions and the messages will be partitioned and organized efficiently, and a combined index structure, called basic indexing architecture, is proposed. Second, several effective pruning techniques which consider both location information and textual information are presented to cut down the processing overhead. Moreover, by employing these pruning techniques into the basic indexing architecture, an more efficient index, called enhanced indexing architecture, is presented. Third, an efficient processing algorithm is designed to improve the scalability. Finally, extensive simulations are conducted to show the efficiency and scalability of the proposed methods in road sensor networks."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new clustering algorithm, the GPIC, a graphics processing unit (GPU) accelerated algorithm for power iteration clustering (PIC). Our algorithm is based on the original PIC proposal, adapted to take advantage of the GPU architecture, maintaining the algorithm’s original properties. The proposed method was compared against the serial implementation, achieving a considerable speedup in tests with synthetic and real data sets. A significant volume of real data application (>107records) was used, and we identified that GPIC implementation has good scalability to handle data sets with millions of data points. Our implementation efforts are directed towards two aspects: to process large data sets in less time and to maintain the same quality of the clusters results generated by the original PIC version."
  },
  {
    "year": "2017",
    "abstract": "There is a significant need to give careful consideration to Capability Maturity Model Integration (CMMI) Level 2 specific practices-SP 1.3 “manage requirements changes,”and SP 1.4 “maintain bidirectional traceability of requirements,”especially in the context of smalland medium-sized software development organizations in Saudi Arabia, in order to assist such organizations in getting one step closer to achieving CMMI Level 2 certification. The objective of this research is to implement CMMI Level 2 specific practices-SP 1.3 and SP 1.4. In this paper, a workflow model for each specific practice has been developed. In addition, initial evaluation of the models has been discussed. It is necessary to highlight that this paper contributes not only to the implementation of SP 1.3 and SP 1.4 of Requirements management process area in the context of smalland medium-sized software development organizations but also to the body of empirical studies in various context. Data has been collected by exploring published research articles and high-level software process descriptions. Moreover, previous research works that dealt with the implementation of CMMI Level 2 process areas have been reviewed. Furthermore, research articles that provide guidance to software development organizations for implementing process areas of CMMI Level 2 in their environments have been considered. After careful analysis of the collected data, we have proposed the models for two specific practices of CMMI level 2, i.e., managing requirements change and maintaining bidirectional traceability of requirements. Each model is divided into core stages, and different activities associated with each stage are clearly indicated. Initial evaluation of the proposed models was also conducted using the expert review process. Based on the initial evaluation, we are confident that our proposed models are clear and easy to learn, follow, and use. Moreover, our models are applicable to smalland medium-sized software de..."
  },
  {
    "year": "2017",
    "abstract": "Grid resource allocation mechanism maps tasks to the available grid resources according to some predefined criterion, such as minimizing makespan or execution cost, load balancing, energy efficiency, maintaining user-defined task deadlines, and efficiently using resource memory. The minimization of the makespan is a dominant criterion and is more challenging when computationally intensive tasks have realtime deadlines and data requirements. Such tasks require data files for processing that are transferred from data storage resources to the computing resources, which consume network bandwidth. Resource allocation mechanism for these tasks takes into account the data files transfer time and processing power of the computing resources to complete execution within deadlines. The problem of allocating real-time data-intensive tasks to the grid heterogeneous computing resources with the assumption that the data resources are decoupled from the computing resources, remain challenging. This paper addresses the aforementioned problem as the global optimization problem by considering heterogeneous computing resources of various processing capabilities connected to the data storage resources by network links of various bandwidths. We have analytically formulated the resources with the aim to maximize total number of mapped tasks while possibly minimizing the makespan subject to the time QoS constraints of deadlines, execution time, and data files transfer time. The experimental results reveal that the proposed technique outperforms the other alternatives when real-time tasks are considered."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a simple self-homodyne detection scheme is proposed and experimentally demonstrated for applications in optical access networks. Unmodulated pilot subframes are periodically inserted and interleaved with data subframes to form an orthogonal frequency-division multiplexing (OFDM) signal. Owing to the coherence between the embedded pilot and data subframes, a Mach-Zehnder delay interferometer with a free spectral range equal to the frequency of the subframe is deployed for the self-homodyne detection of the OFDM signal. It saves the local oscillator and optical hybrid, which are usually used in a conventional coherent receiver, thus reducing the hardware complexity and implementation cost. Meanwhile, the digital signal processing (DSP) for the self-homodyne detection is free from carrier-frequency-offset compensation and carrier-phase estimation, reducing the complexity, power consumption, and latency of the system. It also allows the use of a low-cost laser source as the source for the downstream signal. The proposed scheme provides a cost-effective and energy-efficient downstream solution for optical access networks, owing to the hardware saving and complexity reduction in DSP. A 10-Gb/s OFDM downstream transmission over a 20-km standard single-mode fiber is experimentally demonstrated with an error-free operation, using both a 10-MHz distributed feedback laser and a 100-kHz external cavity laser as downstream laser sources."
  },
  {
    "year": "2017",
    "abstract": "The health of a complex electromechanical system is dynamic and is accompanied by a full life cycle. Due to the complexity and coupling of complex electromechanical systems, the establishment of a dynamic and accurate model for the health state is difficult. A belief rule base (BRB) shows outstanding performance in modeling complex systems because it can combine both quantitative information and expert knowledge. In this paper, a double-layer BRB model is proposed to predict the health state of a complex electromechanical system. The two layers achieve different functions: BRB_layer1 is used to establish the dynamic change of the time series of features, BRB_layer2 is employed to combine the features for predicting the health state of the complex electromechanical system. During this process, the infinite irrelevance method is utilized for feature selection in reducing the scale of the BRB model. Considering the initial parameters are given by experts, which may have boundedness and may not be appropriate for engineering practice, the projection covariance matrix adaption evolution strategy (P-CMA-ES) is chosen as the optimization algorithm to train the initial parameters. To verify the rationality and effectiveness of the proposed model, the low-frequency vibration fault of a certain aero-engine is taken as an example. The results show that the proposed method can predict the health state of a complex electromechanical system precisely according to current and historical data."
  },
  {
    "year": "2017",
    "abstract": "Inter-turn short circuit (ITSC) fault is one of the critical electrical faults in induction motors that affects the reliability of many industrial applications. Although the use of data-driven fault detection techniques have gained much interest, the main deterrent in using these approaches in detecting ITSC faults is in the generalization and robustness of the diagnosis. In this paper, a data-driven on-line fault detection framework, incorporated with multi-feature extraction/selection and multi-classifier ensemble is proposed, capable of detecting ITSC faults in induction motors (IMs) that subjected to variable operating conditions. By using the synchronous time series signals collected from the machines, multiple feature extraction/selection is explored to find the sensitive faulty features, and the different types of classification strategies is used to increase the diversity of single based models. With the increased diversity of the base learners, the fault detection accuracy is expected to be enhanced and the robustness can be guaranteed. The framework was implemented and tested using real data collected from a designed test bed, with the experimental results showing the effectiveness of the framework in detecting ITSC faults in IMs."
  },
  {
    "year": "2017",
    "abstract": "A fully connected vehicular ad hoc network (VANET) establishes a strong foundation for the development of smart cities, where one of the main objectives is the improvement of the welfare of commuting passengers. The availability of a multi-hop path across a VANET system, through vehicle-to-vehicle communication, depends mainly on the vehicular density and the willingness of vehicles to cooperate with one another. This paper proposes to minimize the path availability's dependence on vehicular density and cooperation, by utilizing unmanned aerial vehicles (UAVs). Particularly, this paper explores, both mathematically as well as through an extensive simulation study, the advantages of exploiting UAVs as store-carry-forward nodes so as to enhance the availability of a connectivity path as well as to reduce the end-to-end packet delivery delay. The obtained results shed clear light on the benefits emanating from the coupling of UAVs with vehicles in the context of a highly promising, innovative, and hybrid vehicular networking architecture."
  },
  {
    "year": "2017",
    "abstract": "Because of enormous amount of images and videos to be transmitted in 5G, it is quite desirable to do aggressive downsampling in the transmission side. As a consequence, the co-prime-interpolated compressive sensing approach, which could recover the downsampled data in the receiver side, is proposed in this paper. The co-prime structure, interpolation, and compressive sensing are combined in order to improve the resolution of reconstructed images through compressive-sensing. The numerical analysis of root mean square error and peak signal-to-noise ratio is examined, respectively. This new approach is applied on the test image and real data. The results prove that our approach provides a potential solution for future heterogeneous network toward 5G."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose, design, and evaluate two indoor visible light communication (VLC) systems based on computer generated holograms (CGHs); a simple static CGH-VLC system and an adaptive CGH-VLC system. Each transmitter is followed by the CGH, and this CGH is utilized to direct part of the total power from the best transmitter and focus it to a specific area on the communication floor. This leads to reduction in inter-symbol interference and increasing in the received optical power, which leads to higher data rates with a reliable connection. In the static CG11H-VLC system, the CGH generates 100 beams (all these beams carry same data) from the best transmitter and directs these beams to an area of 2 m × 2 m on the communication floor. In the adaptive CGH-VLC system, the CGH is used to generate eight beams from the best transmitter and steer these beams to the receiver's location. In addition, each one of these eight beams carries a different data stream. Whereas in the first system, a single photodetector is used (added simplicity), an imaging receiver is used in the second one to obtain spatial multiplexing. We consider the lighting constraints where illumination should be at acceptable level and consider diffusing reflections (up to second order) to find the maximum data rate that can be offered by each system. Moreover, due to the fact that each beam in the adaptive CGH-VLC system conveys a different data stream, co-channel interference between beams is taken into account. We evaluate our proposed systems in two different indoor environments: an empty room and a realistic room using simple on-off-keying modulation. The results show that the static CGH-VLC system offers a data rate of 8 Gb/s while the adaptive CGH-VLC system can achieve a data rate of 40 Gb/s."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we introduce a new family of lattices, namely QC-MDPC lattices, which are a special case of LDPC lattices, and an improved bit flipping algorithm for decoding of these lattices. Encoding and decoding implementations of QC-MDPC lattices are practical in high dimensions. Indeed, to take advantage of practical decoding, we use “Construction-A”lattices which makes a tight connection between the structure of lattices and codes. Using these features, we design a lattice-based public key encryption scheme enjoying linear encryption and decryption complexities. The proposed scheme has a reasonable key size due to the sparseness of the parity-check matrix, and the quasi-cyclic structure of the parity-check and generator matrices. Besides, the message expansion of the proposed scheme is smaller than other lattice-based and code-based cryptosystems with comparative parameters. All these features provide a lattice-based public key encryption scheme with reasonable key size, linear encryption, and decryption algorithms and small message expansion. On the other hand, we show that the cryptosystem is resistant against all known attacks both on lattice-based and code-based cryptosystems for different levels of security."
  },
  {
    "year": "2017",
    "abstract": "Content delivery through cloud networks has gained popularity due to the cloud's ability to provide on-demand services. However, composite services, such as customized multimedia content, introduce both delays and resource limitations if traditional cloud solutions are used. With recent advances in mobile edge computing, customized media delivery can be achieved through compositions of service specific overlays (SSOs). This paper presents a workflow-net-based mechanism for mobile edge node cooperation in fog-cloud networks to form guaranteed SSOs. The proposed solution uses a mathematical cooperation operator to turn the SSO composition problem expressed as workflow nets into algebraic representations. In turn, the minimal cost cooperative path from the workflow net is determined such that it guarantees the delivery of the requested composite media services to clients. Experimental results show that the composition process can be adequately established and carried out in a timely manner."
  },
  {
    "year": "2017",
    "abstract": "Sparsely spread code division multiple access (SCDMA) is a non-orthogonal superposition coding scheme that allows concurrent communications between a base station and multiple users over a common channel. However, the detection performance of an SCDMA system is mainly determined by its signature matrix, which should be sparse to facilitate the belief propagation (BP) detection. On the other hand, to guarantee good maximum likelihood (ML) detection performance, the minimum Euclidean distance for the equivalent signal constellation after multi-user superposition should be maximized. In this paper, a code distance analysis is proposed for SCDMA systems with a finite number of users and spreading lengths. Based on this analysis, good signature matrices whose factor graphs have very few short cycles and possess large superposed signal constellation distances are designed. The proposed signature matrices have both good BP and ML detection performances. Moreover, their BP detection performances exactly converge to their ML detection performances with few iterations. It is worth pointing out that the proposed signature matrix design could be directly applied to the 5G non-orthogonal multiple access systems."
  },
  {
    "year": "2017",
    "abstract": "Classical spatial scan statistics are based on pre-defined shapes for scanning windows and specific distribution models and are used to detect latent cluster(s). However, the pre-defined windows (especially circularly shaped windows) may not be suitable for real situations, and the specific distribution models are inadequate for real clusters in which the exact distributions of the test statistics are only known in special cases. To generate more reasonable results, we propose a spatial scan statistic method with an irregularly shaped scanning window. A combinatorial particle swarm optimization method is used to optimize this window. A distribution-free concentration index is constructed to measure the difference between inside cluster and outside cluster. A compactness penalty function is employed to avoid generating clusters in a tree-structure. Simulation data sets are used to test the proposed method, and the results show the feasibility of our method."
  },
  {
    "year": "2017",
    "abstract": "Transparency of personal data processing is a basic privacy principle and a right that is well acknowledged by data protection legislation, such as the EU general data protection regulation (GDPR). The objective of ex post transparency enhancing tools (TETs) is to provide users with insight about what data have been processed about them and what possible consequences might arise after their data have been revealed, that is, ex post. This survey assesses the state of the art in scientific literature of the usability of ex post TETs enhancing privacy and discusses them in terms of their common features and unique characteristics. The article first defines the scope of usable transparency in terms of relevant privacy principles for providing transparency by taking the GDPR as a point of reference, and usability principles that are important for achieving transparency. These principles for usable transparency serve as a reference for classifying and assessing the surveyed TETs. The retrieval and screening process of the publications is then described, as is the process for deriving the subsequent classification of the characteristics of the TETs. The survey not only looks into what is made transparent by the TETs but also how transparency is actually achieved. A main contribution of this survey is a proposed classification that assesses the TETs based on their functionality, implementation and evaluation as described in the literature. It concludes by discussing the trends and limitations of the surveyed TETs in regard to the defined scope of usable TETs and shows possible directions of future research for addressing these gaps. This survey provides researchers and developers of privacy enhancing technologies an overview of the characteristics of state of the art ex post TETs, on which they can base their work."
  },
  {
    "year": "2017",
    "abstract": "Content-centric networking (CCN) introduces a paradigm shift from a host centric to an information centric communication model for future Internet architectures. It supports the retrieval of a particular content regardless of the physical location of the content. Content caching and content delivery networks are the most popular approaches to deal with the inherent issues of content delivery on the Internet that are caused by its design. Moreover, intermittently connected mobile environments or disruptive networks present a significant challenge to CCN deployment. In this paper, we consider the possibility of using mobile users in improving the efficiency of content delivery. Mobile users are producing a significant fraction of the total Internet traffic, and modern mobile devices have enough storage to cache the downloaded content that may interest other mobile users for a short period too. We present an analytical model of the CCN framework that integrates a delay tolerant networking architecture into the native CCN, and we present large-scale simulation results. Caching on mobile devices can improve the content retrieval time by more than 50%, while the fraction of the requests that are delivered from other mobile devices can be more than 75% in many cases."
  },
  {
    "year": "2017",
    "abstract": "Industry 4.0 is gaining more attention from the public, and thus the correlation between factories and nearby environmental pollution sources is a subject worth in-depth research. Among environmental issues, Particulate Matter2.5 (PM2.5) has received considerable attention in recent years from academic units and governments, and one of the secondary PM2.5 sources is the complex chemical reaction of exhaust gases emitted from factories and ammonia (NH3), with NH3 mostly coming from stock farming. Therefore, the correlation between stock farming data and pollutionsources emitted from factories can be examined by using an artificial neural network (ANN). The first target of this study is to investigate the correlation of factory air pollution source data and stock farming data nearby air monitoring stations to the annual mean PM2.5 concentration of nearby air monitoring stations. Second, the study uses Tensorflow to build an ANN model to analyze whether the industrial and stock farming data have an effect on the PM2.5 concentration. Weather data are taken in this experiment to learn about the correlation. The experimental results show that the Spearman’s correlation coefficient of the factory emitted air pollution data and stock farming data nearby air monitoring stations for the annual mean PM2.5 concentration is 0.6 to 0.9, representing positive correlation. The ANN experiment shows the annual mean PM2.5 concentration classification model with industrial data plus stock farming data plus weather data, in which the ANN classification accuracy is 0.75 as validated by mean square error (MSE) methods. Compared with the ANN classification model only with weather data, the MSE classification accuracy is 1.5. According to the two experiments, the industrial factor and stock farming factor are items that may influence the PM2.5 concentration change."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the problem of vision-based obstacle detection and tracking for unmanned aerial vehicle navigation. A real-time object localization and tracking strategy from monocular image sequences is developed by effectively integrating the object detection and tracking into a dynamic Kalman model. At the detection stage, the object of interest is automatically detected and localized from a saliency map computed via the image background connectivity cue at each frame; at the tracking stage, a Kalman filter is employed to provide a coarse prediction of the object state, which is further refined via a local detector incorporating the saliency map and the temporal information between two consecutive frames. Compared with existing methods, the proposed approach does not require any manual initialization for tracking, runs much faster than the state-of-the-art trackers of its kind, and achieves competitive tracking performance on a large number of image sequences. Extensive experiments demonstrate the effectiveness and superior performance of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Path planning is an important problem in autonomous control technology. This paper aims to overcome the shortcomings of the wolf pack algorithm (WPA), such as slow rate of convergence and low convergence precision, by improving the three intelligent behaviors of the WPA, namely, scouting, summoning, and beleaguering. To improve the scouting behavior, interactive scouting is proposed to increase the interactivity among wolf pack. Furthermore, to improve the summoning behavior, a prey-based adaptive step model is established to improve the searching ability. Finally, calculation rules of new beleaguering behavior are designed, which enhance the local fine search ability considerably. A fast path planning method based on dubins path was proposed, which applied the dubins path planning to meet angle control constraint and tunes the turning radius to meet control constraint. The dubins path planning method based on the modified WPA is proposed by establishing the underwater environment threat model under the condition of autonomous underwater vehicle constraint. The path between the path points is the shortest, the threat is minimal, and the energy consumption is the least without the consideration of ocean current. Simulation results show that the modified WPA has a high rate of convergence and good local search capability in the high-precision, high-dimensional, and multi-peak function; moreover, it does not converge prematurely."
  },
  {
    "year": "2017",
    "abstract": "The pilot spoofing attack is considered as an active eavesdropping activity launched by an adversary during the reverse channel training phase. By transmitting the same pilot signal as the legitimate user, the pilot spoofing attack is able to degrade the quality of legitimate transmission and, more severely, facilitate eavesdropping. In an effort to detect the pilot spoofing attack and minimize its damages, in this paper we propose a novel random-training-assisted (RTA) pilot spoofing detection algorithm. In particular, we develop a new training mechanism by adding a random training phase after the conventional pilot training phase. By examining the difference of the estimated legitimate channels during these two phases, the pilot spoofing attack can be detected accurately. If no spoofing attack is detected, we also present a computationally efficient channel estimation enhancement algorithm to further improve the channel estimation accuracy. For the case of the missed detection of the spoofing attack, we also propose a secure transmission algorithm for downlink data transmission to enhance the security. Extensive simulation results demonstrate that the proposed RTA scheme can achieve efficient pilot spoofing detection in all cases and its performance is superior to other state-of-the-art detectors."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new sparse signal recovery algorithm using variational Bayesian inference based on the Laplace approximation. The sparse signal is modeled as the Laplacian scale mixture (LSM) prior. The Bayesian inference with the Laplacian models is a challenge because the Laplacian prior is not conjugate to the Gaussian likelihood. To solve this problem, we first introduce the inverse-gamma prior, which is conjugate to the Laplacian prior, to model the distinctive scaling parameters of the Laplacian priors. Then the posterior of the sparse signal, approximated by the Laplace approximation, is found to be Gaussian distributed with the expectation being the result of maximum a posterior (MAP) estimation. Finally the expectation-maximization (EM)-based variational Bayesian (VB) inference is utilized to accomplish the sparse signal recovery with the LSM prior. Since the proposed algorithm is a full Bayesian inference based on the MAP estimation, it achieves both the ability of avoiding structural error from the sparse Bayesian learning and the robustness to noise from the MAP estimation. Analysis on experimental results based on both simulated and measured data indicates that the proposed algorithm achieves the state-of-art performance in terms of sparse representation and de-noising."
  },
  {
    "year": "2017",
    "abstract": "With the development of cyber-physical-social networks, researches on evaluating social influence have drawn increasing interests. Social influence indicates the importance of people in social networks. As a typical type of social networks, how to evaluate scholar influence in the academic social network has been a practical issue for research institutions. In this paper, we aim at evaluating the latent influence of scholars to find academic rising stars, which refer to scholars that may have few papers and little impact currently, but he or she will become influential scholars in the future. Most of the current works focus on the assessment of rising stars. However, there exists a growth period for each scholar. It is unfair for young scholars with limited resources, who will make acquaintance at conferences and recommendations and who will learn from senior scholars. In this paper, we primarily propose StarRank, which is an improved PageRank method to calculate the initial values of rising stars, construct the social network via explicit and implicit links, and apply the neural network to predict scholars' rankings in the future. The experimental results on real data set demonstrate that our method has a better performance than the-state-of-the-art methods on the count of hitting rising stars and the spearman correlation coefficient."
  },
  {
    "year": "2017",
    "abstract": "Saliency detection on an individual image as well as co-saliency detection from a group of images are currently popular topics or reflect future trends more recently due to their importance and challenging roles in computer vision. In many cases, co-saliency detection is usually dependent on the singleimage saliency detection results. Nevertheless, most efforts have been made to tackle them separately and not much attention has been paid to tackling them together in a unified idea. Being aware of these two tasks are highly related, the difference from previous surveys is that this paper applies a unified framework by employing a multi-instance learning (MIL) algorithm to resolve both the issues, and formulating singleimage saliency and co-saliency detection as top-down weakly supervised learning paradigm. Specifically, for single-image saliency detection, we utilize the evidence confidence-support vector machine algorithm to learn a discriminant model to predict the saliency on test images. For co-saliency detection from image group, we concatenate the EC values and saliency scores to obtain the final results of co-saliency detection. By observing the importance of the selection of negative bags in the MIL framework, we also introduce a novel selection strategy of negative bags to improve the robustness of the proposed method. Experimental results on publicly available image benchmark data sets have demonstrated that the proposed unified framework can achieve competitive performances as compared with the state-of-the-art algorithms in terms of accuracy and effectiveness."
  },
  {
    "year": "2017",
    "abstract": "For batch process fault detection, regular data-driven methods cannot distinguish quality-irrelevant faults from quality-relevant faults. To solve such problem, we propose a multiway multisubspace canonical variate analysis (MMCVA) method for the batch processes. First, the combination of batch-wise unfolding and variable-wise unfolding is adopted to unfold the three-way process and quality data in to two-way data. Then, we use CVA to project the process and quality data spaces to three subspaces, a process-quality correlated subspace, a quality-uncorrelated process subspace, and a process-uncorrelated quality subspace. Fault detection statistics are developed based on the three subspaces. The proposed MMCVA method is capable of indicating the normality or abnormality of the quality variables, while detecting a process fault. The simulation results of a fed-batch penicillin fermentation process illustrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the applicability of hand tremor-based biometric recognition via leap motion device is investigated. The hypothesis is that the hand tremor is unique for humans and can be utilized as a biometric identification. In order to verify our hypothesis, spatiotemporal hand tremor signals are acquired from subjects. The objective is to establish a live and secure identification system to avoid mimic and cloning of password by attackers. Various feature extraction methods, including statistical, fast Fourier transform, discrete wavelet transform, and 1-D local binary pattern are used. For evaluating recognition performance, Naïve Bayes and Multi-Layer Perceptron are utilized as linear-simple and nonlinear-complex classifiers, respectively. Since the conducted experiments produced promising results (above 95% of classification accuracy rate), it is considered that the proposed approach has the potential to be used as a new biometric identification manner in the field of security."
  },
  {
    "year": "2017",
    "abstract": "In image-centric social networks, such as Instagram and Pinterest, users tend to share photos with several tags. These tags describe the content of the image or provide additional contextual information, and therefore may not be necessarily tied to image content and usually carry personal preference. Annotating images in social networks in a personalized manner is in demand. However, the existing image annotation models, which rely only on image content information, cannot capture the user's tagging preference. In this paper, we propose a deep architecture for personalized image annotation by leveraging the wealth of information in user's tagging history. The proposed architecture consists of three components: two components for learning features of the image content and user's history tags and the other one for combining the two learned features to predict the tags. We also explore two ways to model user's history tags: 1) simply average the embeddings of user's history tags and 2) model user's history tags with a sequence model by long short-term memory recurrent neural network. We evaluate our proposed deep architecture on a large-scale and realistic data set, consisting of ~22.8 million public images uploaded by ~4.69 million users. Experimental results show that our proposed deep architecture is effective on a personalized image annotation task."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the uplink semi-persistent scheduling policy problem of minimizing network latency is considered for a training-based large-scale antenna system employing two simple linear receivers, a maximum ratio combiner and a zero-forcing receiver, while satisfying each user's reliability and latency constraints under an energy constraint. The network latency is defined as the air-time requested either to serve all users with a minimum quality-of-service, including reliability constraints and minimum throughput levels, or to maximize the spectral efficiency. Optimal non-orthogonal pilots are used to decrease the network latency. An optimization algorithm for determining the latency-optimal uplink scheduling policy using binary-integer programming (BIP) with an exponential-time complexity is proposed. In addition, it is proven that a linear programming relaxation of the BIP can provide an optimal solution with a polynomial-time complexity. Numerical simulations demonstrate that the proposed scheduling policy can provide several times lower network latency in realistic environments than conventional policies. The proposed optimal semi-persistent scheduling policy provides critical guidelines for designing 5G and future cellular systems, particularly for their ultra-reliable low-latency communication services."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new control chart using sudden death testing is designed by assuming that the lifetime/failure time of the product follows the Weibull distribution. The structure of the proposed chart is presented. The control chart coefficient is determined using some specified average run length for the in control process and the shifted process. Simulation study is given for the illustration purpose."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the problem of adaptive reliable H control for a class of T-S fuzzy systems with actuator failures. In contrast to work found in the literature, stochastic actuator failures are considered, and stochastic functions are used to denote failure scaling factors. By combining an adaptive method with a switching-type control mechanism, a novel and reliable static output feedback control scheme is developed, where adaptive parameters are updated such that failure effects are compensated effectively. Furthermore, an H∞performance index is proposed to attenuate the effects of sensor noises. Finally, a nonlinear massspring-damper example is presented to verify the effectiveness of the method proposed in this paper."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an adaptive polarization-QAM modulation (APQAM) scheme is proposed to improve the power amplifier (PA) energy efficiency (EE) in orthogonal frequency division multiplexing (OFDM) systems. Since we found that polarization modulation (PM) has better EE performance than QAM in the nonlinear region of PA while QAM outperforms PM in the linear region, we can combine these two modulation schemes together and adjust their modulation orders adaptively to obtain higher EE performance. First, a truncated Taylor series model is used to represent PA nonlinearity, so the effects of both the in-band distortions and the out-of-band emissions on the OFDM signals can be analyzed. Second, two APQAM algorithms are investigated in both AWGN channel and depolarization channel with power-dependent loss. Furthermore, symbol error rate performance of the APQAM scheme is obtained in different channel conditions, and the influence of channel estimation error is analyzed to testify the robustness of the proposed APQAM scheme. Simulation results show that, if perfect channel state information is obtained, the EE of the proposed scheme is nearly 50% more than that of the traditional QAM scheme in OFDM systems."
  },
  {
    "year": "2017",
    "abstract": "Software outsourcing partnership (SOP) is a type of cooperative client-vendor relationship for achieving mutually beneficial goals and is totally based on mutual trust and commitment. SOP is an emerging strategy and is different to ordinary software development outsourcing (SDO). Usually, a successful and long-lasting outsourcing association between client and vendor organization might be converted to outsourcing partnership. The overarching target of this exploratory paper is to analyze a list of factors that are considered important for vendors in the renovation of their surviving contractual outsourcing relationship to a partnership. We have executed a systematic literature review (SLR) process. We have performed all the SLR phases, like protocol development, publication collection, publication quality assessment, data generalization, and reporting. We have analyzed the factors found, through SLR, based on different variables such as continents, decades, and study strategy. Some factors like “mutual trust,” “effective communication,” “organizations proximity,” “mutual inter-dependence and shared values,” “3C (coordination, cooperation, and collaboration),” and “quality production” are marked as critical, because these momentously assist vendors in renovation of the standing outsourcing relationship with client into partnership. The factors are correlated to finding any significant relationships among the factors. Vendors should address all the listed success factors, especially the critical success factors in order to attain partner position in SDO. Our outcomes will help practitioners working on outsourcing collaboration in the SDO industry. They can determine from the results of the study where to outsource and which are the emerging trends in software outsourcing."
  },
  {
    "year": "2017",
    "abstract": "The cross-layer resource assignment algorithm of orthogonal frequency division multiple access (OFDMA) video communication systems by Wang et al. allocates the power and subcarriers according to both the layer 1 channel state information and the layer 5 rate distortion function. We introduce the hybrid automatic repeat request (HARQ) in layer 2 and a single-input multiple-output (SIMO) anti-jamming technique in layer 1, and propose an anti-jamming power/subcarrier assignment scheme crossing layers 1, 2, and 5 for HARQ-based SIMO OFDMA uplink video communication networks. We derive the new optimal condition for anti-jamming cross-layer resource allocation analysis, and thus propose a novel resource allocation method crossing layers 1, 2, and 5 by considering the angle between the jammer channel vector and the sender (desired signal) channel vector. By HARQ, we can increase the target symbol error rate without increasing the rate of the packet error, more bits can be transmitted, and the peak signal-to-noise ratio (PSNR) (the video quality) is improved. The results of the simulations show that the PSNR increases by 11.3 dB when we consider the angle between the jammer channel vector and the sender channel vector in the proposed resource allocation algorithm crossing layers 1, 2, and 5. The PSNR improves further by 1.8-2.6 dB when we add HARQ, when the average SNR = 18 dB and there are 12 users."
  },
  {
    "year": "2017",
    "abstract": "As the complexity of cyber-attacks keeps increasing, new robust detection mechanisms need to be developed. The next generation of Intrusion Detection Systems (IDSs) should be able to adapt their detection characteristics based not only on the measurable network traffic, but also on the available highlevel information related to the protected network. To this end, we make use of the Pattern-of-Life (PoL) of a computer network as the main source of high-level information. We propose two novel approaches that make use of a Fuzzy Cognitive Map (FCM) to incorporate the PoL into the detection process. There are four main aims of the work. First, to evaluate the efficiency of the proposed approaches in identifying the presence of attacks. Second, to identify which of the proposed approaches to integrate an FCM into the IDS framework produces the best results. Third, to identify which of the metrics used in the design of the FCM produces the best detection results. Fourth, to evidence the improved detection performance that contextual information can offer in IDSs. The results that we present verify that the proposed approaches improve the effectiveness of our IDS by reducing the total number of false alarms; providing almost perfect detection rate (i.e., 99.76%) and only 6.33% false positive rate, depending on the particular metric combination."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a once-differentiable control strategy for a class of uncertain nonaffine nonlinear systems based on self-structuring neural networks (SSNNs) approximation, such that the system output tracks the desired trajectory. The optimal weight for each neuron in current SSNN is time-varying signals factually, and current stability analysis is only fit for a dwell time. Current SSNN control laws are not smooth and even not continuous, due to addition or pruning of neurons in the approximation procedure. In this paper, a new SSNN estimator and a new weight update law are proposed to ensure the optimal SSNN weights being constant values and the control law being once-differentiable. The effectiveness of the proposed control law is illustrated by the stability analysis in the whole tracking procedure and shown by the simulation results."
  },
  {
    "year": "2017",
    "abstract": "Many classical visual odometry and simultaneous localization and mapping methods are able to achieve excellent performance, but mainly are restricted on the static scenes and suffer degeneration when there are many dynamic objects. In this paper, an efficient coarse-to-fine algorithm is proposed for moving object detection in dynamic scenes for autonomous driving. A motion-based conditional random field for this task is modeled. Particularly, for initial dynamic-static segmentation, a superpixel-based binary segmentation is processed, and further for refinement, a pixel-level object segmentation in local region is performed. Additionally, to reduce the projection noise caused by disparity estimation, an approximate Mahalanobis normalization is provided. Finally, in order to evaluate the proposed method, two relative methods are compared as baseline on the public KITTI data set for visual odometry and moving object detection separately. The experiments show the effectiveness and improvement on odometry when the dynamic region is removed and also on moving objects detection."
  },
  {
    "year": "2017",
    "abstract": "This paper presents results from an extensive measurement campaign of multi-user channels with large-scale antenna arrays (MULAs) in a subway station environment. Based on the measurements, two spatial separation metrics are characterized. The variance of user separability and temporal behavior are investigated. Furthermore, a MULA channel model with transmit correlation is proposed, which ensures that the MULA channels can be generated with a given degree of compatibility. The proposed MULA model is validated by comparing the distributions of the sum rate capacity and the condition number to measurements."
  },
  {
    "year": "2017",
    "abstract": "Controlling and quantifying the presence of Posidonia Oceanica (P.O.) in the Mediterranean sea is crucial for the conservation of these endemic ecosystems and to underscore the negative impact of many anthropogenic activities. These activities, which include uncontrolled leisure anchoring or illegal drag fishing, directly affect the tourism and fishing industries. Nowadays, the control and quantification of P.O. is done by divers, in a slow and imprecise process achieved in successive missions of a duration limited by the capacity of the oxygen scuba tanks. This paper proposes the application of robotic and computer vision technologies to upgrade the current P.O. control methods, building large scale coverage maps using the imagery provided by an autonomous underwater vehicle endowed with a bottom-looking camera. The process includes four main steps: 1) training a classifier based on two different Gabor filter image patch descriptors and a support vector machine; 2) detecting P.O. autonomously, both on-line and off-line, in each individual image; 3) color photo-mosaicking the area explored by the vehicle to obtain a global view of the meadow structure; these mosaics are extremely useful to analyze the structure and extension of the meadow and to calculate some of the biological descriptors needed to diagnose its state; and 4) building a binary coverage map in which the classification results of areas with image overlap are fused according to four different strategies. The experiments, performed in coastal areas of Mallorca and Girona, evaluate and compare the proposed descriptors and fusion techniques, showing, in some cases, accuracies and precisions above 90% in the detection of different patterns of P.O., from video sequences at different locations, in different seasons and with different environmental conditions."
  },
  {
    "year": "2017",
    "abstract": "Increasing the size of target arrays is beneficial to reuse fault-free processing elements (PEs) for reconfiguring 2-D mesh-connected processor arrays with faults. In this paper, we discuss the reconfiguration problem under the row and column rerouting constraint. We present a novel approach, making use of the idea of integer programming, for constructing larger size target arrays. Meanwhile, we propose a new method to deal with the fault-free processing elements in the physical row that is selected for exclusion. Compared with the state-of-arts algorithms, our method can make the fault-free PEs used as much as possible, which means the size of the target array can be significantly improved. Experimental results show that, compared with previous studies, the proposed algorithm achieves better results in terms of the usage rate of fault-free PEs in the host array."
  },
  {
    "year": "2017",
    "abstract": "Secure and efficient lightweight user authentication protocol for mobile cloud computing becomes a paramount concern due to the data sharing using Internet among the end users and mobile devices. Mutual authentication of a mobile user and cloud service provider is necessary for accessing of any cloud services. However, resource constraint nature of mobile devices makes this task more challenging. In this paper, we propose a new secure and lightweight mobile user authentication scheme for mobile cloud computing, based on cryptographic hash, bitwise XOR, and fuzzy extractor functions. Through informal security analysis and rigorous formal security analysis using random oracle model, it has been demonstrated that the proposed scheme is secure against possible well-known passive and active attacks and also provides user anonymity. Moreover, we provide formal security verification through ProVerif 1.93 simulation for the proposed scheme. Also, we have done authentication proof of our proposed scheme using the Burrows-Abadi-Needham logic. Since the proposed scheme does not exploit any resource constrained cryptosystem, it has the lowest computation cost in compare to existing related schemes. Furthermore, the proposed scheme does not involve registration center in the authentication process, for which it is having lowest communication cost compared with existing related schemes."
  },
  {
    "year": "2017",
    "abstract": "Data representation and similarity measurement are two basic aspects of similarity detection in time series data mining. In this paper, we present two novel approaches to perform similarity detection efficiently and effectively. One is composed of a new time series representation model and a corresponding similarity measure, which is called fragment alignment distance (FAD); the other applies dynamic time warping to the representation model of FAD and is called FAD_DTW. The new data representation model is based on the trend information of time series, which can provide a concise yet feature-rich representation of time series. FAD is able to align the segments of time series in linear time, which greatly accelerates the similarity detection process. We extensively compare FAD and FAD_DTW with state-of-the-art time series representation models and similarity measures in classification and clustering frameworks. Experimental results from efficiency and effectiveness validations on various data sets demonstrate that FAD and FAD_DTW can achieve fast and accurate similarity detection. In particular, FAD is much faster than the other methods."
  },
  {
    "year": "2017",
    "abstract": "Sparse code multiple access (SCMA) has been proposed as a candidate air interface (AI) technique for 5G wireless networks. However, the existing resource management schemes with predesigned SCMA codebooks cannot fully exploit user diversities in the frequency domain, thus degrading the performance of SCMA systems. To fully exploit the potential of SCMA, in this paper, we design a more flexible and configurable SCMA through adaptively adjusting the codebook design and assignment according to the user's features. Specifically, for the uplink networks, first we formulate a detection complexity minimization problem by jointly considering the codebook design (i.e., mapping matrix and constellation graph design) and codebook assignment, which is an integer linear program and NP-hard in general. To tackle this hard problem effectively, first we borrow the idea of dual coordinate search to devise a suboptimal but computational efficient algorithm to determine the mapping matrix and codebook assignment. Based on the obtained mapping matrix, we use the multi-dimensional modulation characteristic of SCMA to carefully design the constellations for each codebook to further reduce the detection complexity. For the downlink networks, we formulate a total power consumption minimization problem by jointly considering the codebook design and assignment and power allocation. Exploiting the special structure of the problem, we employ the Lagrangian dual decomposition technique to propose a fast iterative algorithm, which can solve the problem optimally with low complexity. Finally, we present extensive simulations to exhibit the performance improvement against other algorithms in terms of detection complexity and power consumption. The modified SCMA in this paper can be intelligently optimized based on service and user awareness, which can provide some guidelines for the design of software-defined AI in future wireless networks."
  },
  {
    "year": "2017",
    "abstract": "Kernel principal component analysis (KPCA) has been a state-of-the-art nonlinear process monitoring method. However, KPCA assumes the single operation mode while the real industrial processes often run under multiple operation conditions. In order to monitor the nonlinear multimode processes effectively, this paper proposes a modified KPCA method assisted by the local statistical analysis, referred to as local statistics KPCA (LSKPCA). In the proposed method, two kinds of strategies, including local probability density estimation and statistics pattern analysis, are integrated to improve the traditional KPCA method. To handle the multimode characteristic of industrial processes, local probability density estimation is developed to transform the monitored variables into their probability density values, which follow the unimodal data distribution. For further extracting the statistical information among the process data, statistics pattern analysis technique is applied to capture various orders of statistics, including one-order, second-order, and high-order ones, which constitute the statistics pattern matrix of the monitored data. Furthermore, KPCA modeling is performed on the statistics pattern matrix. The simulations on one numerical example and the continuous stirred tank reactor system demonstrate that the proposed LSKPCA method has the superior fault detection performance compared with the conventional KPCA method."
  },
  {
    "year": "2017",
    "abstract": "Resilient vectorial Boolean functions are desirable for both stream cipher and block cipher, which are widely used in information security protection. The tradeoffs between resiliency and nonlinearity have received considerable attention. In this paper, a new method for constructing highly nonlinear resilient vectorial Boolean functions is presented. It is shown that this method can provide resilient vectorial functions with the currently best known nonlinearity, which is confirmed using examples."
  },
  {
    "year": "2017",
    "abstract": "The research of social influence is an important topic in online social network analysis. Influence maximization is the problem of finding k nodes that maximize the influence spread in a specific social network. Robust influence maximization is a novel topic that focuses on the uncertainty factors among the influence propagation models and algorithms. It aims to find a seed set with a definite size that has robust performance with different influence functions under various uncertainty factors. In this paper, we propose a centrality-based edge activation probability evaluation method in the independent cascade model. We consider four different types of centrality measurement methods and add a modification coefficient to evaluate the edge probability. We also propose two algorithms, called NewDiscount and GreedyCIC, by incorporating the edge probability space into previous algorithms. With extensive experiments on various real online social network data sets, we find that our PageRank-based greedy algorithm has the best influence spreads and lowest running times, compared with other algorithms, on some large data sets. The experiment for evaluating the robustness performance shows that all algorithms have optimal robustness performance when the modification coefficient is set to 0.01 under the independent cascade model. This result suggests some further research directions under this model."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a concurrent structure-control design is applied to a five-bar parallel robot in order to minimize the tracking error in a high-speed task. The high power necessary to perform the task leads to a challenging problem in handling a physical constraint on the maximum torque as well as on the structure-control design parameters. Three constraint-handling techniques, the feasibility rules, ε-constrained method and stochastic ranking have been used to analyze how the design changes as the torque constraint are reduced. Studying torque reduction is important from the energy consumption point of view, as well as the use of lighter and cheaper motors. In addition, a comparison among the three constraint-handling techniques is implemented so as to observe the performance and quality of the obtained results. The final results suggest that stochastic ranking method always obtains feasible and successful solutions in all proposed torque limits."
  },
  {
    "year": "2017",
    "abstract": "Basing on the characteristic mode theory, this paper develops the concepts of source-mode (SM) couplings and mode-mode (MM) couplings, which characterized by the modal weighting coefficients and the inter-modal coupling coefficients, respectively. It is found that SM couplings could be adjusted by MM couplings when feeding configuration remains unchanged. Therefore, just by properly adjusting mode-mode couplings, we can reduce Q factor of an antenna at its center frequency and hence its bandwidth could be extended. A new time-saving optimization method based on controlling mode-mode couplings is also proposed. Two examples (one is lossless and the other one is lossy) are given and analyzed in detail to show how to control mode-mode couplings in order to reduce Q factor at the center frequency and hence enhance -10 dB bandwidth."
  },
  {
    "year": "2017",
    "abstract": "The emerging need for the current medical devices to achieve immediate visualization and performing diagnostic imaging at real time augurs the demand for high computational power of the associated electronic circuitry. The demand for such a high computational requirement is often met by using software methods to accelerate the computation, which is possible only to a certain extent, impairing the feasibility of real-time imaging and diagnosis. In this paper, a new method of using digital signal processors (DSPs) with a specialized pipelined vision processor (PVP) embedded at the hardware level to accelerate the routinely time-consuming imaging computation is proposed and validated. A lab prototype is built for the feasibility study and clinical validation of the proposed technique. This unique architecture of the PVP in a dual-core DSP offers a high-performance accelerated framework along with its large on-chip memory resources, and reduced bandwidth requirement provides as an ideal architecture for reliable medical computational needs. We have taken two sets sample studies from SPECT for validation-27 cases of thyroid medical history and 20 cases of glomerular filtration rate of kidneys. The results were compared with definitive post-scan SIEMENS image analysis software. From the statistical results, it is clearly shown that this method achieved very superior accuracy and 250% acceleration of computational speed."
  },
  {
    "year": "2017",
    "abstract": "At present, infrared polarization and intensity image fusion algorithms often cause fused images to appear fuzzy, making the fused image unable to be processed further. In this paper, a new infrared polarization and intensity image fusion algorithm is proposed, and the fused image is divided into base layer image and detail layer image. The infrared intensity image is used as the base layer image, and the infrared polarization image is decomposed by a multi-scale Gaussian filter and residual method. Next, a structural similarity index is introduced as the constraint of the multi-scale decomposition layers, and the detail layer image is obtained by summing of feature images of infrared polarization image. Finally, the fused image is obtained by the superimposition of the base layer image and detail layer image. The fused image retains all the features of the infrared intensity image and the majority of the polarization image features. The experimental results demonstrated that the fused image obtained by the proposed method performed better in both subjective and objective qualities."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a no-reference image quality assessment (IQA) metric for noise-distorted images specifically based on frequency mapping (FM), namely, FMIQA index. First, we decompose the image into intrinsic mode functions (IMFs) from small to large scale by using bidimensional empirical mode decomposition (BEMD), and perform the local feature analysis on the IMFs by Riesz transform. Considering that the combination of BEMD and Riesz transform can denoise the noise-distorted image, we use this method with appropriate application of visual contrast sensitivity function to get the denoised image. Then we calculate the similarity map of the Riesz transform feature maps from the distorted image and the denoised image to obtain the similarity indices. Finally, we combine these similarity indices to obtain the final index. Experimental results on three public databases show that the proposed FMIQA evaluates the noise-distorted image in consistency with subjective assessment and can obtain better performance in image quality prediction than other existing related methods."
  },
  {
    "year": "2017",
    "abstract": "Polar codes, ever since their introduction, have been shown to be very effective for various wireless communication channels. This, together with their relatively low implementation complexity, has made them an attractive coding scheme for wireless communications. Polar codes have been extensively studied for use with binary-input symmetric memoryless channels but little is known about their effectiveness in other channels. In this paper, a novel methodology for designing multilevel polar codes that works effectively with arbitrary multidimensional constellations is presented. In order for this multilevel design to function, a novel set merging algorithm, able to label such constellations, is proposed. We then compare the error rate performance of our design with that of existing schemes and show that we were able to obtain unprecedented results in many cases over the previously known best techniques at relatively low decoding complexity."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we provide a comprehensive review of diverse index modulation (IM) architectures that operate in the space, time, and frequency domains, as well as their related technologies. We clarify that several IM-specific characteristics have explicit advantages over those of the conventional bandwidthefficient counterparts, such as spatial multiplexing, orthogonal frequency division multiplexing, and singlecarrier frequency division multiple access, which have been widely employed in the current wireless standards. While, for the next-generation wireless systems, multiple performance requirements that conflict with each other have been imposed, IM schemes have the potential of satisfying part of the requirements, in addition to enhancing bandwidth efficiency. More specifically, we characterize operational scenarios and system settings that specifically benefit from IM schemes versus their non-IM counterparts while clarifying the fundamental limitations and the open issues for IM schemes that have not been sufficiently explored previously. Furthermore, we also present the rationale of the recent novel IM scheme that amalgamates the time-domain IM scheme and the concept of faster-than-Nyquist signaling and attains a rate enhancement together with a low peak-to-average power ratio."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a polarization filtering-based transmission scheme to enhance the physical layer security in the dual-polarized satellite communication. To prevent eavesdropping, this paper first divides the information sequence into two parts and modulates them independently. Subsequently, a pair of dual polarization states (PSs) is selected to carry the two modulated signals based on the designed selection rule. Last but not least, two polarized signals are added up and transmitted by the orthogonally dual-polarized antenna. Based on the assumption that the selection rule of the dual polarization states is synchronous among the legitimate users, the legitimate users can separate the two polarized signals by polarization filtering (PF). After that, the polarization match is performed to the two polarized signals, respectively. Then according to the demodulation rule, the information can be recovered. However, the eavesdropper does not know the PS selection rule and could not separate the two signals. Therefore, it is impossible for the eavesdropper to recover any useful information so that the security can be enhanced. In addition, the PSs of the signals will be changed due to the polarization dependent loss effect of the satellite channel, which leads to the PF performance degradation. To tackle this problem, a zero-forcing pre-filter is utilized at the receiver side. Finally, the security performance is validated by the theoretical analysis and simulation results in the dual-polarized satellite systems."
  },
  {
    "year": "2017",
    "abstract": "The Tactile Internet presently constitutes a vision of an Internet over which, in addition to current communications modalities, a sense of touch can be transported. In that case, people would no longer need to be physically near the systems they operate, but could control them remotely. The main problem that needs to be solved to realize the Tactile Internet is summarized by the “1 ms challenge.”If the response time of a system is below 1 ms, the end-user will not be able to tell the difference between controlling a system locally or from another location. This paper offers a summary of the requirements for haptic communications, followed by an overview of challenges in realizing the Tactile Internet. In addition, possible solutions to these challenges are proposed and discussed. For example, the development of the fifth generation mobile communication networks will provide a good foundation upon which a Tactile Internet could be built. This paper also describes the design of a modular testbed needed for testing of a wide variety of haptic system applications."
  },
  {
    "year": "2017",
    "abstract": "Patients with Parkinson's disease (PD) may have difficulties in speaking because of reduced coordination of the muscles that control breathing, phonation, articulation, and prosody. Symptoms that may occur are weakening of the volume of the voice, voice monotony, changes in the quality of the voice, the speed of speech, uncontrolled repetition of words, and difficult speech intelligibility. To date, evaluation of the speech intelligibility is performed based on the unified PD rating scale. Specifically, section 3.1 (eloquence) of the cited scale provides the specialist with some tips to evaluate the patient's speech ability. With the aim of evaluating the speech intelligibility by measuring the variation in parameters in an objective manner, we show that a speech-to-text (STT) system could help specialists to obtain an accurate and objective measure of speech, phrase, and word intelligibility in PD. STT systems are based on methodologies and technologies that enable the recognition and translation of spoken language into text by computers and computerized devices. We decided to base our study on Google STT conversion. We expand Voxtester, a software system for digital assessment of voice and speech changes in PD, in order to perform this study. No previous studies have been presented to address the mentioned challenges based on STT. The experiments here presented are related with detection/classification between pathological speech from patients with PD and regular speech from healthy control group. The results are very interesting and are an important step toward assessing the intelligibility of the speech of PD patients."
  },
  {
    "year": "2017",
    "abstract": "To solve the problem of power shortage during load peak periods, policy-driven demand response (PDDR) is put forward in China. This paper proposes a novel PDDR scheme based on potential load values. An index of PDDR is established to identify the characteristics of industry load clients, who have signed contracts with power utilities. The deviation-maximization algorithm is introduced to quantify potential load values for these industry loads. Four different capabilities of PDDR are defined in this method, including daily peak shifting, weekly peak shifting, monthly peak shifting, and peak shedding separately. According to their different PDDR abilities, all clients will be assigned to four groups and the total load gap is resolved into four levels as well. By modeling the four means, respectively, this paper presents an effective PDDR scheme with multi-time scales. Taking Nanjing City, China, as an example, numerical simulations and practical results illustrate that the proposed method is an effective way to address the problem of power deficit during peak time, as well as to improve the security and efficiency of power grid operation."
  },
  {
    "year": "2017",
    "abstract": "Recognizing the certain person of interest in cameras of different viewpoints is known as the task of person re-identification. It has been a challenging job considering the variation in human pose, the changing illumination conditions and the lack of paired samples. Previous matching techniques in the person re-identification field mainly focus on Mahalanobis-like metric learning functions. Taking advantage of the sparse representation and collaborative representation, we propose a new approach that elaborately exploits both the globality and locality of images. First, we explore multi-feature extraction with different spatial levels. The extracted features are then projected to a common subspace which handles dimension reduction. Second, we learn a single dictionary for each level that is invariant with the changing of viewpoints. Third, we adopt a weighted fusion approach that combines the dictionary learning-based sparse representation with collaborative representation. Experiments on two benchmark re-identification data sets (VIPeR and GRID) justify the advances of our integration algorithm by comparing with several state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "A simple multi-objective cross-entropy method is presented in this paper, with only four parameters that facilitate the initial setting and tuning of the proposed strategy. The effects of these parameters on improved performance are analyzed on the basis of well-known test suites. The histogram interval number and the elite fraction had no significant influence on the execution time, so their respective values could be selected to maximize the quality of the Pareto front. On the contrary, the epoch number and the working population size had an impact on both the execution time and the quality of the Pareto front. Studying the rationale behind this behavior, we obtained clear guidelines for setting the most appropriate values, according to the characteristics of the problem under consideration. Moreover, the suitability of this method is analyzed based on a comparative study with other multi-objective optimization strategies. While the behavior of simple test suites was similar to all methods under consideration, the proposed algorithm outperformed the other methods considered in this paper in complex problems, with many decision variables. Finally, the efficiency of the proposed method is corroborated in a real case study represented by a two-objective optimization of the microdrilling process. The proposed strategy performed better than the other methods with a higher hyperarea and a shorter execution time."
  },
  {
    "year": "2017",
    "abstract": "The impact of online social networks on information exchange between humans has revealed the need to study the mechanisms of information diffusion. Multiple prior works have considered empirical studies and introduced new diffusion models to understand the dynamics of the diffusion process. However, the complexity of network structures and user interactions make it challenging to model the diffusion mechanisms of online social networks and to accurately predict diffusion. In this paper, we propose an information diffusion prediction model based on a physical radiation energy transfer mechanism. The aim of this model is to predict the diffusion graph of a certain contagion throughout an interest-based community. This non-parametric model can accommodate the dynamicity of online social networks because it can receive different input diffusion parameters at different diffusion contagions. With our RADiation DIFFusion (RADDIFF) model, we precisely capture the information diffusion process from both temporal and spatial dimensions and measure the level of influence initiated by certain influencers for each diffusion process. To our knowledge, this model is the first in this domain that exploits the prediction of information networks based on a physical radiation mechanism. We conduct an extensive analysis using an experiment that includes two well-known prediction diffusion models, the linear influence model (LIM) and NETINF. The results show that RADDIFF effectively outperforms both the LIM and NETINF in terms of accuracy and the quality of forecast."
  },
  {
    "year": "2017",
    "abstract": "The orbital angular momentum (OAM) technology is able to provide a new degree of freedom for wireless communication systems. The energy of OAM waves is focused within a circle region surrounding the beam axis, which makes the propagation gains inside and outside the circle region different. However, in the existing literature, the propagation gains inside and outside the circle region are assumed to be the same. Therefore, the impact of OAM waves' spatial energy distribution on the capacity of OAM wireless communication systems has not been fully investigated. Considering the spatial energy distribution characteristics of OAM waves, in this paper, an OAM wireless channel model is proposed. Based on the proposed OAM wireless channel model, the capacity of OAM-based multiple-input multiple-output (MIMO) communication system is analytically derived. Simulation results indicate that the capacity of OAM-based MIMO system outperforms the capacity of conventional MIMO system when the transmission distance is larger than a specific threshold. Our results provide a basic capacity model for OAM-based MIMO communication systems."
  },
  {
    "year": "2017",
    "abstract": "As a key component of intelligent vehicle technology, automatic parking technology has become a popular research topic. Automatic parking technology can complete parking operations safely and quickly without a driver and can improve driving comfort, while greatly reducing the probability of parking accidents. An automatic parking system based on parking scene recognition is proposed in this paper to resolve the following issues with existing automatic parking systems: parking scene recognition methods are less intelligent, vehicle control has a low degree of automation, and the research scope is limited to traditional fuel vehicles. To increase the utilization of parking spaces and parking convenience, machine vision and pattern recognition techniques are introduced to intelligently recognize a vertical parking scenario, plan a reasonable parking path, develop a path tracking control strategy to improve the vehicle control automation, and explore a highly intelligent automatic parking technology roadmap. This paper gives three key aspects of system solutions for an automatic parking system based on parking scene recognition: parking scene recognition, parking path planning, and path tracking and control."
  },
  {
    "year": "2017",
    "abstract": "Recently, owing to changes in weather conditions, cyanobacterial blooms, also known as harmful algal blooms (HABs), have caused serious damage to the ecosystems of rivers and lakes by producing cyanotoxins. In this paper, for the removal of HABs, an algal bloom removal robotic system (ARROS) is proposed. The ARROS has been designed with a catamaran-type unmanned surface vehicle (USV) and an algae-removal device attached below. In addition, electrical control systems and a guidance, navigation, and control (GNC) system are implemented on the ARROS to remove the algal bloom autonomously. Moreover, to increase the efficiency of the work, an unmanned aerial vehicle (UAV) is utilized and the system detects algal blooms with an image-based detection algorithm, which is known as a local binary pattern. The overall mission begins with a command from a server when the UAV detects an algal bloom, and the USV follows the given path autonomously generated by a coverage path planning algorithm. Subsequently, with an electrocoagulation and floatation reactor under the USV, HABs are removed. The performance of the algal bloom detection and HABs removal is verified through outdoor field tests in Daecheong Dam, South Korea."
  },
  {
    "year": "2017",
    "abstract": "Sequential allocation is a decentralized mechanism for allocating indivisible objects to agents, in which agents sequentially pick their favorite objects among the remainder based on a pre-defined priority ordering of agents (a sequence). The problem of choosing the “best”sequence of agents to achieve the optimal social welfare has been investigated and conjectured to be NP-hard. We propose a simple parallel allocation protocol that is insensitive to agents' identities. In every round of the parallel allocation process, every agent asks for an object among those that remain, and every reported object will be allocated randomly to an agent reporting it. Supposing additive utilities and independence between the agents, we compare the average (and worst-case) social welfare achieved by a parallel protocol and a sequential protocol. Theoretical and empirical results show that parallel protocol outperforms a sequential protocol (even when the best sequence of agents is applied). We also show that under the parallel mechanism, some manipulation problems (e.g., finding a successful strategy for a target set and finding an optimal strategy under some scoring function) can be solved in polynomial time."
  },
  {
    "year": "2017",
    "abstract": "How to design antenna arrays plays an important role in wireless communications, especially when there are hundreds of antennas. In massive multiple-input and multiple-output (MIMO), if the number of antennas and RF chains are increasing, the channel capacity and transmission efficiency could be obviously improved as well. Since in massive MIMO, antennas at the base station (BS) usually scale up greater than 100, the complexity and hardware requirement of the system are also increased. Many studies about massive MIMO are focused on the analysis of channel capacity, precoding, and so on, and very few are about the sparse antenna array deployment. Based on the sparse linear array structures as indicated by previous studies, three new arrays, namely co-prime cylindrical array (CCA), nested cylindrical array (NCA), and sparse nested cylindrical array (SNCA), are proposed, which are based on co-prime linear array, nested linear array, and sparse circular array, respectively. Compared with the traditional uniform cylindrical array (UCA), the proposed arrays vastly reduce the number of antennas used at the BS. In addition, the performance of spatial resolution and channel capacity of CCA, NCA, and SNCA are discussed in detail. The results show that our proposed sparse cylindrical arrays can obtain a higher resolution with much fewer antennas. Besides, the uplink channel capacity of all the three sparse cylindrical arrays is larger than the UCA with the same number of antennas at the BS."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new mobility metric called generalized speed factor (GSF) is proposed by extending the existing speed factor, which assumes that all vehicles have the same speed at all times. The GSF defines an actual relationship between the inter-vehicle spacing and the relative speed of consecutive vehicles. The vehicle connectivity in three different mobile environments based on GSF is analyzed, i.e., temporal static connectivity, low mobility connectivity, and high mobility connectivity. It is shown that the connectivity probability Pc is directly proportional to the mean velocity μv up-to a specific threshold μτ, and after μτ the connectivity starts going down. Finally, network connectivity is extended to the best route selecting metric for the most strongly connected route. Simulation results show that a congested network is strongly connected as compared with sparse vehicular ad hoc network."
  },
  {
    "year": "2017",
    "abstract": "In named data networking (NDN), content store (CS) is proposed to provide on-path cache service. When user's request with content name is forwarded to NDN node, exact match in CS is carried out first. Under moderate cache hit ratio, most requests result in mismatch in CS searching process, which causes large overhead to the packet forwarding, and the overhead would rise as the scale of CS increases. In this paper, request filter of CS is studied and Compression Trie-based Bloom Filter (CT-BF) is proposed. CT-BF takes advantage of on-chip Bloom Filter to quickly filter out mismatch requests, and Compression Trie is adopted to accommodate the large CS name Trie into space-limited on-chip Bloom Filter. Optimal Compression Trie under space constraint is discussed for the first time and a heuristic approach Adapted Compression Trie based Bloom Filter (ACT-BF) is proposed for on-line operation. Simulation results show that ACT-BF can efficiently filter out mismatch requests with given on-chip space constraint and hence reduce average CS search delay."
  },
  {
    "year": "2017",
    "abstract": "Mobile data offloading through Wi-Fi is a promising solution to alleviate the explosive data increase in cellular network. While extensive attempts have been made at mobile data offloading, previous studies have rarely paid attention to network characteristics (e.g. Wi-Fi deployment density) and its effect on overall mobile offloading performance. In this paper, we propose a stochastic geometry model for the performance analysis of delay-tolerant offloading with mobility prediction. We aim to understand how the network parameters, such as network size and channel condition, affect the long-term offloading potential in the dense Wi-Fi sitting. The deployment of Wi-Fi is modeled as an independent Poisson point process (PPP) to take the effect of interference and CSMA/CA-based medium access control protocol into account. Then the semi-Markov process is used to model the user's movement taking the sojourn time into account. Based on the PPP deployment and semi-Markov process, we can obtain the potential offloading traffic. Through the above proposed analytical studies, the network providers can easily obtain a rough estimation on the average offloading performance from a given dense network."
  },
  {
    "year": "2017",
    "abstract": "As the fundamental technology of autonomous vehicles and high-speed tracking, high-speed vision always suffers from the bottlenecks of on-chip bandwidth and storage due to the resource constraints. To improve the resource efficiency, we propose a hardware-efficient image compression circuit based on the vector quantization for a high-speed image sensor. In this circuit, a self-organizing map is implemented for the on-chip learning of codebook to flexibly satisfy the requirements of different applications. To reduce the hardware resources, we present a reconfigurable complete-binary-adder-tree, where the arithmetic units are reused completely. In addition, a mechanism of partial vector-component storage is adapted to make the compression ratio adjustable. Finally, a parallel-elementary-stream design ensures a high processing speed. The proposed circuit has been implemented on the field-programmable gate araray and also applied in a high-speed object tracking system. The experimental results indicate that it achieves an encoding speed of 722 frames/s with 128 weight vectors when working at 79.8 MHz, and the worst tracking error caused by the proposed circuit is merely 9 pixels. These results evince that our proposed circuit can be completely integrated with a high-speed image sensor and used in high-speed vision systems."
  },
  {
    "year": "2017",
    "abstract": "Aiming at the control and optimization problem of blast furnace gas (BFG) systems in the steel industry, a knowledge-based optimal control algorithm combining fuzzy rules extraction with neural networks (NNs) ensemble-based prediction is proposed. On one hand, a fuzzy model is designed to extract the expert control knowledge from the historical data of the industrial process after community detection, and then, a great deal of scheduling knowledge is employed to compose a fuzzy rule base, which can be used for fuzzy inference of control scheme with a new input. On the other hand, data-driven NNs ensemble is built to model the BFG system for prediction. Meanwhile, the prediction results can provide the inputs when using fuzzy rule base for control and optimization. Finally, a BFG system of one steel enterprise is studied in this paper for experiments, which verifies the effectiveness and practicability of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "We derive closed-form expressions for the achievable rates of a buffer-aided full-duplex (FD) multiple-input multiple-output Gaussian relay channel. The FD relay still suffers from residual self-interference (RSI) after the application of self-interference mitigation techniques. We investigate both cases of a slow-RSI channel where the RSI is fixed over the entire codeword, and a fast-RSI channel where the RSI changes from one symbol duration to another within the codeword. We show that the RSI can be completely eliminated in the slow-RSI case when the FD relay is equipped with a buffer while the fast RSI cannot be eliminated. For the fixed-rate data transmission scenario, we derive the optimal transmission strategy that should be adopted by the source node and relay node to maximize the system throughput. We verify our analytical findings through simulations."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the problem of selecting the regularization parameter for linear least-squares estimation. We propose a new technique called bounded perturbation regularization (BPR). In the proposed BPR method, a perturbation with a bounded norm is allowed into the linear transformation matrix to improve the singular-value structure. Following this, the problem is formulated as a min-max optimization problem. Next, the min-max problem is converted to an equivalent minimization problem to estimate the unknown vector quantity. The solution of the minimization problem is shown to converge to that of the 12-regularized least squares problem, with the unknown regularizer related to the norm bound of the introduced perturbation through a nonlinear constraint. A procedure is proposed that combines the constraint equation with the mean squared error criterion to develop an approximately optimal regularization parameter selection algorithm. Both direct and indirect applications of the proposed method are considered. Comparisons with different Tikhonov regularization parameter selection methods, as well as with other relevant methods, are carried out. Numerical results demonstrate that the proposed method provides significant improvement over state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a sparse video representation with a deformable spatiotemporal template feature, named as active trace template. An active trace is the motion track of an active spatial feature, which moves in a certain velocity. To accommodate geometric variations of the spatial feature and motion variations of the temporal track, the atomic spatial feature in each video frame is capable to slightly shift its location and other attributes within certain ranges to best represent the salient trackable structure. The representation quality is quantified by a spatiotemporal score. It is computed through a new proposed spatiotemporal hierarchical architecture of sum-max maps. Based on the score, a small number of best active trace templates are selected from all the trace candidates to depict the video sketch. The experiments demonstrate that for natural videos, the proposed model is able to provide an intuitive and sparse representation, which matches human vision as well as reveals the spatiotemporal correspondence along consecutive frames even in challenging situations, such as occlusion. Furthermore, it shows the potential on dealing with high level vision tasks by moving object detection and segmentation, and action template learning and representation."
  },
  {
    "year": "2017",
    "abstract": "Application of the hashing method to large-scale image retrieval has drawn much attention because of the high efficiency and favorable accuracy of the method. Its related research generally involves two basic problems: similarity-preserving projection and information-preserving quantization. Most previous works focused on learning projection approaches, while the importance of quantization strategies was ignored. Although several hashing quantization models have been recently proposed to improve retrieval performance by assigning multiple bits to projected directions, these models still suffer from suboptimal results, as the critical information loss that occurs in the quantization procedure is not considered. In this paper, to construct an effective quantization model, we utilize rate-distortion theory in the hashing quantization procedure and minimize the distortion to reduce the information loss. Furthermore, combining principal component analysis with our quantization strategy, we present a quantization-based hashing method named distortion minimization hashing. Extensive experiments involving one synthetic data set and three image data sets demonstrate the superior performance of our proposed methods over several quantization techniques and state-of-the-art hashing methods."
  },
  {
    "year": "2017",
    "abstract": "The classic K-SVD based sparse representation denoising algorithm trains the dictionary only with one fixed atom size for the whole image, which is limited in accurately describing the image. To overcome this shortcoming, this paper presents an effective image denoising algorithm with the improved dictionaries. First, according to both geometrical and photometrical similarities, image patches are clustered into different groups. Second, these groups are classified into the flat category, the texture category, and the edge category. In different categories, the atom sizes of dictionaries are designed differently. Then, the dictionary of each group is trained with the atom size determined by the category that the group belongs to and the noisy level. Finally, the denoising method is presented by using sparse representation over the constructed grouped dictionaries with adaptive atom size. Experimental results show that the proposed method achieves better denoising performance than related denoising algorithms, especially in image structure preservation."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new rateless scheme based on the extendibility of systematic polar codes is proposed, which is applicable for the scenario without channel state information (CSI). With detailed analyses on the existing rateless schemes, we obtain the drawbacks and difficulties which can make the schemes dysfunctional. We expound the extendibility of systematic polar codes elaborately, which forms the basis of the new rateless scheme. In addition, with the incremental redundancy hybrid automatic repeat request transmission, the new rateless scheme is established. The construction of polar codes specialized for the new scheme is also proposed, which can provide reliable performance. Comparing with the existing rateless schemes, the new scheme can be applied for arbitrary channels efficiently and reliably."
  },
  {
    "year": "2017",
    "abstract": "Considering the increase of communication requirements from marine users, more studies try to introduce terrestrial wireless communication techniques into maritime communications to improve communication qualities. However, different communication scenarios introduce challenges for the application of terrestrial techniques to maritime networks. Furthermore, the communication coverage requirement is much larger than that of terrestrial networks, while the quality of service (QoS) requirement of marine users is expected to be like that on land, which makes network design more complicated. To address these problems, a user-centric communication architecture based on distributed antennas is proposed for maritime communications. The scenario of coastal networks based on cellular techniques is modeled mathematically, based on which the performance of such a network is analyzed and closed-form expressions of network performance are presented. To guarantee the QoS requirements of users, an antenna selection scheme is proposed, which can form a virtual service cloud for a targeted user. In addition, the precondition of the antenna selection scheme is discussed. Simulation results verify the analyses and indicate that the proposed scheme can guarantee the QoS of marine users under different cases."
  },
  {
    "year": "2017",
    "abstract": "In modern warfare, as a long distance detection equipment, a reconnaissance radar is crucial to monitor the sensitive regions and the intelligence of airborne targets. It is important for the opponent to identify the tactical information about the enemy's reconnaissance radar. It has a great influence on the war. Scanning cycle of the monitoring radar is an important parameter for the counterreconnaissance of the hostile radar source in the electronic countermeasure. Since the pulse Doppler (PD) radar is one of the most widely used type in modern reconnaissance radar domains, this paper focuses on scanning cycle estimation of the reconnaissance radar (PD radar) using a single unmanned aerial vehicle (UAV). We propose an effective method to reconstruct the main-beam pattern (MBP) curve of the radar antenna based on the norm approximation algorithm, and then the reconstructed MBP curve of the radar antenna is exploited to estimate the scanning cycle of the reconnaissance radar. By hovering the UAV at the same place, the scanning cycle of the reconnaissance radar can be estimated according to the reconstructed MBP curve. In the simulation section, we check the validity and robustness of the proposed method through the performance comparison with the Cramer-Rao lower bound."
  },
  {
    "year": "2017",
    "abstract": "Precoding algorithm is used to transmit signals effectively and to reduce the interferences from other user terminals in the massive multiple-input-multiple-output (MIMO) systems. In order to decrease the computational complexity of the precoding matrix, this paper proposes a new precoding algorithm. We use Chebyshev iteration to estimate the matrix inversion in the regularized zero-forcing precoding (RZF) algorithm. It does not need to compute the matrix inversion directly but uses iterations to estimate the matrix inversion. Therefore, the computational complexity can be decreased in this way. Furthermore, Chebyshev iteration has lower convergence rate, and it can gain precoding matrix quickly. This paper analyzes the performance of the Chebyshev-RZF precoding algorithm using average achievable rate and computes the complexity of the algorithm. Then, this paper optimizes initial values of the Chebyshev iteration algorithm on the basis of the feature of massive MIMO systems and makes initial values easier to be obtained. Simulation results show that after two iterations, the Chebyshev-RZF precoding algorithm can get similar average achievable rate as the RZF precoding algorithm does. An optimized Chebyshev-RZF precoding algorithm gets similar performance to the Chebyshev-RZF precoding algorithm after one iteration."
  },
  {
    "year": "2017",
    "abstract": "We consider the problem of sampling pulse streams with known shapes. The recent finite rate of innovation (FRI) framework has shown that such signals can be sampled with perfect reconstruction at their rate of innovation, which is usually much lower than the Nyquist rate. Although FRI sampling of pulse streams was treated in various works, either the work was unstable for high rate of innovation, or the sampling stage was complex and redundant. In this paper, we propose an FRI sampling and recovery method for pulse streams, which is based on the real parts of the Fourier coefficients. The proposed method is simple and efficient, and leads to stable recovery even when the rate of innovation is very high. This is achieved through modulating the input signal in each channel with a properly chosen cosine signal, followed by filtering with a low-pass filter. Since the modulating process will lead to the signal spectrum aliasing, we propose a spectrum de-aliasing algorithm to solve this problem, resulting in the real parts of a band of Fourier coefficients from each two channels. Combining with the multi-channel sampling structure, we propose a more efficient way to obtain arbitrary frequency bands from the aliased spectrum, which improves the utility of the signal spectrum. By using a sparsity-based recovery algorithm, the time delays and amplitudes of the pulse streams can be recovered from the obtained real parts of the Fourier coefficients. Finally, simulation results have shown that the proposed scheme is flexible and exhibits better noise robustness than previous approaches."
  },
  {
    "year": "2017",
    "abstract": "To improve the control performance in the transient state of a gas turbine engine, a new method based on variable replacement method (VRM) and particle swarm optimization (PSO) algorithm is proposed. Above all, an acceleration schedule under the constraints of fuel air ratio (FAR), high pressure turbine inlet temperature (T4) and high pressure compressor surge margin (SM) could be obtained. Then PSO is employed to optimize the acceleration controller. At the same time, the deceleration controller is designed in consideration of minimum fuel ratio unit (Wf/Ps3) limiter. At last, a simulation is carried out to verify the performance of the proposed method and the results manifest that the optimized controller can track the acceleration command quickly and accurately, while accomplish the requirement of minimum fuel ratio unit (0.005) in deceleration."
  },
  {
    "year": "2017",
    "abstract": "In multi-hop relay networks, the improving end-to-end sum rate is a challenging issue. Although a new cooperative beamforming called virtual multiple-input multiple-output (MIMO) has been introduced as a possible solution, conventional virtual MIMO systems have severe signaling overhead among master and source nodes when the number of hops increases. To resolve this problem, a broadcast virtual MIMO system and a virtual MIMO broadcasting transceiver (VMBT) have been proposed to reduce the computational complexity and improve the end-to-end sum rate. However, the application of such methods is limited to environments wherein interference from other links and networks is not considered. Thus, it is difficult to apply them to practical multi-hop relay networks. In this paper, we propose a generalized version of the VMBT in which intra- and inter-network interferences are simultaneously caused by multiple transmission of clusters in the same network and each network's usage of the same frequency band, respectively. To achieve this goal, we propose an effective interference nulling VMBT scheme. Simulation results show that the proposed scheme has efficient performance in terms of average end-to-end sum rate compared with conventional schemes."
  },
  {
    "year": "2017",
    "abstract": "Translational vibration-based methods have been widely used for machinery fault diagnosis. However, because of the unique gear configuration and complex kinetics, planetary gearbox translational vibration signals have complex modulation features due to gear faults and time-varying vibration transmission paths. This results in complex frequency components of translational vibrations, and adds difficulty to gear fault signature extraction. Under variable speed conditions, the resultant time-variant frequency components and complex sidebands may overlap in frequency domain, thus making it more difficult to pinpoint fault features. To address this issue, torsional vibration signals are exploited, because they are free from the extra modulation effect due to time-varying transmission paths and have simpler frequency contents. Gear faults generate impacts, thus exciting resonances and leading to modulations on resonances. Therefore, torsional resonance frequency band is concentrated to extract gear fault information. The time-variant but symmetric sideband characteristics in the resonance region are derived based on the explicit time-varying amplitude modulation and frequency modulation signal model. Resonance frequencies are identified under variable speed conditions by virtue of their independence on running conditions. Furthermore, time-frequency analysis is utilized to extract time-variant gear fault frequencies. The proposed method is validated using both numerical simulation and lab experimental data. Localized faults of the sun, planet, and ring gears are diagnosed under variable speed conditions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study the performance of receive spatial modulation (RSM) with simultaneous wireless information and power transfer (SWIPT) capabilities. RSM is a multi-antenna modulation scheme, where the information bits are encoded into complex constellation symbols and the indices of the receive antennas. We show how RSM can be combined with SWIPT, by allowing the receivers to increase their data rate and, at the same time, to recharge their batteries. An optimization problem is formulated in order to optimize the fraction of transmit power to be used for information decoding and energy harvesting, as well as the covariance matrix of the energy waveform. Efficient numerical algorithms to tackle the associated optimization problems are proposed. Our analysis shows that RSM-SWIPT is a flexible transmission scheme that is capable of achieving different rate-energy demands. RSM-SWIPT, in particular, can be configured to leverage only the energy waveform for transmitting information data and power simultaneously. Compared with conventional SWIPT-enabled multiple-antenna systems, the proposed RSM-SWIPT scheme increases the amount of harvested energy for low values of the rate and avoids the need of using energy cancellation algorithms if information and power are transmitted only through the energy waveform."
  },
  {
    "year": "2017",
    "abstract": "In the age of Industry 4.0, the techniques of artificial intelligence and pattern recognition play a critical role to develop the smart factories. In this paper, a block recognition system, named e-Block, was developed by using a novel projection algorithm and the convolution neural networks. The developed system displays a picture of the target object (e.g., a car or a house), and the children follow the instructions provided by the system and use the various blocks to build the object. Subsequently, this system compares the assembled block with the target object and determines whether the shape is identical. To identify the assembled block, this system applies Kinect to obtain information on the depth of the object and a new projection algorithm is proposed for converting the depth information into three feature images. By integrating three feature images, the convolution neural networks (CNN) are employed to construct the classifier to identify the assembled block. In the experiments conducted in this paper, the CNN classifier was compared with three classification algorithms. The experimental results show that the CNN classifier can accurately recognizes whether the assembled object is identical to the target object and outperform the compared classification algorithms. In additions, the experimental results also reveal that the proposed recognition algorithm can be a useful technique for applying in various applications of Industry 4.0."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a full characterization of the communications channel inside a train vehicle, in both narrow and wideband configurations. The purpose of this characterization is to be one of the first steps to check the feasibility of a wireless implementation of a train-control management system, a service which has been always carried over a wired network. Many different train topologies and scenarios have been taken into account in this paper (continuous and non-continuous train; train inside a tunnel, open-air or depot) and different results have been obtained (path-loss, angle of arrival, power-delay profile, and delay spread). The results show significant differences between continuous and non-continuous trains, and also highlight the importance of having a proper channel model with one slope per train car, instead of having only one slope for the whole train."
  },
  {
    "year": "2017",
    "abstract": "The widespread installation of distributed energy resources and demand side management resources into the distribution system has the potential to lead its operational parameters outside of their allowable limits. A standard strategy would be to increase the capacity of the network, however, this is costly. A cost-effective strategy could be to improve the management of such a system by improving the determination of its actual capacity. Recent advances in ICT equipment make it appear possible to manage the critical loading conditions instead of increasing capacity of the network. Thus, an energy management system is required to perform that function during the critical loading. In this paper, the authors present an approach for controlling network-oriented energy management systems on a distribution network using network capacity constraints. The proposed approach has been formulated in terms of linear inequality constraints. These constraints are derived from the functional relationships between an arbitrary set of control variables and an extensive variety of constrainable operational variables. The feasibility of the proposed constrained generation is demonstrated using linear programming, which performs the state optimization that already permits the usage of an extensive variety of cost functions. The significant feature of this approach is that it is flexible in terms of both constraint parameters and control variables. The proposed approach is demonstrated using an IEEE 13 bus distribution system."
  },
  {
    "year": "2017",
    "abstract": "Many systems often experience multiple failures resulting from simultaneous exposure to degradation processes and random shocks. For a load-sharing system, the dependencies among the degradation processes, random shocks and component failures potentially cause the system to fail more easily, which poses new challenging issues to evaluate the reliability. A novel reliability model for loadsharing systems subject to dependent degradation processes and random shocks is proposed. The new model extends previous models for simple parallel systems by considering the characteristics and specific dependencies of load-sharing systems. In a load-sharing system, the workload and shock load shared by each surviving component will increase after a component failure, leading to the higher degradation rate, the more serious sudden degradation damage caused by random shocks, and the greater probability of hard failure. In the model, the analytical expression is utilized to calculate the complex reliability. The complexity of this calculation is caused by the stochastic failure time of surviving components, the stochastic arriving time of shocks, and their interaction. A case of the load-sharing redundant micro-engines in micro-electromechanical system is presented to demonstrate the proposed model, and the result shows that the reliability of load-sharing system is lower than that of a simple parallel system."
  },
  {
    "year": "2017",
    "abstract": "Interference minimization while maintaining a target system sum rate by sharing radio resources among cellular user equipments (UEs) and device-to-device (D2D) pairs is an important research question in long term evolution (LTE) and beyond (4G and 5G). Total system sum rate of a cellular network can be improved if cellular UEs and D2D pairs share resource blocks. However, some sharing can also decrease the sum rate and increase the system interference. Considering this observation, we address two types of assignments (fair and restricted) in resource allocation for the interference minimization resource allocation problem. We propose a two-phase resource allocation algorithm for both fair and restricted assignments, where our objective is to minimize the system interference and at the same time, maintaining a target system sum rate. In the phase-I of our proposed algorithm, a weighted bipartite matching algorithm is used to minimize the interference and get a feasible initial solution. In some cases, we can decrease the interference introduced in phase-I of our algorithm. Therefore, in the phase-II, local search techniques are used to improve the solution. We compare the fair assignment of our proposed algorithms with a two-phase auction-based fair and interference aware resource allocation algorithm (TAFIRA), which addresses the same research problem. As well as, we compare the restricted assignment of our proposed algorithm with a minimum knapsack-based interference resource allocation algorithm (MIKIRA). We prove that the MIKIRA fails to provide feasible solutions in most of the cases. We also show that the performance ratio of the TAFIRA can be unbounded in the worst case. Moreover, in some cases, TAFIRA cannot provide any solution to the problem though the solutions exist, whereas our proposed algorithms always provide a solution whenever the solution exists. We perform extensive simulations of the algorithms and find that in all the cases, our proposed algorit..."
  },
  {
    "year": "2017",
    "abstract": "Database forensics is a domain that uses database content and metadata to reveal malicious activities on database systems in an Internet of Things environment. Although the concept of database forensics has been around for a while, the investigation of cybercrime activities and cyber breaches in an Internet of Things environment would benefit from the development of a common investigative standard that unifies the knowledge in the domain. Therefore, this paper proposes common database forensic investigation processes using a design science research approach. The proposed process comprises four phases, namely: 1) identification; 2) artefact collection; 3) artefact analysis; and 4) the documentation and presentation process. It allows the reconciliation of the concepts and terminologies of all common database forensic investigation processes; hence, it facilitates the sharing of knowledge on database forensic investigation among domain newcomers, users, and practitioners."
  },
  {
    "year": "2017",
    "abstract": "Attention deficit hyperactivity disorder (ADHD) is one of the most common mental health disorders. As a neuro development disorder, neuroimaging technologies, such as magnetic resonance imaging (MRI), coupled with machine learning algorithms, are being increasingly explored as biomarkers in ADHD. Among various machine learning methods, deep learning has demonstrated excellent performance on many imaging tasks. With the availability of publically-available, large neuroimaging data sets for training purposes, deep learning-based automatic diagnosis of psychiatric disorders can become feasible. In this paper, we develop a deep learning-based ADHD classification method via 3-D convolutional neural networks (CNNs) applied to MRI scans. Since deep neural networks may utilize millions of parameters, even the large number of MRI samples in pooled data sets is still relatively limited if one is to learn discriminative features from the raw data. Instead, here we propose to first extract meaningful 3-D low-level features from functional MRI (fMRI) and structural MRI (sMRI) data. Furthermore, inspired by radiologists' typical approach for examining brain images, we design a 3-D CNN model to investigate the local spatial patterns of MRI features. Finally, we discover that brain functional and structural information are complementary, and design a multi-modality CNN architecture to combine fMRI and sMRI features. Evaluations on the hold-out testing data of the ADHD-200 global competition shows that the proposed multi-modality 3-D CNN approach achieves the state-of-the-art accuracy of 69.15% and outperforms reported classifiers in the literature, even with fewer training samples. We suggest that multi-modality classification will be a promising direction to find potential neuroimaging biomarkers of neuro development disorders."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the design procedure, optimization strategy, theoretical analysis, and experimental results of a wideband dual-polarized base station antenna element with superior performance. The proposed antenna element consists of four electric folded dipoles arranged in an octagon shape that are excited simultaneously for each polarization. It provides ±45° slant-polarized radiation that meets all the requirements for base station antenna elements, including stable radiation patterns, low cross polarization level, high port-to-port isolation, and excellent matching across the wide band. The problem of beam squint for beam-tilted arrays is discussed and it is found that the geometry of this element serves to reduce beam squint. Experimental results show that this element has a wide bandwidth of 46.4% from 1.69 to 2.71 GHz with ≥15-dB return loss and 9.8 ± 0.9-dBi gain. Across this wide band, the variations of the half-power-beamwidths of the two polarizations are all within 66.5° ± 5.5°, the port-to-port isolation is >28 dB, the cross-polarization discrimination is >25 dB, and most importantly, the beam squint is <;4° with a maximum 10° down-tilt."
  },
  {
    "year": "2017",
    "abstract": "Cervical cancer, as the fourth most common cause of death from cancer among women, has no symptoms in the early stage. There are few methods to diagnose cervical cancer precisely at present. Support vector machine (SVM) approach is introduced in this paper for cervical cancer diagnosis. Two improved SVM methods, support vector machine-recursive feature elimination and support vector machine-principal component analysis (SVM-PCA), are further proposed to diagnose the malignant cancer samples. The cervical cancer data are represented by 32 risk factors and 4 target variables: Hinselmann, Schiller, Cytology, and Biopsy. All four targets have been diagnosed and classified by the three SVM-based approaches, respectively. Subsequently, we make the comparison among these three methods and compare our ranking result of risk factors with the ground truth. It is shown that SVM-PCA method is superior to the others."
  },
  {
    "year": "2017",
    "abstract": "To fully unleash the potentials of quantum computing, several new challenges and open problems need to be addressed. From a routing perspective, the optimal routing problem, i.e., the problem of jointly designing a routing protocol and a route metric assuring the discovery of the route providing the highest quantum communication opportunities between an arbitrary couple of quantum devices, is crucial. In this paper, the optimal routing problem is addressed for generic quantum network architectures composed by repeaters operating through single atoms in optical cavities. Specifically, we first model the entanglement generation through a stochastic framework that allows us to jointly account for the key physical-mechanisms affecting the end-to-end entanglement rate, such as decoherence time, atom-photon and photon-photon entanglement generation, entanglement swapping, and imperfect Bell-state measurement. Then, we derive the closed-form expression of the end-to-end entanglement rate for an arbitrary path and we design an efficient algorithm for entanglement rate computation. Finally, we design a routing protocol and we prove its optimality when used in conjunction with the entanglement rate as routing metric."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the load balancing problem, which is one of the key issues in high-performance computing (HPC) platforms. A novel method, called decentralized active queue management (DAQM), is proposed to provide a fair task distribution in a heterogeneous computing environment for HPC platforms. An implementation of the DAQM is presented, which consists of an ON-OFF queue control and a utility maximization-based coordination scheme. The stability of the queue control scheme and the convergence of the algorithm for utility maximization have been assessed by rigorous analysis. To demonstrate the performance of the developed queueing control system, numerical simulations are carried out and the obtained results confirm the efficiency and viability of the developed scheme."
  },
  {
    "year": "2017",
    "abstract": "Spoofing attacks carried out using artificial replicas are a severe threat for fingerprint-based biometric systems and, thus, require the development of effective countermeasures. One possible protection method is to implement software modules that analyze fingerprint images to tell live from fake samples. Most of the static software-based approaches in the literature are based on various image features, each with its own strengths, weaknesses, and discriminative power. Such features can be seen as different and often complementary views of the object in analysis, and their fusion is likely to improve the classification accuracy. This paper aims at assessing the potential of these feature fusion approaches in the area of fingerprint liveness detection by analyzing different features and different methods for their aggregation. Experiments on publicly available benchmarks show the effectiveness of feature fusion methods, which improve the accuracy of those based on individual features and are competitive with respect to the alternative methods, such as the ones based on convolutional neural networks."
  },
  {
    "year": "2017",
    "abstract": "Electro-hydraulic load simulator is a typical test-equipment for hardware-in-the-loop simulation, and usually performs periodic tasks, in which the modeling uncertainties will also present some periodicity. With this notification, in this paper, the system model of electro-hydraulic load simulator is established, afterward, all periodic uncertainties are transformed into linear-in-parameters form by applying Fourier series approximation, then an adaptive repetitive scheme with a robust integral of the sign of the error (RISE) feedback is synthesized, in which adaptive repetitive law is designed to handle periodic uncertainties and RISE robust term to attenuate unmodeled disturbances. The developed controller features depending on the desired trajectory rather than the system states, therefore it requires little information of the dynamic system and uncertain nonlinearities, which can apparently restrain the problems from noise pollution. In addition, because the periodic uncertainties are approximated as Fourier series and then compensated, the system performance can be greatly improved when performing periodic tasks. The resulting final control input is continuous while asymptotic tracking performance can be achieved with various uncertainties and disturbances by the proposed controller via Lyapunov stability analysis. In comparison to the other three controllers, the effectiveness and high performance of the proposed control method are validated by the experimental results sufficiently."
  },
  {
    "year": "2017",
    "abstract": "Having gained momentum from its promise of centralized control over distributed network architectures at bargain costs, software-defined Networking (SDN) is an ever-increasing topic of research. SDN offers a simplified means to dynamically control multiple simple switches via a single controller program, which contrasts with current network infrastructures where individual network operators manage network devices individually. Already, SDN has realized some extraordinary use cases outside of academia with companies, such as Google, AT&T, Microsoft, and many others. However, SDN still presents many research and operational challenges for government, industry, and campus networks. Because of these challenges, many SDN solutions have developed in an ad hoc manner that are not easily adopted by other organizations. Hence, this paper seeks to identify some of the many challenges where new and current researchers can still contribute to the advancement of SDN and further hasten its broadening adoption by network operators."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the findings of a steerable higher order mode (TE1δ3y) dielectric resonator antenna with parasitic elements. The beam steering was successfully achieved by switching the termination capacitor on the parasitic element. In this light, all of the dielectric resonator antennas (DRAs) have the same dielectric permittivity similar to that of ten and excited by a 50Ω microstrip with a narrow aperture. The effect of the mutual coupling on the radiation pattern and the reflection coefficient, as well as the array factor, was investigated clearly using MATLAB version 2014b and ANSYS HFSS version 16. As the result, the antenna beam of the proposed DRA array managed to steer from -32° to +32° at 15 GHz. Furthermore, the measured antenna array showed the maximum gain of 9.25 dBi and the reflection coefficients which are less than -10 dB with the bandwidth more than 1.3 GHz, which is viewed as desirable for device-to-device communication in 5G Internet of Things applications."
  },
  {
    "year": "2017",
    "abstract": "The k-out-of-n: G (F) majority voter usually consists of n components (modules), and such a system is critical to ensure the correct operation of various computing systems for numerous critical applications. For a k-out-of-n: G (F) majority voter, a specific number of the components are required to operate correctly for the overall system to function. To deal efficiently with the reliability evaluation of a general majority voter, a stochastic architecture can be adopted. The corresponding system reliability can be obtained through analyzing the output sequence. Usually, the system reliability is improved if more components or redundancies are used. Nevertheless, the consumed cost or required space also increases accordingly. In this paper, a tradeoff between the cost and reliability value was made to pursue the most desirable design. The relationship between the cost and corresponding component parameters is also discussed thoroughly in this paper. Then, to find the most cost-effective design, a new evaluation standard was proposed, referred to as the R_per_Cost. Furthermore, the optimal designs under different standards are presented for the investigated example. The results are also pursued with respect to an analysis of several case studies."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the problem of adaptive tracking control for a class of uncertain switched nonlinear systems is studied. The uncertain nonlinear functions in the system model are approximated using radial basis function neural network, and the unmeasured states under asynchronous switching and actuator faults are estimated by designing a time-schedule state observer. Further, adaptive laws subject to delta function are designed to make adaptive parameters continuous during persistent switching. It is proved that under asynchronous switching, the closed-loop system is stable with tracking error converging to a small neighborhood of origin. Finally, an example of a continuous stirred tank reactor is studied to verify the effectiveness of the approach proposed in this paper."
  },
  {
    "year": "2017",
    "abstract": "In this paper, multi-hop cooperative techniques are adopted to improve the physical-layer security in 5G large-scale decode-and-forward relay networks with massive relays and eavesdroppers. The utilization of graph theory is investigated to relieve the burden of massive nodes and ease the cooperative anti-eavesdropping transmission designs. In particular, a secrecy weighted graph is first established according to the network topology. Three scenarios associated with different levels of wiretapping capability are taken into account. Accordingly, secrecy measurements are converted into the weight of each edge and three efficient cooperative anti-eavesdropping strategies are then proposed for physical-layer security enhancement based on the shortest path algorithm, respectively. It is verified that the proposed cooperative anti-eavesdropping strategies have the property of low complexity and are more attractive for large-scale networks. Simulation results highlight the efficiency and effectiveness of our designs. It has been shown that two-hop transmission does not always promise performance gain in terms of secrecy gain. On the contrary, the proposed strategies are able to provide considerable improvement for different cases, emphasizing the necessity of adopting multi-hop cooperative anti-eavesdropping techniques to improve the physical-layer security."
  },
  {
    "year": "2017",
    "abstract": "A fully integrated Ku-band transmit/receive (T/R) switch based on a two-stage equivalent transmission line structure has been designed using a 180-nm complementary metal-oxide-semiconductor (CMOS) process. An analysis shows a relation between the series inductance and turn-on resistance for high isolation. A stack structure with feed-forward capacitors was chosen as a means of improving the power-handling capability of the switch. A low insertion loss (IL) of the switch was achieved by eliminating series transistors. The measured minimum ILs of the switch in the transmitter (TX) and receiver (RX) modes are 2.7 dB and 2.3 dB, respectively. The measured isolations in the TX and RX modes are greater than 34 and 25 dB, respectively, from 15 to 18 GHz. The design reaches a measured input 1-dB power compression point (IP1dB) of 22 dBm at 17 GHz. The switch achieves stringent isolation, insertion loss, and power-handling capability requirements along with the capability of full integration, demonstrating its great potential for use in fully integrated CMOS T/R chips."
  },
  {
    "year": "2017",
    "abstract": "A twin support vector machine (TWSVM) is an effective classifier, especially for binary data, which is defined by squared l2-norm distance in the objective function. Since squared l2-norm distance is susceptible to outliers, it is desirable to develop a revised TWSVM. In this paper, a new robust TWSVM via l2,p-norm formulations was proposed, because it suppress the influence of outliers better than l1-norm or squared l2-norm minimizations. However, the resulted objective is challenging to solve, because it is non-smooth and non-convex. As an important work, we systematically derive an efficient iterative algorithm to minimize the pth order of l2-norm distances. Theoretical support shows that the iterative algorithm is effective in the resolution to improve TWSVM via l2,p-norm instead of squared l2-norm distances. A large number of experiments show that l2,p-norm distances twin support vector machine can treat the noise data effectively and has a better accuracy."
  },
  {
    "year": "2017",
    "abstract": "Traditional recommender systems often suffer from the problem of data sparsity, because most users rate only a few of the millions of possible items. With the development of social platforms, incorporating abundant social relationships into recommenders can help to overcome this issue, because users' preferences can be inferred from those of their friends. Most existing social recommenders are based on matrix factorization, a collaborative filtering model that has been proven to be effective. In this paper, we introduce a novel social recommender based on the idea that distance reflects likability. Compared with matrix factorization, the proposed model enables us to obtain a spatial understanding of the latent factor space and how users and items are positioned inside the space by combining the factorization model and distance metric learning. In our method, users and items are initially mapped into a unified low-dimensional space. The positions of users and items are jointly determined by ratings and social relations, which can help to determine appropriate locations for users who have few ratings. Finally, the learned metrics and positions are used to generate understandable and reliable recommendations. Experiments conducted on real-world data sets have shown that compared with methods based on only matrix factorization, our method significantly improves the recommendation accuracy."
  },
  {
    "year": "2017",
    "abstract": "Determining the features of human binocular vision according to given disparity information has gained significant interest with regard to 3-D-relevant fields. However, subjectively distinguishing the features is internally ambiguous owing to personal factors and external susceptibility due to viewing environmental factors. Moreover, high cost and low reproducibility of the subjective assessment method restricts its usability in numerous practical applications. To alleviate these problems, this paper presents a novel visual stimulus, namely layered random dot stereogram (LRDS), and hierarchical paradigm for vote ratings. Based on the guide depth information in LRDS, viewers could recognize considerably obvious feature points, and our two-step rating strategy enhanced the reliability and efficiency of the viewing tests. The experiments prove that our approach successfully reflects the effects of not only personal factors but also display factors on depth perception. Our approach would be beneficial to the 3-D fields of human factor, viewer-interactive systems, and product performance evaluation."
  },
  {
    "year": "2017",
    "abstract": "A compact self-matched negative group delay (NGD) circuit without the need for an external matching circuit is proposed. The proposed NGD circuit is composed of two-port open-circuited coupled lines, a short-circuited transmission line and two resistors connected by two transmission lines. The coupled lines are utilized to obtain port matching. To verify the design concept, an NGD circuit with the size of 0.39λg × 0.19λg is designed and fabricated. From the measurement results, NGD value of -8.75 ns at the center frequency of 1.570 GHz is obtained with NGD bandwidth of 3.82%, signal attenuation of less than 20.5 dB and return losses of more than 32 dB."
  },
  {
    "year": "2017",
    "abstract": "Power swings may cause power system instability; therefore, hybrid energy storage systems (HESSs) are necessary to smooth the output of wind farms. Superconducting magnetic energy storage (SMES) systems have a high power density, whereas battery energy storage systems (BESSs) provide a high energy density. The significant contribution of this paper is the proposal of hierarchical control strategies for an HESS composed of an SMES system and a BESS. Mathematical models and port-controlled Hamiltonian (PCH) models of the HESS are established. At the device level, a novel HESS control strategy based on the PCH models is proposed to improve its output performance. At the system level, a multilevel power allocation method based on empirical mode decomposition, Fuzzy control and advanced control is proposed to achieve an efficient grid connection for a wind farm; the grid connection considers the real-time and future state of charge of the SMES system and BESS. The effectiveness of the proposed strategies are verified through simulation studies."
  },
  {
    "year": "2017",
    "abstract": "We analyze and optimize the performance of a quality of service (QoS) control scheme in a cross-layer design for wireless body area networks (WBANs). Smart health monitoring systems that incorporate WBANs and multimedia services have recently been studied and developed. In a WBAN system, wearable and implantable vital sensor nodes can include various types of sensors. Thus, QoS control is a key technique to ensure that different kinds of data are communicated in such a system. In previous work, we proposed an optimal QoS control scheme that employs a multiplexing layer for priority scheduling and a decomposable error control coding scheme for WBANs. However, a cross-layer approach, which is an important technique to optimize the QoS requirements of various kinds of data, has not been considered. In this paper, we utilize a cross-layer design between physical and medium access control layers and analyze and compare the performance of our QoS control scheme and a standard scheme. Numerical results demonstrate that the proposed scheme outperforms the standard scheme. The proposed system achieves a more than 5 dB gain compared with the standard scheme relative to the probability of unsuccessful transmission. We also show that a scheduled access protocol outperforms a random access protocol, except for delay time. In addition, we optimize some factors of the proposed system and the standard scheme in a cross-layer design."
  },
  {
    "year": "2017",
    "abstract": "The corpus callosum (CC) is a set of neural fibers in the cerebral cortex, responsible for facilitating inter-hemispheric communication. The CC structural characteristics appear as an essential element for studying healthy subjects and patients diagnosed with neurodegenerative diseases. Due to its size, the CC is usually divided into smaller regions, also known as parcellation. Since there are no visible landmarks inside the structure indicating its division, CC parcellation is a challenging task and methods proposed in the literature are geometric or atlas-based. This paper proposed an automatic data-driven CC parcellation method, based on diffusion data extracted from diffusion tensor imaging that uses the Watershed transform. Experiments compared parcellation results of the proposed method with results of three other parcellation methods on a data set containing 150 images. Quantitative comparison using the Dice coefficient showed that the CC parcels given by the proposed method has a mean overlap higher than 0,9 for some parcels and lower than 0,6 for other parcels. Poor overlap results were confirmed by the statistically significant differences obtained for diffusion metrics values in each parcel, when using different parcellation methods. The proposed method was also validated by using the CC tractography and was the only study that proposed a non-geometric approach for the CC parcellation, based only on the diffusion data of each subject analyzed."
  },
  {
    "year": "2017",
    "abstract": "This paper studies simultaneous wireless information and power transfer in full-duplex (FD) two-way relay networks, where two energy-constrained sources are served by a FD multi-antenna power-supply relay. Using FD technique at the relay can cause self-interference (SI) for the signal forwarding, but this SI can be useful for energy harvesting at two sources. To reasonably compress and utilize the SI, we consider a utility optimization problem aiming to maximize the total harvested energy by jointly optimizing the transmit power, the power splitting ratio at the sources and the beamforming matrix at the relay. In specific, we consider two relaying protocols, amplify-and-forward and decode-and-forward. To solve the complex non-convex problem, we decouple the objective problem into two subproblems which can be solved by the proposed semidefinite relaxation technique and the derived constraints activation solution. We show that the optimal solution of certain subproblems can be obtained in the closed-form. By this way, the objective problem can be finally tackled by utilizing a convergence guaranteed alternating optimization algorithm. Numerical results show that the proposed FD scheme achieves significant improvement of the energy harvesting efficiency compared with the existing works with different transmission protocols, i.e., half-duplex, perfect FD, and non-joint FD."
  },
  {
    "year": "2017",
    "abstract": "The intelligent welding technology is one of key development directions in “Industry 4.0” systems, and the use of sensing method is the main research direction of future intelligent welding technology. Due to the characteristics of aluminum alloy variable polarity plasma arc welding, by employing a complementary metal oxide semiconductor welding camera with a composite filter glass, a clear image of weld pool can be captured by side vision sensor. Aiming at the images captured with digital graphic processing technique, in this paper images are processed by Labview vision module. Moreover, in this paper, a method for image processing, which includes reversing, local threshold determination based on variance within the group, fast Fourier transform low-pass truncate filtering and advanced morphological operations for particle, is proposed to extract the characteristics of weld pool width. The result has shown that proposed image processing system can obtain reliable information on width of weld pool, which represents the basis for realization of quality control in aluminum alloy variable polarity plasma arc welding."
  },
  {
    "year": "2017",
    "abstract": "In vehicular networks, multi-channel operation standard IEEE 1609.4 is designed for vehicular communications across multiple channels. It has been revealed that such multi-channel operations may result in high contention in vehicular communications. However, existing analytical models are unable to capture the dynamic characteristic during channel switching. We develop a novel Markov model that takes into account the dynamic contention behavior during channel switching. In particular, our model reveals the high contention caused by the burst arrivals, which are the results of multi-channel operations. To combat such performance decline, we propose two solutions, a centralized equal-spaced algorithm and a distributed random-spaced algorithm. The key idea is to disperse the burst packet arrivals across the available timeframe in order to alleviate contention. Our model, validated by simulations, accurately characterizes the high contention caused by multi-channel operations. Our results demonstrate our proposed solutions can effectively mitigate packet collision, enhance reliability, and improve system throughput during the multichannel operations."
  },
  {
    "year": "2017",
    "abstract": "Network coding (NC) features a new perspective for leveraging network performances as more efficient resources utilization could be achieved. In recent years, the application of NC to the realms of failure recovery in optical networks has been receiving growing attention and indeed, combining the near-instantaneous recovery of dedicated protection and improved capacity efficiency enabled by NC constitutes an important research trend in optical protection. In order to maximize the benefits empowered by NC, a critical problem on routing of traffic demands, selecting demands for encoding and determining the respective coding node and coding links has to be optimally addressed. The problem becomes even more challenging if multiple traffic demands are considered at once and the traffic is non-equal. In addressing those issues, for the first time, we present a novel unified framework for augmenting 1 + 1 dedicated protection against single link failures with a practical network coding scheme based on XOR operation for both equal and non-equal traffic scenarios. In line with this framework, a mathematical model in the form of integer linear programming for optimal routing and network coding assignment to minimize the path cost is presented. Numerical results based on evaluating the model on realistic topologies and all-to-one traffic setting highlight the cost advantages of our proposed NC-assisted protection scheme compared to traditional counterparts."
  },
  {
    "year": "2017",
    "abstract": "Three-phase phase-locked loops (PLLs) are the most widely used synchronization components in power systems. For common PLL algorithms, there is a tradeoff between the filtering capability and dynamic response. In this paper, a nonlinear PLL (NLADRC-PLL) based on a linear active disturbance rejection controller (LADRC) is proposed to largely improve this tradeoff, thus simultaneously enhancing the filtering capability and dynamic response. With LADRC adopted in PLL structures (LADRC-PLL), good dynamic response and disturbance rejection capability can be achieved. To pursue further improvements in both filtering capability and dynamic response, the NLADRC-PLL derived from the LADRC-PLL is proposed, which adjusts the controller gains adaptively according to the disturbance. It is commonly known that there are stability problems for PLLs with adaptive controller gains, which are highly nonlinear systems. Thanks to the great robustness of LADRC structures, the stability of the proposed NLADRC-PLL is certified by the second method of Lyapunov in the nonlinear model. By comparing its PLL performance with the existing PLL algorithms, the superiority of the NLADRC-PLL in both filtering capability and dynamic response is verified through experimental results."
  },
  {
    "year": "2017",
    "abstract": "Network densification through the deployment of small cells along the coverage area of a macro-cell, employing massive multiple input multiple output (MIMO) and millimeter-wave (mmWave) technologies, is a key approach to enhancing the network capacity and coverage of future systems. For ultra-dense mmWave heterogeneous scenarios with a massive number of users, one should address both inter- and intra-tier interferences contrary to the low-density scenarios, where the network is mainly noise limited. Therefore, this paper proposes low complex hybrid analog-digital receive and transmit beamforming techniques for ultra-dense uplink massive MIMO mmWave heterogeneous systems to efficiently mitigate these interferences. At the small cells, the hybrid analog-digital receive beamforming/equalizer is computed in a distributed fashion, where the analog processing is performed at the small cell base stations or access points and the digital part at a central unit for joint processing. To optimize the analog part of the hybrid equalizer and the precoders used at the user terminals, we consider as a metric the distance relative to the fully digital counterpart induced by the Frobenius norm. In the optimization problem, apart from the analog constraints usually considered in the homogeneous systems, we further impose the constraints inherent to the distributed nature of the access points. To cancel the inter-tier interference, the digital parts of the precoders employed at the small cell user terminals are designed so that this interference resides in a low-dimensional subspace at the macro base station. The results show that the performance of the proposed hybrid analog-digital precoder/equalizer scheme is close to the fully digital counterpart and is able to efficiently remove both inter- and intra-tier interferences."
  },
  {
    "year": "2017",
    "abstract": "Developing highly efficient routing protocols for Mobile Ad hoc NETworks (MANETs) is a challenging task. In order to fulfill multiple routing requirements, such as low packet delay, high packet delivery rate, and effective adaptation to network topology changes with low control overhead, and so on, new ways to approximate solutions to the known NP-hard optimization problem of routing in MANETs have to be investigated. Swarm intelligence (SI)-inspired algorithms have attracted a lot of attention, because they can offer possible optimized solutions ensuring high robustness, flexibility, and low cost. Moreover, they can solve large-scale sophisticated problems without a centralized control entity. A successful example in the SI field is the ant colony optimization (ACO) meta-heuristic. It presents a common framework for approximating solutions to NP-hard optimization problems. ACO has been successfully applied to balance the various routing related requirements in dynamic MANETs. This paper presents a comprehensive survey and comparison of various ACO-based routing protocols in MANETs. The main contributions of this survey include: 1) introducing the ACO principles as applied in routing protocols for MANETs; 2) classifying ACO-based routing approaches reviewed in this paper into five main categories; 3) surveying and comparing the selected routing protocols from the perspective of design and simulation parameters; and 4) discussing open issues and future possible design directions of ACO-based routing protocols."
  },
  {
    "year": "2017",
    "abstract": "A conflict of the spectrum rights and needs between active wireless communication systems and passive radio astronomy systems (RASs) has become substantially greater due to the phenomenal expansion of wireless communications and increased interest in RAS observation. For sustainable growth and coexistence of cellular wireless communications (CWC) and RAS, a coordinated shared spectrum access paradigm was recently introduced. Embracing such paradigm, this paper proposes a distributed auxiliary radio telescope (DART) system which can geographically and spectrally coexist with CWC while offering additional capability or performance enhancement to RAS. Theoretical performance analysis of the DART system with different quantization resolutions is presented, and approximate closed-form expressions are obtained. Adaptation of cooling power of DART receivers according to the time-varying ambient temperature is also proposed. Furthermore, an analytical expression for the DART system parameters under the shared spectrum access paradigm and cooling power constraint to achieve the same performance as the existing single-dish RAS with a radio quiet zone is developed to provide guidance in the DART system design. The numerical and simulation results illustrate feasibility and potentials of the proposed DART system."
  },
  {
    "year": "2017",
    "abstract": "Today's cities generate tremendous amounts of data, thanks to a boom in affordable smart devices and sensors. The resulting big data creates opportunities to develop diverse sets of context-aware services and systems, ensuring smart city services are optimized to the dynamic city environment. Critical resources in these smart cities will be more rapidly deployed to regions in need, and those regions predicted to have an imminent or prospective need. For example, crime data analytics may be used to optimize the distribution of police, medical, and emergency services. However, as smart city services become dependent on data, they also become susceptible to disruptions in data streams, such as data loss due to signal quality reduction or due to power loss during data collection. This paper presents a dynamic network model for improving service resilience to data loss. The network model identifies statistically significant shared temporal trends across multivariate spatiotemporal data streams and utilizes these trends to improve data prediction performance in the case of data loss. Dynamics also allow the system to respond to changes in the data streams such as the loss or addition of new information flows. The network model is demonstrated by city-based crime rates reported in Montgomery County, MD, USA. A resilient network is developed utilizing shared temporal trends between cities to provide improved crime rate prediction and robustness to data loss, compared with the use of single city-based auto-regression. A maximum improvement in performance of 7.8 % for Silver Spring is found and an average improvement of 5.6 % among cities with high crime rates. The model also correctly identifies all the optimal network connections, according to prediction error minimization. City-to-city distance is designated as a predictor of shared temporal trends in crime and weather is shown to be a strong predictor of crime in Montgomery County."
  },
  {
    "year": "2017",
    "abstract": "Future gas turbine engine control systems will be based on a distributed architecture in which the sensors and actuators will be connected to the controllers via a communication network. The performance of the distributed engine control (DEC) system is dependent on the network performance. The network-induced time delay may degrade the performance of the closed-loop systems and even destabilize the systems if the controllers are designed without considering the effects of the delay. This paper introduces a new method to estimate the maximum tolerance of the time delay for analysis of the stability of the GE T700 turboshaft engine DEC system. The sufficient conditions for stability are derived and dynamic output feedback controllers for the turboshaft engine are applied. Hardware-in-the-loop simulation illustrates the effectiveness of the presented method."
  },
  {
    "year": "2017",
    "abstract": "Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, cloud computing networks significantly benefit the deployment of new services and have become one infrastructure provider in the digital society. The virtual extensible local area network (VxLAN), which belongs to the network schemes to overlay Layer 2 over Layer 3, is one of the most popular methods to realize cloud computing networks. Though VxLAN partially overcomes the capacity limitation of its predecessor virtual local area network, it still faces several challenges like annoying signaling overhead during the multicast period and interrupted communication with a migrating virtual machine (VM). In this paper, we propose a new software defined network (SDN) based VxLAN network architecture. Based on this architecture, we address how we can deploy an intelligent center to enhance the multicast capability and facilitate the VM migration. Besides, we discuss the means to update the global information and guarantee the communication continuum. Finally, we use Mininet to emulate this SDN based VxLAN architecture and demonstrate effective load balancing results. In a word, this proposed architecture could provide a blueprint for future cloud computing networks."
  },
  {
    "year": "2017",
    "abstract": "In mobile crowd-sensing systems, the value of crowd-sensed big data can be increased by incentivizing the users appropriately. Since data acquisition is participatory, crowd-sensing systems face the challenge of data trustworthiness and truthfulness assurance in the presence of adversaries whose motivation can be either manipulating sensed data or collaborating unfaithfully with the motivation of maximizing their income. This paper proposes a game theoretic methodology to ensure trustworthiness in user recruitment in mobile crowd-sensing systems. The proposed methodology is a platform-centric framework that consists of three phases: user recruitment, collaborative decision making on trust scores, and badge rewarding. In the proposed framework, users are incentivized by running sub-game perfect equilibrium and gamification techniques. Through simulations, we show that approximately 50% and a minimum of 15% improvement can be achieved by the proposed methodology in terms of platform and user utility, respectively, when compared with fully distributed and user-centric trustworthy crowd-sensing."
  },
  {
    "year": "2017",
    "abstract": "Phased array technology allows for fast electronic beam steering with high antenna gain for radar imaging systems. Currently, common algorithms mainly concentrate on scenarios where targets are in the far-field zone; however, the beamforming performance will be impaired in the near-field zone. This paper presents a compressive sensing (CS)-based phased array imaging method for near-field applications. A novel data acquisition methodology has been proposed on the basis of near-field focusing techniques. CS measurements are taken by randomly focusing beams in the near-field region. When compared with the far-field imaging approach, the proposed method shows superior performance in the presence of noise and background interference. Moreover, the near-field method can better minimize the grating lobe issues caused by using large antenna element spacing. Finally, we show that the resolving power of CS imaging systems can be affected by target sparsity."
  },
  {
    "year": "2017",
    "abstract": "In this paper, resource allocation and interference mitigation are investigated for heterogeneous networks where the lowest tier consists of device-to-device (D2D) cells. In order to alleviate dead-zone problem, we first consider downlink/uplink (DL/UL) decoupling user association and quantify its capability on interference management and network-wide D2D performance enhancement. Second, we propose an UL fractional frequency reuse scheme where subband (SB) bandwidths are adaptively determined based on: 1) user equipment (UE) density; 2) e-node-B (eNB) density; and 3) on/off switching frequency of small cells. Obtained results show that the adaptive method significantly reduces the number of outage users. Thereafter, a novel concatenated bi-partite matching (CBM) method is proposed for joint SB assignment (SA) and resource block allocation (RA) of cellular UEs. Numerical results show that the CBM provides a close performance to exhaustive solution with greatly reduced running time. The CBM is then extended to a centralized mode selection, SA, and RA for D2D cells. Alternatively, we develop offline and online semi-distributed approaches where a D2D-cell can reuse white-list RBs (WRBs), which are not occupied by the adjacent small cells. In the former, D2D-cell members are not aware of intra-cell and inter-cell interference and uniformly distribute their maximum permissible power to WRBs. In the latter, we put D2D sum rate maximization into a convex form by exploiting the proximity gain of D2D UEs. Online distributed solution is then developed by message passing of dual variables and consistency prices. Finally, virtues and drawbacks of the developed approaches are compared and explained."
  },
  {
    "year": "2017",
    "abstract": "Pose (position and attitude) measurement of a space non-cooperative target is very important for on-orbital servicing tasks, including malfunctioning target repairing, space debris removal, and so on. However, such targets are generally non-cooperative, i.e., no markers are mounted on it and there is no prior knowledge. Therefore, the identification and measurement of a non-cooperative target is very challenging. In this paper, we propose an efficient method to recognize the natural objects with circular or near-circular shapes on the target, reducing the computation load and improving accuracy. First, the geometry properties of a practical non-cooperative target are analyzed. A stereo vision system is correspondingly designed to measure the relative pose of the target. Second, the error sources and time-consuming factors of the traditional method are analyzed. Then, a solution concept is proposed. Third, the efficient method is detailed to solve the geometry equation and determine the pose information, reducing the calculation complexity and increasing the accuracy. The image pre-processing and target detecting algorithms are realized on FPGAs, further accelerating the calculation speed. Finally, we develop an experiment system and verify the proposed method through practical experiments. The experiment system is composed of satellite mockup, binocular camera, and high precision laser tracker. The experiment results show that the proposed method has high accuracy and efficiency."
  },
  {
    "year": "2017",
    "abstract": "This paper considers the detection and localization of a human subject in complex environments using an ultra-wideband impulse radar. The subject is remotely sensed by extracting micro-motion information, such as the respiration and heartbeat frequencies. It is challenging to extract this information due to the low signal to noise and clutter ratio in typical disaster environments. To improve the localization accuracy, a new method is proposed using the characteristics of vital sign signals. The range is determined using a short-time Fourier transform of the kurtosis and standard deviation of the received signals. Furthermore, an improved arctangent demodulation technique is used to determine the frequency of human micro-motion based on a multiple frequency accumulation method. Performance results are presented, which show that the proposed method is superior to several well-known techniques."
  },
  {
    "year": "2017",
    "abstract": "With the rapid advances of cyber-physical-social systems (CPSS), large amounts of dynamic multi-modal data are being generated and collected. Analyzing those data effectively and efficiently can help to promote the development and improve the service quality of CPSS applications. As an important technique of multi-modal data analysis, co-clustering, designed to identify groupings of multi-dimensional data based on cross-modality fusion, is often exploited. Unfortunately, most existing co-clustering methods that mainly focus on dealing with static data become infeasible to fuse huge volume of multi-modal data in dynamic CPSS environments. To tackle this problem, this paper proposes a parameter-free incremental co-clustering method to deal with multi-modal data dynamically. In the proposed method, the single-modality similarity measure is extended to multiple modalities and three operations, namely, cluster creating, cluster merging, and instance partitioning, are defined to incrementally integrate new arriving objects to current clustering patterns without introducing additive parameters. Moreover, an adaptive weight scheme is designed to measure the importance of feature modalities based on the intra-cluster scatters. Extensive experiments on three real-world multi-modal datasets collected from CPSS demonstrate that the proposed method outperforms the compared state-of-the-art methods in terms of effectiveness and efficiency, thus it is promising for clustering dynamic multi-modal data in cyber-physical-social systems."
  },
  {
    "year": "2017",
    "abstract": "Multiple-mode orthogonal frequency division multiplexing with index modulation (MM-OFDM-IM) improves the spectral efficiency of the conventional OFDM-IM scheme by considering multiple distinguishable constellations for signal modulation. In this paper, we propose a novel scheme, called space-time MM-OFDM-IM (ST-MM-OFDM-IM), to increase the transmit diversity of MM-OFDM-IM. In ST-MM-OFDM-IM, the signal matrix, which consists of multiple signal vectors of MM-OFDM-IM, is transmitted over multiple time slots by following a specific rule. A low-complexity detection is proposed to mitigate the high burden of the optimal maximum-likelihood detection at the receiver side. A closed-form upper bound on the bit error rate is derived to evaluate the performance of ST-MM-OFDM-IM. Moreover, a diversity improving scheme of ST-MM-OFDM-IM is also studied to obtain full transmit diversity. Simulation results verify the theoretical analysis and show that ST-MM-OFDM-IM outperforms the conventional MM-OFDM-IM scheme."
  },
  {
    "year": "2017",
    "abstract": "Blind Source Separation techniques are widely used in the field of wireless communication for a very long time to extract signals of interest from a set of multiple signals without training data. In this paper, we investigate the problem of separation of the human voice from a mixture of human voice and sounds from different musical instruments. The human voice may be a singing voice in a song or may be a part of some news, broadcast by a channel with background music. This paper proposes a generalized Short Time Fourier Transform (STFT)-based technique, combined with filter bank to extract vocals from background music. The main purpose is to design a filter bank and to eliminate background aliasing errors with best reconstruction conditions, having approximated scaling factors. Stereo signals in time-frequency domain are used in experiments. The input stereo signals are processed in the form of frames and passed through the proposed STFT-based technique. The output of the STFT-based technique is passed through the filter bank to minimize the background aliasing errors. For reconstruction, first an inverse STFT is applied and then the signals are reconstructed by the OverLap-Add method to get the final output, containing vocals only. The experiments show that the proposed approach performs better than the other state-of-the-art approaches, in terms of Signal-to-Interference Ratio (SIR) and Signal-to-Distortion Ratio (SDR), respectively."
  },
  {
    "year": "2017",
    "abstract": "Computer aided detection and diagnosis system (CAD) is designed to improve the efficiency and quality of medical diagnosis. The existing CAD system tries to realize a diagnosis process in an automatic way to replace the doctor's diagnosis work completely, but it is difficult to capture the doctor's detection and diagnosis needs and goals accurately due to lack of doctor's experience. Thus, the accuracy is not up to the doctor's manual diagnosis results, and it is a tedious and cumbersome job to use the system because it requires manual intervention, which leads to the fact that CAD system was difficult to be widely used. This paper analyzes the characteristics of doctors' diagnosis tasks deeply, and makes the reasonable allocation of tasks between the doctor and computer. Then the perceptual control theory is introduced into the task model, a PTT task model is proposed to make it express uncertainty of the doctor's diagnosis tasks, and it can be used as a reference for future uncertainty task analysis. Therefore, an interactive CAD tasks framework is put forward with the assistant decision support provided for doctors by means of Bayesian network model and conceptual graph semantic matching method to diagnose tasks. In addition, effective support is provided for interface development staffs to design interactive systems that are suitable for the physicians' diagnostic tasks. The experimental results show that the method not only improves the accuracy and efficiency of the medical diagnosis, but also improves the usability of the system design."
  },
  {
    "year": "2017",
    "abstract": "Audio–visual recognition (AVR) has been considered as a solution for speech recognition tasks when the audio is corrupted, as well as a visual recognition method used for speaker verification in multi-speaker scenarios. The approach of AVR systems is to leverage the extracted information from one modality to improve the recognition ability of the other modality by complementing the missing information. The essential problem is to find the correspondence between the audio and visual streams, which is the goal of this paper. We propose the use of a coupled 3D convolutional neural network (3D CNN) architecture that can map both modalities into a representation space to evaluate the correspondence of audio–visual streams using the learned multimodal features. The proposed architecture will incorporate both spatial and temporal information jointly to effectively find the correlation between temporal information for different modalities. By using a relatively small network architecture and much smaller data set for training, our proposed method surpasses the performance of the existing similar methods for audio–visual matching, which use 3D CNNs for feature representation. We also demonstrate that an effective pair selection method can significantly increase the performance. The proposed method achieves relative improvements over 20% on the equal error rate and over 7% on the average precision in comparison to the state-of-the-art method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a complex Hadamard matrix-aided generalized space shift keying (HSSK) modulation scheme, which introduces complex-Hadamard-based signal vectors at the transmitter to provide higher spectrum efficiency than generalized space shift keying (GSSK). It also has lower maximum-likelihood detection complexity than the multiple active spatial modulation (MA-SM) and generalized spatial modulation (GSM) systems due to the corresponding fast complex Hadamard transform at the receiver. Based on the Lee distance of our signal vectors, we provide an optimized mapping between our data bits and signal vectors. We also analyze the upper bound on the average bit error rate of our HSSK system, which agrees well with the simulation results. Finally, the performance of HSSK is compared with MA-SM, GSM, and GSSK systems through Monte Carlo simulations. It is shown that for the same transmission rate the HSSK system performs better than the GSM, MA-SM, and GSSK systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we introduce the first validation framework of an indoor navigation system for blind and visually impaired (BVI) users, which is a significant step toward the development of cost effective indoor way-finding solutions for BVI users. The BVI users require detailed landmark-based navigation instructions that will help them arrive at the chosen destination independently. These users will interact with the navigation instructions on a smartphone using an accessible user interface. The validation framework includes the following three main components: 1) virtual reality-based simulation that simulates a BVI user traversing and interacting with the physical environment, developed using Unity game engine; 2) generation of action codes that emulate the avatar movement in the virtual environment, developed using a natural language processing parser of the navigation instructions; and 3) accessible user interface, which enables the user to access the navigation instructions, developed using Sikuli script library. We introduce a case study that illustrates the use of the validation tool using PERCEPT system. It is our strong belief that the validation framework we provide in this paper will encourage other developers to invent indoor navigation systems for BVI users. In addition, we would like to mention that this tool is the first step of validating an indoor navigation system and should be followed by trials with human subjects."
  },
  {
    "year": "2017",
    "abstract": "Space modulation is a group of multiple-input multiple-output (MIMO) techniques that attracted significant research interests lately. However, the aspect of implementation approaches and software defined radio (SDR) has been so far very limited. The aim of this paper is to propose a novel single SDR platform architecture that implements different space modulation techniques using currently available commercial off-the-shelf components. The proposed platform architecture can be dynamically reconfigured to implement different space modulation techniques with marginal to almost no extra hardware overhead. The impact of different hardware components that have to be considered to realize such an implementation is also analyzed and studied."
  },
  {
    "year": "2017",
    "abstract": "Multivariate statistical methods are effective data-driven approaches for complex practical systems. Traditional partial least squares (PLS) serves as a latent projection approach applied to the qualityrelated process monitoring field widely. However, PLS is not suitable for quality-related fault detection which performs an oblique projection to the X variables. In order to address this problem, an improved principal component regression (IPCR) is proposed in this paper. IPCR separates the process measurements into a quality-related part and a quality-unrelated part. Compared with the conventional method, IPCR can represent the relationship between the fault and product quality more clearly. Furthermore, we design the corresponding test statistics to build the logic of fault detection. A numerical experiment and the Tennessee Eastman process simulator are utilized to illustrate the performance of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "The design of DNA codes sets satisfying certain combinatorial constraints is important in reducing hybridization errors due to nonspecific hybridization between distinct codes and their complements in DNA computing, data encryption, and data storage. The DNA code design problem is to find the largest possible set of DNA codes. In this paper, we present a Bloch quantum chaos algorithm for the designing DNA codes sets. The algorithm uses the chaotic equation to initialize the Bloch coordinates of quantum bits, next adopts the whole interference crossover strategy to get crossover operation, then employs quantum non gate strategy to get mutation operation, finally utilizes the dynamic adjustment strategy to adjust the quantum rotation corner. Several experimental results in which our algorithm finds DNA codes sets match or exceed the best previously known constructions."
  },
  {
    "year": "2017",
    "abstract": "This paper studies stability analysis of a class of integral delay systems with multiple exponential kernels. By using the multiple Jensen inequalities established recently and the Lyapunov-Krasovskii functional approach, some new sufficient stability conditions expressed by linear matrix inequalities (LMIs) are obtained. It is shown that the obtained stability conditions are always less conservative than the existing ones. Robust stability of this class of integral delay systems with parameter uncertainties is also investigated and some sufficient conditions expressed by LMIs are obtained. The effectiveness of the proposed methods is illustrated by some numerical examples."
  },
  {
    "year": "2017",
    "abstract": "Automatically predicting age group and gender from face images acquired in unconstrained conditions is an important and challenging task in many real-world applications. Nevertheless, the conventional methods with manually-designed features on in-the-wild benchmarks are unsatisfactory because of incompetency to tackle large variations in unconstrained images. This difficulty is alleviated to some degree through convolutional neural networks (CNN) for its powerful feature representation. In this paper, we propose a new CNN-based method for age group and gender estimation leveraging residual networks of residual networks (RoR), which exhibits better optimization ability for age group and gender classification than other CNN architectures. Moreover, two modest mechanisms based on observation of the characteristics of age group are presented to further improve the performance of age estimation. In order to further improve the performance and alleviate over-fitting problem, RoR model is pre-trained on ImageNet first, and then it is fune-tuned on the IMDB-WIKI-101 data set for further learning the features of face images, finally, it is used to fine-tune on Adience data set. Our experiments illustrate the effectiveness of RoR method for age and gender estimation in the wild, where it achieves better performance than other CNN methods. Finally, the RoR-152+IMDB-WIKI-101 with two mechanisms achieves new state-of-the-art results on Adience benchmark."
  },
  {
    "year": "2017",
    "abstract": "In this paper, by jointly considering resource allocation and subframe type determination, we formulate a stochastic optimization programming to investigate the problem of network stability in heterogeneous networks (HetNets) with almost blank subframe (ABS)-based enhanced inter-cell interference coordination where random and finite traffic loads are considered. Then, by leveraging the Lyapunov optimization technique, an extremely simple but optimal delay-aware dynamic resource allocation and ABS configuration algorithm (DDRAACA) is proposed to solve the formulation. In the DDRAACA, at the beginning of each time slot, eNodeBs should collect current queue states of their own users, and locally calculate the resource scheduling matrix based on channel state information feedbacks. Then, the category of current subframe can be determined. Besides, considering the computational complexity and the signaling overhead brought in by the DDRAACA, another algorithm named semi-static ABS configuration with interference impact factor-based scheduling is developed. The simulation results show that both algorithms can maintain the stability of the system. In particular, no iteration and optimization tools are required in our proposed algorithms, which paves the way for practical applications."
  },
  {
    "year": "2017",
    "abstract": "Virtual network embedding (VNE) problem has been widely accepted as an important aspect in network virtualization (NV) area: how to efficiently embed virtual networks, with node and link resource demands, onto the shared substrate network that has finite network resources. Previous VNE heuristic algorithms, only considering single network topology attribute and local resources of each node, may lead to inefficient resource utilization of the substrate network in the long term. To address this issue, a topology attribute and global resource-driven VNE algorithm (VNE-TAGRD), adopting a novel node-ranking approach, is proposed in this paper. The novel node-ranking approach, developed from the well-known Google PageRank algorithm, considers three essential topology attributes and global network resources information before conducting the embedding of given virtual network request (VNR). Numerical simulation results reveal that the VNE-TAGRD algorithm outperforms five typical and latest heuristic algorithms that only consider single network topology attribute and local resources of each node, such as long-term average VNR acceptance ratio and average revenue to cost ratio."
  },
  {
    "year": "2017",
    "abstract": "A composite sliding mode control based on the load characteristic of the permanent magnet direct-driven system is presented for a mining scraper conveyor. First, the mathematical model of a permanent magnet synchronous motor is established based on the coordinate transformation theory. Subsequently, the soft switching sliding mode observer (SS-SMO) is designed to observe the change of load torque in real time. The composite sliding mode speed controller of PMSM is designed on the basis of non-singular terminal sliding mode control, in which the observed load torque is used for feed-forward compensation. The chain characteristics of a scraper conveyor are described by the Kelvin-Vogit model, and the dynamic model of the overall scraper conveyor system is established with the distinct element method. Next, according to the coupling relationship between the permanent magnet direct-driven system and the scraper conveyor, the electromechanical coupling simulation model is established using the MATLAB/Simulink module. The simulation results demonstrate that the composite sliding mode controller of the permanent magnet direct-driven system can achieve smooth starting of the scraper conveyor, and the effectiveness of the designed controller is illustrated by comparing the controller with the related reference. In addition, the designed SS-SMO can estimate the load torque precisely, enhance system robustness and suppress the chattering of the control system caused by the load change."
  },
  {
    "year": "2017",
    "abstract": "The various faults that inevitably occur represent a primary issue in satellite on-orbit operation. Fault diagnosis is the first step in the fault control process. As a means to perform this step, a semi-supervision fault diagnosis method via attitude information is proposed for a satellite. This method combines static fusion with dynamic updating. The evidence concept is employed to obtain the fault information. It not only allows the detection of the slow change and failure with interference, but also confirms the optimal fusion and updating parameters via historical data. Numerical simulations, including static fusion diagnosis and dynamic updating diagnosis, are all presented with the proposed semi-supervision diagnosis methods to compare and prove the effectiveness of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "High computational complexity and difficulty in taking an analytical expression of detection statistics are some of the problems encountered when using the statistical resolution limit (SRL) analysis in the generalized likelihood ratio test (GLRT). A Rao test-based method is used in this paper to analyze the 1-D SRL of two closely spaced signals, which can simplify the derivation of detection statistics, reduce the computational complexity, and improve the detection performance in some scenarios. In the proposed approach, two cases are considered based on the interference sources that are either involved or not in the received signals. Moreover, in each case, the detection statistic is derived by assuming the known or unknown variance of the added noise, respectively. For the performance comparison, the GLRT detection statistic is also identified. The relationship between the SRL and the required minimum signal-to-noise ratio/signal-to-interference-plus-noise ratio is also obtained to resolve the two adjacent signal sources. Then, the detection performance and computational complexity are evaluated. The simulation results are used to verify the effectiveness and superiority of the Rao test."
  },
  {
    "year": "2017",
    "abstract": "Real-time collaborative programming allows a team of programmers to concurrently edit the shared source code document at the same time. To support semantic conflict prevention in real-time collaborative programming, a dependency-based automatic locking (DAL) approach was proposed in prior work, which automatically grants locks on source code regions with dependency relationships. The prior DAL scheme was devised under two assumptions that are not realistic, and together with other restrictions, they become serious problems in applying the DAL approach and techniques in real-world programming scenarios. To address the issues under the prior DAL scheme, this paper presents a novel DAL scheme with a shared-locking approach, which ensures the responsiveness, effectiveness, and consistency of semantic conflict prevention in unconstrained real-time collaborative programming. Under the novel DAL scheme, programmers can perform concurrent editing operations with overlapping locking scopes and perform editing operations that may dynamically change the source code structure, while three types of shared-locking are allowed under well-defined circumstances with reasonable design rationales. In addition, we have presented major technical issues and solutions in realizing the scheme, which has been implemented in a research prototype. Experimental evaluations have confirmed the good performance of the novel DAL scheme and its supporting techniques."
  },
  {
    "year": "2017",
    "abstract": "Malaria is a leading cause of death in Africa. Many organizations, NGO's, and government agencies are collaborating to prevent, control, and eliminate malaria. In order to succeed in these shared goals, an integrated, consistent knowledge source to empower informed decision-making is required. Malaria surveillance is currently performed using dynamic, interconnected, systems which require rapid data exchange between different platforms. An important challenge these systems must overcome is the occurrence of dynamic changes in one or more interacting components, which can lead to inconsistencies and mismatches between components of the infrastructure. In this paper, we present our efforts toward the design and development of the semantic interoperability and evolution for malaria analytics platform, with the goal of improving data and semantic interoperability for dynamic malaria surveillance and to support the integration of data across multiple scales. The long term target is to deliver transparent and scalable tools for decision making for malaria elimination. Our analysis is focused on sentinel sites in selected African countries, including Uganda and Gabon."
  },
  {
    "year": "2017",
    "abstract": "This paper concerns the beamforming (BF) design for a dual-hop multiple-input multiple-output (MIMO) amplify-and-forward (AF) relay network. Both a general antenna configuration and imperfect channel state information are taking into consideration, where multiple antennas are deployed at the source, relay, and destination, channel impairments exist at the source-relay and relay-destination hops. The BF scheme is optimized to maximize the received signal-to-noise ratio (SNR). In order to evaluate the performance of the relay network, asymptotic average symbol error rate (ASER) at high SNR is derived. Computer simulations are conducted to show the superiority of the designed BF scheme and the impacts of channel impairments and antenna configurations on the performance of the MIMO AF relay systems. It is shown that the diversity order of the relay network can be reduced to one due to the channel impairments."
  },
  {
    "year": "2017",
    "abstract": "This guide presents nine key questions that can help researchers make good use of citation-based journal rankings (metrics) in the natural and social sciences. The nine questions address the characteristics that distinguish one metric from another: the source documents, the citation-counting window, the document types counted, the cited-document window, the impact of highly cited documents, the treatment of self-citations, the distinction between size-dependent and size-independent metrics, the use of normalization to account for disciplinary differences in impact, and the use of weighting to account for the impact or centrality of each citing journal. Next, the guide reviews 19 standard citation metrics, including the h index, g index, impact factor, source normalized impact per paper, eigenfactor, article influence score, and SCImago journal rank. Three underlying data sources (Web of Science, Scopus, and Google Scholar) are described, along with six major data download sites: Journal Citation Reports, Eigenfactor, CWTS Journal Indicators, SCImago, Scopus Journal Metrics, Cabell's International, and Google Scholar Metrics. The paper summarizes the main criticisms of citation metrics and concludes with suggestions for their further development, dissemination, and use."
  },
  {
    "year": "2017",
    "abstract": "In view of the light-emitting diode (LED) and its life prediction, despite its currently wide use, IES TM-21-11 parametric life prediction method is incapable to extrapolate under multidimensional conditions (include working environmental conditions). This paper presents a multidimensional back propagation-neural network (BP-NN) based life prediction method which considers different driving currents and ambient temperatures. In this method, parameters such as temperature, electric current, initial chromaticity coordinates and initial luminous flux serve as the inputs, while life serves as the output. Since the traditional NN can easily get trapped in local minima and be affected by low precision, the BP-NN method is improved using Adaboost algorithm. The expected life predicted by the improved method is compared with that of traditional BP-NN and IES TM-21-11. The LED lamps of different power grades are compared for verification purposes. The results show that when predicting LED's lifetime, the improved method reduces the average relative error by on average by 54% compared with traditional BP-NN. However, the improved method takes 63.6% longer to operate, which requires the users to choose an appropriate model in accordance with particular operating conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the theoretical analysis of phase distortion (AM/PM) mechanisms in Gallium Nitride (GaN) Doherty power amplifiers (DPAs) and a novel approach to optimize the tradeoff between linearity and efficiency. In particular, it is demonstrated how it is possible to mitigate the AM/PM by designing a suitable mismatch at the input of the active devices, based on the identification of constant AM/PM and gain contour circles. The proposed theory is experimentally confirmed by source- and load-pull measurements and further validated through the design and realization of a 7 GHz 10 W DPA based on GaN monolithic technology."
  },
  {
    "year": "2017",
    "abstract": "Knowledge graph embedding aims at representing entities and relations in a knowledge graph as dense, low-dimensional and real-valued vectors. It can efficiently measure semantic correlations of entities and relations in knowledge graphs, and improve the performance of knowledge acquisition, fusion and inference. Among various embedding models appeared in recent years, the translation-based models such as TransE, TransH, TransR and TranSparse achieve state-of-the-art performance. However, the translation principle applied in these models is too strict and can not deal with complex entities and relations very well. In this paper, by introducing parameter vectors into the translation principle which treats each relation as a translation from the head entity to the tail entity, we propose a novel dynamic translation principle which supports flexible translation between the embeddings of entities and relations. We use this principle to improve the TransE, TransR and TranSparse models respectively and build new models named TransE-DT, TransR-DT and TranSparse-DT correspondingly. Experimental results show that our dynamic translation principle achieves great improvement in both the link prediction task and the triple classification task."
  },
  {
    "year": "2017",
    "abstract": "The unknown noise variance and time-variant fading channels make the spectrum sensing design a challenging task for cognitive radios. Most existing sensing methods suffer from the information uncertainty and can hardly acquire promising performances in the adverse situations. To address this challenge, in this paper, we first formulate a dynamic state-space model for spectrum sensing, in which the unknown noise variance and time-variant flat fading channels are all taken into considerations. The dynamic behaviors of both primary user states and fading channels are characterized by two discrete state Markov chains. Based on this model, a novel spectrum sensing scheme is designed to recursively estimate the occupancy state of primary users, by estimating the time-variant fading channel gain and noise parameters jointly. The joint estimation is primarily premised on a maximum a posteriori probability criterion and the marginal particle filtering schemes. Simulation results are provided to demonstrate the advantages of our proposed method, which can significantly improve the sensing performance over time-variant flat fading channels, even with unknown noise variance."
  },
  {
    "year": "2017",
    "abstract": "To achieve model reuse in combat effectiveness simulation systems development, cognitive decision behaviors are usually implemented using a scripting language, which is separate from the programming language used to implement simulation models. Therefore, it is desirable to establish a much better grounding for cognitive behaviors modeling. In the context of domain specific modeling, metamodeling from scratch for designing such a scripting language poses some limitations, among which is the issue of integrating various models that are represented by various customized languages with different syntax and semantics, together with a large expenditure of designing, implementing, and maintaining these languages and their supporting resources. Instead, UML profile-based metamodeling is adopted, as a lightweight extension to capture the cognitive domain specific concepts, relationships, and constraints. Moreover, a unifying framework is proposed to guide the cognitive domain specific profiles design. Upon this framework, the development process is shown through constructing an anti-submarine tactical profile in combat effectiveness simulation systems domain and the feasibility of the domain specific language is illustrated with an armed escort scenario."
  },
  {
    "year": "2017",
    "abstract": "Like other machine learning paradigms, multi-label learning also suffers from the curse of dimensionality problem. Multi-label dimensionality reduction can alleviate the problem but they generally ask for sufficient labeled samples. Nevertheless, we often may only have scarce labeled samples and abundant unlabeled samples. In this paper, we propose a Semi-supervised Multi-label Dimensionality Reduction based on dependence maximization approach (SMDRdm in short). SDMRdm assumes the semantic similarity and feature similarity of multi-label samples are inter-depended. SMDRdm first applies label propagation on a neighborhood graph composed with labeled and unlabeled samples to obtain the soft labels of unlabeled samples, and then measures the semantic similarity between all the training samples (including unlabeled ones) based on these soft labels and available labels of labeled samples. Next, it measures the feature similarity between samples in the subspace projected by the target projective matrix, instead of the original high-dimensional feature space. After that, it maximizes the dependence between these two types of similarities and incorporates the dependence into linear discriminant analysis to optimize the target projective matrix. Experiments on publicly accessible multi-label data sets demonstrate that SMDRdm achieves more prominent results than other related approaches across various evaluation metrics. In addition, the empirical study also shows the semantic similarity between samples derived from soft labels works better than that derived from scarce available labels."
  },
  {
    "year": "2017",
    "abstract": "Wireless power transfer is able to provide sustainable and relatively stable energy supply for battery-powered wireless sensor networks. This paper investigates how to optimally design a wireless powered sensor network with minimal power requirements. To this end, we formulate an optimization problem to minimize the total energy consumption at two remote radio units (RRUs) by jointly optimizing energy beamforming and time assignment, where the circuit energy consumption including basic circuit and information processing energy consumption at sensors is taken into account in order to achieve a more practical and general system design. To solve this non-convex optimization problem, an efficient solution method is presented on the basis of variable substitutions and semidefinite relaxation technique. We analyze the optimality of our proposed solution method. When the number of sensors is not more than four, the rank-one constraint is always guaranteed. When it is larger than four, we show that with our proposed solution method via simulations, an approximate global optimal result can be achieved. Simulation results also show that by jointly optimizing the energy beamforming and time assignment, the system required power can be greatly reduced, while the energy beamforming has greater effect than time assignment on the proposed system. Moreover, it is shown that for fixed non-zero circuit energy consumption (including the static part and the dynamic part), the total energy consumption at the RRUs almost linearly increases with the increment of transmission rate requirement. Besides, the total energy consumption at two RRUs caused by different numbers of enjoyers and collaborators is also discussed."
  },
  {
    "year": "2017",
    "abstract": "Recently, the analysis of remaining useful life (RUL), which is central to the reliability assessment of lasers under various environment stresses, has become one of the most crucial issues in the field of laser reliability. In this paper, a similarity-based difference analysis (SbDA) approach is proposed to estimate the RUL of GaAs-based semiconductor lasers. SbDA utilizes the inherent relation between historical samples and the on-site sample in which we calculate the inherent difference to acquire a more exact performance degradation value. This method can make adequate use of the limited historical data sets to more accurately estimate the lifetime of an operating GaAs laser. In addition, we present several significant results of studies of model parameters, such as random disturbance, weight distribution factor, and similarity. Experimental results show the effectiveness and advantages of the proposed SbDA method."
  },
  {
    "year": "2017",
    "abstract": "The dynamic model of a doubly fed induction generator (DFIG)-based wind energy system is subjected to nonlinear dynamics, uncertainties, and external disturbances. In the presence of such nonlinear effects, a high-performance control system is required to guarantee the smooth and maximum power transfer from the wind energy system to the ac grids. This paper proposes a novel fractional order adaptive terminal sliding mode control system for both the rotor and grid side converters of the DFIG system. The stability of the closed loop is ensured using the fractional order Lyapunov theorem. Numerical results are presented to show the superiority of the proposed control method over the classical sliding mode control system and the proportional integral controllers."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the delay and delay-constrained throughput performance of a point-to-point wireless-powered communication system is investigated. In this system, the wireless-powered node, e.g., a user equipment (UE), receives data at the same time when powered from the other node, e.g., an access point (AP), and uses the harvested wireless energy to send data to the other node. The investigation focuses on the delay performance of sending data in the downlink (DL) from the AP node to the UE node and that in the uplink (UL) from the UE node to the AP node, based on which the throughput performance on both directions when delay constraints are enforced is also studied. To this aim, the cumulative service capacity of the service process is first analyzed for both DL and UL, taking into consideration the delay caused by the nontransmission phase for the AP or UE in each charging cycle. Thereafter, a general upper bound on the delay distribution for stochastic traffic arrivals is obtained for both DL and UL, based on which the delay-constrained throughput performance is further studied. In addition, to ensure the delay performance, the required energy storage capacity and wireless charging rate are investigated. The obtained results are exemplified with two specific traffic types, and the accuracy of the analysis is validated by comparison with extensive simulation results. The analysis and results shed new light on the performance of wireless-powered communication systems."
  },
  {
    "year": "2017",
    "abstract": "Particle filter has been developing prosperously in the prognostics field and is being applied with success in prognostics of complex systems or components. The existing research works on the prognostic process demonstrate that the state prediction phase that is actualized by classical procedures, such as particle projection, is always prone to performance degradation. To overcome such a defect, this paper presents a novel technique, named the F-distribution particle filter -based prognostics, following the principle that the particles' weights are calculated dynamically by the F kernel rather than keeping fixing in the state prediction phase. The effectiveness of the proposed approach is evaluated through a real experiment of a hydraulic actuator. The analytical results show that the proposed method is more effective in the prediction of the remaining useful life for the internal leakage fault benchmarked against the existing classical particle filtering-based prognostics."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a feasibility study of the uplink visible light communication (VLC) beacon system for the universal traffic management system (UTMS). The UTMS is a traffic management system beneath the National Police Agency of Japan. Currently, 55 000 UTMS infrared beacon systems have been installed, and they provide expressway and ordinary road information to cars. However, the data rate is 1 Mbps, and a faster data rate is necessary to support automotive and smart mobility devices. In this paper, we propose an uplink V2I system for the UTMS. The system is designed to match the current beacon system as closely as possible, so that the system can easily be replaced and still provide sufficient bandwidth for future automotive and smart mobility devices. We adopt a photo diode (PD) as the VLC receiver and a commercially available off-the-shelf LED headlight as a transmitter. Unfortunately, the bandwidth of such an LED is usually small, so we consider applying a bit-loading algorithm to direct-current-biased optical orthogonal frequency division multiplexing. To reduce strong background noise, such as from the sun, we narrow down the field-of-view by applying a lens to the PD, which forms a tiny communication area, smaller than the current infrared beacon system. We then consider multiple PDs with the lens to create a similar communication area as the infrared beacon system. As a result, we achieve 3.1-Mbps throughput."
  },
  {
    "year": "2017",
    "abstract": "The emergence of new physical media such as optical wireless and the ability to aggregate these new media with legacy networks motivate the study of heterogeneous network performance, especially with respect to the design of protocols to best exploit the characteristics of each medium. We consider visible light communications (VLC), which is expected to co-exist with legacy and future radio frequency (RF) media. While most of the research on VLC has been done on optimizing the physical medium, research on higher network layers is only beginning to gain attention, requiring new analyses and tools for performance analysis. To meet this need, we have developed a new ns3-based VLC module that can be used to study VLC-RF heterogeneous networks via simulation. The proposed ns3 module has been developed based on existing models for intensity modulated LED signals operating as lighting units transmitting to optical receivers at indoor scales (meters). These models and the corresponding simulation model are validated using a test bed implemented with a software-defined radio system, photo detector, phosphor-converted “white”LEDs, and under PSK and QAM modulation. Two scenarios are used in the validation of the VLC module: 1) using a receiver placed normal to the transmitter with varying range; and 2) using a receiver with a fixed range with varying angle of acceptance. Results indicate good correspondence between the simulated and actual test bed performance. Subsequently, we demonstrate how the VLC module can be used to predict the performance of a hybrid Wi-Fi/VLC network simulated using the ns3 environment with UDP, TCP, and combined network traffic."
  },
  {
    "year": "2017",
    "abstract": "Due to the limited energy supply, prolonging the network lifetime as much as possible is an important concern when designing the topology of wireless sensor networks. Different from designing complex routing and controlling sink node mobility, this paper aims at achieving system-level energy balance to maximize network lifetime. A general multi-ring structural model is developed to formulate the network lifetime by considering data flow, energy consumption on data transmission and receiving, and wireless harvesting. To explore the factors influencing the maximum network lifetime, a general optimization model considering ring depth, node densities, and inner ring transmitting probabilities is developed. Accordingly, the network optimization problem is divided into the following three scenarios: power control, non-uniform deployment, and probabilistic switching (ProSwit) routing. Particularly, ProSwit is a new method for maximizing network lifetime, and has not been considered before. Simulation results demonstrate that system-level energy balance with multi-hop routing can be achieved by exploiting all the above three schemes. Some useful topology control conclusions for prolonging network lifetime are also concluded."
  },
  {
    "year": "2017",
    "abstract": "The cost consumption of industrial buildings is increasing, with heating, ventilation and air conditioning (HVAC) functions typically comprising half of all cost requirements. These cost requirements are heavily influenced by weather conditions based on the season and time of day, which may require different amounts or types of HVAC to provide habitable working conditions. Similarly, different activities that take place in an industrial building during a 24-h period also have different HVAC requirements. In this paper, we propose an optimal scheduling strategy based on activity type and weather forecasting to conserve HVAC costs. We have formulated the activity scheduling problem as a binary integer linear programming problem (BILP), and solved it using a CPLEX solver. Experimental results show that by scheduling activities, using 8-h time slots, we can achieve a reduction in costs of up to 27%. In addition, with 1-h time slots, optimal activity scheduling can yield up to a 38% reduction in costs."
  },
  {
    "year": "2017",
    "abstract": "Software defect prediction provides actionable outputs to software teams while contributing to industrial success. Empirical studies have been conducted on software defect prediction for both cross-project and within-project defect prediction. However, existing studies have yet to demonstrate a method of predicting the number of defects in an upcoming product release. This paper presents such a method using predictor variables derived from the defect acceleration, namely, the defect density, defect velocity, and defect introduction time, and determines the correlation of each predictor variable with the number of defects. We report the application of an integrated machine learning approach based on regression models constructed from these predictor variables. An experiment was conducted on ten different data sets collected from the PROMISE repository, containing 22838 instances. The regression model constructed as a function of the average defect velocity achieved an adjusted R-square of 98.6%, with a p-value of <; 0.001. The average defect velocity is strongly positively correlated with the number of defects, with a correlation coefficient of 0.98. Thus, it is demonstrated that this technique can provide a blueprint for program testing to enhance the effectiveness of software development activities."
  },
  {
    "year": "2017",
    "abstract": "With increasing emphasis on incorporating energy awareness in future communication systems, it is desirable to explore power-efficient resource allocation techniques. Therefore, in this paper, we consider the sum-power minimization of base stations (BSs) and users in a full-duplex (FD) multiple-input multiple-output multi-cell system. In particular, we assume that BSs operating in FD transmission mode serve multiple FD mobile users at the same time over the same frequency band. To guarantee a certain quality of service (QoS), we enforce the maintenance of a minimum signal-to-interference-plus-noise ratio for each user. Concerning these design constraints together with realistic FD self-interference models, we investigate the transmit and receive beamforming designs that minimize the joint transmission power of BSs and users. However, the resulting optimization problem is NP-hard. We therefore divide this optimization problem into separate receive and transmit beamforming design steps, which can be solved iteratively. In addition, the non-convex precoder design problem is posed as a difference of convex function programming, which can be efficiently solved via successive convex approximation. In order to account for practical aspects in our design, we also take into account imperfect channel state information by way of stochastic and bounded uncertainties. Numerical results suggest that the FD systems generally outperform the half-duplex ones under a wide range of QoS constraints and transceiver distortions."
  },
  {
    "year": "2017",
    "abstract": "Human action recognition plays a significant part in the computer vision and multimedia research society due to its numerous applications. However, despite different approaches proposed to address this problem, some issues regarding the robustness and efficiency of the action recognition still need to be solved. Moreover, due to the speedy development of multimedia applications from numerous origins, e.g., CCTV or video surveillance, there is an increasing demand for parallel processing of the large-scale video data. In this paper, we introduce a novel approach to recognize the human actions. First, we explore Apache spark with in-memory computing, to resolve the task of human action recognition in the distributed environment. Secondly, we introduce a novel feature descriptor, namely, adaptive local motion descriptor (ALMD) by considering motion and appearance, which is an extension of local ternary pattern used for static texture analysis, and ALMD also generate persistent codes to describe the local-textures. Finally, the spark machine learning library random forest is employed to recognize the human actions. Experimental results show the superiority of the proposed approach over other state-of-the-arts."
  },
  {
    "year": "2017",
    "abstract": "The speech denoising problem in the presence of mixed impulsive and Gaussian noises is investigated by exploiting transform domains. To that end, the proposed noise suppression scheme is a cascaded form consisting of an impulsive noise suppression module and a Gaussian noise suppression module. For the impulsive noise reduction subsystem, in this paper, the noise is sparsely represented by the time domain, whereas short-time Fourier transform, wavelet transform, and wavelet synchrosqueezed transform are studied to provide sparse representations for the speech. By utilizing the transform domains, the speech recovery and the impulsive noise suppression are simultaneously achieved under an optimization framework. Subsequently, the alternating direction method of multipliers is used to solve 11-norm constrained optimization. In the Gaussian noise reduction subsystem, the Gaussian noise is suppressed by the famous Wiener filter in the transform domains as well. Numerical studies, including simulations and real data analysis, demonstrate the superior performance of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Cross-domain image matching, which investigates the problem of searching images across different visual domains such as photo, sketch, or painting, has attracted intensive attention in computer vision due to its widespread application. Unlike intra-domain matching, cross-domain images appear quite different in various characteristics. This leads to the failure of most existing approaches. However, the great difference between cross-domain images is just like the huge gap between English and Chinese. The two languages are linked up by an English-Chinese translation dictionary. Inspired by this idea, in this paper, we purpose a novel visual vocabulary translator for cross-domain image matching. This translator consists of two main modules: one is a pair of vocabulary trees which can be regarded as the codebooks in their respective fields, whereas the other is the index file based on cross-domain image pair. Through such a translator, a feature from one visual domain can be translated into another. The proposed algorithm is extensively evaluated on two kinds of cross-domain matching tasks, i.e., photo-to-sketch matching and photo-to-painting matching. Experimental results demonstrate that the effectiveness and efficiency of the visual vocabulary translator. And by employing this translator, the proposed algorithm achieves satisfactory performance in different matching systems. Furthermore, our work shows great potential in multiple visual domains."
  },
  {
    "year": "2017",
    "abstract": "Battery State-of-Health (SOH) estimation is of utmost importance for the performance and cost-effectiveness of electric vehicles. Incremental capacity analysis (ICA) has been ubiquitously used for battery SOH estimation. However, challenges remain with regard to the characteristic parameter selection, estimation viability and feasibility for practical implementation. In this paper, a novel ICA-based method for battery SOH estimation is proposed, with the goals to identify the most effective characteristic parameters of IC curves, optimize the SOH model parameters for better prediction accuracy and enhance its applicability in realistic battery management systems. To this end, the IC curve is first derived and filtered using the wavelet filtering, with the peak value and position extracted as health factors (HFs). Then, the correlations between SOH and HFs are explored through the grey correlation analysis. The SOH model is further established based on the Gaussian process regression (GPR), in which the optimal hyper parameters are calculated through the conjugate gradient method and the multi-island genetic algorithm (MIGA). The effects of different HFs and kernel functions are also analyzed. The effectiveness of the proposed MIGA-GPR SOH model is validated by experimentation."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we report the design and implementation of a Kinect-based system for providing automated realtime assessment, feedback and guidance to users who are practicing rehabilitation exercises at home without the supervision of physical therapists. The foundation for the system is a rule-based framework that can be used to assess in realtime the quality and quantity of the exercises performed by the user. We demonstrate the capability of the rule-based framework by showing the detailed rules for three common rehabilitation exercises, including bowling, hip abduction, and sit to stand. To test its usability and accuracy, we have used the system in a human subject study with eight healthy users. The results show that with proper empirical parameters in the rules, the performance of these exercises can be reliably assessed in realtime."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a detection scheme for the uplink transmission of Wi-Fi backscatter system is proposed. In the uplink transmission, a backscatter tag modulates signals from a Wi-Fi access point by backscattering. Since the reflection occurs, the backscattered signal experiences more attenuation than the direct Wi-Fi signals to a Wi-Fi reader. Most recent studies focus on effective detection techniques to increase the coverage of the backscatter tag in the poor signal to interference plus noise ratio environment. This paper proposes an improved detection scheme using multiple antennas at the reader. At the reader, the backscattered signals are received by multiple antennas and thresholds are determined appropriately for improvement of detection performance. Typically the methods using multiple antennas require channel information. However the channel estimation for the uplink of backscatter system is difficult since the backscattered signals are weak. The detection method of this paper does not require the channel information for the uplink. Simulation results show improved performance and possibility for the increase of coverage."
  },
  {
    "year": "2017",
    "abstract": "Ontologies in real-world applications are typically dynamic entities that are frequently modified when new knowledge needs to be added or when existing knowledge is no longer considered valid. Logical errors inevitably occur when ontologies are modified. To effectively identify the problematic axioms that are responsible for these logical errors, an optimization strategy based on the clash sequence strategy is proposed for debugging the incoherent terminologies in dynamic environments. The clash sequence strategy is used to identify the clash set from an incoherent terminology, and then the debugging work can be performed on the identified clash set than on the entire terminology. A heuristic strategy is also proposed to reuse the results of the previous debugging and to provide information for the next debugging. The experiment results show that the proposed debugging approach based on clash sequences can achieve a significant improvement especially for large-scale ontologies in many cases."
  },
  {
    "year": "2017",
    "abstract": "Bitcoin cryptocurrency is reportedly one widely used digital currency in criminal activities (e.g. used for online purchases of illicit drugs and paying of ransom in ransomware cases). However, there has been limited forensic research of bitcoin clients in the literature. In this paper, the process memory of two popular bitcoin clients, bitcoin Core and electrum, is examined with the aims of identifying potential sources and types of potential relevant data (e.g. bitcoin keys, transaction data and passphrases). Artefacts obtained from the process memory are also studied with other artefacts obtained from the client device (application files on disk and memory-mapped files and registry keys). Findings from this study suggest that both bitcoin Core and electrum's process memory is a valuable source of evidence, and many of the artefacts found in process memory are also available from the application and wallet files on the client device (disk)."
  },
  {
    "year": "2017",
    "abstract": "In online sequential applications, a machine learning model needs to have a self-updating ability to handle the situation, which the training set is changing. Conventional incremental extreme learning machine (ELM) and online sequential ELM are usually achieved in two approaches: directly updating the output weight and recursively computing the left pseudo inverse of the hidden layer output matrix. In this paper, we develop a novel solution for incremental and decremental ELM (DELM), via recursively updating and downdating the generalized inverse of the hidden layer output matrix. By preserving the global optimality and best generalization performance, our approach implements node incremental ELM (N-IELM) and sample incremental ELM (S-IELM) in a universal form, and overcomes the problem of self-starting and numerical instability in the conventional online sequential ELM. We also propose sample DELM (S-DELM), which is the first decremental version of ELM. The experiments on regression and classification problems with real-world data sets demonstrate the feasibility and effectiveness of the proposed algorithms with encouraging performances."
  },
  {
    "year": "2017",
    "abstract": "Design of a conical-disc-backed circular-polarized Archimedean single-arm spiral antenna is presented in this paper. The antenna operation covers the X-band frequencies ranging from 8 to 12 GHz. The antenna makes use of a very simple structure having the single-arm spiral backed by a cone-shaped metallic disc to achieve high gain, circular polarization, and unidirectional symmetric radiation near the boresight. The diameter of the antenna only measures to 40 mm. The simulated and measured results show that the antenna has a very good impedance matching (better than -10 dB), good right-hand circular polarization (with an axial ratio of ≤3 dB) throughout the frequency range of interest, and offers a maximum peak gain of 11.4 dBiC. The presented S11response and radiation pattern results also show that the antenna offers excellent performance in the X-band with no need of a balun. Antenna usefulness is also established through a detailed parametric study and comparison with a traditional flat disc structure. Compact size, simple design, wide range, and high gain make the proposed antenna design a good choice for radar, terrestrial communications, and satellite/aerospace communications applications."
  },
  {
    "year": "2017",
    "abstract": "The new generation of communication technologies, named 5G, brings along a variety of emerging applications and services from both human and machine perspectives. The growing demand for bandwidth in 5G may therefore lead to massive deficiency in wireless spectrum availability despite its underutilization in urban areas. The Smart City paradigm assumes a multitude of communicating machines at high density, which requires improved spectrum management flexibility. The novel licensed shared access (LSA) framework that has attracted recent industrial and academic attention may become a feasible solution to leverage such underutilized spectrum more efficiently. This paper analyzes the effects of applying LSA in the Smart City context by proposing an appropriate mathematical model. Particularly, we focus on the vehicle-to-everything 5G use case where connected devices attempt to distribute their sensed data including occasional video information. The proposed analytical framework allows to capture the probabilities of rare events during such operation by providing with a high level of precision in the resulting performance estimates."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new approach from a certification standpoint toward the fault-tolerant control (FTC) strategies used to accommodate failures of a Remotely Piloted Aircraft System (RPAS) in non-conventional aerodynamic configuration. The reference aircraft of this paper is the ATLANTE RPA, which has a V-tail. A novel review of the most common accidents and incidents in general and commercial aviation, and in the RPAS sector, has been conducted in order to check the relevance of the proposed failures and the flight phase where they most frequently happen. Damage scenarios are, on the one hand, one lockedin-place flaperon and, on the other hand, propulsion system failure resulting in a gliding flight condition. This second scenario is an original contribution of this paper. The proposed FTC is based on the multiple model switching and tuning technique, and then a classical control is applied to each model in order to ensure the certification criteria. In the case of the propulsion system failure model, a new architecture with airspeedon-elevator control law is proposed. This controller has been tested using a novel guidance law during the gliding, final approach, and landing phases making use of a flight simulator developed for the ATLANTE RPA. The results obtained highlight the concordance between the regulation requirements and the results for both proposed failures, making it possible for the aircraft to meet the certification requirements, while maintaining a safe condition after failures."
  },
  {
    "year": "2017",
    "abstract": "The key issue of multi-sensor image fusion is how to accurately extract and fuse the high-quality pixels or coefficients of source images. Nevertheless, the so-called high-quality is an uncertain or fuzzy definition, which is very suitable for fuzzy theory to address this problem. By the integration of stationary wavelet transform (SWT) and fuzzy sets, this paper proposes a new multi-focus image fusion scheme, which can merge the important features of different source images into a fused image. First, the source images are decomposed by SWT to get a set of sub-images with different detailed features. Second, the Gaussian membership function (GMF) is utilized to get the fuzzy sets of sub-images data. Third, the local spatial frequency (LSF) is employed to extract the local features of the sub-images by the generated fuzzy sets. At last, the fusion rule is designed based on consistency verification to fuse the sub-images according to the LSF of fuzzy sets, and then inverse SWT (ISWT) is implemented to reconstruct the fused image. The experimental and contrastive results of different image sets show that the proposed method is an effective multi-focus image fusion scheme which can achieve better fusion effect than other methods."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a local spatio-temporal descriptor for action recognistion from depth video sequences, which is capable of distinguishing similar actions as well as coping with different speeds of actions. This descriptor is based on three processing stages. In the first stage, the shape and motion cues are captured from a weighted depth sequence by temporally overlapped depth segments, leading to three improved depth motion maps (DMMs) compared with the previously introduced DMMs. In the second stage, the improved DMMs are partitioned into dense patches, from which the local binary patterns histogram features are extracted to characterize local rotation invariant texture information. In the final stage, a Fisher kernel is used for generating a compact feature representation, which is then combined with a kernel-based extreme learning machine classifier. The developed solution is applied to five public domain data sets and is extensively evaluated. The results obtained demonstrate the effectiveness of this solution as compared with the existing approaches."
  },
  {
    "year": "2017",
    "abstract": "Friendship formation between a pair of individuals (dyads) and its dynamics is a complex phenomenon that has been extensively studied in the literature. Assortative, relational, and proximity mechanisms are the recognized social processes that are responsible for the formation of these dyadic ties. In this paper, we develop an agent-based model that derives its essence from social processes, fuzzy game theory, and social network analysis. The process of dyadic friendship formation depends on the agent's (participant's) spatial configuration, attributes affecting friendship, and interaction with other agents. To model these interactions, we use fuzzy iterated prisoner's dilemma (Fuzzy-IPD) utilizing the decision factors contributing to similar social processes. These strategies have been independently discussed in previously published studies. We, however, use them in combination to design a descriptive model with different experimental settings in an ad-hoc simulation framework. Using an integrationist approach, we blend multiple individual components of friendship formation to construct a comprehensive model. The analysis of the model thus developed reveals a possible interaction pattern responsible for the evolution of the layered associations. This paper further validates various levels of friendship ties (strong ties, medium ties, and weak ties) in social networks as reported in the published sociological studies."
  },
  {
    "year": "2017",
    "abstract": "The interplay of self-heating and polarization affecting resistance is studied in AlGaN/GaN transmission line model (TLM) heterostructures with a scaled source-to-drain distance. This paper is based on meticulously calibrated TCAD simulations against I-V experimental data using an electro-thermal model. The electro-thermal simulations show hot-spots (with peak temperature in a range of ~566 K-373 K) at the edge of the drain contact due to a large electric field. The electrical stress on Ohmic contacts reduces the total polarization, leading to the inverse/converse piezoelectric effect. This inverse effect decreases the polarization by 7%, 10%, and 17% during a scaling of the source-to-drain distance in the 12 μm, 8 μm, and 4 μm TLM heterostructures, respectively, when compared with the largest 18-μm heterostructure."
  },
  {
    "year": "2017",
    "abstract": "Information fusion using evidence theory in wireless sensors networks has been used extensively to identify targets because it offers the advantage of handling uncertainty. But the classical Dempster's combination rule cannot deal with highly conflicting information because it often generates counterintuitive results. In this paper, a new weighted evidence combination approach is proposed to solve this problem. First, two measures, i.e., a new contradiction measure of each body of evidence (BOE) and a probabilistic-based dissimilarity measure between two BOEs, are introduced to estimate the value of weight of each sensor. Then, when combining conflicting information, reasonable results can be produced by using weighted average of BOEs and Dempster's rule. Our experimental results showed that the proposed method has better performance in convergence than the existing methods."
  },
  {
    "year": "2017",
    "abstract": "Risk management in distributed software development (DSD) is a well-researched area, providing different methods for assessing risks and suggesting control strategies. However, some of these methods are narrow in scope, only considering few risks, and are too complex to be used in practice whereas others provide many rules and guidelines which are often implicit. Moreover, the knowledge related to risks in DSD is scattered over different publications which make it difficult to find relevant information to be used in practice. This research aims to develop an automated decision support system to aid practitioners in assessing risks and deciding on suitable control strategies. In order to construct the knowledge base for the proposed decision support system, a systematic literature review (SLR) is conducted. Results of SLR are used to identify required questions, options and set of rules to implement our decision support system (DSS). In total 80 studies were identified from which 49 aspects, 53 questions, and a set of rules are extracted. DSS is evaluated through multiple case studies. The results indicate that the developed DSS supports decision-making process in risk assessment and selection of control strategy."
  },
  {
    "year": "2017",
    "abstract": "An integrated approach to static real-time voltage stability assessment in bulk power systems based on mutual information theory is proposed. An advanced maximum-relevance minimum-redundancy (MRMR) algorithm is designed to explore the invisible association between operation variables and the voltage stability margin (VSM). Multiple MRMR procedures with different selected variables are generated in parallel. A set of inter-complementary features is generated one by one using the MRMR criterion that additional VSM information should be reflected in new obtained variables. A functional expression of the relationship between input variables and the VSM is obtained by curve fitting. The performance of the proposed approach is tested on 21- and 1648-bus systems provided by PSS/E. The impacts of training set size, a number of selected feature sets, length of feature sets, and robustness to topology change are studied. Experimental results indicate that compared with other traditional methods, the proposed technique provides faster and more accurate assessment results. Given the proposed method’s efficiency, it is suitable for real-time voltage stability assessment."
  },
  {
    "year": "2017",
    "abstract": "To simulate the complex behavior of power systems, operators frequently rely on models. The task of model identification and validation becomes important in this context. The validity of the models has a direct influence on operator's decisions and actions. In other words, erroneous or imprecise models lead to erroneous predictions of the systems' behavior which may result in unwanted operator's actions. This paper addresses the challenge of model structure choice for modeling and parameter identification in power systems. Three types of model structures are analyzed: 1) physical principle-based modeling; 2) black-box modeling (NARX, transfer function, Hammerstein-Wiener model); and 3) combination of physical and black-box modeling. This analysis has been performed using real grid measurements and available knowledge about a static VAR compensator (SVC) connected to the U.K.'s transmission network and operated by National Grid. The SVC's modeling is presented in the context of a generalized modeling and identification algorithm, that is offered as a guideline for engineers. The model validity issues of the identified SVC models that include modeling uncertainty are discussed."
  },
  {
    "year": "2017",
    "abstract": "The abrupt change in current or voltage caused by the rapid switching action of power semiconductor devices will generate high-frequency electromagnetic interference (EMI) and needs to be located as the primary interference sources in power electronics. This paper deals with interference suppression on the basis of the study of shaped switching transients in switching waveforms and closed-loop gate drive method for power MOSFETs. The characteristics of switching waveforms with arbitrary switching transients are investigated in both timeand frequency-domain. In addition, conditions of constructing a switching waveform with optimized switching transients are put forward. An optimized Gaussian switching waveform with infinite successive derivatives is proposed which provides the deepest decreasing rate in the interference source spectrum for a given switching time. Compared with a trapezoidal waveform with singleslope transients, the proposed switching waveform has better interference suppression at high frequencies. Meanwhile, a closed-loop gate control prototype with on-state resistance compensation is presented to shape the switching transients of power MOSFETs. The simulated and experimental results show that the proposed controller is successfully implemented to shape the drain-source voltage into an optimized Gaussian reference. Spectrum comparisons show that the EMI generation is effectively suppressed as expected."
  },
  {
    "year": "2017",
    "abstract": "Increasing demands for high-speed broadband wireless communications with voice over long term evolution (LTE), video on demand, multimedia, and mission-critical applications for public safety motivate 4th-generation (4G) and 5G communication development. The flat IP-based LTE and LTE-Advanced technologies are the expected key drivers for 5G. However, LTE, with its elapsed security mechanism and open nature, leaves a huge loophole for intruders to jeopardize the entire communication network. The timeand bandwidth-consuming authentication procedure in LTE leads to service disruptions and makes it unfit for public safety applications. To cater the prevailing LTE security and service requirements, we propose the 4G plus relative authentication model (4G+RAM), which is composed of two dependent protocols: 1) Privacy-protected evolved packet system authentication and key agreement protocol for the initial authentication (PEPS-AKA) and 2) 4G plus frequency-based re-authentication protocol for the re-authentication of known and frequent users (4G+FRP). The 4G+RAM supports seamless communication with a minimum signaling load on core elements and conceals users' permanent identifiers to ensure user privacy. We simulate the proposed protocols for formal security verification with the widely accepted automated validation of Internet security protocols and applications tool. A comparative analysis of bandwidth consumption is also performed and proved that the proposed 4G+RAM outperforms the existing solutions."
  },
  {
    "year": "2017",
    "abstract": "The problem of influence maximization (IM) in a social network is to determine a set of nodes that could maximize the spread of influence. The IM problem has been vitally applied to marketing, advertising, and public opinion monitoring. Although recent studies have studied the IM problem, they are generally greedy or heuristic-based algorithms, which are time consuming for practical use in large-scale social networks. Based on the observation that structural hole nodes usually are much more influential than other nodes, in this paper, we develop a structure-hole-based influence maximization algorithm (SHIM) with an emphasis on time efficiency. The SHIM algorithm utilizes structure hole information to significantly decrease the number of candidates of seed nodes. To measure the structure importance of nodes, we propose an structure hole value calculate algorithm to calculate the structural hole value of nodes. We prove the SHIM is NP-hard and propose a structure-based greedy algorithm to select seeds with wide influence spread and high structural hole value. We conduct experiments on real data sets to verify our algorithm's time efficiency and accuracy, and the experimental results show that comparing with the existing algorithms, our algorithms are much more efficient and scalable."
  },
  {
    "year": "2017",
    "abstract": "The perturbations are the disturbances of motion presented in the plant inputs which affect the motion of the output and states. In this paper, a sliding mode regulator is recommended for the perturbations attenuation in the plant output and states. The novelty of the advised regulator is that it does not employ an observer for the perturbations estimation; consequently, it is more compact. The asymptotic stability of the regulator is ensured via the Lyapunov approach. The mentioned regulator is employed in two tank plants prototypes."
  },
  {
    "year": "2017",
    "abstract": "This paper proposed a fuzzy adaptive chaos synchronization method for a 4-D energy resource system with time-varying delays. The unknown time-varying delays are compensated based on Lyapunov-Krasovskii functional. Fuzzy logic systems are adopted to approximate the unknown nonlinear functions. Under the condition that all the system parameters are useless, an adaptive synchronization scheme is presented based on robust adaptive theory and Lyapunov stability to ensure that the two chaotic systems asymptotically synchronized. It is shown that all the signals in the closed-loop system are proved to be bounded, and the system output could track the given reference signal. The simulation example is given to illustrate the effectiveness of the design proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "Time synchronization is extremely important for wireless sensor networks (WSNs). For largescale WSNs, hierarchical clock synchronization, which can effectively save energy by reducing communication overhead, has become an attractive approach in practical networks. Based on the hierarchical network, in this paper, we present a global clock skew estimation scheme with immediate clock adjustment. The maximum likelihood estimator and corresponding Cramer-Rao lower bound of the clock skew are derived under the Gaussian delay model, and the simulation results verify that the proposed method is efficient."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a delay-sensitive communication approach based on distributed processing for real-time applications that provide interactive services for multiple users in order to minimize the delay considering both admissible delay and delay variation rate. The proposed approach considers two scenarios, namely, simultaneous participation and successive participation. In the simultaneous participation, all users and servers are given, and the application is processed in different distributed servers; a user accesses a suitable server as a solution of the server selection problem. In the successive participation, where all servers are given, different users will be participated sequentially in a greedy manner with variation of time, while executing the currently applications. We formulate an integer linear programming (ILP) problem in the simultaneous participation scenario for the distributed server selection when all users and servers are given considering the parameter of admissible delay and delay-variation rate. We prove that the distributed server selection problem is NP-complete. By using a high-performance optimization solver, we solve the introduced ILP problem within a practical time for 800 users. We provide a method for the successive participation scenario by utilizing the ILP formulated in the simultaneous participation. Numerical results indicate that the proposed delay-sensitive communication approach based on distributed processing outperforms the conventional centralized processing approach in terms of delay."
  },
  {
    "year": "2017",
    "abstract": "A pilot parabolic solar dish-Stirling system was designed and set up in Kerman, Iran, based on initial evaluations. The objective of this paper was to mathematically model this system to improve its performance by taking the design main factors of the collector into account. To analyze the performance of the system a thermodynamic model was developed to predict the thermal efficiency of the dish-Stirling engine based on factors such as fluid and mechanical friction, finite regeneration process time, and heat transfer, including the effects of cycle internal and external irreversibilities. The power output of the Kerman pilot was measured midday in mid-June, and it was in a good agreement with the mathematical model. Based on the results obtained by the model, the power output of the Kerman pilot in the middle days of all months in a year were predicted and then compared with the output results obtained using an improved system with an appropriately designed concentration ratio. The results showed that, in the middle of June, the maximum power output of a system with an improved concentration ratio of 2499.8 was about 1.66 times higher than that of the original Kerman pilot with a concentration ratio of 625. This system enhancement resulted in 3.56 times higher annual energy production. Moreover, the effects of the dish diameter on the system performance and the annual energy production were studied. Results showed that the annual energy production increased from 1.945 to 6.74 GWh/year when the dish diameter was increased from 3 to 5 m."
  },
  {
    "year": "2017",
    "abstract": "In mobile ad hoc networks (MANETs), if mobile devices frequently leave or join the overlay of MANETs, the communication links between mobile devices or between mobile devices and cloud will lose or reestablish; for searching and routing the needed cloud services again, more energy will be consumed. 5G is the fifth generation mobile communication technology, and fog computing is defined as a distributed computing infrastructure that is able to handle billions of Internet-connected devices. Therefore, combining fog computing with 5G, we present a novel and effective dynamic cloudlet-assisted routing mechanism (DCRM) for MANETs to solve the energy-saving problem of link breakages. First, for every mobile device in MANETs, we build a temporary file to record its identity and route information in a certain time. Moreover, as a key promising technology of 5G, device-to-device is used as the communication way between mobile devices, because it can enhance the communication ability and the information sharing ability between mobile devices. Second, cloudlets can be considered as small data centers, and we set the sharing relation table and the cooperation mechanism between cloudlets. Then, relying on these, mobile devices can quickly route and search the requested services regardless of the frequent movement of mobile devices in MANETs. The experimental results show that DCRM can save more time and several times more energy, and display more advantages than the network model without the proposed mechanism in many ways, consequently enable cloud to provide services that are more realistic for the future mobile network applications."
  },
  {
    "year": "2017",
    "abstract": "Metamorphic testing has been successfully used in many different fields to solve the test oracle problem. However, how to find a set of appropriate metamorphic relations for metamorphic testing remains a complicated and tedious task. Recently some machine learning approaches have been proposed to predict metamorphic relations. These approaches predicting single label metamorphic relation can alleviate this problem to some extent. However, many applications involve multi-group metamorphic relations, and these approaches are clearly inefficient. To address this problem, in this paper we propose a Multi-Label Metamorphic Relations prediction approach based on an improved radial basis function (RBF) neural network named RBF-MLMR. First, RBF-MLMR uses state-of-the-art soot analysis tool to generate control flow graph and corresponds labels from the source codes of programs. Second, the extracted nodes and the path properties constitute multi-label data sets for the control flow graph. Finally, a multi-label RBF neural network prediction model is established to predict whether the program satisfies multiple metamorphic relations. In order to improve the prediction results, affinity propagation and k-means clustering algorithms are used to optimize the RBF neural network structure of RBF-MLMR. A set of dedicated experiments based on public programs is conducted to validate RBF-MLMR. The experimental results show that RBF-MLMR can achieve accuracy of around 80% for predicting two and three metamorphic relations."
  },
  {
    "year": "2017",
    "abstract": "IoT generates considerable amounts of data, which often requires leveraging cloud computing to effectively scale the costs of transferring and computing these data. The concern regarding cloud security is more severe because many devices are connected to the cloud. It is important to automatically monitor and control these resources and services to efficiently and securely deliver cloud computing. The writable virtual machine introspection (VMI) technique can not only detect the runtime state of a guest VM from the outside but also update the state from the outside without any need for administrator efforts. Thus, the writable VMI technique can provide the benefit of high automation, which is helpful for automated cloud management. However, the existing writable VMI technique produces high overhead, fails to monitor the VMs distributed on different host nodes, and fails to monitor multiple VMs with heterogeneous guest OSes within a cloud; therefore, it cannot be applied for automated and centralized cloud management. In this paper, we present CloudVMI, which is a writable and crossnode monitoring VMI framework that can overcome the aforementioned issues. CloudVMI solves the semantic gap problem by redirecting the critical execution of system calls issued by the VMI program into the monitored VM. It has strong practicability by allowing one introspection program to inspect heterogeneous guest OSes and to monitor VMs distributed on remote host nodes. Thus, CloudVMI can be directly applied for automated and centralized cloud management. Moreover, we implement some defensive measures to secure CloudVMI itself. To highlight the writable capability and practical usefulness of CloudVMI, we implement four applications based on CloudVMI. CloudVMI is designed, implemented, and systematically evaluated. The experimental results demonstrate that CloudVMI is effective and practical for cloud management and that its performance overhead is acceptable compared with existing VMI sy..."
  },
  {
    "year": "2017",
    "abstract": "Wireless body area network (WBAN) has attracted more and more attention to automatically and intelligently sense the health data of one person for supporting various health applications in smart cities. In the energy-constrained and heterogeneous WBAN system, there are three main issues: 1) the dynamic link characteristics due to the time-varying postures and environments; 2) the high energy efficiency requirement with considering the limited sensor battery; and 3) the high quality-of-service (QoS) requirement due to the importance of health data. To provide long service with high quality, the resource allocation scheme becomes indispensable with considering all these issues. In this paper, a mix-cost parameter is designed to evaluate the energy efficiency and QoS effectiveness, and a resource allocation problem is formulated to minimize the total mix-cost with optimizing the transmission rate, the transmission power, and the allocated time slots for each sensor. Then, a buffer-aware sensor evaluation method with low complexity is introduced to the resource allocation scheme to evaluate the sensor state in real time and then decide when applying for the resource reallocation by the hub for further improving both the short-term and the long-term QoS performance. Finally, a greedy sub-optimal resource allocation scheme is designed to reduce the time complexity of the resource allocation scheme. Simulation results are presented to demonstrate the effectiveness of the proposed optimal buffer-aware resource allocation scheme as well as the greedy sub-optimal resource allocation scheme with low complexity."
  },
  {
    "year": "2017",
    "abstract": "Software process improvement and business process reengineering are concomitant for software companies that struggle to mature their processes to reduce software project failures. Process gap analysis is an indispensable activity of both the initiatives. It is the identification of deviations in any process from a standard well-defined process. To identify deviations, an as-is process (descriptive/current process) and its corresponding to-be process (prescriptive/standard) are required. However, there is a lack of reengineering tools that support automated gap analysis. Companies rely on manual identification of deviations. The literature discusses various graph matching algorithms/techniques that determine similarities and differences between two graphs. They can be used in software industry as well to achieve multiple objectives, such as process improvement. As these techniques present certain limitations, such as insufficient element coverage for process gap analysis, they cannot deal with process gap analysis per se. However, they establish a ground for a much sophisticated solution. This paper presents an improved gap analysis algorithm to identify deviations in processes. The proposed algorithm is formally verified and also evaluated using an example process model."
  },
  {
    "year": "2017",
    "abstract": "With increasing the penetration of distributed and renewable sources into power grids, and with increasing the use of power electronics-based devices, the dynamic behavior of large-scale power systems is becoming increasingly complex. These recent developments have led to several models attempting to simplify the analysis of dynamic phenomena, among them are models based on the dq0 transformation. Many recent works present dq0-based models of various power system components, ranging from small renewable sources to complete networks. The purpose of this paper is to review and categorize these works, with an objective to promote a straightforward modeling and the analysis of complex systems, based on dq0 quantities. This paper opens by recalling basic concepts of the dq0 transformation and dq0-based models. We then review several recent works related to dq0 modeling and analysis, considering the models of passive components, complete passive networks, synchronous machines, wind turbine systems, photovoltaic inverters, and others."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel multi-frame super-resolution (SR) method, which is developed by considering image enhancement and denoising into the SR processing. For image enhancement, a gradient vector flow hybrid field (GVFHF) algorithm, which is robust to noise is first designed to capture the image edges more accurately. Then, through replacing the gradient of anisotropic diffusion shock filter (ADSF) by GVFHF, a GVFHF-based ADSF (GVFHF-ADSF) model is proposed, which can effectively achieve image denoising and enhancement. In addition, a difference curvature-based spatial weight factor is defined in the GVFHF-ADSF model to obtain an adaptive weight between denoising and enhancement in the flat and edge regions. Finally, a GVFHF-ADSF-based multi-frame SR method is presented by employing the GVFHF-ADSF model as a regularization term and the steepest descent algorithm is adopted to solve the inverse SR problem. Experimental results and comparisons with existing methods demonstrate that the proposed GVFHF-ADSF-based SR algorithm can effectively suppress both Gaussian and salt-and-pepper noise, meanwhile enhance edges of the reconstructed image."
  },
  {
    "year": "2017",
    "abstract": "Random linear network coding (RLNC) is a popular coding scheme for improving communication and content distribution over lossy channels. For packet streaming applications, such as video streaming and general IP packet streams, recent research has shown that sliding window RLNC approaches can reduce the in-order delay compared with block-based RLNC. However, existing sliding window RLNC approaches have prohibitive computational complexity or require feedback from the receivers to the sender. We introduce caterpillar RLNC (CRLNC), a practical finite sliding window RLNC approach that does not require feedback. CRLNC requires only simple modifications of the encoded packet structure and elementary pre-processing steps of the received coded packets before feeding the received coding coefficients and symbols into a standard block-based RLNC decoder. We demonstrate through extensive simulations that CRLNC achieves the reliability and low computational complexity of block-based RLNC, while achieving the low in-order delays of sliding window RLNC."
  },
  {
    "year": "2017",
    "abstract": "The Web of Things is a new and emerging concept that defines how the Internet of Things can be connected using common Web technologies, by standardizing device interactions on upper-layer protocols. Even for devices that can only communicate using proprietary vendor technologies, upper-layer protocols can generally provide the necessary contact points for a high degree of interoperability. One of the major development issues for this new concept is creating efficient hypermedia-enriched application programming interfaces (APIs) that can map physical Things into virtual ones, exposing their properties and functionality to others. This paper does an in-depth comparison of the following six hypermedia APIs: 1) the JSON Hypertext Application Language from IETF; 2) the Media Types for Hypertext Sensor Markup from IETF; 3) the Constrained RESTful Application Language from IETF'; 4) the Web Thing Model from Evrythng; 5) the Web of Things Specification from W3C; and 6) the Web Thing API from Mozilla."
  },
  {
    "year": "2017",
    "abstract": "An open loop control law for stator d- and q-axis currents in a rotor field oriented induction machine are derived in the form of analytical functions of time and used to study how energy losses during speed transients can be minimized. The trajectories due to the developed functions are inspired by the numerical solution of the induction machine optimal control problem. It is found that transient energy efficiency of the machine depends primarily on the initial rotor flux at the beginning of the transient interval. The influences of change in the rotor speed, rotor moment of inertia, and rotor time constant on optimal transient energy efficiency are analyzed and results are discussed."
  },
  {
    "year": "2017",
    "abstract": "LLCresonant converter is utilized for a 3.3-kW on-board charger (OBC), where high efficiency and wide output voltage are required. In this paper, the resonant frequency and the magnetizing inductor of the converter are first optimized based on the required efficiency. Then, the resonant inductor and the resonant capacitor are designed considering the required maximum output voltage. The energy equations and the KCL and KVL equations about the converter are established by the time domain method to find out the information about peak resonant current, peak magnetizing current, and minimum switching frequency. The above-mentioned information is used to accurately design the converter’s magnetic components. A 3.3-kW prototype applied for OBC is developed. Its output voltage ranges from 230 to 430 V. Its peak efficiency is higher than 97.6%. The experimental results verify that the proposed method can accurately design the efficiency, the voltage gain, and the magnetic components ofLLCresonant converter in a wide output voltage range."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, telemedicine is an emerging healthcare service where the healthcare professionals can diagnose, evaluate, and treat a patient using telecommunication technology. To diagnose and evaluate a patient, the healthcare professionals need to access the electronic medical record (EMR) of the patient, which might contain huge multimedia big data including X-rays, ultrasounds, CT scans, and MRI reports. For efficient access and supporting mobility for both the healthcare professionals as well as the patients, the EMR needs to be kept in big data storage in the healthcare cloud. In spite of the popularity of the healthcare cloud, it faces different security issues; for instance, data theft attacks are considered to be one of the most serious security breaches of healthcare data in the cloud. In this paper, the main focus has been given to secure healthcare private data in the cloud using a fog computing facility. To this end, a tri-party one-round authenticated key agreement protocol has been proposed based on the bilinear pairing cryptography that can generate a session key among the participants and communicate among them securely. Finally, the private healthcare data are accessed and stored securely by implementing a decoy technique."
  },
  {
    "year": "2017",
    "abstract": "Public protection and disaster relief (PPDR) situations are becoming increasingly common due to the rapid urbanization of our society. Among these, harsh weather conditions and harmful human activity create challenges for reliable operation of mobile communication infrastructures, which calls for immediate action. The wireless networks of today may not be ready to accommodate emergency scenarios as they have not been optimized for PPDR contexts historically. In this paper, we first review the important use cases, challenges, and requirements in the context of next-generation mobile networking for PPDR applications. We argue that many emerging services may be supported by the novel communication technology operating in millimeter-wave spectrum. Against this background, we contribute a new analytical model to characterize session continuity and other service-level performance indicators in cases when the communication system is susceptible to sudden intermissions caused by emergency situations."
  },
  {
    "year": "2017",
    "abstract": "Leakage detection and localization in pipelines has become an important aspect of water management systems. Since monitoring leakage in large-scale water distribution networks (WDNs) is a challenging task, the need to develop a reliable and robust leak detection and localization technique is essential for loss reduction in potable WDNs. In this paper, some of the existing techniques for water leakage detection are discussed and open research areas and challenges are highlighted. It is concluded that despite the numerous research efforts and advancement in leakage detection technologies, a large scope is still open for further research in this domain. One such area is the effective detection of background type leakages that have not been covered fully in the literature. The utilization of wireless sensor networks for leakage detection purposes, its technical challenges as well as some future research areas are also presented. In a general remark, practical application of these techniques for large-scale water distribution networks is still a major concern. In this paper, an overview of this important problem is addressed."
  },
  {
    "year": "2017",
    "abstract": "Insulator detection using an infrared image is challenged by variance of temperature, orientations, and a cluttered background. A robust and discriminative representation of insulators in electric power systems is needed. This paper proposes a novel method for generating this type of representation in infrared images by taking advantage of high-level discriminative Convolutional Neural Networks (CNNs) to feature the extraction framework and the deformation invariant nature of the Vector of Locally Aggregated Descriptors (VLAD) aggregator. Different from existing methods, we delve deep into the convolutional feature maps. We first extract deep activation maps from convolutional layers of a pretrained deep model and replace the last three fully-connected layers with a VLAD pooling layer to generate the representation of an insulator. Then, we train a Support Vector Machine (SVM) for binary classification. To further verify the effectiveness and robustness of our proposed feature, an insulator detection pipeline based on an object proposal is introduced. The experimental results show that our proposed method can achieve an accuracy of 93%. Meanwhile, the detection results demonstrate that our insulator detection pipeline has satisfied performance goals."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the analysis of microstrip structures with graphene material as the conducting strip using two numerical methods, spectral domain technique and method of lines. The conductivity of graphene sheet is modeled in the analytical method using a tensor matrix. The results obtained from the above-mentioned methods are compared with those of commercial COMSOL modeling software. The structure is parametrically studied to investigate the effects of chemical potential and magnetic field bias on its behavior. The considered structures demonstrate attractive characteristics such as tunablility of dispersion and characteristic impedance as functions of chemical potential and magnetic bias, which can be used in new microwave applications. These characteristics have not been observed in the ordinary microstrip line structures."
  },
  {
    "year": "2017",
    "abstract": "Near-field magnetic wireless systems have distinct advantages over their conventional farfield counterparts in water-rich environments, such as underwater, underground, and in biological tissues, due to lower power absorption. This paper presents a comprehensive review of near-field magnetic wireless power transfer (WPT) and communication technologies in a variety of applications from general free-space systems, to implantable biomedical devices we find of particular interest. To implement a fully wirelessly-powered implantable system, both high-efficiency power transfer and high-rate data communication are essential. This paper first presents the history and the fundamentals of near-field WPT and communication in free-space systems, followed by technical details for their specific use in implantable biomedical devices. Finally, this paper reviews recent advances in simultaneous wireless information and power transfer and highlights their applications in implantable biomedical systems. The knowledge reviewed in the paper could provide intuition in the design of various wireless and mobile systems such as wireless body area networks, small-cell 5G cellular, as well as in-body biomedical applications, especially for efficient power and data management and higher security."
  },
  {
    "year": "2017",
    "abstract": "Power fluctuations caused by wind speed variations affect power quality, especially in weak or isolated grids, and degrade the reliability of wind power converters. This paper develops a wind power smoothing scheme by making use of the large inertial energy of a wind turbine system (WTS). The proposed method, which explores the energy storage capability of the WTS shaft, is easy to implement by adding two additional terms into the existing maximum power point tracking (MPPT) control reference. Based on the law of conservation of energy, the new controller includes two parts: one part is to duplicate the original power trajectory under the MPPT control and the other is to compensate the fluctuations of it. In this way, two control objectives, namely, optimized wind power capture and its smoothing can be achieved simultaneously since the rotor rotates around the optimum speed points. Meanwhile, the mechanical stress of a WTS is alleviated with less oscillating torque reference, and the stability of a WTS is maintained by disabling the smoothing function when the rotor speed hits the speed limits. RTDS simulations of double-fed induction generator-and direct-driven permanent magnet synchronous generator-based WTSs are used to demonstrate the effectiveness of the proposed power smoothing control algorithm. The proposed method is validated on both a single WTS and a wind farm. Quantitative analysis is then carried out to evaluate the relationship between the smoothing performance and the efficiency of wind energy capture."
  },
  {
    "year": "2017",
    "abstract": "This work was supported in part by the National Natural Science Foundation of China under Grant 61473331, in part by the Natural Science Foundation of Guangdong Province of China under Grant 2014A030307049, in part by the Ordinary University Innovation of Guangdong Province of China under Grant 2015KTSCX094, in part by the Sail Plan Training High-Level Talents of Guangdong Province of China, in part by the Science and Technology Plan of Guangdong Province of China under Grant 2015B020233019, in part by the High-level Personnel of Institutions of Higher Learning of Guangdong under Grant [2013] 246.152, in part by the Scientific Research Foundation of Discipline and Specialty Construction in Higher Education of Guangdong under Grant 2013KJCX0133, in part by the 2016 Annual Scientific and Technological Innovation Special Fund to foster Students Projects of Guangdong under Grant pdjh2016b0341, in part by the Guangdong University of Petrochemical Technology College Students' Innovation Incubation Project under Grant 2015pyA006, and in part by the Science and Technology Project of Guangzhou under Grant 201604010099, Grant 2016B030306002, and Grant 2016B030308001."
  },
  {
    "year": "2017",
    "abstract": "A reconfigurable full-metal-rimmed MIMO antenna is designed and proposed for WWAN/LTE smartphones. This antenna consists of two centro-symmetrically distributed antenna elements and radiation structures using the unbroken metal rim in plastic casing. It can achieve a good isolation of more than 17dB over the entire operation bands. Each antenna element occupies a small ground area of 30 × 6 mm2. The U-shaped feeding line provides a coupled feed and the antenna element generates four typical loop resonant modes. Using reconfigurable technique to combine these four resonant modes, this hepta-band MIMO antenna can satisfactory cover lower bands of GSM850/900 and higher bands of GSM1800/1900/ UMTS/LTE2300/2500. A prototype MIMO antenna was fabricated and the measured results of S-parameters, antenna efficiency and gain, envelope correlation coefficient, mean effective gain, and channel capacity are reported."
  },
  {
    "year": "2017",
    "abstract": "This paper explores the feasibility of wireless energy harvesting by direct voltage multiplication on lateral waves. Whilst free space is undoubtedly a known medium for wireless energy harvesting, space waves are too attenuated to support realistic transmission of wireless energy. A layer of thin stratified dielectric material suspended in mid-air can form a substantially less attenuated pathway, which efficiently supports propagation of wireless energy in the form of lateral waves. The conductivity of the suspended dielectric layer does not appear to be a critical factor rendering propagation of lateral waves impossible. In this paper, a mathematical model has been developed to simulate wireless energy harvesting over a suspended layer of stratified dielectric material. The model has been experimentally verified with the help of a novel open-ended voltage multiplier designed to harvest energy from ambient electromagnetic fields."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a region-based relaxed multiple kernel collaborative representation method for the spatial-spectral classification of hyperspectral images. The proposed method consists of three steps. In the first step, a multiscale method achieved by extending a superpixel segmentation algorithm is designed to capture the spatial-spectral information of hyperspectral images. For each scale, a hyperspectral image can be segmented into several nonoverlapping spectrally similar regions that consist of some spatially adjacent pixels. In the second step, two criteria (i.e., the first two moments) are computed within the regions of each scale to generate the corresponding spatial features. In the final step, a relaxed multiple kernel technique is proposed to fuse the obtained spatial multiscale features and original spectral features in the framework of column generation kernel collaborative representation classification. Experimental results obtained from two real hyperspectral images demonstrate the effectiveness of the proposed method as compared with some popular spatial-spectral techniques."
  },
  {
    "year": "2017",
    "abstract": "The dc motor is one of the most fundamental electromechanical devices of mechatronic systems, which plays an important role in maintaining the accuracy in the execution of tasks. One of the main issues in the accuracy and robustness of dc motor control system is how to optimally tune its parameters. In this paper, a multi-objective online tuning optimization approach is proposed to adaptively tune up the velocity control parameters of the permanent magnet dc motor. This approach simultaneously considers the modeled error and the corresponding sensitivity to choose the best compromise solution in the Pareto dominance-based selection process of solutions to deal the changing optimum solutions in the dynamic environment of the tuning approach based on online optimization method and moreover, the modified differential evolution with induced initial population based on non-dominated solution through a memory is proposed to guide the search into the feasible region, and to promote the exploitation of solutions found in the previous time interval. Simulation results verify that proposed modifications provide higher robustness and better quality in the velocity regulation control of the dc motor under parametric uncertainties, and also under discontinuous dynamic load, than multi-objective differential evolution, particle swarm optimization, and non-dominated sorting genetic algorithm-II."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the hybrid spatial modulation (SM) aided virtual multiple-input multiple-output one-way and two-way relaying architectures with multiple distributed single-antenna relay nodes are studied. For the one-way relaying with multiple-antenna source and destination nodes, a two-stage relay detector is proposed. In the proposed detector, first, the relay node determines its state, active or silent, through the energy-based threshold detection; second, the signal is estimated and forwarded only when the relay node is active. Furthermore, the threshold is designed based on a simplified error probability criterion. For the two-way relaying with two multiple-antenna source nodes, a two-phase relaying based on signal constellation rotation and simple XOR network coding (NC) is presented. First, both source nodes transmit pre-coding-aided SM symbols simultaneously to relay nodes. Second, the relay nodes estimate the source signals, perform XOR NC, and broadcast the relay signal to both source nodes through the distributed SM. To improve the detection performance of relay nodes, the signal constellation used at one source node is a rotated version of that at the other source node, and the optimization of the rotation angle is presented. Finally, the validity of both the proposed detector for one-way relaying and the proposed relay protocol for two-way relaying is justified by simulation results."
  },
  {
    "year": "2017",
    "abstract": "In the Internet of Things scene, the wireless sensor network (WSN) is widely used to monitor and perceive various context environments. The efficient utilization of time division multiple access (TDMA) slot resource has attracted more and more attention, especially for applications with high network performance requirements, for example, vehicular networks. The characteristics of the WSN, which have limited battery volume and variable topology structure, restrict the development of the centralized time slot allocation algorithm. Moreover, the traditional distributed time slot allocation algorithm is helpless to reduce the energy consumption, even if the variable topology is solved to some extent. In this paper, we propose the distributed TDMA scheduling algorithm based on exponential backoff rule and energy-topology factor, namely EB-ET-distributed randomized (DRAND) algorithm. We analyze the typical DRAND time slot assignment algorithm and the distributed TDMA slot scheduling algorithm based on energy-topology factor, which is proposed in our another work. By introducing the idea of Lamport's bakery algorithm, the priority control algorithm based on exponential backoff rules and energy-topology factor are presented to appropriately adjust the priority of time slot allocation and greatly reduce the probabilities of message collision and time slot allocation failure. Then, we introduce the implementation processes of the EB-ET-DRAND scheduling algorithm in various different states. The time slot structure and frame formats of algorithm are designed in detail. Finally, we implement a mesh network simulation system to evaluate the performance of proposed scheme. The experimental results indicate that the EB-ET-DRAND scheduling algorithm greatly improves the performance of time slot allocation and reduces the message complexity, time complexity, and energy consumption."
  },
  {
    "year": "2017",
    "abstract": "Identity-based signature (IBS) which is a paradigm built on public key cryptography has played a significant role in light-weight authentication. With the advent of the post quantum era, the lattice has become a main mathematical tool to construct quantum-immune cryptographic schemes. By utilizing an admissible hash function with compatible algorithms and lattice trapdoors as basic building blocks, we propose a new IBS scheme over lattices. The scheme is proved existentially unforgeable against adaptive identity attacks and chosen message attacks in the standard model under inhomogeneous short integer solution assumption via the generalized partitioning proof technique. Moreover, the scheme needs only logarithmic basic matrices as master public key while keeping the same private key size and signature size as those of other standard model lattice-based IBS schemes. This construction is the first adaptive-ID secure standard model IBS scheme over lattice with such space efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the problem of two-dimensional (2-D) direction-of-arrival (DOA) estimation for incoherently distributed (ID) noncircular sources is addressed. A low-complexity estimator with automatic pairing in the three-parallel uniform linear arrays (ULAs) is proposed. First, the signal non-circularity is applied to establish an extended generalized array manifold (GAM) model based on one-order Taylor series approximation. Resorting to such model, the generalized rotational invariance relationships are identified among the extended GAM matrices of the three ULAs. Thereafter, a modified propagator method is utilized to estimate the central elevation and azimuth DOAs. Without any spectrum searching, estimation or eigenvalue decomposition of the sample covariance matrix, the proposed approach is capable of considerably reducing the calculation cost in comparison with the existing methods. In addition, it can automatically pair the estimated central azimuth and central elevation DOAs. We also derive the Cramer-Rao lower bound regarding the 2-D DOA estimation of the ID noncircular source and conduct the computational complexity analysis. Numerical results demonstrate that the proposed method achieves better estimation performance than the existing methods. Furthermore, it can be applied in the multi-source scenario where different sources may have different angular distribution shapes."
  },
  {
    "year": "2017",
    "abstract": "Several well-known international cooperation programs in the research field of air traffic management, e.g., SESAR and NextGen, aim to overcome the deficiencies of airspace capacity, while ensuring safety level and efficient operations. The increasing airspace traffic density would cause congested traffic scenarios, which require the developed safety procedures to resolve multithreat conflicts. In this paper, we provide a complete survey on the conflict detection and resolution approaches (CDR), mainly including long term CDR, medium term CDR, and short term CDR on three different levels classified based on the acting period. In order to achieve absolute security, it is very important to conduct a summarization of previous and present study on the traffic alert and collision avoidance system (TCAS), utilized as the final means in the security technology system. This review not only offers an intuitionistic and in-depth comprehension of the potential collision emergence for risk assessment, but also summarizes the various encounter models for the TCAS analysis and different strategies for the TCAS improvement, making an overall perspective of the research progresses and trends to facilitate the development."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we introduce a novel method for reconstructing roller bearings vibration signals. As well as the sparse reconstruction algorithm, our approach is based on the Lasso via the alternate direction multiplier method (ADMM) and optimized by least square QR-factorization (LSQR), which takes the priority over the Basis Pursuit and Lasso in iterations and errors. First, we use the discrete cosine transformation to achieve sparse signals, then we compress signals by using the Gaussian random matrix, and, finally, we reconstruct the original signals with the Lasso-LSQR by using the ADMM. According to the results, vibration signals can keep sufficient reconstruction accuracy with high compressive ratio, which validates the effectiveness of the method for vibration signals."
  },
  {
    "year": "2017",
    "abstract": "Visual navigation for mobile robots has emerged in recent years. Among the various methods, topological navigation using visual information provides a scalable map representation for large-scale mapping and navigation. A topological map is essentially a graph with keyframes as its nodes and adjacency relations as its edges. Previous topological mapping uses local feature descriptors, such as scale-invariant feature transform or Speeded-Up Robust Features, to select keyframes in mapping, localization, and estimate relative pose. In practice, local features are not robust for severe motion blur or large illumination change. In this paper, we improve topological mapping to make it more efficient and robust. First, we use a convolutional neural network (CNN) feature as the holistic image representation. The CNN feature can be used to effectively retrieve keyframes that have similar appearance from a topological map, and it is robust to motion blur and illumination change. Thus, it improves the performance for place recognition and robot relocalization. Second, we use sharpness measure to select high-quality keyframes and avoid selecting blurry ones. Third, an efficient and robust non-rigid matching method, vector field consensus, is used for efficient geometric verification and to retrieve the most similar keyframe. The qualitative and quantitative experimental results demonstrate that our method is satisfactory."
  },
  {
    "year": "2017",
    "abstract": "Advanced persistent threats (APTs) pose a grave threat to cyberspace, because they deactivate all the conventional cyber defense mechanisms. This paper addresses the issue of evaluating the security of the cyber networks under APTs. For this purpose, a dynamic model capturing the APT-based cyber-attack-defense processes is proposed. Theoretical analysis shows that this model admits a globally stable equilibrium. On this basis, a new security metric known as the equilibrium security is suggested. The impact of several factors on the equilibrium security is revealed through theoretical analysis or computer simulation. These findings contribute to the development of feasible security solutions against APTs."
  },
  {
    "year": "2017",
    "abstract": "Object tracking suffers from appearance change of the target caused by heavy occlusion. In this paper, we propose a complex form of local orientation plane (Comp-LOP) for visual object tracking. CompLOP is a simple but an effective descriptor for object tracking, which is robust to occlusion. It effectively considers the spatiotemporal relationship between the target and its surrounding region in a correlation filter framework by the complex form, which successfully deals with the heavy occlusion problem. Moreover, we perform scale estimation to treat scale variation of the target for better tracking performance. Besides, we automatically determine an appropriate size of the search region based on the entropy ratio of the target to the background. Experimental results demonstrate that the proposed method achieves good object tracking performance in accuracy, robustness, and computational efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel frequency-hopping sequence with lower probability of detection is proposed for covert communication systems. By formulating and solving a constrained optimization problem, a probability vector aiming for covert communication is obtained in the presence of interference. The proposed frequency-hopping sequence chooses channels based on the probabilities, which can achieve the lowest probability of detection under a prescribed bit error rate. Moreover, by using an 1-2 norm constraint in the optimization problem, the maximum Hamming autocorrelation of the proposed frequency-hopping sequence is studied. We also discuss the relationship between the 1-2 norm constraint and the bounds on the maximum Hamming autocorrelation. Simulation results verify the performance of the proposed frequency-hopping sequence."
  },
  {
    "year": "2017",
    "abstract": "The concept of index modulation (IM) has gained increased attention in recent years. As a member of the IM family, orthogonal frequency division multiplexing with index modulation (OFDM-IM), which is able to convey additional information bits using the indices of the active subcarriers, has emerged as an attractive physical layer transmission technique. Vector OFDM (V-OFDM) has inherently good peakto-average-power ratio (PAPR) feature and good bit error rate (BER) performance due to the nearly full diversity gains achieved by most of its sub-blocks. In this paper, in order to improve the BER performance of OFDM-IM and reduce the PAPR of the transmit signal, we propose an enhanced OFDM-IM scheme termed vector OFDM with index modulation (V-OFDM-IM). In addition to the structure of the transceiver, a complexity reduced maximum likelihood detector is presented. To further reduce the detection complexity, a near-optimal detector based on sequential Monte Carlo technique is introduced. The average bit error probability of the proposed scheme is derived in closed form over frequency-selective block Rayleigh-fading channel. Both the theoretical and the simulation-based results show that, under the same spectrum efficiency, V-OFDM-IM outperforms the conventional OFDM-IM and OFDM."
  },
  {
    "year": "2017",
    "abstract": "Cognitive radios that are able to operate across multiple standards depending on environmental conditions and spectral requirements are becoming more important as the demand for higher bandwidth and efficient spectrum use increases. Traditional custom ASIC implementations cannot support such flexibility, with standards changing at a faster pace, while software implementations of baseband communication fail to achieve performance and latency requirements. Field programmable gate arrays (FPGAs) offer a hardware platform that combines flexibility, performance, and efficiency, and hence, they have become a key in meeting the requirements for flexible standards-based cognitive radio implementations. This paper proposes a dynamically reconfigurable end-to-end transceiver baseband that can switch between three popular OFDM standards, IEEE 802.11, IEEE 802.16, and IEEE 802.22, operating in non-contiguous fashion with rapid switching. We show that combining FPGA partial reconfiguration with parameterized modules offers a reduction in reconfiguration time of 71% and an FIFO size reduction of 25% compared with the conventional approaches and provides the ability to buffer data during reconfiguration to prevent link interruption. The baseband exposes a simple interface which maximizes compatibility with different cognitive engine implementations."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel LQ-based generalized side-information cancellation (GSIC) precoder for multiuser multi-input multi-output (MU-MIMO) downlink systems with sum-rate performance enhancement. The proposed transceiver comprises the following stages. First, a unitary transform matrix designed through the LQ decomposition of the MU-MIMO channel is proposed for suppressing MU interference and obtaining the low-triangular MU-MIMO channel effect for each receiving user. A subchannel matrix with a nontriangular channel causes interference from other users to degrade the reception performance for each user. To overcome this problem, we propose a novel cancellation matrix for suppressing nontriangular MU-MIMO channel and composite noise effects. The proposed LQ-based precoder scheme, which is coupled with unitary transformation and cancellation matrices, can be extended for use with multiple users. The LQ-based GSIC precoder for two users can be realized and extended to three or more users by adopting a cascaded structure. The closed-form solution of the proposed LQ-based GSIC precoder is derived using a constraint-based optimization algorithm. Furthermore, suboptimum solutions show that the performance of the proposed GSIC precoder is almost equal to that of the optimum solutions, and that the precoder also has low complexity. Simulation results show that the proposed LQ-based GSIC precoder outperforms conventional precoders and exhibits reliable and excellent sum-rate performance."
  },
  {
    "year": "2017",
    "abstract": "The communication needs of the different stages of production proposed in the new industrial generation (INDUSTRY 4.0), demand devices that can handle high availability protocols. This paper presents an architecture of a cyber physical production system gateway that can be implemented in an SoC, integrating high availability communication interfaces as the high-availability seamless redundancy/ parallel redundancy protocol (HSR/PRP), industrial ethernet communication interfaces (e.g. Profinet), and connections to sensors and actuators (e.g. Modbus series). Considering the software and hardware adaptability that the architecture should have, field programmable gate array and reconfigurable devices, in general, are considered as the best options for implementation, since the architecture requires high levels of hardware and software flexibility. The proposed architecture was validated in an experimental environment that is implemented utilizing electronic design automation tools, IP cores, and Python libraries developed by third parties is presented, to achieve a device which handles high availability communication HSR/PRP, Profinet, Profibus, and Modbus."
  },
  {
    "year": "2017",
    "abstract": "Dual-mode index modulation aided orthogonal frequency division multiplexing (DM-OFDM) is recently proposed, which modulates all subcarriers to eliminate the limits of spectrum efficiency (SE) in OFDM with index modulation (OFDM-IM). In DM-OFDM, the subcarriers within each subblock are divided into two groups, which are modulated by two distinguishable constellation alphabets drawn from the inner and the outer constellation points of a given M-ary QAM constellation. In this paper, a new DM-OFDM scheme, called DM-OFDM with constellation power allocation (DM-OFDM-CPA) is proposed, where the two groups of subcarriers within each subblock are set at different power levels and modulated by different M-ary PSK symbols, leading to the improvement of the system performance at low-order modulation. At the receiver, a low-complexity maximum likelihood (LC-ML) detector and two reduced search complexity detectors, based on energy detection and log-likelihood ratio (LLR) criterion, respectively, are employed for demodulation. Then, the bit error rate (BER) analyses based on pairwise error probability are provided for the proposed DM-OFDM-CPA, and the power ratio between the two groups is optimized to maximize achievable BER performance for a given signal to noise ratio. The simulation results confirm that at a given SE, the proposed DM-OFDM-CPA achieves a significantly better BER performance than the existing OFDM-IM. When the modulation order is lower than 16, it outperforms the classic DM-OFDM. The results also show that two reduced search complexity detectors, especially the LLR detector, provide similar performance to the LC-ML detector in the DM-OFDM-CPA."
  },
  {
    "year": "2017",
    "abstract": "Data mining and analytics have played an important role in knowledge discovery and decision making/supports in the process industry over the past several decades. As a computational engine to data mining and analytics, machine learning serves as basic tools for information extraction, data pattern recognition and predictions. From the perspective of machine learning, this paper provides a review on existing data mining and analytics applications in the process industry over the past several decades. The state-of-the-art of data mining and analytics are reviewed through eight unsupervised learning and ten supervised learning algorithms, as well as the application status of semi-supervised learning algorithms. Several perspectives are highlighted and discussed for future researches on data mining and analytics in the process industry."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things envisions a multitude of heterogeneous objects and interactions with physical environments. It has provided a promising opportunity to build powerful services and applications by leveraging the growing ubiquity of smart objects connected to the Internet. In this environment, it is challenging to locate desirable services due to the considerable diversity, large scale, dynamic behavior, and geographical distribution of the services provided by physical objects. In this paper, we propose a decentralized semantics-based service discovery framework, which can effectively locate trustworthy services based on requester's quality of service demands and changing context requirements. The proposed service discovery system is built upon fully distributed peer-to-peer architectures and includes two discovery approaches which are scalable, robust, and trust assured. Moreover, an efficient trust propagation mechanism is proposed, which seamlessly integrates with the proposed service discovery system without adding additional infrastructure overhead. Comprehensive simulation studies have demonstrated the effectiveness of the proposed framework."
  },
  {
    "year": "2017",
    "abstract": "A concurrent dual-band low-noise amplifier (LNA) targeted for W-LAN IEEE 802.11 a/b/g standards is designed using 0.13-μm CMOS process. To attain the power-constrained simultaneous noise and input matching at 2.4 and 5.2 GHz, cascode common source inductive degeneration topology is adopted. The LNA achieves input reflection coefficients of -16.8 and -19.4 dB, forward gains of 19.3 and 17.5 dB at 2.4 and 5.2 GHz, respectively. Furthermore, the LNA exhibits noise figures of 3.2 and 3.3 dB with input 1-dB compression points of -29.6 and -28.2 dBm, while third-order input intercept points of -20.1 and -18.1 dBm at 2.4 and 5.2 GHz, respectively. The LNA dissipates 2.4 mW of power from a 1.2-V supply."
  },
  {
    "year": "2017",
    "abstract": "The use of a graphics processing unit (GPU) together with a CPU, referred as GPU-accelerated computing, to accelerate tasks that requires extensive computations has been the trends for last a few years in high performance computing. In this paper, we propose a new paradigm of GPU-accelerated method to parallelize extraction of a set of features based on the gray-level co-occurrence matrix (GLCM), which may be the most widely, used method. The method is evaluated on various GPU devices and compared with its serial counterpart implemented and optimized in both Matlab and C on a single machine. A series of experimental tests focused on magnetic resonance (MR) brain images demonstrate that the proposed method is very efficient and superior to its serial counterpart, as it could achieve more than 25-105 folds of speedup for single precision and more than 15-85 folds of speedup for double precision on Geforce GTX 1080 along different size of ROIs."
  },
  {
    "year": "2017",
    "abstract": "Efficient and accurate state estimation is essential for the optimal management of the future smart grid. However, to meet the requirements of deploying the future grid at a large scale, the state estimation algorithm must be able to accomplish two major tasks: 1) combining measurement data with different qualities to attain an optimal state estimate and 2) dealing with the large number of measurement data rendered by meter devices. To address these two tasks, we first propose a practical solution using a very short word length to represent a partial measurement of the system state in the meter device to reduce the amount of data. We then develop a unified probabilistic framework based on a Bayesian belief inference to incorporate measurements of different qualities to obtain an optimal state estimate. Simulation results demonstrate that the proposed scheme significantly outperforms other linear estimators in different test scenarios. These findings indicate that the proposed scheme not only has the ability to integrate data with different qualities but can also decrease the amount of data that needs to be transmitted and processed."
  },
  {
    "year": "2017",
    "abstract": "Generally, the probability density function (PDF) of orthogonal frequency division multiplexing (OFDM) signal amplitudes follow the Rayleigh distribution, thus, it is difficult to correctly predict the existence of impulsive noise (IN) in powerline communication (PLC) systems. Compressing and expanding the amplitudes of some of these OFDM signals, usually referred to as companding, is a peak-to-average power ratio reduction technique that distorts the amplitudes of OFDM signals towards a uniform distribution. We suggest its application in PLC systems, such as IEEE 1901 powerline standard (which uses OFDM) to reduce the impacts of IN. This is because the PLC channel picks up impulsive interference that the conventional OFDM driver cannot combat. We explore, therefore, five widely used companding schemes that convert the OFDM signal amplitude distribution to uniform distribution to avail the mitigation of IN in PLC system receivers by blanking, clipping and their hybrid (clipping-blanking). We also apply nonlinear optimization search to find the optimal mitigation thresholds and results show significant improvement in the output signal-to-noise ratio (SNR) for all companding transforms considered of up to 4 dB SNR gain. It follows that the conventional PDF leads to false IN detection, which diminishes the output SNR when any of the above three nonlinear memoryless mitigation schemes is applied."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the emerging wireless power transfer for machine type communication (MTC) network, where one hybrid access point (AP) with constant power supply communicates with a set of users (i.e., wearable devices and sensors) without power supply. The information and energy are transferred simultaneously in downlink direction. For MTC networks, most devices only receive several bits control data from AP in downlink transmission. So it is possible to utilize part of the received power to execute energy harvesting provided that the transmission reliability is guaranteed. Since we assume that all devices are without power supply or battery, the power of uplink transmission is entirely from energy harvesting. After converting electromagnetic wave to electricity, the devices are able to transmit their measured and collected data in uplink. Based on these considerations, a non-cooperative game model is formulated and a utility function involving both downlink decoding signal to noise ratio (SNR) and uplink throughput is established. The existence of Nash equilibrium (NE) in the formulated game model is proved. The uniqueness of NE is discussed and the expected NE is selected based on fairness equilibrium selection mechanism. The optimal splitting ratio within the feasible set, which maximizes the utility function, is obtained by an iterative function derived from this utility function. The numerical results show that in addition to ensuring the downlink decoding SNR and maximizing uplink throughput of an individual device, our proposed algorithm outperforms the conventional algorithm in terms of system performance."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency-division multiplexing (OFDM) with index modulation has been emerged as a promising technique for next-generation networks, where the specific activation pattern of the OFDM subcarriers is capable of conveying additional information implicitly without additional energy consumption, hence improving the system energy efficiency. In this paper, zero-padded tri-mode OFDM with index modulation (ZTM-OFDM-IM) is proposed, which is capable of achieving high spectral and energy efficiency. In ZTM-OFDM-IM, subcarriers are partitioned into subblocks. In each OFDM subblock, only a fraction of subcarriers are modulated by two distinguishable constellation alphabets, while the others remain empty, which reduces the energy consumption. With such an arrangement, extra information bits can be carried by the subcarrier activation pattern. At the receiver, a maximum-likelihood (ML) detector as well as a reduced-complexity two-stage log-likelihood ratio (LLR) detector are developed for signal demodulation. Theoretical performance analysis based on Euclidean distance metric and pairwise error probability are conducted. Besides, in order to attain better BER performance, the design strategies for the two distinguishable constellation alphabets are investigated, which is followed by brief discussions on generalization methods for the proposed ZTM-OFDM-IM. It is demonstrated via Monte Carlo simulations that ZTM-OFDM-IM is capable of enhancing the BER performance compared with the conventional OFDM and other conventional index-modulated OFDM benchmarks, which provides high-rate data transmission with low energy consumption. Moreover, the LLR detection of ZTM-OFDM-IM only suffers from slight performance loss in comparison with the ML detection and achieves significant complexity reduction."
  },
  {
    "year": "2017",
    "abstract": "Delineation of the cardiac right ventricle is essential in generating clinical measurements such as ejection fraction and stroke volume. Given manual segmentation on the first frame, one approach to segment right ventricle from all of the magnetic resonance images is to find point correspondence between the sequence of images. Finding the point correspondence with non-rigid transformation requires a deformable image registration algorithm, which often involves computationally expensive optimization. The central processing unit (CPU)-based implementation of point correspondence algorithm has been shown to be accurate in delineating organs from a sequence of images in recent studies. The purpose of this study is to develop computationally efficient approaches for deformable image registration. We propose a graphics processing unit (GPU) accelerated approach to improve the efficiency. The proposed approach consists of two parallelization components: Parallel compute unified device architecture (CUDA) version of the deformable registration algorithm; and the application of an image concatenation approach to further parallelize the algorithm. Three versions of the algorithm were implemented: 1) CPU; 2) GPU with only intra-image parallelization (sequential image registration); and 3) GPU with inter and intra-image parallelization (concatenated image registration). The proposed methods were evaluated over a data set of 16 subjects. CPU, GPU sequential image, and GPU concatenated image methods took an average of 113.13, 16.50, and 5.96 s to segment a sequence of 20 images, respectively. The proposed parallelization approach offered a computational performance improvement of around 19× in comparison to the CPU implementation while retaining the same level of segmentation accuracy. This paper demonstrated that the GPU computing could be utilized for improving the computational performance of a non-rigid image registration algorithm without compromising the accuracy."
  },
  {
    "year": "2017",
    "abstract": "Collaborative spectrum sensing (CSS) enables secondary users in cognitive radio networks to collaboratively explore spectrum holes as well as protecting the primary user from being interfered. Unfortunately, the emergence of spectrum sensing data falsification (SSDF) attack, also known as the Byzantine attack, brings significant threat to the reliability of the CSS. Majority of the existing studies on Byzantine defense can be divided into two categories: one is directly to make the judgment based on the current spectrum sensing data, while the other uses the historical spectrum sensing data to update sensors' reputation. The first category of studies does not take the historical spectrum sensing data into account, while most of the second category of studies are heuristic in nature. In this paper, we invoke Bayesian learning to design Byzantine defense schemes. First, we develop a Bayesian offline learning algorithm by considering one practical challenge that the ground-truth spectrum state is unavailable for training. Then, we develop a Bayesian online learning algorithm by considering the case that the sensors' attribute may be time-varying. In addition, we present simulations to show the performance of the proposed defence algorithms."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the transceiver optimization of full-duplex multiple-input multipleoutput decode-and-forward (DF) relaying by taking into account the practical factor of limited dynamic range (LDR). Focusing on the maximization of end-to-end achievable rate which involves highly coupled variables, we develop a convergent block coordinate ascent (BCA) algorithm to deal with the complicated optimization problem. In each iteration of BCA, the optimal source beamformer, relay receive beamformer, and destination receive beamformer all admit closed-form solutions. As for the optimization of relay transmit beamformer, we transform the corresponding non-convex maximin problem into a single second-order cone program problem which thus allows an efficient optimal solution. Simulations validate the remarkable performance gain attained by incorporating LDR into the full-duplex DF relaying transceiver optimization."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a design method for wireless power transmission systems in unknown electromagnetic environments. In a wireless power transmission system, several antenna elements are used for power transmitting and one antenna is utilized for power receiving. By measuring the scattering parameters (S-parameters) of the whole system, the power transmission capability of the system can be fully characterized. The maximum possible power transmission efficiency (PTE) can then be determined, and the corresponding excitations for the transmitting antenna elements can be obtained. By designing a feeding network that provides the required excitations to feed the transmitting antenna elements, the optimum power transmission can be achieved without identifying the properties of the unknown electromagnetic environments. Two design examples are presented to demonstrate the proposed method. The measured PTEs are close to the theoretical maximum possible values."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the hierarchical path following control of a fully submerged hydrofoil vessel (FSHV) in the presence of additive disturbances. Roll dynamics is particularly considered for planar path following in both kinematics and rigid-body dynamics. A coordinated turn aided line-of-sight (LOS) guidance methodology is proposed for the guidance system design. In this approach, an adaptive LOS guidance algorithm is presented to calculate the command course angle. An adaptive estimator is designed to estimate the sideslip angle caused by the drift forces of ocean currents. The command bank angle is calculated based on the dynamics of the cross-track error and the coordinated turn constraint, which highly improves the maneuverability of the FSHV. A robust integral of the sign of the error feedback control is proposed as the autopilot to cope with attitude tracking of the lateral dynamics. The cascade characteristics of the guidance system and the autopilot are discussed; uniform asymptotic stability of the overall closed-loop system is achieved via cascade system theory. Simulation results validate the effectiveness of the hierarchical control strategy, and disturbance attenuation can be guaranteed for the composite guidance and control of the FSHV."
  },
  {
    "year": "2017",
    "abstract": "With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shopfloor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively."
  },
  {
    "year": "2017",
    "abstract": "Clutter rejection is a key technique in digital radio Mondiale (DRM)-based HF passive bistatic radar, because the power of a target signal is many orders of magnitude weaker than the direct-path wave and multipath echoes. Many temporal approaches can be used to reject the multipath clutter. We proposed a novel approach which takes full advantage of characteristic of the transmitted waveform. DRM signal is based on the orthogonal frequency division multiplexing modulation technique. After the temporal signal model in subcarrier domain is analyzed, an approach using recursive least square adaptive filter is introduced to remove unwanted components on each effective subcarrier. It has low computational complexity. Simulation and experiment data verification are carried out, which proved the efficiency of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "How to model user distance from multiple social networks is an important challenge. People often simultaneously appear in multiple social networks that can provide complementary services. Thus, knowledge from different social networks can help overcome the data sparseness problem. However, the knowledge cannot be directly obtained due to that they are from different social networks. To solve this problem, we construct an adaptive model to learn user distance in multiple social networks via combining distance metric learning and boosting technologies. The basic idea of our model is to embed related social networks into a potential feature space, while retaining the topologies of social networks. To get the solution to our model, we formulate it as a convex optimization problem. Moreover, we propose an adaptive user distance measure algorithm whose time complexity is linear with the number of the links. We verify the feasibility and effectiveness of our model on the link prediction problem. Experiments on two real large-scale data sets demonstrate that our method outperforms the compared methods. To the best of our knowledge, the joint learning of metric learning with boosting is first studied in multiple social networks."
  },
  {
    "year": "2017",
    "abstract": "The privacy of users must be considered as the utmost priority in distributed networks. To protect the identities of users, attribute-based encryption (ABE) was presented by Sahai et al. ABE has been widely used in many scenarios, particularly in cloud computing. In this paper, public key encryption with equality test is concatenated with key-policy ABE (KP-ABE) to present KP-ABE with equality test (KP-ABEwET). The proposed scheme not only offers fine-grained authorization of ciphertexts but also protects the identities of users. In contrast to ABE with keyword search, KP-ABEwET can test whether the ciphertexts encrypted by different public keys contain the same information. Moreover, the authorization process of the presented scheme is more flexible than that of Ma et al.'s scheme. Furthermore, the proposed scheme achieves one-way against chosen-ciphertext attack based on the bilinear Diffie-Hellman (BDH) assumption. In addition, a new computational problem called the twin-decision BDH problem (tDBDH) is proposed in this paper. tDBDH is proved to be as hard as the decisional BDH problem. Finally, for the first time, the security model of authorization is provided, and the security of authorization based on the tDBDH assumption is proven in the random oracle model."
  },
  {
    "year": "2017",
    "abstract": "Damping strategies are cost-effective and easy-to-implement, and are used to mechanically load heaving wave energy converters (WECs) by utilizing the combination of a properly sized power takeoff (PTO) system and an accompanying control algorithm. Compared with reactive-based control strategies, damping strategies have lower energy throughput, but they can be effective for small WEC systems. To the best of our knowledge, damping strategies have been generally discussed either within the mechanical or the electrical framework. Therefore, this paper is an attempt to bridge the two directly interacting sides of the problem. Furthermore, the effect of the wave characteristics and the operating conditions of the PTO system on the power capturing performance of WECs is examined. A criterion to properly select the required damping, considering not only the hydrodynamic forces but also the limitations present in the PTO system, is proposed. The simulation and experimental results of the investigated system are provided and discussed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study the problem of node aggregation under different perspectives for increasing PageRank of some nodes of interest. PageRank is one of the parameters used by the search engine Google to determine the relevance of a web page. We focus our attention to the problem of finding the best nodes in the network from an aggregation viewpoint, i.e., what are the best nodes to merge with for the given nodes. This problem is studied from global and local perspectives. Approximations are proposed to reduce the computation burden and to overcome the limitations resulting from the lack of centralized information. Several examples are presented to illustrate the different approaches that we propose."
  },
  {
    "year": "2017",
    "abstract": "Simple and low cost tag antenna with long reading distance in various environments is in great demand with its wide applications. This paper describes the design and optimization procedure of a single-layer tag antenna, which covers relatively long reading range when mounted on both metallic surface and various dielectrics. The antenna is based on the loop structure, with a small ka of 0.66. Characteristic mode analysis is first performed to inspect how a typical loop structure radiates in free space and on PEC. Antenna structure is then designed based on the characteristics of the loop. Afterward, equivalent circuits of the tag antenna on dielectrics and on metal are extracted, in order to provide guidance for antenna optimization. The proposed tag antenna achieves the maximum reading distance of 6.1 m and 14.1 m, respectively, when mounted on metal and dielectrics with low permittivity. Measurements of the tag antenna were carried out in different environments, including outdoor scenario, indoor scenarios with low and high reflections. The measured results agree reasonably well with the predicted ones. The tag antenna is proved to be competitive in perspective of simple structure, low cost, long reading distance, and tolerance on various background materials."
  },
  {
    "year": "2017",
    "abstract": "Motivated by applications in wireless communications, in this paper we propose a reconstruction algorithm for sparse signals whose values are taken from a discrete set, using a limited number of noisy observations. Unlike conventional compressed sensing algorithms, the proposed approach incorporates knowledge of the discrete valued nature of the signal in the detection process. This is accomplished through the alternating direction method of the multipliers which is applied as a heuristic to decompose the associated maximum likelihood detection problem in order to find candidate solutions with a low computational complexity order. Numerical results in different scenarios show that the proposed algorithm is capable of achieving very competitive recovery error rates when compared with other existing suboptimal approaches."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we strive to construct an efficient multi-hop network based on the sub-GHz low-power wide-area technology. Specifically, we investigate the combination of LoRa, a physical-layer standard that can provide several-kilometer outdoor coverage, and concurrent transmission (CT), a recently proposed multi-hop protocol that can significantly improve the network efficiency. The main contributions of this paper are threefold. 1) Since the CT enhances the network efficiency by allowing synchronized packet collisions, the performance of the physical-layer receiver under such packet collisions needs to be carefully examined to ensure the network reliability. We first extensively evaluate the LoRa receiver performance under CT to verify that LoRa is compatible to CT. Specifically, we find that, due to the time-domain and frequency-domain energy spreading effect, LoRa is robust to the packet collisions resulting from CT. 2) We further find the receiver performance under CT can be further improved by introducing timing offsets between the relaying packets. In view of this, we propose a timing delay insertion method, the offset-CT method, that adds random timing delay before the packets while preventing the timing offset from diverging over the multi-hop network. 3) We conduct proof-of-concept experiments to demonstrate the feasibility of CT-based LoRa multi-hop network and the performance improvement brought by the proposed offset-CT method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the effect of nitride passivation layer on the irradiation response of PNP bipolar junction transistors (BJTs) by Co-60 gamma ray under high and low dose rates is investigated. In order to analyze the damage mechanisms on BJTs with or without nitride passivation layer induced by gamma rays, the excess base current and deep level transient spectroscopy are measured. Experimental results show that there is an enhanced low dose rate sensitivity for PNP transistors with and without nitride passivation layers. In addition, the degradation of PNP BJTs with nitride layer is more serious than that of PNP BJTs without nitride layer under the same irradiation condition. Compared with the PNP BJTS without nitride passivation layer, ionization effect in the PNP BJTs with nitride passivation layer can generate greater density of interface traps with deeper energy level at a given dose rate. Moreover, the irradiated BJTs under the low dose rate produces deeper energy level of interface traps than that under the high dose rate. Based on the analysis, hydrogen is an important factor influencing the dose rate sensitivity and the degradation of the BJT with nitride passivation layers."
  },
  {
    "year": "2017",
    "abstract": "Electro-hydraulic shake table (EHST) is vital seismic testing equipment in earthquake engineering for the assessment of structures subject to dynamic vibration excitations. The EHST system can be generally simplified as an electro-hydraulic servo system with prominent acceleration replication requirement. In order to improve the acceleration tracking performance of a typical EHST system, a novel realtime acceleration tracking strategy combining inverse compensation technique and neural-based adaptive controller is presented in this paper. The traditional three variable controller (TVC) is applied to the EHST system for obtaining a preliminary acceleration tracking accuracy in advance, and then the multi-innovation stochastic gradient algorithm is utilized to estimate the discrete parametric transfer function of the TVC controlled EHST system. Next, the zero magnitude error tracking technique, which is capable of handling non-minimum phase zeros, is exploited to design a stable and casual inverse model, and subsequently the parametric inverse compensation technique for the EHST system is constructed. Finally, a neural-based online adaptive controller is incorporated to the offline designed parametric inverse compensator as an outer loop, and the side effects of the system's inherent nonlinearities, varying dynamics, and external uncertainties are further addressed. The proposed controller is successfully implemented in the control system of a unidirectional EHST test rig using xPC target rapid prototyping technique, and experimental results reveal that a superior acceleration replication performance is achieved in contrast to the other comparative controllers."
  },
  {
    "year": "2017",
    "abstract": "Hybrid analog/digital precoding architectures are a low-complexity alternative for fully digital precoding in millimeter-wave (mmWave) MIMO wireless systems. This is motivated by the reduction in the number of radio frequency and mixed signal hardware components. Hybrid precoding involves a combination of analog and digital processing that enables both beamforming and spatial multiplexing gains in mmWave systems. This paper develops hybrid analog/digital precoding and combining designs for mmWave multiuser systems, based on the mean-squared error (MSE) criteria. In the first design with the analog combiners being determined at the users, the proposed hybrid minimum MSE (MMSE) precoder is realized by minimizing the sum-MSE of the data streams intended for the users. In the second design, both the hybrid precoder and combiners are jointly designed in an iterative manner to minimize a weighted sum-MSE cost function. By leveraging the sparse structure of mmWave channels, the MMSE precoding/combining design problems are then formulated as sparse reconstruction problems. An orthogonal matching pursuit-based algorithm is then developed to determine the MMSE precoder and combiners. Simulation results show the performance advantages of the proposed precoding/combining designs in various system settings."
  },
  {
    "year": "2017",
    "abstract": "Laser technology has observed a great advancement over the last few decades. This technology is used for a wide range of applications including medical sciences, military, industrial manufacturing, electronics, holography, spectroscopy, astronomy and much more. Military operations often demand a secure and timely transmission of a massive amount of information from one place to another. Until now, the military has relied on the radio spectrum for effective communication, which is vulnerable to security threats and susceptible to electromagnetic interference (EMI). Also, this spectrum is hard-pressed to meet the current bandwidth requirement for high-resolution images, on-air video conferencing and real-time data transfer. Therefore, the focus has shifted to visible and infrared spectrum using laser technology which is capable of providing secure data transfer because of its immunity to EMI. The probability of intercepting a laser signal is very low due to its narrow beam divergence and coherent optical beam, making the laser a suitable candidate for secure military tactical operations. Besides the communication aspect, the highly directive nature of a laser beam is also used as a directed energy laser weapon. These highly powerful and light weighted directed energy laser weapons are very cost-effective countermeasures for airborne threats. Furthermore, laser sensors are deployed in the battlefield or in space for tracking the path of a wide range of military vehicles like missiles, unmanned aerial vehicles, fighter aircraft, warships, submarines, and so on. Advancements in space operations and laser technology have offered synergistic possibilities of using lasers from space-based platforms during military operations. In this paper, we are providing our readers with a comprehensive study of laser applications, used by the military, to carry out tactical operations on the ground or space-based platforms. Also, an intensive investigation on the development of laser te..."
  },
  {
    "year": "2017",
    "abstract": "Existing machine-learning-based vehicle detection algorithms for intelligent vehicles have an obvious disadvantage in that the detection effect decreases dramatically when the distribution of training samples and the scene target samples do not match. To address this issue, a scene-adaptive vehicle detection algorithm based on a composite deep structure is proposed in this paper. Inspired by the Bagging (Bootstrap aggregating) mechanism, multiple relatively independent source samples are first used to build multiple classifiers and then voting is used to generate target training samples with confidence scores. The automatic feature extraction ability of deep convolutional neural network is then used to perform source-target scene feature similarity calculations with a deep auto-encoder in order to design a composite deep-structure-based scene-adaptive classifier and its training method. Experiments on the KITTI data set and a data set captured by our group demonstrate that the proposed method performs better than existing machine-learning-based vehicle detection methods. In addition, compared with existing scene-adaptive object detection methods, our method improves the detection rate by an average of approximately 3%."
  },
  {
    "year": "2017",
    "abstract": "At present, a hyperspectral image has a significant advantage in the aspect of application because of its high spectral resolution. However, owing to the limit of communication capacity, a hyperspectral image must be compressed. In this paper, we develop and propose a fractal lossy hyperspectral image compression method based on prediction. First, we exploit spatial correlation by applying predictive lossy compression to obtain a reference band of high quality. Then, the local similarity between the two adjacent bands is used through fractal encoding using a local search algorithm. Next, we encode the fractal parameters and the error and fractal residual is transformed by discrete cosine transform, quantized, and entropy encoded to improve the decoded quality. Through experiments, we demonstrate that the proposed algorithm leads to considerably improved performance in compression compared with the other well-known methods. Finally, we validate whether the compression affects the data in the hyperspectral images through classification. The results indicate that the accuracy of classification obtained for the reconstructed image is marginally less than the accuracy reported for the original data set; however, the loss in accuracy is less than 1% and thus acceptable."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel architecture for ternary content-addressable memory (TCAM), using G-AETCAM cells, which outputs the address of the provided input data. The proposed architecture is a matrix of G-AETCAM cells arranged in the form of rows and columns using flip-flop as a memory element and a control logic circuitry consisting of logic gates. One G-AETCAM cell encodes the input and stored bit into one encoded bit which results in a match-line after passing from the AND-gate-array. Many architectures configure random-access memory (RAM) available on FPGAs as content-addressable storage architecture but are efficient for specific size and deal with data only in ascending or descending order while the proposed architecture provides freedom in size with no chance of making a single memory cell as useless and can store ternary data in any order. RAM-based TCAMs require pre-processing for the storage of TCAM words while the proposed design does not involve any pre-processing. The proposed architecture reduces the transistor count by a factor of 25.55, as compared with the RAM-based TCAM, which ultimately reduces area and increases the speed of operations. The proposed architecture is successfully implemented on Xilinx Virtex-6 FPGA for the size 64 × 36 and achieves a speed of 358 MHz."
  },
  {
    "year": "2017",
    "abstract": "We present the detailed design and experimental demonstration of a low-sidelobe horn antenna based on controlling the amplitude and the phase distribution of the electromagnetic fields over the aperture of the horn antenna using a thin single-layer metasurface lens. The lens is composed of two identical subwavelength metallic square-ring arrays printed on the two sides of a single dielectric layer. By placing the metasurface lens inside a standard pyramidal horn, the electromagnetic fields over the horn aperture can be manipulated, resulting in low sidelobe radiation in both E- and H-planes. Both simulated and measured results demonstrate the tapered field distribution over the horn aperture and the significant reduction of sidelobes in the E-plane as well as the reduction of the backlobes."
  },
  {
    "year": "2017",
    "abstract": "The localization for sources in the heterogeneous and complex media is of vital significance, which can be applied to monitor the invisible cracks and determine the potential damage areas of buildings with safety hazards. Based on the localization function with the model of arrival time difference (TD), a multi-step localization method (MLM) without premeasured velocity for heterogeneous and complex propagation media was proposed. The velocity interval used for localization was narrowed and optimized continuously through the multi-step localization, where the optimal velocity interval was determined when the velocity differences were less than the threshold. Then, the optimal localization results with higher accuracy corresponding to this velocity interval can be obtained with the TD algorithm. A source locating test was performed at a building of masonry structure. In addition, the locating accuracy was compared and discussed between the optimized MLM, the one-step method without premeasured velocity, and the traditional method with different premeasured velocity values. Results show that MLM is obviously superior to both the one-step method and the traditional method. The developed MLM can not only eliminate the errors caused by premeasured velocity, but also can improve the locating accuracy in the heterogeneous and complex media, which is an efficient and effective method for engineering applications."
  },
  {
    "year": "2017",
    "abstract": "To deal with the explosive traffic demands on the overloaded cellular network, device-to-device (D2D) offloading is proposed to transmit the traffic originally delivered through cellular network by D2D communications. Current D2D offloading schemes are based on direct transmissions or simple relay-assisted transmissions, which is hard to achieve high throughput. Network coding can effectively solve the problem. However, two problems must be addressed, topology formation and resource allocation. We formulate the topology formation problem as a function on network throughput under transmission pair matching and relay selection. we adopt coalition game theory to jointly match devices to form transmission pairs and select relay to form topology. Moreover, we propose a greedy algorithm to allocate the limited spectrum resource for each transmitter to decrease the interference influence. We evaluate our proposed offloading scheme through extensive evaluations under different network environments. The result shows that our scheme can effectively improve the network throughput and enhance the offloading efficiency."
  },
  {
    "year": "2017",
    "abstract": "Provides a listing of current committee members and society officers."
  },
  {
    "year": "2017",
    "abstract": "Today's mobile phone users are faced with large numbers of notifications on social media, ranging from new followers on Twitter and emails to messages received from WhatsApp and Facebook. These digital alerts continuously disrupt activities through instant calls for attention. This paper examines closely the way everyday users interact with notifications and their impact on users' emotion. Fifty users were recruited to download our application NotiMind and use it over a five-week period. Users' phones collected thousands of social and system notifications along with affect data collected via self-reported Positive and Negative Affect Schedule tests three times a day. Results showed a noticeable correlation between positive affective measures and keyboard activities. When large numbers of post and remove notifications occur, a corresponding increase in negative affective measures is detected. Our predictive model has achieved a good accuracy level using three different \"in the wild\" classifiers (F-measure 74%-78% within-subject model, 72%-76% global model). Our findings show that it is possible to automatically predict when people are experiencing positive, neutral, or negative affective states based on interactions with notifications. We also show how our findings open the door to a wide range of applications in relation to emotion awareness on social and mobile communication."
  },
  {
    "year": "2017",
    "abstract": "Recently, avionics systems have evolved into a time and space partitioning (TSP)-based integrated modular avionics (IMA) structure for integration into a single system from a variety of existing independently configured federated systems. The TSP-based IMA architecture is suitable for solving size, weight, and power problems in avionics systems. Partitioning real-time operating systems (RTOSs) to support TSP-based IMA have been researched, and the international aviation industry has established the ARINC 653 standard for a partitioning RTOS. The ARINC 653 standard has defined the health monitoring (HM) function for debugging. However, the HM of the ARINC 653 standard does not support monitoring and debugging functions, such as snapshot, cycle, and, redundancy monitor, which makes the system development hard. To this end, the purpose of this paper is to introduce a monitoring framework that supports high reliability and stability for RTOS and application software based on TSP structure used in avionics systems. The proposed monitoring framework is designed for Qplus-AIR, an RTOS based on the TSP structure that conforms to the ARINC 653 for aircraft systems. It is also applicable to other RTOSs based on TSP structure that does not conform to ARINC 653. It supports monitoring functions, such as snapshot, trigger, and cycle as well as various debugging functions. It also supports debugging and monitoring operations under the redundancy of avionics systems, and minimizes the intrusive effect, which is a disadvantage of the software-based debugging approach. These functionalities enable avionics system developers to monitor and measure the performance of TSP structure-based RTOS and application software in flight control system for unmanned aerial vehicles. Our evaluation results show that the proposed monitoring framework is suitable for monitoring and debugging of RTOS and application software based on TSP structure."
  },
  {
    "year": "2017",
    "abstract": "A compact and wideband ultra-high-frequency antenna is developed in this paper. By applying the Minkowski fractal geometry into both the lateral boundaries of monopole and the upper boundary of ground plane and loading the asymmetric strips at the top of monopole simultaneously, the miniaturization is realized; by means of adjusting the fractal direction to produce a complementary structure and cutting the triangular notch on the ground plane, the impedance bandwidth is enhanced. The influences of critical parameters on the impedance bandwidth are determined through the sensitivity analysis. Furthermore, to validate the performance of the proposed antenna, the return loss, radiation patterns, transfer function, and fidelity factors are measured; the electrical dimension and ratio bandwidth are compared with those of the existing antennas. It shows that the antenna with size of 0.28λL× 0.28λLcan cover the frequency ranging from 700 MHz to 4.71 GHz and has an average gain of 3.93 dBi along with strong pulse handling capability. The results demonstrate the superiority of the complementary fractal technique."
  },
  {
    "year": "2017",
    "abstract": "Handwritten signature recognition is a biometric mode that has started to be deployed. Therefore, it is necessary to analyze the robustness of the recognition process against presentation attacks, to find its vulnerabilities. Using the results of a previous work, the vulnerabilities are detected and two presentation attack detection techniques have been implemented. With such implementations, a new evaluation has been performed, showing an improvement in the performance. Error rates have been lowered from about 20% to below 3% under operational conditions."
  },
  {
    "year": "2017",
    "abstract": "When investing in the stock market, the first problem and one of paramount importance which investors have to face is making the proper stock selection. Selecting the stocks that simultaneously offer high return and low risk is a difficult problem that is worth investigating. However, the traditional risk calculation based on the modern portfolio theory (MPT) of portfolios has some defects. The MPT method requires the calculations of every relationship between each pair of stocks in the portfolio, entailing high computation complexity, which grows exponentially with the increased number of stocks. Besides, the traditional calculation is unable to calculate the coefficient of variation, and merely considers the relationship between each pair of stocks, so it cannot accurately assess portfolio risk. Therefore, this paper proposes a novel method, funds standardization, and utilizes it to represent the portfolio return and calculate portfolio risk. The fluctuation of portfolio funds standardization shows not only the relationships between each pair of stocks, but also the interactions among all stocks. Hence, utilizing funds standardization can accurately assess portfolio risk and completely represent the mood swings of investors. Compared with the traditional method, the proposed method significantly reduces the computation complexity because the complexity does not increase when the portfolios stock number increases. We combine the genetic algorithm, Sharpe ratio and funds standardization to find the optimal portfolio. In addition, we utilize the sliding window to avoid the over-fitting problem, which is common in this field, and test the effect of all kinds of training and testing periods. The experimental results show that the portfolio can spread the risk effectively, and that the portfolio risk can be assessed accurately by utilizing the funds standardization. Comparing with the traditional method, our method can identify the optimal portfolio efficiently and esta..."
  },
  {
    "year": "2017",
    "abstract": "A microfluidically frequency-reconfigurable microstrip patch antenna and an array are proposed in this paper. The reconfiguration performance is realized to be frequency-hopping by inserting polypropylene tubes, which act as microfluidic controllers selectively filled with deionized (DI) water between the patch and ground plane. It is a low-cost and environment-friendly choice for frequency-reconfigurable microwave devices and low profile patch antennas. Remarkably, controllability of the frequency-hopping range, number of hopping frequencies and hopping states in the proposed design can be obtained by adjusting the locations and numbers of the tube. With this feature, the hopping range of the operating frequency can be effectively enlarged using as few tubes as possible through choosing appropriate positions for adding the tubes. To verify the proposed concepts, the experimental prototypes of a patch antenna and an array are designed, fabricated and measured, and the simulated and measured results are presented, showcasing good agreement."
  },
  {
    "year": "2017",
    "abstract": "Fog computing (FC) is currently receiving a great deal of focused attention. FC can be viewed as an extension of cloud computing that services the edges of networks. A cooperative relationship among applications to collect data in a city is a fundamental research topic in FC. When considering the green cloud, people or vehicles with smart-sensor devices can be viewed as users in FC and can forward sensing data to the data center. In a traditional sensing process, rewards are paid according to the distances between the users and the platform, which can be seen as the existing solution. Because users with smart-sensing devices tend to participate in tasks with high rewards, the number of users in suburban regions is smaller, and data collection is sparse and cannot satisfy the demands of the tasks. However, there are many users in urban regions, which makes data collection costly and of low quality. In this paper, a cooperative-based model for smartphone tasks, named a cooperative-based model for smart-sensing tasks (CMST), is proposed to promote the quality of data collection in FC networks. In the CMST scheme, we develop an allocation method focused on improving the rewards in suburban regions. The rewards to each user with a smart sensor are distributed according to the region density. Moreover, for each task there is a cooperative relationship among the users; they cooperate with one another to reach the volume of data that the platform requires. Extensive experiments show that our scheme improves the overall data-coverage factor by 14.997% to 31.46%, and the platform cost can be reduced by 35.882%."
  },
  {
    "year": "2017",
    "abstract": "Retrieval of TV talk-show speakers based on solely visual face recognition is hard because of the significant visual variation caused by illumination, pose, size, and expression, which can exceed those due to identity. Fortunately, TV talk-shows often exhibit specific visual production styles and are accompanied with other modalities, such as audio transcript. Hence, this paper presents a speaker retrieval framework which associates the who and when information provided by the audio transcript to a set of visual clusters. First, to obtain the visual clusters, an unsupervised speaker identity clustering strategy is proposed, by which the same speakers are grouped together but without knowing who exactly he/she is. Then, to further identify the specific speaker for each group, we propose an association strategy, by which the search are initially limited to those corresponding to when the queried speaker speaking, followed by a graph-based densest sub-graph refinement. Comprehensive experiments on 3 h French TV talk-show “Le Grand Echiquier” provided by K-space project show satisfactory results. Moreover, evaluation of the proposed association strategy on more challenging MediaEval 2015 task with just the provided speaker diarization module and face tracking module could provide state-of-the-art performances, demonstrating the effect of the proposed association strategy."
  },
  {
    "year": "2017",
    "abstract": "Due to the centralized control, network-wide monitoring and flow-level scheduling of software-defined-networking (SDN), it can be utilized to achieve quality of service (QoS) for cloud applications and services, such as voice over IP, video conference, and online games. However, most existing approaches stay at the QoS framework design and test level, while few works focus on studying the basic QoS techniques supported by SDN. In this paper, we enable SDN with QoS guaranteed abilities, which could provide end-to-end QoS routing for each cloud user service. First of all, we implement an application identification technique on SDN controller to determine required QoS levels for each application type. Then, we implement a queue scheduling technique on SDN switch. It queues the application flows into different queues and schedules the flows out of the queues with different priorities. At last, we evaluate the effectiveness of the proposed SDN-based QoS technique through both theoretical and experimental analysis. Theoretical analysis shows that our methods can provide differentiated services for the application flows mapped to different QoS levels. Experiment results show that when the output interface has sufficiently available bandwidth, the delay can be reduced by 28% on average. In addition, for the application flow with the highest priority, our methods can reduce 99.99% delay and increase 90.17% throughput on average when the output interface utilization approaches to the maximum bandwidth limitation."
  },
  {
    "year": "2017",
    "abstract": "The impact and productivity of researchers are assessed using bibliometric parameters, such as the number of publications and citation analysis. A number of indices exist that use these parameters, but almost all of them overlook citation pattern of the researchers, which results in assigning the same index value to the two different authors with different citation patterns. In this paper, a new index called DS-index is proposed, which differentiates among the authors having even a very small change in the citation pattern of their publications. It uniquely identifies the different index values and thus the proper ranking order for authors. The index is applied to the self-developed large DBLP data set having publication data of over 50 years. The results compared with the existing indices using the standard performance evaluation measures confirm that the proposed index performs better by ranking the authors in a distinctive order."
  },
  {
    "year": "2017",
    "abstract": "In the last years, Internet is evolving towards the cloud-computing paradigm complemented by fog-computing in order to distribute computing, storage, control, networking resources, and services close to end-user devices as much as possible, while sending heavy jobs to the remote cloud. When fog-computing nodes cannot be powered by the main electric grid, some environmental-friendly solutions, such as the use of solaror wind-based generators could be adopted. Their relatively unpredictable power output makes it necessary to include an energy storage system in order to provide power, when a peak of work occurs during periods of low-power generation. An optimized management of such an energy storage system in a green fog-computing node is necessary in order to improve the system performance, allowing the system to cope with high job arrival peaks even during low-power generation periods. In this perspective, this paper adopts reinforcement learning to choose a server activation policy that ensures the minimum job loss probability. A case study is presented to show how the proposed system works, and an extensive performance analysis of a fog-computing node highlights the importance of optimizing battery management according to the size of the Renewable-Energy Generator system and the number of available servers."
  },
  {
    "year": "2017",
    "abstract": "This paper develops a unified solution for time-difference-of-arrival (TDOA) localization in the presence of sensor position errors. This technique starts with maximum likelihood estimation (MLE), which is known to be nonconvex. A semidefinite programming technique to effectively transform the MLE problem into a convex optimization is proposed, together with a unified solution for four scenarios: 1) without a calibration emitter; 2) with a single calibration emitter, whose position is subject to measurement errors; 3) with a single calibration emitter, whose position is perfectly known; and 4) with a single calibration emitter, whose position is completely unknown. The results are finally extended to the case of multiple calibration emitters, whose positions are also subject to errors. Similar to the existing schemes that are known to have good performances, the proposed solution also reaches the Cramer-Rao lower bound when sensor position errors and TDOA measurement noise are sufficiently small. However, as TDOA measurement noise or sensor position errors increase, comparison with the existing state-of-the-art methods for each scenario shows that the proposed solution performs significantly better."
  },
  {
    "year": "2017",
    "abstract": "We propose signal-to-interference-plus-noise power ratio (SINR) maximizing rank one beamforming schemes for the full-duplex (FD) relay systems. The non-regenerative amplify and forward (AaF) relay is considered with multiple transmit antennas and multiple receive antennas. The residual selfinterference (SI) after analogue domain processing is to be suppressed by the proposed schemes so that the spectral efficiency of FD can be improved. We first analyze the correlation matrix of SI in a matrix power series and derive a convergent form of the correlation matrix so that the SINR expressions can be identified. Leveraging the structure of the SINR function on the beamformer (BF) vectors and power control parameter, two of the proposed schemes try to maximize SINR by optimizing a BF vector through iterative updates exploiting a bisection type search with the other BF vector being fixed. The third proposed scheme alternates over these two schemes to further enhance them by widening the search space that the BF vectors span. We compare the SINR of the proposed schemes with some reference schemes based on zero forcing approaches, maximum ratio reception, and maximum ratio transmission to characterize the performance improvement of the proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "The evolution of the Internet of things and the continuing increase in the number of sensors connected to the Internet impose big challenges regarding the management of the resulting deluge of data and network latency. Uploading sensor data over the web does not add value. Therefore, an efficient knowledge extraction technique is badly needed to reduce the amount of data transfer and to help simplify the process of knowledge management. Homoscedasticity and statistical features extraction are introduced in this paper as novelty detection enabling techniques, which help extract the important events in sensor data in real time when used with neural classifiers. Experiments have been conducted on a fog computing platform. System performance has been also evaluated on an occupancy data set and showed promising results."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a compact, low-cost unmanned aerial system for antenna measurement. The proposed system overcomes existing limitations in terms of unmanned aerial vehicle positioning and data geo-referring accuracy using a real-time kinematic positioning system to achieve centimeter-level accuracy. Amplitude-only measurements acquired using a low-cost power sensor are processed by means of the phaseless sources reconstruction method. This is an iterative phase retrieval technique that allows recovering an equivalent currents distribution, which characterizes the antenna under test (AUT). From these equivalent currents, near-field to far-field transformation is applied to calculate the AUT radiation pattern. This contribution also analyzes probe antenna characterization and the impact of positioning and geo-referring accuracy on the radiation pattern. Two application examples of antenna measurement at S- and C-bands using the implemented system are presented."
  },
  {
    "year": "2017",
    "abstract": "Millimeter-wave (mm-Wave) MIMO systems have been proposed to achieve higher spectral efficiency via the hybrid beamforming structure, which consists of analog beamforming and digital beamforming. In analog beamforming, each antenna subarray generates a codebook-based directional beam, which determines the equivalent MIMO channel. Then, digital beamforming can be applied to fully exploit the spatial multiplexing gain of MIMO channels. In this paper, we propose a low-complexity analog beam selection scheme to achieve near-optimal spectral efficiency for the split hybrid beamforming system. The core of our scheme is the beam selection criterion, which is derived from capacity analysis. Furthermore, we propose a beam switching algorithm to ensure the robustness when blockage occurs. Through simulations under different channel conditions, the near-optimal performance of our scheme is demonstrated, and the beam switching algorithm is able to ensure robust network connectivity and achieve higher channel capacity when the blockage is relived."
  },
  {
    "year": "2017",
    "abstract": "An improved singular value decomposition based on Toeplitz (TopSVD) is proposed to solve the problem of inaccurately estimating source numbers under the condition of a low signal-to-noise (SNR) ratio for blind source separation. First, Toeplitz modifies the covariance of the received data, and singular value decomposition is used to estimate the number of signal sources. The advantages of TopSVD over traditional approaches are demonstrated by simulated signals. The results demonstrate that the proposed method can be used to estimate the number of coherent sources under low SNR conditions; at the same time, it can significantly improve the accuracy of source number estimation under the conditions of a low SNR and coherent signal source with the simple algorithm."
  },
  {
    "year": "2017",
    "abstract": "Stereo matching is a challenging problem with respect to weak texture, discontinuities, illumination difference and occlusions. Therefore, a deep learning framework is presented in this paper, which focuses on the first and last stage of typical stereo methods: the matching cost computation and the disparity refinement. For matching cost computation, two patch-based network architectures are exploited to allow the trade-off between speed and accuracy, both of which leverage multi-size and multi-layer pooling unit with no strides to learn cross-scale feature representations. For disparity refinement, unlike traditional handcrafted refinement algorithms, we incorporate the initial optimal and sub-optimal disparity maps before outlier detection. Furthermore, diverse base learners are encouraged to focus on specific replacement tasks, corresponding to the smooth regions and details. Experiments on different datasets demonstrate the effectiveness of our approach, which is able to obtain sub-pixel accuracy and restore occlusions to a great extent. Specifically, our accurate framework attains near-peak accuracy both in non-occluded and occluded region and our fast framework achieves competitive performance against the fast algorithms on Middlebury benchmark."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider downlink non-orthogonal multiple access cooperative communication system. The base station (BS) serves two types of users, which are named relay user (RU) and far user (FU). The BS and RU are equipped with multiple transmit antennas. The RU harvests energy from the BS transmissions to perform the relaying operation for the FU. We have considered 1) amplify-forward; 2) decode-forward; and 3) quantize-map-forward relaying protocols at the RU. As the BS and RU have multiple antennas, therefore we consider 1) beamforming and 2) random antenna selection strategies at the BS and RU. Closed form expressions for the outage probability are provided for the aforementioned relay protocols and antenna strategies. Further, we show that for certain data rate range of the relay and FU the quantize-map-forward relaying protocol can perform better than the other two relaying protocols."
  },
  {
    "year": "2017",
    "abstract": "Mine water inrush poses a serious threat to the safe production of coal mines in China. The transient electromagnetic method (TEM) on the ground has been applied to explore water-bearing structures, but the resolution is low. Therefore, some geophysicists in China moved the TEM onto underground coal mine roadways and obtained good results at the end of the last century. Although the TEM has been applied in mining for many years, there are so few theoretical studies that the data interpretation is not accurate. It is necessary to study the transient electromagnetic field diffusion in the entire space with physical or numerical simulation methods. First, based on the diffusion equations, we deduced the wave number domain equations, whose whole-space electromagnetic field is excited by a 3-D source in a 2-D geoelectric model; then, we derived the 2.5-D finite-difference time domain equations. At the beginning of the calculation, we gave the grid nodes near the source the initial values with the cosine filtering method. To improve the calculating efficiency, the time intervals gradually increased with time. At the end of the calculation, we transformed the calculating results from the wave number domain to the space domain by fitting the segmented exponential function. Compared with the analytical solutions, the numerical solutions are accurate, and the algorithm is reliable and efficient. The simulation results of a collapse-column model show that the transient electromagnetic field diffusion in the entire space is dominated by low-resistivity bodies."
  },
  {
    "year": "2017",
    "abstract": "Four-wheel independently driven skid-steered mobile robots are widely used in the fields of industrial automation and outdoor exploration. In most of existing controllers of skid-steered mobile robots, the wheel velocities are controlled independently to track the desired velocities from the high-level kinematic controller. However, this kind of control method may lead to chattering phenomenon of skidsteered mobile robots in practice, when the desired velocity commands of four wheels are not matched under different ground conditions. In this paper, the coordinated control problem is investigated for the four-wheel independently driven skid steer mobile robots, so as to solve the chattering phenomenon and also achieve good control performance under different ground conditions. Since the mobile robots are overactuated and lack of suspension systems, a coordinated adaptive robust control scheme integrated with torque allocation technique is proposed. First, an adaptive robust control law is developed to attenuate the negative effects of load variations and uncertainties. Second, instead of directly giving the desired velocity commands, a torque control and allocation algorithm is developed to regulate the driving torque of each wheel motor. A coordinated control law with considering the wheel slip compensation is also proposed. Comparative experiments are carried out, and the results show the proposed scheme can avoid the chattering problem and achieve the excellent performance under different ground conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the problem of guaranteed cost control of an interval type-2 Takagi-Sugeno fuzzy descriptor systems with time-varying delays satisfying probabilistic characteristics. In order to fully consider the delay distributions, the delay segmentation approach is introduced. Then, an interval type-2 fuzzy controller is designed such that the closed-loop fuzzy descriptor system is regular, causal, mean square asymptotically stable, and the corresponding quadratic cost function is guaranteed which lower than a certain upper bound. Finally, one simulation example is given to demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "To accommodate the trend toward mass customization launched by intelligent manufacturing in the era of Industry 4.0, this paper proposes the combination of model-driven engineering and knowledgedriven engineering during the development process of self-reconfigurable machine control systems. The complete tool chain for model development, execution, and reconfiguration is established. For the design phase, a machine-control-domain-specific modeling language and the supporting design environment are developed. With regard to the execution stage, a runtime framework compliant with the IEC 61499 standard is proposed. On the ground of the modeling environment and the reconfigurable run-time framework, a self-adaptive control module is developed to establish the close-loop self-reconfiguration infrastructure. The ontological representation of knowledge base toward this end is described, along with extendable SQWRL rules specified to automatically initiate the reconfiguration process in the cases of external user demands and internal faults. A prototype motion control kernel in the low-level layer of machine control system architecture is developed with the proposed modeling language and is then deployed to the runtime framework. Two case studies on self-reconfiguration of the proof-of-concept motion control kernel are demonstrated, which prove the feasibility of our proposal."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an automatic modeling method based on constructive grammar for building Chinese Huizhou traditional vernacular houses, which are famous and important examples of Chinese traditional architecture. The proposed method includes two steps: layout generation and feature generation. In the layout generation step, layout guidelines based on 2-D geometric rules are used to evaluate the layout result. In the feature generation step, a probabilistic network is used to generate the features for a single house while feature conflict penalty functions are used to generate the reasonable features for multiple houses. Both the layout generation and feature generation steps use the Metropolis-Hastings algorithm to search for the optimal solution. To increase the computational efficiency of the proposed system, the two steps are performed on a graphics processing unit device using a Monte Carlo sampler. Moreover, a dynamic probability strategy is used to perform the layout perturbation. The proposed method is easy to implement and extend. The experimental results show that the proposed method is practical and efficient. Non-expert users can rapidly generate reasonable Huizhou vernacular houses via simple and intuitive interactions with the system."
  },
  {
    "year": "2017",
    "abstract": "Multimedia services over mobile networks are subject to multiple factors that affect the quality of experience (QoE) perceived by users. In a long term evolution (LTE) multimedia broadcast service, these factors are initial delay, technical quality of multimedia content, and service disruptions. However, there is a lack of QoE models to enable QoE measurement. We propose to use video mean opinion score as a new and objective QoE model that is in the process of standardization, and we show how it can be applied to LTE multimedia broadcast services for QoE assessment. The results obtained are useful to better understand the impact of several service parameters on perceived quality. By applying this assessment methodology, it is possible to determine the most adequate service parameters for a specific LTE broadcast deployment."
  },
  {
    "year": "2017",
    "abstract": "The development of automated approaches employing computational methods using data from publicly available drugs datasets for the prediction of drug side effects has been proposed. This paper presents the use of a hybrid machine learning approach to construct side effect classifiers using an appropriate set of data features. The presented approach utilizes the perspective of data analytics to investigate the effect of drug distribution in the feature space, categorize side effects into several intervals, adopt suitable strategies for each interval, and construct data models accordingly. To verify the applicability of the presented method in side effect prediction, a series of experiments were conducted. The results showed that this approach was able to take into account the characteristics of different types of side effects, thereby achieve better predictive performance. Moreover, different feature selection schemes were coupled with the modeling methods to examine the corresponding effects. In addition, analyses were performed to investigate the task difficulty in terms of data distance and similarity. Examples of visualized networks of associations between drugs and side effects are also discussed to further evaluate the results."
  },
  {
    "year": "2017",
    "abstract": "Multimodal imaging techniques have received a great deal of attention, since their inceptions for achieving an enhanced imaging performance. In this paper, a novel joint reconstruction framework for computed tomography (CT) and magnetic resonance imaging (MRI) is implemented and evaluated. The CT and MRI data sets are synchronously acquired and registered from a hybrid CT-MRI platform. Because the image data sets are highly undersampled, the conventional methods (e.g., analytic reconstructions) are unable to generate decent results. To overcome this drawback, we employ the compressed sensing (CS) sparse priors from an application of discrete gradient transform. On the other hand, to utilize multimodal imaging information, the concept of projection distance is introduced to penalize the large divergence between images from different modalities. During the optimization process, CT and MRI images are alternately updated using the latest information from current iteration. The method exploits the structural similarities between the CT and MRI images to achieve better reconstruction quality. The entire framework is accelerated via the parallel processing techniques implemented on a nVidia M5000M Graph Processing Unit. This results in a significant decrease of the computational time (from hours to minutes). The performance of the proposed approach is demonstrated on a pair of undersampled projections CT and MRI body images. For comparison, the CT and MRI images are also reconstructed by an analytic method, and iterative methods with no exploration of structural similarity, known as independent reconstructions. Results show that the proposed joint reconstruction provides a better image quality than both analytic methods and independent reconstruction by revealing the main features of the true images. It is concluded that the structural similarities and correlations residing in images from different modalities are useful to mutually promote the quality of joint image recons..."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an enhanced cooperative spectrum sharing scheme in a cognitive radio network, which consists of two pairs: a primary transmitter-primary receiver pair and a secondary base station-secondary receiver pair. The developed scheme is based on a three time slots cooperative spectrum sharing, which exploits the maximum diversity gain for both the primary user (PU) and secondary user (SU). The performance of the developed scheme is assessed through the derivation of new closed-form expressions for both the bit error rate and achievable rate for arbitrary signal-to-noise ratio (SNR). In addition, we carry out an asymptotic analysis in the high SNR regime, which proves that the proposed scheme achieves a full diversity order for the PU and SU. Results of analytical expressions and numerical simulations both verify that the proposed scheme achieves significant gains for error and rate performance, for both the PU and SU, in comparison to other baseline schemes."
  },
  {
    "year": "2017",
    "abstract": "Most traditional engineered systems are designed with a passive and fixed reliability capability and just required to achieve a possibly low level of failure occurrence. However, as the complexity at spatialtemporal scales and integrations increases, modern complex engineered systems (CESs) are facing new challenges of inherent risk and bottleneck for a successful and safe operation through the system life cycle when potential expected or unexpected disruptive events happen. As a prototype for ensuring the successful operation of inherently risky systems, resilience has demonstrated itself to be a promising concept to address the above-mentioned challenges. A standard multi-dimensional resilience triangle model is first presented based on the concept of the three-phase system resilience cycle, which can provide a theoretical foundation for indicating the utility objectives of resilience design. Then, the resilience design problem for CESs is proposed as a multi-objective optimization model, in which the three objectives are to maximize the survival probability, to maximize the reactive timeliness and to minimize the total budgeted cost. Furthermore, the proposed multi-objective optimization programming is solved based on the efficient multi-objective evolutionary algorithm NSGA-II. Finally, the effectiveness of the proposed models and solving procedure is illustrated with an engineered electro-hydrostatic aircraft control actuator resilience design problem, a comparative analysis on the case study is also carried out with respect to previous works. This work can provide an effective tradeoff foundation to improve the resilience of CESs."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a new strategy to promote the robustness of structure from motion algorithm from uncalibrated video sequences. First, an augmented affine factorization algorithm is formulated to circumvent the difficulty in image registration with noise and outliers contaminated data. Then, an alternative weighted factorization scheme is designed to handle the missing data and measurement uncertainties in the tracking matrix. Finally, a robust strategy for structure and motion recovery is proposed to deal with outliers and large measurement noise. This paper makes the following main contributions: 1) An augmented factorization algorithm is proposed to circumvent the difficult image registration problem of previous affine factorization, and the approach is applicable to both rigid and nonrigid scenarios; 2) by employing the fact that image reprojection residuals are largely proportional to the error magnitude in the tracking data, a simple outliers detection approach is proposed; and 3) a robust factorization strategy is developed based on the distribution of the reprojection residuals. Furthermore, the proposed approach can be easily extended to nonrigid scenarios. Experiments using synthetic and real image data demonstrate the robustness and efficiency of the proposed approach over previous algorithms."
  },
  {
    "year": "2017",
    "abstract": "Virtually, detection of shifts in the dispersion parameter of the process is more valuable before monitoring the location parameter of the process. For the monitoring of the dispersion parameter, the S2chart is a common choice in the literature. In this paper, we proposed a modified S2chart based on modified successive sampling, which is cost effective relative to simple random sampling. The run length properties are used as comparative measure and the findings depict that all proposed schemes outperform the classical S2chart. Finally, the application of the proposed scheme is demonstrated using a real-life engineering process."
  },
  {
    "year": "2017",
    "abstract": "In aerospace engineering, condition monitoring is an important reference for evaluating the performance of complex systems. Especially, effective anomaly detection, based on telemetry data, plays an important role for the system health management of a spacecraft. With the advantages of easy-to-use, high efficiency, and data-driven, the predicted model has been applied for anomalous point detection for monitoring data. However, compared with the point abnormal mode, fragment anomaly is more attractive and meaningful for the system identification. Therefore, the detection strategy of fragment anomaly is proposed based on the uncertainty estimation of least square support vector machine and statistical analysis. Moreover, some effective estimation indicators are presented to evaluate the performance of the detection method. Experimental validations are also carried out for some typical simulation data sets and open source data sets. In particular, relied on the analysis of fragment anomaly modes, experiments are conducted with the real satellite telemetry data and different anomaly modes are injected to examine the applicability of the proposed framework."
  },
  {
    "year": "2017",
    "abstract": "The increasing use of virtualization puts stringent security requirements on software integrity and workload isolation of cloud computing. The encryption card provides hardware cryptographic services for users and is believed to be superior to software cryptography. However, we cannot use the encryption card directly in the user domain because of the complicated virtualization mechanisms and the security problems about the user key and the user private data flow. To address these challenges, we propose a new virtualization architecture to ensure the trustworthiness of encryption cards. First, we design a privacy preserving model to ensure the security of the dynamic schedule of encryption cards. Second, we present a hardware trust verification procedure based on the trusted platform module to supply a trusted virtualization hardware foundation. Third, we provide a series of security protocols to establish a trusted chain between users and encryption cards. Finally, we give security proofs of the encryption card virtualization architecture. Based on our prototype implementation, the encryption service provided by the encryption card has higher-level security and higher efficiency than software encryption. It provides strong support for security services of virtualization systems in cloud computing."
  },
  {
    "year": "2017",
    "abstract": "Social networking has become part of our life in recent years, allowing users to converse and connect with people sharing similar interests in real world. However, networking via the social media suffers from serious privacy issues, and one of which is profile attribute leakage in friend discovery. While existing studies mainly focus on leveraging rich cryptographic algorithms to prevent privacy leak, we propose a novel perturbation-based private profile matching mechanism by mixing the private data with random noise to preserve privacy in this paper. In this paper, we consider the case where the profiles are fine-grained, meaning that each attribute is associated with a user-specific numerical value to indicate the level of interest. By carefully tuning the amount of information owned by each party, we guarantee that privacy is effectively preserved while the matching result of users' profiles can be cooperatively obtained. We first give an introduction to a basic scheme, then detail two improved ones by, respectively, taking collusion attack and verifiability into consideration. As no expensive encryption algorithms get involved, our methods are computationally efficient; thus they are more practical for real-world applications. Theoretical security analysis as well as comparison-based simulation studies are carried out to evaluate the performance of our designs."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel protocol, called an aggregation-based topology learning (ATL) protocol, to identify energy holes in a randomly deployed hierarchical wireless sensor network (HWSN). The approach taken in the protocol design is to learn the routing topology of a tree-structured HWSN in real-time, as an integral part of the sensed data collection and aggregation process in the network. The learnt topology is then examined to identify high energy-consuming nodes, that are more likely to create energy holes in the network. The major challenge in designing this protocol is to code topology data in such a way that it can be carried in length-constrained messages supported by current sensor technologies. To address this challenge, three topology coding methods are proposed. A theoretical analysis of the three topology coding methods is carried out to find the optimum method among the three, and this optimum method is used in the ATL protocol. The ATL protocol is tested and evaluated on a real WSN test bed in terms of completeness, correctness and energy costs. Based on the evaluation results, we have identified two classes of high energy-consuming nodes, which are: 1) nodes that carry topology data from more downstream nodes and 2) nodes that more frequently switch between different upstream nodes. This finding is significant as it provides an insight as how topology-learning, as well as data collection, may be used to prolong the life-time of a HWSN. In addition, the evaluation results also show that the energy cost incurred in a data collection process integrated with our proposed topology-learning facility is at a similar level as for the process without the facility, thereby implying that the cost incurred in topology-learning by using our proposed method is negligible. These findings indicate that, by integrating the topology-learning process with the sensed data collection and aggregation process, the ATL protocol can identify high energy-consuming nodes, ..."
  },
  {
    "year": "2017",
    "abstract": "Underwater images are difficult to process because of low contrast and color distortion. The in-water light propagation model was proposed several years ago but is relatively complicated to be used in reality. In this paper, the full underwater light propagation model is simplified to be used as the transmission model. On the basis of this model, we propose a new method, called maximum attenuation identification, to derive the depth map from degraded underwater images. At the same time, regional background estimation is implemented to ensure optimal performance. Experiments on three groups of images, namely, natural underwater scene, calibration board, and colormap board, are conducted. We report the quantitative and qualitative comparisons of our approach with existing state-of-the-art approaches. The performance evaluation on contrast enhancement and color restoration validates that our approach outperforms existing state-of-the-art approaches."
  },
  {
    "year": "2017",
    "abstract": "We consider the resource allocation for the virtualized OFDMA uplink cloud radio access network (C-RAN), where multiple wireless operators (OPs) share the C-RAN infrastructure and resources owned by an infrastructure provider (InP). The resource allocation is designed through studying tightly coupled problems at two different levels. The upper-level problem aims at slicing the fronthaul capacity and cloud computing resources for all OPs to maximize the weighted profits of OPs and InP considering practical constraints on the fronthaul capacity and cloud computation resources. Moreover, the lower-level problems maximize individual OPs' sum rates by optimizing users' transmission rates and quantization bit allocation for the compressed I/Q baseband signals. We develop a two-stage algorithmic framework to address this two-level resource allocation design. In the first stage, we transform both upper-level and lowerlevel problems into corresponding problems by relaxing underlying discrete variables to the continuous ones. We show that these relaxed problems are convex and we develop fast algorithms to attain their optimal solutions. In the second stage, we propose two methods to round the optimal solution of the relaxed problems and achieve a final feasible solution for the original problem. Numerical studies confirm that the proposed algorithms outperform two greedy resource allocation algorithms and their achieved sum rates are very close to sum rate upper-bound obtained by solving relaxed problems. Moreover, we study the impacts of different parameters on the system sum rate, performance tradeoffs, and illustrate insights on a potential system operating point and resource provisioning issues."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an experimental study on the real-time estimation of observed learners' attention given the task of touch-typing. The aim is to examine whether the observed attention estimates gathered from human raters can be computationally modeled in real time, based on the learner's psychophysiological and affective signals. A key observation from this paper is that the observed attention varies continuously and throughout the task. The findings show that a relatively high sampling interval is required for the modeling of observed learners' attention, which is impossible to achieve with traditional assessment methods (e.g., between-session self-reports). The results show that multiple linear regression models were relatively successful at discriminating low and high levels of the observed attention. In the best case, the within-learner model performed with the goodness-of-fit adjusted R2adj= 0.888 and RMSE = 0.103 (range of the attention scores 1-5). However, the multiple linear model underperformed in the estimation of the observed attention between learners, indicating that the differences among the learners are often significant and cannot be overcome by a general linear model of attention. The between-learner model achieved an adjusted R2adj= 0.227 and RMSE = 0.708), explaining only 22.7% of the variability. The influence of individual psychophysiological and affective signals (eye gaze, pupil dilation, and valence and arousal) on the estimation of the observed attention was also examined. The results show that both affective dimensions (valence and arousal), as well as the EyePos2D offset (the distance of an eye from the average position in the xy plane parallel to the screen), and the EyePos-Z (the distance of an eye from the screen) significantly and most frequently influence the performance of the within-learner model."
  },
  {
    "year": "2017",
    "abstract": "emergingFusion of electroencephalography (EEG) and functional near infrared spectroscopy (fNIRS) is an emerging approach in the field of psychological and neurological studies. We developed a decision fusion technique to combine the output probabilities of the EEG and fNIRS classifiers. The fusion explored support vector machine as classifier for each modality, and optimized the classifiers based on their receiver operating characteristic curve values. EEG and fNIRS signal were acquired simultaneously while performing mental arithmetic task under control and stress conditions. Experiment results from 20 subjects demonstrated significant improvement in the detection rate of mental stress by +7.76% (p <; 0.001) and +10.57% (p <; 0.0005), compared with sole modality of EEG and fNIRS, respectively."
  },
  {
    "year": "2017",
    "abstract": "Over the past decade, there has been a significant increase in research examining the various aspects of mobile game addiction diagnosis and treatment using different scales and questionnaires. The aim of this paper was to examine the frequency attributes of the EEGs (electroencephalographs) of addicted and non-addicted mobile game players to detect the early signs of game addiction using physiological parameters and to design a framework for the use of these results to alert for potential game addiction. This research comprises two parts. The first part addresses the diagnosis of mobile game addiction psycho-physiologically, and the second part consists of a design to implement the results of the proposed diagnostic tests practically to detect mobile game addiction using a wearable mobile addiction sensing system. The comprehensive scale for assessing game behavior manual from 2010 was used to record the basic demographic information and pre-categorization regarding the game addiction. Temporal and frequency domain analysis were applied to the electroencephalographic data from all the subjects to acquire quantitative information to identify mobile game players with addiction. Finally, logistic regression modeling was employed to quantify the parameters that can be used as decision variables to identify the subject's category. The overall trend in alpha and theta frequencies was observed to be dominant and distinctive compared with the other frequencies in the occipital region of subjects with addiction. This paper reveals that the parameterization of EEG signals from the occipital region can provide evidential proof to identify mobile game addicts."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a model for time-averaged realistic maximum power levels for the assessment of radio frequency (RF) electromagnetic field (EMF) exposure for the fifth generation (5G) radio base stations (RBS) employing massive MIMO is presented. The model is based on a statistical approach and developed to provide a realistic conservative RF exposure assessment for a significant proportion of all possible downlink exposure scenarios (95th percentile) in-line with requirements in a recently developed International Electrotechnical Commission standard for RF EMF exposure assessments of RBS. Factors, such as RBS utilization, time-division duplex, scheduling time, and spatial distribution of users within a cell are considered. The model is presented in terms of a closed-form equation. For an example scenario corresponding to an expected 5G RBS product, the largest realistic maximum power level was found to be less than 15% of the corresponding theoretical maximum. For far-field exposure scenarios, this corresponds to a reduction in RF EMF limit compliance distance with a factor of about 2.6. Results are given for antenna arrays of different sizes and for scenarios with beamforming in both azimuth and elevation."
  },
  {
    "year": "2017",
    "abstract": "Vehicle platooning, which is formed by a group of vehicles traveling in close proximity to one another, nose-to-tail, at highway speeds, has received considerable attention in recent years. However, though it brings many opportunities in self-driving, the security of vehicle platooning is still challenging. In this paper, to secure vehicle platooning, particularly to secure communication and efficient key updating for vehicles in a platoon, we first present the notion of ternary join exit tree. A ternary join exit tree consists of main tree, join tree, and exit tree. The users join in the join tree and leave from exit tree. Then, we propose a new dynamic ternary join-exit tree-based dynamic key management scheme, called TJET, for vehicle platooning, which is characterized by providing efficient key updating for not only vehicle joining and leaving, but also platoon merging and splitting. Specifically, based on the structure of ternary join-exit tree, we devise concrete algorithms for vehicle joining, vehicle exiting, platoon merging, and splitting. Moreover, we also analyze the capacities and activation conditions of join tree and exit tree based on strict mathematical proofs. Detailed security analysis show that our proposed TJET holds desirable security properties including forward security, backward security, and resistance to key control. In addition, performance evaluations via extensive simulations demonstrate the efficiency of TJET."
  },
  {
    "year": "2017",
    "abstract": "As a novel cyber-physical-social network paradigm, the Internet of Things (IoT) provides a powerful tool to monitor the hazardous fields of interest. Due to the uneven random deployment, sensor energy depletion, and external attacks, the emergence of coverage holes would remarkably degrade the network performance and quality of service. For overcoming the drawbacks resulting from the coverage holes, this paper focuses on how to locally detect coverage holes by exploiting one-hop neighboring sensors' cooperation based on the novel confident information coverage model (CIC), which is formulated as the localized confident information coverage hole detection (LCICHD) problem. For handling the CICHD problem, we devise a family of heuristic CIC holes detection schemes including the LCHD, LCHDRL, random and randomRL. Both the LCHD and LCHDRL schemes locally determine coverage status of each subregion and take the sensor communication ability into consideration. While the LCHDRL considers not only the sensor remaining energy but also the residual lifetime during the CIC hole detection. After acquiring the coverage status of each partitioned local subregion, the coverage hole boundary will be extracted by image processing techniques. For comparison, both the Random and RandomRL schemes arbitrarily select sensors within the sensing field to detect CIC holes, and the RandomRL scheme takes the sensors' residual lifetime into consideration during the hole detection process. Experimental simulations show that the proposed schemes can efficiently detect the emerged coverage holes including the locations and the number, and the LCHDRL algorithm is more practical and efficient compared with the other three peer solutions."
  },
  {
    "year": "2017",
    "abstract": "Active contour models based on the level set method (LSM) are widely used in image segmentation. The major advantages of these models based on an LSM are topological flexibility and evolution robustness. However, topological flexibility is not always needed, and it could bring some negative effects for object extraction, such as extracting noise and non-objects. In this paper, a topological preservation method is proposed to constrain the evolution of contour. First, the modes of topological changes in geometric active contour models are analyzed. Second, on the basis of the modes of topological changes, the corresponding constraints are designed to keep the topology. To be specific, extracting objects with a known topology (such as k-connected objects) is viewed as a sparse representation problem under a set of basis functions. According to sparse representation, the increase or decrease of evolving contours' topology corresponds to those of the basis functions. Thus, a corresponding energy functional for topology preservation is defined based on basis functions. Finally, the proposed constraint is integrated into geometric active contour models, which is useful in extracting special objects. Experiments demonstrate that the proposed method improves the robustness of the performance of active contour models and can increase the accuracy in target object extraction."
  },
  {
    "year": "2017",
    "abstract": "Filtering or state estimation plays an important role in the cyber-physical systems (CPSs). This paper aims to solve the data-driven non-fragile filtering problem for the cyber-physical system. Randomly occurring gain variations are considered so as to account for the parameter fluctuations occurring during the filter implementation. The data-driven communication mechanism is utilized to reduce the measurement transmission frequency and save energy for the CPSs. Therefore, a unified H∞filtering framework that combines the data-driven communication mechanism and the non-fragility of filters is constructed. Based on this unified framework, the influence of the simultaneous presence of networked-induced packet dropouts, quantization, randomly occurring nonlinearities and randomly occurring parameter uncertainties in the CPS is investigated. A modified dropouts model is proposed under the data-driven communication mechanism. By utilizing stochastic analysis and Lyapunov functional theory, sufficient conditions guaranteeing the filtering performance are derived. The H∞filter is obtained through the proposed algorithm. Last, a simulation is given to demonstrate the filtering method for CPS in this paper."
  },
  {
    "year": "2017",
    "abstract": "Due to its low price, webcam has become one of the most promising sensors with the rapid development of computer vision. However, the accuracies of eye tracking and eye movement analysis are largely limited by the quality of the webcam videos. To solve this issue, a novel eye movement analysis model is proposed based on five eye feature points rather than a single point (such as the iris center). First, a single convolutional neural network (CNN) is trained for eye feature point detection, and five eye feature points are detected for obtaining more useful eye movement information. Subsequently, six types of original time-varying eye movement signals can be constructed by feature points of each frame, which can reduce the dependency of the iris center in low quality videos. Finally, behaviors-CNN can be trained by the timevarying eye movement signals for recognizing different eye movement patterns, which is capable of avoiding the influence of errors from the basic eye movement type detection and artificial eye movement feature construction. To validate the performance, a webcam-based visual activity data set was constructed, which contained almost 0.5 million frames collected from 38 subjects. The experimental results on this database have demonstrated that the proposed model can obtain promising results for natural and convenient eye movement-based applications."
  },
  {
    "year": "2017",
    "abstract": "Green clouds optimally use energy resources in large-scale distributed computing environments. Large scale industries such as smart grids are adopting green cloud paradigm to optimize energy needs and to maximize lifespan of smart devices such as smart meters. Both, energy consumption and lifespan of smart meters are critical factors in smart grid applications where performance of these factors decreases with each cycle of grid operation such as record reading and dispatching to the edge nodes. Also, considering large-scale infrastructure of smart grid, replacing out-of-energy and faulty meters is not an economical solution. Therefore, to optimize the energy consumption and lifespan of smart meters, we present a knowledge-based usage strategy for smart meters in this paper. Our proposed scheme is novel and generates custom graph of smart meter tuple datasets and fetches the frequency of lifespan and energy consumption factors. Due to very large-scale dataset graphs, the said factors are fine-grained through R3F filter over modified Hungarian algorithm for smart grid repository. After receiving the exact status of usage, the grid places smart meters in logical partitions according to their utilization frequency. The experimental evaluation shows that the proposed approach enhances lifespan frequency of 100 smart meters by 72% and optimizes energy consumption at an overall percentile of 21% in the green cloud-based smart grid."
  },
  {
    "year": "2017",
    "abstract": "Robots as therapy tools have been researched in intervention for children with autism. During the interaction between robots and autistic children, engagement is an important metric which can be used to express whether robot's behavior is suited to the current context. The evaluation of engagement is a key prerequisite to improve the autonomous ability of robots in intervention. In this paper, we propose a new model to evaluate the engagement of children with autism. The proposed model is developed based on the dynamic Bayesian network, and the parameters of the model are obtained by fuzzy logic and expert elicitation. After determining the input features and the classification of engagement, the topology of the model is established. Afterward, experts' opinions are collected based on linguistic variables. Based on triangular fuzzy number, the parameterization of the model is realized by fuzzification, aggregation, and defuzzification. Finally, the model is validated by experiment. The result demonstrates that proposed model satisfies the actual demands and the result of engagement classification can provide the input condition for the decision making of the robot."
  },
  {
    "year": "2017",
    "abstract": "The aim of this paper is to introduce the use of sparse multistatic arrays to reduce the number of elements in novel portable and muti-view millimiter-wave scanners. Thus, the complexity of these novel scanners is significantly reduced. Furthermore, sparsity is expected to enable embedding a conventional optical camera sensor inside the aperture of the scanner allowing a reduction of the scanner size. This camera sensor is used to build a complementary 3-D optical model as well as to estimate the millimeter-wave scanner position so that the imaging merging techniques can be applied. The approach is validated for concealed weapon detection by means of simulation as well as measurements, in which the scanner aperture is emulated by raster scan, showing a performance comparable to the case of dense arrays."
  },
  {
    "year": "2017",
    "abstract": "Spoofing attacks are one of the most dangerous threats for the application of the global navigation satellite system (GNSS), especially for autonomous driving and unmanned aerial vehicles. In this paper, we present a more robust spoofing mitigation algorithm based on subspace projection that is independent of the number of antennas and that can be utilized in single-antenna GNSS receivers. During a spoofing attack, authentic signals are contaminated by spoofing signals. We demonstrate that all spoofing signals can be eliminated by projecting the received signal onto the orthogonal null space of the spoofing signals. Moreover, two types of receiver structures are designed: a centralized structure that has the ability to suppress cross-correlation interference and a distributed structure with lower computational complexity and lower projection power losses. The proposed algorithm is verified by the Beidou B1I signals for improving the security of the receiver."
  },
  {
    "year": "2017",
    "abstract": "Power system operators, when obtaining a model's parameter estimates; require additional information to guide their decision on a model's acceptance. This information has to establish a relationship between the estimates and the chosen model in the parameter space. For this purpose, this paper proposes to extend the usage of the particle filter (PF) as a method for the identification of power plant parameters; and the parameters' confidence intervals, using measurements. Taking into consideration that the PF is based on the Bayesian filtering concept, the results returned by the filter contain more information about the model and its parameters than usually considered by power system operators. In this paper the samples from the multi-modal posterior distribution of the estimate are used to identify the distribution shape and associated confidence intervals of estimated parameters. Three methods [rule of thumb, least-squares cross validation, plug-in method (HSJM)] for standard deviation (bandwidth) selection of the Gaussian mixture distribution are compared with the uni-modal Gaussian distribution of the parameter estimate. The applicability of the proposed method is demonstrated using field measurements and synthetic data from simulations of a Greek power plant model. The distributions are observed for different system operation conditions that consider different types of noise. The method's applicability for model validation is also discussed."
  },
  {
    "year": "2017",
    "abstract": "By segmenting, modeling, and visualizing computed tomography sequence data, surgeons can better understand the spatial relationship of the intrahepatic vein, portal vein, artery, and tumor. Accurate preoperative understanding of liver anatomy and volume of the corresponding liver segment are necessary for anatomical liver resection. This paper gives an efficient and semiautomatic method for segmenting the liver in clinical cases. This method is based on Couinaud’s theory and automatically divides the liver segment by portal vein branches. Considering the vascular variation of individual cases, the adjustment of the portal vein branches was provided on the basis of automatic segmentation, thus adaptability to various cases was implemented. For the final segmentation results, the portal vein blood supply of different liver segments can be confirmed by 3-D visualization, and the liver volume can be accurately estimated. Experiments show that this liver segmentation method has good clinical value."
  },
  {
    "year": "2017",
    "abstract": "The tailings dam, a necessary facility to maintain the normal operation of mining enterprises, is a hazard source of human-caused debris flow with high potential energy. The real-time pre-alarm for the instability of tailings dam is vital to ensure the normal mining and safety of human lives and properties. Based on the Internet of Things and wireless networks, the multiple and the key information system of tailings dam is constructed using the sensor data, which include the stability indexes like phreatic line, reservoir water level, internal and external deformation of the tailings dam. The cloud platform is applied to predict the future state of the phreatic line based on real-time monitoring data, where the equation of phreatic line can be obtained. The numerical simulation model is established by considering the predicted equation of phreatic line, limit equilibrium state parameters, reservoir water level, and rainfall. Then, the safety factor, random reliability, and interval non-probabilistic reliability can be solved out through the cloud platform. Combined with the trend of real-time monitoring deformation, as well as calculated dynamic safety factor, random reliability, and interval non-probabilistic reliability, the stable or dangerous warning signals of tailings dam can be obtained by the remote real-time pre-alarm system. The main solved method for the key parameters and pre-alarm process are presented through a case study. It is proved that the pre-alarm system is an efficient and real-time platform for the tailings dam stability with the integration and mutual validation of key information."
  },
  {
    "year": "2017",
    "abstract": "Human health has become a social and personal focus. Targeting the problems of the heterogeneity and randomness of crowd samples, diversity of health features and randomness of health feature values, an intelligent cognition method of human health states based on a variant knowledge granularity feedback mechanism is explored in this paper to imitate the human cognition process with repeated comparison and inference, and evaluate the human health state quickly and accurately. First, an intelligent cognition model of human health states with interconnection between the granularity decision layer, training layer, and cognition layer is proposed, and the corresponding variant knowledge granularity feedback mechanism is established. Second, based on bag of words, latent semantic analysis, and entropy, the estimated index of uncertain health states and the regulative index of knowledge granularity are constructed. Third, based on the proposed model and indexes, the optimal feedback cognition of human health states with variant knowledge granularity is achieved in the sense of pattern classification. Finally, for the collected bioelectrical impedance signals of random crowd samples, the simulated experiment has been carried out to validate the proposed method. Experimental results indicate that our method can effectively improve the accuracy of human health states compared with the existing open-loop methods."
  },
  {
    "year": "2017",
    "abstract": "Steam sterilization is a standard tool in the field of healthcare and medical equipment as it is economical, effective, and reliable. Considering the increase of antibiotic resistance and the challenge in sterilizing narrow tubes used for keyhole surgery, a safe process control is required. To achieve this, a full understanding of the local dynamics of the sterilization process inside the sterilizer is crucial. In this paper, water condensation under high temperature and high pressure, focusing on sterilization conditions, is qualitatively analyzed. An infrared sensor system was designed supplied by two LEDs, at a steam-absorbing and a non-absorbing wavelength, respectively. The local water vapor concentration was directly detected by evaluating the absorbance of infrared light as it passes through steam. Based on the absorbance monitored by this optical sensor, the condition of the steam was classified with respect to saturation and the onset of condensation. For typical sterilization cycles, differences as well as identical behavior between the local sensor measurements and the global results calculated from the temperature and pressure sensors are discussed."
  },
  {
    "year": "2017",
    "abstract": "Risk evaluation of the containers remains a difficult task, often due to incomplete or ambiguous information on containers. In addition, the evaluation process needs to be adapted on an ongoing basis to cope with emerging risk factors. Furthermore, high-risk container inspection is commonly hindered by a low inspection capacity, which leads to a major issue: how can we prioritize the container inspection if the number of suspect containers exceeds the inspection capacity? Container inspection prioritizing may be the answer. In this paper, we propose a novel approach for adaptively prioritizing container inspection (APRICOIN). First, we enhance the container information flow to alleviate the problem of incomplete information by proposing an enhanced container descriptive. Second, we introduce the APRICOIN algorithm, which combines frequent pattern mining and a fuzzy logic system, to assess the container's risk score. The frequent pattern growth algorithm is proposed to retrieve the key criteria for evaluating container risk. This is done through mining frequent criteria sets within the historic data set of container inspections by customs. The mined frequent criteria sets are used to assess fuzzy inference rules which are periodically readjusted to integrate new key criteria. Thereafter, the fuzzy logic system uses the obtained fuzzy inference rules to calculate a container's risk score. Our major contribution consists of providing a new adaptive approach for assessing a container's risk through combining frequent criteria mining and fuzzy logic. An illustrative study and a comparison with alternative approaches are performed to validate the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Clustering is an important problem, which has been applied in many research areas. However, there is a large variety of clustering algorithms and each could produce quite different results depending on the choice of algorithm and input parameters, so how to evaluate clustering quality and find out the optimal clustering algorithm is important. Various clustering validity indices are proposed under this background. Traditional clustering validity indices can be divided into two categories: internal and external. The former is mostly based on compactness and separation of data points, which is measured by the distance between clusters' centroids, ignoring the shape and density of clusters. The latter needs external information, which is unavailable in most cases. In this paper, we propose a new clustering validity index for both fuzzy and hard clustering algorithms. Our new index uses pairwise pattern information from a certain number of interrelated clustering results, which focus more on logical reasoning than geometrical features. The proposed index overcomes some shortcomings of traditional indices. Experiments show that the proposed index performs better compared with traditional indices on the artificial and real datasets. Furthermore, we applied the proposed method to solve two existing problems in telecommunication fields. One is to cluster serving GPRS support nodes in the city Chongqing based on service characteristics, the other is to analyze users' preference."
  },
  {
    "year": "2017",
    "abstract": "This work was supported in part by the China MOST Program of International S&T Cooperation under Grant 2016YFE0133000 and Grant 2016YFE0119000, in part by the National Natural Science Foundation of China (NSFC) under Grant 61461136004, in part by NSFC Major International Joint Research Project under Grant 61210002, in part by the Fundamental Research Funds for the Central Universities under Grant 2015XJGH011, in part by EU Horizon 2020 Program EXCITING project under Grant 723227, in part by EU FP7 CROWN project under Grant PIRSES-GA-2013-610524, and in part by the China International Joint Research Center of Green Communications and Networking under Grant 2015B01008."
  },
  {
    "year": "2017",
    "abstract": "N-gram feature templates that consider consecutive contextual information comprise a family of important feature templates used in structured prediction. Some previous studies considered the n-gram feature selection problem but they focused on one or several types of features in certain tasks, e.g., consecutive words in a text categorization task. In this paper, we propose a fast and robust bottom-up wrapper method for automatically inducing n-gram feature templates, which can induce any type of n-gram feature for any structured prediction task. According to the significance distribution for n-gram feature templates based on the n-gram and bias (offset), the proposed method first determines the n-gram that achieves the best tradeoff between the severity of the sparse data problem with n-gram feature templates and the richness of the corresponding contextual information, before combining the best n-gram with lower-order gram templates in an extremely efficient manner. In addition, our method uses a template pair, i.e., the two symmetrical templates, rather than a template as the basic unit (i.e., including or excluding a template pair rather than a template). Thus, when the data in the training set change slightly, our method is robust to this fluctuation, thereby providing a more consistent induction result compared with the template-based method. The experimental results obtained for three tasks, i.e., Chinese word segmentation, named entity recognition, and text chunking, demonstrated the effectiveness, efficiency, and robustness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "High energy efficiency is critical for enabling massive machine-type communications (MTC) over cellular networks. This paper is devoted to energy consumption modeling, battery lifetime analysis, lifetime-aware scheduling, and transmit power control for massive MTC over cellular networks. We consider a realistic energy consumption model for MTC and model network battery-lifetime. Analytic expressions are derived to demonstrate the impact of scheduling on both the individual and network battery lifetimes. The derived expressions are subsequently employed in the uplink scheduling and transmit power control for mixed-priority MTC traffic in order to maximize the network lifetime. Besides the main solutions, lowcomplexity solutions with limited feedback requirement are investigated, and the results are extended to existing LTE networks. In addition, the energy efficiency, spectral efficiency, and network lifetime tradeoffs in resource provisioning and scheduling for MTC over cellular networks are investigated. The simulation results show that the proposed solutions can provide substantial network lifetime improvement and network maintenance cost reduction in comparison with the existing scheduling schemes."
  },
  {
    "year": "2017",
    "abstract": "In recommender systems, collaborative filtering technology is an important method to evaluate user preference through exploiting user feedback data, and has been widely used in industrial areas. Diffusion-based recommendation algorithms inspired by diffusion phenomenon in physical dynamics are a crucial branch of collaborative filtering technology, which use a bipartite network to represent collection behaviors between users and items. However, diffusion-based recommendation algorithms calculate the similarity between users and make recommendations by only considering implicit feedback but neglecting the benefits from explicit feedback data, which would be a significant feature in recommender systems. This paper proposes a mixed similarity diffusion model to integrate both explicit feedback and implicit feedback. First, cosine similarity between users is calculated by explicit feedback, and we integrate it with resource-allocation index calculated by implicit feedback. We further improve the performance of the mixed similarity diffusion model by considering the degrees of users and items at the same time in diffusion processes. Some sophisticated experiments are designed to evaluate our proposed method on three real-world data sets. Experimental results indicate that recommendations given by the mixed similarity diffusion perform better on both the accuracy and the diversity than that of most state-of-the-art algorithms."
  },
  {
    "year": "2017",
    "abstract": "Wireless communication channels are highly prone to interference in addition to the presence of additive white Gaussian noise (AWGN). Stochastic gradient (SG)-based non-parametric maximum likelihood (NPML) estimator, gives better channel estimates in the presence of Gaussian mixture (AWGN plus interference) noise processes, for subsequent use by the channel equalizer. However, for sparse channels, the SG-NPML-based channel estimator requires large iterations to converge. In this paper, we propose a natural gradient (NG)-based channel estimator for sparse channel estimation in the presence of high interference. We propose a generalized pth order warping transformation on channel coefficients space and then calculate the Riemannian metric tensor, thereby resulting in faster convergence in interference limited channels. The proposed algorithm is applied for IEEE 802.22 (based on orthogonal frequency division multiplexing) channel estimation in the presence of interference. Extensive simulations and experimental results show that the proposed NG-based algorithm converges faster than SG-NPML for the same mean squared error (MSE) floor with similar computational complexity per iteration as an SG-NPML algorithm. We also present convergence analysis of proposed NG-NPML algorithm in the presence of Gaussian mixture noise and derive an analytical expression for the steady-state MSE."
  },
  {
    "year": "2017",
    "abstract": "The inherently high bandwidth of fiber and free-space optical (FSO) links make them ideally suited to provide broadband backhaul in fifth-generation (5G) mobile networks. However, both fiber and FSO systems suffer from a variety of impairments, which must be properly modeled in order to design the network. In this paper, we present analytical results for mixed FSO/fiber amplify-and-forward backhauling systems, where the impacts of radio-frequency (RF) co-channel interference, FSO pointing errors, and both fiber and FSO modulator nonlinearity are modeled and taken into consideration. Closed-form and asymptotic expressions are derived for the outage probability, the average bit-error rate, and the cumulative distribution function (CDF) of the channel capacity for mixed FSO/fiber backhauling systems. Our results reveal an optimal average-launched power for the fiber, which balances the impact of fiber nonlinear distortion with the receiver noise. In particular, when using the optimal fiber average-launched power, our estimated user capacity CDF results show that the 50th percentile user rates using mm-wave RF access can reach over 1.5 Gb/s in ideal conditions. However, user rates are more sensitive to the FSO backhaul channel characteristics."
  },
  {
    "year": "2017",
    "abstract": "One of the challenges of mobile health is to provide a way of maintaining privacy in the access to the data. Especially, when using ICT for providing access to health services and information. In these scenarios, it is essential to determine and verify the identity of users to ensure the security of the network. A way of authenticating the identity of each patient, doctor or any stakeholder involved in the process is to use a software application that analyzes the face of them through the cams integrated in their devices. The selection of an appropriate facial authentication software application requires a fair comparison between alternatives through a common database of face images. Users usually carry out authentication with variations in their aspects while accessing to health services. This paper presents both 1) a database of facial images that combines the most common variations that can happen in the participants and 2) an algorithm that establishes different levels of access to the data based on data sensitivity levels and the accuracy of the authentication."
  },
  {
    "year": "2017",
    "abstract": "Since the characteristics of opposite objectives, non-cooperation relationship, and dependent strategies of network attack and defense are highly consistent with game theory, researching the decision-making methods of network defense and applying the game models to analyze the network attack-defense behaviors has been of concern in recent years. However, most of the research achievements regarding to the game models are based on the hypothesis that both the two sides' players are completely rational, which is hard to meet. Therefore, we combined the evolutionary game theory and Markov decisionmaking process to construct a multi-stage Markov evolutionary game model for network attack-defense analysis, in view of the bounded rationality constraint. The model, based on the non-cooperative evolutionary game theory, could accomplish dynamic analysis and deduction for the multi-stage and multi-state network attack-defense process. In addition, an objective function with discounted total payoffs was designed by analyzing payoff characteristics of the multi-stage evolutionary game, which is more consistent with the reality of network attack and defense. Besides, the solving method for multi-stage game equilibrium was proposed on the basis of calculating the single-stage evolutionary game equilibrium. In addition, an algorithm for optimal defense strategy of the multi-stage evolutionary games was given. Finally, the experiments showed the high effectiveness and validity of the model and method that has a guiding significance for the network attack and defense."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new type of wideband absorptive bandstop filter (ABSF) design that is capable of absorbing the input power within the stopband at its Port 1. It is achieved by introducing one additional resistor to a conventional wideband stub bandstop filter. Suitable design procedures are established to facilitate the synthesis of the proposed wideband ABSFs with different filter orders and stopband bandwidths. To validate the proposed design method, microstrip ABSF design examples with a stopband center frequency f0of 2 GHz and 30-dB stopband bandwidths ranging from 12% to 42% are demonstrated. The measured stopband rejection atf0is larger than 60 dB for all design examples. In addition, good input return losses both in the passband and stopband are achieved, and the measured input return loss is better than 10 dB from dc to 2.5f0. Larger than 90% of the input power within the stopband can thus be dissipated by the proposed ABSF. To the best of our knowledge, these are the ABSFs with the widest stopband bandwidth ever reported."
  },
  {
    "year": "2017",
    "abstract": "Return on investment (ROI) analyses of solar photovoltaic (PV) systems used for residential usage have typically shown that at least 10 to 12 years is needed to break even, with this amount varying based on tax credits and reliability. This paper discusses the challenges with the reliability of current solar photovoltaic systems and the key reliability bottlenecks, with a focus on the ROI. The problem stems primarily from reliability issues of currently available power electronics hardware. This paper's analysis of failure data shows that the short warranties and reliability concerns associated with solar PV inverters reduce the long-term ROI of residential solar PV systems by up to 10%. This paper, therefore, provides key insights for accurate ROI calculations for solar PV investments. Furthermore, methods to improve the reliability of PV inverters, such as selection of capacitors, inverter topology, and incorporating wide-bandgap semiconductor devices, are presented."
  },
  {
    "year": "2017",
    "abstract": "Sparse code multiple access (SCMA), as a promising non-orthogonal multiple access scheme for the 5G system, aims to achieve massive connections and grant-free transmission in the radio access scenario. In this paper, we propose a blind detection scheme for the uplink grant-free SCMA transmission based on a novel sparsity-inspired sphere decoding (SI-SD) algorithm. By introducing one additional all-zero code word, each user's status and data can be jointly detected, thus avoiding the redundant pilot overhead. Considering the sparsity features in the grant-free SCMA transmission, we establish its mathematical model where the degree of sparsity is characterized by a transmission probability parameter, which will be estimated during the SI-SD detection process. With such a priori probability, the proposed SI-SD algorithm will achieve the maximum a posteriori (MAP) detection. Furthermore, unlike the conventional sphere decoding, in the grant-free SCMA scenario, strong constraints are proven to exist among the nodes in the proposed SI-SD algorithm which can be utilized to early remove some improbable transmit hypotheses. In addition, a reduced sparsity-inspired MAP metric constitutes a tight sphere constraint which in turn implies less valid hypotheses within the search sphere. By using the above two strategies, the complexity of the SI-SD can be efficiently reduced."
  },
  {
    "year": "2017",
    "abstract": "With the equipment of mobile terminals with multiple antennas, a bandwidth-friendly approach for increasing data rate and reliability has become the main trend in the development of future fifth generation (5G). However, this scenario presents significant challenges in the antenna and hardware design. For further system development, building real-time testbeds is a desirable track given that this endeavor can demonstrate the possibilities and limitations of the technology. In this paper, we present the design, implementation, and evaluation of a multiple input, multiple output system with eight antennas at a mobile terminal on the basis a software-defined radio (SDR) platform. The system uses long-term evolution-like system parameters. We illustrate the hierarchical hardware architecture and the implementation features, including the timing and synchronization, the processing partitioning, and the performance indicators of a particular eight-antenna module, which could meet the demands of 5G smartphone applications. Link-level simulations corresponding to the designs are conducted to validate the feasibility of the system. Accordingly, the SDR-based testbed is implemented, and a series of experiments are carried out to test the performance of our design in realistic situations. The proposed system has experimentally demonstrated its capability to transmit four-independent high-definition video streams on the same time-frequency resource."
  },
  {
    "year": "2017",
    "abstract": "Location fingerprint (LF) has been widely applied in indoor positioning. However, the existing studies on LF mostly focus on the fingerprint of Wi-Fi below 6 GHz, bluetooth, ultra wideband, and so on. The LF with millimeter-wave (mmWave) was rarely addressed. Since mmWave has the characteristics of narrow beam, fast signal attenuation, and wide bandwidth, and so on, the positioning error can be reduced. In this paper, an LF positioning method with mmWave is proposed, which is named direction of arrival (DoA)-LF. Besides received signal strength indicator of access points (APs), the fingerprint database contains DoA information of APs, which is obtained via DoA estimation. Then the impact of the number of APs, the interval of reference points, the channel model of mmWave and the error of DoA estimation algorithm on positioning error is analyzed with Cramer-Rao lower bound. Finally, the proposed DoA-LF algorithm with mmWave is verified through simulations. The simulation results have proved that mmWave can reduce the positioning error due to the fact that mmWave has larger path loss exponent and smaller variance of shadow fading compared with low frequency signals. Besides, accurate DoA estimation can reduce the positioning error.Kay, Fundamentals of Statistical Signal Processing: Estimation Theory."
  },
  {
    "year": "2017",
    "abstract": "Non-orthogonal multiple access (NOMA) has become one of the desirable schemes for the 5G cellular network standard due to its better cell coverage capability, higher data rate, and massive connectivity. Orthogonal frequency division multiplexing (OFDM) can be combined with NOMA to get the higher spectral efficiency. The main drawback of OFDM-based NOMA (OFDM-NOMA) scheme is high peak-to-average power ratio (PAPR). Therefore, this paper presents a new discrete-cosine transform matrix precoding-based uplink OFDM-NOMA scheme for PAPR reduction. Additionally, the proposed precoding-based uplink multicarrier NOMA scheme takes advantage of information spreading over the entire signal spectrum; thus, bit-error rate is also reduced. Simulation results show that the proposed precodingbased NOMA scheme outperforms as compared with the non-precoding-based NOMA schemes available in the literature."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we review the background and state-of-the-art of the narrow-band Internet of Things (NB-IoT). We first introduce NB-IoT general background, development history, and standardization. Then, we present NB-IoT features through the review of current national and international studies on NB-IoT technology, where we focus on basic theories and key technologies, i.e., connection count analysis theory, delay analysis theory, coverage enhancement mechanism, ultra-low power consumption technology, and coupling relationship between signaling and data. Subsequently, we compare several performances of NB-IoT and other wireless and mobile communication technologies in aspects of latency, security, availability, data transmission rate, energy consumption, spectral efficiency, and coverage area. Moreover, we analyze five intelligent applications of NB-IoT, including smart cities, smart buildings, intelligent environment monitoring, intelligent user services, and smart metering. Finally, we summarize security requirements of NB-IoT, which need to be solved urgently. These discussions aim to provide a comprehensive overview of NB-IoT, which can help readers to understand clearly the scientific problems and future research directions of NB-IoT."
  },
  {
    "year": "2017",
    "abstract": "Cloud gaming or gaming as a service, the newest entry in the online gaming world, leverages the well-known concept of cloud computing to provide real-time gaming services to players. This gaming paradigm provides affordable, flexible, and high performance solutions for end users with constrained computing resources and enables them to play high-end graphic games on low-end thin clients, because it renders everything in the cloud and simply streams the resulting high-quality video to the player. Despite its advantages, cloud gaming's quality of experience suffers from high and unstable end-to-end delay. According to this fact of cloud gaming, datacenters are in charge of performing complex rendering and video encoding computations, delivering high-quality gaming experience to gamers which requires an efficient and smart resource allocation mechanism to allot resources (e.g., memory and network bandwidth) to gaming sessions consistent with their requirements. In this paper, we propose a bi-objective optimization method to find an optimum path for packet transmission within a data center by minimizing delay and maximizing bandwidth utilization. We use a metaheuristic model, called analytic hierarchy process, to solve the NP-complete optimization problem. The resulting method is an analytic hierarchy process-based game aware routing (AGAR) scheme that considers requested game type and requirements in terms of delay and bandwidth to select the best routing path for a game session in a cloud gaming network. The method executes within a software defined network controller, which affords it a global view of the data center with respect to communication delay and available bandwidth. Simulation results indicate that the AGAR can reduce the end-to-end delay by up to 9.5% compared with three other conventional representative methods: the delay-based Dijkstra, the equal cost multi-path routing, and the Hedera routing algorithms. In addition, we demonstrate that the proposed met..."
  },
  {
    "year": "2017",
    "abstract": "Designing a well-generalized architecture for artificial neural networks (ANNs) is an important task. This paper presents an adaptive memetic algorithm with a rank-based mutation, denoted as AMARM, to design ANN architectures. The proposed algorithm introduces an adaptive multi-local search mechanism to simultaneously fine-tune the number of hidden neurons and connection weights. The adaptation of the multi-local search mechanism is achieved by identifying effective local searches based on their search characteristics. Such an algorithm is distinguishable from previous evolutionary algorithm-based methods that incorporate one single local search for evolving ANN architectures. Furthermore, a rank-based mutation strategy is devised for avoiding premature convergence during evolution. The performance of the proposed algorithm has been evaluated on a number of benchmark problems and compared with related work. The results show that the AMARM can be used to design compact ANN architectures with good generalization capability, outperforming related work."
  },
  {
    "year": "2017",
    "abstract": "Sharing the infrastructure of wireless sensor networks (WSNs) for achieving concurrent requests becomes a trend nowadays, where a relatively complex request should be satisfied through aggregating complementary functionalities provided by contiguous sensor nodes contained in a certain network region. To address this challenge, this paper proposes a multi-requests cooperative-integrating mechanism leveraging service-oriented WSNs. Specifically, a sensor node is encapsulated with one or multiple WSN services, which capture various functionalities provided by this sensor node. These WSN services can be categorized into service classes, where their functionalities are the main concern. Candidate service class chains are generated independently with respect to concurrent requests represented in plain text. The selection of candidate WSN services for the instantiation of certain service classes can be reduced to a multi-objective and multi-constraints optimization problem, where the spatial and temporal-constraints, and energy efficiency of the network, are the factors to be considered. This combinational optimization problem is solved through adopting heuristic algorithms. Experimental results show that this technique improves the shareability of WSN services among concurrent requests, and reduces the energy consumption of the network significantly, especially when the spatial, temporal, and functional overlap between concurrent requests is relatively large."
  },
  {
    "year": "2017",
    "abstract": "An accurate model is important for design and optimization control of centrifugal compressor. However, due to the varying operation conditions and the complexity of the flow dynamics inside it, establishing a satisfaction model of a new compressor is time and cost consuming. This paper proposes a rapid modeling method for centrifugal compressor based on model migration and support vector machines (SVMs). A general framework for centrifugal compressor model migration is given between two similar compressors, the base model of an existing old compressor is revised to fit for the new compressor by SVM using a small number of data. The effective of the proposed method is contrasted with pure SVM by a simulation case and the results show that, compared with the pure SVM, the migrated model can fit the new compressor faster with better accuracy, which is useful for reducing the cost and time in developing the model for new compressors."
  },
  {
    "year": "2017",
    "abstract": "There are two important aspects in human action recognition. The first one is how to locate the area that better indicates what the subjects in the videos are doing. The second one is how we can utilize the appearance and motion information from the video data. In this paper, we propose a gaze-assisted deep neural network, which performs the action recognition task with the help of human visual attention. Based on the above-mentioned consideration, we first collect a large number of human gaze data by recording the eye movements of human subjects when they watch the video. Then, we employ a fully convolutional network to learn to predict the human gaze. To efficiently utilize the human gaze, inspired by the rank pooling concept, which can encode the video into one image, we design a novel video representation named by dynamic gaze. The proposed dynamic gaze captures both the appearance and motion information from the video, and our human gaze data can better locate the area of interest. Based on the dynamic gaze, we build our dynamic gaze stream. We combine the proposed dynamic gaze stream together with the two-stream architecture as our final multi-stream architecture. We have collected over 300-k human gaze maps for the J-HMDB data set in this paper, and experiments show that the proposed multi-stream architecture can achieve comparable results with the state of the art in the task of action recognition with both collected human gaze data and predicted human gaze data."
  },
  {
    "year": "2017",
    "abstract": "In cloud storage systems, users can upload their data along with associated tags (authentication information) to cloud storage servers. To ensure the availability and integrity of the outsourced data, provable data possession (PDP) schemes convince verifiers (users or third parties) that the outsourced data stored in the cloud storage server is correct and unchanged. Recently, several PDP schemes with designated verifier (DV-PDP) were proposed to provide the flexibility of arbitrary designated verifier. A designated verifier (private verifier) is trustable and designated by a user to check the integrity of the outsourced data. However, these DV-PDP schemes are either inefficient or insecure under some circumstances. In this paper, we propose the first non-repudiable PDP scheme with designated verifier (DV-NRPDP) to address the non-repudiation issue and resolve possible disputations between users and cloud storage servers. We define the system model, framework and adversary model of DV-NRPDP schemes. Afterward, a concrete DV-NRPDP scheme is presented. Based on the computing discrete logarithm assumption, we formally prove that the proposed DV-NRPDP scheme is secure against several forgery attacks in the random oracle model. Comparisons with the previously proposed schemes are given to demonstrate the advantages of our scheme."
  },
  {
    "year": "2017",
    "abstract": "Non-orthogonal multiple access (NOMA) is promoted as a key component of 5G cellular networks. As the name implies, NOMA operation introduces intracell interference (i.e., interference arising within the cell) to the cellular operation. The intracell interference is managed by careful NOMA design (e.g., user clustering and resource allocation) along with successive interference cancellation. However, most of the proposed NOMA designs are agnostic to intercell interference (i.e., interference from outside the cell), which is a major performance limiting parameter in 5G networks. This paper sheds light on the drastic negativeimpact of intercell interference on the NOMA performance and advocates interference-aware NOMA design that jointly accounts for both intracell and intercell interference. To this end, a case study for fair NOMA operation is presented and intercell interference mitigation techniques for NOMA networks are discussed. This paper also investigates the potential of integrating NOMA with two important 5G transmission schemes, namely, full duplex and device-to-device communication. This is important since the ambitious performance defined by the third generation partnership project for 5G is foreseen to be realized via seamless integration of several new technologies and transmission techniques."
  },
  {
    "year": "2017",
    "abstract": "In a century where technology is rapidly shaping the way we communicate, travel, work, and live, the numbers of students studying the natural sciences (which are often perceived as more difficult) in both the high school and the university is on the decline. Many universities and schools have been addressing this lack of interest using a wide variety of engagement programs to encourage and retain students in science, technology, engineering and mathematics (STEM) disciplines. This paper describes a handson activity, LaserTag, that has been developed by the Department of Engineering at La Trobe University and has had thousands of high school participants over the last few years. During the activity, students solder together (and keep) electronic LaserTag devices, which they can use to shoot infrared light packets at each other to have their own skirmish activities. The effectiveness of the activity was measured based on anonymous student surveys evaluating students prior and post interest in engineering and the STEM disciplines. The survey results were very positive indicating 97% of the participants found the activity `highly enjoyable' or `enjoyable' and that 55% of students who were previously unsure about engineering as a career `strongly agreed' or `agreed' they were more interested in studying engineering as a result."
  },
  {
    "year": "2017",
    "abstract": "Content-centric networking (CCN) aims to improve network reliability, scalability, and security by changing the way that information is organized and retrieved in the current Internet. One critical issue in CCN is in-network cache allocation. It is known that in-network caching mechanisms are vulnerable to distributed denial of service attacks, especially to pollution attacks. That is, a caching mechanism under pollution attacks cannot work well. The past years witnessed kinds of proposals of cache allocation mechanisms. However, none of them could effectively allocate in-network cache while defending against attacks. In this paper, we propose a lightweight non-collaborative cache allocation approach (IFDD), which could not only enhance in-network caching performance in terms of the cache hit ratio and the request processing delay, but also defend against pollution attacks. By lightweight, we mean that IFDD generates low communication overhead (due to non-collaboration) and computational overhead at routers. The key idea behind IFDD is to combine the content popularity with the content locality in making caching decision. Extensive simulation results on ndnSIM platform demonstrate the capability of the proposed approach in improving cache allocation performance while reducing the impact of pollution attacks."
  },
  {
    "year": "2017",
    "abstract": "Machine-to-machine (M2M) communication is a system that allows information interaction between machines independently and automatically through a network without human intervention. However, when massive M2M devices access the network, they can quickly scramble preambles, and induce significant network congestion. Specially, when the massive M2M devices consist of delay tolerant devices (DTDs) and delay sensitive devices (DSDs), DSD success rate will decrease sharply. Therefore, this paper proposes a novel scheme of congestion reduction, Markov chain-based access class barring (M-ACB) to guarantee random access success for massive M2M devices that incorporate DTDs and DSDs, and ensure network resources are utilized efficiently. The proposed M-ACB scheme uses a 6D Markov chain to model preamble transfer status of preambles, and estimate the number of access devices for the next time slot. Dynamic regulation of barring factors and preserved DTD and DSD preamble is then applied based on the estimate. Simulation results validated the proposed M-ACB scheme for several key performance indicators, such as success rate, collision rate, time delay, and repeat times."
  },
  {
    "year": "2017",
    "abstract": "In multiband/multifunction radars, the received echoes are usually multiband signals consisting of several subbands with different carrier frequencies. Digital acquisition of the in-phase and quadrature (I and Q) components of each subband is important for the extraction of radar targets. However, the existing acquisition methods are inefficient because their sampling rates are at least twice of the effective bandwidth, also known as the Landau rate. In this paper, we merge the quadrature compressive sampling into the uniform sampling technique for multiband signals, and develop a multiband quadrature compressive sampling (MQuadCS) system. The MQuadCS system first applies the random modulation to generate a compressive multiband signal, and then utilizes the uniform sampling to output the samples of the compressive multiband signal at its Landau rate. As the Landau rate of the compressive multiband signal is much less than that of the received echo, the MQuadCS achieves the sub-Landau rate sampling. With the assumption of sparse targets, the I and Q components of each subband can be independently recovered by the corresponding samples separated from the compressive multiband samples. For the independent recovery, we establish the model of MQuadCS system parameters and provide a sufficient condition to ensure the existence of the system parameters. To guarantee successful recovery of each subband, we introduce the frequency domain representation of the MQuadCS and then derive the reconstructability condition via restricted isometry property analysis. Furthermore, we design a system parameter optimization scheme to improve the recovery performance. Theoretical analyses and simulations validate the efficiency of the MQuadCS system."
  },
  {
    "year": "2017",
    "abstract": "Calculating the minimal unsatisfiability-preserving sub-TBoxes (MUPS) for an unsatisfiable concept using the glass-box debugging method is a key reasoning service in ontology debugging. However, the glass-box method is limited as it can easily fall into an unnecessary expansion, especially in the process of non-deterministic expansion. An efficient method to solve this problem is to pre-select a set of relevant axioms involved in the unsatisfiability. For this purpose, we propose an optimization technique based on the unsatisfiable dependent path to avoid unnecessary expansion. The basic idea is to construct unsatisfiable dependent paths based on three basic conflict patterns and then obtain a conflict set from the unsatisfiable dependent paths. Accordingly, all the unsatisfiable concepts can be found and their MUPS can be calculated on the basis of the conflict set. Our experimental results show that the proposed method works well on real large-scale incoherent TBoxes."
  },
  {
    "year": "2017",
    "abstract": "An important goal of smart grid is to leverage modern digital communication infrastructure to help control power systems more effectively. As more and more Internet of Things (IoT) devices with measurement and/or control capability are designed and deployed for a more stable and efficient power system, the role of communication network has become more important. To evaluate the performance of control algorithms for inter-dependent power grid and communication network, a test bed that could simulate inter-dependent power grid and communication network is desirable. In this paper, we demonstrate the design and implementation of a novel co-simulator, which would effectively evaluate IoT-aided algorithms for scheduling the jobs of electrical appliances. There are three major features of our co-simulator: 1) large-scale test is achieved by distributed modules that are designed based on a Turing-indistinguishable approach; 2) remote servers or test devices are controlled by local graphical user interface (we only need to configure the simulator on a local server); 3) a software virtual network approach is employed to emulate real networks, which significantly reduces the cost of real-world test beds. To evaluate our co-simulator, two energy consumption scheduling algorithms are implemented. Experimental results show that our co-simulator could effectively evaluate these methods. Thus our co-simulator is a powerful tool for utility companies and policy makers to commission novel IoT devices or methods in future smart grid infrastructure."
  },
  {
    "year": "2017",
    "abstract": "We analyze the ergodic capacity of multiple-input multiple-output (MIMO) Rayleigh-fading relay channels. We first derive the probability density function of a sum of independent complex central Wishart matrices-called the central hyper-Wishart matrix-and its joint eigenvalue density. We then derive a trace representation for the max-flow min-cut upper bound on the ergodic capacity of general full-duplex MIMO relay channels where each communicating node is equipped with N antennas and has access only to respective receive channel state information. We also establish the Schur monotonicity theorem for this cutset bound as a functional of the signal-to-noise ratios (SNRs) of three communication links. We further characterize the exact ergodic capacity in the regularity SNR regime where the upper and lower bounds coincide."
  },
  {
    "year": "2017",
    "abstract": "This paper reports a wireless passive resonator architecture that is used as a fiducial electronic marker (e-marker) intended for internal marking purposes in magnetic resonance imaging (MRI). As a proof-of-concept demonstration, a class of double-layer, sub-cm helical resonators were microfabricated and tuned to the operating frequency of 123 MHz for a three T MRI system. Effects of various geometrical parameters on the resonance frequency of the e-marker were studied, and the resulting specific absorption rate (SAR) increase was analyzed using a full-wave microwave solver. The B1+field distribution was calculated, and experimental results were compared. As an exemplary application to locate subdural electrodes, these markers were paired with subdural electrodes. It was shown that such sub-cm self-resonant e-markers with biocompatible constituents can be designed and used for implant marking, with sub-mm positioning accuracy, in MRI. In this application, a free-space quality factor (Q-factor) of approximately 50 was achieved for the proposed resonator architecture. However, this structure caused an SAR increase in certain cases, which limits its usage for in vivo imaging practices. The findings indicate that these implantable resonators hold great promise for wireless fiducial e-marking in MRI as an alternative to multimodal imaging."
  },
  {
    "year": "2017",
    "abstract": "In order to solve the segmentation degradation phenomenon when the number of super pixels is low, we propose a novel color image segmentation algorithm based on GrabCut. The method integrates Bayes classification with simple linear iterative clustering (SLIC) and then use the GrabCut method to obtain the segmentation. The SLIC is applied to cluster the features of a color image and integrated it into the GrabCut framework to overcome the problem of the image segmentation deterioration when the number of super pixels is low. In addition, we extend the Gaussian mixture model (GMM) to SLIC features and GMM based on SLIC is constructed to describe the energy function. The color clustering can be suitably integrated into the GrabCut framework and fused with the color feature to achieve more superior image segmentation performance than the original GrabCut method. For easier implementation and more efficient computation, the Bayes classification is chosen for reconstruction of the simplified graph cut model instead of the original graph cut based on the SLIC model. The min-cut algorithm technique served as the division measure in the simplified image space for more discriminating power. A classification strategy is presented, to effectively adjust the energy function so that the Bayes classification and SLIC features are efficiently integrated to achieve more robust segmentation performance. Finally, boundary optimization is proposed to dramatically reduce the boundary roughness of the GrabCut algorithm with satisfactory segmentation accuracy. As a practical application, the superior performance of our proposed method was demonstrated through a large number of comparative tests."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Vehicle (IoV) utilizes networks to conduct message exchange and related services or application. In recent years, smart cities and IoVs have become areas of interest in the new generation Internet of Things development, especially since the development of intelligent transportation system has focused on bettering traffic conditions. This paper proposes establishing an intelligent transportation system with a network security mechanism in an IoV environment, with emphasis on the following aspects: 1) this paper integrates intelligent transportation systems in traffic signal control to aid emergency vehicles in more promptly arriving at its destination; 2) in the case of traffic incidents, this paper's approach allows regular vehicles to obtain proof of incident from pertaining authorities and learn about nearby vehicles global positioning system information, such as position and speed, and utilize their car camcorder data for proving purposes; and 3) this paper combines roadside units (RSUs) with traffic signal control and transmits important information to the certificate authority (CA) for storage. Given that RSUs are limited in computation ability and storage space, we can assess and filter the information before sending it to the CA, reducing RSUs computational burden and storage space usage. This paper satisfies IoVs network security requirements of authentication, non-repudiation, conditional anonymity, and conditional untraceability, and, as seen from experiment results, the proposed method is superior to that of other studies."
  },
  {
    "year": "2017",
    "abstract": "Device-to-device (D2D) communications achieve a considerable proximate gain by means of single hop, which can improve the link spectrum efficiency of cellular networks by reusing the shortage licensed spectrum. However, co-channel interference will become a serious challenge that will influence the performance of both D2D and cellular links if it cannot be processed appropriately. The existing solutions are limited to single radio access technology (RAT), and they all involve tradeoffs between the available terminal density and the link spectrum efficiency. In this paper, we propose the offloading scheme of D2D communications on multi-RATs, which can achieve high link spectrum efficiency without sacrificing the available terminal density. The multi-RATs offloading scheme will achieve maximum link spectrum efficiency with the retention probability as a parameter that is formulated for a non-convex function. Considering the main factor of different scenarios that refer to high and sparse available terminal densities, we propose the dynamic adjustment offloading algorithm and the sparse-density optimization offloading algorithm to solve the non-convex problem. In addition, because we use the closed form of the stochastic geometry, the optimum offloading algorithms possess predictable features that do not break the established D2D links when a new link is applied. Finally, the simulation results show that the performance of the coverage probability and link spectrum efficiency is both greatly improved compared with the traditional D2D communications without exploiting the offloading scheme. More significantly, the spectrum efficiency of cellular links is also improved effectively due to the offloading effect."
  },
  {
    "year": "2017",
    "abstract": "The new training plans of the European Higher Education Area recommend the implementation of new teaching methods, which poses new challenges. Different teaching methods have produced successful results by applying collaborative methodologies. This paper evaluates adapting a collaborative methodology for engineering project subjects at a university school of engineering. A statistical analysis that employs a multifactor analysis of variance was performed to identify the factors that influence the success of implementing this approach in engineering project subjects. The results indicate that the size of the group is the most influential factor in implementing a collaborative methodology. With an analytic hierarchy process, a value function was defined to compare the behavior of the proposed collaborative methodology with the behaviors of other methodologies. Using this value function, the results of the proposed collaborative methodology were compared with those of lectures. Relating the comparison criteria to the skills that are acquired by the project subjects, better results are observed with the collaborative methodology."
  },
  {
    "year": "2017",
    "abstract": "The problem of output regulation for a class of cascade switched nonlinear systems is investigated in this paper. Sufficient conditions for the problem to be solvable are given using the average dwell time method and the multiple Lyapunov function method. The problem for each subsystem to be solvable and may not be solvable are discussed, respectively. The main results are obtained based on full information feedback and error feedback. In addition, the method of designing the switched law is also presented in this paper. Finally, the simulation examples show that the results are very effective."
  },
  {
    "year": "2017",
    "abstract": "To deal with the increasing load demand and environmental effects of conventional power devices, power system has become an enlarged complex network with the integration of distributed generators. Real-time control of power system now needs a massive amount of information to be transmitted between each local device and the central controller. The transmission of a huge quantity of information data poses great challenge to the communication network. To deal with this issue in reactive power control, this paper proposes a novel real-time compressive sensing-based optimal reactive power control of a multi-area interconnected power system. The objective is to minimize the power loss, voltage deviation, and reactive power generation cost simultaneously. According to the proposed scheme, the measured data in each control area is compressed before being transmitted through the communication network, and then recovered accurately by the discrete central controller. Orthogonal matching pursuit algorithm is adopted to recover the compressed data, owing to its fast convergence speed. Simulation results demonstrate the effectiveness of the proposed compressive sensing-based approach by significantly reducing the data size of the transmitted data."
  },
  {
    "year": "2017",
    "abstract": "In wireless sensor networks, it is a typical threat to source privacy that an attacker performs backtracing strategy to locate source nodes by analyzing transmission paths. With the popularity of the Internet of Things in recent years, source privacy protection has attracted a lot of attentions. In order to mitigate this threat, many proposals show their merits. However, they fail to get the tradeoff between multipath transmission and transmission cost. In this paper, we propose a constrained random routing mechanism, which can constantly change routing next-hop instead of a relative fixed route so that attackers cannot analyze routing and trace back to source nodes. First, we design a specific selection domain which is located around the sending node according to the dangerous distance and the wireless communication range. Then sending nodes calculate the selected weights of the candidate nodes according to their offset angles in this domain. Finally, the selected weights help to decide which node will become the next hop. In this way, attackers would be confused by the constantly changing paths. The simulation results prove that our proposal can achieve high routing efficiency in multi-path transmission, while only introducing a controllable energy consumption, end-to-end delay and redundant paths."
  },
  {
    "year": "2017",
    "abstract": "Two-switch buck-boost (TSBB) is one of the non-isolated dc-to-dc converters that can change its mode from among buck, boost, and buck-boost modes. Changing its mode is possible by controlling gate signals. This paper presents a novel modified topology of TSBB converter. Even if the proposed converter has the same number of components as a conventional TSBB converter, the proposed converter has fewer conduction components and switching semiconductors than a conventional TSBB. This results in reduced power loss. Moreover, source terminals of metal-oxide-semiconductor field-effect transistor in the proposed converter are directly connected to ground. This configuration has an advantage in selecting gate driver integrated circuit (IC), since the IC does not necessarily need to provide high-side gate signals. A printed circuit board was designed to evaluate the improvement of the proposed converter."
  },
  {
    "year": "2017",
    "abstract": "Millimeter wave exhibits relatively straight propagation as well as high penetration into dielectric materials, such as plastics, cloth, and paper. In security imaging, we use these features to discover weapons concealed under clothes. Self-organizing map (SOM), a type of neural networks, can map highdimensional data on any dimension with unsupervised learning. It is utilized for clustering and visualization of high-dimensional data. Previously, we proposed a millimeter-wave imaging system for moving targets consisting of a 1-D array antenna, a parallel front end, and a complex-valued SOM to deal with complex texture. Experiments demonstrated its high performance in the visualization. In this paper, we investigate the dependence of the visualization performance on its configuration parameters as well as processing parameters. We reveal the effect of the modulation-frequency number and the window size. We also discuss the effective depth range for visualization and a tradeoff relationship between the measurement time and the visualization quality."
  },
  {
    "year": "2017",
    "abstract": "Disastrous events are cordially involved with the momentum of nature. As such mishaps have been showing off own mastery, situations have gone beyond the control of human resistive mechanisms far ago. Fortunately, several technologies are in service to gain affirmative knowledge and analysis of a disaster's occurrence. Recently, Internet of Things (IoT) paradigm has opened a promising door toward catering of multitude problems related to agriculture, industry, security, and medicine due to its attractive features, such as heterogeneity, interoperability, light-weight, and flexibility. This paper surveys existing approaches to encounter the relevant issues with disasters, such as early warning, notification, data analytics, knowledge aggregation, remote monitoring, real-time analytics, and victim localization. Simultaneous interventions with IoT are also given utmost importance while presenting these facts. A comprehensive discussion on the state-of-the-art scenarios to handle disastrous events is presented. Furthermore, IoT-supported protocols and market-ready deployable products are summarized to address these issues. Finally, this survey highlights open challenges and research trends in IoT-enabled disaster management systems."
  },
  {
    "year": "2017",
    "abstract": "In recent years, the Internet has become an indispensable part of people's lives, and it offers increasingly comprehensive information tailored to people's personal preferences as well as commodity attribute information. Consequently, many researchers have used external information to improve recommendation technology. However, most previous studies consider only adding single relationship types, such as social networking friend-relationships. In the real world, considering multiple types of external relations can more accurately determine the reason why a user selected an item. To address this problem, in this paper, we propose a hybrid method called the semantic preference-based personalized recommendation on heterogeneous information networks (SPR), which combines user feedback scores with heterogeneous information networks. This method can improve recommendation problems by considering multiple types of external relationships. To apply the method, we first introduce a similarity measure between users based on a user's potential preferences in the meta-path and design the recommended model at the global and individual level. Finally, we perform experiments on two real-world data sets, finding that the SPR method achieves better results compared with the several widely employed and the state-of-the-art recommendation methods."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a new joint cooperative beamforming and jamming (JCBJ) scheme for improving the physical layer security of decode-and-forward wireless networks where a source node transmits to its destination with the aid of multiple intermediate nodes in the presence of an eavesdropper. In the proposed JCBJ scheme, we select the intermediate nodes succeeding in source decoding as the relays to forward the source transmission simultaneously by employing a beamforming weight vector, and meanwhile, use the remaining ones as the friendly jammers to disturb the eavesdropper by sending artificial noise. In order to achieve the secrecy rate maximum, we further study on the power allocation among the source, relays, and jammers under two assumptions of the wiretap link's channel state information. We derive the closed-form optimal solutions by first allocating the transmit power at the source within different ranges to consider all the possible relay selection schemes in which different numbers of relays are employed, and then transforming the multivariable power allocation problem to a set of single-variable optimization subproblems. Our numerical results show the superiority of the proposed JCBJ scheme and the proposed power allocation strategies."
  },
  {
    "year": "2017",
    "abstract": "Finite control set-model predictive control (FCS-MPC) has been used in power converters due to its advantages, such as fast dynamics, multi-objective control, and easy implement. However, due to variable switching frequency, the harmonics of inverter output current spread in a wide range of frequency. Furthermore, a large amount of computation is required for the implementation of the traditional FCS-MPC method. Here, an improved FCS-MPC algorithm with fast computation and fixed switching frequency is proposed in this paper for two-level three-phase inverters. First, according to the principle of deadbeat control, the inverter voltage vector reference can be constructed. Then, the operation durations and sequences of different voltage vectors are determined according to the location of the inverter voltage vector reference and the cost functions of different voltage vectors. In this algorithm, the operation durations of different voltage vectors are arranged inversely proportional to their cost functions. Compared with the conventional fixed switching frequency FCS-MPC control, the number of sectors involved in the FCS-MPC calculation can be reduced from 6 to 1, which greatly improves the computation efficiency. Moreover, the delay due to digital implementation is effectively compensated in the proposed algorithm. Finally, experimental tests are carried out to verify the advantages of the proposed method in terms of both steady-state and dynamic performance."
  },
  {
    "year": "2017",
    "abstract": "Visible light communication (VLC) builds upon the idea of using existing lighting infrastructure for wireless data transmission. In a conventional VLC network, each light fixture acts as an access point (AP) which are connected to each other through electrical grid as well as data backbone. These VLC-enabled fixtures consist baseband unit (BBU) followed by the optical front-end (OFE). In this paper, we propose the so-called centralized light access network (C-LiAN) which aggregates all AP computational resources into a central pool that is managed by a centralized controller. Unlike the distributed architecture where each light fixture performs both baseband processing and optical transmission/reception, the centralized architecture employs “dummy”fixtures with a VLC OFE. Moving the baseband processing to a central pool reduces the associated cost and complexity of each VLC-enabled LED luminary. It further enables joint processing of signals from different APs making possible an efficient implementation of joint processing, offloading, handover, interference management, scheduling, and resource management algorithms. As an example to demonstrate the virtues of C-LiAN, we further present the performance of coordinated multipoint transmission and enhanced inter-cell interference coordination with almost blank subframe techniques originally proposed for Long Term Evolution-Advanced in the context of indoor VLC networks."
  },
  {
    "year": "2017",
    "abstract": "A numerical study is presented in this paper based on semiconductor laser chaos generation which is being used to hide multi-level data signal, i.e., duo-binary message to take the advantage of secure environment & higher data rates at the same time. Duobinary message is generated by using the combination of duobinary precoder, duobinary generator & RZ/NRZ pulse generator. Laser rate equations are used to model chaos generation through semiconductor laser whereas message is made secured by hiding it through chaos masking scheme. Propagation of chaos hiding the multi-format message is studied for long distance communication model. Synchronization between transmitter & receiver is achieved to obtain the acceptable eye-diagrams & quality factor (Q-factor). Q-factor is function of optical signal to noise ratio (OSNR) that gives a qualitative performance of receiver. It provides the minimum SNR to obtain specific bit error rate of signal. A comparison is made with & without deployment of chaos masking scheme on RZ & NRZ duobinary optical system to observe the penalty in terms of Q-factor. In addition, response of amplifier on chaotic signal due to its nonlinearities is investigated by varying the gain of amplifier."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an algorithm for timing synchronization, cell identity detection, and carrier frequency offset (CFO) estimation is presented for long-term evolution (LTE) systems. The proposed algorithm is robust against partial-band interference and/or jamming. It utilizes adaptive filtering to suppress the contribution of the jamming signal to the timing detection metric without using any a priori knowledge of the jamming signal characteristics. The timing detection metric is computed by minimizing the output of the adaptive filter corresponding to any received signal that does not match the signature of the LTE primary synchronization signals (PSS). The filter coefficients are updated iteratively using the recursive least squares algorithm. The frequency response of the adaptive filter at the PSS detection instant is used to weight the contribution of different subcarriers to the metrics used in cell identity detection and CFO estimation. Simulation results are presented showing the ability of the proposed algorithm to complete the synchronization process successfully even in the presence of partial-band jamming signals that cover one third of the frequency band of the LTE synchronization signals."
  },
  {
    "year": "2017",
    "abstract": "An improved multi-carrierM-ary differential chaos shift keying (MM-DCSK) system is presented, where differential modulation and demodulation are carried out across multiple carriers in the frequency domain, so channel estimation is not needed. For one data frame transmission, only one non-information-bearing reference sub-carrier signal is required, and the reference of each information-bearing sub-carrier is its previous sub-carrier signal, thus high energy efficiency is attained. If channel response changes during a frame period, the time diversity is achieved. In addition, the peak-to-average power ratio (PAPR) is considered, and it is found that adjacent symbols with a large Euclidean distance achieve a low PAPR. Accordingly, a low-complexity PAPR reduction algorithm is proposed based on symbol-interleaving with only one inverse fast Fourier transform processor. The simulation results demonstrate that the system with the proposed algorithm dramatically reduces the PAPR. Analytical bit-error-rate expressions are derived and verified by simulations over additive white Gaussian noise and multi-path fading channels."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we have performed a comprehensive analysis of the gate-induced drain leakage (GIDL) in emerging nanotube (NT) and nanowire (NW) FET architectures. We demonstrate that the additional lateral band-to-band-tunneling (L-BTBT) in the NTFETs owing to the core gate increases their OFF-state current compared with the NWFETs. The increased L-BTBT results in a significantly degraded performance of NTFETs when the gate lengths are scaled to the sub-10-nm regime. Therefore, the enhanced gate control offered by the NT architecture is detrimental from L-BTBT GIDL perspective. We show that although the core gate leads to a considerable increase in the gate capacitance of NTFETs, their dynamic performance improves compared with NWFETs due to the enhanced effective drive current owing to the NT architecture. In addition, we also provide the necessary design guidelines for the NTFETs and NWFETs with respect to spacer dielectric constant, intrinsic material bandgap, effective oxide thickness, supply voltage, and NT diameter from L-BTBT GIDL perspective."
  },
  {
    "year": "2017",
    "abstract": "Developing simple, economic, and efficient electrical power conversion systems for wave energy converters (WECs) is an on-going research topic. This paper considers a simple resonance circuit to maximise the ac-dc power conversion of a permanent magnet linear generator (PMLG). To implement this circuit, the PMLG model parameters were obtained. In this paper, we developed a procedure for designing a two-sided planar PMLG considering the corresponding physical parameters. For this method, we set the basic parameters and calculated the derived parameters for the PMLG. The resonance circuit was composed of a three-phase rectifier with a shunt connection of capacitors between its diodes. The value of the capacitors was calculated using the resonance principle at a specific dominant frequency obtained from the location of the WEC installation. We compared the performance of the proposed resonance circuit with that of an existing resonance circuit. The proposed circuit generates more power, requires fewer components, and presents fewer harmonics. In addition, a higher-quality damping force was obtained when using the PMLG connected to the proposed resonance circuit and a resistive load."
  },
  {
    "year": "2017",
    "abstract": "In complex industrial processes, the knowledge has properties of multi-source heterogeneity, polymorphism, and uncertainty. When the conventional knowledge representation methods are used to represent this type of knowledge, they often result in misunderstanding, inexplicability, and ambiguity. To solve this problem, a semantic network based on intuitionistic fuzzy directed hyper-graphs (SN-IFDHGs) model is proposed. First, qualitative knowledge is transformed to quantitative knowledge using an intuitionistic fuzzy algorithm. In the SN-IFDHG model, an edge set can connect multiple vertexes, which mean multi-source knowledge elements. Meanwhile, to present uncertain knowledge, the weights between semantic nodes are characterized by simultaneously containing both membership and non-membership. Then, to reduce the space complexity and facilitate the reconstruction of the SN-IFDHG model, a novel storage structure based on in-degree index list is proposed. Finally, a knowledge reasoning method based on entropy weight of SN-IFDHG is proposed and applied to aluminum electrolysis cell condition identification. The experimental results show that the proposed knowledge reasoning method is more effective and accurate than other existing algorithms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a wideband circularly polarized cylindrical shaped dielectric resonator antenna (DRA) with simple microstrip feed network has been designed and investigated. The proposed design uses dual vertical microstrip lines arranged in a perpendicular fashion to excite fundamental orthogonal hybrid HExIIδ and HEyIIδ modes in the cylindrical DR. The Phase quadrature relationships between orthogonal modes have been attained by varying corresponding microstrips heights. To ratify the simulation results, an antenna prototype is fabricated and measured. Measured input reflection coefficient and axial ratio bandwidth (at Φ = 0°, θ = 0°) of 30.37% (2.82-3.83 GHz) and 24.6% (2.75-3.52 GHz) has been achieved, respectively. This antenna design achieves an average gain of 5.5 dBi and radiation efficiency of above 96% over operational frequency band. Justifiable agreement between simulated and fabricated antenna results are obtained."
  },
  {
    "year": "2017",
    "abstract": "To improve low-latency computing and communication services, a new type of mobile edge computing architecture named multi-layer cloud radio access network (Multi-layer CRAN) is designed in this paper. In Multi-layer CRAN, a high-level edge cloud is deployed next to base band unit pool to handle the computing tasks of user equipment (UE) in centralized way. Meanwhile, a low-level edge cloud is deployed in each remote radio head (RRH) to locally handle UEs' computing tasks in a distributed way. Based upon Multi-layer CRAN, a cooperative communication and computation resource allocation (3C-RA) algorithm is further designed for lower service latency and energy cost, and higher network throughput in this paper. 3C-RA utilizes a distributed RRH cell coloring algorithm to enable each RRH to work out the resource allocation in an efficient and distributed way. 3C-RA employs a proportional fairness-based approach to allocate communication and computation resource in each RRH cell. A series of simulations on Multi-layer CRAN with 3C-RA were carried out. The simulation results validate that Multi-layer CRAN is more capable of providing low-latency computing and communication services, and 3C-RA enables Multi-layer CRAN to have lower service latency and energy cost and higher network throughput."
  },
  {
    "year": "2017",
    "abstract": "One of the notable aspects of public safety applications in 5G networks is location awareness, which is a feature of contemporary technology that imparts details about a user`s geographical location to another user or application. Mobile users take their cell phones and other gadgets with them almost everywhere. Thus, integrating location awareness in mobile applications gives users a much more real experience. Therefore, this paper presents an algorithm to predict user location in 5G networks by using received signal strength measurements. Initially, the relative coordinates of users are computed using Isomap. Then the relative coordinates of users are transformed by Procrustes analysis. In order to evaluate the performance of the proposed algorithm, the Cramer-Rao lower bound is derived, which is the lower bound on error variance. It can be concluded from our results that the proposed approach outperforms those found in the existing literature."
  },
  {
    "year": "2017",
    "abstract": "Driving distraction is a topic of great interest in the transport safety-research community, because it is now a primary cause of road accidents. A recent report has revealed that distraction is more alarming than previously thought, and a suitable measurement to effectively detect distraction is required. Most agree that driving distraction actually comprises the simultaneous interaction of two or more types of distraction. The purpose of this paper is, therefore, to determine the promising method for measuring visual cognitive distraction. We discuss the five common measurement methods for visual and cognitive driving distraction, which include driving performance, driver physical measures, driver biological measures, subjective reports, and hybrid measures. Hybrid measurement of driver's physical measures (e.g., eye movement) and driver's biological measures (e.g., electroencephalogram) is better than other methods at detecting types of visual cognitive distraction. This new perspective on measurement methods will help the field of transport safety to determine the best means of detecting and measuring the effect of visual cognitive distraction."
  },
  {
    "year": "2017",
    "abstract": "Eye movement is proven to be the most frequent activities of human beings; as a result research on recognition of unit eye movement has become a hotspot in human activity recognition. In this paper, we propose a robust online saccade recognition algorithm, which integrates electrooculography (EOG) and video together. Initially, EOG signals and video data are collected simultaneously from eight saccadic directions. Then online active eye movement segment detection algorithm is developed to detect the effective saccadic signal from ongoing eyeball activities. Furthermore, we extract features from different modalities and explore two fusion strategies [i.e., feature level fusion (FLF) and decision level fusion (DLF)]. In laboratory environment, the average recognition accuracy of FLF and DLF achieves 89.37% and 89.96%, respectively, which reveals that the proposed method can improve the performance of consecutive saccade recognition in comparison with sole modality."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes three game-theoretic approaches for coalition formation in cooperative networks with simultaneous wireless information and power transfer. To improve the reception reliability of destinations with poor channel conditions, we first divide destinations in the network into two types: Type I and Type II. Type I destinations refer to the destinations with capability of successful information decoding and energy harvesting, which serve as relays to help other destinations. Type II destinations have poor connections to the source and hence compete to obtain help from Type I destinations. Accordingly, cooperative relaying strategies for the two types of destinations are proposed on the basis of coalition formation game. First, we propose to utilize the dynamic programming (DP) approach to obtain the optimal coalition structure in the network, though at the cost of heavy time and storage complexity. Then, two distributed hedonic coalition formation (DHCF) approaches are developed to generate coalition structures, which are more efficient than the DP approach. Simulation results show that all proposed approaches outperform the non-cooperative one (i.e., direct link transmission). The results also illustrate that the DP approach achieves the largest data rate and lowest outage probability for destinations, and the DHCF approaches achieve near-to-optimal performance."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the fault ride through (FRT) capability improvement of a doubly fed induction generator (DFIG)-based wind turbine using a dynamic voltage restorer (DVR). Series compensation of terminal voltage during fault conditions using DVR is carried out by injecting voltage at the point of common coupling to the grid voltage to maintain constant DFIG stator voltage. However, the control of the DVR is crucial in order to improve the FRT capability in the DFIG-based wind turbines. The combined feed-forward and feedback (CFFFB)-based voltage control of the DVR verifies good transient and steady-state responses. The improvement in performance of the DVR using CFFFB control compared with the conventional feed-forward control is observed in terms of voltage sag mitigation capability, active and reactive power support without tripping, dc-link voltage balancing, and fault current control. The advantage of utilizing this combined control is verified through MATLAB/Simulink-based simulation results using a 1.5-MW grid connected DFIG-based wind turbine. The results show good transient and steady-state response and good reactive power support during both balanced and unbalanced fault conditions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the robust power allocation issue in orthogonal frequency division multiplexing-based cognitive radio networks (CRNs) with unavoidable uncertainties (channel perturbations and variable environment). In this case, to control the performance degradation due to the uncertainties, we maximize the data rate of secondary users (SUs) by considering maximum allowable interference constraints and total power budget of SUs. To solve this problem, we design a controller for a switched affine system with state constraint. This system is based on a distributed projected dynamic system in accordance with the classical distributed convex optimization model for the power allocation and dynamic property of the Nash equilibrium. The robust controller design is on the basis of Lyapunov stability theory and linear matrix inequality to better realize the original power allocation from the control perspective. To the best of our knowledge, we are the first to solve the aforementioned problem by this kind of approach under the control frame, which is more practical for the realization in CRNs. Simulation results are provided to show the validation of the effectiveness of this approach in comparison with iterative water filling algorithm and the worst-case method."
  },
  {
    "year": "2017",
    "abstract": "Mobile learning (m-learning) is increasingly becoming a popular global trend, especially among English language learners. However, despite the growing interest in mobile English language learning, there have been no reviews of research conducted on this subject. This paper represents the first attempt to provide a comprehensive analysis of the existing literature (2010-2015) to identify the taxonomy and distribution of research as well as to identify the advantages and challenges and provide some recommendations to facilitate the effective use of mobile English language learning and its applications. Following a review protocol, articles on mobile English language learning from six major databases (IEEE Xplore, ScienceDirect, Web of Science, ERIC, SpringerLink, and Wiley Online Library) were reviewed. Applying inclusion and exclusion criteria, 133 related articles were identified. The results show that the majority of studies were conducted on application m-learning technologies. Pure mobile applications were the most widely-used applications in the English m-learning context. Meanwhile, concerns regarding quality, usability, integration, financial costs, security and privacy, pedagogical practice, and safety were found to be the main challenges of mobile English language learning. Finally, some recommendations are provided for users, developers/providers, and researchers. The results of this paper can assist users, researchers, policymakers, and practitioners in the education sector to allocate the necessary resources and make plans to mitigate the challenges and facilitate the effective use of mobile English language learning in educational practices."
  },
  {
    "year": "2017",
    "abstract": "Spectrum sharing based on the dedicated databases, particularly in the context of TV band, is widely considered as a promising tool for better spectrum utilization in the future wireless networks. Practical realization of this paradigm entails the need for the true protection of the incumbent system, and at the same time the guarantee of the quality of the services offered to the secondary users. In this respect, this paper discusses the results achieved in numerous measurement campaigns performed for last years in two European cities, i.e., Poznan, Poland, and Barcelona, Spain. Both indoor and outdoor measurements of the TV band have been compared with the main purpose of true identification of key practical considerations for spectrum sharing in the TV white spaces. As such, this paper constitutes a concise summary of various analyses and provides pragmatic guidelines for deployment of radio-environment maps (REM)-based systems. Based on the conducted measurements and achieved results, the set of practical conclusions for REMs has been deduced, and the prospective procedure of deployment of such a network has been proposed."
  },
  {
    "year": "2017",
    "abstract": "A low profile differential-fed dual-polarized microstrip patch antenna (MPA) with bandwidth enhancement is proposed under radiation of the first and second odd-order resonant modes. First, all of even-order modes are fully suppressed by using a differentially feeding scheme instead of the single probe feed. Next, the radiation pattern of a square MPA is theoretically analyzed. It is demonstrated that the traditional monopole-like radiation of the second odd-order mode in the H-plane, i.e., TM21mode, can be transformed into the broadside radiation by etching out a narrow slot at the center of the radiating patch. After that, an array of shorting pins is symmetrically embedded underneath the radiating patch so as to progressively push up the resonant frequency of the TM01mode (or TM10mode), while almost maintaining that of TM21mode (or TM12mode) to be unchanged. With these arrangements, a wide impedance bandwidth with stable radiation peak in the broadside direction is achieved for the MPA under this dual modes operation. Finally, the dual-polarized MPA is fabricated and measured. The measured results are found in good agreement with the simulated ones in terms of the reflection coefficient, radiation pattern, and realized gain, demonstrating that the MPA's impedance bandwidth (|Sdd11| <; -10 dB) is tremendously increased up to about 8% with a high differential port-to-port isolation of better than 22.6 dB. In particular, a low profile property of about 0.024 free-space wavelength and the stable radiation pattern are also achieved."
  },
  {
    "year": "2017",
    "abstract": "Measuring perceived quality of audio-visual signals at the end-user has become an important parameter in many multimedia networks and applications. It plays a crucial role in shaping audio-visual processing, compression, transmission and systems, along with their implementation, optimization, and testing. Service providers are enacting different quality of service (QoS) solutions to issue the best quality of experience (QoE) to their customers. Thus, devising precise perception-based quality metrics will greatly help improving multimedia services over wired and wireless networks. In this paper, we provide a comprehensive survey of the works that have been carried out over recent decades in perceptual audio, video, and joint audio-visual quality assessments, describing existing methodologies in terms of requirement of a reference signal, feature extraction, feature mapping, and classification schemes. In this context, an overview of quality formation and perception, QoS, QoE as well as quality of perception is also presented. Finally, open issues and challenges in audio-visual quality assessment are highlighted and potential future research directions are discussed."
  },
  {
    "year": "2017",
    "abstract": "Recently, a large number of multi-objective evolutionary algorithms (MOEAs) for many-objective optimization problems have been proposed in the evolutionary computation community. However, an exhaustive benchmarking study has never been performed. As a result, the performance of the MOEAs has not been well understood yet. Moreover, in almost all previous studies, the performance of the MOEAs was evaluated based on nondominated solutions in the final population at the end of the search. Such traditional benchmarking methodology has several critical issues. In this paper, we exhaustively investigate the anytime performance of 21 MOEAs using an unbounded external archive (UEA), which stores all nondominated solutions found during the search process. Each MOEA is evaluated under two optimization scenarios called UEA and reduced UEA in addition to the standard final population scenario. These two scenarios are more practical in real-world applications than the final population scenario. Experimental results obtained under the two scenarios are significantly different from the previously reported results under the final population scenario. For example, results on the Walking Fish Group test problems with up to six objectives indicate that some recently proposed MOEAs are outperformed by some classical MOEAs. We also analyze the reason why some classical MOEAs work well under the UEA and the reduced UEA scenarios."
  },
  {
    "year": "2017",
    "abstract": "This paper considers secrecy of a three node cooperative wireless system in the presence of a passive eavesdropper. The threshold-selection decode-and-forward relay is considered, which can decode the source message correctly only if a predefined signal-to-noise ratio (SNR) is achieved. The effects of channel state information (CSI) availability on secrecy outage probability (SOP) and ergodic secrecy rate (ESR) are investigated, and closed-form expressions are derived. Diversity is achieved from the direct and relaying paths both at the destination and at the eavesdropper by combinations of maximal-ratio combining and selection combining schemes. An asymptotic analysis is provided when each hop SNR is the same in the balanced case and when it is different in the unbalanced case. The analysis shows that both hops can be a bottleneck for secure communication; however, they do not affect the secrecy identically. While it is observed that CSI knowledge can improve secrecy, the amount of improvement for SOP is more when the required rate is low and for ESR when the operating SNR is also low. It is also shown that the source to eavesdropper link SNR is more crucial for secure communication."
  },
  {
    "year": "2017",
    "abstract": "Using FPGA-based acceleration of high-performance computing (HPC) applications to reduce energy and power consumption is becoming an interesting option, thanks to the availability of high-level synthesis (HLS) tools that enable fast design cycles. However, obtaining good performance for memoryintensive algorithms, which often exchange large data arrays with external DRAM, still requires timeconsuming optimization and good knowledge of hardware design. This article proposes a new design methodology, based on dedicated applicationand data array-specific caches. These caches provide most of the benefits that can be achieved by coding optimized DMA-like transfer strategies by hand into the HPC application code, but require only limited manual tuning (basically the selection of architecture and size), are neutral to target HLS tool and technology (FPGA or ASIC), and do not require changes to application code. We show experimental results obtained on five common memory-intensive algorithms from very diverse domains, namely machine learning, data sorting, and computer vision. We test the cost and performance of our caches against both out-of-the-box code originally optimized for a GPU, and manually optimized implementations specifically targeted for FPGAs via HLS. The implementation using our caches achieved an 8X speedup and 2X energy reduction on average with respect to out-of-the-box models using only simple directive-based optimizations (e.g., pipelining). They also achieved comparable performance with much less design effort when compared with the versions that were manually optimized to achieve efficient memory transfers specifically for an FPGA."
  },
  {
    "year": "2017",
    "abstract": "Powerful smart terminals with rich set of embedded sensors promote the development of the Internet of Things (IoTs). Mobile crowdsensing systems (MCSs) can be formed by these mobile smart terminals from IoTs to collect and exchange data. The main idea of MCSs is to outsource sensing tasks (collecting data) to various mobile devices which are carried by people or vehicles. The design of incentive mechanisms in MCSs is one of the hottest current research topics. However, most of the existing studies focus on maximizing the utilities or social welfare while neglecting the practical requirements of MCSs surveillance applications. In this paper, we discuss the importance of fairness and unconsciousness of MCS surveillance applications. Then, we propose offline and online incentive mechanisms with fair task scheduling based on the proportional share allocation rules. Furthermore, to have more sensing tasks done over time dimension, we relax the truthfulness and unconsciousness property requirements and design a (ε, μ)-unconsciousness online incentive mechanism. Real map data are used to validate these proposed incentive mechanisms through extensive simulations."
  },
  {
    "year": "2017",
    "abstract": "Hydro-pneumatic suspension systems have been widely used in many fields for their variable stiffness characteristics that effectively improve the comfort and operation stability of a vehicle. However, due to poor environmental conditions, hydro-pneumatic suspension is frequently subjected to the influence of transient impact and environmental temperature changes, which results in sealing failure and gas leakage problems and reduces the reliability of the system. In this paper, a method combining parametric modeling and probability analysis is adopted to establish the reliability model of a hydro-pneumatic suspension system considering the influence of temperature variations. First, the working principle and failure mode of the hydro-pneumatic suspension system are analyzed, and then the reliability of the hydro-pneumatic suspension system is defined. On this basis, for the key failure modes of the hydro-pneumatic suspension system, a reliability model based on the allowable height and a reliability model based on the allowable stiffness are established. The system reliability model of the hydro-pneumatic suspension system is obtained synthetically. Finally, the single-chamber hydro-pneumatic suspension system is selected as the experimental object. Comparative tests of different design parameters of the hydro-pneumatic suspension system under temperature effect are conducted. The accuracy is verified for the failure mode analysis and reliability model of the hydro-pneumatic suspension system."
  },
  {
    "year": "2017",
    "abstract": "A 6-bit digital-controlled attenuator with low phase imbalance for a K-band phased array system is presented in this paper. To decrease the insertion phase difference, the proposed design adopts a phase correction capacitor in the shunt branch of the conventional switched T/Pi structure. The capacitor and the parallel resistor compose a phase compensation network to correct the insertion phase error. The attenuator is designed and fabricated in0.18μmCMOS process. From 19 to 21 GHz, the insertion loss is 7.2–8 dB. The rms phase imbalance is less than 3.8° over 19–21 GHz. The attenuator has a maximum attenuation range of 32 dB with 0.5-dB step (64 states). The core cell chip size is 1.32 mm×0.34mm excluding pads."
  },
  {
    "year": "2017",
    "abstract": "The tremendous increase in wireless data rate over the past few decades can be attributed to the use of higher frequency bands and increased density of access points along with advanced signal processing in transceiver. With the use of higher bands and increased access point density, terrestrial wireless communication systems are encountering more and more line-of-sight conditions than systems of earlier era. Moreover modern era of communication systems is generally designed to adapt transmission parameters dynamically. Such adaptations are done based on estimation of channel statistics. The measure of line-of-sight (Rician K-factor) is one of such statistics. It plays a vital role in estimating fade statistics, which influences the bit error rate, spectral efficiency, level crossing rate, average fade duration and so on. These factors significantly influence design of communication systems. This paper focuses on analytical computation of Rician K-factor of multi-clustered propagation channel models including antenna gain-patterns. Rician K-factor in different wireless channel models, which are based on the indoor channel model given by Saleh and Valenzuela and the channel model for IEEE 802.11ad standard have been calculated and compared with simulations. We show that, channel model provided explicit Rician factor does not agree with actual K-factor experienced by a link when details such as directivity of clusters and antenna gains are considered. The difference results in erroneous estimate of system performance. It is seen that the estimates of the required signal to noise ratio per bit for a given modulation and coding schemes can be affected by as much as 4 dB in sub 6 GHz systems and as high as 5 dB for millimeter wave systems due to incorrect use of Rician K-factor for relevant links. Average channel capacity is affected by around 13% for high SNR links due to variation of Rician K-factor."
  },
  {
    "year": "2017",
    "abstract": "Extracellular matrix (ECM) proteins play a major role in the tissues of multicellular organisms. The ECM presents structural support for cells inside a tumor. Meanwhile, it also works homeostatically to mediate the interaction between cells. However, the current bioinformatics tools to predict the ECM proteins seem often fail. This paper introduces a method for predicting the ECM proteins from the protein sequence as well as the molecular characteristics. We report a novel hybrid animal migration optimization and random forest method to predict the ECM protein sequences adapting four various features design methods. Binary animal migration optimization (AMORF) is used to select a near-optimal subset of informative features that are most relevant for the classification. AMORF experiments on a data set, including 145 ECM and 3887 non-ECM proteins. Our algorithm performs 86.4700% accuracy, a sensitive of 84.9655%, a specificity of 86.5261%, a Matthew's correlation coefficient of 0.3627, and an area under receiver operating characteristic of 0.877804. The results confirm that the proposed method is promising. From the results, we can summarize that it can choose small subsets of features and still increase the classification efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study a decode-and-forward (DF) relaying network with random interferers, in which the source transmits its message to the destination with the help of N DF relays. We consider the interference-limited environments, where the reception at the relays and the destination are corrupted by random interferers, which are distributed according to a homogeneous Poisson point process. To improve the system performance, relay selection based on received signal-to-interference ratio (SIR) has been employed to select the best relay among N ones. We examine the network performance by deriving the analytical outage probability under Rayleigh fading transmission channels and Nakagami-m fading interference channels. Moreover, we compute the asymptotic expressions of outage probability, and confirm that the system diversity order on SIR is equal to 2/α, where α denotes the path loss factor. Furthermore, we see that the major limitation of system results from the second hop. Numerical and simulation results are demonstrated to validate the proposed analysis as well."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the resource allocation problem for multi-user full-duplex deviceto-device (D2D) underlay communication, considering both perfect channel state information (CSI) and statistical CSI scenarios. In perfect CSI scenario, the weighted sum-rate maximization problem under cellular users' minimum rate constraints is formulated as a mixed integer programming problem. To solve the challenging problem, we decouple it into two subproblems as power allocation and channel assignment. Then we proposed a power allocation algorithm based on difference of two convex functions programming and a channel assignment algorithm based on Kuhn-Munkres algorithm, respectively. In statistical CSI scenario, we formulate the resource allocation problem as an outage probability constrained weighted ergodic sumrate maximization problem. To solve the problem, the closed-form expressions of outage probability and weighted ergodic sum-rate are derived first. Then we decouple resource allocation problem into power allocation and channel assignment. An optimization solution that consists of a 2-D global searching and Kuhn-Munkres algorithm is then developed. Simulation results demonstrate that the proposed algorithms can improve the weighted sum-rate of full-duplex D2D communications significantly both in perfect CSI and statistical CSI scenarios and confirm the accuracy of our derived closed-form expressions."
  },
  {
    "year": "2017",
    "abstract": "One major topic for robust face recognition could be the efficient encoding of facial descriptors. Among various encoders, Fisher vector (FV) is one of the probabilistic methods that yield promising results. However, its huge representation is fairly forbidding. In this paper, we present approaches to efficiently compress FV and retain its robustness. First, we put forward a new Compact FV (CFV) descriptor. The CFV is obtained by zeroing out small posteriors, calculating first-order statistics and reweighting its elements properly. Second, in light of Iterative Quantization (ITQ) scheme, we present a Generalized ITQ (GITQ) method to binarize our CFV. Finally, we apply our CFV and GITQ to encode convolutional activations of convolutional neural networks. We evaluate our methods on FERET, LFW, AR, and FRGC 2.0 datasets, and our experiments reveal the advantage of such a framework."
  },
  {
    "year": "2017",
    "abstract": "Motor imagery (MI)-based brain-computer interface (BCI) using electroencephalography (EEG) allows users to directly control a computer or external device by modulating and decoding the brain waves. A variety of factors could potentially affect the performance of BCI such as the health status of subjects or the environment. In this paper, we investigated the effects of soft drinks and regular coffee on EEG signals under resting state and on the performance of MI-based BCI. Twenty-six healthy human subjects participated in three or four BCI sessions with a resting period in each session. During each session, the subjects drank an unlabeled soft drink with either sugar (Caffeine Free Coca-Cola), caffeine (Diet Coke), neither ingredient (Caffeine Free Diet Coke), or a regular coffee if there was a fourth session. The resting state spectral power in each condition was compared; the analysis showed that power in alpha and beta band after caffeine consumption were decreased substantially compared with control and sugar condition. Although the attenuation of powers in the frequency range used for the online BCI control signal was shown, group averaged BCI online performance after consuming caffeine was similar to those of other conditions. This paper, for the first time, shows the effect of caffeine, sugar intake on the online BCI performance, and resting state brain signal."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new, systematic method of synthesizing an output feedback adaptive controller for a class of uncertain, non-square multi-input/multi-output systems. The control design process consists of first designing an inner-loop controller for a reduced order plant model to enforce command tracking of selected inner-loop variables, with an adaptive element used to accommodate parametric uncertainties in the plant. Once this inner-loop control design is complete, an outer-loop is then designed, which prescribes the inner-loop commands to enforce command tracking of selected outer-loop variables. The main challenge that needs to be addressed when designing the inner-loop controller is the determination of a corresponding square and strictly positive real transfer function. This is accomplished by appropriate selection of two gain matrices that allow the realization of such a transfer function, thereby allowing a globally stable adaptive output feedback law to be generated. The outer-loop controller is designed around the plant with existing adaptive inner-loop controller such that global stability of the closed-loop system is guaranteed. The design of the outer-loop uses components of a closed-loop reference model in a judicious manner which enables a modular approach, without requiring any re-design of the inner-loop controller. In addition, this architecture facilitates the use of an additional state-limiter to enforce desired limits on the state variables. A numerical example based on a scramjet powered, generic hypersonic vehicle model is presented, demonstrating the efficacy of the proposed control design."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we design a mobility-aware user association strategy for millimeter-wave (mmW) networks to overcome the limitations of the conventional received power (RSS)-based association strategies in a mobile 5G scenario. More in detail, first the design of a mobility-aware strategy for user association in 5G mmW networks is posed as a constrained optimization problem. Then, it is showed that the proposed strategy exhibits several attractive features: a) it is able to track the dynamic changes in the network topology and in the channel conditions induced by the user mobility; b) it takes into account the distribution of the loads among the small base stations (sBSs), thus overcoming to associate an UE to an already congested sBS. This, in turn, affects positively the overall fairness of the network; c) it overcomes overly frequent handovers between sBSs, and thus the need of frequent re-association; d) it takes into account the peculiar aspects of the mmW communications, such as directionality, sensitivity to blockage, and NLoS propagation effects; and e) it is fully distributed, i.e., each mobile user associates to an sBS independently of each other, stemming from local information only. Furthermore, it is showed that the exhaustive search for the solution of the posed optimization problem is computationally unfeasible. Consequently, within this paper, an efficient algorithm exhibiting a polynomial-time complexity is proposed. Finally, the numerical results validate the benefits of adopting the proposed mobility-aware and fully distributed association rule. In particular, it is quantified the very significant performance enhancement of the proposed association with respect to the conventional RSS-based one."
  },
  {
    "year": "2017",
    "abstract": "This work was supported in part by the Science and Technology Program of Guangzhou, China, under Grant 201707010389, in part by the Scientific Research Project of Guangzhou Municipal University under Grant 1201620439, in part by the Qingshanhu Young Scholar Program in GZPYP under Grant 2016Q001, in part by Comba Research Funds under Grant JX-PYP-201501 and Grant H2017007, in part by the Sichuan International Science and Technology Cooperation Project under Grant 2017HH0035, in part by the National Natural Science Foundation of China under Grant 61501382, in part by the Fundamental Research Funds for the Central Universities under Grant 2682015RC20 and Grant 2682016CY22, in part by the Science and Technology Planning Key Project of Guangdong under Grant 2016B010124014, in part by the National Natural Science Foundation of China under Grant 61471229 and Grant 61772007, in part by the Innovation Improvement Project for Universities under Grant 2015KTSCX040, in part by the Natural Science Foundation of Guangdong under Grant 2014A030306027, and in part by Guangzhou University's 2017 training program for young top-notch personnels under Grant BJ201702."
  },
  {
    "year": "2017",
    "abstract": "The problem of stability analysis for discrete-time switched nonlinear system is investigated with mode-dependent average dwell time (MDADT) method in this paper. A slow switching strategy is adopted in the discrete-time nonlinear stable subsystems and unstable subsystems are handled by a fast switching strategy. Takagi-Sugeno (T-S) fuzzy model is utilized to approximate the switched nonlinear system. By constructing a multiple discontinuous Lyapunov function approach, the stability condition of switched T-S fuzzy system is built to get tighter bound on MDADT, which shows that our proposed method outperforms the classical one. Finally, through a numerical example, the effectiveness of the presented control approach is illustrated by comparison with result from classical one."
  },
  {
    "year": "2017",
    "abstract": "The real-time position of an autonomous underwater vehicle (AUV) is always of great interest. With advances of technologies, underwater wireless sensor networks (UWSNs) become promising tools for AUV tracking. Due to the energy constraint of underwater nodes, energy saving is a key issue that affects all aspects of the design of a tracking scheme. In this paper, we propose a novel energy-efficient tracking scheme for an AUV to locate itself in time by UWSNs. We first design a tracking protocol considering the energy consumptions in both the AUV and sensor nodes (SNs). Particularly, the protocol is designed in two aspects: 1) the passive listening mechanism and duty-cycle strategy for the AUV and 2) the detection-based ranging packet transmission for SNs. Since the tracking protocol will inevitably affect the packet delivery between the AUV and SNs, we analyze the packet delivery success rate (PDSR) to shed light on the impact of system parameters on the tracking performance. To cope with non-linearity of the model and the intermittent observations mainly arisen from the effect of the tracking protocol, we adopt two extended versions of the original intermittent Kalman filter for tracking. They are intermittent extended Kalman filter and intermittent unscented Kalman filter. Simulation results demonstrate the effectiveness of the proposed tracking scheme, and reveal that the PDSR analysis provides a design guidance for parameter selection in system configuration."
  },
  {
    "year": "2017",
    "abstract": "For efficiency improvement and public key size reduction, a new public key compression scheme is proposed for fully homomorphic encryption based on quadratic parameters with correction (QPC-PKC scheme). Compared with existing public key compression schemes, the size of the public key in the proposed scheme is reduced from Õ(λ5) to Õ(λ3.5) by reducing the number of subgroup public key elements and the element bit-lengths. Based on the construction mechanisms of the somewhat fully homomorphic encryption (SWHE), a QPC-PKC SWHE scheme is constructed and the parameter constraints are presented. The correctness and semantical security of the proposed QPC-PKC SWHE scheme are then proved based on the error-free approximate greatest common divisor assumption. Finally, the public key size performance of the QPC-PKC scheme is theoretically analyzed, while the public key sizes and running times of the QPC-PKC SWHE scheme are experimentally evaluated. The results show that the public key size of the proposed scheme is significantly reduced compared with the existing schemes, and the encryption efficiency of the QPC-PKC SWHE scheme is also improved as expected."
  },
  {
    "year": "2017",
    "abstract": "Channel estimation is crucial for massive multiple-input multiple-output (MIMO) systems to scale up multi-user MIMO, providing significant improvement in spectral and energy efficiency. In this paper, we present a simple and practical channel estimator for multipath multi-cell massive MIMO time division duplex systems with pilot contamination, which poses significant challenges to channel estimation. The proposed estimator addresses performance under moderate to strong pilot contamination without previous knowledge of the inter-cell large-scale fading coefficients and noise power. Additionally, we derive and assess an approximate analytical mean square error (MSE) expression for the proposed channel estimator. We show through simulations that the proposed estimator performs asymptotically as well as the minimum MSE estimator with respect to the number of antennas and multipath coefficients."
  },
  {
    "year": "2017",
    "abstract": "Over the years, many heuristic algorithms have been proposed for solving various Grid scheduling problems. GridSim simulator has become a very popular simulation tool and has been widely used by Grid researchers to test and evaluate the performance of their proposed scheduling algorithms. As heterogeneity is one of the unique characteristics of Grid computing, which induces additional challenges in designing heuristic-based scheduling algorithms, the main concern when performing simulation experiments for evaluating the performance of scheduling algorithms is how to model and simulate different Grid scheduling scenarios or cases that capture the inherent nature of heterogeneity of Grid computing environment. However, most simulation studies that based on GridSim have not considered the nature of heterogeneity. In this paper, we propose a new simulation model that incorporates the range-based method into GridSim for modeling and simulating heterogeneous tasks and resources in order to capture the inherent heterogeneity of Grid environments that later can be used by other researchers to test their algorithms."
  },
  {
    "year": "2017",
    "abstract": "Fog computing paradigm extends the storage, networking, and computing facilities of the cloud computing toward the edge of the networks while offloading the cloud data centers and reducing service latency to the end users. However, the characteristics of fog computing arise new security and privacy challenges. The existing security and privacy measurements for cloud computing cannot be directly applied to the fog computing due to its features, such as mobility, heterogeneity, and large-scale geo-distribution. This paper provides an overview of existing security and privacy concerns, particularly for the fog computing. Afterward, this survey highlights ongoing research effort, open challenges, and research trends in privacy and security issues for fog computing."
  },
  {
    "year": "2017",
    "abstract": "Recent advances in wearable devices allow non-invasive and inexpensive collection of biomedical signals including electrocardiogram (ECG), blood pressure, respiration, among others. Collection and processing of various biomarkers are expected to facilitate preventive healthcare through personalized medical applications. Since wearables are based on sizeand resource-constrained hardware, and are battery operated, they need to run lightweight algorithms to efficiently manage energy and memory. To accomplish this goal, this paper proposes SURF, a subject-adaptive unsupervised signal compressor for wearable fitness monitors. The core idea is to perform a specialized lossy compression algorithm on the ECG signal at the source (wearable device), to decrease the energy consumption required for wireless transmission and thus prolong the battery lifetime. SURF leverages unsupervised learning techniques to build and maintain, at runtime, a subject-adaptive dictionary without requiring any prior information on the signal. Dictionaries are constructed within a suitable feature space, allowing the addition and removal of code words according to the signal's dynamics (for given target fidelity and energy consumption objectives). Extensive performance evaluation results, obtained with reference ECG traces and with our own measurements from a commercial wearable wireless monitor, show the superiority of SURF against state-of-the-art techniques, including: 1) compression ratios up to 90-times; 2) reconstruction errors between 2% and 7% of the signal's range (depending on the amount of compression sought); and 3) reduction in energy consumption of up to two orders of magnitude with respect to sending the signal uncompressed, while preserving its morphology. SURF, with artifact prone ECG signals, allows for typical compression efficiencies (CE) in the range CE ∈ [40, 50], which means that the data rate of 3 kbit/s that would be required to send the uncompressed ECG trace is lowered to..."
  },
  {
    "year": "2017",
    "abstract": "Traffic classification is currently a significant challenge for network monitoring and management. Feature selection is an effective method to realize dimension reduction and decrease redundant information. To realize accurate traffic classification at lower price of evaluations, a hybrid feature subset selection method is proposed on the base of sliding block, the size of which is flexible according to the classification performance. Furthermore, an incremental strategy of convergence is designed on the base of hybrid feature subset selection methods. The strategy gathers all the features that have been selected. To discover the value of relationship among all the selected features, an extra round of selection is added on the base of the original algorithm. The performances are examined by three groups of experiments. Our theoretical analysis and experimental observations reveal that the proposed method consumes fewer evaluations with similar or even better classification performance at different initialized size of block. Moreover, the incremental strategy of convergence makes a further improvement on the classification accuracy."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces an automatic image annotation framework based on multi-auxiliary information which aims at improving the annotation performance. We propose three novel ideas in the framework of annotation: 1) multi-information extraction: besides various visual features, tag co-occurrence, and user interest vector are added to enrich the multi-auxiliary information; 2) initial labeling: based on the traditional term frequency-inverse document frequency model-we utilize the visibility of words and extended tag set to enhance the result of initial labeling and propose a more efficient model, TF-IDF, visibility and extended tag set model; and 3) tag refinement: by considering multi-auxiliary information, including multi-visual content, tag co-occurrence, and user interest similarity, we propose the multi-information alllabels model for tag refinement. The tag refinement process is formalized as an optimization problem by adjusting confidence score set by the initial labeling model. Experimental results demonstrate that, compared with the state-of-the-art methods, our method achieves the best performance on MIR-Flickr data sets, outperforming the second best by 2%."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a model of swarm behavior that encodes the spatial-temporal characteristics of topological features, such as holes and connected components. Specifically, the persistence of topological features with respect to time is computed using zig-zag persistent homology. This information is in turn modelled as a persistence landscape, which forms a normed vector space and facilitates the application of statistical and data mining techniques. Validation of the proposed model is performed using a real data set corresponding to a swarm of fish. It is demonstrated that the proposed model may be used to perform retrieval and clustering of swarm behavior in terms of topological features. In fact, it is discovered that clustering returns clusters corresponding to the swarm behaviors of flock, torus, and disordered. These are the most frequently occurring types of behavior exhibited by swarms in general."
  },
  {
    "year": "2017",
    "abstract": "We consider the problem of delivering region of interest (ROI)-coded mobile video streams using limited radio resources. Under the conditions of limited bandwidth and time-varying channel status, the goal is to optimize the transmission latency, while ensuring the quality of the ROI parts. Multi-homing support enables the terminals to establish multiple connections for transmission performance improvement. In this paper, we propose a novel framework for ROI-based video transmission in heterogeneous wireless networks with multi-homed terminals. The framework contains the modules of ROI detector and frame splitter, where macroblocks are categorized based on ROI detection and encapsulated into transforming units. It also includes a channel monitor that keeps track of the status of each communication path and sends feedback signals to the streaming controller for packet-scheduling control; a deep learning method is proposed for channel status prediction. To address the delivery problem, we propose a scheduling approach based on the formulated network model and the rate-distortion model. The scheduling method makes a tradeoff between the transmission delay and the distortion. It also guarantees that packets with ROI content are delivered on paths with sufficient bandwidths and low loss rates. Through comparisons with other scheduling methods, we find that the proposed scheme outperforms the other scheduling methods in terms of improving the quality (peak signal-to-noise ratio), balancing the end-to-end delay, and maintaining the playback fluency."
  },
  {
    "year": "2017",
    "abstract": "A novel low-profile, ultra-lightweight, high-efficient circularly polarized (CP) planar patch antenna array is reported for Ku-band satellite TV reception applications. The basic radiating element of the antenna array is realized by a 2 × 2 corner-removed patch subarray. This 2 × 2 patch subarray is centerfed by a rectangular coupling aperture etched on the top surface of a substrate-integrated-waveguide cavity. A novel compact sequential rotation feeding technique is adopted to broaden the operating bandwidth without occupying additional area. The 2×2 CP subarray can be easily scaled up for large size antenna arrays due to its single layer feeding network and compact radiating elements. In addition, the patch radiators are printed on a thin layer of Polyimide film backed by a piece of supporting foam to minimize the entire weight. To verify the design concept, a 96-element (16 × 6) CP patch array was fabricated and tested. Measured results show that the operating bandwidth is 700 MHz from 11.55 to 12.25 GHz. The gain is stable across the operating bandwidth with a realized peak gain of 26.4 dBic. The height of the antenna is 0.05 λ0and the total weight is only 66.5 g. It serves as an excellent candidate for Ku-band satellite applications."
  },
  {
    "year": "2017",
    "abstract": "Magnetic resonance imaging (MRI) has been widely employed in medical diagnosis, since it enables superior visualization of anatomical structure with noninvasive and nonionizing radiation nature. However, during the data acquisition process of MRI, patients' translational motion usually leads to phase changes of the observed data; moreover, the amplitudes of the observed data are usually contaminated by noises. In this paper, we assume that the phase and amplitude noises, respectively, cause the phase and amplitude changes of the observed data. Therefore, how to reconstruct high-quality magnetic resonance (MR) images via highly undersampled K-space data with noises is a challenge. To address this issue, a novel MR image reconstruction model, named the adaptive tight frame and total variation MR image reconstruction model (TFTV-MRI), is proposed based on the compressed sensing (CS) theory. TFTV-MRI fuses the adaptive tight frame (ATF) learning and total variation (TV) into the image reconstruction model. The sparse representations of MR images in tight frame domain can adapt to the MR image by itself, simultaneously, the advantage of TV is better edge preserving property and MR images are sparse in gradient domain. Differing from the l0-norm or l1-norm utilized in traditional AFT learning, we exploit the logarithm penalty term to measure the sparsity of MR images in TFTV-MRI. The alternating iterative minimization algorithm is utilized to tackle the optimization problem of TFTV-MRI, including ATF learning step and MR image reconstruction step. In MR image reconstruction step, the inertial proximal algorithm for nonconvex optimization is employed. The experiments verified that the proposed model achieved the superior performance for dislodging the phase noises caused by the translational motion and removing the amplitude noises of the observed data, and reconstructed MR images nicely in different sampling schemes. Compared with the existing methods, the proposed approa..."
  },
  {
    "year": "2017",
    "abstract": "WiFi direct (WD) network is of significant interest during public safety scenarios due to its easy, quick, and efficient implementation. WD provides device to device communication using the MAC and PHY layers specifications of 802.11 standards, which facilitate multiple communications channels and a number of transmission rates to cope with the requirements and challenges of emerging applications in public safety and disaster management. Although they achieve substantial benefits in terms of high throughput, it creates a performance anomaly problem, wherein the selection of a particular communication channel and transmission rate can significantly affect the performance of a wireless communication system. This paper investigates the problem of selecting the most favorable channel and rate for a multicast communication system in the context of public safety using a WD 802.11 network. To this end, M3-Cast protocol is proposed, which refers to a novel multi-rate multi-channel multicast scheme. M3-Cast not only chooses the most favorable communication channel and transmission rate, but also considers the implementation details of the underlying WD technology, thereby optimizing the overall system performance. M3-Cast is formulated analytically and evaluated by a complete system level simulation. The detailed results and the analysis considers a number of performance metrics, such as bit error rate, multicast capacity, and system throughput under different multiple input multiple output configurations, channel bandwidths, and various network radii. Consequently, the simulation and analytical results show that M3-Cast protocol outperforms the standard multicast protocol of WD by almost twofold in terms of system throughput."
  },
  {
    "year": "2017",
    "abstract": "Software regression testing verifies previous features on a software product when it is modified or new features are added to it. Because of the nature of regression testing it is a costly process. Different approaches have been proposed to reduce the costs of this activity, among which are: minimization, prioritization, and selection of test cases. Recently, soft computing techniques, such as data mining, machine learning, and others have been used to make regression testing more efficient and effective. Currently, in different contexts, to a greater or lesser extent, software products have access to databases (DBs). Given this situation, it is necessary to consider regression testing also for software products such as information systems that are usually integrated with or connected to DBs. In this paper, we present a selection regression testing approach that utilizes a combination of unsupervised clustering with random values, unit tests, and the DB schema to determine the test cases related to modifications or new features added to software products connected to DBs. Our proposed approach is empirically evaluated with two database software applications in a production context. Effectiveness metrics, such as test suite reduction, fault detection capability, recall, precision, and the F-measure are examined. Our results suggest that the proposed approach is enough effective with the resulting clusters of test cases."
  },
  {
    "year": "2017",
    "abstract": "As the technique that determines the position of a target device based on wireless measurements, Wi-Fi localization is attracting increasing attention due to its numerous applications and the widespread deployment of Wi-Fi infrastructure. In this paper, we propose ConFi, the first convolutional neural network (CNN)-based Wi-Fi localization algorithm. Channel state information (CSI), which contains more position related information than traditional received signal strength, is organized into a time-frequency matrix that resembles image and utilized as the feature for localization. The ConFi models localization as a classification problem and addresses it with a five layer CNN that consists of three convolutional layers and two fully connected layers. The ConFi has a training stage and a localization stage. In the training stage, the CSI is collected at a number of reference points (RPs) and used to train the CNN via stochastic gradient descent algorithm. In the localization stage, the CSI of the target device is fed to the CNN and the localization result is calculated as the weighted centroid of the RPs with high output value. Extensive experiments are conducted to select appropriate parameters for the CNN and demonstrate the superior performance of the ConFi over existing methods."
  },
  {
    "year": "2017",
    "abstract": "Micro-motion dynamics, such as rapid rotation, vibration and spinning motion, impose additional time-varying frequency modulation on the returned radar signals, which is known as the micro-Doppler (m-D) effect. Micro-Doppler frequency is considered as a stable and unique feature, where the uniqueness means that different micro-motions have distinct signatures. Thus, radar m-D feature extraction is of great potential in target classification and identification. This paper presents m-D frequency estimation from the HRRPs of rotating targets in frequency-stepped signal (FSS) based on the circular correlation (CC) coefficients and the circular average magnitude difference (CAMD) coefficients. The m-D frequency of rotating targets can be estimated accurately from the two proposed methods and the corresponding computational cost burden is also investigated. The accuracy and efficiency of the estimations are compared and revealed by the simulated trials and experimental data."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) distribute hundreds to thousands of inexpensive microsensor nodes in their regions, and these nodes are important parts of Internet of Things (IoT). In WSN-assisted IoT, the nodes are resource constrained in many ways, such as storage resources, computing resources, energy resources, and so on. Robust routing protocols are required to maintain a long network lifetime and achieve higher energy utilization. In this paper, we propose a new energy-efficient centroid-based routing protocol (EECRP) for WSN-assisted IoT to improve the performance of the network. The proposed EECRP includes three key parts: a new distributed cluster formation technique that enables the self-organization of local nodes, a new series of algorithms for adapting clusters and rotating the cluster head based on the centroid position to evenly distribute the energy load among all sensor nodes, and a new mechanism to reduce the energy consumption for long-distance communications. In particular, the residual energy of nodes is considered in EECRP for calculating the centroid's position. Our simulation results indicate that EECRP performs better than LEACH, LEACH-C, and GEEC. In addition, EECRP is suitable for networks that require a long lifetime and whose base station (BS) is located in the network."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on improving the standard form of the classical simulated annealing algorithm (CSAA). A novel method of improving the performance of CSAA by the variable universe adaptive fuzzy logic system (VUAFLS) is studied. We develop the VUAFLS to adjust the annealing temperature, which is a very important parameter governing the performance of CSAA, and this algorithm is named VUAFLS-CSAA. The main innovations of VUAFLS-CSAA lie in the application of VUAFLS containing the fast cooling mechanism and reheating mechanism relative to the characteristic of the sustained temperature fall of CSAA. Compared with the conventional method for controlling annealing temperature, VUAFLS-CSAA can control the annealing temperature more effectively, leading to the high efficiency of CSAA. The performance of the proposed method is evaluated and compared with CSAA through two examples. One is the image restoration problem, and the other is the traveling salesman problem (TSP). The experimental result indicates that the new method proposed in this paper can improve the efficiency of CSAA by tremendously shortening the iteration optimization process. And at the same time, the successful application of the new method for tackling two different problems demonstrates the generality of this method. In addition, techniques that can further improve the performance of CSAA are discussed."
  },
  {
    "year": "2017",
    "abstract": "Dynamic principal component analysis (DPCA) is generally employed in monitoring dynamic processes and typically incorporates all measured variables. However, for a large-scale process, the inclusion of variables without fault-relevant information may cause redundancy and degrade monitoring performance. In this paper, the influence of variable and time-lagged variable selection on the DPCA monitoring performance is analyzed. Then, a fault-relevant performance-driven distributed monitoring scheme is proposed to achieve efficient fault detection and diagnosis. First, performance-driven process decomposition is performed, and the optimal subset of variables and time-lagged variables for each fault are selected through a stochastic optimization algorithm. Second, local DPCA models are established to characterize the process dynamics and generate fault signature evidence. Finally, a Bayesian diagnosis system with the most efficient evidence sources is established to identify the process status. Case studies on a numerical example and the Tennessee Eastman benchmark process demonstrate the efficiency of the proposed monitoring scheme."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate into direction estimation in bistatic multiple-input multiple-output (MIMO) radar in the presence of unknown spatial colored noise. Taking the stationary property of the spatial colored noise into consideration, a transform-based tensor covariance differencing method is proposed. The spatial colored noise is eliminated by forming the difference of the original and the transformed covariance matrices. To further exploit the inherent multidimensional nature, a fourth-order tensor is constructed, which helps to achieve more accurate subspace estimation. Thereafter, the traditional subspace-based methods are applied for ambiguous direction estimation. Finally, a special matrix is formed to associate the real angles with the targets. The proposed scheme does not bring virtual aperture loss, and it has complexity lower than the existing tensor-based subspace methods. Numerical simulations verify the improvement of our scheme."
  },
  {
    "year": "2017",
    "abstract": "In electrical distribution grids, the constantly increasing number of power generation devices based on renewables demands a transition from a centralized to a distributed generation paradigm. In fact, power injection from distributed energy resources (DERs) can be selectively controlled to achieve other objectives beyond supporting loads, such as the minimization of the power losses along the distribution lines and the subsequent increase of the grid hosting capacity. However, these technical achievements are only possible if alongside electrical optimization schemes, a suitable market model is set up to promote cooperation from the end users. In contrast with the existing literature, where energy trading and electrical optimization of the grid are often treated separately, or the trading strategy is tailored to a specific electrical optimization objective, in this paper, we consider their joint optimization. We also allow for a modular approach, where the market model can support any smart grid optimization goal. Specifically, we present a multi-objective optimization problem accounting for energy trading, where: 1) DERs try to maximize their profit, resulting from selling their surplus energy; 2) the loads try to minimize their expense; and 3) the main power supplier aims at maximizing the electrical grid efficiency through a suitable discount policy. This optimization problem is proved to be non-convex, and an equivalent convex formulation is derived. Centralized solutions are discussed and a procedure to distribute the solution is proposed. Numerical results to demonstrate the effectiveness of the so obtained optimal policies are finally presented, showing the proposed model results in economic benefits for all the users (generators and loads) and in an increased electrical efficiency for the grid."
  },
  {
    "year": "2017",
    "abstract": "The cognitive radio-based sensor network (CRSN) is envisioned as a strong driver in the development of modern power system smart grids (SGs). This can address the spectrum limitation in the sensor nodes due to interference cause by other wireless devices operating on the same unlicensed frequency in the Industrial, Scientific and Medical band. These sensor nodes are used for monitoring and control purposes in various components of a SG, ranging from generation, transmission, and distribution, and down to the consumer, including monitoring of utility network assets. A reliable SG communication network architecture is required for transferring information which needed by the SG applications, alongside the monitoring and control by CRSN. Hence, this paper investigates and explores the CRSN conceptual framework, and SG communication architecture with its applications; vis-à-vis the communication access technologies, including implementation design with quality of service support. Consequently, this paper highlights various research gaps, such as implementation design model, utilization of LPWAN for CRSN based SG deployment, and so on. This includes discussion on the future direction for various aspects of the CRSN in SG. To address these research gaps, we introduced a smart unified communication solution to improve the efficiency of the SG and mitigate various associated challenges."
  },
  {
    "year": "2017",
    "abstract": "Growing demand for software has attracted the attention of the software development industry. Crowdsourced software development has provided a new method for the software industry to produce quality software based on an open-call format. Selecting an appropriate task to develop (developer-end) or evaluate (platform-end) is one of the primary problems in this type of open-call format. Receiving or assigning an improper task to an improper crowdsource (CS) developer does not only decrease the quality of the software deliverables, but also causes overburden on both the platform and the developers. To solve this problem, sorting the tasks based on the developers' human characteristics may increase task relevancy for developers, which can accelerate efficiency and lessen complexity. Thus, this paper has conducted an empirical experiment to measure the influence of personality on task selection based on the important characteristics of a task: money, time, and type. A total of 83 students from the University of Sindh voluntarily participated in four different short-duration rounds of task development using the developed CS platform. The personality types of the participants were measured based on the Myers-Briggs type indicator. In addition, a complex network technique called weighted degree centrality was applied to identify the most suitable personality for task sorting based on money or complexity attractions (i.e., time or type). Based on the results, it can be observed that personality has a significant relationship with task selection. For instance, developers with intuitive (N) and feeling (F) personality traits are primarily focused on the time duration of a project."
  },
  {
    "year": "2017",
    "abstract": "A network traffic classifier (NTC) is an important part of current network monitoring systems, being its task to infer the network service that is currently used by a communication flow (e.g., HTTP and SIP). The detection is based on a number of features associated with the communication flow, for example, source and destination ports and bytes transmitted per packet. NTC is important, because much information about a current network flow can be learned and anticipated just by knowing its network service (required latency, traffic volume, and possible duration). This is of particular interest for the management and monitoring of Internet of Things (IoT) networks, where NTC will help to segregate traffic and behavior of heterogeneous devices and services. In this paper, we present a new technique for NTC based on a combination of deep learning models that can be used for IoT traffic. We show that a recurrent neural network (RNN) combined with a convolutional neural network (CNN) provides best detection results. The natural domain for a CNN, which is image processing, has been extended to NTC in an easy and natural way. We show that the proposed method provides better detection results than alternative algorithms without requiring any feature engineering, which is usual when applying other models. A complete study is presented on several architectures that integrate a CNN and an RNN, including the impact of the features chosen and the length of the network flows used for training."
  },
  {
    "year": "2017",
    "abstract": "The arms race between the distributors of malware and those seeking to provide defenses has so far favored the former. Signature detection methods have been unable to cope with the onslaught of new binaries aided by rapidly developing obfuscation techniques. Recent research has focused on the analysis of low-level opcodes, both static and dynamic, as a way to detect malware. Although sometimes successful at detecting malware, static analysis still fails to unravel obfuscated code, whereas dynamic analysis can allow researchers to investigate the revealed code at runtime. Research in the field has been limited by the underpinning data sets; old and inadequately sampled malware can lessen the extrapolation potential of such data sets. The main contribution of this paper is the creation of a new parsed runtime trace data set of over 100 000 labeled samples, which will address these shortcomings, and we offer the data set itself for use by the wider research community. This data set underpins the examination of the run traces using classifiers on count-based and sequence-based data. We find that malware detection rates are lessened when samples are labeled with traditional anti-virus (AV) labels. Neither count-based nor sequence-based algorithms can sufficiently distinguish between AV label classes. Detection increases when malware is re-classed with labels yielded from unsupervised learning. With sequenced-based learning, detection exceeds that of labeling as simply “malware”alone. This approach may yield future work, where the triaging of malware can be more effective."
  },
  {
    "year": "2017",
    "abstract": "Over-the-air (OTA) radiated testing for multiple-input multiple-output (MIMO) capable mobile terminals has been actively discussed in the standardization in recent years, where multi-probe anechoic chamber (MPAC) method has been selected, together with the radiated two-stage method. The supported test zone size is a key parameter to determine for an MPAC design, and the test zone size is restricted by the number of OTA antennas. A larger test zone would necessitate more OTA antennas, each port of which is driven by an expensive channel emulator radio frequency interface. Results available in the literature are typically limited to free space scenarios, where no user effect in the vicinity of MIMO terminal is present. There is a concern whether or not the test zone size should encompass the user phantom, together with the mobile terminal in the MPAC setup. To address this issue, an extensive measurement campaign was carried out in this paper. Two realistic long term evolution mockups were designed and their performance were evaluated under standard spatial channel models with and without the presence of user phantom. The measurement results have shown that the nearby user phantom can significantly affect the MIMO performance. However, its impact on the test zone size of the MPAC system is negligible, since emulation accuracy in terms of received power, branch power ratio, antenna correlation, and measured throughput under the target and the emulated channels is not affected by the presence of user phantom. Moreover, results measured with the synthetic MPAC method generally match those obtained with the reference two-stage method. These findings are valuable inputs for the ongoing MIMO OTA harmonization work in the standardization."
  },
  {
    "year": "2017",
    "abstract": "Cloud applications provides users with services that can be accessed on demand through the Internet. Fertile service frameworks are considered one of the most critical ingredients for the envisaged benefits so as to further interactions among cloud computing resources and application components. Such foundations should lead to the proliferation of new innovative services and applications. The research community has been exploring the Open Service Gateway initiative's (OSGi) potential as a top candidate for cloud application platforms. Although the current OSGi specification provides some level of support for dynamic service discovery, tracking, and composition, more should be done to be able to adequately address the need for diverse interaction patterns for cloud applications. This paper introduces a novel service framework built upon OSGi platforms that supports a directed-acyclic-graph style composition of constituent services. Given a declarative blueprint of service interconnections and interactions, the framework can find and assemble corresponding component services to form a real application. Our proposal can enable a realistic topology of service component interlinkings beyond linear chaining interactions as supported by the status quo. The design, implementation details, and validation results of our workflow-based service composition framework architecture are discussed in the paper."
  },
  {
    "year": "2017",
    "abstract": "In many scenarios of security analysis, Bayesian methods are often used for assessing harmful factors like attacks, as Bayesian causal model can estimate or predict the effect from the observed factors. To distinguish which ones are direct or significant causal (harmful) factors to the target systems, we often need to calculate a (local) causal network, but the existing methods usually return Markov equivalence classes instead of an actual causal structure. In this paper, a new approach for inferring causal direction from multidimensional causal networks for assessing harmful factors in security analysis is proposed based on a split-and-merge strategy. The method first decomposes an n-dimensional network into induced subnetworks, each of which corresponds to a node in the network. We show that each induced subnetwork can be subsumed into one of the three substructures: one-degree, non-triangle, and triangle-existence substructures. Three effective algorithms are developed to infer causalities from the three substructures. The whole causal structure of the multi-dimensional network is obtained by learning these induced subnetworks separately. Experimental results demonstrate that our method is more general and effective than the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Hybrid object storage systems provide opportunities to achieve high performance and energy efficiency with low cost for enterprise data centers. Existing object storage systems, however, distribute data objects in the system without considering the heterogeneity of the underlying devices and the asymmetric data access patterns. Therefore, the system performance and energy efficiency may degrade as data are placed on improper storage devices. For example, energy-efficient high-density archive hard disk drives (archive HDDs) are significantly slower than normal HDDs and solid state disks (SSDs), which mean that the archive HDDs are not appropriate for storing frequently accessed objects. Besides, flash-based SSDs have limited write endurance, which makes SSDs vulnerable for storing write-intensive objects. In this paper, we analyze various real enterprise workloads and find that read and write requests are not uniformly distributed to data objects. Based on the observations, we propose a novel strategy, biased object storage strategy (BOSS), to reduce writes to SSDs and improve system performance for hybrid object storage systems. Different from conventional uniform and fixed data distribution strategies, the BOSS can distribute and migrate data objects to various types of devices dynamically, according to the data access patterns collected online. The experimental results show that the BOSS can reduce 64% of writes on SSDs and improve system performance by 29.51% on average, while maintaining a high level of load balance."
  },
  {
    "year": "2017",
    "abstract": "The so-called Internet of Things (IoT) aims at connecting every single object to the Internet with the purpose to automate every aspect of daily life. The IoT relies heavily on wireless low-power and lossy networks (LLNs) that collect information from the physical world and send the measurements to data aggregation and processing nodes. Most LLNs operate in the non-licensed industrial, scientific, and medical radio band, which is shared by a considerable number of systems. Coexisting wireless systems cause interference to each other, limiting their achievable performance. Multichannel communications enable frequency diversity, which in turn provides robustness against interference as well as increased network capacity. There is a considerable interest in multichannel medium access control (MAC) protocols for LLNs, including an evolving standard for the MAC layer of LLNs. In this paper, we review the latest advances in the topic and introduce a new classification framework for multichannel MAC protocols for LLNs. While our framework builds on previous review and classification studies, it adds aspects of a MAC protocol that reflect its interactions with the surrounding network stack. Seeing the resource constraints of the LLN devices, the study of such interactions—which is missing in prior classification efforts—can be the key for improving future designs. Relevant protocols published since 2006 are discussed and classified using the presented framework, including the recent multichannel MAC protocols for LLNs, such as the latest version of the IEEE 802.15.4 standard for time slotted channel hopping."
  },
  {
    "year": "2017",
    "abstract": "Parkinson's Disease (PD) is one of the most severe neurological diseases prevalent in the world. A neurodegenerative disease, it impairs the body's balance, damages motor skills, and leads to disorder in speech production. These problems also affect decision-making processes and the expression of emotions. In this paper, we propose a PD monitoring framework for use in smart cities. Using this framework, city residents will have their health constantly monitored and get feedback on their PD situation. Early PD symptoms can, therefore, be detected and the proper medication provided. In this framework, we use speech signals from clients captured from various sensors and transmitted to the cloud for processing. In the cloud, decisions are made using a support vector machine-based classifier. Decisions, along with the signal features, are sent to registered doctors, who then prescribe certain medications to the client. Several experiments were performed, with the results demonstrating that the proposed framework can achieve 97.2% accuracy in detecting PD."
  },
  {
    "year": "2017",
    "abstract": "Image mosaicking is an important part of remote sensing image processing and plays a vital role in the analysis of trans-regional remote sensing images. In order to solve the problems of low utilization of nodes and frequent data I/O in traditional parallel mosaicking algorithms, we propose a parallel mosaicking algorithm based on Apache Spark. First, multi-nodes parallel computation for image overlapping region estimation are implemented in the algorithm. Then, we self-define the Resilient Distributed Data sets (RDD) for remote sensing image processing, and use the three key steps of the image mosaicking, including overlapping region estimation, image registration, and image fusion, which are as the transformation-type operators of the self-defined RDD (the self-defined RDD is what we get by extending the functionality of RDD in Spark). Finally, the parallel processing of image mosaicking is realized by calling the operators of self-defined RDD with the method of implicit conversion. Experimental results show that the parallel mosaicking algorithm of massive remote sensing image based on Spark can effectively improve the mass data image mosaicking efficiency on the basis of guaranteeing the image mosaicking effect."
  },
  {
    "year": "2017",
    "abstract": "Extended logical Petri nets are proposed to improve logical Petri nets, and the related firing rules and state reachability graph are introduced. Their attributes, place arrival time, and priority function are defined for each token, batch processing wait time and transition firing duration are defined for each logical input/output transition, and firing duration is defined for each ordinary transition. Their token removal and generation functions are defined to operate the attributes and arrival time of tokens in places. A state in their reachability graph is redefined. They are used to model an e-commerce system. The reachability, time cost superiority of tokens with different priorities, and fairness of the resulting model are analyzed and correct end-states are illustrated."
  },
  {
    "year": "2017",
    "abstract": "Currently available wearables are usually based on a single sensor node with integrated capabilities for classifying different activities. The next generation of cooperative wearables could be able to identify not only activities, but also to evaluate them qualitatively using the data of several sensor nodes attached to the body, to provide detailed feedback for the improvement of the execution. Especially within the application domains of sports and health-care, such immediate feedback to the execution of body movements is crucial for (re-)learning and improving motor skills. To enable such systems for a broad range of activities, generalized approaches for human motion assessment within sensor networks are required. In this paper, we present a generalized trainable activity assessment chain (AAC) for the online assessment of periodic human activity within a wireless body area network. AAC evaluates the execution of separate movements of a prior trained activity on a fine-grained quality scale. We connect qualitative assessment with human knowledge by projecting the AAC on the hierarchical decomposition of motion performed by the human body as well as establishing the assessment on a kinematic evaluation of biomechanically distinct motion fragments. We evaluate AAC in a real-world setting and show that AAC successfully delimits the movements of correctly performed activity from faulty executions and provides detailed reasons for the activity assessment."
  },
  {
    "year": "2017",
    "abstract": "The asynchronous L1output tracking control problem for switched positive linear systems is studied in this paper. The sufficient conditions for the solvability of the asynchronous output tracking problem are developed with the co-positive Lyapunov function and the average dwell time method. The L1tracking performances are obtained by virtue of designing controllers. Finally, a simulation example for the main results is performed to validate the effectiveness of the method and its improvements."
  },
  {
    "year": "2017",
    "abstract": "Digital subscriber line (DSL) technology remains the most popular broadband access technology. A variety of algorithms has been developed to improve performance in DSL networks, which are commonly referred to as dynamic spectrum management (DSM) algorithms. The main goal of these algorithms is to fight crosstalk between different lines in a cable bundle. Current DSM algorithms provide an equal level of error protection for each serviced application and each user. However, different applications may have unequal error protection (UEP) requirements. The equal level of error protection usually provided by DSM algorithms may then be excessive for some applications, which leads to a waste of valuable resources. This paper, therefore, considers DSM for DSL networks providing UEP. Four joint signal and spectrum coordination algorithms are presented, enabling a different level of error protection for different applications. These algorithms are modified versions of existing optimal spectrum balancing and distributed spectrum balancing algorithms for joint signal and spectrum coordination in upstream as well as downstream DSL. In addition, an algorithm is presented which, for each application, selects a suitable modulation and coding (MC) scheme from a set of admissible MC schemes. Through simulations, it is shown that DSM with UEP can indeed lead to moderate performance gains."
  },
  {
    "year": "2017",
    "abstract": "There has been numerous seismic hazard studies so far that includes Malaysian territories. However, there is a need to assess how reliable those studies are. Two main potential contributors to error have been identified: 1) seismic hazard analysis method and 2) ground motion prediction equation (GMPE). The amount of variation in predicting erroneous GMPE is huge. Thus, this paper concentrates on generating new GMPEs due to subduction specified for Malaysia and validated against developed GMPE. Empirical method for GMPE generation was utilized using recorded ground motion data acquired from the Malaysian Meteorological Department. The earthquakes were grouped according to the source, and only source types in the Sumatran subduction area were used due to the availability of enough data to identify a pattern. Three GMPEs were generated for three different source types, namely, shallow subduction earthquake, deep subduction earthquake, and backarc earthquake sources. Sumatran strike slip fault is considered within backarc seismicity. They were compared with the models proposed by Petersen (modified from Young), Atkinson and Boore, and Megawati. The comparison results showed that the proposed models are far superior at predicting the earthquakes in the Sumatran region, with percentage difference between estimates and the recorded values being the lowest. Therefore, the equations should be used in further seismic hazard analyses. Thus, this paper becomes a part of the recent initiatives in Malaysia to assess the hazards posed by earthquakes."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present an approach of convolutional neural networks (CNNs) to identify prostate cancers. Prostate tissue specimen samples were obtained from the tissue microarrays and digitized. For each sample, epithelial nuclear seeds were identified and used to generate a nuclear seed map, i.e., only the location information of epithelial nuclei was utilized. From the nuclear seed maps, CNNs sought to learn the high-level feature representation of nuclear architecture and to detect cancers. Applying data augmentation technique, CNNs were trained on the training data set including 73 benign and 89 cancer samples and validated on the testing data set comprising 217 benign and 274 cancer samples. In detecting cancers, CNNs achieved an AUC of 0.974 (95% CI: 0.961-0.985). In comparison with the approaches of utilizing hand-crafted nuclear architecture features and the state of the art deep learning networks with standard machine learning methods, CNNs were significantly superior to them (p-value <; 5e-2). Moreover, stromal nuclei were incapable of improving the cancer detection performance. The experimental results suggest that our approach offers the ability to aid in improving prostate cancer pathology."
  },
  {
    "year": "2017",
    "abstract": "Due to the increase of power electronic-based loads, the maintenance of high power quality poses a challenge in modern power systems. To limit the total harmonic distortion in the line voltage and currents at the point of the common coupling (PCC), active power filters are commonly employed. This paper investigates the use of the multilevel modular converter (MMC) for harmonics mitigation due to its high bandwidth compared with conventional converters. A selective harmonics detection method and a harmonics controller are implemented, while the output current controller of the MMC is tuned to selectively inject the necessary harmonic currents. Unlike previous studies, focus is laid on the experimental verification of the active filtering capability of the MMC. For this reason an MMC-based double-star STATCOM is developed and tested for two representative case studies, i.e., for grid currents and PCC voltage harmonics. The results verify the capability of the MMC to mitigate harmonics up to the thirteenth order, while maintaining a low effective switching frequency and thus, low switching losses."
  },
  {
    "year": "2017",
    "abstract": "Physical-layer network coding holds the great potential of improving the power efficiency and the spectral efficiency for the two-stage transmission scheme. The first stage is the multiple access stage, where two source nodes (SN1and SN2) simultaneously transmit to the relay node (RN). The second stage is the Broadcast stage, where the RN broadcasts to the two destination nodes (DN1and DN2), after a denoising-and-mapping operation. In this paper, we investigate the joint network-coded modulation design of the two stages. A universal modulation framework is built, referred to as analog network-coded modulation strategy, which is more general than the former modulation design mechanism. More explicitly, we propose a joint design criterion to guarantee the forwarding reliability at the RN. The criterion ensures that the neighboring constellation points superposed at the RN are mapped to an identical constellation point for broadcasting if their Euclidean distance (ED) is less than a given threshold. This yields a non-convex polynomial optimization problem by minimizing the average transmission power and constraining the ED among the constellation points. By solving the problem, we propose two joint modulation design algorithms, termed as the Enhanced Semidefinite Relaxation Algorithm and the Fast-Relaxation Algorithm, respectively. The two algorithms can achieve the tradeoff between the communication performance and the computation resources. As for the Fast-Relaxation Algorithm, the theoretical performance boundary is derived in detail. Simulation results demonstrate the effectiveness of both the proposed algorithms by comparing symbol error rate performance with the existing modulation design methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a framework for inverse synthetic aperture radars (ISAR) imaging with wideband V-FM waveforms is investigated, where the dual-channel compressed-sensing-based dechirping (CS-D) algorithms are applied to achieve high-resolution range profiles (HRRPs) of moving targets. The final HRRPs are reconstructed via the synthesis of the two HRRPs recovered from the two independent channels with CS-D. The ISAR formation is achieved from the Fourier transform-based azimuth compression methods being applied to the rearranged 2-D array of HRRPs. Simulated trials of targets modeled as point scatterers are conducted and the final well-focused images demonstrate the effectiveness of the proposed dual-channel CS-D algorithm in ISAR imaging with wideband V-FM waveforms."
  },
  {
    "year": "2017",
    "abstract": "Video compression has become more and more important nowadays along with the increasing application of video sequences and rapidly growing resolution of them. H.264 is a widely applied video coding standard for academic and commercial purposes. And fractal theory is one of the most active branches in modern mathematics, which has shown a great potential in compression. In this paper, this study proposes an improved inter prediction algorithm for video coding based on fractal theory and H.264. This study take the same approach to make intra predictions as H.264 and this study adopt the fractal theory to make inter predictions. Some improvements are introduced in this algorithm. First, luminance and chrominance components are coded separately and the partitions are no longer associated as in H.264. Second, the partition mode for chrominance components has been changed and the block size now rages from 16 × 16 to 4 × 4, which is the same as luminance components. Third, this study introduced adaptive quantization parameter offset, changing the offset for every frame in the quantization process to acquire better reconstructed image. Comparison between the improved algorithm, the original fractal compress algorithm and JM19.0 (The latest H.264/AVC reference software) confirms a slightly increase in Peak Signal-to-Noise Ratio, a significant decrease in bitrate while the time consumed for compression remains less than 60% of that using JM19.0."
  },
  {
    "year": "2017",
    "abstract": "Fog computing dramatically extends the cloud computing to the edge of the network and admirably solves the problem that the brokers (in publish-subscribe system) generally lack of computing capacity and energy power. However, brokers may be disguised, hacked, sniffed, and corrupted. The traditional security technology cannot protect the system privacy when facing a possible collusion attack. In this paper, we propose a privacy-preserving content-based publish/subscribe scheme with differential privacy in fog computing context, named PCP, where the fog nodes act as the brokers. Specifically, PCP firstly utilizes the U-Apriori algorithm to mine the top-K frequent itemsets (i.e., the attributes) from uncertain data sets, then applies the exponential and Laplace mechanism to ensure the differential privacy, and the broker uses the mined top-K itemsets to match appropriate publisher and subscriber finally. Security analysis shows that the PCP can guarantee differential privacy in theory. To evaluate the performance of PCP, we carry out experiments with real-world scenario data sets. The experimental results show that PCP efficiently achieves the tradeoff between the system cost and the privacy demand."
  },
  {
    "year": "2017",
    "abstract": "Numerous studies have developed self-reliance support robots, such as those assisting the sit-to-stand (STS) movement, which requires coordination between the upper body and the lower limbs. However, few studies have quantitatively evaluated the service quality of such robots. This paper proposes a method to evaluate the service quality of STS-assistance robots through the relative phase (RP), which contains information on the coordinating relationship between the upper body and the lower limbs. STS experiments were performed under three conditions, namely unassisted STS movement and robot-supported STS movements lasting 2 and 5 s. The results showed that the quality of robot assistance during STS movement could be quantitatively evaluated through RP. Furthermore, three features—minimum RP, mean absolute RP, and deviation phase (DP)—that contained information on the users response to the robot could be extracted for data mining. Moreover, electromyography performed to verify the experimental results confirmed the relationship between coordinated performance and muscle activities during STS movements. Thus, evaluating STS movements through the RP is an effective method of evaluating the service quality of robots, and features extracted from RP theory could distinguish classes of movements with a high probability."
  },
  {
    "year": "2017",
    "abstract": "The gravitational search algorithm (GSA) has been proved to yield good performance in solving various optimization problems. However, it is inevitable to suffer from slow exploitation when solving complex problems. In this paper, a thorough empirical analysis of the GSA is performed, which elaborates the role of the gravitational parameter Gin the optimization process of the GSA. The convergence speed and solution quality are found to be highly sensitive to the value of G. A self-adaptive mechanism is proposed to adjust the value of G automatically, aiming to maintain the balance of exploration and exploitation. To further improve the convergence speed of GSA, we also modify the classic chaotic local search and insert it into the optimization process of the GSA. Through these two techniques, the main weakness of GSA has been overcome effectively, and the obtained results of 23 benchmark functions confirm the excellent performance of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Motor drives is a widely used technology, offering many advantages, such as exceptional speed control and flexibility. Improvement of reliability and efficiency has become a great research interest. Toward this direction and considering the major recent developments in supercapacitor technology, the use of bidirectional energy recovery converters has been introduced in various industrial applications. In this paper, the regenerative braking of a three-phase induction motor controlled by a variable frequency drive will be analyzed and the portion of kinetic energy that can be recovered will be calculated. The main contribution of this paper is a methodology for the estimation of the energy savings that can be achieved from the use of such an energy recovery feature. In addition, the optimum braking duration that maximizes the recovered energy will be investigated. The analysis presented in this paper has been validated experimentally and the results are discussed."
  },
  {
    "year": "2017",
    "abstract": "A novel multiuser multiple-input multiple-output (MU-MIMO) cognitive radio (CR) system with an improved received signal-to-interference-noise ratio (SINR) and enhanced primary user (PU) interference suppression is proposed for systems with the independent parallel streams of CR multiusers communication. In the overlay CR system with a licensed PU and unlicensed CR users (CUs), the performance of PU tends to be degraded by the interference of CU. Likewise, the transmission efficiency of CU tends to be reduced by the interference of PU. In conventional MU-MIMO systems, precoding techniques are mainly designed to constrain the CU transmitted power, which can prevent interference to PU. However, the transmitted signal of PU unavoidably induces some interference to CUs. In performance studies of the conventional CR systems, the signals of PU interference are regarded as white noise. In the paper, a cooperative MU-MIMO CR relay technique is proposed to improve the quality of the CR transceiver via the relay station canceling the PU interference in two time slots. Specifically, the relay station applies MU-MIMO precoding scheme to carry multiple negative PU signals to CUs for canceling PU interference and to acquire an improved received SINR. Furthermore, the proposed MU-MIMO CR relay system is simulated to confirm the performance being better than a conventional CR system. Besides, the sum rate linear growth of the proposed system is due to its robustness against strong interference from the PU, against interference from multiple CUs, and against stream interference."
  },
  {
    "year": "2017",
    "abstract": "To satisfy the delay constraint, the computation tasks can be offloaded to some computing servers, referred to as offloading destinations. Different to most of existing works which usually consider only a single type of offloading destinations, in this paper, we study the hybrid computation offloading problem considering diverse computation and communication capabilities of two types of offloading destinations, i.e., cloud computing servers and fog computing servers. The aim is to minimize the total energy consumption for both communication and computation while completing the computation tasks within a given delay constraint. It is quite challenging because the delay cannot be easily formulated as an explicit expression but depends on the embedded communication-computation scheduling problem for the computation offloading to different destinations. To solve the computation offloading problem, we first define a new concept named computation energy efficiency and divide the problem into four subproblems according to the computation energy efficiency of different types of computation offloading and the maximum tolerable delay. For each subproblem, we give a closed-form computation offloading solution with the analysis of communicationcomputation scheduling under the delay constraint. The numerical results show that the proposed hybrid computation offloading solution achieves lower energy consumption than the conventional single-type computation offloading under the delay constraint."
  },
  {
    "year": "2017",
    "abstract": "This paper describes the lattice problems that are key in the study of lattice-based cryptography, identifies and categorizes methods for solving these problems, analyzes existing implementations of these algorithms, and extrapolates on the future of lattice-based cryptanalysis, based on the foreseeable advances in computer architecture. Some future lines of work are given, considering the existence of parallel architectures that seem adequate for current attacks."
  },
  {
    "year": "2017",
    "abstract": "Wireless network virtualization (WNV) has drawn attention from the researchers ranging from academia to industry as one of the significant technologies in the cellular network communication. It is considered as a pioneer to achieve effective resource utilization with decreased operating expenses and capital expenses by decoupling the networks functionalities of coexisting virtual networks. It facilitates fast deployment of new services and novel technologies. WNV paradigm is in the early stages, and there is a large room for the research community to develop new architectures, systems, and applications. The availability of software-defined networking (SDN) and cloud/centralized radio access network (C-RAN) steers up the hope for the WNV realization. This paper surveys WNV along with the recent developments in SDN and C-RAN technologies. Based on these technologies and WNV concepts, we identify the requirements and opportunities of future cellular networks. We then propose a general architectural framework for the WNV based on SDN. In-depth discussion of challenges and research issues as well as promising approaches for future networks communication improvements are also proposed. Finally, we give several promising candidates of future network services for residential customers and business customers."
  },
  {
    "year": "2017",
    "abstract": "Wireless network virtualization (WNV) and cloud radio access networks (CRANs) are promising technologies with the potential to be game changing for the fifth generation (5G) wireless networks. In particular, these technologies may have significant impact on the capital expenditure, quality of service provisioning, as well as spectral efficiency in 5G networks. These two technologies are mostly considered separately in previous works. This paper, however, investigates both the gains and requirements of integrating WNV with CRAN. In this paper, we propose WNV schemes for CRAN, where the objective is to maximize the overall system throughput and minimize delay. The proposed schemes are designed to maintain a high level of isolation between mobile network operators (MNOs), which allows the deployment of different scheduling polices by different MNOs, and managing intercell interference, which may lead to significant throughput gain. Overall, the results presented in this paper reveal that a joint CRAN-WNV architecture can be highly efficient when MNOs have unbalanced loads, because MNOs with high loads can seamlessly access the underutilized resources of underloaded MNOs. The throughput gain in unbalanced loads can be as much as 50% using optimal sharing schemes when compared with static sharing, and about 18% when compared with the WNV without CRAN. The resource allocation problem in the joint CRAN-WNV is formulated, and both optimal and low complexity suboptimal solutions are derived. The obtained results show that integrating the two technologies in a joint architecture can significantly improve the network performance. However, reducing the complexity by adopting efficient sharing techniques may have tangible impact on the throughput when compared with optimal sharing."
  },
  {
    "year": "2017",
    "abstract": "Heterogeneous ad hoc networks with MIMO links can significantly improve transmission performance of the entire distributed wireless communication system. In this paper, we investigate how to increase total system throughput and decrease end-to-end delay with the help of heterogeneous characteristics of the ad hoc networks. Even if there are lots of references about distributed scheduling control considering multiple antennas, channel state, and so on, it still needs to be addressed how to guarantee destination to receive packets with a short delay. To resolve this issue, we first propose an interference-delay tradeoff method using convex optimization, which adjusts transmission rate and power to balance interference and delay. We then develop a speed power interference-based topology resource control algorithm with delay constraint to further adjust transmission power for reducing energy consumption. Simulation results show that the proposed algorithms can outperform the existing ones in terms of throughput, end-to-end delay, and power consumption."
  },
  {
    "year": "2017",
    "abstract": "Transient stability assessment is a critical tool for power system design and operation. With the emerging advanced synchrophasor measurement techniques, machine learning methods are playing an increasingly important role in power system stability assessment. However, most existing research makes a strong assumption that the measurement data transmission delay is negligible. In this paper, we focus on investigating the influence of communication delay on synchrophasor-based transient stability assessment. In particular, we develop a delay aware intelligent system to address this issue. By utilizing an ensemble of multiple long short-term memory networks, the proposed system can make early assessments to achieve a much shorter response time by utilizing incomplete system variable measurements. Compared with existing work, our system is able to make accurate assessments with a significantly improved efficiency. We perform numerous case studies to demonstrate the superiority of the proposed intelligent system, in which accurate assessments can be developed with time one third less than state-of-the-art methodologies. Moreover, the simulations indicate that noise in the measurements has trivial impact on the assessment performance, demonstrating the robustness of the proposed system."
  },
  {
    "year": "2017",
    "abstract": "A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system. Current research trends from areas, such as from Internet of Things and fog computing use sensors as the source of data. Therefore, energy-efficient data routing in WSN is still a challenging task for real-time applications. Hierarchical grid-based routing is an energy-efficient method for routing of data packets. This method divides the sensing area into grids and is advantageous in wireless sensor networks to enhance network lifetime. The network is partitioned into virtual equal-sized grids. The proposed mode-switched grid-based routing protocol for WSN selects one node per grid as the grid head. The routing path to the sink is established using grid heads. Grid heads are switched between active and sleep modes alternately. Therefore, not all grid heads take part in the routing process at the same time. This saves energy in grid heads and improves the network lifetime. The proposed method builds a routing path using each active grid head which leads to the sink. For handling the mobile sink movement, the routing path changes only for some grid head nodes which are nearer to the grid, in which the mobile sink is currently positioned. Data packets generated at any source node are routed directly through the data disseminating grid head nodes on the routing path to the sink."
  },
  {
    "year": "2017",
    "abstract": "The physical validation of devices must comply with the principles of causality, passivity, and stability. For linear and time-invariant devices, it can be proved that passivity implies a causal transfer function. In this sense, it is understood that causality is a consequence of the passivity condition. Moreover, if the real part of the admittance is non-negative, it can also be demonstrated that the device is passive. The main subject of this work is a novel class of one-port passive devices presenting negative real part admittances on certain frequency ranges. Thus, the equations expressing the passivity condition, as far defined, are not applicable and the causality condition must also be checked. A theoretical model able to explain this effect and a generalization of the passivity condition, which fully address the applicability of the passivity-causality theorem are provided. The experimental verification of a specific device having this property is also shown. In this way, we report the results of a practical realization of a resonant circuit having negative real part values and a tunable positive to negative real part transition. As a possible outcome, novel passive circuits, such as oscillators and phase modulators covering the full trigonometric circle may be constructed. We also discuss the causality condition, show that negative real part admittances are causal and provide a new causality test that is in full consistence with the Kramers-Kronig relations."
  },
  {
    "year": "2017",
    "abstract": "Compared with line powered wireless sensor nodes, power allocation, and rate adaption in energy harvesting (EH) nodes are challenging problems, due to the intermittent nature of the energy arrival process and data causality constraints. To address this problem, in this paper we propose an online fuzzy logic-based power allocation (FPA) scheme for a cooperative and delay constraint EH wireless sensor network (EHWSN) using opportunistic relaying. An EHWSN model is developed with finite energy and data buffer constraints at the relay node. The performance of FPA scheme is evaluated in terms of throughput, fairness, delay, transmission time, and energy consumption. The performance of FPA is also compared with one offline policy and two online policies. It is observed that the delay and the energy consumption of FPA scheme for a given throughput are very close to the offline power allocation policy. The results show that for a given EH profile tradeoff exists between data buffer capacity and throughput for a given payload in all the schemes. In addition, the opportunistic behavior of relay can be controlled by increasing buffer size, however, that may compromise the throughput beyond a certain buffer size. Furthermore, the performance of FPA scheme is also evaluated under Uniform, Rayleigh and Beta distributed energy arrivals."
  },
  {
    "year": "2017",
    "abstract": "It has been suggested that the spatiotemporal characteristics of complex cardiac arrhythmias can be extracted from the spectrum of cardiac signals. However, the analysis of simple bioelectric models indicates that the spectrum of cardiac signals can be affected by the spatial resolution of the electrode system. In this paper, we derive exact measurement transfer functions relating the spectrum of cardiac signals to the spatiotemporal dynamics of cardiac sources. The analysis of the measurement transfer bandwidths for dynamics with different degrees of spatiotemporal correlation shows that as the spatial resolution decreases, the bandwidth of the measurement transfer function decreases until it reaches a constant value. Moreover, this transition from decreasing to constant values is determined by the degree of spatiotemporal correlation of the underlying cardiac source. Motivated by our analytical results, we investigate in a realistic computer simulation environment the impact of additive noise on the accuracy of body-surface dominant frequency (DF) maps. Our simulation results show that meaningful DF values are obtained on those locations where the analytical measurement transfer bandwidth is wide. These findings suggest that the accuracy of body-surface DF maps can be limited by the low spatial resolution of body-surface electrode systems."
  },
  {
    "year": "2017",
    "abstract": "Nonorthogonal multiple access (NOMA) with successive interference cancellation is considered as one of the most promising schemes in multi-user access wireless networks. Based on the principles of NOMA and full-duplex (FD) communications, this paper proposes a novel FD-aided cooperative NOMA (FD-NOMA) scheme to optimize the maximum achievable rate region. Since selfinterference often exists in FD communications, a self-interference canceller is employed in this system. Specifically, three schemes that aim to maximize the achievable rate region are provided. The first one is investigated under the assumption that the transmitted power is fixed, while the other two schemes are achieved with the aid of two developed algorithms. For the purpose of studying the rate region in the nonideality condition, the error vector magnitudelevel is introduced in the analysis of the third scheme. Finally, analytical results demonstrate that the proposed FD-NOMA scheme outperforms the conventional schemes based on NOMA in terms of the rate region, and the maximum rate region of the FD-NOMA scheme is compared with different coefficients."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel method for maximizing the spatial frequency reuse in cellular networks by exploiting the possibility to simultaneously associate each user to multiple base-stations (BSs). To this end, the proposed technique presents a criterion for determining when a user should be associated with one or more BSs and whether the uplink and downlink should be decoupled, based on minimizing the average interference power across the network. To minimize the effect of interference that may occur due to increasing the spatial frequency reuse, the proposed association methods are integrated with an overlap checking scheme to insure that the resources are orthogonalized between the interfering BSs and user equipments. The results show that significant performance improvements can be attained by the proposed scheme in comparison with other benchmark techniques."
  },
  {
    "year": "2017",
    "abstract": "Off-grid sparse Bayesian learning algorithms for estimating the directions-of-arrival (DOAs) of multiple signals using an array of sensors are attractive in practice due to three primary reasons. First, these algorithms are fully automatic Bayesian algorithms and hence tuning of regularization parameters (hyperparameters) is not necessary. Second, since these algorithms are based on sparsity, they can produce high accuracy DOA estimates by exploiting the spatial sparsity of acoustic signals even when the signals are coherent. Third, they can also estimate the offset in the DOAs for signals, whose DOAs are not exactly aligned with the steering vectors. Two previously proposed off-grid sparse Bayesian DOA estimation algorithms are considered. The first off-grid model is based on the Taylor series expansion method (OGSBL-T algorithm) and the second is based on the linear interpolation method (OGSBL-I algorithm). The Cramer-Rao lower bound (CRLB) of the off-grid bias parameters for both the algorithms is derived for multiple snapshots. It is shown that the CRLB of the off-grid bias parameters for the OGSBL-T algorithm is significantly less than that for the OGSBL-I algorithm. It is also shown that the CRLBs of the off-grid bias parameters for both the algorithms get worse when we move from the broadside to the endfire directions. A simulation study is also carried out to characterize the performances of both the algorithms in terms of the root-meansquared error in the DOA estimates. It is shown that the OGSBL-T algorithm performs comparably to the OGSBL-I algorithm when the signals are relatively broadside and better than the OGSBL-I algorithm when the signals are relatively endfire. Finally, the application of the OGSBL-T algorithm for high resolution DOA estimation in an underwater communication system is demonstrated by analyzing passive sonar data from the SWellEx-96 ocean acoustic experiment."
  },
  {
    "year": "2017",
    "abstract": "There is a growing demand for the use of robots to assist humans in their tasks, especially those involving risks, such as search and rescue. For this reason, coordination among several robots has been a common option, and one of the ways to study and model these applications involves the problem of pursuit evasion. This paper extends the results presented earlier on the use of an evolutionary robotics approach to solve the worst case pursuit-evasion problem, in which evaders are considered arbitrarily fast and omniscient, while pursuers have limited sensing and communication capabilities, with no prior knowledge regarding environments, which are treated as discrete and can be multiply connected. First, a formulation based on random walk is offered. Then, the concept is extended to include a decentralized multi-robot control system based on a finite-state machine with state-action mapping defined by means of a genetic algorithm. Results show that the proposed system is able to decontaminate several types of maps, but does not generalize to all initial conditions, due to the incompleteness in the automaton mapping. Therefore, a complementary approach is presented in which random walk is used alternatively with the evolved automaton, indicating random actions in cases of states not sufficiently visited during evolution. In addition, a comparative analysis of the evolutionary approach and the random walk formulation is also carried out."
  },
  {
    "year": "2017",
    "abstract": "To balance the convergence speed and the solution's diversity in the large-scale travel salesman problem (TSP), this paper proposes a new heuristic communication heterogeneous dual population ant colony optimization (HHACO). First, the main characteristics of HHACO are the heuristic communication and the two heterogeneous ant colonies. Heuristic communication, an indirect communication strategy, helps improve the deviation of solution. Heterogeneous ant colonies are beneficial to balance the convergence speed and the diversity of solution, in which one ant colony is in charge of solution's diversity and the another one in charge of convergence speed inspiring from nature evolution with self-adaptive ability. Besides, this paper takes advantage of orthogonal test to discuss the parameters in HHACO algorithm and a better parameters' set is obtained. Then, HHACO algorithm is applied to solve TSP, and meanwhile characteristics of different ant colonies in HHACO are discussed. Finally, HHACO is compared with the other dual colonies algorithms and several classic ant colony optimization algorithms, and results suggest that the HHACO has a better performance in the large-scale problem."
  },
  {
    "year": "2017",
    "abstract": "Photovoltaic embedded generation in low-voltage ac networks is quite popular; however, despite its benefits, there are some problems especially when photovoltaic (PV) penetration exceeds certain thresholds. Among others, voltage violation is of prime importance. Our review of the literature focused on PV penetration limits due to voltage violations in low-voltage (LV) networks. The review revealed that voltage violations can occur at a penetration level as low as 2.5% when a large distributed generator (DG) is installed at a single point. Alternatively, a LV network can host a large number of photovoltaic distributed generators (PVDGs), with a penetration level up to 110% if evenly distributed over shorter lengths. However, an LV network has no rules of thumb for safe penetration limits. Penetration-level calculations have been found that they used numerous approaches, which we have analyzed and discussed to adopt a more rational and unified approach. Our literature review revealed that, in LVs, a very high penetration level can be achieved as compared with medium-voltage (MV) networks. However, MV voltage-level control problems impose a limit for PV hosting in LV networks. There is a need to evolve strategies for robust voltage control at the MV level and to develop certain rules of thumb for PV penetration limits in LV networks independent of the MV level, to increase the PV hosting capacity."
  },
  {
    "year": "2017",
    "abstract": "It is a challenging task to recognize smoke from images due to large variance of smoke color, texture, and shapes. There are smoke detection methods that have been proposed, but most of them are based on hand-crafted features. To improve the performance of smoke detection, we propose a novel deep normalization and convolutional neural network (DNCNN) with 14 layers to implement automatic feature extraction and classification. In DNCNN, traditional convolutional layers are replaced with normalization and convolutional layers to accelerate the training process and boost the performance of smoke detection. To reduce overfitting caused by imbalanced and insufficient training samples, we generate more training samples from original training data sets by using a variety of data enhancement techniques. Experimental results show that our method achieved very low false alarm rates below 0.60% with detection rates above 96.37% on our smoke data sets."
  },
  {
    "year": "2017",
    "abstract": "We present an approach to jointly detect mitotic events spatially and temporally in time-lapse phase contrast microscopy images. In particular, we combine a convolutional neural network (CNN) and a long short-term memory (LSTM) network to detect mitotic events in patch sequences. The CNN-LSTM network can be trained end-to-end to simultaneously learn convolutional features within each frame and temporal dynamics between frames, without hand-crafted visual or temporal feature design. Owing to the LSTM layer, this approach is able to detect mitotic events in patch sequences of variable length, as well as making use of longer context information among frames in the sequences. To the best of our knowledge, this is the first work to detect mitosis using deep learning in both spatial and temporal domains. Experiments have shown that the CNN-LSTM network can be trained efficiently, and we evaluate this design by applying the network to original raw microscopy image sequences to locate mitotic events both spatially and temporally. The data with which we validate the proposed method include C3H10 mesenchymal and C2C12 myoblastic stem cell populations. Our approach achieved the F score of 98.72% on the C2C12 data set, and the F score of 96.5% on the C3H10 data set. The results on both data sets outperform the traditional graph modelbased approaches by a large margin, both in terms of detection accuracy and frame localization accuracy. Furthermore, we have developed a framework to aid humans in annotating mitosis with high efficiency and accuracy in raw phase contrast microscopy images based on the joint detection results using the proposed method. Under this framework, expert level annotations can be obtained in raw phase contrast microscopy image sequences, and the annotations have shown to further improve the training performance of the CNN-LSTM network."
  },
  {
    "year": "2017",
    "abstract": "The advancement in the current communication technology makes it incumbent to analyze the conventional features of reflectarray antenna for future adaptability. This paper thoroughly reviews the design and experimental features of reflectarray antenna for its bandwidth improvement in microwave and millimeter wave frequency ranges. The paper surveys the fundamental and advanced topologies of reflectarray design implementations, which are needed particularly for its broadband features. The realization of its design approaches has been studied at unit cell and full reflectarray levels for its bandwidth enhancement. Various design configurations have also been critically analyzed for the compatibility with the high-frequency 5G systems."
  },
  {
    "year": "2017",
    "abstract": "With the sharp increase in mobile apps, modular design and functional reuse are commonly adopted. The inter-component communication (ICC) mechanism in Android allows apps to exchange data with other apps and components, resulting in large amounts of security issues, such as component hijacking vulnerabilities, privilege escalation and spoofing attacks. Although ICC has been extensively studied in previous work, none of the previous approaches is practically scalable to simultaneously analyze a large number of Android apps, giving the combinational explosion of possible inter-component (and inter-app) communications. In this paper, we first propose an explorative study to analyze the ICC-based interaction for a large amount of Android apps. Then we propose CRSPR, a PageRank-like topic-aware app ranking approach to highlight influential Android apps for ICC analysis. The experimental results show that CRSPR is better than the basic counting approach as well as the traditional PageRank-based approach, which further demonstrate that CRSPR is useful for highlighting influential Android apps."
  },
  {
    "year": "2017",
    "abstract": "The execution of the airline operation is often deviated from the original schedule due to some unexpected disruptions, such as aircraft breakdowns and severe weather conditions. In this situation, a recovery plan is needed to get the irregular operation back to normal to minimize the losses of the airline. To produce recovery plans and solve the airline disruption problems, a novel modified traveling salesman problem model is proposed to generate sets of the feasible flight routes for each aircraft fleet type. Then, the feasible flight routes are reassigned to the available aircrafts in each fleet to form a recovery plan. Numerical results show that the approach proposed in this paper is efficient and promising."
  },
  {
    "year": "2017",
    "abstract": "Layered asymmetrically clipped optical orthogonal frequency division multiplexing (LACO-OFDM) has been proposed for improving the spectral efficiency of conventional asymmetrically clipped optical OFDM. Multiple base layers that are orthogonal in the frequency domain are sequentially superimposed to form LACO-OFDM, where each superimposed layer fills the empty subcarriers left by the previous layer. As our contribution, the bit error ratio (BER) considering the effect of thermal noise, clipping distortion, inter-layer interference, and the bit rate difference between layers is analysed in this paper. Since the BER performance of LACO-OFDM is closely related to its peak-to-average power ratio (PAPR) distribution, we also provide the analytical expression of the PAPR distribution in this paper, which quantifies how the number of layers in LACO-OFDM reduces the PAPR. As a further advance, we propose a tone-injection aided PAPR reduction design for LACO-OFDM, which in turn improves the BER performance. Simulations are provided for verifying both the analytical BER performance and the PAPR distribution of LACO-OFDM. The results show that the expressions derived match well with the simulations. Furthermore, the PAPR reduction method proposed attains a 5 dB PAPR reduction at the 10-3 probability-point of the complementary cumulative distribution function, as well as a better BER performance than the original LACO-OFDM scheme."
  },
  {
    "year": "2017",
    "abstract": "The introduction of smart mobile devices has radically redesigned user interaction, as these devices are equipped with numerous sensors, making applications context-aware. To further improve user experience, most mobile operating systems and service providers are gradually shipping smart devices with voice controlled intelligent personal assistants, reaching a new level of human and technology convergence. While these systems facilitate user interaction, it has been recently shown that there is a potential risk regarding devices, which have such functionality. Our independent research indicates that this threat is not merely potential, but very real and more dangerous than initially perceived, as it is augmented by the inherent mechanisms of the underlying operating systems, the increasing capabilities of these assistants, and the proximity with other devices in the Internet of Things (IoT) era. In this paper, we discuss and demonstrate how these attacks can be launched, analysing their impact in real world scenarios."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel probabilistic localization approach that relies on a Metropolis-Hastings (MH) algorithm-based Bayesian approach to visible light communication (VLC) systems. Due to the usage of the MH algorithm from Markov chain Monte Carlo methods, the positioning capability of the proposed approach becomes more robust against varying channel propagation conditions and measurement uncertainties. The validity of the proposed approach is demonstrated by numerical analyses based on simulations in 3-D indoor environments in a comparative manner with the least square (LS) and the differential LS algorithms-based localization solutions, while circumventing the shortcomings of LS-based approaches. Addressing the short range challenge in the VLC-based positioning system, an efficient hybrid localization framework is also developed for multi-tier heterogeneous networks (HetNets), jointly considering VLC and radio frequency networks. Our methodology mainly considers independent positioning solution branches that each estimate the target location by utilizing the MH-based Bayesian approach. Based on simulation results, the proposed framework for multi-tier HetNets provides a robust performance. Overall, we show that with the new VLC localization scheme, the performance in the short range is enhanced, while with HetNets the effectiveness of the localization in the long range is improved."
  },
  {
    "year": "2017",
    "abstract": "Software Engineering is a discipline that provides a systematic approach to develop software in a cost-effective manner. Successful software development is challenged by various challenges, such as varying situational contexts, conformity with standards, changing requirements, optimism of schedule, schedule pressure, software complexity, and software invisibility. Varying situational contexts are the changed circumstances that are resulted due to varying situational factors. These situational factors are the root cause of varying situations, which need to be discovered in detail. If these situational factors are left unattended, they can cause software failures. Software standards can help to deal with software failures. In this paper, we have reviewed various software engineering standards from the Institute of Electrical and Electronics Engineers Standard Association. These software engineering standards were investigated for the factors and sub-factors that can lead to varying situations among software development team members. As a result we found 12 factors grouped with 52 sub-factors that can lead to varying situations among software development team members. These resulted factors and sub-factors can act as a source for varying situations among team members. Unattended identified situational factors can lead to software failures. This paper provides a guideline for the practitioners to consider these factors and sub-factors while performing software development in order to have a successful software development."
  },
  {
    "year": "2017",
    "abstract": "Neighbor discovery protocol (NDP) is the core protocol of Internet protocol version 6 (IPv6) suite. The motive behind NDP is to replace address resolution protocol (ARP), router discovery, and redirect functions in Internet protocol version 4. NDP is known as the stateless protocol as it is utilized by the IPv6 nodes to determine joined hosts as well as routers in an IPv6 network without the need of dynamic host configuration protocol server. NDP is susceptible to attacks due to the deficiency in its authentication process. Securing NDP is extremely crucial as the Internet is prevalent nowadays and it is widely used in communal areas, for instance, airports, where trust does not exist among the users. A malicious host is able to expose denial of service or man-in-the-middle attacks by injecting spoofed address in NDP messages. With the intention to protect the NDP many solutions were proposed by researchers. However, these solutions either introduced new protocols that need to be supported by all nodes or built mechanisms that require the cooperation of all nodes. Moreover, some solutions are deviating from the layering principals of open system interconnection model. Therefore, the necessity to study NDP in details to recognize and identify the points that could be a source of enhancement has become mandatory task. This article revolves around the survey of the vulnerabilities mitigations approaches of NDP, since the time of the protocol development up to the date of finalized this paper. We described the technical specifications of NDP showing its components, functions, and working procedures. In addition, each threat of NDP is classified and explained in details. Open challenges of NDP and recommended future directions for scientific research are presented at the end of this paper."
  },
  {
    "year": "2017",
    "abstract": "Unmanned aerial vehicle (UAV) systems are one of the most rapidly developing, highest level and most practical applied unmanned aerial systems. Collision avoidance and trajectory planning are the core areas of any UAV system. However, there are theoretical and practical problems associated with the existing methods. To manage these problems, this paper presents an optimized artificial potential field (APF) algorithm for multi-UAV operation in 3-D dynamic space. The classic APF algorithm is restricted to single UAV trajectory planning and usually fails to guarantee the avoidance of collisions. To overcome this challenge, a method is proposed with a distance factor and jump strategy to solve common problems, such as unreachable targets, and ensure that the UAV will not collide with any obstacles. The method considers the UAV companions as dynamic obstacles to realize collaborative trajectory planning. Furthermore, the jitter problem is solved using the dynamic step adjustment method. Several resolution scenarios are illustrated. The method has been validated in quantitative test simulation models and satisfactory results were obtained in a simulated urban environment."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a Ka-band polarization converter is presented, which is based on multilayer slab. In order to improve impedance matching, metallic circular traces are printed periodically on each dielectric multilayer slab. Simulated results of the polarizer show that it can transform linearly polarized (LP) to circularly polarized (CP) fields over a frequency band from 23 to 35GHz (42%) with an insertion loss less than 0.5 dB. The transmitted CP wave by the polarizer is approximately robust under oblique illuminations. The polarizer is fabricated and measured by a wideband horn antenna satisfying the simulated results. Next, in order to design a high-gain CP structure around 30 GHz, an 8-element LP array antenna with Chebyshev tapered distribution is designed and integrated with the polarizer. Obviously, the antenna limits the overall bandwidth (nearly 28 to 31.5 GHz) due to the narrowband nature of the LP antenna array. When the polarizer is illuminated by an incident LP wave, the two linear components of the transmitted wave with approximately equal amplitudes and 90° phase difference on the frequency band of interest are produced. Experimental results of the proposed structure show a pure CP with a gain of 13 dBi at 30 GHz, which can be suitable for millimeter wave communication."
  },
  {
    "year": "2017",
    "abstract": "Human action recognition nowadays plays a key role in varieties of computer vision applications. Many computer vision methods focus on algorithms designing classifiers with handcrafted features which are complex and inflexible. In this paper, we focus on the human action recognition problem and utilize 3D convolutional neural networks to automatically extract both spatial and temporal features for classification. Specifically, in order to address the training problems with small data sets, we propose an internal transfer learning strategy adapted to this framework, by incorporating the sub-data classification method into transfer learning. We evaluate our method on several data sets and obtain promising results. With the proposed strategy, the performance of human action recognition is improved obviously."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with the problem of sampled-data exponential synchronization for chaotic Lur'e systems (CLSs) in the form of master-slave framework. An improved time-dependent Lyapunov functional (TDLF) is put forward to fully exploit the accessible information about sampling characteristics and nonlinearities of the CLS. By resorting to the improved TDLF, a new synchronization criterion is established, which ensures the synchronization error system is globally exponentially stable. An illustrative example is offered to demonstrate the validity and virtue of the proposed design methodology."
  },
  {
    "year": "2017",
    "abstract": "Though existing works of sign prediction have reasonable prediction performances, they suffer from the data sparseness problem, especially for the negative link prediction. Most nodes in signed social networks are connected to very limited number of other nodes, which could not provide enough knowledge for sign prediction. This paper, therefore, proposes a novel edge-dual graph preserving sign prediction model, which reconstructs the signed social network by converting the original graph into the edge-dual graph, uses Jaccard coefficient to measure the node similarity and applies support vector machine classifier to predict signs. The proposed method reconstructs the graph by converting edges of the original graph into nodes of the edge-dual graph, and creating edges for the edge-dual graph according to the connections of edges in the original graph. It is mathematically and experimentally verified that the sparseness of the signed social networks can be significantly reduced by the proposed method. Using the publicly available data sets, it is verified that the average degree of signed social networks can be 7 to 8 times enlarged by the proposed method and the sign prediction accuracy can be improved around 10% comparing with the existing works."
  },
  {
    "year": "2017",
    "abstract": "In recent years because of the increasing number and types of scientific payloads on a probe, the constraints between payload and probe and the constraints among payloads have become increasingly complex. The technology of constraint processing has gradually become a focus of research in deep space planning. In this paper, we propose a constrained-programmed planner called DSPlan for deep space planning problems based on table constraints. We first propose a technique for automatically converting the planning domain definition language model used in planning into the form of table constraints. Following the common practice of coding a planning problem as a constraint satisfaction problem with multiple levels, we propose a dynamic constraint set and a corresponding mutex filtering algorithm to express the different combinations of constraints on varying levels that need to be satisfied. This new form of data structure uses explicit domain information to maintain the generalized arc consistency of table constraints. Empirical analyses demonstrate the efficiency of table constraints over the international planning competition problem and classic deep space instances in general arc consistency schema algorithms. Experimental results also prove that DSPlan and table constraints are highly promising general-purpose tools for deep space planning problems compared with other planners."
  },
  {
    "year": "2017",
    "abstract": "Large-scale quantum network coding (LQNC) is conceived for distributing entangled qubits over large-scale quantum communication networks supporting both teleportation and quantum key distribution. More specifically, the LQNC is characterized by detailing the encoding and decoding process for distributing entangled pairs of qubits toMpairs of source-and-target users connected via a backbone route ofNhops. The LQNC-based system advocated is then compared with entanglement swapping-based systems for highlighting the benefits of the proposed LQNC."
  },
  {
    "year": "2017",
    "abstract": "A rigid satellite fault diagnosis strategy, subject to faults of external disturbances and thruster faults, is developed. In this design, an equivalent idea is introduced to design a sliding mode observer that can detect and identify the failures indicated previously. Considering the measurability of parameters of the satellite, such as angular velocity and attitude, a sliding mode observer is implemented. Next, the amplitudes of the faults and disturbances can be detected, identified, and estimated via the sliding mode observer; these tasks are accomplished with zero estimation error within a finite period. A sliding mode-based attitude controller is developed using an exponential reaching law that relies on the system states and the corresponding formation of the estimated parameters. The controller not only guarantees the attitude system to be stable but also governs the attitude and angular velocity to converge to zero within a finite period. The good reliability of the proposed controller can be proved via multiple simulation tests."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a classification algorithm based on ensemble neural networks. In the training phase, the proposed algorithm uses a random number of training data to develop multiple random artificial neural network (ANN) models until those ANN models converge. Those models with lower accuracy than the threshold are filtered out. The remaining highly accurate models will be used to predict the output in the testing phase. Meanwhile, the accuracy of ANN models is presented as a weighting value in the testing phase. In the testing phase, the testing data are loaded into the selected ANN models to predict the output class. The output values are multiplied by the corresponding weighting values of ANN models. Then the weighted average of the outputs can be obtained. Finally, the predicted output is converted into the predicted class. We design an augmented reality question answering system (AR-QAS) applying and implementing the proposed algorithm on mobile devices. AR-QAS offers an interactive user interface and automatically replies according to user's queries. By comparing with the logistic regression method and the ANN method, the experiment results demonstrate that the proposed algorithm offers the highest accuracy."
  },
  {
    "year": "2017",
    "abstract": "With the rapid development of mobile communication technology, the pressure of core network from wireless traffic is explosively growing. Meanwhile, ultra-low latency and real-time user experience are urgently demanded, which gives raise to the severe challenge of traditional cellular networks. As one of the key technologies in 5G, device-to-device (D2D) communication underlaying cellular networks is a promising way to elevate the network system performance, improve the user experience and expand the applications. In this paper, we present an architecture for analyzing the network capacity when D2D communication shares the channel resources with cellular links. This architecture consists of three types of links: cellular links, D2D links, and relay links. We mathematically model the network capacity of the three different links. Moreover, a cooperative caching strategy is proposed, which caches the files with the greatest popularity in the D2D group to improve the network capacity. Finally, we conduct the numerical simulations and the results show the proposed architecture improves the network capacity significantly."
  },
  {
    "year": "2017",
    "abstract": "Considering the low reliability and poor adaptability of existing drum shear cutting parts, this paper presents a permanent magnet short-range cutting transmission system with a low-speed and high-torque interior permanent magnet synchronous motor (IPMSM) as the driving source and a sensorless control strategy based on a new sliding mode observer (SMO). To increase the robustness of the observer and reduce the error caused by chattering in the traditional SMO, the phase-locked loop technique is used instead of the traditional arc-tangent function estimation, and the sigmoid function is introduced to replace the traditional sign function; then, the sliding mode gain is adjusted through the fuzzy control algorithm in the new SMO. The scheme effectively improves the problems of the high failure rate caused by the long transmission chain of the shearer cutting section and the environmental impact for the mechanical sensor measurement results. Finally, the mathematical model of IPMSM based on the two-phase rotating coordinate system and end cutting load is established to verify the effectiveness and feasibility of the program. The results show that the new observer can accurately realize the speed and position estimation of the shearer cutting motor, and it has good dynamic response performance, observation accuracy, and robustness."
  },
  {
    "year": "2017",
    "abstract": "Automatic modulation classification (AMC) plays a key role in non-cooperative communication systems. Feature-based (FB) methods have been widely studied in particular. Most existing FB methods are deployed at a fixed SNR level, and the pre-trained classifiers may no longer be effective when the SNR level changes. The classifiers may also need to be re-trained to be suitable for the varying channel environment. To address these problems, a robust AMC method under varying noise conditions is proposed in this paper. The method attempts to select noise-insensitive features from a large feature set to ensure that the trained classifiers will be robust to SNR variations. First, a feature set consisting of 25 types of features is extracted, and 4 features that are insensitive to noise are chosen through a feature selection method based on rough set theory. The generalizability of an SVM classifier trained on the 4 chosen features is evaluated based on numerical results. The classification accuracy remains reasonable when the SNR varies between 5 and 20 dB, indicating that the proposed method can be deployed under varying noise conditions."
  },
  {
    "year": "2017",
    "abstract": "An improved understanding of customer preference is crucial for successful business in physical stores. Online stores are capable learning customer preference from the click logs and transaction records, while retailers with physical store still lack effective methods to in-depth understand customer preference. Fortunately, user-generated data from mobile devices and social media are providing rich information to uncover customer preference. In this paper, we present a novel approach to mine customer preference in physical stores from their interaction behaviors. To demonstrate the utility of the proposed model, we conduct a store-type recommendation model for physical stores by jointly considering the learned customer preference and temporal influence. We have performed a comprehensive experiment evaluation on two real-world data sets, which are collected by more than 120 000 customers during 12 months from two urban shopping malls. Experimental results show the superiority of the proposed model not only in recommending interesting stores for customer, but also help retailers better understand customer preference."
  },
  {
    "year": "2017",
    "abstract": "The rapid and accurate measurement of the volume of a large cavity is much in demand in practice, especially for a cavity of irregular shape. In this paper, a new method is proposed to measure the volume of a large cavity. This method is based on the measurement of the decay time constant of the cavity. A lossy object with a known averaged absorption cross section is used to aid the measurement. By measuring decay time constants of the cavity with and without the lossy object, the cavity volume can be extracted. It is found that only one antenna is required for the measurement and the whole measurement can be completed simply and rapidly. The method could be applied to both metallic and non-metallic cavities which makes the proposed method a very attractive alternative to existing methods."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a new source number estimator with improved degrees of freedom for blind source separation, where the mixing matrix does not have the parameterized structure. In order to enhance the degrees of freedom, we exploit the sample dependence of each source and construct a new matrix by vectorizing some delayed covariance matrices based on Khatri-Rao product. Then, an improved Gerschgorin disk estimator for source number is presented based on the new matrix. This estimator can detect the number of sources up to 2M - 1 using only M sensors, while the traditional source number estimators can merely estimate the number of sources less than M employing the same number of sensors. Simulation results verify the superiority of the proposed method by comparing with the existing source enumeration methods in scenario of spatially non-uniform noise when the sensor number is more than the source number and validate the reliability of the proposed method in the case with fewer sensors than sources."
  },
  {
    "year": "2017",
    "abstract": "Parkinson's disease (PD) is a progressive neurodegenerative motor system disorder. Early diagnosis of PD is important to control the symptoms appropriately. Recent voice and speech recognition techniques provide alternative solutions for PD screening. In this paper, an optimal support vector machine (SVM) based on bacterial foraging optimization (BFO) was established to predict PD effectively. The effectiveness of the proposed method, BFO-SVM, was validated on a PD data set based on vocal measurements. The proposed method was compared with two of the most frequently used parameter optimization methods, including an SVM based on the grid search method and an SVM based on particle swarm optimization. Additionally, to further boost the prediction accuracy, the relief feature selection was employed prior to the BFO-SVM method, consequently the RF-BFO-SVM was proposed. The experimental results have demonstrated that the proposed framework exhibited excellent classification performance with a superior classification accuracy of 97.42%."
  },
  {
    "year": "2017",
    "abstract": "Controllers are designed to regulate output voltage and improve dynamic performance of dc-dc converter to variable supply voltage, load current or circuit element variation. Conventional controller like PID has narrow dynamics that limit its application to quiescent supply input voltage and load current change. Recent research efforts are exploiting state of the art power electronics devices and high computational speed digital signal processor to improve transient and dynamics performance of power converters through advanced modern control techniques. This paper presents a design and evaluation of observer state output feedback controller for phase-shifted full bridge zero voltage switching dc-dc converter output voltage regulation to widen the supply input voltage. The converter closed-loop control was implemented in MATLAB/Simulink environment and the results demonstrated improved transient response to wider supply voltage and sudden load current change as compared with the conventional PID controller."
  },
  {
    "year": "2017",
    "abstract": "Health care professionals are increasingly viewing medical images and videos in a variety of environments. The perception of medical visual information across all specialties, career stages, and practice settings are critical to patient care and patient safety. Visual signal distortions, such as various types of noise and artifacts arising in medical imaging, affect the perceptual quality of visual content and potentially impact diagnoses. To optimize clinical practice, it is of fundamental importance to understand the way medical experts perceive visual quality. Psychophysical studies have been undertaken to evaluate the impact of visual distortions on the perceived quality of medical images and videos. However, very little research has been conducted on how speciality settings affect the perception of visual quality. In this paper, we investigate whether and how radiologists and sonographers differently perceive the quality of compressed ultrasound videos, via a dedicated subjective experiment. The findings can be used to develop useful solutions for improved visual experience and better image-based diagnoses."
  },
  {
    "year": "2017",
    "abstract": "Ultra-dense deployment of small cell networks is widely regarded as a key role to meet the increasing demand for huge capacity of wireless communication systems. Meanwhile, network densification will result in severe inter-cell interference and thus impair system performance. Traditional radio resource management schemes pay attention to interference mitigation through resource allocation in time, frequency, space, and power domains, or a mix of them. In this paper, polarization, an important and underutilized property of electromagnetic waves, is exploited as a novel means to enhance system capacity. We propose a multicell joint polarization, power and subcarrier allocation (MC-JPPSA) scheme to maximize system capacity through joint optimization of transmitting polarization states, power, and subcarriers with an iterative approach. Though the iterative solution is suboptimal, simulation results demonstrate that MC-JPPSA scheme can strike a balance between performance and complexity compared with the optimal exhaustive search. Furthermore, the proposed scheme outperforms traditional joint power and subcarrier allocation schemes by means of exploiting polarization in ultra-dense small cell networks."
  },
  {
    "year": "2017",
    "abstract": "Predicting students' grades has emerged as a major area of investigation in education due to the desire to identify the underlying factors that influence academic performance. Because of limited success in predicting the grade point average (GPA), most of the prior research has focused on predicting grades in a specific set of classes based on students' prior performances. The issues associated with data-driven models of GPA prediction are further amplified by a small sample size and a relatively large dimensionality of observations in an experiment. In this paper, we utilize the state-of-the-art machine learning techniques to construct and validate a predictive model of GPA solely based on a set of self-regulatory learning behaviors determined in a relatively small-sample experiment. We quantify the predictability of each constituents of the constructed model and discuss its relevance. Ultimately, the goal of grade prediction in similar experiments is to use the constructed models for the design of intervention strategies aimed at helping students at risk of academic failure. In this regard, we lay the mathematical groundwork for defining and detecting probably helpful interventions using a probabilistic predictive model of GPA. We demonstrate the application of this framework by defining basic interventions and detecting those interventions that are probably helpful to students with a low GPA. The use of self-regulatory behaviors is warranted, because the proposed interventions can be easily practiced by students."
  },
  {
    "year": "2017",
    "abstract": "Spatiotemporal information and application have received considerable attention. Spatiotemporal information is often imprecise or uncertain; therefore, the establishment of a reasonable and effective fuzzy spatiotemporal data model is vital. The traditional tool-based modeling method cannot meet the needs of fuzzy spatiotemporal data modeling. XML has become the standard of Web data representation and exchange. Based on the fuzzy set and probability theory, this paper analyzes the characteristics of fuzzy spatiotemporal data and establishes a fuzzy spatiotemporal XML data model. We present a fuzzy spatiotemporal UML data model and provide the rules for converting the fuzzy spatiotemporal UML data model to the fuzzy spatiotemporal XML model. We demonstrate our model and the conversion by applying them to a meteorological event."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an autonomic network management and policy execution framework. The proposed framework refactors the network functionalities by decomposing the network architecture into hierarchical layered architecture. This paper aims at enabling the transition from a rule-based control structure to a more distributed and autonomic network control by implementing the self-x or self-* learning vision on each layer. The problem is modeled using multi-layer dynamic games. At each layer, a self-* learning procedure is proposed to learn and adapt the reverse Stackelberg policies. To validate the proposed framework, we develop a full scale demonstrator comprising of flat IP core and heterogeneous wireless access networks. We have also developed various tools and software agents to implement the self-x management vision. The proposed self-x learning is implemented via mobile intelligent agents in a distributed fashion. Our experimental results show quick re-stabilization of the self-* learning in mobile intelligent agents and the observed performance remain well above the satisfactory values for different key performance indicator with the proposed meta-learning approach."
  },
  {
    "year": "2017",
    "abstract": "User identification is very helpful for building a better profile of a user. Some works have been devoted to this issue. However, the existing works with a good performance are mainly based on the rich online data and do not consider the cost of online data acquisition. In this paper, we aim to address this issue with a lower cost of data acquisition. A machine learning-based solution is proposed solely based on the user’s display names. It consists of three key steps: we first analyze the users’ unique naming patterns that lead to information redundancies across sites; second, we construct features that exploit information redundancies; afterward, we employ machine learning method for user identification. The experiment shows that the proposed solution can provide excellent performance with F1 score reaching 96.24%, 92.49%, and 90.68% on three real different data sets, respectively. This paper shows the possibility of user identification with a lower cost of data acquisition."
  },
  {
    "year": "2017",
    "abstract": "To consider the uncertainty when determining the values of geo-mechanical parameters, interval values are used to indicate the physical and mechanical parameters of the rockmass. An interval non-probabilistic reliability model of the surrounding jointed rockmass of an underground opening, which can be used when the data are scarce, is developed to evaluate the stability of the rockmass in the Jiaojia gold mine. The calculation results of the interval non-probabilistic reliability are in agreement with the actual situation. Thus, the interval non-probabilistic reliability is a beneficial complement to the traditional analysis methods of the random reliability and the safety factor."
  },
  {
    "year": "2017",
    "abstract": "Social networks (SNs) have been gradually applied by utility companies as an addition to smart grid and are proved to be helpful in smoothing load curves and reducing energy usage. However, SNs also bring in new threats to smart grid: misinformation in SNs may cause smart grid users to alter their demand, resulting in transmission line overloading and in turn leading to catastrophic impact to the grid. In this paper, we discuss the interdependence in the SN coupled smart grid and focus on its vulnerability. That is, how much can the smart grid be damaged when misinformation related to it diffuses in SNs? To analytically study the problem, we propose the misinformation attack problem in social-smart grid that identifies the top critical nodes in the SN, such that the smart grid can be greatly damaged when misinformation propagates from those nodes. This problem is challenging as we have to incorporate the complexity of the two networks concurrently. Nevertheless, we propose a technique that can explicitly take into account information diffusion in SN, power flow balance, and cascading failure in smart grid integratedly when evaluating node criticality, based on which we propose various strategies in selecting the most critical nodes. Also, we introduce controlled load shedding as a protection strategy to reduce the impact of cascading failure. The effectiveness of our algorithms is demonstrated by experiments on the IEEE bus test cases as well as the Pegase data set."
  },
  {
    "year": "2017",
    "abstract": "The accurate measurement of wave velocity has a significant effect on the locating accuracy of acoustic emission sources, especially in health assessment and determination for rock structures. There commonly exists some deviation between the measured velocity value and the actual velocity value due to the anisotropy of rock velocity, which causes the large locating error. In this paper, the locating error caused by the anisotropy for P-wave velocity is discussed quantitatively. The locating experiments were carried out on the sandstone sample, whose length, width, and height are 100, 100, and 200 cm respectively. The mineral composition and micro structures for the sample were observed. AE sources were triggered by lead breaks and the arrival times were detected through eight sensors. Then, the sources can be located based on time difference locating method. Results show that the difference of wave velocity is large in different directions, which reaches 2400 m/s. The errors of wave velocity affect the locating accuracy seriously, which is up to 20.5%. A total of 135 groups of velocity values in different directions were measured. It is found that the locating accuracy of repeatedly measuring velocity through diagonal line is higher than accuracy of traditional used axial velocity. In addition, the source locating accuracy can be improved greatly by measuring and solving the average wave velocity in multiple directions. However, the average velocity value corresponds to the locating result is not the best. Tests clarify that the optimal velocity is higher than the average velocity. It is suggested that the wave velocity should be measured in multiple directions for several times when performing the laboratory acoustic emission (AE) sources locating experiments. The conclusions provide important theoretical guidance for the current traditional AE sources locating experiments with only average value of axial velocities."
  },
  {
    "year": "2017",
    "abstract": "The security of streaming data should be ensured in current complex data era in order to provide a trusted and secure network environment. To authenticate the scalable video coding (SVC) streams by fully utilizing its decoding relationship without reducing its scalability, we establish an acyclic and directed decoding dependence graph (DDG) on the logical units of SVC steams. By applying the topological sort on DDG, we obtain the hash appendence mode for different layers of the streams (i.e., spatial and temporal layers). We propose a secure and efficient SVC authentication method based on the deduced hash appendence mode. With regard to the quality layer, we consider the corresponding quality data packets with unequal importance, and propose a grouping authentication strategy with constrained group lengths. We form the optimization problem of minimizing the authentication cost, and solve it by an iteration method. Simulation results show that our authentication approach can achieve much less computation cost and much lower overhead, while it can preserve higher verification rates and better recovered quality of video as compared with other state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "In modern power systems, the stochastic and interactive characteristics of mixed generations have gained increasing interest, especially when more renewable energy sources are connected to the grid. The uncertainty of renewable energy has notable effects on power system security. In this paper, a set of composite security indices, which are derived from the Hyper-box and Hyper-ellipse Space theory, are extended by a Latin hypercube sampling method to model multiple probabilistic scenarios under uncertainty. Thus, the proposed approach is suitable for power system security assessment with wind power integrated. According to the indices, a security-based active demand response (DR) strategy is proposed. This strategy is able to provide expected active DR capacity based on the forecast wind power fluctuations. Therefore, it can be applied to day-ahead power system dispatches."
  },
  {
    "year": "2017",
    "abstract": "Voltage-source converter-based multiterminal high-voltage direct current (VSC-MTDC) systems/grids are prone to system instability. This critical issue is overlooked in the literature. In order to improve system stability, this paper proposes an effective active damping method as a remedy to suppress voltage and power resonances in the VSC-MTDC grids by injecting damping signals into the inner current loops of VSC-MTDC stations. With dynamic regulation of the damping current, resonance is suppressed by power converter controllers without any additional current and voltage measurement. In this paper, modeling and stability analysis of the VSC-MTDC system/grid is presented considering the dc-side energy storage components, and control with a droop control structure. Then, single-frequency and multifrequency resonance mechanisms of dc-bus voltage and power in the event of transients are analyzed. Later, the stability effect of the MTDC system/grid inductance and capacitance values to the resonance amplitude and frequency droop coefficients is investigated. A PSCAD/EMTDC platform is developed to conduct dynamic simulations, and a scaled-down four-terminal 20-kW experimental prototype is used to validate the effectiveness of the proposed control methodology."
  },
  {
    "year": "2017",
    "abstract": "Multiple-input multiple-output orthogonal frequency division multiplexing with index modulation (MIMO-OFDM-IM) is a relatively new multicarrier transmission technique for the MIMO systems to achieve both energy and spectral efficiency. However, due to the dependence of subcarrier symbols introduced by the index modulation, existing MIMO detection techniques cannot be applied in MIMO-OFDM-IM as it will lead to erroneous detection on index information of the active subcarriers and further deteriorate the system performance. In this paper, we first develop an optimal detection algorithm with reduced complexity for MIMO-OFDM-IM by performing the subcarrier-wise detection under the constraint on the legal subcarrier combination within each OFDM-IM subblock. To further reduce the computational complexity, we then propose a low-complexity subcarrier-wise algorithm based on the deterministic sequential Monte Carlo technique to achieve near-optimal detection for MIMO-OFDM-IM. Specifically, the near-optimal detector applies the QR decomposition to generate an upper triangular structure and draw antenna-wise samples at the subcarrier level. Computational simulations and complexity analysis show that the proposed algorithms provide similar performance to optimal one with reduced computational complexity."
  },
  {
    "year": "2017",
    "abstract": "With the rapid development of mobile health technologies and applications in recent years, large amounts of electrocardiogram (ECG) signals that need to be processed timely have been produced. Although the CPU-based sequential automated ECG analysis algorithm (CPU-AECG) designed for identifying seven types of heartbeats has been in use for years, it is single-threaded and handling lots of concurrent ECG signals still poses a severe challenge. In this paper, we propose a novel GPU-based automated ECG analysis algorithm (GPU-AECG) to effectively shorten the program executing time. A new concurrency-based GPU-AECG, named cGPU-AECG, is also developed to handle multiple concurrent signals. Compared with the CPU-AECG, our cGPU-AECG achieves a 35 times speedup when handling 24-h-long ECG data, without reducing the classification accuracy. With cGPU-AECG, we can handle 24-h-ECG signals from thousands of users in a few seconds and provide prompt feedback, which not only greatly improves the user experience of mobile health services, but also reduces the economic cost of building healthcare platforms."
  },
  {
    "year": "2017",
    "abstract": "Low-quality surveillance cameras throughout the cities could provide important cues to identify a suspect, for example, in a crime scene. However, the license-plate recognition is especially difficult under poor image resolutions. In this vein, super-resolution (SR) can be an inexpensive solution, via software, to overcome this limitation. Consecutive frames in a video may contain different information that could be integrated into a single image, richer in details. In this paper, we design and develop a novel, free and open-source framework underpinned by SR and automatic license-plate recognition (ALPR) techniques to identify license-plate characters in low-quality real-world traffic videos, captured by cameras not designed specifically for the ALPR task, aiding forensic analysts in understanding an event of interest. The framework handles the necessary conditions to identify a target license plate, using a novel methodology to locate, track, align, super-resolve, and recognize its alphanumerics. The user receives as outputs the rectified and super-resolved license-plate, richer in detail, and also the sequence of license-plates characters that have been automatically recognized in the super-resolved image. Additionally, we also design and develop a novel SR method that projects the license-plates separately onto the rectified grid, and then fill in the missing pixels using inpainting techniques. We compare the different algorithms in the framework (five for tracking, three for registration, seven for reconstruction, two for post-processing, and two for the recognition step), and present discussions on the pros and cons of each choice. Our experiments show that SR can indeed increase the number of correctly recognized characters posing the framework as an important step toward providing forensic experts and practitioners with a solution for the license-plate recognition problem under difficult acquisition conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with microwave hyperthermia, presenting a novel way to achieve the blind focusing on the tumor of the electric field radiated by an array of antennas. As in a recently proposed approach, the idea is to determine the antenna excitations by measuring the variation of the electric field arising from a localized variation of the electromagnetic contrast, without requiring any apriori knowledge of the geometry and of the electric properties of the tissues wherein the electromagnetic field propagates (thus, the adjective “blind”). The first novelty of the new approach is the use of magnetic nanoparticles as contrast agents, which, in addition to being biocompatible, are appealing thanks to the possibility of changing their magnetic contrast, in a fast, remote, and reversible way, by applying an external magnetic field. This allows a reconfigurable focusing through a continuous tuning of the antenna excitations, thereby enabling one to counteract the possible loss of focusing that could occur during the treatment. However, the magnetic nature of the induced contrast variation requires the development of ad hoc strategies for the synthesis of the excitations, which represent the other novelty of the new approach. Its effectiveness has been thoroughly investigated with an exhaustive 2-D numerical analysis, considering as case study that of breast cancer, and further assessed through 3-D realistic numerical simulations."
  },
  {
    "year": "2017",
    "abstract": "Graph-based ranking models, such as manifold ranking (MR), have been widely used in various image retrieval applications. To further improve such models, a current trend is to fuse the ranking results from multiple feature sets. Most of existing methods mainly concentrate on fusing the homogeneous feature sets derived from a single information channel, like the multiple modalities of image visual content, but little is known in fusing such heterogeneous feature sets derived from multiple information channels as the click-through data associated with images and their visual content. The primary challenge is how to effectively exploit the complementary properties of the heterogeneous feature sets. Another tough issue is the low-quality nature of the click-through data, which makes the exploration of such complementary properties more difficult. In this paper, we propose a heterogeneous MR (HMR) model, in which a couple of graphs built on the click and visual feature sets are fused to simultaneously encode the image ranking results. Specifically, our HMR model applies different solutions to fuse the heterogeneous feature sets in terms of whether the relevance feedback mechanism is available or not. In addition, we develop a click refinement technique to address the noiseness and sparseness problems inherent in the click-through data. Concretely, it prunes the inaccurate clicks from the click-through data using a neighbor voting strategy, and then enriches the pruned data with novel yet accurate clicks based on a novel collaborative filtering (CF) approach, which is devised by integrating the merits of three popularly used CF methods, thus called TriCF algorithm. Extensive experiments on the tasks of click refinement and image retrieval demonstrate the superior performance of the proposed algorithms over several representative methods, especially when the click-through data is highly noisy and sparse."
  },
  {
    "year": "2017",
    "abstract": "Exudates can be regarded as one of the most prevalent clinical signs of diabetic retinopathy, and the detection of exudates has important clinical significance in diabetic retinopathy diagnosis. In this paper, a novel approach named superpixel multi-feature classification for the automatic detection of exudates is developed. First, an entire image is segmented into a series of superpixels considered as candidates. Then, a total of 20 features, including 19 multi-channel intensity features and a novel contextual feature, are proposed for characterizing each candidate. A supervised multi-variable classification algorithm is also introduced to distinguish the true exudates from the spurious candidates. Finally, a novel optic disc detection technique is designed to further improve the performance of classification accuracy. Extensive experiments are carried out on two publicly available online databases, DiaretDB1, and e-ophtha EX. Compared with other state-of-the-art approaches, the experimental results show the advantages and effectiveness of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a pricing strategy for energy management in the electricity market composed of one generation company, multiple competing utility companies, and consumers with heating, ventilation, and air conditionings, which participate in demand response to keep the electricity real-time balance. The utility company plays the role of an intermediary agent between the generation company and consumers. We model the cost of the utility companies from the demand-side regulation and give the condition of a unique optimal regulation price. For the multiple competing utility companies, we demonstrate that the retail pricing game belongs to the supermodular game and the game exists a pure Nash equilibrium. The uniqueness of the Nash equilibrium is also proved, and then a distributed algorithm is developed to search for the optimal equilibrium price. Furthermore, we study the influence of the wholesale price on the equilibrium. Finally, numerical results demonstrate the efficiency of the proposed pricing strategy."
  },
  {
    "year": "2017",
    "abstract": "Social networks have become one of the most popular platforms for users to interact with each other. Given the huge amount of sensitive data available in social network platforms, user privacy protection on social networks has become one of the most urgent research issues. As a traditional information stealing technique, phishing attacks still work in their way to cause a lot of privacy violation incidents. In a Web-based phishing attack, an attacker sets up scam Web pages (pretending to be an important Website such as a social network portal) to lure users to input their private information, such as passwords, social security numbers, credit card numbers, and so on. In fact, the appearance of Web pages is among the most important factors in deceiving users, and thus, the similarity among Web pages is a critical metric for detecting phishing Websites. In this paper, we present a new solution, called Phishing-Alarm, to detect phishing attacks using features that are hard to evade by attackers. In particular, we present an algorithm to quantify the suspiciousness ratings of Web pages based on the similarity of visual appearance between the Web pages. Since cascading style sheet (CSS) is the technique to specify page layout across browser implementations, our approach uses CSS as the basis to accurately quantify the visual similarity of each page element. As page elements do not have the same influence to pages, we base our rating method on weighted page-component similarity. We prototyped our approach in the Google Chrome browser. Our large-scale evaluation using real-world websites shows the effectiveness of our approach. The proof of concept implementation verifies the correctness and accuracy of our approach with a relatively low performance overhead."
  },
  {
    "year": "2017",
    "abstract": "The acoustic emission (AE) and microseismic (MS) monitoring are efficient methods to detect faults/breaking signals for both healthy evaluation and disaster control in mining engineering. This paper presents an MS or AE source location method without the need for a pre-measured wave velocity. It can eliminate the location errors for MS/AE monitoring systems caused by the deviations of the wave velocity. To verify the applicability of the proposed method, first, tests of both the pencil lead break and the thermal fracture in granite were carried out, and location errors were compared and analyzed. Results show that the location accuracy of the proposed method is significantly improved, which is superior to the results of the traditional location method (TM) using pre-measured wave velocity. Second, blasting experiments were carried out in Dongguashan copper mine in China. The blasts were used as simulated seismic sources. Average values of absolute distance errors of the MS/AE source locations resulting from the proposed method without wave velocity and the traditional method using average measured wave velocity are 10.16 and 17.55 m, respectively. It shows that the calculated locations by the proposed method are in better agreement with the real blast coordinates. Third, the proposed method is also applied to previously published data. It gives superior results compared with the considered existing methods. Results of the pencil lead break tests, the thermal fracture experiment in granite, and the blasting experiments (including published data) have demonstrated that the proposed method can not only decrease the location errors induced by measurement deviation of velocity, but also locate the MS/AE source in real time, which is a beneficial complement to the method TM in mines."
  },
  {
    "year": "2017",
    "abstract": "A symmetrical hybrid driving waveform (SHDW) is proposed in this paper, which includes a symmetrical saw-tooth driving waveform and a sinusoidal friction regulation waveform, and the sinusoidal friction regulation waveform is applied to the shrinkage period of the symmetrical saw-tooth driving waveform. In other words, the proposed SHDW can be achieved when the waveform symmetry of the hybrid driving method is 50%. The SHDW can effectively drive the designed symmetrical linear piezoelectric stick-slip actuator, and the motion direction is also easily regulated. The excitation principle of the actuator excited by the SHDW is explained in detail. A prototype is fabricated and the experimental investigations of the actuator characteristics are carried on. The higher velocity and the larger driving capacity are realized using by the SHDW relative to the asymmetrical hybrid driving waveform. Testing results show that the prototype excited by the SHDW can obtain the peak no-load speeds of 0.41 and 0.39 mm/s in the forward and reverse directions when the saw-tooth driving waveform voltage is 10Vp-pfor 800 Hz and the sinusoidal friction regulation waveform voltage is 2Vp-pfor 39 kHz. The step efficiencies can reach 92% and 90%. The driving capacities can reach 10.52 and 9.85 [(mm/s)g/mW] with the load of 70 g under the locking force of 0.1 N. The actuator excited by the SHDW will make it ideal for miniature information technology devices."
  },
  {
    "year": "2017",
    "abstract": "This paper considers user cooperation and a pricing mechanism in a wireless-powered communication network (WPCN) in which two users harvest energy from a dedicated hybrid access point (H-AP), which has a constant power supply and acts as a power station during a downlink (DL). They also independently transmit their information to the H-AP [which acts as an information receiving station during an uplink (UL)] using the individually harvested energy. Based on the “doubly near-far”problem, this paper proposes a cooperative scheme among users in the WPCN. Compared with the source user (SU), the channel conditions for a helping user (HU), which is closer to the H-AP, is usually better for DL energy harvesting and for transmitting UL information. Thus, the HU can use its harvested energy to forward the SU's information to the H-AP. Furthermore, energy is usually scarce for each user in a WPCN; therefore, the HU is under no obligation to accept the SU's cooperative request and can choose to act selfishly to conserve resources. This paper presents a new pricing strategy to motivate the HU to sell its excess energy to help an SU complete a UL information transfer. Two transmission protocols are investigated: in the ideal case, the energy expenditure of the SU equals the energy used by the HU to relay information; in the normal case, the HU seeks additional profit. This paper formulates the SU's expenditures and relay data in the ideal case as an optimization problem. An investigation of relay placement and the SU communication mode selection problem are also discussed. The numerical results show that the proposed pricing strategy can significantly reduce the expected costs to the SU and improve the reliability of user UL communications in a WPCN."
  },
  {
    "year": "2017",
    "abstract": "Next-generation networks (NGNs) are embracing two key principles of software defined networking (SDN) paradigm functional segregation of control and forwarding plane, and logical centralization of the control plane. A centralized control enhances the network management significantly by regulating the traffic distribution dynamically and effectively. An eagle-eye view of the entire topology opens up the opportunity for an SDN controller to refine the routing. Optimizing the network utilization in terms of throughput is majorly dependent on the routing decisions. Open Shortest Path First (OSPF) and Intermediate System to Intermediate System (IS-IS) are well-known traditional link state routing protocols proven with operation over operator networks for a long time. However, these classical protocols deployed distributively fall short of expectation in addressing the current routing issues due to the lack of a holistic view of the network topology and situation, whereas handling enormous traffic and user quality of experience (QoE) requirements are getting critical. IP routing in NGN is widely expected to be supported by SDN to enhance the network utilization in terms of throughput. We propose a novel routing algorithm-CentFlow, for an SDN domain to boost up the network utilization. The proposed weight functions in CentFlow achieve smart traffic distribution by detecting highly utilized nodes depending on the centrality measures and the temporal node degree that changes based on node utilization. Furthermore, the frequently selected edges are penalized thereby augmenting the flow balancing and dispersion. CentFlow reaps greater benefits on an SDN controller than the classical OSPF due to its comprehensive view of the network. Experimental results show that CentFlow enhances the utilization of up to 62% of nodes and 49% of links, respectively, compared to an existing Dijkstra algorithm-based routing scheme in SDN. Furthermore, nearly 6.5% more flows are processed network..."
  },
  {
    "year": "2017",
    "abstract": "An energy management system (EMS) that is augmented by Internet of Things (IoT) is introduced. Using IoT technology, real-time energy-consumption data can be efficiently collected and analyzed, leading to an improved awareness and evaluation of the energy consumption of manufacturing processes. The architecture and function of the IoT-based EMS are introduced. Because the existing monitoring standard for energy conservation defines only the minimum evaluation criterion, the result is either qualified or unqualified. Fully characterizing the energy consumption of industrial energy-intensive equipment is challenging. For this reason, this paper constructs a comprehensive evaluation model for monitoring industrial energy conservation. An evaluation index for industrial energy-intensive equipment is proposed. Then, by integrating an analytic hierarchy process and a fuzzy comprehensive evaluation method, a method is provided for an IoT-based industrial EMS to fully evaluate the operational level of energyintensive equipment. Finally, a case study is provided to verify the effectiveness of this method."
  },
  {
    "year": "2017",
    "abstract": "Currently, the cleaning process for power equipment monitoring data is cumbersome and often leads to loss of information. To address these problems, a data cleaning method based on stacked denoising autoencoder (SDAE) networks is proposed in this paper. SDAE networks have a strong ability to denoise and restore corrupted data and have a strong feature extraction capability. The status monitoring data of equipment under normal conditions are trained by SDAE to obtain the cleaning parameters and the reconstruction errors. An upper threshold of the reconstruction errors obtained from training samples is determined through Kernel density estimation. A tolerance window width is added to achieve rapid anomaly detection. The abnormal data are classified as outliers, missing data, or fault status data according to the relationship between the reconstruction error and the threshold and between the duration of abnormal data and the tolerance window. To verify the effectiveness of the proposed method, the SDAE model is used to process the data for the dissolved gas concentration in transformer oil and the temperature of the transmission line. The results show that the proposed method can effectively identify and repair outliers and missing information. The model can perform rapid anomaly detection when the equipment is running abnormally."
  },
  {
    "year": "2017",
    "abstract": "In order to solve the problems of high gas consumption and low battery power in hybrid electric buses, the logic threshold control strategy is optimized by the key technology research of driving conditions, control strategy, and so on. First, driving condition data of hybrid electric buses are collected and analyzed, and three typical working conditions are selected. Second, the torque distribution control strategy is investigated based on the instantaneous optimization algorithm. The objective function of the instantaneous equivalent fuel consumption is derived. The process of solving the objective function is attributed to linear programming problem of the nonlinear objective function. The SIMULINK model of instantaneous torque distribution strategy is established based on equivalent fuel consumption. On this basis, the SIMULINK model of the function which can be integrated into the vehicle control model is established. Then, considering the actual driving conditions of the bus, the vehicle control strategy model is established in the MATLAB/SIMULINK environment, and the vehicle model established by the cruise software. Finally, the vehicle model is simulated under three representative working conditions. The main contribution of this paper is the optimized torque distribution control strategy to control hybrid electric bus's energy distribution and reduce emissions. The strategy can be obtained by combining the logic threshold torque distribution control strategy, along with the optimal engine torque and motor torque, which can be obtained by solving the objective function of instantaneous equivalent fuel consumption. Results show that compared with the logic threshold value torque distribution control strategy, the energy control strategy of the instantaneous optimization algorithm can further reduce gas consumption and maintain the state of charge value balance of the power battery."
  },
  {
    "year": "2017",
    "abstract": "Mobile device and its applications have revolutionized the way we store and share data. It is becoming a warehouse of users personal information. Unluckily, most of these data are stored in an unencrypted format, prone to security threats. In this paper, we propose a lightweight, computationally efficient protocol, called CLOAK, for the mobile device. CLOAK is based on stream cipher and takes the help of an external server for the generation and distribution of cryptographically secure pseudo-random number (CSPRN). In order to enhance the security of our protocol, we use the concept of symmetric key cryptography. We present three versions of the protocol referred as s-CLOAK, r-CLOAK and d-CLOAK, varying on the basis of the key selection procedure. In CLOAK, the core encryption/decryption operation is performed within the mobile devices to secure data at its origin. The security of CSPRN is ensured using deception method. In CLOAK, all messages are exchanged securely between mobile and the server with mutual identity verification. We evaluate CLOAK on Android smart phones and use Amazon Web services for generating CSPRN. Additionally, we present attack analysis and show that the brute force attack is computationally infeasible for the proposed protocol."
  },
  {
    "year": "2017",
    "abstract": "An ultra wide band (UWB)-based time-delay indoor human localization scheme is proposed to provide indoor human localization with time-delay measurements. The human position is localized using the UWB-based distance data and the extended finite impulse response (EFIR) estimator employing the timedelay localization model. Only one-step delayed measurements are considered in this paper. We employ the state augmentation method to combine the delayed and not delayed states. To improve the localization robustness for the time-delay localization model, we employ the EFIR filter, which does not require the noise statistics. The experimental results have shown that the EFIR estimator is more robust than the extended Kalman filter-based one for the delayed data."
  },
  {
    "year": "2017",
    "abstract": "Conductive polymer composites have been receiving increased interest both from the scientific community and industry with a special focus on electromagnetic interference (EMI) shielding applications. In this paper, we present the design, EM wave simulation, and validation through S-parameters measurements of an EMI shielding effectiveness (SE) tester based on the ASTM D4935 standard, to be used in the development of such materials. EM wave simulations and computer aided design were used in parallel to improve the SE test setup performance, which resulted in a unique low-loss coaxial-spherical-conical smooth transition design that ensured the best tradeoff between sample size and performance. The proposed SE tester has an insertion loss smaller than 1 dB, with good reproducibility and a setup-independent frequency response in the frequency range from a few kHz up to 3 GHz."
  },
  {
    "year": "2017",
    "abstract": "Robust optimization seeks designs with optimized performance and low sensitivity to possible variations in a product's life-cycle. As a popular robust design scheme in industry, Taguchi method uses the signal-to-noise ratio (SNR) as a metric of robustness. However, the Taguchi experimental design includes an inner orthogonal arrays (OA) for control factors and an outer OA for noise factors in estimating SNR-based robustness, raising a serious cost concern, especially if expensive samples are involved. Furthermore, rigorous control of noise factors to prespecified levels in the outer OA is impractical in engineering applications. This paper presents a novel approach, robust optimization using evolving reliable Kriging surrogate (ROERKS) that uses an evolving surrogate model to approximate the actual system, and uses a soft outer array to estimate the robustness. Both control variables and noise factors are merged into a combined experimental design served as the training samples to construct a Kriging-based surrogate model. An evolutionary optimizer is applied to search of the subspace of the design variables for a robust optimal solution, and a soft outer array is introduced to estimate the fitness function consisted of the mean and the variance response of evolving individual. To accommodate reduced accuracy of the surrogate model owing to an inadequate sample size, an issue that commonly arises in expensive optimization, the proposed algorithm uses a reliable region to constrain the genetic algorithm search. The verification result of the quasi-optimum is then added to the training samples to refine the evolving surrogate and to adjust the reliable region. A hybrid infilling strategy is then introduced to prevent the early convergence of the quasi-optimum. If the predicted optimum is in close proximity to current samples, the infilling strategy switches to an alternative sample with maximum expected improvement to improve sample efficiency. The iteration process c..."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a fault detection and location (FDL) system for the situation of the coexistence of faults and health degradation in aeroengines. The FDL is able to locate the faulty sensors and actuators when the two kinds of faults coexist and avoid the interference of health degradation. The FDL is formed by a matrix of hybrid Kalman filters, and the different performances of hybrid Kalman filters can be used to distinguish the different faults. The proposed approach is applied to the nonlinear aeroengine model, and the ability of the proposed approach to detect and locate the faulty sensors and actuators reliably is demonstrated. According to the results, the FDL is able to locate the faulty sensors and actuators during the interference of health degradation."
  },
  {
    "year": "2017",
    "abstract": "We propose an ontological Chinese legal consultation system (CLCS) based on Chinese legal characteristics by integrating statutes and judicial precedents to facilitate the retrieval of relevant statutes and judgments for the general public. Ontology, an emerging research topic in recent years, incorporates a hierarchical structure and supports logical reasoning, which can reduce semantic ambiguities and extract implied semantic information. We constructed statutes ontology and a case ontology using a bottom-up method and a top-down method, respectively. Then, to test the retrieval precision of the proposed CLCS, we performed experiments using emotional damage compensation as an example by combining genetic algorithm and k-nearest neighbor approaches. Experimental results demonstrate that the proposed method improves retrieval precision."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a hybrid structure-adaptive radial basis function-extreme learning machine (HSARBF-ELM) network classifier is presented. HSARBF-ELM consists of a structure-adaptive radial basis function (SARBF) network and an extreme learning machine (ELM) network of cascade, where the output of the SARBF network hidden layer is used as the input layer of the ELM network. In the HSARBF-ELM network classifier, the SARBF network is utilized to achieve adaptively localizing kernel mapping of input vectors, after that step, the ELM network is utilized to implement global classification of mapping samples in the kernel space. HSARBF-ELM indicates the combination of localized kernel mapping learning and the global nonlinear classification, which combines the advantages of the SARBF network and the ELM network. The quantitative conditions for the separability enhancement and the corresponding theoretical explanation for the HSARBF-ELM network are given, which demonstrate that when input vectors go through the SARBF network, adaptively adjusting the RBF kernel parameters can boost the separability of the original sample space. Thus, the classification performance of the HSARBF-ELM network can be guaranteed theoretically. An appropriate learning algorithm for the HSARBF-ELM network is subsequently presented, which effectively combines the methods of density clustering with a potential function, center-oriented unidirectional repulsive force and the existing ELM algorithm, and the optimized complementary HSARBF-ELM network can be constructed. The experimental results show that the classification performance of the HSARBF-ELM network clearly outperforms the ELM network, and outperforms other classifiers on most classification problems."
  },
  {
    "year": "2017",
    "abstract": "In the design of multiplierless finite impulse response (FIR) filters, tremendous efforts have been made to reduce the number of adders of the multiplier block for the reduction of overall chip area and power consumption. However, fewer in the multiplier block do not necessarily lead to lower power consumption, since the structural adders dominate the power consumption of an FIR filter circuit. In this paper, we propose a power-oriented optimization method for linear phase FIR filters. In the proposed algorithm, the power index, which is the average adder depth of the structural adders, is used as the optimization objective in the discrete coefficients search. A gate-level simulation of benchmark filters shows that the proposed technique designs filters consuming less power than those obtained by the best available algorithms, which aim to minimize the number of adders. The power savings over existing designs can be as much as 19.6%."
  },
  {
    "year": "2017",
    "abstract": "This paper analyzes the impact of nonlinear high power amplifiers (HPAs) on the multiband carrier aggregated (CA) long-term evolution-advanced (LTE-A) system. It is assumed that the LTE-A system consists of a multi-input-multioutput (MIMO) orthogonal frequency-division multiplexing (OFDM)-based downlink physical-layer architecture. It has been shown that the nonlinear distortion caused by HPAs can be represented in terms of a complex attenuation factor and additive zero mean Gaussian “nonlinear\" noise. The closed-form generalized expressions of complex attenuation factor and variance of additive Gaussian nonlinear noise are derived that are applicable to any number of aggregated bands with any nonlinearity order and memory depth. From these expressions, the overall performance of a multiband CA-MIMOOFDM system in terms of symbol error rate and error vector magnitude for M-ary quadrature amplitude modulation (M-QAM) has been evaluated. We also investigate the combined effect of a number of aggregated bands, input-back off, and diversity gain on the performance of a CA-MIMO-OFDM system. It is observed that diversity gain can improve the performance of CA-MIMO-OFDM in low signal-to-noise ratio (SNR) region. However, in the high SNR region, there is no substantial effect of increasing diversity on the performance. A good agreement between the analytical and simulation results in the multipath Rayleigh fading channel validates the theoretical results obtained in this paper."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the chromatic dispersion of the As2S3three-bridge suspended-core fiber (SCF) is numerically investigated. All the cross-section parameters, including the thickness of the bridges and the internal circle and external circle diameter of the air hole, have been considering in the simulation of the SCFs by means of the full-vectorial finite-element method in detail. Eighty three models with different structural parameters are established, and the changes of the chromatic dispersion and zero-dispersion wavelength (ZDW) of the fundamental mode in the wavelength ranging from 0.6 to 11.6 μm are evaluated. The relations between the dispersion and structural parameters are obtained by numerical simulations. Numerical results indicate that a proper design of the bridges and air holes can significantly change the dispersion properties of the SCF. A SCF with dual-ZDW (1.805 & 5.315 μm), highly nonlinearity (3.480683 m-1W-1), and flattened chromatic dispersion (<;17.70133 ps/(km· nm)), which can be used to generate broadband supercontinuum, is obtained by optimizing the structural parameters."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel bilateral 2-D neighborhood preserving discriminant embedding for supervised linear dimensionality reduction for face recognition. It directly extracts discriminative face features from images based on graph embedding and Fisher's criterion. The proposed method is a manifold learning algorithm based on graph embedding criterion, which can effectively discover the underlying nonlinear face data structure. Both within-neighboring and between-neighboring information are taken into account to seek an optimal projection matrix by minimizing the intra-class scatter and maximizing the inter-class scatter based on Fisher's criterion. The performance of the proposed method is evaluated and compared with other face recognition schemes on the Yale, PICS, AR, and LFW databases. The experiment results demonstrate the effectiveness and superiority of the proposed method as compared with the state-ofthe-art dimensionality reduction algorithms."
  },
  {
    "year": "2017",
    "abstract": "Quantum key distribution (QKD) is an innovative solution in the cryptography world to prevent the information leakage that can sometimes be deliberate. Several QKD protocols were recently presented for building a secure shared key, of which the BB84 protocol is one of those interesting protocols. The authentication between the communicating parties is one of the issues that cause a huge argument. Furthermore, the current well-known QKD protocols are not yet ready to realize the personality of either the sender or the receiver, although the QKD protocol is already protected by the rules of physics and quantum mechanics to detect any interruption. This paper introduces a new QKD protocol that utilizes two quantum channels to provide authenticated communications for legitimate parties. Moreover, the proposed QKD protocol uses two type of physical behaviors, entanglement and superposition states. The entangled states are utilized to confirm the authentication between the end users, while the superposition states carry the secret key that will be shared between the users."
  },
  {
    "year": "2017",
    "abstract": "This paper designs a robust discriminative tracking method based on correlation filter and key point matching, the highlight of which is the ability to adapt appearance changes. Toward the complicated and changeable real-world scene, a multi-channel of optimal selection correlation filter (MOSCF) is proposed, and it can model the holistic appearances by learning short-term dynamic features. Meantime, a key point feature set is maintained for representing the long-term stable appearances. In order to combine the similarity evaluation scores of two appearance features, a confidence fusion framework is established to obtain the final output confidence map. Particularly, partially occluded object is located by a kind of local key point voting mechanism. To alleviate error accumulation caused by inappropriate learning, an adaptive learning ratio is set to independently update the filter template corresponding to each channel of MOSCF. The results of the qualitative and quantitative experiments on the OTB-100 benchmark suggest that the proposed tracker outperforms several state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Improving the accuracy of power system load forecasting is important for economic dispatch. However, a load sequence is highly nonstationary and hence makes accurate forecasting difficult. In this paper, a method based on wavelet decomposition (WD) and a second-order gray neural network combined with an augmented Dickey–Fuller (ADF) test is proposed to improve the accuracy of load forecasting. First, the load sequence is decomposed by WD to reduce the nonstationary load sequence. Then, the ADF test is adopted as the test method for the stationary load sequence of each decomposed component after WD in which the test results determine the best WD level. Finally, because forecasting the wavelet details characterized by high frequencies is difficult owing to its fluctuation, a second-order gray forecasting model is used to forecast each component after WD. Furthermore, to obtain the optimum parameters of the second-order gray forecasting model, the neural network mapping approach is used to build the second-order gray neural network forecasting model. The simulation result of a real load sequence verifies that the method proposed in this paper can effectively improve the load-forecasting accuracy."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing platform is one of the most important parts in the smart factory of industry 4.0. Currently, most cloud computing platforms have adopted flash memory as the mainly storage for more efficiency, because the flash memory having high capacity and speed. However, flash memory exhibits certain drawbacks in terms of out-of-place updates and asymmetric I/O latencies for read, write, and erase operations. These disadvantages prevent replacing traditional disks. Fortunately, the flash buffer can be used to address these drawbacks, and its replacement policies provide efficiency methods. Therefore, in this paper, we propose a locality-aware least recently used (LLRU) replacement algorithm, which exploits both access and locality characteristics. LLRU divides the LRU list into four lists: the hot-clean, hot-dirty, cold-clean, and cold-dirty LRU lists. According to reuse probability and eviction cost, the eviction page is selected to ensure effective system performance for cloud computing. The experimental results demonstrate LLRU outperforms other algorithms, including LRU, CF-LRU, LRU-WSR, and AD-LRU, which can optimize cloud computing for smart factory of industry 4.0."
  },
  {
    "year": "2017",
    "abstract": "Reproducing key fault information quantitatively has practical significance for the fault diagnosis of overhead transmission lines (OLTs). In order to reproduce the key fault information of a single phase-to-ground (SPG) fault, this paper proposes a reproduction methodology based on the waveform inversion theory and the propagation characteristics of a traveling wave. Based on the frequency-dependent parameter model and the inversion technique, the current traveling wave at the fault point can be obtained. The fault reproduction model was then created based on the wave propagation characteristics and the obtained waveforms at the fault point. The proposed method adopted a chaos particle swarm optimization algorithm to realize a fast search of the solution space, and this contributes to accurately reproducing the fault angle and the fault resistance of a SPG fault. The simulation results demonstrate that the method proves suitable for reproducing the key information at the fault point. In addition, the proposed method was implemented in 500-kV OTLs, which could help to provide data support for fault diagnosis and insulation protection."
  },
  {
    "year": "2017",
    "abstract": "Finding an optimal node deployment strategy in wireless sensor networks (WSNs) that would reduce cost, be robust to node failures, reduce computation, and communication overhead, and guarantee a high level of coverage along with network connectivity is a difficult problem. In fact, sensing coverage and network connectivity are two of the most fundamental problems in WSNs as they can directly impact the network lifetime and operation. In this paper, we consider deriving optimal conditions for connectivity with coverage in WSNs. Most versions of this problem are (NP-complete), while approximation algorithms cannot be developed for some versions of polynomial time, unless P = NP. Hence, we also develop a heuristic for some versions of the problem and the efficacy of the heuristic will be evaluated through extensive simulations. We are also interested in determining the probability of finding a path between a given pair of nodes over a given topology of WSNs. This will serve as a measure of connectivity with coverage of the network. Hence, we derive necessary and sufficient conditions for connectivity with coverage over a clustered structure in WSNs. Then, employing queuing networks modeling techniques, we present a dynamic programming study of the connectivity with coverage of clustered structure and its effect on routing in generalized WSNs. The performance evaluation of the proposed schemes shows that availability of nodes, sensor node coverage, and the connectivity were sufficiently enhanced to maximize network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Equipped with various sensors and intelligent systems, modern cars turn into entities with connectivity, autonomy, and safety. Car rental/car sharing is an innovative transportation concept and integral in today's urban living. It enables users to access a fleet of vehicles located throughout cities. Complementing public transportation, the car-sharing service helps people to meet their transportation needs economically and in an environmentally responsible manner. When a customer wants to rent a car from a rental company or an owner wants to share a private car with his/her friends or family members, the customer or the user should gain admission to the car, such as unlocking the door and starting the engine. In this paper, we proposed a novel and secure key-sharing system named hierarchical identity-based signature key sharing (HIBS-KSharing), which consists of key generation, key transmission, and key management (e.g., remote issuing, revocation of access rights, and their delegation to other users or sharers). We implemented our proposed system based on Nexus smartphones and near-field communication devices. Compared with existing key-sharing schemes of car rental/sharing, our proposed HIBS-KSharing system is secure and easily extended."
  },
  {
    "year": "2017",
    "abstract": "In vehicular ad hoc networks (VANETs), vehicles broadcast their status information in beacons periodically to make the surrounding vehicles aware of their presence. To maximize the level of awareness, a congestion control mechanism is necessary to avoid loss of beacons due to collision in dense traffic environments. In addition to congestion control, it is desirable that vehicles share network bandwidth in a manner proportional to their dynamics or safety application requirements. Current congestion control mechanisms have a number of issues including control information overheads, fairness, and awareness. In this paper, a beacon rate and awareness control mechanism based on non-cooperative game theory called non-cooperative beacon rate and awareness control (NORAC), is proposed. The existence and uniqueness of the Nash equilibrium of the game is proved mathematically and an algorithm is proposed to find the equilibrium point in a distributed manner. The proposed algorithm is used to assign a beacon rate to every vehicle proportional to its requirements, while ensuring fairness between vehicles with the same requirement. NORAC is compared with the two other known congestion control mechanisms. The simulation results show the efficiency and stability of the proposed NORAC algorithm in several high-density traffic scenarios. The results indicate its advantages in terms of fairness and congestion and awareness control over the other two algorithms, while not requiring excessive information to be included in beacons."
  },
  {
    "year": "2017",
    "abstract": "Sink mobility can improve the energy efficiency and data gathering performance in wireless sensor networks. However, mobility of the sink station may be constrained in some applications and it becomes a challenge to optimize the network performance for random distribution and hierarchical topology. We focus on prolonging the network lifetime and keep the data gathering performance at an acceptable level. To address this issue, we propose a comprehensive data gathering scheme based on graphing technique, called double optimization of energy efficiency (DOEE) to optimize the energy consumption of all sensor nodes hierarchically. The objective problem of DOEE is solved with a heuristic algorithm. Along with the scheme, we also specialize a route discovery protocol and its corresponding dynamic gateway protocol to balance the energy consumption among sensor nodes. The proposed algorithm and protocols are evaluated in the simulation platform Network Simulation-3 and the experiment results show our technique has superior performance."
  },
  {
    "year": "2017",
    "abstract": "Morphings are usually used for aircrafts to achieve a better performance in variable environment, whereas this paper focuses on how to achieve a trajectory-attitude separation control effect with an active morphing strategy. Aimed at this target, a systemic work, including modeling, linearization, and control, is presented. An accurate nonlinear dynamic model of morphing aircraft is built with centroid dynamic equations, of which all the additional terms that stem from morphing are expatiated for gullwing aircraft. Then, a linear parameter varying (LPV) approach is applied to linearize the equations for a controller design. A state feedback with a feedforward H∞control approach for an LPV system is proposed in this paper and is applied to the attitude control of gull-wing aircraft. Based on the stabilized aircraft attitude, a dynamic inversion control approach for the trajectory channels with active morphing is designed. The nonlinear simulation cases validate the feasibility of trajectory-attitude separation control with active morphing, as well as the performance of the control approach proposed in this paper."
  },
  {
    "year": "2017",
    "abstract": "Caching on the edge has been recognized as an effective solution to tackle the backhaul constraint of network densification. However, most related works ignored user mobility in wireless networks, which is unreasonable under the background of network densification. For a more flexible and context-aware caching decision, the concept of caching on the edge can be extended to mobile edge computing (MEC) that enables computation and storage resources at mobile edge networks. With MEC servers deployed on base stations, a huge amount of collected radio access network context data can be analyzed and utilized to render a caching scheme adaptive to user's context-aware information. In this regard, a novel mobility-aware coded probabilistic caching scheme is proposed for MEC-enabled small cell networks (SCNs). Different from previous mobility-aware caching schemes, user mobility and distributed storage are incorporated into a conventional probabilistic caching scheme, with the aim of throughput maximization. Based on stochastic geometry theory and a modified mobility model of discrete random jumps, the explicit expression of throughput is derived. Due to the complexity of the expression, two light-weight heuristic algorithms are provided to numerically obtain the optimal solutions. Moreover, a significant trade-off among the gains of mobility diversity, content diversity, and channel selection diversity is discussed, and we further numerically analyze how such a trade-off is influenced by user mobility, content popularity, and backhaul capacity, with some fundamental insights into the application of the proposed scheme in MEC-enabled SCNs. The superiority of our proposed scheme is demonstrated by the comparisons with the classical M most popular caching scheme and the conventional probabilistic caching scheme. Numerical results show that our proposed caching scheme achieves higher throughput than those of the other two, especially when users of intense mobility request conte..."
  },
  {
    "year": "2017",
    "abstract": "The development of wireless technology like Internet Protocol version 6 over Low power Wireless Personal Area Networks, which defines IP communication for resource-constrained networks enables communication on the lower layers, while the diverging and incompatible application layer protocols lead to barriers in the way of information transferring between heterogeneous networks. Fortunately, extensible messaging and presence protocol (XMPP) is a preferential protocol to solve the problem of interoperability between heterogeneous networks. Hence, it is attractive to extend XMPP to the Internet of Things (IoT). However, XMPP protocol is initially designed for the Internet where the equipment is rich in resources, considering the characteristics of the IoT, the XMPP protocol needs to be optimized to meet the requirements of IoT, e.g., downsized protocol, publish/subscribe service and sleeping mechanism. In this paper, by staying true to the IoT visions, we propose a lightweight XMPP publish/subscribe scheme for resource-constrained IoT devices to perform data exchange either periodically or upon any value change. According to the subscriber’s needs, the publisher can adjust the data information published to the server. Inherit the merits of XEP-0060, the server maintains and manages the publish/subscribe relationships with multiple subscribers, as well as distributes the received data sent by publisher to all subscribers, yielding less complexity of publication and energy efficiency. In addition, the proposed scheme strongly supports publish/subscribe architecture of the sleeping clients that actually prolongs the lifetime of battery-powered devices. Thus, based on the standardized XMPP protocol, we present a down-sized and trimmed XMPP to implement this scheme. Through the experimental results, we demonstrate our work on optimizing and improving XMPP publish/subscribe scheme for resource-constrained IoT devices and show the simplicity and efficiency of this scheme."
  },
  {
    "year": "2017",
    "abstract": "Cerebral micro-bleed (CMB) is small perivascular hemosiderin deposits from leakage through cerebral small vessels. They can result from cerebra-vascular disease, dementia, or simply from normal aging. It can be visualized via the susceptibility weighted imaging (SWI). Based on the SWI, we propose to use different structures of the CNN with rank-based average pooling to detect the CMB, and compare this method used in this paper to the current state-of-the-art methods. We can find that the CNN with five layers obtains the best performance, with a sensitivity of 96.94%, a specificity of 97.18%, and an accuracy of 97.18%."
  },
  {
    "year": "2017",
    "abstract": "The analog low-density parity-check (LDPC) decoder, which is a specific application of the probabilistic computing, is considered to be a promising solution for power-constrained applications. However, due to the lack of efficient electronic design automation tools and reliable circuit model, the analog LDPC decoders suffer from costly hand-craft design cycle, and are unable to provide enough coding gains for practical applications. In this paper, we present an implementation of a (480,240) CMOS analog LDPC decoder, which is the longest implemented code to date using the analog approach. We first propose an analog LDPC decoder architecture, which is constructed by the reusable modules and can significantly reduce the hardware complexity. And then, we present a mixed behavioral and structural model for the analog LDPC decoding circuits, which can reliably and efficiently predict the error-correcting performance. Finally, the experimental results show that the decoder prototype, which is fabricated in a 0.35-μm CMOS technology, can achieve a throughput higher than 50 Mbps with the power consumption of 86.3 mW for the decoder core, and can offer a superior 6.3-dB coding gain at the bit error rate of 10-6 when the tested throughput is 5 Mbps. The proposed analog LDPC decoder is suitable for the power-limited applications with moderate throughput and certain coding gains."
  },
  {
    "year": "2017",
    "abstract": "Beyond energy, the growing number of defects in physical substrates is becoming another major constraint that affects the design of computing devices and systems. As the underlying semiconductor technologies are getting less and less reliable, the probability that some components of computing devices fail also increases, preventing designers from realizing the full potential benefits of on-chip exascale integration derived from near atomic scale feature dimensions. As the quest for performance confronts permanent and transient faults, device variation, and thermal issues, major breakthroughs in computing efficiency are expected to benefit from unconventional and new models of computation, such as brain-inspired computing. The challenge is then to find not only high-performance and energy-efficient, but also fault-tolerant computing solutions. Neural computing principles remain elusive, yet as source of a promising fault-tolerant computing paradigm. In the quest to fault tolerance can be translated into scalable and reliable computing systems, hardware design itself and/or to use circuits even with faults has further motivated research on neural networks, which are potentially capable of absorbing some degrees of vulnerability based on their natural properties. This paper presents a survey on fault tolerance in neural networks manly focusing on well-established passive techniques to exploit and improve, by design, such potential but limited intrinsic property in neural models, particularly for feedforward neural networks. First, fundamental concepts and background on fault tolerance are introduced. Then, we review fault types, models, and measures used to evaluate performance and provide a taxonomy of the main techniques to enhance the intrinsic properties of some neural models, based on the principles and mechanisms that they exploit to achieve fault tolerance passively. For completeness, we briefly review some representative works on active fault tolerance in neura..."
  },
  {
    "year": "2017",
    "abstract": "While random linear network coding is known to improve network reliability and throughput, its high costs for delivering coding coefficients and decoding represent an obstacle where nodes have limited power to transmit and decode packets. In this paper, we propose sparse network codes for scenarios where low coding vector weights and low decoding cost are crucial. We consider generation-based network codes where source packets are grouped into overlapping subsets called generations, and coding is performed only on packets within the same generation in order to achieve sparseness and low complexity. A sparse code is proposed that is comprised of a precode and random overlapping generations. The code is shown to be much sparser than existing codes that enjoy similar code overhead. To efficiently decode the proposed code, a novel low-complexity overhead-optimized decoder is proposed where code sparsity is exploited through local processing and multiple rounds of pivoting. Through extensive simulation comparison with existing schemes, we show that short transmissions of the order of 102-103source packets, a denomination convenient for many applications of interest, can be efficiently decoded by the proposed decoder."
  },
  {
    "year": "2017",
    "abstract": "Sentiment analysis and opinion mining in social networks present nowadays a hot topic of research. However, most of the state of the art works and researches on the automatic sentiment analysis and opinion mining of texts collected from social networks and microblogging websites are oriented toward the binary classification (i.e., classification into “positive”and “negative”) or the ternary classification (i.e., classification into “positive,”“negative,”and “neutral”) of texts. In this paper, we propose a novel approach that, in addition to the aforementioned tasks of binary and ternary classifications, goes deeper in the classification of texts collected from Twitter and classifies these texts into multiple sentiment classes. While in this paper, we limit our scope to seven different sentiment classes, the proposed approach is scalable and can be run to classify texts into more classes. We first introduce SENTA, our tool built to help users select out of a wide variety of features the ones that fit the most for their application, to run the classification, through an easy-to-use graphical user interface. We then use SENTA to run our own experiments of multiclass classification. Our experiments show that the proposed approach can reach up to 60.2% accuracy on the multi-class classification. Nevertheless, the approach proves to be very accurate in binary classification and ternary classification: in the former case, we reach an accuracy of 81.3% for the same data set used after removing neutral tweets, and in the latter case, we reached an accuracy of classification equal to 70.1%."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates a scheme to reject the unknown bounded time varying external disturbance for a ship course keeping control system. A mathematical model of a steering system is derived considering nonlinear features that could affect the control design process. The feedback linearization approach is adopted to simplify the nonlinear system. The adaptive sliding mode control algorithm and nonlinear disturbance observer method are developed for course keeping maneuvers in vessel steering and for providing robust performance for the environment disturbance and rudder dynamics. Furthermore, the overall stability conditions of the presented controllers are analyzed by Lyapunov's direct method. Finally, the effectiveness of the controllers is illustrated by the simulation results on a navy vessel with twin rudders."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces an imitation system based on the similarity of the replaying motions of robots with the sequential poses of a demonstrator. The system is composed of three modules-key pose elicitation, real robot balance control, and memorization for motion replay. The elicitation of key poses drives the balance learning and motion replay of the robot. Dissimilarity values associated with the defined spatiotemporal function of simultaneous joint motion are used to analyze the degree of similarity. To overcome the difference in mechanical structures and kinematics, such as the number of joints between robots and human demonstrators, the key poses extracted from the motions of demonstrators are modified by a Q-Learning process that considers the kinematic constraints and maintains the balance of the robot while executing imitation. The rewards were designed not only to encourage a robot to execute as many consecutive poses as possible, but also to guide the robot to maintain its balance even though the biped lacks information on the ankle joint. These modified key poses are stored in databases for replaying or composing new motions in an ordered sequence. The experimental results demonstrate that a robot could adjust the poses, mapped from the movements of the demonstrator, to its static stable states, thereby imitating human motions by self-learning."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel framework based on the non-subsampled contourlet transform (NSCT) and sparse representation (SR) to fuse the multi-focus images. In the proposed fusion method, each source image is first decomposed with NSCT to obtain one low-pass sub-image and a number of high-pass sub-images. Second, an SR-based scheme is put forward to fuse the low-pass sub-images of multiple source images. In the SR-based scheme, a joint dictionary is constructed by integrating many informative and compact sub-dictionaries, in which each sub-dictionary is learned by extracting a few principal component analysis bases from the jointly clustered patches obtained from the low-pass subimages. Thirdly, we design a multi-scale morphology focus-measure (MSMF) to synthesize the high-pass sub-images. The MSMF is constructed based on the multi-scale morphology structuring elements and the morphology gradient operators, so that it can effectively extract the comprehensive gradient features from the sub-images. The “Max-MSMF” is then defined as the fusion rule to fuse the high-pass sub-images. Finally, the fused image is reconstructed by performing the inverse NSCT on the merged low-pass and high-pass subimages, respectively. The proposed method is tested on a series of multi-focus images and compared with several well-known fusion methods. Experimental results and analyses indicate that the proposed method is effective and outperforms some existing state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "The fifth generation (5G) cellular network is upon us. Academia and Industry have intensively collaborated together to bring the power of 5G cellular networks to the masses, and now the 5G millimeterwave (mmWave) platforms come into being in the market. One of the most popular 5GmmWave platforms mounts the massive mmWave phased antenna arrays in order to transfer a huge number of bits in a second (e.g., more than ten gigabits-per-second) to the baseband in the platform. While exploiting chip multicore processors (CMPs) may be the best solution to process such huge data in the mmWave baseband platform, power dissipate by the CMPs should become critical. Starting from an intuition that utilizing all processors in every single time introduces inefficient energy consumption, this paper proposes an energy aware queue-stable control (EQC) algorithm to control the activation/deactivation of individual processors and antenna arrays for pursuing time average energy consumption minimization subject to the stability of queues in the 5G-mm Wave baseband. Results from intensive simulations based on realistic experimental setups demonstrate the efficacy of the proposed EQC that achieves significant energy savings while queue stability is maintained."
  },
  {
    "year": "2017",
    "abstract": "Community detection algorithms are important for determining the character statistics of complex networks. Compared with the conventional community detection algorithms, which always focus on undirected networks, our algorithm is concentrated on directed networks such as the WeChat moments relationship network and the Sina Micro-Blog follower relationship network. To address disadvantages such as lower execution efficiency and higher deviation of precision that current directed community detection algorithms always have, we propose a new approach that is based on the triangle structure of community basis and modeled on the local information transfer process to precisely detect communities in directed networks. Based on the directed vector theory in probability graphs and the dynamic information transfer gain (ITG) of vertices in directed networks, we propose the novel ITG method and the corresponding target optimal function for evaluating the partition quality in a community detection algorithm. Then, we combine ITG and the target function to create the new community detection algorithm ITG-directed weighted community clustering for directed networks. With extensive experiments using artificial network data sets and large, real-world network data sets derived from online social media, our algorithm proved to be more accurate and faster in directed networks than several traditional, well-known community detection methods, such as FastGN, order statistics local optimization method, and Infomap."
  },
  {
    "year": "2017",
    "abstract": "Topology control is relevant in wireless sensor network because of two reasons, namely minimal sensor coverage and power constraints. The former condition is typically satisfied by high-density deployment, whereas the latter mainly concerns with the control protocol design that is adaptable. Controlling communication topology is at the center of the efforts to optimize network performance while improving energy conservation. A dense topology often results in high interference and lower spatial reuse thus reduced capacity, while sparse topology is susceptible to network partitioning and sub-optimal path selection from the routing layer. Topology control has been extensively studied in both flat and hierarchical network by mean of power adjustment and clustering, respectively. Despite a common goal of making the topology less complex both techniques differ in their approach. While the focus of clustering is to form a connected backbone which consists of a minimum subset of nodes, i.e., dominating set, power adjustment focuses on minimizing energy consumption. Combining both approaches remains a relatively lesser explored area. We proposed a hybrid framework called collaborative topology control protocol, which combines dominating set-based clustering and transmission power adjustment. The protocol operates in two stages. During the first stage, a parameterized minimum virtual connected dominating set algorithm is executed to obtain clusters of various desirable properties. In the second stage, each cluster-head executes a distributed power adjustment algorithm. The simulation results show that the proposed topology control framework is capable of versatile performance in terms of transmission range/energy cost, the number of neighbors, edges, and hop distance. Moreover, the topology construction process uses the locally available information only with minimal communication overhead."
  },
  {
    "year": "2017",
    "abstract": "Identity-based proxy re-encryption (IBPRE) is a powerful cryptographic tool for various applications, such as access control system, secure data sharing, and secure e-mail forwarding. Most of the existing efficient IBPRE schemes are based on the Diffie-Hellman assumption, and they only focus on the single-hop construction. Based on the work of Chandran et al.'s lattice-based proxy re-encryption (PRE) scheme (PKC'14) and Yamada's lattice-based identity-based encryption (IBE) scheme (EUROCRYPT'16), in this paper, we first show the possibility of assembling lattice-based IBE into lattice-based PRE. Then, we present the construction of a new efficient single-hop homomorphic IBPRE from learning with errors (LWEs) via key homomorphic computation. Furthermore, using branching program (BP), we obtain an efficient multi-hop IBPRE scheme. To the best of our knowledge, our scheme is the first multi-hop homomorphic IBPRE scheme via BP. Our scheme supports homomorphic evaluation and is proved secure under the decisional LWE assumption."
  },
  {
    "year": "2017",
    "abstract": "Recently, a local binary patterns-based initialization scheme for robust cascaded pose regression was proposed, which selects the most correlated shapes with the estimated face from training set as the initial shapes. Nevertheless, due to the massive samples in training set, the operation of selecting the most correlated shapes with the estimated shape turns out to be time-consuming. To reduce the quantity of the faces in training set for correlation analyzing in the training set, the faces should be divided into latent classes, and a face in each class could be chosen to form a smaller initial shape pool. In this paper, we view the faces and the latent classes as the latent Dirichlet allocation model. We first extract scale-invariant feature transform features from each face and employ k-means algorithm on the features to obtain a fixed number of clusters. The features in each cluster are represented by its centroid, which can be used to generate the probability distribution of a face belonging to the latent classes via Gibbs sampling. The performance of the proposed scheme is evaluated on the challenging data set of Caltech Occluded Faces in the Wild. The experimental results show that the proposed scheme can significantly reduce time cost on landmark localization by 65.84% without dropping accuracy."
  },
  {
    "year": "2017",
    "abstract": "An integrated approach for online dynamic security assessment based on exploring connotative associations in massive data is proposed; this approach consists of three stages and can give visual and credible dynamic security assessment results. The relationships of operation variables and transient stability margin are assigned scores by the maximal information coefficient and the Pearson-correlation coefficient. The connotative nonlinear functional relationships and linear relationships are explored by ranking the scores, and some highly ranked relationships are shown and curve fitted. In this approach, a processing unit is designed for dynamic security assessment based on the explored highly ranked relationships. The approach considers classification and prediction. This approach is tested in a 21-bus test system and a larger 1648-bus system. The robustness with respect to topology changes, variation of power distribution among generators/loads, and variation of peak load/minimum load are analyzed. The test results indicate that compared with the traditional methods, the proposed approach provides a relatively fast and accurate dynamic security assessment and is suitable for online use."
  },
  {
    "year": "2017",
    "abstract": "Sentiment in multimedia contents has an influence on their topics, since multimedia contents are tools for social media users to convey their sentiment. Performance of applications such as retrieval and recommendation will be improved if sentiment in multimedia contents can be estimated; however, there have been few works in which such applications were realized by utilizing sentiment analysis. In this paper, a novel method for extracting the hierarchical structure of Web video groups based on sentiment-aware signed network analysis is presented to realize Web video retrieval. First, the proposed method estimates latent links between Web videos by using multimodal features of contents and sentiment features obtained from texts attached to Web videos. Thus, our method enables construction of a signed network that reflects not only similarities but also positive and negative relations between topics of Web videos. Moreover, an algorithm to optimize a modularity-based measure, which can adaptively adjust the balance between positive and negative edges, was newly developed. This algorithm detects Web video groups with similar topics at multiple abstraction levels; thus, successful extraction of the hierarchical structure becomes feasible. By providing the hierarchical structure, users can obtain an overview of many Web videos and it becomes feasible to successfully retrieve the desired Web videos. Results of experiments using a new benchmark dataset, YouTube-8M, validate the contributions of this paper, i.e., 1) the first attempt to utilize sentiment analysis for Web video grouping and 2) a novel algorithm for analyzing a weighted signed network derived from sentiment and multimodal features."
  },
  {
    "year": "2017",
    "abstract": "Mining frequent closed sequential pattern (FCSPs) has attracted a great deal of research attention, because it is an important task in sequences mining. In recently, many studies have focused on mining frequent closed sequential patterns because, such patterns have proved to be more efficient and compact than frequent sequential patterns. Information can be fully extracted from frequent closed sequential patterns. In this paper, we propose an efficient parallel approach called parallel dynamic bit vector frequent closed sequential patterns (pDBV-FCSP) using multi-core processor architecture for mining FCSPs from large databases. The pDBV-FCSP divides the search space to reduce the required storage space and performs closure checking of prefix sequences early to reduce execution time for mining frequent closed sequential patterns. This approach overcomes the problems of parallel mining such as overhead of communication, synchronization, and data replication. It also solves the load balance issues of the workload between the processors with a dynamic mechanism that re-distributes the work, when some processes are out of work to minimize the idle CPU time."
  },
  {
    "year": "2017",
    "abstract": "Content-centric networks are designed as potential candidates for future 5G networks and the Internet. In these kinds of networks, contents are queried, searched, and routed on names that people are interested in. Collecting names that a person queries in a content-centric network can violate his/her privacy. As more and more people are concerned about their privacy in daily life, it is desirable to present privacy-preserving protocols for content-centric networks. Currently, many schemes are designed to protect people's privacy but few of them consider the malicious behaviors of the transmitting routers, especially when the routers collude with a certain user. We discuss a kind of attack called collusion name guessing attack where intermediate routers collude with a certain user to perform a name guessing attack in order to expose people's privacy. It is shown that present schemes cannot resist such kind of attack, which will be a new challenge for content-centric networks. A new scheme with anonymous user identity and limited key validation time is designed to fight against the collusion name guessing attack. In the scheme, the users are anonymous and the shared keys are valid within a specified time period so the adversary does not know whose packets should be collected and it is infeasible to precompute the name matching datasets during the valid time period of the key. Moreover, slow matching for all users and all time periods needs enormous storage and will last a long time, which will make the attack cost-ineffective."
  },
  {
    "year": "2017",
    "abstract": "Teleoperating cyber-physical system (TCPS) has been considered as a promising technology to stretch artificial intelligences to remote locations. Many applications of TCPS demand operator and slaves to keep state consensus on the shared information. However, the cyberand physicalconstrained characteristics on TCPS make it difficult to realize such a consensus. This paper investigates the consensus problem for single-master-multi-slave TCPS with time-varying delay and actuator saturation. According to the communication structures of slaves, centralized and decentralized controllers are, respectively, designed to drive the consensus of master and slave robots. To simplify the information fusion in decentralized controller design, we use min-weighted rigid graph-based topology optimization algorithm to reduce the communication redundancy in slave site. Under time-varying delay and actuator saturation constraints, the sufficient stability conditions are presented to show that the centralized and decentralized controllers can stabilize the single-master-multi-slave TCPS. Moreover, the stability conditions are rearranged into a form of linear matrix inequalities, and then, the required initial stability conditions for master and slaves are developed. Finally, simulations and experiments are demonstrated to show the validity of the method. It is shown that the consensus controllers can guarantee the asymptotic stability of single-master-multi-slave TCPS, while the topology optimization can reduce the redundancy of communication links."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a quality and distance guided metaheuristic algorithm (QD-ILS) for solving the vertex separation problem. QD-ILS integrates a basic local search procedure with QD-LS strategy, which uses an augmented evaluation function that considers both solution quality and distance between the current solution and the best found solution to guide the search to explore promising regions of the search space. Assessed on two sets of 162 common benchmark instances, QD-ILS achieves highly competitive results in terms of both solution quality and computational efficiency compared with the state-of-the-art algorithms in the literature. Specifically, it improves the previous best known results for 33 out of 162 benchmark instances and matches the best known results on all except four of the remaining instances compared with the state-of-the-art algorithms in the literature. The impact of the distance and quality-based diversification strategy is also investigated."
  },
  {
    "year": "2017",
    "abstract": "MultiresolutionM-ary differential chaos shift keying (MR-M-DCSK) modulation using non-uniformly spaced phase constellation is a promising technique that can satisfy different bit-error-rate (BER) requirements within one symbol over multipath fading channels. However, the BER performance always deteriorates as the modulation orderMbecomes larger. To overcome this shortcoming, a new hierarchical square-constellation-basedM-DCSK communication system using non-uniformly spaced distance constellation is proposed, which can be easily extended to other-constellation scenarios, e.g., rectangular, star, and asymmetrical square constellations. Furthermore, an adaptive transmission scheme is designed by modifying the distance between the two constellation points in the last hierarchical level. In addition, theoretical BER expressions of the proposed systems are derived over multipath Rayleigh fading channels, which are consistent with the simulated results. Analytical and simulated results show that the proposed system not only can provide lower energy consumption as compared with the conventional MR-M-DCSK system but also can efficiently adjust BER performance based on the signal-to-noise ratio information. Therefore, the proposed system can serve as a desirable alternative for energy-efficient short-range wireless-communication applications."
  },
  {
    "year": "2017",
    "abstract": "In recent years, bicycles have quickly become one of the major urban sports. At the same time, with the rise of Internet of Things (IoT), embedded system combine IoT devices are widely used and making computing truly ubiquitous. Although bicycles have various functions, they fail to provide cyclists with sufficient exercise-related information and post-exercise analysis. Therefore, this paper introduced a bicycle record system of ground conditions based on IoT which is combining smartphone and embedded system. The event data recorder comprised two parts, a “smartphone-based event data recorder”and “bicycle-based real-time information feedback system\". Using the event data recorder, this paper integrated and provided various types of real-time information for cyclists while they cycled to help them achieve their desired exercise results. After cycling, the cyclists could view cycling-related information through software analysis. This information included cycling routes taken, total cycling distance, and total calories burned. The event data recorder also saved information related to cycling routes, such as acceleration, deceleration, directional changes, and slope changes. By analyzing the recorded information, cyclists not only gained further insight into their exercise results but were also able to share cycling-related information through the Internet, which would benefit cyclists who had not cycled along this route before. By developing the bicycle record system, this paper aimed to provide cyclists with real-time, accurate, and complete information, enabling them to enjoy a consummate cycling environment."
  },
  {
    "year": "2017",
    "abstract": "In recent years, there has been a paradigm shift in Internet of Things (IoT) from centralized cloud computing to edge computing (or fog computing). Developments in ICT have resulted in the significant increment of communication and computation capabilities of embedded devices and this will continue to increase in coming years. However, existing paradigms do not utilize low-level devices for any decision-making process. In fact, gateway devices are also utilized mostly for communication interoperability and some low-level processing. In this paper, we have proposed a new computing paradigm, named Edge Mesh, which distributes the decision-making tasks among edge devices within the network instead of sending all the data to a centralized server. All the computation tasks and data are shared using a mesh network of edge devices and routers. Edge Mesh provides many benefits, including distributed processing, low latency, fault tolerance, better scalability, better security, and privacy. These benefits are useful for critical applications, which require higher reliability, real-time processing, mobility support, and context awareness. We first give an overview of existing computing paradigms to establish the motivation behind Edge Mesh. Then, we describe in detail about the Edge Mesh computing paradigm, including the proposed software framework, research challenges, and benefits of Edge Mesh. We have also described the task management framework and done a preliminary study on task allocation problem in Edge Mesh. Different application scenarios, including smart home, intelligent transportation system, and healthcare, are presented to illustrate the significance of Edge Mesh computing paradigm."
  },
  {
    "year": "2017",
    "abstract": "Smart grids require communication networks to convey sensing and control data for improving the efficiency of energy generation, transmission, and delivery. As a result, smart girds become vulnerable to various types of cyber-attacks. Trust models were recognized as one of the important methods of defending a large communication network against malicious cyber-attacks. In this paper, a fuzzy logic trust model is proposed to detect untrusted nodes in smart grid networks, and compared with an existing model to show its advantages. Using this proposed model, both the routing efficiency and the detection rate for all types of considered malicious behaviors can be improved. In comparison with the existing lightweight and dependable trust system model, the proposed model improves the packet dropping rate by up to 90% when the percentage of malicious nodes is less than 25%, as verified by simulations."
  },
  {
    "year": "2017",
    "abstract": "Most of the previous approaches to lyrics-to-audio alignment used a pre-developed automatic speech recognition (ASR) system that innately suffered from several difficulties to adapt the speech model to individual singers. A significant aspect missing in previous works is the self-learnability of repetitive vowel patterns in the singing voice, where the vowel part used is more consistent than the consonant part. Based on this, our system first learns a discriminative subspace of vowel sequences, based on weighted symmetric nonnegative matrix factorization, by taking the self-similarity of a standard acoustic feature as an input. Then, we make use of canonical time warping, derived from a recent computer vision technique, to find an optimal spatiotemporal transformation between the text and the acoustic sequences. Experiments with Korean and English data sets showed that deploying this method after a pre-developed, unsupervised, singing source separation achieved more promising results than the other state-of-the-art unsupervised approaches and an existing ASR-based system."
  },
  {
    "year": "2017",
    "abstract": "Licensed-assisted access (LAA) has been becoming a promising technology to the supplementary utilization of the unlicensed spectrum. However, due to the densification of small base stations (SBSs) and the dynamic variation of the number of Wi-Fi nodes in the overlapping areas, the licensed channel interference and the unlicensed channel collision could seriously influence the quality of service and the energy consumption. In this paper, jointly considering time-variant multi-wireless-channel conditions and random numbers of Wi-Fi nodes, we address an adaptive spectrum access and power allocation problem that enables the minimization of the system power consumption under a certain queue stability constraint in the LAA-enabled SBSs and Wi-Fi networks. The complex stochastic optimization problem has been decomposed as a modified Hungarian algorithm and a difference of two convex algorithm in the framework of Lyapunov optimization. We also characterize the performance bounds of the proposed algorithm with a tradeoff of[O(1/V),O(V)]between power consumption and delay theoretically. The numerical results verify the tradeoff and show that our scheme can reduce the power consumption over the existing scheme by up to 73.3% under the same traffic delay."
  },
  {
    "year": "2017",
    "abstract": "System of systems (SoS) engineering ensures that subsystems successfully interoperate with one another via a physical network along with the designed interface specifications. The twofold challenge that motivated the authors is regarding the achievement of the interoperability for an SoS-based combat system as follows: 1) the validation of the interface specifications against the specified requirements at the system-design phase and 2) the verification of the subsystems against the interface specifications at the system-integration phase. To this end, an interoperability validation and verification toolset (IVVT) consisting of the following three components was developed: signal distributor, message collector, and message analyzer. The signal distributor captures the signal data in the middle of the existing communication interfaces, the message collector stores the signals in the form of distinguishable messages, and the message analyzer evaluates the messages by comparing the designed interface specifications that cover the communication syntax and semantics. For the experimentations, the developed IVVT was utilized for the combat systems of real submarines that have been domestically targeted for a renovation project. The objective of the experiments is the validation of the overall designed interface specifications before the development of the subsystems. The empirical results show that 12 fault cases were found in the specifications, some of which are extremely critical; therefore, a preferential validation of the specifications could prevent the incompatibilities between the subsystems during the combat system integration. In a future work, the authors will employ the IVVT for a verification of the developed subsystems to be integrated depending on the validity of the interface specifications."
  },
  {
    "year": "2017",
    "abstract": "Under the background of cyber-physical systems and Industry 4.0, intelligent manufacturing has become an orientation and produced a revolutionary change. Compared with the traditional manufacturing environments, the intelligent manufacturing has the characteristics as highly correlated, deep integration, dynamic integration, and huge volume of data. Accordingly, it still faces various challenges. In this paper, we summarize and analyze the current research status in both domestic and aboard, including industrial big data collection, modeling of the intelligent product lines based on ontology, the predictive diagnosis based on industrial big data, group learning of product line equipment and the product line reconfiguration of intelligent manufacturing. Based on the research status and the problems, we propose the research strategies, including acquisition schemes of industrial big data under the environment of intelligent, ontology modeling and deduction method based intelligent product lines, predictive diagnostic methods on production lines based on deep neural network, deep learning among devices based on cloud supplements and 3-D selforganized reconfiguration mechanism based on the supplements of cloud. In our view, this paper will accelerate the implementation of smart factory."
  },
  {
    "year": "2017",
    "abstract": "Available bandwidth (AB) measurement technologies have been widely applied in evaluating the efficiency of the network communication. The performance of most existing AB measurement methods relies on the quality of the input data, which inevitably contains noises during the measurement. These noises can be multisourcing from end-to-end packet transmission and measuring, and in many practical situations, are nonnegligible compared with the value of measuring data. This paper focuses on estimating the end-to-end AB in terms of packet delays from sampled data that is contaminated by noises. We propose a novel algorithm, referred to as the adaptive-threshold algorithm, that can estimate and adaptively adjust a threshold value to separate the packets affected by the queueing delays from the rest of the packets to further improve the accuracy of AB measurement. A laboratory network-based simulation has been presented to evaluate the performance of our proposed algorithm. Numerical results demonstrate that the proposed algorithm can significantly improve the accuracy of the measurement and the estimated AB is within 10% difference from the true AB."
  },
  {
    "year": "2017",
    "abstract": "K-nearest neighbor rule (KNN) and sparse representation (SR) are widely used algorithms in pattern classification. In this paper, we propose two new nearest neighbor classification methods, in which the novel weighted voting methods are developed for making classification decisions on the basis of sparse coefficients in the SR. Since the sparse coefficients can well reflect the neighborhood structure of data, we mainly utilize them to design classifier in the proposed methods. One proposed method is called the coefficient-weighted KNN classifier, which adopts sparse coefficients to choose KNNs of a query sample and then uses the coefficients corresponding to the chosen neighbors as their weights for classification. Another new method is the residual-weighted KNN classifier (RWKNN). In the RWKNN, KNNs of a query sample are first determined by sparse coefficients, and then, we design a novel residual-based weighted voting method for the KNN classification. The extensive experiments are carried out on many UCI and KEEL data sets, and the experimental results show that the proposed methods perform well."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a fuzzy adaptive model predictive approach for load frequency control of an isolated micro grid. A generalized state space model of a typical isolated micro grid having controllable and uncontrollable generating power sources is derived, and the same has been utilized to predict the future output and control inputs for the micro grid frequency control. A centralized model predictive control (MPC) is implemented with a single input multi-output system model based on the controllable distributed energy resources in the micro grid. The parameter-driven MPC is made adaptable by dynamically adjusting its parameter Rw using fuzzy controller. The proposed fuzzy MPC employs a rule-based fuzzy controller to fuzzify the tuning parameter Rw present in the cost function of MPC, which plays an important role in minimizing the frequency deviation in the system. The closed loop system response obtained by the proposed fuzzy MPC has been found faster and adaptable for different scenarios in the system. The effectiveness has been evaluated with performance index integral time square error (ITSE) value and has been compared with MPC with constant tuning parameter value also with the proportional-integral controller response. Thus, the efficacy of using proposed fuzzy MPC in secondary load frequency control has been validated thereof."
  },
  {
    "year": "2017",
    "abstract": "With the sustained development of social networks, increasing attention has been paid to social recommender systems. Current studies usually focus on indirect factors such as the similarity between users, but multiple direct interactions, such as mentions, reposts, and comments, are seldom considered. This paper addresses direct connections between users in social recommender systems. We analyze direct interactions to investigate the connection strength between users, and then, user preferences and item characteristics can be better described. Based on the analysis of social influence between users and users' influence over the whole social network, we propose a recommendation method with social influence, which makes full use of information among users in social networks and introduces the mechanisms of macroscopic and microscopic influences. Direct interactions between users are incorporated into a matrix factorization objective function. Real-world microblog data are applied to verify our model, and the results show that the proposed recommendation method outperforms other state-of-the-art recommendation algorithms."
  },
  {
    "year": "2017",
    "abstract": "Zero head discrete Fourier transform (DFT) spread spectral efficient frequency division multiplexing (ZH-DFT-s-SEFDM) as a non-orthogonal multicarrier transmission scheme is proposed for the bandwidth compressing. A zero head DFT spread approach consists in this waveform design for reducing the peak-average-power-ratio (PAPR) and suppressing the out-of-band emissions introduced by the inter symbol interference and the inter carrier interference. Simultaneously, the corresponding receiver design is given, and a low complexity zero-forcing (ZF) detection algorithm is attached to the ZH-DFT-s-SEFDM receiver design. As the loss of orthogonality, the conventional SEFDM detector is overly complex, and however, the ZF detector as a linear detector performs well in the ZH-DFT-s-SEFDM system by adjusting the length of zero head. Simulation results show that the ZH-DFT-s-SEFDM signal achieves lower out-of-band emissions and a better PAPR performance than the conventional SEFDM signal at the same bandwidth compressing ratio. The binary error ratio (BER) performance of a ZH-DFT-s-SEFDM receiver with a ZF detector is also investigated. It performs better as the longer zero head inserted, and can achieve the better BER performance than conventional SEFDM and OFDM at the low signal-to-noise-ratio (SNR) for a particular number of zero head, and the BER performance of ZH-DFT-s-SEFDM remained the same as OFDM and traditional SEFDM at the high SNR."
  },
  {
    "year": "2017",
    "abstract": "With the increase in applications of face verification, increasing attention has been paid to their accuracy and security. To ensure both the accuracy and safety of these systems, this paper proposes an encrypted face-verification system. In this paper, face features are extracted using deep neural networks and then encrypted with the Paillier algorithm and saved in a data set. The framework of the whole system involves three parties: the client, data server, and verification server. The data server saves the encrypted user features and user ID, the verification server performs verification, and the client is responsible for collecting a requester's information and sending it to the servers. The information is transmitted among parties as cipher text, which means that no parties know the private keys except for the verification server. The proposed scheme is tested with two deep convolutional neural networks architectures on the labeled faces in the Wild and Faces94 data sets. The extensive experimental results, including results for identification and verification tasks, show that our approach can enhance the security of a recognition system with little decrease in accuracy. Therefore, the proposed system is efficient with respect to both the security and high verification accuracy."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a number of pair-counting similarity measures associated with a general formulation of cluster ensemble are proposed. These measures are formulated based on our motivation to evaluate the consistency between an individual clustering solution and a cluster ensemble solution, or that between different cluster ensemble solutions, in a uniform manner. A number of criteria are proposed for the comparison of these generalized measures, from both the perspectives of theoretical analysis and experimental validation. We identify their different behaviors and their correlations in different scenarios of traditional clustering solutions and cluster ensembles, with the hope that the results of these studies could 1) serve as important criteria for the design and selection of evaluation measures for clustering solutions, and 2) provide explanations for ambiguous clustering results in related scenarios. Experiments with both synthetic and real data sets are conducted to verify our findings."
  },
  {
    "year": "2017",
    "abstract": "Quantifying the impact of scientific papers objectively is crucial for research output assessment, which subsequently affects institution and country rankings, research funding allocations, academic recruitment, and national/international scientific priorities. While most of the assessment schemes based on publication citations may potentially be manipulated through negative citations, in this paper, we explore the conflict of interest (COI) relationships and discover negative citations and subsequently weaken the associated citation strength. Positive and negative COIdistinguished objective rank algorithm (PANDORA) has been developed, which captures the positive and negative COI, together with the positive and negative suspected COI relationships. In order to alleviate the influence caused by negative COI relationship, collaboration times, collaboration time span, citation times, and citation time span are employed to determine the citing strength; while for positive COI relationship, we regard it as normal citation relationship. Furthermore, we calculate the impact of scholarly papers by PageRank and HITS algorithms, based on a credit allocation algorithm which is utilized to assess the impact of institutions fairly and objectively. Experiments are conducted on the publication data set from American Physical Society data set, and the results demonstrate that our method significantly outperforms the current solutions in recommendation intensity of list Rat top-K and Spearman's rank correlation coefficient at top-K."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the secrecy performance of a two-user downlink non-orthogonal multiple access systems. Both single-input and single-output and multiple-input and single-output systems with different transmit antenna selection (TAS) strategies are considered. Depending on whether the base station has the global channel state information of both the main and wiretap channels, the exact closed-form expressions for the secrecy outage probability (SOP) with suboptimal antenna selection and optimal antenna selection schemes are obtained and compared with the traditional space-time transmission scheme. To obtain further insights, the asymptotic analysis of the SOP in high average channel power gains regime is presented and it is found that the secrecy diversity order for all the TAS schemes with fixed power allocation is zero. Furthermore, an effective power allocation scheme is proposed to obtain the non-zero diversity order with all the TAS schemes. Monte Carlo simulations are performed to verify the proposed analytical results."
  },
  {
    "year": "2017",
    "abstract": "Due to the imbalanced distribution of business data, missing user features, and many other reasons, directly using big data techniques on realistic business data tends to deviate from the business goals. It is difficult to model the insurance business data by classification algorithms, such as logistic regression and support vector machine (SVM). In this paper, we exploit a heuristic bootstrap sampling approach combined with the ensemble learning algorithm on the large-scale insurance business data mining, and propose an ensemble random forest algorithm that uses the parallel computing capability and memory-cache mechanism optimized by Spark. We collected the insurance business data from China Life Insurance Company to analyze the potential customers using the proposed algorithm. We use F-Measure and G-mean to evaluate the performance of the algorithm. Experiment result shows that the ensemble random forest algorithm outperformed SVM and other classification algorithms in both performance and accuracy within the imbalanced data, and it is useful for improving the accuracy of product marketing compared to the traditional artificial approach."
  },
  {
    "year": "2017",
    "abstract": "Accompanied by the rapid development of mobile video service requirements, the dramatic increase in video streaming traffic causes a heavy burden for mobile networks. Mobile edge computing (MEC) has become a promising paradigm to enhance the mobile networks by providing cloudcomputing capabilities within the radio access network (RAN). With the ability of content caching and context awareness, MEC could provide low-latency and adaptive-bitrate video streaming to improve service providing ability of the RAN. In this paper, we propose an MEC enhanced adaptive bitrate (ABR) video delivery scheme, which combines content caching and ABR streaming technology together. The MEC server acts as a controlling component to implement the video caching strategy and adjust the transmitted bitrate version of videos flexibly. A Stackelberg game is formulated to deal with the storage resources occupied by each base station. The joint cache and radio resource allocation (JCRA) is tackled into a matching problem. We propose the JCRA algorithm to solve the matching problem in order to make the cooperation between cache and radio resources. Simulation results reveal that the proposed scheme could improve both the cache hit ratio and the system throughput over other schemes."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a simulation of the growth process of leaves for computer graphics, visualization, and virtual reality applications. The following two-stage simulation is presented in this paper. First, a reference image is used to guide the early stage growth of the leaf; second, a growth function was created based on several vector fields controlled by a generalized logistic function. This growth function allows the leaf growth to continue beyond the information provided by the reference image. The core of both stages is the use of the level set method to extract and evolve the leaf shape. The proposed method facilitates the creation of frequently needed objects in an easy and flexible way that releases the user, usually an animator, from the burden of animating a leaf, which is usually a background object in a scene. We present several results from our experiments using various growth parameters and different leaves to showcase the advantages of using our method."
  },
  {
    "year": "2017",
    "abstract": "In conventional orthogonal frequency division multiplexing with index modulation (OFDM-IM), theM-ary modulated symbols are transmitted on a subset of subcarriers under the guidance of information bits. In this paper, a novel information guided precoding technique, called precoding aided (P-) OFDM-IM, is proposed to improve the spectral efficiency (SE) of OFDM-IM. In P-OFDM-IM, the information bits are jointly conveyed through the conventionalM-ary modulated symbols and the indices of precoding matrices and vectors. The P-OFDM-IM principle is embodied in two different implementations, P-OFDM-IM-I and P-OFDM-IM-II. Specifically, P-OFDM-IM-I divides all subcarriers intoLgroups and modulates them usingLdistinguishable constellations. P-OFDM-IM-II partitions the set of all subcarriers intoLoverlapping layers and performs IM layer by layer, where distinguishable constellations are employed across layers. A practical precoding strategy is designed for P-OFDM-IM under the phase shift keying/quadrature amplitude modulation constraint. A low-complexity log-likelihood ratio detector is proposed to ease the computational burden on the receiver. To evaluate the performance of P-OFDM-IM analytically, an upper bound on the bit error rate and the achievable rate is studied. Computer simulation results show that P-OFDM-IM-I outperforms the existing OFDM-IM-related schemes at high SE, while P-OFDM-IM-II performs the best at low SE."
  },
  {
    "year": "2017",
    "abstract": "The aim of an automatic video-based facial expression recognition system is to detect and classify human facial expressions from image sequence. An integrated automatic system often involves two components: 1) peak expression frame detection and 2) expression feature extraction. In comparison with the image-based expression recognition system, the video-based recognition system often performs online detection, which prefers low-dimensional feature representation for cost-effectiveness. Moreover, effective feature extraction is needed for classification. Many recent recognition systems often incorporate rich additional subjective information and thus become less efficient for real-time application. In our facial expression recognition system, first, we propose the double local binary pattern (DLBP) to detect the peak expression frame from the video. The proposed DLBP method has a much lower-dimensional size and can successfully reduce detection time. Besides, to handle the illumination variations in LBP, logarithm-laplace (LL) domain is further proposed to get a more robust facial feature for detection. Finally, the Taylor expansion theorem is employed in our system for the first time to extract facial expression feature. We propose the Taylor feature pattern (TFP) based on the LBP and Taylor expansion to obtain an effective facial feature from the Taylor feature map. Experimental results on the JAFFE and Cohn-Kanade data sets show that the proposed TFP method outperforms some state-of-the-art LBP-based feature extraction methods for facial expression feature extraction and can be suited for real-time applications."
  },
  {
    "year": "2017",
    "abstract": "The orchestration of application components across heterogeneous cloud providers is a problem that has been tackled using various approaches, some of which led to the creation of cloud orchestration and management standards, such as TOSCA and CAMP. Standardization is a definitive method of providing an end-to-end solution capable of defining, deploying, and managing applications and their components across heterogeneous cloud providers. TOSCA and CAMP, however, perform different functions with regard to cloud applications. TOSCA is focused primarily on topology modeling and orchestration, whereas CAMP is focused on deployment and management of applications. This paper presents a novel solution that not only involves the combination of the emerging standards TOSCA and CAMP, but also introduces extensions to CAMP to allow for multi-cloud application orchestration through the use of declarative policies. Extensions to the CAMP platform are also made, which brings the standards closer together to enable a seamless integration. Our proposal provides an end-to-end cloud orchestration solution that supports a cloud application modeling and deployment process, allowing a cloud application to span and be deployed over multiple clouds. The feasibility and the benefit of our approach are demonstrated in our validation study."
  },
  {
    "year": "2017",
    "abstract": "An integrated radar and communication system can cooperatively form a radar-communication network with significantly enhanced efficiency and considerably less occupied hardware resources. Such a system exhibits great advantages compared with traditional individual radar and communication modes. Numerous papers have proposed achieving the integrated functions based on phased array radar, whereas the channel modeling and channel estimation problems concerning communications are seldom discussed in the literature. In this paper, we propose a ray-cluster-based spatial channel model and a sounding channel estimation scheme realized on the existing hardware of phased array radar. Considering the correlation, we model the channel by comparing the difference between adjacent antennas, and we present the response vector of the antenna array. We analyze the number of beams that are needed to cover the space, and we present the sequence of directional beamforming vectors when sounding the channel. Redundant dictionary matrices are utilized to present the channel as a sparse signal recovery problem, in which the spatial sparsity is leveraged for performance enhancement. A sparsity adaptive matching pursuit (SAMP)-based compressed sensing tool is exploited for the sparse recovery problem and compared with the conventional least squares (LS) algorithm. The experimental results demonstrate that our proposed scheme can effectively solve the channel estimation problem in the integrated radar and communication system with reduced complexity, and it outperforms LS by 25% when considering mean square error (MSE) performance in general."
  },
  {
    "year": "2017",
    "abstract": "Detecting the foreground region of interest (ROI) for video sequences is an important issue both for video codecs and monitoring systems. In this paper, we propose a flow-process-based method to detect foreground ROI using four steps: global motion compensation, motion block extraction, multi-layer segmentation, and model updating. The former two procedures extract the foreground motion blocks and form a motion mask, and the latter two procedures remove the pixels belonging to the background inside the motion mask and update the color distributions of the background model. In addition, a block-based to pixel-based detection scheme is proposed to allow detection flexibility. Another benefit of the proposed method is that it can be embedded in video codecs for real-time ROI detection and encoding. Experimental results demonstrate that our method achieves improved performance in terms of both detection accuracy and time consumption."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a simple and compact planar balanced-to-unbalanced in-phase power divider with arbitrary terminated impedances is proposed based on the coupled-line structure and a single grounded resistor. By using the even-/odd-mode analysis and the traditional transmission-line theory, the complete design procedure and analytical equations are obtained to achieve good performances for differential-mode transmission, common-mode suppression, phase difference, arbitrary terminated impedances, and isolation. For demonstration, two different prototypes with 50-to-50 Ω matching and complex impedance transformation are designed, fabricated, and measured. Good agreement can be observed between simulated and measured results."
  },
  {
    "year": "2017",
    "abstract": "Arctic sea ice concentration information can provide technical support for the safety of Arctic shipping routes using visible and near-infrared satellite imagery, but clouds reduce detection accuracy. According to the reflectance changes of ice, clouds, and water, and because the near-infrared reflectances of clouds are much higher than that of ice and water, we propose a new method for identifying clouds. On this basis, thin clouds are extracted using atmospheric precipitation. The Arctic Ocean sea ice distribution under thin cloud cover over can be obtained based on the proposed influential factor iteration method. Finally, we obtain the sea ice concentration in the critical region of Baffin Bay and Davis Strait on June 15, 2014 from the Medium Resolution Imaging Spectrometer (MERSI) data. MERSI is one of the major payloads of the Chinese second-generation polar-orbiting meteorological satellite, FengYun-3, and is similar to the Moderate-resolution Imaging Spectroradiometer. The proposed method is shown to accurately detect sea ice concentration under thin clouds by comparison with the sea ice results from the National Snow and Ice Data Center."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the theory of characteristic modes (TCMs) is used for the first time to analyze the behavior of defected ground structures (DGS), when added to antenna designs. A properly designed DGS introduces currents opposite in direction to the original characteristic modes (CM) currents thus reducing mutual coupling. TCM is also applied to multiple-input-multiple-output (MIMO) antenna systems to develop a systematic approach that can predict whether the isolation can be enhanced further or not. For this purpose two 4-element and one 2-element MIMO designs, i.e. monopole and planar inverted-F antennas are studied. The addition of different antenna elements affects the CM significantly as well as differently. Some of the CM excited on the antenna surface contributes to the coupling between the antenna ports that is why they can be classified as coupling modes. To improve the isolation, the DGS should be introduced at certain locations that blocks the coupling modes but at the same time does not affect the non-coupling modes. If there is no such location or the current on the surface of the chassis for coupling and non-coupling modes is approximately same, the isolation cannot be enhanced further. Using this approach, isolation was improved on an average by 11 dB in all the designs considered, giving the most isolation enhancement following a systematic way compared to other works."
  },
  {
    "year": "2017",
    "abstract": "An accurate and reliable massive MIMO channel model is crucial for supporting design and performance evaluation of such systems in the future. However, massive MIMO channel sounding systems are cost prohibitive and complicated, where a large number of antenna elements and associated radio frequency transceiver chains are needed. Virtual large-scale arrays have been extensively utilized as an alternative for massive MIMO channel characterization. In this paper, we investigate virtual large-scale array systems formed by repositioning a real subarray system for channel characterization. With this scheme, we have the flexibility to scale between system cost and system channel sounding capability. Based on this scheme, general beampatterns of subarrays and subarray-based virtual large-scale arrays are derived, based on measured complex antenna patterns of antenna elements on the subarray. Three real subarray antenna systems, i.e., a 16-element uniform rectangular array (URA) at 3.5 GHz, an 8-element uniform circular array at 3.5 GHz, and an 8-element uniform linear array (ULA) at 10 GHz, were utilized to form the respective large-scale virtual arrays, i.e., a 128-element URA, a 48-element uniform cylinder array, and a 64 element ULA, respectively. Beamforming analysis based on the measured complex radiation patterns of the real arrays is provided to demonstrate that virtual large-scale arrays can significantly improve the capability of multipath parameter detection compared with the subarrays. Therefore, such cost-effective systems are promising for characterization massive MIMO propagation channels."
  },
  {
    "year": "2017",
    "abstract": "We have demonstrated and characterized the generation of ultra-broadband microwave frequency combs (MFCs) based on a current modulated distributed feedback semiconductor laser (DFB-SL) subject to optical injection, and the comb spacing of MFCs can be tuned easily through adjusting the modulation frequency fm. For the DFB-SL under only current modulation with modulation frequency fm= 1.2 GHz and modulation power Pm= 22 dBm, the generated MFC has a bandwidth of about 15.6 GHz within ±5.0 dB amplitude variation. Further, introducing continuous-wave optical injection into the current modulated DFB-SL with injection power Pi= 1170 μW and no frequency detuning between the injection light frequency and the oscillation frequency of the free-running DFB-SL, the bandwidth of MFC can be increased to 57.6 GHz. Through measuring the single sideband (SSB) phase noises of some representative comb lines, the performances of the MFCs generated before and after introducing optical injection are compared, and the SSB phase noises at 10 kHz offset frequency can be increased by 10 dB for the harmonics with frequencies of more than 40fm after adopting optical injection. Moreover, the influences of operation parameters on the bandwidths of MFCs are analyzed, and the optimized parameter range for generating ultra-broadband MFCs has been determined."
  },
  {
    "year": "2017",
    "abstract": "Distributed estimation, where a set of nodes collaboratively estimate some parameters of interest from noisy measurements, has received much attention in both science and engineering. Recent studies mainly focus on distributed non-blind or training-based estimation, that is, a training signal and its desired output are both known to the distributed receivers. However, in some applications, it is physically difficult, if not impossible, to get a training signal in prior. Besides, the use of training signals consumes much channel bandwidth. So, it is more preferable for the receivers to perform distributed estimation without the assistance and expense of training sequences, i.e., distributed blind estimation. In this paper, the problem of distributed blind estimation over sensor networks is considered, and a kind of distributed diffusion generalized Sato algorithm is proposed to design a blind equalizer for channel equalization and source signal estimation. The stability of the proposed method in mean and mean-square senses is analyzed theoretically, and its performance is verified numerically by a series of simulations."
  },
  {
    "year": "2017",
    "abstract": "The implantable microsystems are conventionally powered using batteries that have limited life-span and bio-compatibility issues. Hence, energy harvesting as an alternate and continuous power source in miniaturized implantable medical devices, especially cardiac and neural implants, has been investigated in this paper. An electret-based electrostatic energy harvester has been proposed with angular electrode structures along with a switching converter circuit to harvest maximum possible energy. The proposed harvester incorporates the properties of both area-overlap and gap closing topologies to achieve larger capacitance variation with respect to displacement, as is observed in the results. The maximum power that can be scavenged from the proposed harvester with an active surface area of 2.5 × 3.5 mm2and volume 0.4375 mm3at maximum displacement is 9.6 μW; along with a maximum power per unit surface area of 109.71 μW/cm2, which is within the advised limit of power density for in vivo implantable applications. Hence, the proposed electrostatic harvester can be used as a power source for cardiac and neural implants."
  },
  {
    "year": "2017",
    "abstract": "Fairness, low latency, and high throughput with low energy consumption are desired attributes for medium access control (MAC) protocols. The IEEE 802.15.4 standard defines the MAC and physical layers standard for IPv6 over low power personal area network (6LoWPAN). When a non-appropriate parameter setting is used, the default MAC parameters generate excessive collisions, packet losses, and high latency under high traffic when a large number of 6LoWPAN nodes being deployed. A search of the literature revealed few studies that investigate the impact of optimizing these parameters to achieve high throughput with minimum latency. This paper proposes a new intelligent approach to selecting the optimal 6LoWPAN MAC layer parameters set; the introduced mechanism depends on artificial neural networks, genetic algorithm, or particles swarm optimization to select and validate the optimized MAC parameters. The obtained simulation results showed that utilizing the optimal MAC parameters improved 6LoWPAN network throughput by 52-63% and reduced the end-to-end delay by 54-65% in which the enhancement percentage depends on the number of deployed sensor nodes in the network."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the heat transfer performance of the multi-chip (MC) LED module is investigated numerically by using a general analytical solution. The configuration of the module is optimized with genetic algorithm (GA) combined with a response surface methodology. The space between chips, the thickness of the metal core printed circuit board (MCPCB), and the thickness of the base plate are considered as three optimal parameters, while the total thermal resistance (Rtot) is considered as a single objective function. After optimizing objectives with GA, the optimal design parameters of three types of MC LED modules are determined. The results show that the thickness of MCPCB has a stronger influence on the total thermal resistance than other parameters. In addition, the sensitivity analysis is performed based on the optimum data. It reveals that Rtot increases with the increased thickness of MCPCB, and reduces as the space between chips increases. The effect of the thickness of base plate is far less than that of the thickness of MCPCB. After optimization, three types of MC LED modules obtain lower Tjand Rtot. Moreover, the optimized modules can emit large luminous energy under high-power input conditions. Therefore, the optimization results are of great significance in the selection of configuration parameters to improve the performance of the MC LED module."
  },
  {
    "year": "2017",
    "abstract": "Received signal strength (RSS) is a typical type of measurements used for indoor fingerprint localization on wireless local area network platform. To make good use of RSS information, we rely on the hypothetical test approach to perform localization with the optimized access points (APs). Specifically, in offline phase, the operating characteristics function is used to minimize the sample capacity of fingerprints at each reference point, and meanwhile the APs are optimally selected based on the concept of information gain criterion. Then, in online phase, the F-test and T-test approaches are used to conduct the RSS variance and mean test, respectively, with the purpose of achieving RPs matching, namely coarse localization. After that, the density-based spatial clustering of applications with noise is developed to realize fine localization with the improved accuracy performance. The extensive experimental results demonstrate that the proposed system is able to avoid the blindness of fingerprints collection as well as improve the effectiveness of fingerprints matching especially under the small sample capacity of fingerprints."
  },
  {
    "year": "2017",
    "abstract": "Non-volatile memory (NVM) provides persistence with dynamic random access memory (DRAM)-like performance. This paper presents SwapX, an NVM-based hierarchical swapping framework for guest operating systems (OSs) in virtual machines (VMs). SwapX works in a cluster connected to a NVM pool, where each server is equipped with both NVM and DRAM to provide hierarchical swapping service for VMs. SwapX: 1) manages free NVM on different machines and forward swap request to the central NVM pool and 2) adaptively maps the virtual address space of VMs onto the hosts DRAM, NVM, and the NVM pool according to its access patterns, so that the guest pages could be transparently swapped to the appropriate place. Prototype evaluation shows that SwapX improves energy efficiency significantly compared with both DRAM-swap and local disk swap, and only introduces small performance loss compared with DRAM-swap."
  },
  {
    "year": "2017",
    "abstract": "Reliability demonstration testing is widely applied to the industry for the verification of products' certain reliability requirement. However, for long-life and high-reliability products, the sample size and testing time are both unacceptable. To shorten the testing time, the performance degradation data are used to predict whether one sample will fail by the end of the testing. To decrease the sample size or further shorten the testing time, the hardened testing method is considered. Thus, this paper proposes a hardened reliability demonstration testing method with the accelerated degradation model to demonstrate the structural reliability at a high confidence level. First, an accelerated gamma degradation model for the considered problem is formulated. Then, the transformation method of the reliability indexes under different stress levels is proposed. Finally, we develop the optimal testing plan to obtain the stress level, sample size, and average testing time by minimizing the total testing cost, and give the testing termination rules for one sample. A numerical example is given to demonstrate the availability of the proposed method on shortening the testing time and reducing the sample size."
  },
  {
    "year": "2017",
    "abstract": "Predicting the impact of research institutions is an important tool for decision makers, such as resource allocation for funding bodies. Despite significant effort of adopting quantitative indicators to measure the impact of research institutions, little is known that how the impact of institutions evolves in time. Previous studies have focused on using the historical relevance scores of different institutions to predict potential future impact for these institutions. In this paper, we explore the factors that can drive the changes of the impact of institutions, finding that the impact of an institution, as measured by the number of the accepted papers of the institution, more is determined by the authors' influence of the institution. Geographic location of institution feature and state GDP can drive the changes of the impact of institutions. Identifying these features allows us to formulate a predictive model that integrates the effects of individual ability, location of institution, and state GDP. The model unveils the underlying factors driving the future impact of institutions, which can be used to accurately predict the future impact of institutions."
  },
  {
    "year": "2017",
    "abstract": "The volume ratio in the total solid particle mixture is an important parameter indicating the characteristics of particulate mixtures. Therefore, a simple measurement method is desirable. In this paper, the normalized permittivities of two groups of particle mixtures are tested using electrical capacitance tomography (ECT) with the series and parallel models. The experimental results show that normalized permittivity changes obtained from the series ECT model have a very strong linear relationship with the volume ratio of higher permittivity materials in the mixture. The Maxwell Garnett formula can predict the normalized permittivity only after the permittivity of each type of particle is known. The comparison between two methods suggests that ECT with the series model is a better way to monitor the volume ratio in mixtures comprising two different types of solid particle."
  },
  {
    "year": "2017",
    "abstract": "Moving pictures experts group (MPEG) media transport (MMT) and MPEG-dynamic adaptive streaming over hypertext transfer protocol (MPEG-DASH) are emerging as the content-delivery technologies for the next-generation broadcasting systems, as they seamlessly utilize various underlying delivery networks to provide hybrid multimedia services in any location. In this paper, we present an empirical analysis of the channel-zapping time, which is an important metric in the measurement of the quality of experience (QoE) of broadcast services, regarding the MMT and MPEG-DASH technologies. During this process, we also clarify the important factors that determine the channel-zapping time of the individual technologies. In addition, we propose a simple yet effective method that enables fast channel zapping for the MMT technology."
  },
  {
    "year": "2017",
    "abstract": "In order to solve the problem of the speed response and system buffeting for a bearingless induction motor (BIM), which is subjected to various interferences and uncertainties, as well as the worse convergence performance of linear sliding mode and the singularity of terminal sliding mode, a nonsingular fast terminal sliding mode control strategy is proposed. Taking the power function of system state variables into consideration, the sliding mode hyperplane is designed as a combination of linear and nonsingular terminal sliding modes, which make the approaching speed correlate with the state variables of the system. Meanwhile, the differential sliding surface is constructed, and it is based on the rotational speed and radial displacement error of the BIM. Therefore, current signal and radial force are derived by the synthesis of the equations of electromagnetic torque, motion, and levitation force motion. Compared with the conventional strategies, the convergence speed of system state variables can be accelerated during the whole process, which contributes to operate without chattering and achieve high servo precisions. The theoretical simulation and experimental results indicate that the presented strategy can not only quickly track the given value of speed and radial displacement simultaneously, but also enhance the operation quality and robustness of the system. In addition, the rotor is capable of quickly reaching the steady position and achieving stable suspension."
  },
  {
    "year": "2017",
    "abstract": "Physiological signs can be remotely observed from the physiological and physical effects caused by a cardiorespiratory activity. A wide range of research on remote cardiorespiratory monitoring systems has been done using different methods, including methods based on Doppler effect, thermal imaging, and video camera imaging. The aim of this paper was to review and compare the newest and most promising of such remote measuring methods, introducing their merits and limitations under different circumstances. In addition, this paper summarizes the performance of these methods in a table regarding the noise artifacts, subject movement, the number of regions of interest, generalization to multiple subjects, detection range (distance), biological effects, and cost. This is a thorough general overview of the remote measurement of cardiorespiratory methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a radial basis function network-based single maximum power point tracking (MPPT) control algorithm for a hybrid solar and wind energy system is designed and analyzed for standalone and grid connected applications. The extraction of maximum power from the intermittent and erratic nature renewable energy sources is the main target in the hybrid renewable energy system. In the literature, many researchers developed an individual MPPT control algorithm for solar and wind energy system, which in turn increases the number of control algorithms in a hybrid system. In this paper, a single MPPT controller is proposed to extract maximum power from both the sources simultaneously. The performance of the proposed MPPT control algorithm is analyzed in both standalone and grid connected modes, under different weather conditions. The hybrid renewable energy system is designed by considering 560-W photovoltaic system and 500-W wind system with the conventional boost converter, and it is simulated in MATLAB/Simulink environment to analyze the performance of the proposed MPPT controller."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) is one of the evolutionary directions of the Internet. This paper focuses on the low earth orbit (LEO) satellite constellation-based IoT services for their irreplaceable functions. In many cases, IoT devices are distributed in remote areas (e.g., desert, ocean, and forest) in some special applications, they are placed in some extreme topography, where are unable to have direct terrestrial network accesses and can only be covered by satellite. Comparing with the traditional geostationary earth orbit (GEO) systems, LEO satellite constellation has the advantages of low propagation delay, small propagation loss and global coverage. Furthermore, revision of existing IoT protocol are necessary to enhance the compatibility of the LEO satellite constellation-based IoT with terrestrial IoT systems. In this paper, we provide an overview of the architecture of the LEO satellite constellation-based IoT including the following topics: LEO satellite constellation structure, efficient spectrum allocation, heterogeneous networks compatibility, and access and routing protocols."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the problem of H∞proportional-integral (PI) output feedback tracking control for a ducted rocket engine when event-triggering mechanism is incorporated. We determine necessary samplings of the feedback signal by constructing predefined event-triggering condition that can reduce redundant signal transmission and updates. Specifically, the mathematical model of ducted rocket is first introduced and its control problem is described. Then, for control design, an output-based periodic event-triggering scheme is provided. Particularly, a variable built by the exogenous disturbance and reference signal is added in the event-triggering condition to adjust triggering frequency and H∞output tracking performance. Moreover, to facilitate system performance analysis, a time-delay closed-loop model is established with the PI controller. By using the Lyapunov-Krasovskii functional method, a sufficient condition is further provided to guarantee the H∞output tracking performance. Meanwhile, the influence of the event-triggered control on the system performance analysis is clarified. Finally, the proposed control method is applied to the ducted rocket control model, and simulation results demonstrate its effectiveness."
  },
  {
    "year": "2017",
    "abstract": "In the signal processing, active signal filters are commonly used to filter out the zero-average high-frequency components of a signal. In the power system, the power filters are used to filter and control the harmonics in voltages and current waveforms in the concept of power quality. In this paper, we introduce energy filters to filter and control the undesirable frequency components of power flow waveforms in the concept of energy quality. In contrast to the power filters, a family of general energy filters (GEFs) using energy storage is proposed, which virtually work as low-pass filters of power flow and can smooth, track, and process the power flow, as the power filters do with the current and voltage waveforms. In order to illustrate the GEF, the mainstream electrical energy storage (EES) systems are briefly reviewed and classified, and a general model of the EES is developed accordingly. Then, the series, parallel, and series-parallel GEF in the first and second order are proposed, and the focuses are laid on their topologies and controls. Time-domain demonstrations of the GEF based on different implementations are presented on RTDS. Bode plots of the proposed GEF are also obtained through simulations. Finally, key factors in designing GEF for practical applications are briefly discussed."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the cryptanalysis of optical ciphers combining double random phase encoding with permutation techniques, and shows its vulnerability against plaintext attack regardless of the implementation order of the two procedures. The equivalent secret keys of both the combination fashions can be retrieved, instead of the recovery of random phase masks and permutation matrix. Numerical simulations are also given for validation."
  },
  {
    "year": "2017",
    "abstract": "Video surveillance is one of the promising applications of the Internet of Things paradigm. We see heterogeneous deployment of sensor platforms in a multi-tier network architecture as a key enabler for energy optimization of battery powered high-quality video surveillance applications. In this paper, we propose a heterogeneous wireless multimedia sensor network (WMSN) prototype composed of constrained low-power scalar sensor nodes and single board computers (SBCs). Whereas constrained nodes are used for preliminary motion detection, more capable SBCs are used as camera nodes. The camera nodes stream full HD (1080 pixels) video to a remote laptop during occurrence of an event (when motion is detected). We also present a simple power model and simulation results of battery life of the motes for variable event interval and event duration."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a review is presented for the research on eye gaze estimation techniques and applications, which has progressed in diverse ways over the past two decades. Several generic eye gaze use-cases are identified: desktop, TV, head-mounted, automotive, and handheld devices. Analysis of the literature leads to the identification of several platform specific factors that influence gaze tracking accuracy. A key outcome from this review is the realization of a need to develop standardized methodologies for the performance evaluation of gaze tracking systems and achieve consistency in their specification and comparative evaluation. To address this need, the concept of a methodological framework for practical evaluation of different gaze tracking systems is proposed."
  },
  {
    "year": "2017",
    "abstract": "Epilepsy is one of the most common neurological disorders, which manifests as unprovoked seizures. The prevalence of epilepsy is higher in developing countries, where medical facilities are ill-equipped and under-staffed. Mobile EEG devices promise a new dawn for long-term ambulatory EEG monitoring, which has a potential to revolutionize health care for neurological disorders especially epilepsy. Increasing the outreach to underserved communities and continuous monitoring of patients will yield vast amount of data. This requires the development of a method that can mark regions of interest, to aid in the evaluation of the EEG trial by the experts. Such an experimental setting calls for an unsupervised method, which can detect seizure regions with high accuracy. This paper focuses on the development of a seizure detection method with the above-stated characteristics. Group invariant scattering, a novel data representation technique, has been used for feature extraction. Tested on CHB-MIT data set, the proposed methodology outperforms the current state-of-the-art approaches under similar testing conditions, by successfully detecting 180 out of 197 seizures."
  },
  {
    "year": "2017",
    "abstract": "The increasing complexity of modern day networked applications and the massive demand on the Internet resources has reignited interest and concern in the underlying networking infrastructures and their ability to cope with such complexity and adapt to the demands of the business applications, particularly where such applications require a high degree of robustness and reliability. As a result, software-defined networking has emerged as a promising approach to the definition of network architectures that could carry a high degree of adaptability and robustness reminiscent of the future Internet. Fault tolerance and network updates are considered two of the current research challenges that hamper the growth of software-defined networking in this area. Therefore, this paper represents a step toward tackling these two issues in the context of single link failures. Our main contribution lies in the definition of new algorithms that aim to enhance the problem of finding alternative paths in large-scale networks with minimal cost and time-to-update factors. The new solution aims at increasing the efficiency of flow operation reduction during link failures. We evaluate our framework and show how its implementation results in improved efficiency."
  },
  {
    "year": "2017",
    "abstract": "Compute-and-forward (C&F) has been proposed as an efficient strategy to reduce the backhaul load for distributed antenna systems. Finding the optimal coefficients in C&F has commonly been treated as a shortest vector problem, which is NP-hard. The point of our work and of Sahraei's recent work is that the C&F coefficient problem can be much simpler. Due to the special structure of C&F, some low polynomial complexity optimal algorithms have recently been developed. However, these methods can be applied to real-valued channels and integer-based lattices only. In this paper, we consider the complex valued channel with complex integer-based lattices. For the first time, we propose a low polynomial complexity algorithm to find the optimal solution for the complex scenario. Then, we propose a simple linear search algorithm, which is conceptually suboptimal, and however, numerical results show that the performance degradation is negligible compared with the optimal method. Both algorithms are suitable for lattices over any algebraic integers, and significantly outperform the lattice reduction algorithm. The complexity of both algorithms is investigated both theoretically and numerically. The results show that our proposed algorithms achieve better performance-complexity tradeoffs compared with the existing algorithms."
  },
  {
    "year": "2017",
    "abstract": "It is well recognized that the computation of an optimal liveness-enforcing supervisor (optimal supervisor for short) for a sequential resource allocation system is intractable due to the nature of the problem itself, since an integer linear programming model has to be formulated to find its solution. In this paper, a novel vector covering approach is developed to reduce the computational cost of designing maximally permissive supervisors for flexible manufacturing systems (FMSs), by reducing the number of operation places and legal markings (LMs) that need to be considered. A vector covering approach is used to find the minimal covered set of first-met bad markings (FBMs). Then, a novel vector covering approach is proposed to reduce the set of LMs to a smaller covering set. The proposed method can reduce the number of both variables and constraints in the integer linear programming problems (ILPPs). It raises the efficiency of designing optimal supervisors by solving ILPPs."
  },
  {
    "year": "2017",
    "abstract": "Early lung cancer detection with suitable treatment can significantly reduce cancer-related death rates. This paper presents a single frequency holographic electromagnetic induction (HEI) imaging method for small lung tumor detection in human thorax models. A numerical system is developed to study the feasibility of early lung tumor detection. The system includes various realistic tumors within a thorax model and a HEI measurement model. Simulation results show that various arbitrary shaped lung tumors with random sizes and locations can be identified in the thorax images. The proposed protocol has the potential for the further instantiation of lung structure."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel user plane framework, tailored for different 5G services with diverse and conflicting key performance indicators. Initially, this paper identifies the major challenges in the legacy user-plane approaches and highlights the up-to-date 5G standardization activities in this area. It further analyzes new functional requirements related to service-oriented design and the introduction of new mechanisms to address them. Subsequently, this paper discusses how various user plane design decisions related to the control/user plane split options, network slicing, and radio access network (RAN)core network (CN) interfacing can potentially impact the overall 5G architecture. For the latter, some key RAN/CN interface considerations and the interactions with CN given different protocols and quality of service models are investigated."
  },
  {
    "year": "2017",
    "abstract": "Production quality indices of complex industrial processes are usually hard to be measured in real time, which leads to unavailability of closed-loop operational optimization and control. Therefore, data-driven modeling techniques have been extensively employed to estimate production quality indices online. However, the conventional data-driven modeling methods often fail to achieve good performance because of interference from outliers. To solve the above-mentioned problem, this paper proposes an improved random vector functional link network (RVFLN) using a novel training method, which adopts a ridge regularized model with weighted factor for each training sample to evaluate the output weights. The robustness of the model has been achieved by employing a nonparametric kernel density estimation method to assign the weighted factors according to the training sample. To ensure the quality and computational load of the network in online applications, various online learning versions are presented according to the scope of data sampling. The improved RVFLN called robust regularized RVFLN has been validated using UCI, Statlib standard data sets, and an industrial grinding operation data. Results show that our proposed modeling technique perform favorably, and demonstrate its good potential for real world applications."
  },
  {
    "year": "2017",
    "abstract": "As one of the most important candidate technologies for the fifth-generation wireless communication systems, massive MIMO technology has been widely studied recently because of the significant improvements it can provide in terms of spectrum efficiency and power efficiency. As the foundation of wireless communication, research on propagation characteristics for massive MIMO channels is of primary importance. This paper investigates the characteristics for massive MIMO channels in an indoor hall scenario at 6-GHz. Channel measurements were conducted with a bandwidth of 200 MHz in both line of sight (LOS) and non-LOS (NLOS) conditions. The statistical parameters in the delay domain were extracted to show the spatial variation along the large-scale antenna array. Based on the measured data, the spatial variation is first defined, and then characterized by using the spatial power delay profile correlation coefficient and spatial channel gain correlation matrix collinearity, and the quasi-stationarity region along the massive MIMO array is estimated. Furthermore, by using the space-alternating generalized expectation-maximization algorithm, the multipath components are extracted and classified according to the propagation environments, which provide more insights to the spatial variation of massive MIMO channels. Finally, the characteristics of the extracted angular parameters are investigated and the fluctuations are modeled, where the spatial variation phenomenon was clearly observed over the large-scale antenna array. The quasi-stationarity distance of the variation was found to range from 2.5 to 32.5 cm, and the LOS case differs from the NLOS case at 6 GHz. These results and discussions are useful for analysis and future modeling for massive MIMO channels, and may contribute to future definitions of channel spatial consistency."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the NPi-Cluster, an energy proportional computing cluster that automatically powers ON or OFF the number of running machines according to the actual processing demand. A theoretical model is proposed, discussed, and implemented on a cluster composed of Raspberry Pi computer boards designed and built in order to test the proposed system architecture. Experimental results show adequate performance of the proposed platform when compared with other web servers running on traditional server architectures, but with considerably less power consumption. The power consumption of the entire cluster is about 14 W when running at maximum performance. In this situation, the system is able to handle more than 450 simultaneous requests, with about 1000 transactions per second, making it possible to be used as a server capable of handling real web workloads with acceptable quality of service. When the requests demand is reduced to a minimum, the power consumption is dynamically reduced until less than 2 W. Additionally, the proposed cluster architecture also provides high availability by reducing single points of failure on the system."
  },
  {
    "year": "2017",
    "abstract": "Wideband sensing-based cognitive radio with simultaneous wireless information and power transfer can be designed for efficient spectrum and energy usage. We first aim to maximize the sum energy harvested by all the energy harvesters subject to constraints on rate, transmit power, interference, and subchannel assignment. Due to the non-convexity of the formulated problem, we relax the integer variable and introduce an auxiliary variable to transform the original problem into a convex problem. Then, the Lagrangian and subgradient methods are adopted to obtain the optimal solutions. However, this scheme may lead to a severe fairness issue among different links. In view of this fact, we further propose an energyharvesting scheme for max-min fairness. In particular, we aim to maximize the energy harvested by the worst case individual link. We show that this problem can be solved in a similar manner to the problem of sum harvested energy maximization. Simulation results are presented to verify the convergence and fairness performance of the proposed algorithm, and to reveal a novel tradeoff between the network harvested energy and sensing time."
  },
  {
    "year": "2017",
    "abstract": "The traditional MAC protocol in ad hoc networks includes carrier sensing to judge the busy/idle state of a channel. However, in airborne tactical networks, the results of carrier sensing are usually inaccurate due to the wide distribution of nodes, large communication distance, and high-dynamic network topology, and the carrier sensing causes a large transmission delay and low channel utilization ratio. In this paper, we propose a novel channel busy recognition mechanism combined with auto regressive (AR) forecasting, namely, L-steps-revise AR (LS-AR). LS-AR predicts the number of bursts in the current time frame based on the number of bursts received in previous time frames, and the predicted number of bursts determines the channel busy/idle state. The difference between the predicted value and the true value serves as the means for correcting the next prediction. This mechanism avoids the delay caused by carrier sensing, improves the channel utilization ratio and provides a more accurate judgment to enable different priority packets to access a channel. The simulation results show that the algorithm can accurately predict the channel load and meet the requirements of the MAC protocol in airborne tactical networks."
  },
  {
    "year": "2017",
    "abstract": "Excessive power consumption is expected to be the major obstacle to achieve exascale performance within a reasonable power budget in the upcoming years. In addition, graphics processing units (GPUs) are expected to become a significant ingredient in the pursuit of exascale computing due to their fine-grained, highly parallel architecture and advancements in performance and power efficiency. To address the power obstacle of exascale systems, we suggest evaluating power and energy consumption of the fundamental software building blocks. We experimentally investigate power consumption, energy consumption, and kernel runtime of Bitonic Mergesort (a promising sort for parallel architectures) under various workloads on NVIDIA K40 GPU. The results show some insights in terms of power and energy consumption advantage of Bitonic Mergesort compared with NVIDIA’s Advanced Quicksort (a highly optimized parallel quicksort)."
  },
  {
    "year": "2017",
    "abstract": "What is index modulation (IM)? This is an interesting question that we have started to hear more and more frequently over the past few years. The aim of this paper is to answer this question in a comprehensive manner by covering not only the basic principles and emerging variants of IM, but also reviewing the most recent as well as promising advances in this field toward the application scenarios foreseen in next-generation wireless networks. More specifically, we investigate three forms of IM: spatial modulation, channel modulation and orthogonal frequency division multiplexing (OFDM) with IM, which consider the transmit antennas of a multiple-input multiple-output system, the radio frequency mirrors (parasitic elements) mounted at a transmit antenna and the subcarriers of an OFDM system for IM techniques, respectively. We present the up-to-date advances in these three promising frontiers and discuss possible future research directions for IM-based schemes toward low-complexity, spectrum- and energy-efficient next-generation wireless networks."
  },
  {
    "year": "2017",
    "abstract": "Random linear network coding (RLNC) is attractive for data transfer as well as data storage and retrieval in complex and unreliable settings. The existing systematic RLNC approach first sends all source symbols in a generation without encoding followed by the coded redundant packets at the tail of the generation. This systematic tail RLNC achieves low delay when packet drops are rare; however, recovery of any dropped source symbol requires to wait for the coded packets at the end of the generation. We propose and evaluate a novel PACE RLNC approach that paces the transmissions of coded redundant packets throughout the generation of source symbols. The paced coded packets enable the recovery of dropped source symbols without waiting for the tail end of the generation. More specifically, we propose PACE-Uniform, which uniformly intersperses individual coded packets throughout the generation, and PACE-Burst, which intersperses bursts of code packets. Our extensive simulation evaluations indicate that PACE-Uniform significantly reduces the mean source symbol delay compared to tail RLNC, while achieving nearly the same loss probability. We also demonstrate that PACE-Burst generalizes the concept of pacing the redundant packet transmissions and can be flexibly tuned between PACE-Uniform and the conventional tail RLNC by controlling the number of coded packets in a burst."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel analysis methodology applying bond graph (BG) theory for dynamic systems prognostics, which is realized through the derivation of a mathematical model from physical knowledge using the BG formalism. The graphical formalism allows generating residuals to derive the system degradation model. Moreover, the performance threshold can be determined by stability analysis to predict remain useful life of degraded components. The efficiency of the proposed methodology was demonstrated through a simulation experiment for locomotive electronically controlled pneumatic brake. A leakage fault of relay valve is injected and then predicted. The experimental results show that well performance can be obtained with lower uncertainty, which make the prognostics analysis suitable for engineering application in short of sufficient historic data."
  },
  {
    "year": "2017",
    "abstract": "Magnetic nanoparticles (MNP) enhanced microwave imaging could provide an effective approach for an early stage diagnosis of breast cancer, if encouraging results coming from accurate and realistic numerical studies are confirmed by an experimental proof of concept framework. To this end, an ad hoc laboratory setup has been designed and built up to verify the possibility of detecting the low signal scattered by MNP when embedded into a simplified but realistic breast phantom. This paper describes the developed measurement setup and the results coming from a first run of experiments, which confirm the possibility to detecting realistic amounts of accumulated nanoparticles. Moreover, the experimental results analysis allows addressing the future developments required to determine the ultimate detection limits of the technique, giving relevant information to plan the preclinical assessment."
  },
  {
    "year": "2017",
    "abstract": "Sleep posture has been used as a sleep assessment indicator in home health monitoring and clinical monitoring in recent years. Considering comfort and usability, unobtrusive sleep posture detection is needed. In this paper, we proposed a novel sleep respiration-derived posture (RDP) method based on left and right lung respiration impedance signals. We developed a dual-channel respiratory impedance acquisition system with wireless transmission. Then, support vector machine using radial basis function kernel was applied to recognize four typical sleep postures. Moreover, the performance of the SVM classifier was improved by using backward elimination. In-situ experiments with 16 subjects indicated that the RDP method reached an accuracy of 99.67%. Thus, our method is reliable in sleep posture recognition. Furthermore, a whole-night monitoring system based on respiration impedance can be conducted for sleep quality assessment."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the fault detection problem for a class of continuous-time Markovian jump systems is considered. A residual generator is constructed by a fault detection filter. The corresponding fault detection and isolation (FDI) problem is converted into an H∞filtering problem by minimizing the error between residual and fault in H∞sense. Particularly, the filter designed here is neither mode-dependent nor mode-dependent, whose operation mode is partially available but unmatched. Sufficient conditions for the existence of an FDI filter are derived in terms of linear matrix inequalities. A numerical example is given to illustrate the effectiveness and potential application of the developed theoretical results."
  },
  {
    "year": "2017",
    "abstract": "In traditional single image super-resolution (SR) methods based on dictionary model, a large number of image features are needed to train the SR dictionary. In general, these features are extracted by artificial rules, such as pixel gray, gradient, and texture structure. But, the dictionary model trained by these artificial features or their combinations has exhibited poor expression especially for the images with complex and rich structures. Therefore, how to improve the dictionary expression ability and make the dictionary have more accurate description of the image features is a problem worthy of further study. In this paper, based on the advantage of dictionary training and deep learning, a new method of single image SR based on deep learning features and dictionary model is proposed. The new algorithm contains three steps. First, the features of high-resolution and low-resolution training images are extracted by a Kernel deep learning network. Second, in the sparse representation of SR framework, the dictionary model is trained by these deep learning features. Finally, an LR image SR is completed. Theoretical analysis show that the dictionary trained by deep learning features can improve in the ability to express image complex structure and texture, and it has more advantage than traditional artificial features dictionary. The experimental results indicate that the proposed algorithm can produce good SR visual results than the comparison algorithm, such as Bicubic, sparse coding super-resolution, and super-resolution convolutional neural network. And the peak signal to noise ratio and structural similarity index measurement are improved, the Computation Time is also reasonable."
  },
  {
    "year": "2017",
    "abstract": "Wireless communications have become one of the main stake holders on which our contemporary world relies for carrying out many daily activities. In this era, the number of connected devices is increasing rapidly, contemplating not only smart phone, but also growing connectivity of machines, sensors, and so on. Therefore, it is important to investigate the alternative energy sources for powering these connected small devices. In this paper, we design an RF wireless power transfer scheme for multiple access relay system model with different signal transmission schemes. Here, it is assumed that the sources and relay are self-powered devices and fitted in with rechargeable batteries. Therefore, each node is powered by an RF wireless power transfer that relies on a dedicated energy beam sent from the destination (serves as a power beacon) and other RF transmission links and such approach is referred as opportunistic-harvesting (OH) scheme. An idea of message combining resorting to network coding (NC) and physical layer NC is presented. Performance is demonstrated in terms of error rate and outage probability analyses by using OH. The schemes presented in this paper contribute substantially to sustaining the energy in the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "A sizable amount of current literature on online drift detection tools thrive on unrealistic parametric strictures such as normality or on non-parametric methods whose power performance is questionable. Using minimal realistic assumptions such as unimodality, we have strived to proffer an alternative, through a novel application of Bernstein's inequality. Simulations from such parametric densities as Beta and Logitnormal as well as real-data analyses demonstrate this new method's superiority over similar techniques relying on bounds, such as Hoeffding's. Improvements are apparent in terms of higher power, efficient sample sizes, and sensitivity to parameter values."
  },
  {
    "year": "2017",
    "abstract": "In the mobile Internet era, users access interesting information in a continuous manner rather than as one-time results through search engines. The traditional link-based ranking algorithms typically return the relevant “popular”web pages. The current, most important web pages are ranked lower than these pages. Furthermore, most of the results are repeated when the user submits the same query days later. In this paper, we have described a novel service called tracking engine. The tracking engine allows users to enter and save queries, displays time-sensitive information, and notifies users when new, relevant information appears. To the best of our knowledge, this is the first solution seen in such a service in the mobile Internet era. First, our tracking engine called Tianji crawls the web pages based on time priority and constructs a new index structure, which enables a faster match of web pages to related keywords. Then, we develop a ranking model based on the correlation between time and importance. The experimental results show that the ranking model of Tianji has better performance than existing time-sensitive ranking methods in terms of timeliness and relevance."
  },
  {
    "year": "2017",
    "abstract": "Image fusion is a well-recognized and a conventional field of image processing. Image fusion provides an efficient way of enhancing and combining pixel-level data resulting in highly informative data for human perception as compared with individual input source data. In this paper, we have demonstrated a comprehensive survey of multi-scale and non-multi-scale decomposition-based image fusion methods in detail. The reference-based and non-reference-based image quality evaluation metrics are summarized together with recent trends in image fusion. Several image fusion applications in various fields have also been reported. It has been stated that though a lot of singular fusion techniques seemed to have given optimum results, the focus of researchers is shifting toward amalgamated or hybrid fusion techniques, which could harness the attributes of both multi-scale and non-multi-scale decomposition methods. Toward the end, the review is concluded with various open challenges for researchers. Thus, the descriptive study in this paper would form basis for stimulating and nurturing advanced research ideas in image fusion."
  },
  {
    "year": "2017",
    "abstract": "This paper examines the uniform parallel-machine scheduling problem in which the objective aims to minimize the total resource consumption (TRC) with a bounded makespan. A matheuristic is proposed to deal with this strongly NP-hard problem. The performance of the proposed matheuristic is compared with that of the state-of-the-art particle swarm optimization (PSO) meta-heuristic and the lower bound (LB) of TRC on a set of benchmark instances. Computational results show that the proposed matheuristic significantly outperforms the PSO meta-heuristic and its solution is very close to the tight LB. Given the critical need for environmental protection, this paper provides an effective and efficient algorithm for diminishing the gap between the theoretical progress of scheduling and the practical need for environmental protection."
  },
  {
    "year": "2017",
    "abstract": "Commercial RGB-D cameras provide the possibility of fast, accurate, and cost-effective 3-D scanning solution in a single package. These economical depth cameras provide several advantages over conventional depth sensors, such as sonars and lidars, in specific usage scenarios. In this paper, we analyze the performance of Kinect v2 time-of-flight camera while operating fully submerged underwater in a customized waterproof housing. Camera calibration has been performed for Kinect's RGB and NIR cameras, and the effect of calibration on the generated 3-D mesh is discussed in detail. To overcome the effect of refraction of light due to the sensor housing and water, we propose a time-of-flight correction method and a fast, accurate and intuitive refraction correction method that can be applied to the acquired depth images, during 3-D mesh generation. Experimental results show that the Kinect v2 can acquire point cloud data up to 650 mm. The reconstruction results have been analyzed qualitatively and quantitatively, and confirm that the 3-D reconstruction of submerged objects at small distances is possible without the requirement of any external NIR light source. The proposed algorithms successfully generated 3-D mesh with a mean error of ±6 mm at a frame rate of nearly 10 fps. We acquired a large data set of RGB, IR and depth data from a submerged Kinect v2. The data set covers a large variety of objects scanned underwater and is publicly available for further use, along with the Kinect waterproof housing design and correction filter codes. The research is aimed toward small-scale research activities and economical solution for 3-D scanning underwater. Applications such as coral reef mapping and underwater SLAM in shallow waters for ROV's can be a viable application area that can benefit from results achieved."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new method of computing a minimal supervisory structure that optimally enforces liveness on the Petri net models for flexible manufacturing systems (FMSs). The proposed method utilizes the structural properties of a Petri net model to avoid the computation of its reachability graph, which in general leads to the state explosion problem. This paper aims to design a single control place for each concurrent process of a Petri net model or a sub-net model, which thus provides a constant number of control places in a supervisor regardless of the number of resource places in a Petri net or sub-net model. It is shown that the structural size of a supervisor is minimal as the number of control places depends on the number of concurrent processes in the Petri net model. Precisely, two algorithms are developed in this paper. The first aims to compute active uncontrolled transitions and the second is concerned with a method to compute the generalized mutual exclusion constraints (GMECs) for each process of the Petri net model of an FMS. Furthermore, it provides an approach to design control places for each computed GMEC without solving integer linear programming problems, which greatly reduces the computational costs. When the computed control places are coupled with the uncontrolled Petri net model for an FMS, it optimally enforces liveness behavior of the Petri net model, and hence ensures the high utilization of resources in a considered system."
  },
  {
    "year": "2017",
    "abstract": "Degradation modeling and remaining useful life (RUL) prediction for products with multiple degradation features are hot topics in the prognostic and health management. The key to this problem is to describe the dependence among multiple degradation features effectively. In this paper, a multivariate degradation modeling approach based on the Bayesian dynamic linear model (BDLM) is proposed to calculate the RULs of degradation features, and the Copula function is employed to capture the dependence among RUL distributions. A combined BDLM is used to establish the multivariate degradation model, which includes two typical BDLMs, namely, the linear growth model and seasonal factors model. After the model parameters get calibrated by the maximum likelihood estimation, the model can predict the degradation process of features. Once the failure thresholds are given, the probability density function and cumulative distribution function (CDF) of RUL for each degradation feature can be obtained. Since these RUL distributions are not independent of each other, the Copula function is adopted herein to couple the CDFs. Finally, some practical testing data of a microwave component, which has two degradation features, are utilized to validate our proposed method. This paper provides a new idea for the multivariate degradation modeling and RUL prediction."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a distributed optimization algorithm for scheduling the energy consumption of multiple smart homes with distributed energy resources. In the proposed approach, the centralized optimization problem for home energy management is decomposed into a two-level optimization problem, corresponding to the local home energy management system (LHEMS) at the first level and the global home energy management system (GHEMS) at the second level. The controllable household appliances (e.g., air conditioner and washing machine) are scheduled in the LHEMS within the consumer's preferred appliance scheduling and comfort level, while the energy storage system and power trading between households are scheduled in the GHEMS. In the simulation study, the proposed distributed algorithm shows almost equivalent performance to the centralized algorithm in terms of the electricity cost and the consumer's comfort level. The impact of different network topologies on the proposed algorithm is also analyzed, and the result provides insight into the selection of the optimal network configuration in view of the consumer's electricity cost saving."
  },
  {
    "year": "2017",
    "abstract": "A compact and wideband directional circularly polarized (CP) antenna is presented in this paper. The antenna adopts four distributed micropatches as the radiation structure to realize directional radiation and wideband potential, and a low-loss sequentially rotated feeding network is utilized to provide CP excitation. Because of the good impedance matching between the proposed radiation structure and the feeding network, the antenna obtains wide bandwidths in both impedance and axial ratio (AR), and high efficiency is also achieved in the wide band. A prototype of the antenna is fabricated to validate the proposed method. The antenna's dimensions are 0.418λ0× 0.418λ0× 0.064λ0(λ0is the free-space wavelength at the center frequency of operating band). The impedance bandwidth for VSWR ≤ 2 reaches 42.9% (1.457 ~ 2.253 GHz), and the CP bandwidth for AR ≤ 3 dB reaches 22.8% (1.67 ~ 2.10 GHz). In the overlapped band, the radiation efficiency is more than 96.5%, and the gains are greater than 4.8 dBic."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) technologies enable connections among things with wider ranges. The development of such technologies in cyberspace promotes the convergence of physical space and cyberspace. The research on social attributes (e.g., relationships and social existence) that currently exist and on interactive behavior of physical things from the convergence of those two spaces can help to efficiently address certain social problems such as food safety, medicine source tracking, and traffic adjustments. This research on social attributes can also help to improve the serviceability of the IoT. At present, research on social attributes in the IoT has not modeled the relations of things in the IoT. In this paper, we formulate social attributes of thing, analyze the role of relations that is one of important social attributes in the IoT, and use super network architecture to present the complex relations among physical things. Based on these relations and relation architecture, we use an ontology-based approach to model the relations of things. Finally, we use a case to interpret the concrete application process of relations in smart home."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a two-way multi-antenna and multi-relay amplify-and-forward (AF) network with hardware impairments is analyzed. The opportunistic relay selection scheme is used in the relay selection. Maximum ratio transmission and maximum ratio combining were used in transmitted and received slot by the multi-antenna relay, respectively. In this paper, we consider two AF protocols, one is variable gain protocol and the other is fixed gain protocol. Especially, the closed-from expressions for the outage probability of the system and the closed-expressions for the throughput of the system are derived, respectively. The system performance at high signal-to-noise ratio (SNR) is very important in real scenes. In order to analyze the impact of hardware impairments on the system at high SNRs, the asymptotic analysis for the system is also derived. In order to analyze the power efficiency, the closed-form expression for the energy-efficiency performance is derived, and a brief analysis is given, which provides a powerful reference for engineering practice. In addition, simulation results are provided to show the correctness of our analysis. From the results, we know that the system will have better performance when the number of relay is growing larger and the impairments' level is growing smaller. Moreover, the results reveal that the outage floor and the throughput bound appear when the hardware impairments exist."
  },
  {
    "year": "2017",
    "abstract": "In an orthogonal frequency division multiplexing (OFDM) system, the cyclic prefix (CP) has traditionally been not useful for data detection at the receiver. This paper presents a low-complexity turboOFDM receiver to exploit all of the extra information offered by the CP to improve the data detection and channel estimation performance. In the receiver, two iterative processes, namely, the outer iteration based on the turbo equalization principle and the inner iteration based on the expectation-maximization algorithm, are proposed. The CP observation, which contains extra information about data and channel, is represented by a Forney-style factor graph and incorporated into the inner iteration for joint channel estimation and data detection, using a Gaussian message passing process. The extrinsic messages of the data enhanced by exploiting the CP are then exchanged in the outer iteration for joint channel estimation, data detection, and decoding to further improve a system performance. To effectively implement the receiver, several approximations are introduced to reduce the computational complexity to be logarithmic in the length of the OFDM symbol N, i.e., O(NlogN) per OFDM symbol. Extensive simulation results show that the bit error rate performance of the proposed low-complexity turbo-OFDM receiver is superior to that of existing turbo-OFDM receivers with exploiting the channel information in the CP only or without exploiting the CP, as well as conventional OFDM receivers, in particular for time-varying channels."
  },
  {
    "year": "2017",
    "abstract": "Sharing economy becomes an emerging issue in urban life. It is not a new phenomenon but an assembling of existing techniques to meet specific demands of users. It also points out a better way to implicitly collect users' contexts and to understand users than the conventional one that requires much user involvement (e.g., tedious inputs). A universal model, for this purpose, that supports dynamic analysis and mining of user-generated content (or contexts) is designed in this paper. Two major factors, sensing and analysis of crowd preference and their decision-making behavior, are especially targeted. This model formulates the given scenario that comprehensively illustrates the possible actors and correlated actions among them with a set of rules to enhance the machine learning results. This model outlines a detail process on pre-/post-process of the data, and indicates the core techniques for user modeling. The raw data collected from on-service website, i.e., Airbnb, are utilized for the preliminary examination of our proposal. We especially look at internal factors (e.g., nationality, gender, and age) and external factors (e.g., device, social media, and time) that reflect implicitly the difference on crowd's preference and behavior. Results after statistics-based machine learning reveal that the relation among users' internal and external factors share high similarity with their behavior patterns, and can be applied, considering particular features, for service provision to a specific type of crowds."
  },
  {
    "year": "2017",
    "abstract": "This paper identifies the market changes following the technological switch from 3G to 4G in the Indonesian market. The primary data were obtained by conducting a market survey in April-May 2017. A set of questionnaires was developed to compare subscribers' activities between 3G and 4G service utilization in terms of two activity clusters. The first cluster consists of 14 conventional activities, representing typical activities that have been occurring since the previous implementation of mobile technology. The second cluster consists of 11 digital ecosystem activities, referring to services that also engage other technological systems through data communications. Subsequently, the strategic implications for mobile network operators were investigated from the theoretical perspective of technological evolution. The results indicate that mobile network operators should adaptively respond by making messenger applications the core of new service innovations. Significant traffic intensification is also observed with regard to conventional activities, and there is a need for market education along with digital ecosystem establishment. The findings also imply a changing paradigm in terms of how users value service experience when accessing 4G applications. The overall experience is determined by interdependent components shaping an ecosystem perspective. The user's handheld mobile device acts as the central gateway for data communications, and its performance is assessed in relation to other connected devices and applications."
  },
  {
    "year": "2017",
    "abstract": "Cell outage compensation is a crucial way for public safety network (PSN) to recover network communication independently during disasters. As a significant technology for 5G, a cloud-radio access network (C-RAN) plays an important role in a PSN. C-RAN can better achieve multi-cell cooperative outage compensation under dense network coverage because of the characteristics of densification and centralization. Therefore, we propose an efficient multi-cell cooperative outage compensation convergence for the scene where more than one radio remote units (RRUs) are destructed in C-RAN-based PSN. This scheme compensates the network using both cooperative transmission and power adjustment. First, RRUs are selected to participate in the compensation according to the topology structure. Then, the problem model is built aiming at optimizing system outage probability. At the same time, the constraints of resources and service quality are considered. In addition, an enhanced immune-genetic algorithm is proposed innovatively to solve this NP-hard problem and to get the results of RRU transmit power parameters. Finally, simulation results demonstrate that the proposed algorithm convergences rapidly and our scheme reduces the PSN system outage probability effectively with the guarantee of users received power and the restriction of interference effects. The outage probability of the PSN system using the proposed method is 17.8% of the only cooperative transmit method and 3.9% lower than the only adjust power method."
  },
  {
    "year": "2017",
    "abstract": "With the elderly and disabled population increasing worldwide, the functionalities of smart wheelchairs as mobility assistive equipment are becoming more enriched and extended. Although there is a well-established body of literature on fatigue detection methods and systems, fatigue detection for wheelchair users has still not been widely explored. This paper proposes a neuro-fuzzy fatigue tracking and classification system and applies this method to classify fatigue degree for manual wheelchair users. In the proposed system, physiological and kinetic data are collected, including surface electromyography, electrocardiography, and acceleration signals. The necessary features are then extracted from the signals and integrated with a self-rating method to train the neuro-fuzzy classifier. Four degrees of fatigue status can be distinguished to provide further fatigue and alertness prediction in the event of musculoskeletal disorders caused by underlying fatigue."
  },
  {
    "year": "2017",
    "abstract": "We describe our experience of introducing digital signal processing (DSP) concepts via a software-defined radio project using a very inexpensive TV USB capture dongle. Through a series of weekly lab exercises, the students learned and applied DSP concepts to design a completely digital FM receiver. The proposed lab experience introduced concepts, such as sampling, IQ signal representation, sample rate conversion, filter design, filter delays, and more, all with an attractive learn-by-doing approach. The first offering of this course initially took place in Fall 2014 and has been successfully offered and repeated with growing success ever since. Our experience can serve as a proof of concept of the possibility of carrying out, in a massive open online course-like fashion, certain engineering labs that require inexpensive and readily available hardware components."
  },
  {
    "year": "2017",
    "abstract": "Internet Engineering Task Force (IETF) has proposed an extension based on Mobile IPv6 (MIPv6), named as network mobility basic support protocol (NEMO-BSP), to support NEMO in IPv6 networks. However, NEMO-BSP inherits all the drawbacks of MIPv6, such as inefficient routing path, high handover latency, and packet encapsulation overhead. To address these drawbacks of NEMO-BSP, this paper proposes an NEMO supporting scheme based on a novel Locator/ID Separation (LIDS) architecture, namely LIDS-NEMO. In LIDS-NEMO, Multiple Virtual Mapping (MVM) scheme is proposed to differentiate the intra-NEMO and inter-NEMO mobility. Besides, packets are transmitted through the most optimized route in LIDS-NEMO. The simulation results show that LIDS-NEMO reduces the signaling cost significantly when compared with NEMO-BSP and it will be a promising scheme to provide NEMO support in the LIDS context."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the distributed blocking flow shop scheduling problem (DBFSP) using metaheuristics. A mixed integer programming model for solving the problem is proposed, and then three versions of the hybrid iterated greedy algorithm (HIG1, HIG2, and HIG3) are developed, combining the advantages of an iterated greedy algorithm with the operators of the variable Tabu list, the constant Tabu list, and the cooling schedule. A benchmark problem set is used to assess empirically the performance of the HIG1, HIG2, and HIG3algorithms. Computational results show that all the three versions of the proposed algorithm can efficiently and effectively minimize the maximum completion time among all factories of the DBFSP, and HIG1is the most effective."
  },
  {
    "year": "2017",
    "abstract": "A decision map contains complete and clear information about the image to be fused, and detecting the decision map is crucial to various image fusion issues, especially multi-focus image fusion. Nevertheless, in an attempt to obtain an approving image fusion effect, it is necessary and always difficult to obtain a decision map. In this paper, we address this problem with a novel image segmentation-based multi-focus image fusion algorithm, in which the task of detecting the decision map is treated as image segmentation between the focused and defocused regions in the source images. The proposed method achieves segmentation through a multi-scale convolutional neural network, which performs a multi-scale analysis on each input image to derive the respective feature maps on the region boundaries between the focused and defocused regions. The feature maps are then inter-fused to produce a fused feature map. Afterward, the fused map is post-processed using initial segmentation, morphological operation, and watershed to obtain the segmentation map/decision map. We illustrate that the decision map gained from the multi-scale convolutional neural network is trustworthy and that it can lead to high-quality fusion results. Experimental results evidently validate that the proposed algorithm can achieve an optimum fusion performance in light of both qualitative and quantitative evaluations."
  },
  {
    "year": "2017",
    "abstract": "In this paper, two novel bridge type dual input dc-dc converter topologies are introduced for integrating two input energy sources. Out of the two topologies, the latter topology is an improved version of the former one. Both converters have the capability to simultaneously deliver power to the load from the input energy sources. The major advantages of the improved converter as compared with the basic topology are its capability to perform the buck, boost, and buck-boost modes of operation using the same structure and the ability to deliver power to the load even with the failure of any one of the input energy sources. Hence, the detailed software simulation of the improved converter has been performed using MATLAB/Simulink platform. Different analyses have been conducted by considering the parameters, such as the equivalent series resistance of the passive elements in the converter and efficiency of the converter, for better validation of the converter performance. The hardware prototype of the improved converter has been developed in the laboratory environment and tested successfully. The proposed converters have certain merits like less component count, compact structure, and efficient energy utilization, compared with existing converter topologies, which are already reported in the literature."
  },
  {
    "year": "2017",
    "abstract": "To address key challenges for beyond 5G wireless technologies in a simultaneous manner, we propose an orbital angular momentum (OAM)-based, secure, energy-efficient multidimensional coded modulation. The key idea is to employ all available degrees of freedom (DOFs) to convey the information over the wireless links, including amplitude, phase, polarization state, and spatial-domain DOFs. In particular, the OAM is associated with the azimuthal phase dependence of the wavefront, and represents an underutilized DOF. Given that OAM eigenstates are orthogonal, an arbitrary number of bits per symbol can be transmitted. Here, we propose utilizing OAM DOF not only to improve spectral and energy efficiencies, but also to significantly improve the physical-layer security of future wireless networks. To implement the OAM multiplexer and demultiplexer in the RF domain, we propose using properly designed antenna arrays. We also propose employing the Slepian sequences as either basis functions in baseband or impulse responses of antenna arrays in passband to further increase the dimensionality of the wireless system and enable beyond 1-Tb/s wireless transmission. Monte Carlo simulations demonstrate high tolerance to fading effects of LDPC-coded multidimensional signaling schemes compared with the conventional LDPC-coded QAM."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) is an emerging concept, which aims to connect billions of devices with each other. The IoT devices sense, collect, and transmit important information from their surroundings. This exchange of very large amount of information amongst billions of devices creates a massive energy need. Green IoT envisions the concept of reducing the energy consumption of IoT devices and making the environment safe. Inspired by achieving a sustainable environment for IoT, we first give the overview of green IoT and the challenges that are faced due to excessive usage of energy hungry IoT devices. We then discuss and evaluate the strategies that can be used to minimize the energy consumption in IoT, such as designing energy efficient datacenters, energy efficient transmission of data from sensors, and design of energy efficient policies. Moreover, we critically analyze the green IoT strategies and propose five principles that can be adopted to achieve green IoT. Finally, we consider a case study of very important aspect of IoT, i.e., smart phones and we provide an easy and concise view for improving the current practices to make the IoT greener for the world in 2020 and beyond."
  },
  {
    "year": "2017",
    "abstract": "An uni-directional antenna designed by resonance-based reflector has the merits of compact size, low-profile, and ultra-wide impedance bandwidth. However, its front to back ratio (FBR) bandwidth is narrow owing to the small reflection coefficient values at the high frequencies of the RBR in-phase band. To solve this problem, a ring-shaped director (RD) was placed above a resonance-based reflector-based antenna to guide the high frequencies. Then, the FBR bandwidth was enhanced. The proposed antenna achieves a wide measured impedance bandwidth from 2.17 to 3.76 GHz (53.6%). Its FBR band (FBR >7 dB) covers the whole operational band and the FBR >10-dB band covers 2.17-2.58 GHz (17.3%). The proposed antenna consists of a bow-tie element, a ring-shaped resonance-based reflector under the bowtie element and an RD above the bow-tie element to form a sandwich configuration. The profile of the proposed antenna is only 0.16 λ at the lowest frequency of 2.17 GHz. To further evaluate the performances of the proposed antenna, the time-domain characteristics of the antenna were analyzed in terms of group delay, waveform response, correlation coefficient, and pulsewidth stretch ratio. Good time-domain characteristics were observed."
  },
  {
    "year": "2017",
    "abstract": "Recent advancements in human-computer interaction research have led to the possibility of emotional communication via brain-computer interface systems for patients with neuropsychiatric disorders or disabilities. In this paper, we efficiently recognize emotional states by analyzing the features of electroencephalography (EEG) signals, which are generated from EEG sensors that noninvasively measure the electrical activity of neurons inside the human brain, and select the optimal combination of these features for recognition. In this paper, the scalp EEG data of 21 healthy subjects (12-14 years old) were recorded using a 14-channel EEG machine while the subjects watched images with four types of emotional stimuli (happy, calm, sad, or scared). After preprocessing, the Hjorth parameters (activity, mobility, and complexity) were used to measure the signal activity of the time series data. We selected the optimal EEG features using a balanced one-way ANOVA after calculating the Hjorth parameters for different frequency ranges. Features selected by this statistical method outperformed univariate and multivariate features. The optimal features were further processed for emotion classification using support vector machine, k-nearest neighbor, linear discriminant analysis, Naive Bayes, random forest, deep learning, and four ensembles methods (bagging, boosting, stacking, and voting). The results show that the proposed method substantially improves the emotion recognition rate with respect to the commonly used spectral power band method."
  },
  {
    "year": "2017",
    "abstract": "Quality assessment of 3-D images encounters more challenges in better understanding of human visual system. In this paper, we propose a perceptual quality assessment approach for stereoscopic images by modeling visual properties of the primary visual cortex. For this purpose, we obtain a new feature encoding approach for the visual information, and define a new similarity measure approach to match the feature encoding to give more reliable and accurate quality assessment. Experimental results on three symmetrically, asymmetrically, and multiple distorted stereoscopic image quality assessment databases demonstrate that our method has high consistency with subjective assessment."
  },
  {
    "year": "2017",
    "abstract": "The design of a millimetre-sized power converter is proposed which is based on coil coupling that could be integrated into the neural or cardiac implantable medical device (IMD) to provide isolated power or energy transmission by harvesting it from external transmitter device. A special step-up case of transformer coupling to a millimetre-sized receiver coil by a comparatively larger transmitter coil is examined. This paper is expected to increase research efforts to develop the battery-less IMD's with reduced size, low power, high efficiency, and improved reliability and feasibility. Based on our work, we believe that the inductive coupling link with low loss ferrite material is the suitable method to be used to power the batteryless devices. The converter produces the targeted output power of more than 400 μW with 1 mm3size of the coil at 2 MHz."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) brings the third development wave of the global information industry, which makes users, network, and perception devices cooperate more closely. However, if IoT has security problems, it may cause a variety of damage and even threaten human lives and properties. To improve the abilities of monitoring, providing emergency response, and predicting the development trend of IoT security, a new paradigm called network security situation awareness (NSSA) is proposed. However, it is limited by its ability to mine and evaluate security situation elements from multi-source heterogeneous network security information. To solve this problem, this paper proposes an IoT network security situation awareness model using a situation reasoning method based on semantic ontology and user-defined rules. Ontology technology can provide a unified and formalized description to solve the problem of semantic heterogeneity in the IoT security domain. In this paper, four key sub-domains are proposed to reflect an IoT security situation: context, attack, vulnerability, and network flow. Furthermore, user-defined rules can compensate for the limited description ability of ontology, and hence can enhance the reasoning ability of our proposed ontology model. The examples in real IoT scenarios show that the ability of the network security situation awareness that adopts our situation reasoning method is more comprehensive and more powerful reasoning abilities than the traditional NSSA methods."
  },
  {
    "year": "2017",
    "abstract": "Cloud data centres are faced with the serious problem of increasing energy consumption. Thus, the problem of virtual machine placement for energy saving is becoming a critical issue. Considering various requirements of cloud providers and users, a many-objective virtual machine placement model is built to minimize energy consumption and maximize load balance, resource utilization, and robustness. An energy-efficient KnEA (EEKnEA) algorithm is proposed to address this problem. EEKnEA is improved by proposing an energy-efficient-oriented population initialization strategy based on the knee point-driven evolutionary algorithm (KnEA), which is a high-performance algorithm for many-objective problems. The proposed model and performance of EEKnEA are evaluated in comparison to KnEA and other algorithms. Experimental results show that the proposed model is reasonable, and the EEKnEA algorithm outperforms its counterparts on this type of problem in terms of energy saving, load balance, and robustness."
  },
  {
    "year": "2017",
    "abstract": "In vehicular ad hoc networks (VANETs), trust establishment among vehicles is important to secure integrity and reliability of applications. In general, trust and reliability help vehicles to collect correct and credible information from surrounding vehicles. On top of that, a secure trust model can deal with uncertainties and risk taking from unreliable information in vehicular environments. However, inaccurate, incomplete, and imprecise information collected by vehicles as well as movable/immovable obstacles have interrupting effects on VANET. In this paper, a fuzzy trust model based on experience and plausibility is proposed to secure the vehicular network. The proposed trust model executes a series of security checks to ensure the correctness of the information received from authorized vehicles. Moreover, fog nodes are adopted as a facility to evaluate the level of accuracy of event's location. The analyses show that the proposed solution not only detects malicious attackers and faulty nodes, but also overcomes the uncertainty and imprecision of data in vehicular networks in both line of sight and non-line of sight environments."
  },
  {
    "year": "2017",
    "abstract": "As one of the signed variants of the diffusion least mean square (DLMS) algorithm over networks, the diffusion sign error algorithm has been presented in previous reference. In this paper, we propose two novel signed variants of the DLMS algorithm, i.e., the diffusion signed regressor algorithm and the diffusion sign-sign algorithm. Moreover, this paper analyzes the performance of these three signed variants of the DLMS algorithm for cyclostationary white Gaussian inputs which have periodically time-varying variances. It is assumed that the distributed algorithms are in non-stationary environments. Specifically, the unknown parameter to be identified is time-varying according to the standard random walk model. The analysis models in terms of mean weight behavior and mean square performance are provided, in which, we can find some interesting results. Finally, simulations are carried out to verify the correctness of the proposed analysis model."
  },
  {
    "year": "2017",
    "abstract": "Model-based reliability analysis and assessment methods rely on models, which are assumed to be precise, to predict reliability. In practice, however, the precision of the model cannot be guaranteed due to the presence of epistemic uncertainty. In this paper, a new reliability metric, called belief reliability, is defined to explicitly account for epistemic uncertainty in model-based reliability analysis and assessment. A new method is developed to explicitly quantify epistemic uncertainty by measuring the effectiveness of the engineering analysis and assessment activities related to reliability. To evaluate belief reliability, an integrated framework is presented where the contributions of design margin, aleatory uncertainty, and epistemic uncertainty are integrated to yield a comprehensive and systematic description of reliability. The developed methods are demonstrated by two case studies."
  },
  {
    "year": "2017",
    "abstract": "With the proliferation of millimeter-Wave (mm-Wave) systems and visible light communications (VLCs), indoor localization may find multiple applications. When high localization accuracy is required and triangulation is not possible due to the infrastracture and scenario limitations, the computational complexity of searching on a virtual grid may become excessive. In this paper, we amalgamate uplink mm-Wave-based and downlink VLC-based localization. We employ quantum search algorithms for reducing the computational complexity required for achieving the optimal full-search-based performance. Regarding the uplink mm-Wave-based localization, we employ a single anchor equipped with multiple antenna elements and we exploit the specular multipath components created by the room's walls. The proposed solutions outperform the state-of-the-art algorithms. Furthermore, various channel models are considered based on real indoors mm-Wave measurements. By using the VLC-based triangulation for downlink and the proposed mm-Wave-based localization algorithm for uplink, there was an average positioning error of 5.6 cm in the room considered, while requiring 261 database queries on average."
  },
  {
    "year": "2017",
    "abstract": "The advent of topological data analysis enabled us to extract topological invariants under object deformations and transformations, such as the number of loops in an image, which was conventionally unachievable with the filters of analog nature. However, the existing algorithms are mostly off-line or non-parallel, and therefore not suitable for interactive applications, such as touch sensors. Therefore, we previously proposed a real-time, distributed algorithm to compute the Euler characteristics as a touch invariant by summing up the Poincare-Hopf index for each pixel, which is fortunately sparse being zero for most pixels. However, the previous algorithm was specialized and restricted to plane screens with triangulated meshes. The explosive growth of the tablet or touch interface technology with super-thin screens or virtual realities is creating a new demand for software, for example, to detect if or not a touch wraps plastic bottles, coffee cup handles, or balls. In this paper, we extended the scope of our previous algorithm from plane to curved screens, including cylinders, toruses, and regular polyhedra, for solving truly topological sensing problems. We demonstrate that our implementation in processing, in the form of solely local logical operations and without any time-consuming iterative operations, returns and updates the correct topological invariants of touches on curved screens in real time."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we analyze the performance of downlink transmission in a space division multiple access (SDMA) millimeter-wave (mmWave) system with beam selection, where antenna arrays are considered at a base station (BS) and users. Under the assumption of limited scattering environment, we propose a simplified approach to analyze the downlink performance of the SDMA system. In this scheme, the throughput for each BS beam is approximated by a binary random variable for tractable analysis and an approximate closed-form solution for the downlink sum rate is derived. It is shown that the predicted throughputs by the proposed method reasonably agree with simulation results."
  },
  {
    "year": "2017",
    "abstract": "The cumulative sum (CUSUM) control charts are widely used for measurement control of continuous processes. However, the quality characteristics of interest in many production processes, follows a sequence of discrete counts for non-conformities often modeled using a Poisson distribution. This paper introduces new CUSUM control chart design structure to monitor the location of a Poisson parameter. The proposed two-sided scheme is based on ranked set sampling, a more well-structured data collection method than the traditional random sampling. Extensive simulations were used to compute the average, standard deviation and percentiles of the run-length distribution for the new Poisson CUSUM charts. Relative run-length performances achieved were compared with the classical schemes for monitoring improvements or deteriorations in a Poisson process. Consequently, it turns out that the new scheme has greatly enhanced the sensitivity of the classical chart in detecting changes in Poisson processes. The practical application of the new Poisson CUSUM chart is illustrated through a numerical example."
  },
  {
    "year": "2017",
    "abstract": "In order to overcome the disadvantage that the dynamic sliding mode surface of the discrete global sliding mode control has a too long evolution time, a quick discrete global sliding mode control method is proposed. A decay function of the dynamic sliding mode surface which can decay to zero in the finite time is constructed. Thereby, the dynamic sliding mode surface can evolve into the linear sliding mode surface at the given time. Thus, the method not only is strong global robustness, but also can quicken the response of the system and shorten the transition time. The method can be applied in the tension control system of the time delay carbon fiber multilayer diagonal loom. Simulation results prove the validity of the method."
  },
  {
    "year": "2017",
    "abstract": "Device-to-device (D2D) communications can effectively offload the traffic of cellular system in a distributed way. However, during the data forwarding process, malicious D2D users can intermittently discard data of other users, which seriously affects the data forwarding efficiency. Therefore, a malicious-forwarding-behavior-aware link selection mechanism (MBLS) is proposed in this paper to alleviate the influence of malicious attacks. User behaviors are analyzed according to the correlation between the social relationship and forwarding behavior of users, and the identification of malicious behavior is obtained by Elman neural network. Thus, malicious users can be detected, and then the optimal link can be selected. The simulation results show that the proposed mechanism can effectively detect the malicious behaviors of D2D users, notably improve the reliability of data transmission and significantly enhance the network performance."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider hardware limitation at the secondary user, which makes multiband (wideband) spectrum sensing more challenging. Under secondary user (SU) hardware limitation, the SU can only sense a small portion of the multiband spectrum for a given time period, which introduces a design issue of selecting subchannels to sense at a given time. A random spectrum sensing strategy (RSSS) is presented to select the subchannels to sense in a totally random fashion. With the Markov assumption of the primary user (PU) behavior, a persistent spectrum sensing strategy (PSSS) is proposed to take advantage of the PU traffic patterns in determining the channels to sense. Theoretical and simulation results show that RSSS and PSSS display different performance in different ranges of PU traffic parameters. We finally propose an adaptive spectrum sensing strategy (ASSS), which determines whether to use RSSS or PSSS for spectrum sensing at a given time based on the estimated PU traffic parameters. Numerical results under various system parameters are presented to evaluate the performance of RSSS, PSSS, and ASSS. The ASSS is shown to gain the advantages of both RSSS and PSSS in different ranges of PU traffic parameters and provide more available subchannels for SU."
  },
  {
    "year": "2017",
    "abstract": "The quantitative feedback theory is adopted as a robust control scheme for the distribution-static-compensator (DSTATCOM) in order to deactivate the effects of variations in its harmonic filter parameters on the fault ride through the capability of wind turbines (WTs). These variations may be due to factors like component aging and thermal drift. The DSTATCOM is applied in parallel with the wind generation (WG) together with a bridge-type-fault-current-limiter in series, to improve FRT capability of the WT. This proposed robust control strategy of the DSTATCOM is applied to a microgrid, including WG. The performance of this proposed scheme is simulated in PSCAD/EMTDC environment and the results indicate its efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a backstepping global sliding mode fuzzy control based on neural network together with a proportional integral derivative (PID) sliding mode manifold is proposed for a three-phase active power filter (APF). This system consists of a backstepping PID global sliding mode controller, a fuzzy uncertainty approximator and a neural estimator. The design process of Lyapunov function and the controller can be systematic and structured through the reverse design by backstepping control. A global sliding mode controller is introduced to obtain overall robustness, speeding up the system response. On the issues of the conventional proportional derivative sliding mode surface, the integral item is added to suppress the steady state error and enhance the robustness. Besides, it is beneficial to estimate the unknown dynamic characteristics of the APF system via RBF neural network. Furthermore, the fuzzy controller utilized to approach to the switching function can reduce the influence of chattering which may lead to insulated gate bipolar transistor malfunction of the actual active power filter, achieving a better property. Finally, simulation studies with MATLAB/SimPower systems toolbox demonstrate that the designed backstepping neural PID global sliding mode fuzzy controller can obtain expected properties in three different conditions, and some comparisons are made to verify the superior performance of the raised control method."
  },
  {
    "year": "2017",
    "abstract": "A novel control scheme for a thrust vector system with an electromechanical actuator is proposed. The proposed method merges the idea exploited in sliding mode control (SMC) with proportion- integration-differentiation (PID) control, which brings advantages in terms of strong robustness and good position tracking performance, while the chattering of the control signal produced by the SMC is small. A model for a typical thrust vector system with an electromechanical actuator is established and analyzed. To evaluate the performance of the proposed approach, the traditional PID controller mixed with bangbang control and the proposed compound control law is applied to the two-channel model of the thrust vector system with an electromechanical actuator. Various simulation examples are provided to show that this compound control law has stronger robustness to the model parameter uncertainty and better position tracking performance. In addition, the chattering is slight."
  },
  {
    "year": "2017",
    "abstract": "A single-feed dual-band dual-sense circularly polarized (CP) stacked patch antenna with a small frequency ratio is proposed for Chinese 842.5/922.5-MHz radio frequency identification (RFID) reader applications. Two elliptical-ring patches are configured orthogonally to operate at different frequency bands with different senses of circular polarization. A π-type dual-band complex impedance transformer is modified with asymmetric open-ended stubs to easily tune the input matching for both bands. Measured impedance bandwidth is 2.99% (824-849 MHz) for the lower band and 2.72% (908-933 MHz) for the upper band, in which the input return loss is greater than 10 dB. The measured 3-dB axial ratio (AR) bandwidths for the lower and upper bands are 1.07% (838-847 MHz) and 1.19% (918-929 MHz), respectively. The measured frequency ratio is 1.10. The measured gain is more than 4.5 dBic over both bands. Therefore, the proposed antenna can be a good candidate for Chinese RFID readers operating in the bands of 840-845 MHz and 920-925 MHz."
  },
  {
    "year": "2017",
    "abstract": "Controlling a grain dryer plant is a challenging task because of its complex drying mechanism. The aim of this paper is to investigate effective control strategies for a newly designed grain dryer plant, and to optimize the control performance, such as the overshoot, accuracy, and anti-disturbance abilities. In this paper, a genetically optimized fuzzy immune proportional integral derivative controller (GOFIP) is designed, which is a combination of intelligent fuzzy immune feedback control and traditional control. Fuzzy rules are used to imitate the biological immune feedback mechanism to automatically tune the proportional integral derivative (PID) parameters, and a genetic algorithm is used to optimize the controller's initial parameters, which can overcome the inadequacy of the general fuzzy immune PID controller. In addition, the dryer plant is introduced in this paper, and the classic drying model to verify the effectiveness of the proposed controller is fitted based on data from the practical drying experiments. Finally, simulation comparisons of control performances with three other controllers (the general PID controller, the fuzzy PID controller, and the fuzzy immune PID controller) are made, and anti-disturbance performance is tested based on the reformulated drying model in MATLAB. By simulating the step response of the outlet grain moisture content (MC), it is shown that the GOFIP controller has the best control performances to bring the outlet grain MC to the target value rapidly, enabling the drying control system to have no overshoot, better accuracy, and stronger anti-disturbance performance compared with the other three simulated controllers. The proposed controller has overcome the parameter adjustment difficulty of the traditional PID controller and can obtain the optimized control of grain drying by using the genetic optimization algorithm. The GOFIP controller is a reliable and precise control method incorporating uncertainty factors and may als..."
  },
  {
    "year": "2017",
    "abstract": "Image set classification has attracted increasing attention with respect to the use of significant amounts of within-set information. The covariance matrix is a natural and effective descriptor for describing image sets. Non-singular covariance matrices, known as symmetric positive definite (SPD) matrices, are regarded as points on a Riemannian manifold. A common method of classifying points on a manifold is to explicitly map the SPD matrices from a Riemannian manifold to Euclidean space, such as in the covariance discriminative learning (CDL) method. However, the disadvantages of the CDL method are as follows: 1) the method models the whole image set as a covariance matrix, whereas if there are insufficient set samples or merely one set, the within-class information studied by the discriminative learning may not be utilized well and 2) when the original sample covariance matrices are of high dimensionality, the computational cost is non-trivial. To address these problems of CDL, we propose to exploit the maximal linear patch to cluster image sets into multiple subsets (local patches), which could provide substantially more within-class information. Moreover, we refine the manifold formed by the SPD matrices to a lower dimensionality and more discriminative manifold by collaboratively applying principal component analysis to all training sets. Experiments are performed on face recognition and objection categorization tasks; extensive comparison results illustrate the considerable effectiveness of our proposed method."
  },
  {
    "year": "2017",
    "abstract": "This paper explores and describes the state of the art for what concerns the model-driven approaches proposed in the literature to support reverse engineering. We conducted a systematic literature review on this topic with the aim to answer three research questions. We focus on various solutions developed for model-driven reverse engineering, outlining in particular the models they use and the transformations applied to the models. We also consider the tools used for model definition, extraction, and transformation and the level of automation reached by the available tools. The model-driven reverse engineering approaches are also analyzed based on various features such as genericity, extensibility, automation of the reverse engineering process, and coverage of the full or partial source artifacts. We describe in detail and compare fifteen approaches applying model-driven reverse engineering. Based on this analysis, we identify and indicate some hints on choosing a model-driven reverse engineering approach from the available ones, and we outline open issues concerning the model-driven reverse engineering approaches."
  },
  {
    "year": "2017",
    "abstract": "Large amounts of sensor data are frequently generated and streamed from sensors deployed on various buildings, in forests or in other application areas. In many of these areas, one difficulty is managing the velocity and volume of the big sensor data while still providing low time latency support for data analysis. Data aggregation can reduce the volume of big sensor data. However, data aggregation is a fundamental yet time-consuming operation in wireless sensor networks (WSNs), particularly in high-density WSNs. Therefore, researchers have started focusing on minimizing the latency of data aggregation, which has been proven to be an NP-hard problem. This paper proposes a cluster-based distributed data aggregation scheduling algorithm, distributed multi-power and multi-channel (DMPMC), that can minimize the data aggregation latency in multi-channel and multi-power WSNs. To save energy, low transmission power is used for packet transmissions inside a cluster, and high power is used for packet transmissions among clusters. Simulations are conducted to compare DMPMC with the best centralized algorithm in a single channel, named E-PAS, the best distributed algorithm in a single channel, named CLU-DDAS, and the best algorithm in multi-channels, named multi-channel. The results show that the DMPMC algorithm proposed in this paper achieves the lowest average latency."
  },
  {
    "year": "2017",
    "abstract": "Assessing cognitive load during a learning phase is important, as it assists to understand the complexity of the learning task. It can help in balancing the cognitive load of postlearning and during the actual task. Here, we used electroencephalography (EEG) to assess cognitive load in multimedia learning task. EEG data were collected from 34 human participants at baseline and a multimedia learning state. The analysis was based on feature extraction and partial directed coherence (PDC). Results revealed that the EEG frequency bands and activated brain regions that contribute to cognitive load differed depending on the learning state. We concluded that cognitive load during multimedia learning can be assessed using feature extraction and measures of effective connectivity (PDC)."
  },
  {
    "year": "2017",
    "abstract": "The ambient backscatter technique is a communication technology that uses ambient radio frequency signals to enable battery-free devices to communicate with other device. This paper proposes the ambient backscatter technique using multiple antennas. Since the tag only plays a role of reflecting signals, a signal is transmitted with a power allocation in the case of multiple antennas. At the receiving end, the higher power signal is detected first via the received signal. Next, signal from other antenna is detected by using the first detected signal. Since the backscatter technique generally uses energy detection, it has a low data rate using a single antenna. The proposed method can obtain a higher data rate than conventional methods by using multiple antennas. Also, it can be usefully used for the Internet of Things system, which requires high data rate through the proposed backscatter method."
  },
  {
    "year": "2017",
    "abstract": "Taxi drivers always look for strategies to locate passengers quickly and therefore increase their profit margin. In reality, the passenger seeking strategies are mostly empirical and substantially vary among taxi drivers. From the history taxi data, the top performing taxi drivers can earn 25% more than the ones with mediocre seeking strategy in the same period of time. A better strategy not only helps taxi drivers earn more with less effort, but also reduce fuel consumption and carbon emissions. It is interesting to examine the influential factors in passenger seeking strategies and find algorithms to guide taxi drivers to passenger hotspots with the right timing. With the abundant availability of history taxicab traces, the existing methods of doing taxi business have been radically changed. This paper focuses on the problem of mining efficient operation strategies from a large-scale history taxi traces collected over one year. Our approach presents generic insights into the dynamics of taxicab services with the objective of maximizing the profit margins for the concerned parties. We propose important metrics, such as trip frequency, hot spots, and taxi mileage, and provide valuable insights toward more efficient operation strategies. We analyze these metrics using techniques, such as Newton's polynomial interpolation and Gamma distribution, to understand their dynamics. Our strategies use the real taxicab traces from the city of Changsha (P.R.China), may predict the taxi rides at different times by 90.68% per day, and increase the taxi drivers income levels up to 19.38% by controlling appropriate mileage per trip and following the route across more urban hot spots."
  },
  {
    "year": "2017",
    "abstract": "The traditional distributed generation (DG) locating and sizing method is based on a fixed network structure, which is assumed to be unchangeable during the planning period. The flexible distribution network structure is not considered. This paper proposes a novel method for DG locating and sizing in active distribution network (ADN), which mixes DG locating and sizing problem and distribution network reconfiguration problem together. The objective is to minimize the total costs of the distribution network in the planning period. DG locating and sizing considering network reconfiguration is a complex mixed-integer non-linear programming problem. This paper convert the dual-level planning model to the second-order cone programming model, which can be solved with commercial solver GUROBI. The proposed model and method are testified with the modified IEEE 33-bus system."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad-hoc NETworks (VANETs) have received considerable attention in recent years, due to its unique characteristics, which are different from mobile ad-hoc NETworks, such as rapid topology change, frequent link failure, and high vehicle mobility. The main drawback of VANETs network is the network instability, which yields to reduce the network efficiency. In this paper, we propose three algorithms: cluster-based life-time routing (CBLTR) protocol, Intersection dynamic VANET routing (IDVR) protocol, and control overhead reduction algorithm (CORA). The CBLTR protocol aims to increase the route stability and average throughput in a bidirectional segment scenario. The cluster heads (CHs) are selected based on maximum lifetime among all vehicles that are located within each cluster. The IDVR protocol aims to increase the route stability and average throughput, and to reduce end-to-end delay in a grid topology. The elected intersection CH receives a set of candidate shortest routes (SCSR) closed to the desired destination from the software defined network. The IDVR protocol selects the optimal route based on its current location, destination location, and the maximum of the minimum average throughput of SCSR. Finally, the CORA algorithm aims to reduce the control overhead messages in the clusters by developing a new mechanism to calculate the optimal numbers of the control overhead messages between the cluster members and the CH. We used SUMO traffic generator simulators and MATLAB to evaluate the performance of our proposed protocols. These protocols significantly outperform many protocols mentioned in the literature, in terms of many parameters."
  },
  {
    "year": "2017",
    "abstract": "With the tremendous growth of cloud computing and Internet-scale online services, massive geographically distributed infrastructures have been deployed to meet the increasing demand, resulting in significant monetary expenditure and environmental pollution caused by energy consumption. In this paper, we investigate how to minimize the long-term energy cost of dynamic Internet-scale systems by fully exploiting the energy efficiency in geographic diversity and variation over time. To this end, we formulate a stochastic optimization problem by considering the fundamental uncertainties of Internet-scale systems, such as the dynamic data. We develop a dynamic request mapping algorithm to solve the formulated problem, which balances the tradeoff between energy cost and delay performance. Our designed algorithm makes real-time decisions based on current queue backlogs and system states, and does not require any knowledge of stochastic job arrivals and service rates caused by dynamic data queries. We formally prove the optimality of our approach. Extensive trace-driven simulations verify our theoretical analysis and demonstrate that our algorithm outperforms the baseline strategies with respect to system cost, queue backlogs, and delay."
  },
  {
    "year": "2017",
    "abstract": "We propose a spectrally efficient design that guarantees the statistical delay quality-ofservice (QoS) for delay-sensitive traffic in the downlink of orthogonal frequency-division multiple-access (OFDMA) networks. This design is based on the so-called effective capacity (EC) concept, which describes the maximum throughput, a system can achieve under a specific statistical delay-QoS violation probability constraint. We investigate the EC maximization problem, in which, the statistical delay profile of the traffic is characterized by the QoS-exponent θ determining the exponential decay rate of the delay-QoS violation probability. By exploiting the properties of concave programming and Slater's condition, the Lagrangian dual decomposition method is applied and an iterative algorithm that does not depend on the instantaneous channel state information (CSI) is proposed for solving the concave problem formulated. Extensive simulations demonstrate the efficacy and robustness of the proposed iterative algorithm. Furthermore, we show that the system's achievable EC does not depend on the specific choice of the subcarrier allocation, but rather on the number of subcarriers allocated to each user. This is, because, the EC is calculated using the channel's statistics, instead of the instantaneous CSI, implying that the EC is more of a long term channel capacity metric."
  },
  {
    "year": "2017",
    "abstract": "For modern enterprises and organizations, new business workflow can be constructed by reusing already available similar workflows in the repository. Workflow reuse is an important method for implementing business workflow management. Semantic workflows contain control-flow, data-flow, and semantic information relevant to a domain, which facilitates workflow reuse and adaptation. A similarity metric for semantic workflows is important for achieving workflow reuse. However, the existing similarity metrics for semantic workflows focus on workflow structures while ignoring their behaviours, which affect the quality of retrieved similar semantic workflows. Therefore, this paper proposes a behavioral similarity metric for semantic workflows based on semantic task adjacency relations with importance (ISTARs) that incorporate domain knowledge. First, ISTARs that involve semantic tasks and importance of semantic task adjacency relations are defined, and the ISTARs set is used to express the behaviour of the semantic workflow. The ISTAR similarity proposal is based on the similarity between two ISTARs sets and represents the similarity between semantic workflows. The ISTAR distance deduced from ISTAR similarity satisfies the properties of distance metrics. An experimental evaluation revealed that the proposed ISTAR similarity resulted in more effective retrieval of similar semantic workflows than did existing popular behavioral similarity measures."
  },
  {
    "year": "2017",
    "abstract": "This study proposes an accurate mathematical model and a novel decoupling scheme for developing a 5-degrees-of-freedom rotor system of a wind turbine with high robustness, fast response and good-tracking properties. The proposed scheme incorporates neural network generalized inverse (NNGI) control and five model reference adaptive (MRA) controllers. The decoupled open-loop generalized pseudo-linear system can be established by placing the NNGI system in front of the original system. The MRA controllers are utilized to design a closed-loop controller to improve the robustness and anti-disturbance ability of the entire rigid rotor system. The effectiveness of the proposed control scheme is demonstrated via simulation and experimental results for various operations."
  },
  {
    "year": "2017",
    "abstract": "The active vector effects on torque and flux linkage are different in interior permanent magnet synchronous motor (IPMSM) systems at different times under direct torque control (DTC). These different effects may cause overcompensation or undercompensation to torque and flux linkage leading to large torque and flux linkage ripples in the IPMSM DTC systems. A novel duty ratio modulation strategy for the IPMSM DTC systems is presented, which considers these differences that are ignored in conventional duty ratio modulation strategies. The proposed duty ratio modulation strategy aims at minimizing torque ripple and flux linkage ripple, which makes sure that the control system can work in an optimum state. The active angle, the impact angle, the active factor, and the impact factor are first introduced. The active angel and the impact angle are used to get the active factor and the impact factor, respectively. Every sector is divided into five small sectors based on the impact angels, and then, a switching table is redesigned according to the small sectors division. Also, the vector selection rules for the redesigned switching table are described in details. Subsequently, an optimal duty ratio can be derived through the simplified duty ratio determination method. Finally, the effectiveness of the proposed novel modulation strategy is verified through the experimental results on a 100-W IPMSM drive system."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the fault detection problem is considered for a class of discrete-time systems with fault signal happening randomly. First, the random occurrence of fault is described by a Markov approach, which is transformed into some matrices experiencing Markov switchings. By using a fault detection filter as a residual generator, the fault detection and isolation (FDI) problem is transformed into an H∞filtering problem. Moreover, a mode-dependent Lyapunov functional is exploited to make its analysis and synthesis and is also named to be a fault-dependent approach. Then, sufficient conditions on the existence of an FDI filter are all provided in terms of linear matrix inequalities, in which two general cases about transition probability matrix are included. Finally, a practical example is used to illustrate the effectiveness and potential application of the developed theoretical results."
  },
  {
    "year": "2017",
    "abstract": "The dynamic output-feedback control problem is addressed for a class of nonlinear discrete uncertain systems with multiple time-delays. First, the system is decomposed into two subsystems based on the output and input matrix. Second, the compensator is designed for first the subsystem, and the output feedback controller is designed based on the second subsystem and compensator. Then, by choosing a Lyapunov–Krasovskii functional, we show that the developed controller makes the solutions of the closed-loop system exponentially convergent to a ball. Compared with previous work, the developed controller only depends on the system output. The design conditions of the controller are relaxed because of the proposed dynamic compensator. Furthermore, the results are extended to a general nonlinear system and a robot system. Finally, numerical examples are included to show the effectiveness of the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "Wireless nanosensor networks (WNSNs) consist of nano-sized communication devices, which are equipped with nano-transceivers, nano-antennas, and other functional modules. A nanosensor is an integrated device that ranges from 10 to 100 μm2in size. Due to the limited communication capabilities of WNSNs, existing localization algorithms and protocols for wireless sensor networks (WSNs) are no longer applicable to WNSNs. This paper proposes a pulse-based distance accumulation (PBDA) localization algorithm for WNSNs that can be utilized to estimate the distance between nodes with known positions and nodes with unknown positions. The algorithm adopts femtosecond-long pulse for terahertz band communication based on ON-OFF keying (OOK) modulation. A clustering algorithm is first employed to reduce the energy consumption and time delay, then the nano-device analyzes the value of the received pulse based on the OOK modulation and estimates the distance between nodes. MATLAB simulations are implemented to verify the performance of PBDA by comparing it against the flooding-based hop-counting algorithm and cluster based hop-counting algorithm in terms of estimated distance accuracy, energy consumption, and time delay. The trilateral positioning method is also utilized to compare the localization error of PBDA with that of distance vector (DV)-hop. The results show that PBDA is able to support WNSNs with very high density in ranging and locating."
  },
  {
    "year": "2017",
    "abstract": "Industrial control systems are distributed hierarchical networks that share information via an assortment of communication protocols. Such systems are vulnerable to attacks that can cause disastrous consequences. This article focuses on time delay switch (TDS) attacks and shows that cryptographic solutions are ineffective in recovering from the denial of service component of TDS attacks. Therefore, a cryptography-free TDS recovery (CF-TDSR) communication protocol enhancement is developed that leverages adaptive channel redundancy techniques and a novel state estimator, to detect and recover from the destabilizing effects of TDS attacks. Simulation results are conducted to prove that CF-TDSR ensures the control stability of linear time invariant systems and to show the efficacy of CF-TDSR against attacks deployed on multi-area load frequency control components of a distributed power grid."
  },
  {
    "year": "2017",
    "abstract": "Moore's law is expected to lead to the gates of the quantum world in 2017. Therefore, the emerging quantum computing research is expected to give rise to novel quantum search algorithms, which may replace the currently used classical ones in wireless communications, leading to performance improvements and complexity reduction. In this paper, we demonstrate the benefits of quantum-assisted multi-user detection (QMUD) in the uplink of a multi-user system, where the reference user conveys a multilayered video stream to the base station, while using adaptive modulation and different rates per video layer. This is the first study, where a QMUD is employed in a video application. The QMUD does not treat the rest of the users as interference, but rather detects the signals transmitted by all the users. We have evaluated the system's performance both in terms of its bit error ratio and peak signal-to-noise ratio versus the channel's signal-to-noise ratio, while quantifying the complexity reduction achieved by using the QMUD instead of the optimal classical maximum a posteriori probability MUD. The effect of the number of users on the system's performance is also quantified."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel differential directional filter bank (DFB) decomposition-based video coding scheme. DFB decomposition is generally preceded by Laplacian pyramid decomposition, as in contourlet transform, in order to separate the high pass content from an image or a video frame. This leads to redundant representation in the transform domain. In the proposed work, increase in redundancy due to contourlet transform is compensated by the application of DFB decomposition directly to the difference between motion compensated consecutive frames, called residual frames, which capture temporal discontinuities in a video. Low-complexity adaptive rood pattern search scheme is used for motion-estimation and tiled version of set partitioning embedded block coder is proposed which reduces the encoding time. The proposed compression scheme is implemented in CIE La*b* color space to exploit its advantages like; linearity and perceptual uniformity. The proposed low complexity sequential video coding scheme achieves, on an average, 0.71 dB more PSNR than H.264 while requiring up to 17.6% less encoding time compared with the H.264 baseline encoder on standard test video sequences."
  },
  {
    "year": "2017",
    "abstract": "To meet the current cellular capacity demands, proactive offloading is required in heterogeneous cellular networks (HetCNets) comprising of different tiers of base stations (BSs), e.g., small-cell BSs (sBSs) and conventional macro-cell BSs (mBSs). Each tier differs from the others in terms of BS transmit power, spatial density, and association bias. Consequently, the coverage range of each tier BSs is also different from others. Due to low transmit power, a fewer number of users are associated to an sBS as compared with mBS. Thus, inefficient utilization of small-cell resources occurs. To balance the load across the network, it is necessary to push users to the underloaded small cells from the overloaded macro-cells. In co-channel deployed HetCNets, mBSs cause heavy inter-cell interference (ICI) to the offloaded users, which significantly affects the network performance gain. To address this issue, we develop a tractable analytical network model abating ICI using reverse frequency allocation (RFA) scheme along with cell range expansion-based user association. We probabilistically characterize coverage probability and user rate while considering RFA with and without selective sBS deployment. Our results demonstrate that selective sBS deployment outperforms other deployment methods."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the problem of transient events in model-based observers for dynamic positioning of marine surface vessels. Traditionally, model-based observers experience a deterioration of performance during transients, and there is a give or take relationship between transient and steady state performance. To remedy this problem, we propose to use time-varying gains for a model-based observer. The gains are aggressive during transients to improve transient performance, and relaxed in steady state to lower the oscillations of the estimates. The proposed observer is analyzed with regard to stability. Its performance is verified in both a high-fidelity simulation model, and on experimental data with the research vessel (R/V) Gunnerus. In addition, a partial closed-loop validation with R/V Gunnerus has been performed."
  },
  {
    "year": "2017",
    "abstract": "Energy harvesting techniques are promising in next generation wireless communication systems. However, most of the existing works are based on an ideal linear energy harvesting model. In this paper, a multiple-input single-output cognitive radio network is studied under a practical non-linear energy harvesting model. In order to improve the security of both the primary network and the secondary network, a cooperative jamming scheme is proposed. A robust artificial noise aided beamforming design problem is formulated under the bounded channel state information error model. The formulated problem is non-convex and challenging to be solved. Using S-Procedure and the semidefinite relaxation method, a suboptimal beamforming can be obtained. Simulation results show that the performance achieved under the non-linear energy harvesting model may be better than that obtained under the linear energy harvesting model. It is also shown that the cooperation between the primary network and the secondary network can obtain a performance gain compared with that without this cooperation."
  },
  {
    "year": "2017",
    "abstract": "A load balancing mechanism can adjust the load distribution among access points (APs) and improve resource utilization for dense wireless local area networks (WLANs). In this paper, we propose a semi-matching-based load balancing scheme for the IEEE 802.11 dense WLANs. The proposed scheme runs in a centralized controller. The controller judges whether the load is unevenly distributed according to the collected channel busy time ratio information of the entire network, and triggers the load balancing mechanism accordingly. In order to realize load balancing among APs and maximize the overall network throughput, we model the station to AP association problem as a weighted bipartite graph matching problem and find the optimal semi-matching using the Kuhn-Munkres (K-M) algorithm. Simulation results show that the proposed scheme achieves performance improvement comparing with traditional schemes."
  },
  {
    "year": "2017",
    "abstract": "This paper represents a twofold approach. On the one hand, we introduce a simple method that encompasses an ensemble of image processing algorithms with a multilevel color transfer approach at its core. On the other hand, the method is applied for providing an artistic look to standard images. The approach proposes a multilevel color transfer in a chromatic channel of the CIELAB color space. Once converted from red, green and blue, a specific channel on both images, input and target (reference), is thresholded in a number of levels. Later, the color transfer is performed between regions from corresponding levels using a classical color transfer method. In the application phase, the color palette of a recognized artwork of the Fauve movement is mapped to the input image, emulating the sight of the artist, characterized by the use of vivid colors. Filtering techniques are applied to the outcome, in order to emulate the basic brushstrokes of the artist. Experimental results are shown, visualizing and comparing the input images with the outcomes."
  },
  {
    "year": "2017",
    "abstract": "Power quality (PQ) has received the attention of several research groups due to the impact of PQ disturbances (PQDs) and how they affect the operation of the electrical equipment connected to the grid, especially in industrial and healthcare facilities. The monitoring and analysis of PQD are generally performed with specialized measuring equipment, such as power analyzers, based on the standards. However, this equipment is not suited to perform continuous monitoring and classification of PQD, and it cannot be configured to perform further analysis of the monitored signal. Smart sensors, on the other hand, can provide the functionality that the standard equipment cannot, by integrating several signal processing modules that can be reconfigured using a reconfigurable technology, such as field programmable gate arrays (FPGAs). This paper presents the development of an FPGA-based smart sensor that integrates the processing cores of higher order statistics (HOS) to provide a signal analysis aimed to detect and quantify PQD on electrical installations and an artificial neural network to classify the PQD. Experimentation is performed on the electrical installation in hospital facilities. Results from the HOS processing of electrical signals show that these processing methodologies are suitable for the quantification and classification of PQD on electrical installations."
  },
  {
    "year": "2017",
    "abstract": "Recently, the Internet of Things (IoT) has attracted the interest of network researchers all over the world. Multimedia transmission through IoT presents an important challenge owing to nodes diversity. In this paper, adaptive versions of the real-time transport protocol (RTP) and real-time control protocol (RTCP), i.e., IoT-RTP and IoT-RTCP, are proposed. In these versions, the nature of IoT environments, such as transmission channels heterogeneity, sudden change in session size, and different multimedia sources, is considered. The basic idea of the proposed adaptive versions is to divide the large multimedia sessions into simple sessions with awareness of network status. To achieve this target, additional fields are added to the RTP and RTCP headers. These fields work under certain conditions to decrease the network overload. Finally, to test the performance of the proposed IoT-RTP and IoT-RTCP, a simulation environment is constructed using the network simulation package (NS2).The results of intensive simulations proved that the proposed adaptive versions of the multimedia protocols outperform the basic ones in terms of end-to-end delay, delay jitter, number of receiver reports, packet loss, throughput, and energy consumption."
  },
  {
    "year": "2017",
    "abstract": "For frequency diverse array (FDA) range-angle-dependent beampattern synthesis, the objective is to obtain the desired beampattern performance using fewer antenna elements or smaller aperture. This paper proposes a FDA single-beam pattern synthesis by joint I1-norm minimization and convex optimization in the beginning. A virtual uniform FDA array with small element spacing and corresponding frequency increment is created first. Then, we formulate the array pattern synthesis (APS) problem as finding a joint sparse weight vector, which can be obtained by solving a convex optimization problem with the joint sparse constraint between angle dimension weight vector and range dimension weight vector, where some small entries of the vector can be regarded as zeros without significantly changing the array pattern performance. The antenna elements corresponding to the mapping positions of nonzero values of the joint sparse weight vector are placed to form a non-uniform FDA. Finally, convex optimization is further conducted to obtain the optimal weight vector of the non-uniform FDA. Besides, we expand the idea to FDA multi-beam pattern synthesis based on the convex optimization problem with joint sparse constraint between angle dimension weight matrix and range dimension weight matrix. Numerical examples are provided to verify the efficiency of achieving the desired radiation pattern with the fewer antenna elements, and better APS performance for given array elements."
  },
  {
    "year": "2017",
    "abstract": "Latin hypercube sampling (LHS) method has difficulty in dealing with non-positive definite correlation matrices by traditional Cholesky decomposition, whereas it may often happen with the increasing scale of input variables. In order to improve the numerical stability of LHS, an improved LHS with modified alternating projections method (L-Mapm) is proposed in this paper. Compared with other two existing modified algorithms, L-Mapm is considered to possess accuracy, speediness, and controllability at the same time. The accuracy and effectiveness of L-Mapm applied to probabilistic load flow are proven by the comparative tests in the IEEE 33-bus system and PG&E 69-bus system. The simulation results show that L-Mapm has the best performance in modification and expands the application of LHS."
  },
  {
    "year": "2017",
    "abstract": "Industry 4.0 can be said to be the current trend of automation and data exchange in manufacturing technologies. Originally, the term “Industrie 4.0” is from a project in the high-tech strategy of the German government, which hope to promote the computerization of manufacturing. Usually involves terms like cyber-physical systems, Internet of things, amd cloud computing. For now, Industry 4.0 becomes an emerging buzzword that is gaining significant interest among all stakeholders of the global industry-related R&D market from academia to international companies. It is a new business model attracting much interest, yet the definitions are not very matured and is an amazing melting pot of disruptive technologies. No doubt, to maximize the impact of Industry 4.0, researchers from different fields and industry have to work together applying the new technologies in practice. On the top of the wave, it is timely to analyze the cross section who can benefit from the novel achievements of Industry 4.0."
  },
  {
    "year": "2017",
    "abstract": "Zinc is an important trace element, and it can be used in combination with proteins to play an important biological function. In this paper, three types of prediction tools based on sequence were studied for the prediction of zinc-binding sites in proteins, and a novel integrated predictor termed meta-zincPrediction is presented. Multiple linear regressions were used in the proposed approach to integrate the results of the three prediction tools, and the parameters were estimated by the least square method until the optimal model was constructed. Using the Zhao_dataset data set, the area under recall-precision curve (AURPC) of our predictor reached nearly 0.9 and increased by 2%-9% compared with the other three predictors; the other performance indexes were also improved. To further demonstrate the robustness and accuracy of the integrated predictor, we tested it on a non-redundant independent test dataset (CollectedDataset). The AURPC increased by 2%-8%. The other three indexes, including the precision, specificity, and MCC, were increased by 5%-8%, 2%-8%, and 4%-12%, respectively, with a recall of 70%. The prediction ability of the meta-zincPrediction was better than the other three predictors, regardless of whether the zinc-binding sites contained four types of residues or a single residue. Our method can be applied to the recognition of zinc binding sites based on sequence information, but will also be useful for inferring protein function and more propitious for the treatment of some diseases."
  },
  {
    "year": "2017",
    "abstract": "In the template matching of finger vein recognition, the probe will be accepted if the number of its overlapped vein points with the enrolled user is larger than the predefined threshold. However, the acceptance may be false owing to ignoring the structure of the vein pattern. We find that local vein branches near the bifurcation point of vein pattern vary largely between the imposter images. So, this paper tries to explore this kind of local vein structure to improve the recognition performance of the template matching. The bifurcation point and its local vein branches, named tri-branch vein structure, are extracted from the vein pattern, and fused with the whole vein pattern by a user-specific threshold-based filter framework. The experimental results on two public databases prove the effectiveness of the proposed framework for improving the performance of vein pattern-based finger vein recognition."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a novel interactive cutting simulation model for soft tissue based on the meshless framework. Unlike most existing methods that consider the cutting process of soft tissue in an over simplified manner, the presented model is able to simulate the complete cutting process that includes three stages: deformation before cutting open, cutting open, and deformation after cutting open. To characterize the complicated physical and mechanical properties of soft tissue, both nonlinearity and viscoelasticity were incorporated into the equations governing the motion of soft tissue. A line contact model was used for simulating the cutting process after analyzing the two major types of surgical instruments, i.e., scalpel and electrostick. The cutting speed and angle were taken into account in order to improve haptic rendering. Biomechanical tests and simulation experiments verified the validity of the introduced model. Specifically, the displacement versus cutting force curves can be divided into three segments corresponding to the three stages of the cutting process. The results were also applied in a liver cutting simulating system and satisfactory visual effect and haptic feedback were achieved."
  },
  {
    "year": "2017",
    "abstract": "In wireless sensor networks, secure MAX/MIN query processing is a challenging issue, and it is useful in fields, where security is necessary. In this paper, we propose a secure MAX/MIN query processing method in two-tiered wireless sensor networks. To the best of our knowledge, it is the first work that can achieve data privacy protection and query result integrity verification simultaneously. Three schemes, naïve secure MAX/MIN query (NSMQ), complicated secure MAX/MIN query (CSMQ), and OSMQ, are designed to achieve secure MAX/MIN queries. In NSMQ, we present an intuitive and baseline solution that makes the master nodes return all the ciphertext as the query result. However, it may incur high query communication cost. To address this limitation, a CSMQ scheme is designed, which introduces the comparable factors (c-factors) based on 0-1 encoding verification to find the accurate encrypted query result from the stored ciphertext of the master nodes even when their real values are unknown. Then, a broadcasting method is introduced to generate minor-node-sets as the proofs for verifying the integrity of the query results. CSMQ can significantly reduce the query communication cost, but its in-cell communication cost is high because of the extra data submission and broadcasting. To balance the in-cell and query communication cost, OSMQ, as an optimized version of CSMQ, is proposed to address the minor-node-set compression and random c-factor selection. The proposed schemes are built upon symmetric encryption and hash-based message authentication coding primitives. OSMQ can prevent compromised master nodes from obtaining the plaintext of private data and force them to return integrity-satisfying query results to avoid being detected. Extensive theoretical and experimental studies have been conducted to demonstrate the efficacy and efficiency of the proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "The use of light emitting diode reflective distance sensors (LED-RDS) for high-resolution displacement measurement is a cost-effective and inherently safe alternative to sensors using lasers and optical fibers. Experimental testing shows that a variety of distance ranges are achievable depending on the geometry of the LED-RDS chosen. The use of an LED-RDS without focusing lens offers higher resolution, making it suited to measure displacements in the micrometer range. Results from testing the SFH9206 on a target with a modest reflectivity of 31% indicate that the LED-RDS offers sensitivity of 52.8 %/mm, over a linear range of 540 μm. With a focus on LED-RDS with GaAs-based LEDs, thermal drift of the sensors is theoretically modeled and compensation circuitry proposed. Results for the SFH9206 show the thermal drift to be linear, and the compensation circuitry effective, between 25 °C and 35 °C. As a consequence, at room temperatures, the compensation circuitry also reduces the noise, as measured by the Allan deviation and standard deviation. With a 3-dB bandwidth of 5.56 Hz, the compensation circuitry gives an LED-RDS signal with resolution below 1 μm. LED-RDS are mass produced and primarily find their application as source/detectors in encoders and barcodes scanners and as position sensitive devices in mobile robots. This paper suggests that LED-RDS also have the potential for analogue displacement measurements at high resolution."
  },
  {
    "year": "2017",
    "abstract": "The multi-homed mobile devices in the mobile cloud computing (MCC) systems can improve their throughput by allocating the application data over several paths simultaneously, enabled by the promising Multipath TCP (MPTCP) technology. Meanwhile, network attacks against current Internet infrastructures are likely to increase, especially with the widely deployment of MCC systems. When a MPTCP connection is under network attacks and becomes a poor-performing path or a broken path, it can significantly affect other stable paths and in the absence of related schemes to handle this, MPTCP will undoubtedly suffer from serious performance degradation. Moreover, applying MPTCP to cloud data delivery may generally lead to higher energy consumption and is not favorable to a power-constrained mobile device. In this paper, we propose MPTCP-La/E2, a low-rate distributed denial-of-service (LDDoS) attack-aware energy-efficient MPTCP solution aiming at: 1) avoiding the LDDoS-caused performance degradation of cloud multipath transmission, which has been seldom considered in existing MPTCP solutions and 2) optimizing the energy usage while still maintaining user's perceived quality of cloud multipathing services. The simulation results show that MPTCP-La/E2outperforms the baseline MPTCP in terms of QoS and energy-savings in a multihomed MCC network environment."
  },
  {
    "year": "2017",
    "abstract": "A two-way bus corridor system always suffers severe demand imbalance between their two operational directions during the peak hours. This paper intends to minimize the average passenger travel time by applying the A/B skip-stop strategy in such an imbalance situation. This strategy defined three types of stations: A, B, and AB. In the service, the buses depart alternately from the original station as type A and B, and A (or B) buses serve A (or B) stations, as well as AB stations. Then the problem becomes determining the skip-stop patterns for both directions. A heuristic genetic algorithm is adopted to solve this problem with a kernel of a precise simulation model depicting the bus system. Finally, we apply the optimization method to a realistic bus corridor of BRT line 1 in Beijing, China. Results demonstrate that the bidirectional A/B skip-stop service prevails over the unidirectional services applying A/B skip-stop only on one direction, and the common used regular service visiting all stations. It is certificated that the bidirectional skip-stop service reduces bus bunching, yields a more balanced bus load and provides a smooth bus service with lower cycle time and variability. Moreover, a sensitivity analysis is conducted to show the impacts of some key attributes on potential benefits of bidirectional skip-stop service. Finally, the elastic demand case where transferring passengers may change their origins or destinations has been discussed."
  },
  {
    "year": "2017",
    "abstract": "Faster-than-Nyquist (FTN) signaling is a promising non-orthogonal transmission technique to considerably improve the spectral efficiency. This paper presents the first attempt in the literature to estimate the transmit data symbols of any high-order quadrature amplitude modulation (QAM) FTN signaling in polynomial time complexity. In particular, we propose a generalized approach to model the finite alphabet of any high-order QAM constellation as a high degree polynomial constraint. Then, we formulate the high-order QAM FTN signaling sequence estimation problem as a non-convex optimization problem. As an example of a high-order QAM, we consider 16-QAM FTN signaling and then transform the high degree polynomial constraint, with the help of auxiliary variables, to multiple quadratic constraints. Such transformation allows us to propose a generalized approach semidefinite relaxation (SDR)-based sequence estimation (GASDRSE) technique to efficiently provide a sub-optimal solution to the NP-hard non-convex FTN detection problem, with polynomial time complexity. For the particular case of 16-QAM FTN signaling, we additionally propose a sequence estimation technique based on concepts from the set theory. We show that the set theory SDR-based sequence estimation (STSDRSE) technique is of lower complexity when compared with the proposed GASDRSE. Simulation results show the effectiveness of the proposed GASDRSE and STSDRSE techniques in increasing the data rate and spectral efficiency of 16-QAM FTN signaling, without increasing the bit-error-rate, the bandwidth, or the data symbols energy, when compared with the Nyquist signaling."
  },
  {
    "year": "2017",
    "abstract": "Massive multiple-input multiple-output system can enable multi-stream transmission for high spectrum efficiency, which is a key technology in future 5G cellular networks. In this paper, we degenerate a direction of arrival (DOA) related 2-D weighted subspace fitting function into two independent parameterized 1-D versions. Based on this, we develop a novel 2-D DOA estimation algorithm, which can be utilized to assist in performing downlink precoding. Furthermore, we also make an analysis on the computational complexity and the theoretical Cramér-Rao lower bound. The direct merits are as follows: the proposed algorithm includes only once polynomial rooting and also does not require angle paring, hence it is of computational efficiency; in addition, compared with some existing algorithms, it can achieve higher 2-D angle estimating accuracy. A series of Monte Carlo simulations are subsequently carried out, which demonstrate the effectiveness of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Vehicle-to-everything (V2X) is a form of wireless communication that is extremely sensitive to latency, because the latency is directly related to driving safety. The V2X systems developed so far have been based on the LTE system. However, the conventional LTE system is not able to support the latency requirements of latency-aware V2X. Fortunately, the state-of-the-art cellular technology standard includes the development of latency reduction schemes, such as shortened transmission time intervals (TTI) and selfcontained subframes. This paper verifies and analyzes the latency of cellular-based V2X with shortened TTI, which is one of the most efficient latency reduction schemes. To verify the feasibility of V2X service, we divide the V2X latency into two types of latency, TTI-independent latency and TTI-proportional latency. Moreover, using system-level simulations considering additional overhead from shortened TTI, we evaluate the latency of cellular-based V2X systems. Based on this feasibility verification, we then propose cellularbased V2X system design principles in terms of shortened TTI with only one OFDM symbol and while sustaining radio resource control connection."
  },
  {
    "year": "2017",
    "abstract": "The success of providing smart healthcare services in ambient assisted living (AAL) largely depends on an effective prediction of situations in the environment. Situation awareness in AAL is to determine the environment smartness by perceiving information related to the surroundings and human behavioral changes. In AAL environment, there are plenty of ways to collect data about its inhabitants, such as through cameras, microphones, and other sensors. The collected data are complicated enough to go for an efficient processing in perceiving the situation. This paper gives an overview of the existing research results in multimodal data analysis in AAL environment to improve the living environment of the seniors, and it attempts to bring efficiency in complex event processing for real-time situational awareness. This paper thus considers multimodal sensing for detection of current situations as well as to predict future situations using decision-tree and association analysis algorithms. To illustrate the proposed approach, we consider elderly activity recognition in the AAL environment."
  },
  {
    "year": "2017",
    "abstract": "An embedded real-time indexing engine for live radio stations requires a high-speed parallel advanced audio coding (AAC) decoder architecture to decode hundreds of compressed audio streams broadcast in the digital radio mondiale band. Several AAC hardware core units must be integrated into a single chip and synchronized with a global controller to achieve such high performance. This paper proposes a new parallel AAC decoder architecture to address this challenge. The proposed architecture includes multiple AAC decoder core units, each of which achieves a speed-up by a factor of 2 compared with the existing AAC decoder core units while using optimal logic resources. The proposed architecture overcomes several challenges faced by existing architectures. The Huffman decoder module decodes one word per clock cycle regardless of word length, and a smaller lookup table size is achieved for the inverse quantization module. The inverse modified discrete cosine transform architecture is fully pipelined, and the resource sharing technique is used to reduce the logic area. An initial prototype is implemented on an FPGA platform."
  },
  {
    "year": "2017",
    "abstract": "Due to the increasing potentials and benefits of unmanned aerial vehicles (UAVs) in civil and surveillance applications, the cooperative flight using multiple UAVs has attracted more and more attention. However, fault-tolerant cooperative positioning for malfunctions in global positioning system (GPS) is one of the challenges that need to be addressed in various practical applications of UAVs. Motivated by solving this issue, this paper presents a reliable cooperative positioning approach for multiple UAVs cooperative flight by using the geometric azimuth angle and the inclination angle relative to the reference UAVs. In this proposed cooperative positioning system (COPS), these relative angles are measured through radio direction finding equipped on UAVs. With the horizontal dilution of precision of the various reference UAVs carefully analyzed, the optimal reference UAVs set can be first selected. Based on a constant acceleration kinematic model, an extended Kalman filter is then employed to improve the positioning accuracy. A COPS/GPS faulttolerant navigation algorithm is finally developed to accommodate GPS fault. Simulation results are further presented to verify that the proposed algorithm can guarantee satisfactory navigation of the UAVs even when their GPS cannot work."
  },
  {
    "year": "2017",
    "abstract": "Heterogeneous networks are a promising technology in fifth generation (5G) wireless networks, which has been shown to significantly increase the capacity and coverage compared with the conventional wireless networks. In this paper, we consider the robust multiple-input single-output beamforming design in a two-tier heterogeneous network. By considering the worst case deterministic model, our objective is to maximize the worst case signal-to-interference-plus-noise-ratio in a small cell base station while guaranteeing that its interference to a macro cell user equipment is less than a threshold. Although interesting and attractive, such a problem is non-convex and also essentially involves an infinite number of constraints. Nevertheless, we first transform the problem into an equivalent one which is more tractable and then propose an efficient algorithm to obtain a near optimal solution. Furthermore, we also develop two algorithms that provide an upper bound and a lower bound of the original problem, respectively. Simulation results validate the effectiveness of the proposed algorithms."
  },
  {
    "year": "2017",
    "abstract": "With the ever-increasing demands for popular content sharing among humans, device-to-device (D2D) multicast communication, as a promising technology to support wireless services within a local area, is introduced in a 5G cellular network. However, the existing resource allocation approaches for D2D multicast communication usually consider only physical domain constraints but neglect social domain factors, which would result in ineffective D2D links between users unwilling to share interests. Different from existing works, the D2D multicast scheme proposed in this paper will produce effective D2D multicast links by sufficiently utilizing both the physical and social properties of mobile users, with the goal to maximize the throughput of the overall social-aware network and guarantee fairly allocation of the channel between different D2D multicast clusters. The scheme mainly consists of two parts, the formation of D2D multicast clusters and joint optimization of power and channel allocation. In the formation of D2D multicast clusters, members and head in each cluster are selected by taking into account both social attributes and physical factors, such as community, ties, and geographical closeness. In the joint optimization, a two-step scheme is designed to first calculate the optimal power allocation by geometric proximity and then select suitable cellular channels for each D2D multicast cluster utilizing an extended one-to-many bipartite graphs matching algorithm. Simulation results demonstrate that, compared with heuristic algorithm and stochastic algorithm, the proposed scheme can increase the throughput of the overall social-aware network by about 5% and 50%, respectively."
  },
  {
    "year": "2017",
    "abstract": "In multihop wireless networks, data packets are forwarded from a source node to a destination node through intermediate relay nodes. With half-duplex relay nodes, the end-to-end delay performance of a multihop network degrades as the number of hops increases, because the relay nodes cannot receive and transmit at the same time. Full-duplex relay nodes can reduce their per-hop delay by starting to forward a packet before the whole packet is received. In this paper, we propose a pipelined medium access control (PiMAC) protocol, which enables the relay nodes on a multihop path to simultaneously transmit and receive packets for full-duplex forwarding. For pipelined transmission over a multihop path, it is important to suppress both the self-interference of each relay node with the full-duplex capability and the intra-flow interference from the next relay nodes on the same path. In the PiMAC protocol, each relay node can suppress both the self- and intra-flow interference for full-duplex relaying on the multihop path by estimating the channel coefficients and delays of the interference during a multihop channel acquisition phase. To evaluate the performance of the PiMAC protocol, we carried out extensive simulations and software-defined radio-based experiments."
  },
  {
    "year": "2017",
    "abstract": "Multidimensional magnetic resonance spectroscopy (MRS) serves as a valuable tool to analyze metabolites in medical imaging, complex chemical compounds in the chemistry, and protein structures in biology. The data acquisition time, however, is relatively long because it increases exponentially with dimensions. Non-uniform sampling is an effective way to accelerate the data acquisition and a proper reconstruction method is necessary to obtain a full spectra of high quality. A state-of-the-art low-rank Hankel matrix method has shown a great ability to reconstruct the low intensity broad peaks and increase the effective sensitivity of the reconstructed spectra. However, this technology faces the challenge of slow computation time because minimizing the rankness encounters the time-consuming singular value decomposition in the iterative algorithm. This heavily prohibits the method from processing higher dimensional MRS. In this paper, a low-rank matrix factorization method that avoids singular value decomposition is introduced to enable fast MRS reconstruction without sacrificing the spectra quality. Combined with a designed parallel computing architecture, the proposed approach can speed up the computation of low-rank approach with a factor up to 150 and enables reconstructing the challenging 3-D MRS within 15 minutes."
  },
  {
    "year": "2017",
    "abstract": "The past two decades have seen significant advances in learning-related technologies, with the attendant recognition (and expectation) of their impact on the higher education system. Many new teaching methods can now be employed and their efficacy and scalability studied. In parallel, the demand for Electrical and Computer Engineering (ECE) education continues to grow world-wide, as an increasing world population seeks educational opportunities. There is now a growing acknowledgement that technical education must be complemented with skills for professional success such as design, leadership, communication, understanding historical and contemporary social contexts, lifelong learning, creativity, entrepreneurship, and teamwork. It is also widely accepted that solving today’s major challenges requires a multidisciplinary approach. The time is ripe for large-scale experimentation and adoption of possibly revolutionary changes in ECE education."
  },
  {
    "year": "2017",
    "abstract": "Massive MIMO (MaMI) is often promoted as a technology that will enable the use of low-quality, cheap hardware. One particular component that has been in the focus of MaMI-related research is the analog-to-digital converter (ADC), and use of very low-resolution ADCs has been proposed. However, studies about whether this strategy is justified from an energy-efficiency point of view have largely been inconclusive. In this paper, we choose system setup and models that reflect the hardware implementation reality as close as possible and perform a parametric analysis of uplink energy efficiency as a function of ADC resolution. If antenna scaling and decrease of ADC resolution are considered independently, the energy efficiency is shown to be maximized at intermediate ADC resolutions, typically in the range of 4-8 bits. Moreover, optimal ADC resolution does not decrease when more antennas are used except in some specific cases, and when it does, the decrease is approximately logarithmic in the number of antennas. In the case when antenna scaling and ADC degradation are coupled through a constant-performance constraint, it is shown that energy efficiency cannot improve with reduced bit resolution unless the power consumption of blocks other than ADCs scales down with the upscaling of antennas at a fast enough rate. Altogether it is concluded that in MaMI, intermediate ADC resolutions are optimal in energy efficiency sense, and, except in some special cases, scaling up the antennas to very large numbers does not change this conclusion."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study transmission strategies for hybrid free space optical (FSO)/radio frequency (RF) systems by jointly considering link selection, power allocation, and reliability guarantees. Specifically, under an explicit long-term average reliability requirement, the transmitter in the hybrid FSO/RF system makes decisions about which links should be selected and how much power should be allocated to the corresponding active link. The problem of minimizing the power consumption cost while guaranteeing packet success-probability requirements and peak and average power constraints is considered and formulated as a stochastic problem. Using the Lyapunov optimization techniques, we solve this problem and derive closed-form power allocation solutions for different link selection modes. Furthermore, we design a dynamic link selection and power allocation algorithm that can arbitrarily push the consumed power approach to the optimum at the expense of a tradeoff over reliability queue occupancy. Simulation results verify the theoretical analysis and validate the performance superiority of our proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Smart cities are becoming a reality. Various aspects of modern cities are being automated and integrated with information and communication technologies to achieve higher functionality, optimized resources utilization, and management, and improved quality of life for the residents. Smart cities rely heavily on utilizing various software, hardware, and communication technologies to improve the operations in areas, such as healthcare, transportation, energy, education, logistics, and many others, while reducing costs and resources consumption. One of the promising technologies to support such efforts is the Cloud of Things (CoT). CoT provides a platform for linking the cyber parts of a smart city that are executed on the cloud with the physical parts of the smart city, including residents, vehicles, power grids, buildings, water networks, hospitals, and other resources. Another useful technology is Fog Computing, which extends the traditional Cloud Computing paradigm to the edge of the network to enable localized and real-time support for operating-enhanced smart city services. However, proper integration and efficient utilization of CoT and Fog Computing is not an easy task. This paper discusses how the service-oriented middleware (SOM) approach can help resolve some of the challenges of developing and operating smart city services using CoT and Fog Computing. We propose an SOM called SmartCityWare for effective integration and utilization of CoT and Fog Computing. SmartCityWare abstracts services and components involved in smart city applications as services accessible through the service-oriented model. This enhances integration and allows for flexible inclusion and utilization of the various services needed in a smart city application. In addition, we discuss the implementation and experimental issues of SmartCityWare and demonstrate its use through examples of smart city applications."
  },
  {
    "year": "2017",
    "abstract": "We focus on the problem of learning distributed representations for entity search queries, named entities, and their short descriptions. With our representation learning models, the entity search query, named entity, and description can be represented as low-dimensional vectors with minimal human preprocessing. Our goal is to develop a simple but effective model that can make the distributed representations of query-related entities similar to the query representation in the vector space. Hence, we propose three kinds of learning strategies, and the difference between them mainly lies in how to deal with the relationship between an entity and its description. We analyze the strengths and weaknesses of each learning strategy and validate our methods on public data sets, which contain various query types and different languages (i.e., English and Chinese). The experimental results indicate that our proposed methods can adapt to different types of entity search queries, and outperform the current state-of-the-art methods no matter the entity collection is homogeneous or heterogeneous. Besides, the proposed methods can be trained fast and can be easily extended to other similar tasks."
  },
  {
    "year": "2017",
    "abstract": "Fault diagnosis is an important topic both in practice and research. There is intense pressure on industrial systems to continue reducing unscheduled downtime, performance degradation, and safety hazards, which requires detecting and recovering from potential faults as early as possible. From the historical perspective, this paper divides fault diagnosis into previous research and industrial big data era. According to primary drivers, this paper classifies fault diagnosis into knowledge-driven, data-driven, and value-driven methods. Among them, the former two approaches belong to the previous research on fault diagnosis. They mainly depend on expert experience and shallow models to detect and extract failures from relatively small size data. With the continuous exponential growth of data, it is insufficient to mine valuable fault information from massive multi-source heterogeneous data. The huge diagnostic value embodied in industrial big data has driven the emergence of the third category, which belongs to fault diagnosis based on big data. It consists of big data processing and analysis corresponding to high efficiency, cost effectiveness, and generality, which can deal well with problems that previous methods faced. We introduce the concept of a device electrocardiogram from the perspective of applicability to outline the present status of fault diagnosis for big data, and compare it with traditional diagnostic system. We also discuss issues and challenges that need to be further considered. It would be great valuable to integrate or explore more advanced diagnostic methods to handle collected industrial big data and put them into practice to mine the huge hidden diagnostic value."
  },
  {
    "year": "2017",
    "abstract": "Crowdsourcing activities, carrying out large-scale tasks via wisdoms of crowds, are widely used in practice. However, it is hard for users to find tasks that are suitable for them. Thus, many users participate in tasks, and they are not good at or not interested in, and give answers carelessly or randomly. This phenomenon causes heavy astroturfing problem in crowdsourcing systems, which not only hurts the quality of completing tasks, but also influences user experience. Therefore, recommendation mechanisms that can optimize the match between users and tasks are in demand. However, existing studies simply adopt users' expertise level or interest degree as the key rule for recommendation. They neglect the fact that interest and expertise function jointly, and that interest can sometimes exert reaction force on expertise. Besides, previous studies assume that users' interest degree is steady, yet ignoring that it is time-varying rather than static in real world. In this paper, we propose IntexCrowd, fine-grained recommendation mechanism through interest-expertise collaborative awareness for crowdsourcing systems, to curb astroturfing problem. First, the IntexCrowd assigns a topic to each task. Then, topic-specific expertise level as well as interest degree of users are estimated according to historical records of tasks. At last, suitable user lists for topic-specific tasks are suggested as recommendation results. And we present a case study and a set of experiments to confirm the validity of IntexCrowd."
  },
  {
    "year": "2017",
    "abstract": "The skyline is a piece of important reference information in the automatic flight control system of an unmanned vehicle. Currently, most skyline detection algorithms assume that the skyline has distinct edge features that can be located in the image by edge detection. This method of detection, however, is only applicable when the skyline is obvious. Its detection result in images with an indistinct skyline is affected by the threshold value, such as on cloudy or heavily foggy days, when clear skyline features cannot be found. To find both distinct and indistinct skylines in the images, this paper proposes a vision-based skyline detection algorithm, in which the skyline is located by analyzing image brightness variations. This method is able to identify nonlinear skyline profiles in scenes with a clear skyline, and find the interface region between the sky and earth in scenes with an indistinct skyline, to estimate its location. According to the experimental results, the algorithm correctly finds the skyline profile in 97% of the test images, making it ideal to provide skyline reference information for the automatic flight control systems of unmanned vehicles."
  },
  {
    "year": "2017",
    "abstract": "The kernel minimum square error classification (KMSEC) algorithm has been widely used in classification problems. It shows a good performance on image data besides the following drawbacks: not sparse in the solutions and sensitive to noises. The latter drawback will result in a decrease in the recognition performance. To this end, we propose an improved (IKMSEC) by using the L2,1-norm regularization, which can obtain a sparse representation of nonlinear features to guarantee an efficient classification performance. The comprehensive experiments show the promising results in face recognition and image"
  },
  {
    "year": "2017",
    "abstract": "Power line communication (PLC) has enabled many smart grid applications and functionalities over the past few years. Secure communications over such links however remain a crucial aspect for further development. Due to their shared nature, akin to wireless, PLC channels can benefit from many wirelesstype security techniques, including physical layer security. To this end, and in contrast to existing studies, which focus on non-cooperative PLC systems, this paper considers the application of physical layer security in cooperative PLC networks in the presence of passive eavesdropping. We analyze the performance of such systems using log-normal correlated channel models considering background and impulsive noise components. Furthermore, the impact of PLC/wireless coding diversity on the system secrecy capacity is evaluated. The results include accurate mathematical expressions for providing an insight into the secrecy capacity and outage probability performance of such systems under various network scenarios."
  },
  {
    "year": "2017",
    "abstract": "With the rapid development of smart phones and wireless technology, mobile services and applications in the world are growing rapidly. Advanced mobile computing and communications greatly enhance users’ experience by the notion of “carrying small while enjoying large”, which have brought a huge impact to all aspects of people’s lifestyles in terms of work, social, and economy. Although these advanced techniques have extensively improved users’ quality of experience (QoE), it is not adequate to provide affective services without efficient mechanisms of emotion-aware mobile computing, which includes various unique aspects, e.g., mobile data sensing and transmissions; sentiment analysis and emotion recognition; affective interaction. Under the new service paradigm, novel mobile services and innovative applications need to be extensively investigated to gain the great potentials brought by emotion-aware mobile computing."
  },
  {
    "year": "2017",
    "abstract": "Physical-based simulation technique has been widely used in creating astounding fluid appearances for film industries and computer games. However, stable and realistic fluid simulation based on Smoothed Particle Hydrodynamics (SPH) method is still challenging, as unstable solid boundary handling and numerical dissipation always plague current SPH fluid solvers. To solve these issues, we present a new method for improving SPH fluid simulation using position-based dynamics (PBD). For the stable fluidsolid interaction, by combining the position constraint solved by PBD and the relative contribution of solid boundary particles, we significantly alleviate the penetration issues at fluid-solid interfaces. And in order to stably simulate turbulence diffusion of SPH fluids, we enforce a novel nonlinear vorticity constraint on each fluid particle, and then solve it using PBD to smooth the vorticity field. The implementation results demonstrate that our method significantly improves SPH method for simulating realistic and stable animations of fluid phenomena."
  },
  {
    "year": "2017",
    "abstract": "Wireless local area network fingerprint-based indoor localization schemes have been widely studied because of the increasing requirements of location-based services (LBSs). The features of fingerprint based localization are known to have higher precision in indoor environments than traditional methods, such as triangulation. However, the precision depends on the amount of pre-created received signal strength (RSS) fingerprints, which is associated with the number of reference points (RPs) of the RSS measurements and the available signal sources in the environment. In this paper, we consider the resource limitations of todays' wireless environment and propose an improved fingerprint-based localization approach that adapts a path loss model for fingerprint creation and localization. Based on the proposed approach, we present two related localization schemes. The first is a path-loss-based fingerprint localization (PFL) scheme and the second is a dual-scanned fingerprint localization (DFL) scheme. The PFL attempts to improve positioning precision, and the DFL attempts to guarantee positioning reliability. Several simulations are performed, and they show that the proposed schemes improve the positioning precision and reliability in resource-limited environments, which would improve the practicability of fingerprint-based localizations in indoor LBSs."
  },
  {
    "year": "2017",
    "abstract": "Face spoofing detection is commonly formulated as a two-class recognition problem where relevant features of both positive (real access) and negative samples (spoofing attempts) are utilized to train the system. However, the diversity of spoofing attacks, any new means of spoofing attackers, may invent (previously unseen by the system) the problem of imaging sensor interoperability, and other environmental factors in addition to the small sample size make the problem quite challenging. Considering these observations, in this paper, a number of propositions in the evaluation scenario, problem formulation, and solving are presented. First of all, a new evaluation protocol to study the effect of occurrence of unseen attack types, where the train and test data are produced by different means, is proposed. The new evaluation protocol better reflects the realistic conditions in spoofing attempts where an attacker may come up with new means for spoofing. Inter-database and intra-database experiments are incorporated into the evaluation scheme to account for the sensor interoperability problem. Second, a new and more realistic formulation of the spoofing detection problem based on the anomaly detection concept is proposed where the training data come from the positive class only. The test data, of course, may come from the positive or negative class. Such a one-class formulation circumvents the need for the availability of negative training samples, which, in an in deal case, should be the representative of all possible spoofing types. Finally, a thorough evaluation and comparison of 20 different one-class and two-class systems on the video sequences of three widely employed databases is performed to investigate the merits of the one-class anomaly detection approaches compared with the common two-class formulations. It is demonstrated that the anomaly-based formulation is not inferior as compared with the conventional two-class approach."
  },
  {
    "year": "2017",
    "abstract": "This paper considers network capacity and user coverage improvement in Internet of Things (IoT)-oriented massive MIMO systems. In the literature, user grouping approaches have been used in massive MIMO to improve the network capacity, where users are generally divided into non-overlapping groups, and those users with less favorable channel conditions are dropped for capacity optimization. As a result, users may suffer from unpredicted interruptions and delays, even long time disconnection from the network. Moreover, non-overlapping user grouping also leads to unnecessary resource waste. As an effort to overcome these limitations, in this paper, we introduce the concept of overlapping user grouping by exploiting the favorable propagation property in massive MIMO. More specifically, we propose two new user grouping approaches. First, we present a greedy search-based user grouping method by allowing overlapping among the selected subgroups. Second, we introduce a new channel similarity measure, and develop a low complexity overlapping user grouping approach based on the spectral clustering algorithm in machine learning. Both the theoretical and numerical results demonstrate that: overlapping user grouping can achieve much higher network capacity, and can ensure that at any given time, each IoT device will be served in at least one subgroup."
  },
  {
    "year": "2017",
    "abstract": "Mobile data traffic has been growing exponentially over the past few years. A report from Cisco shows that the mobile data traffic in 2014 grew 69 percent and was nearly 30 times the size of the entire global Internet in 2000 [item 1) in the Appendix]. One of the primary contributors to the explosive mobile traffic growth is the rapid proliferation of mobile social applications running on multimedia mobile devices (particularly smartphones). These sharp increases in mobile traffic (particularly from mobile social applications) are projected to continue in the foreseeable future. As mobile networks by and large are designed and deployed to meet people’s social needs, people’s behaviors and interactions in the social domain will shape their ways to access mobile services. Therefore, there is an urgent need to integrate social effects into the design of mobile networks."
  },
  {
    "year": "2017",
    "abstract": "A broadband electrically small antenna with directive circularly polarized radiation is presented. It is composed of a compact single-feed crossed dipole driver, which is backed by a near-field resonant parasitic (NFRP) reflector to achieve the directive radiation pattern. The NFRP reflector is designed to generate extra resonances and minimum axial ratio (AR) points in the antenna system. These features are combined with those resulting from the driver to broaden the operational bandwidth. The proposed antenna was fabricated and measured. The antenna prototype, with a low profile (0.066 λoat 1.45 GHz) and an electrically small size (ka = 0.71 at 1.45 GHz), has a measured |S11| <; -10 dB bandwidth of 25.66% (1.362-1.763 GHz) and a 3-dB AR bandwidth of 10.56% (1.390-1.545 GHz). Additionally, the measurements resulted in a broadside gain of 2.31 ± 0.4 dBic and an average radiation efficiency of 80% within the operational bandwidth."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a new wideband digital receiver based on the modulated wideband converter (MWC) discrete compressed sampling (CS) structure, and we further propose a uniform linear array (ULA)-based MWC discrete CS structure to estimate the carrier frequency and angle-of-arrival (AOA). The proposed receiver and ULA-based system use a bank of pseudorandom sequences to mix signals to baseband and other sub-bands. The product is then low-pass filtered and down-sampled at a low rate to obtain the baseband CS data. Meanwhile, the cross-channel signal problem can be solved flexibly, since the frequency spectrum of the cross-channel signal is all mixed to the baseband. And the sensitivity can be increased a lot, because the bandwidth of the baseband is very small. However, the CS data lose the true carrier frequency and phase differences information, because of the mixing operation.Therefore, we propose to utilize the cyclic-shifted pseudorandom sequences in the ULA-based system in order to design a special phase relationship for the CS data, and on this basis, we can get the carrier frequency estimation. Then, we correct the phase differences of the CS data to estimate AOA. Finally, simulation experiments show that the proposed systems are effective and demonstrate the superior estimation performance in the case of small numbers of snapshots and low signal-to-noise ratios."
  },
  {
    "year": "2017",
    "abstract": "The definition of the next generation of wireless communications, so-called 5G networks, is currently underway. Among many technical decisions, one that is particularly fundamental is the choice of the physical layer modulation format and waveform, an issue for which several alternatives have been proposed. Two of the most promising candidates are: 1) orthogonal frequency division multiple (OFDM), a conservative proposal that builds upon the huge legacy of 4G networks and 2) filter bank multicarrier/offset quadrature amplitude modulation (FBMC/OQAM), a progressive approach that in frequency selective channels sacrifices subcarrier orthogonality in lieu of an increased spectral efficiency. The comparative merits of OFDM and FBMC/OQAM have been well investigated over the last few years but mostly, from a purely physical layer point of view and largely neglecting how the physical layer performance translates into user-relevant metrics at the upper-layers. This paper aims at presenting a comprehensive comparison of both modulation formats in terms of practical network indicators, such as goodput, delay, fairness, and service coverage, and under operational conditions that can be envisaged to be realistic in 5G deployments. To this end, a unifying cross-layer framework is proposed that encompasses the downlink scheduling and resource allocation procedures and that builds upon a model of the queueing process at the data-link control layer and a physical layer abstraction that can be chosen to model either OFDM or FBMC/OQAM. Extensive numerical results conclusively demonstrate that most of the a priori advantages of FBMC/OQAM over OFDM do indeed translate into improved network indicators, that is, the increase in spectral efficiency achieved by FBMC/OQAM makes up for the distortion caused by the loss of orthogonality."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we explore surveillance and target detection applications of Internet of Things (IoT) with radio detection as the primary means of sensing. The problem of surveillance and target detection has found its place in numerous civilian and military applications, and IoT is well suited to address this problem. Radio frequency (RF) sensing techniques are the next generation technologies, which offer distinct advantages over traditional means of sensing used for surveillance and target detection applications of IoT. However, RF sensing techniques have yet to be widely researched due to lack of transmission and computational resources within IoT. Recent advancements in sensing, computing, and communication technologies have made radio detection enabled sensing techniques available to IoT. However, extensive research is yet to be done in developing reliable and energy efficient target detection algorithms for resource constrained IoT. In this paper, we have proposed a multi-sensor RF sensing-based target detection architecture for IoT. The proposed target detection architecture is adaptable to interference, which is caused due to the co-existence of sensor nodes within IoT and adopts smart sensing strategies to reliably detect the presence of the targets. A waveform selection criterion has been proposed to identify the optimum choice of transmit waveforms within a given set of sensing conditions to optimize the target detection reliability and power consumption within the IoT. A dual-stage target detection strategy has been proposed to reduce the computational burden and increase the lifetime of the sensor nodes."
  },
  {
    "year": "2017",
    "abstract": "Feature-level fusion approaches for multispectral biometrics are mainly grouped into two categories: 1) concatenation and 2) elementwise multiplication. While concatenation of feature vectors has benefits in allowing all elements to interact, it is difficult to learn output classification. Differently, elementwise multiplication has the benefits in enabling multiplicative interaction, but it is difficult to learn input embedding. In this paper, we propose a novel approach to combine the benefits of both categories based on a compact representation of two feature vectors' outer product, which is called the multimodal compact multi-linear pooling technique. We first propose to expand the bilinear pooling technique for two inputs to a multi-linear technique to accommodate for multiple inputs (multiple inputs from multiple spectra are frequent in the multispectral biometric context). This fusion approach not only allows all elements to interact and enables multiplicative interaction, but also uses a small number of parameters and low computation complexity. Based on this fusion proposal, we subsequently propose a complete multispectral periocular recognition system. Employing higher order spectra features with an elliptical sampling approach proposed by Algashaam et al., our proposed system achieves the state-of-the-art performance in both our own and the IIIT multispectral periocular data sets. The proposed approach can also be extended to other biometric modalities."
  },
  {
    "year": "2017",
    "abstract": "The inclusion of machine-type communication in the 5G technology has motivated the research community to explore new derivative waveforms of orthogonal frequency division multiplexing. Filter bank multicarrier, universal filtered multicarrier (UFMC), and generalized frequency division multiplexing techniques are under evaluation with respect to their suitability to 5G requirements. In addition to acceptable spectral performance, investigation on computational complexity reduction while addressing flexibility can help in the selection of suitable waveform among multiple options available for 5G. In this regard, based on analysis of computation involved in UFMC waveform construction, few reduced complexity solution for UFMC transmitter implementations are recently proposed. However, hardware-implementation-related issues have not been discussed in detail. In this paper, we have proposed reduced complexity hardware solutions for all three constituent blocks, i.e., inverse discrete Fourier transform (IDFT), finite impulse response (FIR) filter, and spectrum shifting blocks of a UFMC transmitter. For IDFT part, a reduced complexity IFFT solution using Radix-2 decimation in a time technique is presented, where more than 42% computations can be avoided. It is also shown that how five times less number of multipliers can be used in an FIR filter to simplify filter architecture. Finally, a highly efficient method is presented to compute spectrum shifting coefficients through small sized lookup table."
  },
  {
    "year": "2017",
    "abstract": "Pattern division multiple access (PDMA) is a promising non-orthogonal multiple access scheme for the fifth generation mobile communication system. Link performance estimation technique is the key to ensure accurate performance evaluation of the PDMA uplink system. Although the belief propagation (BP) receiver with near-optimal performance is normally considered for PDMA uplink system, it remains a big challenge for the estimation of the link performance for the PDMA uplink system with the BP receiver. In this paper, we first propose a novel link performance estimation technique for the PDMA uplink system with the BP receiver. The performance of the BP receiver is estimated by utilizing the genie-aided interference cancellation receiver as an upper bound with a single fitting parameter. Then, we provide a simple search process of finding the fitting parameter. Finally, the simulation results show that the proposed method achieves greater link performance estimation accuracy over the conventional method in the PDMA uplink evaluation."
  },
  {
    "year": "2017",
    "abstract": "Most off-the-shelf subspace learning methods directly calculate the statistical characteristics of the original input images, while ignoring different contributions of different image components. In fact, to extract efficient features for image analysis, the noise or trivial structure in images should have little contribution and the intrinsic structure should be uncovered. Motivated by this observation, we propose a new subspace learning method, namely, discriminant manifold learning via sparse coding (DML_SC) for robust feature extraction. Specifically, we first decompose each input image into several components via dictionary learning, and then regroup the components into a more important part (MIP) and a less important part (LIP). The MIP can be considered as the clean portion of the image residing on a low-dimensional submanifold, while the LIP as noise or trivial structure within the image. Finally, the MIP and LIP are incorporated into manifold learning to learn a desired discriminative subspace. The proposed method is general for both cases with and without class labels, hence generating supervised DML_SC (SDML_SC) and unsupervised DML_SC (UDML_SC). Experimental results on four benchmark data sets demonstrate the efficacy of the proposed DML_SCs on both image recognition and clustering tasks."
  },
  {
    "year": "2017",
    "abstract": "The inadequate capacity of distribution networks to consume renewable energy and the inappropriate allocation of renewable distributed generation (RDG) have become important issues. In this paper, a 3-level learning automata-based methodology in a master-slave structure is proposed for optimal RDG siting and sizing considering network reconfiguration. The RDG allocation optimization, i.e., the master problem, is proposed in the first level, with the objective of minimizing the annual investment cost and operation cost. Network reconfiguration is modeled as a slave problem in the second level to promote the consumption of RDG and decrease the operation cost. The RDG power control strategy, including active power curtailment and reactive power compensation, is introduced as a secondary slave problem in the third level. Considering the stochastic characteristics of renewable energy and loads, intelligent algorithms based on learning automata are proposed and embedded into the master-slave structure. The simulation results on the standard test systems demonstrate the feasibility and effectiveness of proposed method."
  },
  {
    "year": "2017",
    "abstract": "Optimal allocation of distributed generation units is essential to ensure power loss minimization, while meeting the real and reactive power demands in a distribution network. This paper proposes a solution to this non-convex, discrete problem by using the hybrid grey wolf optimizer, a new metaheuristic algorithm. This algorithm is applied to IEEE 33-, IEEE 69-, and Indian 85-bus radial distribution systems to minimize the power loss. The results show that there is a considerable reduction in the power loss and an enhancement of the voltage profile of the buses across the network. Comparisons show that the proposed method outperforms all other metaheuristic methods, and matches the best results by other methods, including exhaustive search, suggesting that the solution obtained is a global optimum. Furthermore, unlike for most other metaheuristic methods, this is achieved with no tuning of the algorithm on the part of the user, except for the specification of the population size."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a compound multimode printed loop antenna based on degraded spilt-ring resonators (SRRs) for broadband wireless applications is proposed. The proposed antenna consists of an outer split ring and one inner closed ring with a big difference in size, which can be considered as degraded SRRs. By virtue of the orthogonal radiating mode of two rings, the compound multimode loop antenna can achieve multi-band resonances. Collaborating with the two coupled rings, a parasitic strip is placed close to the feed gap of the inner ring, which not only induces a new resonant frequency at upper band but also greatly improves the impedance matching in all high-frequency bands. The proposed antenna not only covers the first split ring mode at 816 MHz but also exhibits a broadband property covering from 2.3 to 4.6 GHz (reflection coefficient |S11| <; -10 dB, 67% fractional bandwidth). The antenna operational principle and physical mechanism are analyzed by carrying out the studies of mode analysis and surface current distribution. To demonstrate the effectiveness of the proposed antenna, an antenna prototype is fabricated and tested. It is numerically and experimentally proved that broadband and multimode characteristics, stable radiation patterns with a peak gain of 1.2 and 5.1 dBi in the lowand high-frequency bands respectively, and more than 80% efficiency can be achieved. With merits of a compact size of 0.12λ0x 0.11λ0(λ0is the wavelength at the lowest operating frequency), uniplanar and simple printed structure and wide bandwidth characteristics make it suitable for a wide range of wireless applications."
  },
  {
    "year": "2017",
    "abstract": "The dissemination of patients' medical records results in diverse risks to patients' privacy as malicious activities on these records cause severe damage to the reputation, finances, and so on of all parties related directly or indirectly to the data. Current methods to effectively manage and protect medical records have been proved to be insufficient. In this paper, we propose MeDShare, a system that addresses the issue of medical data sharing among medical big data custodians in a trust-less environment. The system is blockchain-based and provides data provenance, auditing, and control for shared medical data in cloud repositories among big data entities. MeDShare monitors entities that access data for malicious use from a data custodian system. In MeDShare, data transitions and sharing from one entity to the other, along with all actions performed on the MeDShare system, are recorded in a tamper-proof manner. The design employs smart contracts and an access control mechanism to effectively track the behavior of the data and revoke access to offending entities on detection of violation of permissions on data. The performance of MeDShare is comparable to current cutting edge solutions to data sharing among cloud service providers. By implementing MeDShare, cloud service providers and other data guardians will be able to achieve data provenance and auditing while sharing medical data with entities such as research and medical institutions with minimal risk to data privacy."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the tracking control of a class of uncertain nonlinear systems with consideration of both time-varying input delay and output constraints. By introducing an auxiliary signal, which is based on the finite integral of the past control values in the design procedure, an adaptive controller is proposed to compensate for the effect of input delay and to handle various uncertainties. Meanwhile, an asymmetric time-varying barrier Lyapunov function is employed in the controller design to ensure the output constraint satisfaction. The stability analysis utilizing Lyapunov-Krasovskii functionals reveals that the proposed adaptive controller guarantees a uniformly ultimately bounded tracking performance and the time-varying output constraints are never violated. Two simulation examples are given to verify the effectiveness of the proposed control scheme."
  },
  {
    "year": "2017",
    "abstract": "Underwater acoustic sensor networks (UW-ASNs) have recently been proposed for exploring the underwater resources and gathering the scientific data from the aquatic environments. UW-ASNs are faced with different challenges, such as high propagation delay, low bandwidth, and high energy consumption. However, the most notable challenge is perhaps how to efficiently forward the packets to the surface sink by considering the energy constrained sensor devices. The opportunistic routing concept may provide an effective solution for the UW-ASNs by the cooperation of the relay nodes to forward the packets to the surface sink. In this paper, the energy consumption problem is addressed and an energy-efficient cooperative opportunistic routing (EECOR) protocol is proposed to forward the packets toward the surface sink. In the EECOR protocol, a forwarding relay set is firstly determined by the source node based on the local information of the forwarder and then, a fuzzy logic-based relay selection scheme is applied to select the best relay based on considering the energy consumption ratio and the packet delivery probability of the forwarder. In the UW-ASNs, most of the energy is wasted due to the collisions amongst sensor nodes during the packet transmission. To alleviate the packet collisions problem, we have designed a holding timer for each of the forwarder to schedule the packets transmission toward the surface sink. We have performed our extensive simulations of the EECOR protocol on the Aqua-sim platform and compared with existing routing protocols in terms of average packet delivery ratio, average end-to-end delay, average energy consumption, and average network lifetime."
  },
  {
    "year": "2017",
    "abstract": "An improved faster region-based convolutional neural network (R-CNN) [same object retrieval (SOR) faster R-CNN] is proposed to retrieve the same object in different scenes with few training samples. By concatenating the feature maps of shallow and deep convolutional layers, the ability of Regions of Interest (RoI) pooling to extract more detailed features is improved. In the training process, a pretrained CNN model is fine-tuned using a query image data set, so that the confidence score can identify an object proposal to the object level rather than the classification level. In the query process, we first select the ten images for which the object proposals have the closest confidence scores to the query object proposal. Then, the image for which the detected object proposal has the minimum cosine distance to the query object proposal is considered as the query result. The proposed SOR faster R-CNN is applied to our Coke cans data set and three public image data sets, i.e., Oxford Buildings 5k, Paris Buildings 6k, and INS 13. The experimental results confirm that SOR faster R-CNN has better identification performance than fine-tuned faster R-CNN. Moreover, SOR faster R-CNN achieves much higher accuracy for detecting low-resolution images than the fine-tuned faster R-CNN on the Coke cans (0.094 mAP higher), Oxford Buildings (0.043 mAP higher), Paris Buildings (0.078 mAP higher), and INS 13 (0.013 mAP higher) data sets."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we intend to reduce the operational cost of cloud data centers with the help of fog devices, which can avoid the revenue loss due to wide-area network propagation delay and save network bandwidth cost by serving nearby cloud users. Since fog devices may not be owned by a cloud service provider, they should be compensated for serving the requests of cloud users. When taking economical compensation into consideration, the optimal number of requests processed locally by each fog device should be decided. As a result, existing load balancing schemes developed for cloud data centers cannot be applied directly and it is very necessary to redesign a cost-ware load balancing algorithm for the fogcloud system. To achieve the above aim, we first formulate a fog-assisted operational cost minimization problem for the cloud service provider. Then, we design a parallel and distributed load balancing algorithm with low computational complexity based on proximal Jacobian alternating direction method of multipliers. Finally, extensive simulation results show the effectiveness of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Fault tree analysis (FTA) has been widely utilized as a reliability evaluation technique for complex systems, such as nuclear power plants and aerospace systems. However, it is hard to obtain the crisp failure probabilities of basic events, owning to the insufficient information about some complex engineering systems. Hence, fuzzy set theory and fuzzy arithmetic operation (FAO) have been used as effective methods to analyze system reliability. However, it is cumbersome to evaluate complex systems based on FAO. To improve the evaluation efficiency, stochastic computational models are proposed in this paper to perform reliability analysis of a fuzzy system. Due to the features of Gaussian distribution in stochastic computation, a basic event's failure possibility given by a fuzzy number is transformed into the expected value of it. The standard deviation of stochastic computational results gives the spread of the fuzzy number. A fuzzy system is then converted into a deterministic system. The analysis of an illustrating example shows that the proposed stochastic approach can efficiently evaluate the failure probability of a system."
  },
  {
    "year": "2017",
    "abstract": "Current generation of smartphones is running more and more complex applications that reduce the battery life to as short as several hours. Thus, it becomes very important to understand the diversities of applications installed on smartphones and how batteries are consumed across different applications. This paper presents a large-scale battery study on smartphones focusing on diversities in applications and users. Based on application and battery traces collected on over 80000 Android smartphones for a four-week period, we analyze the battery discharging patterns, the types of mobile applications, and the usage and energy consumption patterns for these applications. During the analysis, we introduce a novel method to calculate the energy consumption rate for each application based on coarse-grained battery data collected with a lightweight monitoring tool. Based on the results, we present some observations and discuss possible improvements on smartphone designs and mobile application development. We also compare our results to some previous studies wherever it is possible."
  },
  {
    "year": "2017",
    "abstract": "Research and development on the next generation wireless systems, namely 5G, has experienced explosive growth in recent years. In the physical layer, the massive multiple-input-multiple output (MIMO) technique and the use of high GHz frequency bands are two promising trends for adoption. Millimeter-wave (mmWave) bands, such as 28, 38, 64, and 71 GHz, which were previously considered not suitable for commercial cellular networks, will play an important role in 5G. Currently, most 5G research deals with the algorithms and implementations of modulation and coding schemes, new spatial signal processing technologies, new spectrum opportunities, channel modeling, 5G proof of concept systems, and other system-level enabling technologies. In this paper, we first investigate the contemporary wireless user equipment (UE) hardware design, and unveil the critical 5G UE hardware design constraints on circuits and systems. On top of the said investigation and design tradeoff analysis, a new, highly reconfigurable system architecture for 5G cellular user equipment, namely distributed phased arrays based MIMO (DPA-MIMO) is proposed. Finally, the link budget calculation and data throughput numerical results are presented for the evaluation of the proposed architecture."
  },
  {
    "year": "2017",
    "abstract": "An obvious limitation of wireless sensor networks (WSNs) concerns the energy consumption and the network lifetime. Transmitting signals, including sending and receiving, take most of the energy dissipation in such a network. Generally the data transmission in such a network follows a many-to-one pattern, which leads to the so-called energy hole near the sink and lifetime reduction. This paper makes a first attempt to solve the many-to-one transmission problem of strip-based WSN and avoid energy holes of such a network, which is divided into multiple layers. Specifically, we propose an accurate-distances based transmission scheme, which aims at achieving the most precise layer lengths so far and obtaining the optimal transmission distances in different regions to date. Such a transmission scheme enables the network lifetime of the strip-based WSN to reach a maximum. Extensive simulations are carried out to validate the effectiveness and advantages of our transmission scheme."
  },
  {
    "year": "2017",
    "abstract": "Software development organizations are globalizing their activities by adopting the phenomenon of global software development (GSD), mainly due to the significant return on investment it offers. Various challenges are associated with the software process improvement (SPI). The aim of this paper is to develop a software process improvement implementation and management model (SPIIMM) that can assist GSD organizations in assessing and improving their SPI activities. A thorough systematic literature review (SLR) study was performed to identify the critical success factors (CSFs), critical barriers (CBs), and the relevant practices of SPI. An empirical study of the industry was conducted with 111 SPI experts using a survey questionnaire to verify the outcomes of the SLR. The final CSFs and CBs were categorized into five maturity levels based on the implementation maturity model, the software outsourcing vendor readiness model, and capability maturity model integration. Each maturity level consisted of different CSFs and CBs to assess and improve the SPI-related maturity level of an organization. Three case studies were conducted to evaluate the effectiveness of the proposed model. The results revealed that SPIIMM can provide a robust framework to assess and improve SPI activities in GSD organizations."
  },
  {
    "year": "2017",
    "abstract": "Advanced metering infrastructure (AMI) is becoming a vital part of utility distribution networks, allowing the development of smart cities. AMI consists of smart electric, gas, and water meters, and the devices are very limited in terms of battery, processing power, and memory. The deployment and operational needs of energy-constrained network infrastructures in smart water and gas metering systems require the use of routing mechanisms that consider energy consumption, minimize energy use, and prolong network lifetime. An efficient routing metric is needed for energy-constrained devices. In this paper, we propose an energy- and congestion-aware routing metric for smart meter networks to be deployed in smart cities. The proposed metric is an adaptive parent node selection mechanism that considers the residual energy and queue utilization of neighboring nodes. Minimizing power consumption will enhance network lifetime. The proposed scheme was evaluated with the Cooja Simulator 3.0 using random and grid topology. The simulation results show greater network performance in terms of average power consumption and packet delivery ratio."
  },
  {
    "year": "2017",
    "abstract": "A non-autonomous second-order memristive chaotic circuit is considered in this paper, which is comparatively simple, only consisting of a memristor, a capacitor, a resistor, and a sinusoidal voltage source. Based on the descriptive equation of the memristive circuit, the dynamical behaviors are investigated by theoretical analyses and numerical simulations. It is noted that the number of AC equilibrium points changes with the evolution of the time and the circuit exhibits striking dynamical features, including period, chaos, forward period-doubling, reverse period-doubling, tangent bifurcation, and crisis scenarios. Furthermore, a hardware circuit is set up by off-the-shelf discrete components, where hardware experiments are performed to verify the numerical results. The most significant feature of the proposed memristive circuit is the inductorfree realization with simplified topology, which makes the circuit much simpler and more intuitive in physical realization."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) technologies have been broadly applied in smart grid for monitoring physical or environmental conditions. Especially, state estimation is an important IoT-based application in smart grid, which is used in system monitoring to get the best estimate of the power grid state through an analysis of the meter measurements and power system topologies. However, false data injection attack (FDIA) is a severe threat to state estimation, which is known for the difficulty of detection. In this paper, we propose an efficient detection scheme against FDIA. First, two parameters that reflect the physical property of smart grid are investigated. One parameter is the control signal from the controller to the static Var compensator (CSSVC). A large CSSVC indicates there exists the intense voltage fluctuation. The other parameter is the quantitative node voltage stability index (NVSI). A larger NVSI indicates a higher vulnerability level. Second, according to the values of the CSSVC and NVSI, an optimized clustering algorithm is proposed to distribute the potential vulnerable nodes into several classes. Finally, based on these classes, a detection method is proposed for the real-time detection of the FDIA. The simulation results show that the proposed scheme can detect the FDIA effectively."
  },
  {
    "year": "2017",
    "abstract": "Partial least squares (PLS) regression is a versatile modeling approach for high-dimensional data analysis. Recently, PLS-based variable selection has attracted great attention due to high-throughput data reduction and modeling interpretability. In this paper, a class of variable selection methods for PLS, which employs marginal screening approaches to select relevant variables, is proposed. The proposed methods select variables in two steps: first, a solution path of all predictors is generated by sorting the sequence of marginal correlations between each predictor and response, and second, variable selection is carried out by screening the solution path with PLS. We provide three marginal screening methods for PLS in this paper, namely, sure independence screening (SIS), profiled independence screening (PIS), and high-dimensional ordinary least-squares projection (HOLP). The promising performance of our methods is illustrated via three near-infrared (NIR) spectral data sets. Compared with SIS and PIS, HOLP for PLS is more suitable for selecting important wavelengths and enhances the prediction accuracy in the NIR spectral data."
  },
  {
    "year": "2017",
    "abstract": "In current epoch, the economic operation of micro-grid under soaring renewable energy integration has become a major concern in the smart grid environment. There are several meta-heuristic optimization techniques available under different categories in literature. One of the most difficult tasks in cost minimization of micro-grid is to select the best suitable optimization technique. To resolve the problem of selecting a suitable optimization technique, a rigorous review of six meta-heuristic algorithms (Whale Optimization, Fire Fly, Particle Swarm Optimization, Differential Evaluation, Genetic Algorithm, and Teaching Learning-based Optimization) selected from three categories (Swarm Intelligence, Evolutionary Algorithms, and Teaching Learning) is conducted. It presents, a comparative analysis using different performance indicators for standard benchmark functions and proposed a smart micro-grid (SMG) operation cost minimization problem. A proposed SMG is modeled which incorporates utility connected power resources, e.g., wind turbine, photovoltaic, fuel cell, micro-turbine, battery storage, electric vehicle technology, and diesel power generator. The proposed work will help researchers and engineers to select an appropriate optimization method to solve micro-grid optimization problems with constraints. This paper concludes with a detailed review of micro-grid operation cost minimization techniques based on an exhaustive survey and implementation."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present the application of a projective geometry tool known as conformal geometric algebra (CGA) to transmission line theory. Explicit relationships between the Smith Chart, Riemann Sphere, and CGA are developed to illustrate the evolution of projective geometry in transmission line theory. By using CGA, fundamental network operations, such as adding impedance, admittance, and changing lines impedance can be implemented with rotations, and are shown to form a group. In addition, the transformations relating different circuit representations, such as impedance, admittance, and reflection coefficient are also related by rotations. Thus, the majority of relationships in transmission line theory are linearized. Conventional transmission line formulas are replaced with an operator-based framework. Use of the framework is demonstrated by analyzing the distributed element model and solving some impedance matching problems."
  },
  {
    "year": "2017",
    "abstract": "Recent breakthroughs in wireless charging technologies have greatly promoted the development of rechargeable wireless sensor networks (WSNs). To improve the lifetime of WSNs in many applications, the charging efficiency of mobile chargers (MCs) and the energy supplement of MCs should be improved. Although optimized charging path schemes in WSNs have been studied extensively, little attention has been paid to determine the energy consumption of MCs while charging and their movement during the charging tasks. In this paper, we analyze the relationship of the movement energy consumption of MCs and their energy transfer to the nodes and put forward our algorithm for improving the charging efficiency of the MCs. We divide the entire network into different charging regions and propose three charging schemes based on different situations in each region. The idea of cooperation among the MCs to charge MCs further enhances the charging efficiency of the MCs. A simulation demonstrates the advantages of our algorithm for improving the lifetime and charging efficiency of the MCs. This paper aims to improve the lifetime of WSNs and to decrease the cost for charging nodes and results in a longer lifetime for WSNs in applications with limited energy."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a novel big feature data analytics scheme for integration toward data analytics with decision making. In this scheme, a split and combine approach for a linear discriminant analysis (LDA) algorithm termed SC-LDA is proposed. The SC-LDA replaces the full eigenvector decomposition of LDA with much cheaper eigenvector decompositions on smaller sub-matrices, and then recombines the intermediate results to obtain the exact reconstruction as for the original algorithm. The splitting or decomposition can be further applied recursively to obtain a multi-stage SC-LDA algorithm. The smaller sub-matrices can then be computed in parallel to reduce the time complexity for big data applications. The approach is discussed for an LDA algorithm variation (LDA/QR), which is suitable for the analytics of Big Feature data sets. The projected data vectors into the LDA subspace can then be integrated toward the decision-making process involving classification. Experiments are conducted on real-world data sets to confirm that our approach allows the LDA problem to be divided into the size-reduced sub-problems and can be solved in parallel while giving an exact reconstruction as for the original LDA/QR."
  },
  {
    "year": "2017",
    "abstract": "Formal methods help in quantifying the functional and nonfunctional requirements that are later used in the verification process for safety assurance in real-time systems. System formalism is a crucial step in terms of exploring system's behavior and listing the non-functional requirements. In the context of real-time systems, the non-functional requirements refer to the verification properties of the system. Formalism in software development life cycle refines every process, starting from the formalization of system's requirements, analysis of system's behavior and exploring its properties, implementation of the problem's solution under consideration, and verification of safety critical properties. Rule-based expert system helps in inferring unknown on the basis of some known input, that is, knowledge and rule set. Knowledge is comprised of something known by an individual called an expert of that domain. It requires an expert skill set in order to model and verify some system in model checkers like UPPAAL. This research contribution has explored a variation of traffic light system's case study, modeled the system in UPPAAL model checker, and later verified the safety critical properties of the generated system like safety, liveness, fairness, reachability, and deadlock freeness to cross-check the validity of transformation rule set. This research is focused on providing the rule-based expert system for inferring timed automata (input of UPPAAL model checker) on the basis of fact cum input, that is, C++ code. Structural facts are used along with the transformation rule set to get the timed automata that verify safety properties of selected case studies-multiple variations of a traffic light system."
  },
  {
    "year": "2017",
    "abstract": "Robust performance of nonlinear systems has attracted phenomenal worldwide attention. It is well known that deviating argument and stochastic disturbance may derail the evolution properties of nonlinear systems. Then the following issue has become a major bottleneck: for a given globally exponentially stable nonlinear system, the perturbed nonlinear system can sustain how much the length of the interval of the deviating function and the noise intensity so that the perturbed nonlinear system in the presence of deviating argument and stochastic disturbance may remain to be exponentially stable. In this paper, theoretical investigation has been made on the robustness of global exponential stability of nonlinear systems with deviating argument and stochastic disturbance. The allowable upper bounds of the length of interval of deviating function and the noise intensity are derived for the perturbed nonlinear systems to remain exponentially stable. It is also proven that, if the length of interval of deviating function and the noise intensity of perturbed nonlinear systems are lower than the upper bounds derived herein, the nonlinear systems infected by deviating argument and stochastic disturbance are still exponentially stable. Finally, we give several simulation examples to demonstrate the efficacy of the proposed results."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present an efficient amplitude shift keying (ASK)-aided orthogonal chaotic vector PSK (ASK-OCVPSK) non-coherent modulation scheme with considerations of different quality of service (QoS) demands. In our ASK-OCVPSK design, the reference chaotic signal is generated recursively from the shifted chaotic vectors orthogonalized by the Gram-Schmidt transform buffered in the shift register. Then, we embed the information on both the position and the amplitude of the chaotic sequence. The binary information bitstream is divided into two segments, which are modulated, respectively, by the parallel concatenated position shift keying (PSK) scheme and the ASK scheme. Next, the ASK symbol is further modulated by the PSK modulated chaotic vector, and the resultant symbol is transmitted together with the reference chaotic vector. Notably, with the aid of the shift register, only one chaotic vector is transmitted and the reference chaotic sequences can be easily regenerated recursively at the receiver for information recovery. Furthermore, we derive the theoretical bit error rate (BER) expressions for the proposed system over additive white Gaussian noise (AWGN) channel. Then, the spectrum efficiency and the complexity of the proposed scheme are analyzed and compared with those of the counterpart schemes. Simulations are performed over the AWGN channel and multipath Rayleigh fading channel, and the results demonstrate that the theoretical BER matches the simulation results. Moreover, the results verify that the presented scheme are more efficient and more reliable than the counterpart schemes and can provide different BER performances without changing the modulator structure to meet the different QoS demands of the users."
  },
  {
    "year": "2017",
    "abstract": "Motivated by the problem that the Gaussian assumption of process noise may be violated and the statistics of process noise may be inaccurate when the carrier maneuvers severely, a new process uncertainty robust Student's t-based Kalman filter is proposed to integrate the strap-down inertial navigation system (SINS) and global positioning system (GPS). To better address the heavy-tailed process noise induced by severe maneuvering, the one-step predicted probability density function is modeled as a Student's t distribution, and the conjugate prior distributions of inaccurate mean vector, scale matrix, and degrees of freedom (dofs) parameter are, respectively, selected as Gaussian, inverse Wishart, and Gamma distributions, based on which a new Student's t-based hierarchical Gaussian state-space model for SINS/GPS integration is constructed. The state vector, auxiliary random variable, mean vector, scale matrix, and dof parameter are jointly estimated based on the constructed hierarchical Gaussian state-space model using the variational Bayesian approach. Experimental results illustrate that the proposed method has significantly better robustness for the suppression of the process uncertainty but slightly higher computational complexity than the existing state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Environmental noise and reverberation conditions severely degrade the performance of forensic speaker verification. Robust feature extraction plays an important role in improving forensic speaker verification performance. This paper investigates the effectiveness of combining features, mel frequency cepstral coefficients (MFCCs), and MFCC extracted from the discrete wavelet transform (DWT) of the speech, with and without feature warping for improving modern identity-vector (i-vector)-based speaker verification performance in the presence of noise and reverberation. The performance of i-vector speaker verification was evaluated using different feature extraction techniques: MFCC, feature-warped MFCC, DWT-MFCC, feature-warped DWT-MFCC, a fusion of DWT-MFCC and MFCC features, and fusion feature-warped DWT-MFCC and feature-warped MFCC features. We evaluated the performance of i-vector speaker verification using the Australian Forensic Voice Comparison and QUT-NOISE databases in the presence of noise, reverberation, and noisy and reverberation conditions. Our results indicate that the fusion of feature-warped DWT-MFCC and feature-warped MFCC is superior to other feature extraction techniques in the presence of environmental noise under the majority of signal-to-noise ratios (SNRs), reverberation, and noisy and reverberation conditions. At 0-dB SNR, the performance of the fusion of feature-warped DWT-MFCC and feature-warped MFCC approach achieves a reduction in average equal error rate of 21.33%, 20.00%, and 13.28% over feature-warped MFCC, respectively, in the presence of various types of environmental noises only, reverberation, and noisy and reverberation environments. The approach can be used for improving the performance of forensic speaker verification and it may be utilized for preparing legal evidence in court."
  },
  {
    "year": "2017",
    "abstract": "As a key technology that is widely adopted in location-based services (LBS), indoor localization has received considerable attention in both research and industrial areas. Despite the huge efforts made for localization using smartphone inertial sensors, its performance is still unsatisfactory in large open areas, such as halls, supermarkets, and museums, due to accumulated errors arising from the uncertainty of users’ mobility and fluctuations of magnetic field. Regarding that, this paper presents iBILL, an indoor localization approach that jointly uses iBeacon and inertial sensors in large open areas. With users’ real-time locations estimated by inertial sensors through an improved particle filter, we revise the algorithm of augmented particle filter to cope with fluctuations of magnetic field. When users enter vicinity of iBeacon devices clusters, their locations are accurately determined based on received signal strength of iBeacon devices, and accumulated errors can, therefore, be corrected. Proposed by Apple Inc. for developing LBS market, iBeacon is a type of Bluetooth low energy, and we characterize both the advantages and limitations of localization when it is utilized. Moreover, with the help of iBeacon devices, we also provide solutions of two localization problems that have long remained tough due to the increasingly large computational overhead and arbitrarily placed smartphones. Through extensive experiments in the library on our campus, we demonstrate that iBILL exhibits 90% errors within 3.5 m in large open areas."
  },
  {
    "year": "2017",
    "abstract": "As a breakthrough in the field of machine fault diagnosis, deep learning has great potential to extract more abstract and discriminative features automatically without much prior knowledge compared with other methods, such as the signal processing and analysis-based methods and machine learning methods with shallow architectures. One of the most important aspects in measuring the extracted features is whether they can explore more information of the inputs and avoid redundancy to be representative. Thus, a stacked sparse autoencoder (SAE)-based machine fault diagnosis method is proposed in this paper. The penalty term of the SAE can help mine essential information and avoid redundancy. To help the constructed diagnosis network further mine more abstract and representative high-level features, the collected non-stationary and transient signals are preprocessed with ensemble empirical mode decomposition and autoregressive (AR) models to obtain AR parameters, which are extracted based on the intrinsic mode functions (IMFs) and regarded as the low-level features for the inputs of the proposed diagnosis network. Only the first four IMFs are considered, because fault information is mainly reflected in high-frequency IMFs. Experiments and comparisons are complemented to validate the superiority of the presented diagnosis network. Results fully demonstrate that the stacked SAE-based diagnosis method can extract more discriminative high-level features and has a better performance in rotating machinery fault diagnosis compared with the traditional machine learning methods with shallow architectures."
  },
  {
    "year": "2017",
    "abstract": "We present a multidisciplinary approach for learning, visualizing, and assessing a model for the intrinsic value of a batted ball in baseball. The new methodology addresses one of the most fundamental problems in baseball analytics. Traditional outcome-based statistics for representing player skill on batted balls have been shown to have a low degree of repeatability due to the effects of multiple confounding variables, such as the defense, weather, and ballpark. New sensors have created the opportunity to define batted-ball descriptors that are invariant to these variables. We exploit this opportunity by using a Bayesian model to construct a continuous mapping from a vector of batted-ball parameters to an intrinsic value defined using a linear weights representation for run value. A kernel method is used to learn nonparametric estimates for the component probability density functions in Bayes theorem using a set of over 100 000 batted-ball measurements, while cross validation enables the model to adapt to the size and structure of the data. Properties of the mapping are visualized by considering reduced-dimension subsets of the batted-ball parameter space. The approach separates the intrinsic value of a batted ball at contact from its outcome and, as a result, allows the definition of batted-ball statistics for batters and pitchers that are less subject to systematic bias and random variation than traditional statistics. We use Cronbach's alpha to show that statistics derived from batted-ball intrinsic values have a higher reliability than the traditional outcome-based statistics and that this leads to more accurate estimates of player talent level that can be used for performance forecasting."
  },
  {
    "year": "2017",
    "abstract": "A new high altitude propeller is analyzed and designed in this paper to be used on the stratospheric aircraft propulsion system. Two more appropriate approaches to investigate the aerodynamics characteristics of the high altitude propeller are obtained by comparison of vortex theory with the Spalart-Allmaras (S-A) model and XFOIL program, computational fluid dynamics (CFD), and wind tunnel tests, which are vortex theory with the S-A model and CFD method. In addition, the comparison results show the S-A model is more suitable than the XFOIL program to calculate lift and drag coefficients of S1223 airfoil in case of laminar flow separation and low Reynolds number. What is more, the design procedure of the new high altitude propeller is also described. The above approaches are applied to the new high altitude propeller to get the thrust coefficient, power coefficient, and efficiency. It is indicated that the design propeller can meet the cruising requirement of aircraft at the design point."
  },
  {
    "year": "2017",
    "abstract": "We investigate how to leverage limited local information for mobile advertisement popularization, where users are motivated to propagate advertisements with rewards or credits distributed from a centralized platform. Previous solutions on social networks failed to be applicable for mobile advertisement propagation because of the mobility, which would lead to extremely high overhead and low propagation efficiency. Participants need to be selected carefully and efficiently in dealing with the highly dynamic network and uncertain contacts among users. Even worse, the propagation effects are difficult to quantify with the increased number of mobile users. In tackling these difficulties, we propose αMAP (α here means efficient mobile advertisement popularization with local information), a lightweight but effective propagation user selection scheme with local information. Two key technologies inspire us to achieve efficient and effective mobile advertisement propagation. First, we advocate propagation effects instead of influence for user selection, where mobile users with strong information dissemination ability could be selected. Second, we use local information instead of the global information to achieve near optimal performance for propagation. In our proposed scheme, the information potentials proposed by Loukas et al. are leveraged to find the influential users with local information. With extensive experimental study, we find that αMAP could effectively improve the mobile advertisements delivery ratio. Using the propagation instead of popularization is validated with different aspects of investigations when the budget is constrained. To evaluate the impact of mobility, we leverage the mobile trace data set for comprehensive evaluations. αMAP performs fairly well when more realistic experimental settings are incorporated."
  },
  {
    "year": "2017",
    "abstract": "Predictive current control of induction motors can effectively avoid performance deterioration of control caused by delays in the current loop and improve the dynamic performance of current control. However, owing to measurement errors and parameter changes, deviations can appear between the predictive controller parameters and the actual motor parameters. This might lead to static current error, which can cause problems, including decrease in system's efficiency, inability to deliver nominal torque, and to operate in torque control mode, among others. Based on an induction motor model, this paper quantitatively analyzes the influence on current control stability caused by errors in the predictive control model parameters. In addition, we present the mathematical relation between errors in model parameters and static current error, and propose an algorithm to eliminate this type of error. The algorithm corrected the parameters for predictive control using dq axis current feedback and eliminated the static error caused by parameter mismatch. Through experimental results, the stability and effectiveness of the proposed method were shown."
  },
  {
    "year": "2017",
    "abstract": "Cloud Radio Access Network (CRAN) is a promising approach to cope with the challenges of next generation mobile communications. This paper studies the downlink ergodic rate of a (N, K) virtual cell-based CRAN, in which each mobile station (MS) selects the N closest remote radio heads (RRHs) to form its virtual cell and the K (K ≤ N) closest RRHs will serve the target MS cooperatively with a total transmit power constraint. Using the stochastic geometry, the locations of RRHs and MSs are modeled as two independent Poisson point processes, respectively. Then, a computationally tractable integral expression is derived for the downlink ergodic rate of the (N, K) virtual cell-based CRAN. The analytical expression indicates that in the interference limited regime, the ergodic rate only relies on the MS to RRH intensity ratio and is independent with the individual intensity of either the RRH or the MS. Therefore, without deteriorating the downlink ergodic rate significantly, the number of simultaneously served MSs can be improved by increasing the RRH intensity. Specially, when there is only one RRH in each virtual cell, the analytical expression reduces to the ergodic rate expression for the conventional cellular networks. Numerical results indicate that the cooperation among multiple RRHs within each virtual cell can improve the downlink ergodic rate significantly."
  },
  {
    "year": "2017",
    "abstract": "Due to limited radio resources, non-orthogonal multiple access (NOMA) is a promising technology to enable massive connectivity in future 5G and beyond wireless networks. However, it suffers from the multiple access interference, which usually requires a high detection complexity to mitigate. In this paper, we consider NOMA with sparse multiple-access sequences, so as to leverage the message passing algorithm (MPA) for low-complexity and high-reliability multiuser detection. The optimal sparsity of spreading sequences is analyzed by minimizing the average bit error rate in the asymptotic largesystem limit. Based on the analysis, the optimal sparse sequences that optimize the performance of MPA detector are designed in a systematically hierarchical way. The sparse structure is constructed given the target girth. Then, the values of nonzero entries are determined to maximize the minimum distance. The detection performance of the designed sparse sequences is presented for both additive white Gaussian noise and Rayleigh fading channels. Simulation results show the superiority of the proposed design in comparison with existing schemes."
  },
  {
    "year": "2017",
    "abstract": "Feature selection, which aims to select the most informative feature subset, has been playing a critical role in dimension reduction. In this paper, a novel unsupervised feature selection algorithm called the inner product regularized nonnegative self-representation (IRNSR) is designed for image classification and clustering. In the IRNSR algorithm, first, each feature in high-dimensional data is represented by a linear combination of other features. Then, the inner product regularized loss function is introduced into the objective function with the aim of reducing the correlation and redundancy among the selected features. More importantly, a simple yet efficient iterative update optimization algorithm is accordingly designed to solve the objective function. The convergence behavior of the proposed optimization algorithm is also analyzed. Comparative experiments on six image databases indicate that the proposed IRNSR algorithm is effective and efficient."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a compression algorithm for color filter array (CFA) images in a wireless capsule endoscopy system. The proposed algorithm consists of a new color space transformation (known as YLMN), a raster-order prediction model, and a single context adaptive Golomb-Rice encoder to encode the residual signal with variable length coding. An optimum reversible color transformation derivation model is presented first, which incorporates a prediction model to find the optimum color transformation. After the color transformation, each color component has been independently encoded with a low complexity raster-order prediction model and Golomb-Rice encoder. The algorithm is implemented using a TSMC 65-nm CMOS process, which shows a reduction in gate count by 38.9% and memory requirement by 71.2% compared with existing methods. Performance assessment using CFA database shows the proposed design can outperform existing lossless and near-lossless compression algorithms by a large margin, which makes it suitable for capsule endoscopy application."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider a wireless powered communication network (WPCN) consisting of a multi-antenna hybrid access point (HAP) that transfers wireless energy to and receives sensing data from a cluster of low-power wireless devices (WDs). To enhance the throughput performance of some far-away WDs, we allow one of the WDs to act as the cluster head (CH) that helps forward the messages of the other cluster members. However, the performance of the proposed cluster-based cooperation is fundamentally limited by the high energy consumption of the CH, who needs to transmit all the WDs’ messages including its own. To tackle this issue, we exploit the capability of multi-antenna energy beamforming (EB) at the HAP, which can focus more transferred power to the CH to balance its energy consumption in assisting the other WDs. Specifically, we first derive the throughput performance of each individual WD under the proposed scheme. Then, we jointly optimize the EB design, the transmit time allocation among the HAP and the WDs, and the transmit power allocation of the CH to maximize the minimum data rate achievable among all the WDs (the max–min throughput) for improved throughput fairness among the WDs. An efficient optimal algorithm is proposed to solve the joint optimization problem. Moreover, we simulate under practical network setups and show that the proposed multi-antenna enabled cluster-based cooperation can effectively improve the throughput fairness of WPCN."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a method for texture image labeling that works with a small number of training images. Our method is based on a tree of shapes and histogram features computed on the tree structure. Labeling results could be obtained by simply classifying the histogram features of all nodes in a tree of shapes. However, it is difficult to obtain satisfactory results, because features of smaller nodes are not sufficiently discriminative. Consequently, our method selects optimal discriminative subtrees for image labeling. We model an objective function that includes the parameters of a classifier and a set of thresholds for each training image to be used to select optimal subtrees. Then, labeling is performed by mapping the classification results of selected subtrees into corresponding blobs in the image. Experimental results with synthetic and real data sets that we created for evaluation show that the proposed method performs qualitatively and quantitatively much better than the existing methods."
  },
  {
    "year": "2017",
    "abstract": "Inter-datacenter services such as data replication and virtual machine migration contribute significantly to the underlying network traffic. These bulk-data transfer services can tolerate certain delay if the completion time is guaranteed with a pre-defined deadline. In this paper, we propose joint frequency and time-domain optimization algorithms of static routing and spectrum assignment (RSA) for these deadline-driven bulk-data transfer requests in elastic optical networks. We formulate the problem as an integer linear program (ILP) and then propose six scheduling schemes, which combine three request ordering strategies with two RSA algorithms. Simulation results show that compared with ILP, our schemes can achieve the same performance in terms of spectrum utilization with efficient time complexity. Furthermore, based on the numerical results and computational efficiency, we provide a guideline on choosing scheduling schemes."
  },
  {
    "year": "2017",
    "abstract": "Serious games can be used to push consumers of common-pool resources toward socially responsible consumption patterns. However, gamified interactions can result in privacy leaks and potential misuses of player-provided data. In the Smart Grid ecosystem, a smart metering framework providing some basic cryptographic primitives can enable the implementation of serious games in a privacy-friendly manner. This paper presents a smart metering architecture in which the users have access to their own high-frequency data and can use them as the input data to a multi-party secure protocol. Authenticity and correctness of the data are guaranteed by the usage of a public blockchain. The framework enables a gaming platform to administer a set of team game activities aimed at promoting a more sustainable usage of energy and water. We discuss and assess the performance of a protocol based on Shamir secret sharing scheme, which enables the members of the teams to calculate their overall consumption and to compare it with those of other teams without disclosing individual energy usage data. Additionally, the protocol impedes that the game platform learns the meter readings of the players (either individual or aggregated) and their challenge objectives."
  },
  {
    "year": "2017",
    "abstract": "Communication plays a significant role in terms of providing connectivity for urban users as well as sensors in smart cities. It has been shown that better communication capability for vehicular users can be obtained by introducing moving relays (MRs). With MRs, it is possible for macro base stations and moving relays to serve non-vehicular macro-users by performing coordinated multipoint (CoMP) joint transmission (JT). A bias-based CoMP scheme for MR enabled cellular network is analyzed in this paper. Motivated by antenna design constraints, in this paper, we assume that the outdoor antenna system of the MR can only be used for the moving backhaul link, i.e., the in-vehicle antenna system is also serving the nonvehicular macro-users. Using the stochastic geometry approach, a tractable model of the network is proposed. Based on the proposed model, integral expressions for CoMP-JT probability and coverage probability of nonvehicular macro user equipment are derived. Simulations verify the accuracy of the derived expressions. The results show that the probability for macro user equipment to be served with CoMP-JT is up to 70% when the intensity of MRs is ten times that of MBSs. This paper also includes a performance comparison among the analyzed scheme and related works. CoMP-JT with MRs provides better coverage performance for nearby macro user equipment. It can be found that the coverage gain of CoMP increases when the intensity of MRs increases within a certain range. Simulation results provide insights for practical system design in smart cities, such as the optimal MR intensity and the feasibility for opening access of MRs to macro user equipment."
  },
  {
    "year": "2017",
    "abstract": "A 3D surface is considered one of the most promising tools for representing and recognizing 3D objects. Therefore, 3D surface matching is widely applied to 3D object recognition, retrieval, and so on. In this paper, a 3D surface matching method using a keypoint-based covariance matrix descriptor is proposed, whose purpose is to find correspondences between 3D surfaces (e.g., 3D model and scene) by matching feature points, which are highly repeatable keypoints described by a multi-scale covariance matrix descriptor. A keypoint is detected by analyzing the surface variation index and eigenvalue variation index of a local neighborhood centered at a point. A multi-scale covariance matrix descriptor of a keypoint describes the geometric relation, surface variation gradient, and eigenvalue variation gradient between the keypoint and its neighborhood. The rationale for adopting the keypoint-based covariance matrix descriptor in our proposed 3D surface matching method is that a small number of keypoints with high repeatability can greatly enhance the matching effect of a 3D surface, after being described by a multi-scale covariance matrix descriptor with high descriptiveness. The experimental results also show that our proposed keypoint detection algorithm has higher repeatability than the surface variation index-based and eigenvalue variation index-based detection algorithms; our proposed multi-scale covariance matrix descriptor has higher descriptiveness than spin image, PFH, and 3DSC; our proposed bidirectional nearest-neighbor distance ratio algorithm can obtain better feature matching effect than the nearest-neighbor-based and nearest-neighbor distance-ratio-based feature matching. Finally, our proposed 3D surface matching method has a better matching effect than 3D surface matching methods based on spin image, PFH, and 3DSC on the Stanford 3D Scanning Repository, UWA data set and Bologna data set."
  },
  {
    "year": "2017",
    "abstract": "Today, high-level synthesis (HLS) tools are being touted as a means to perform rapid prototyping and shortening the long development cycles needed to produce hardware designs in register transfer level (RTL). In this paper, we attempt to verify this claim by testing the productivity benefits offered by current HLS tools by using them to develop one of the most important and complex processing blocks of modern software-defined radio systems: the forward error correction unit that uses low density paritycheck (LDPC) codes. More specifically, we consider three state-of-the-art HLS tools and demonstrate how they can enable users with little hardware design expertise to quickly explore a large design space and develop complex hardware designs that achieve performances that are within the same order of magnitude of handcrafted ones in RTL. Additionally, we discuss how the underlying computation model used in these HLS tools can constrain the microarchitecture of the generated designs and, consequently, impose limits on achievable performance. Our prototype LDPC decoders developed using HLS tools obtain throughputs ranging from a few Mbits/s up to Gbits/s and latencies as low as 5 ms. Based on these results, we provide insights that will help users to select the most suitable model for designing LDPC decoder blocks using these HLS tools. From a broader perspective, these results illustrate how well today's HLS tools deliver upon their promise to lower the effort and cost of developing complex signal processing blocks, such as the LDPC block we have considered in this paper."
  },
  {
    "year": "2017",
    "abstract": "Simultaneous localization and mapping (SLAM) has a wide range of applications, such as mobile robots, intelligent vehicle localization, and intelligent transportation system. However, loop closure detection is a challenge task for SLAM. This task concerns the difficulty of recognizing already mapped areas. To this end, this paper proposes a novel loop closure detection method called image sequence matching (ISM), which only uses a low-cost monocular camera. This method first divides the already mapped areas into some “feature-zones.”One feature-zone is selected by a novel topological detection model. Then, we adopt two different feature spaces to make sequence matching between query image and feature-zone. Last but not least, we propose a novel clustering method called voting K-nearest neighbor to fuse candidates. As a result, the ISM method has been validated by using collection data sets and public data sets, which were collected along different routes, covering different times and weather conditions. The total lengths of these routes are more than 10 km. Experimental results show that the ISM method can adapt to different times with good detection stability in varying scenarios. The mean of detection errors is all less than 1 frame and the detection accuracies are all more than 90% in these scenarios. Compared with other methods, the proposed method has high accuracy and great robustness."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the rate and outage tradeoffs for orthogonal frequency division multiple access-based device-to-device (D2D) communication frameworks, wherein multiple D2D users coexist with the cellular users in the same cell. Analytical expressions for outage probability for three D2D frameworks, namely underlay, overlay, and cooperative D2D (C-D2D) have been derived. Specifically, for underlay framework, a minimum value of angle θ (an angle between a cellular link and D2D interference link) is derived, for which the target rate and outage probability constraint of both cellular and D2D users are satisfied. For overlay and C-D2D frameworks, an optimal subcarrier sharing scheme is proposed, which not only helps the cellular users to achieve the target quality-of-service but also helps the D2D users to communicate with each other. In addition to above, benefits involved in employing one framework over other have also been investigated. Our results show that for a higher outage probability constraint of the cellular user, the C-D2D framework outperforms the underlay and overlay frameworks."
  },
  {
    "year": "2017",
    "abstract": "With the popularity of smart mobile devices, “context-aware”applications have attracted intense interest, for which location is one of the most essential contexts. Compared with outdoor localization, indoor localization has received much more attention from both academia and industry these days. Given the widespread use of WiFi hotspots, the received signal strength (RSS) fingerprint-based indoor localization technique is considered as a promising and practical solution because of its relatively high accuracy and low infrastructure cost. Inspired by our observation that sparsity is inherent to the WiFi signal, we present a new RSS fingerprint-based indoor localization approach, called SparseLoc. Through sparse representation of the fingerprints, SparseLoc can estimate a smart mobile device's location with a small error most of the time. Although the correlation between neighboring fingerprints affects the localization accuracy, SparseLoc uses the similarity between principal components of fingerprints to alleviate this effect. Based on the empirical experiments, we demonstrate that SparseLoc improves the localization accuracy by over 25% compared with the existing WiFi signal-based localization methods."
  },
  {
    "year": "2017",
    "abstract": "As modern systems become increasingly complex, current security practices lack effective methodologies to adequately address the system security. This paper proposes a repeatable and tailorable framework to assist in the application of systems security engineering (SSE) processes, activities, and tasks as defined in the recently released National Institute of Standards and Technology (NIST) Special Publication 800-160. First, a brief survey of systems-oriented security methodologies is provided. Next, an examination of the relationships between the NIST-defined SSE processes is conducted to provide context for the engineering problem space. These findings inform a mapping of the NIST SSE processes to seven system-agnostic security domains which enable prioritization for three types of systems (conventional IT, cyber-physical, and defense). These concrete examples provide further understanding for applying and prioritizing the SSE effort. The goal of this paper is assist practitioners by informing the efficient application of the 30 processes, 111 activities, and 428 tasks defined in NIST SP 800-160. The customizable framework tool is available online for developers to employ, modify, and tailor to meet their needs."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider transmission optimization in a multiple-input-single-output downlink network, in which each user is wiretapped by a specific eavesdropper. Particularly, we aim to minimize the total transmit power and maximize the sum secrecy rate (SSR) of the system simultaneously, under the assumption that the channel state information (CSI) of the eavesdroppers is not perfectly known at the transmitter. Considering the conflict between two objectives, a multi-objective optimization (MOO) framework based on the weighted Tchebycheff approach is proposed. The formulated MOO problem is non-convex and intractable. To tackle it, several auxiliary variables are introduced and the corresponding Taylor series expansion is employed to linearize the term related to each auxiliary variable. Then, the non-convexity resulting from the CSI errors is recast as a convex one with the aid of S-procedure and Cauchy-Schwarz inequality. Based on above treatments, a robust iterative algorithm is proposed to solve the original problem. Simulation results not only demonstrate the effectiveness of the proposed design, but also unveil the tradeoff between the total transmit power and the SSR."
  },
  {
    "year": "2017",
    "abstract": "Most existing results do not take the effects of backlash hysteresis of actuators into account in a controller design of missile systems, but such hysteresis seems inevitable in practice. In this paper, a robust adaptive neural network (NN) control law for a missile system with unknown parameters and hysteresis input is proposed based on a backstepping technique. The controller is designed by introducing NN approximation, which can be adjusted by an adaptive law based on the backstepping approach. The developed NN controller does not require a priori knowledge of the unknown backlash hysteresis. In particular, unlike existing results on adaptive compensation for unknown backlash hysteresis, the sign of b is no longer needed. It is shown that the designed controller can ensure the stability and tracking performance of the closed-loop system."
  },
  {
    "year": "2017",
    "abstract": "A three-phase cascaded multilevel inverter topology and a hybrid control technique are presented in this paper. The topology is derived from a proposed module of addition and subtraction of sources. An attempt is made to optimize the component count, viz., power switches count, gate drive count, capacitor count, diode count, and source count. The operating modes of basic module and the proposed three-phase topology are explained. The analysis is presented for both symmetrical and asymmetrical configurations. The fundamental frequency hybrid control technique, which is derived from nearest level control (NLC) and switching frequency optimal (SFO) algorithms, is presented. The power semiconductor switches in the topology are driven by gating signals generated with hybrid SFO-NLC technique. The necessary comparisons are done to show the enhanced features with the view of optimized component count and power quality. The simulations are carried out by MATLAB/SIMULINK software tool under both steady state and dynamic conditions. Experimental results are presented to validate the simulation results."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the 3-D massive multiple-input multiple-output (MIMO) for air-to-ground transmission, where an air platform (AP) is equipped with a 2-D rectangular antenna array and communicates with a number of user equipments (UEs) on the ground. By exploiting the slow timevarying parameters, such as channel correlation and angles of departure (AoDs) of UEs, we first propose a location-assisted two-layer precoding scheme for downlink transmission. The first-layer precoding aims to decompose the original massive MIMO system into several low-dimension MIMO systems, with each operating on the orthogonal subspace. Through proper UE clustering, we show that the first-layer precoding matrix can be approximated using a constant-envelope matrix, which results in significant reduction on hardware complexity of AP. The second-layer precoding is designed to eliminate the multi-UE interference within each low-dimension MIMO system. Since the AoD information is usually not perfectly known at AP, we then investigate the effect of AoD uncertainty on the performance of the proposed precoding scheme. In particular, we propose a new analytic method to fast estimate approximately the power loss due to AoD error. Numerical simulations are presented to evaluate the performance of location-assisted precoding under different system parameters, including Rician factor, altitude of AP, and AoD uncertainty. The results show that the location-assisted precoding outperforms match filter precoding and basis expansion-based precoding in the air-to-ground transmission scenarios significantly."
  },
  {
    "year": "2017",
    "abstract": "Fog computing is a paradigm that extends cloud computing to the edge of the network. It can provide computation and storage services to end devices in Internet of Things (IoT). Attribute-based cryptography is a well-known technology to guarantee data confidentiality and fine-grained data access control. However, its computational cost in encryption and decryption phase is linear with the complexity of policy. In this paper, we propose a secure and fine-grained data access control scheme with ciphertext update and computation outsourcing in fog computing for IoT. The sensitive data of data owner are first encrypted using attribute-based encryption with multiple policies and then outsourced to cloud storage. Hence, the user whose attributes satisfy the access policy can decrypt the ciphertext. Based on the attribute-based signature technique, authorized user whose attributes integrated in the signature satisfy the update policy can renew the ciphertext. Specifically, most of the encryption, decryption, and signing computations are outsourced from end devices to fog nodes, and thus, the computations for data owners to encrypt, end users to decrypt, re-encrypt, and sign are irrelevant to the number of attributes in the policies. The security analysis shows that the proposed scheme is secure against known attacks, and the experimental results show that the fog nodes perform most of the computation operations of encryption, decryption, and signing, and hence, the time of encryption for data owner, decryption, re-encryption, and signing for users is small and constant."
  },
  {
    "year": "2017",
    "abstract": "Because wireless sensor networks (WSNs) are becoming increasingly integrated into daily life, solving the energy efficiency problem of such networks is an urgent problem. Many energy-efficient algorithms have been proposed to reduce energy consumption in traditional WSNs. The emergence of software defined networks (SDNs) enables the transformation of WSNs. Some SDN-based WSNs architectures have been proposed and energy-efficient algorithms in SDN-based WSNs architectures have been studied. In this paper, we integrate an SDN into WSNs and an improved software-defined WSNs (SD-WSNs) architecture is presented. Based on the improved SD-WSNs architecture, we propose an energy-efficient algorithm. This energy-efficient algorithm is designed to match the SD-WSNs architecture, and is based on the residual energy and the transmission power, and the game theory is introduced to extend the network lifetime. Based on the SD-WSNs architecture and the energy-efficient algorithm, we provide a detailed introduction to the operating mechanism of the algorithm in the SD-WSNs. The simulation results show that our proposed algorithm performs better in terms of balancing energy consumption and extending the network lifetime compared with the typical energy-efficient algorithms in traditional WSNs."
  },
  {
    "year": "2017",
    "abstract": "Recent years have seen an upsurge in novel techniques to satisfy the ambitious requirements of modern wireless cellular systems in terms of area spectral efficiency whereby users located anywhere in the cell, even at the edge, should be able to obtain a reasonably large throughput. In particular, interference control/cancellation techniques based on different forms of frequency reuse (FR) and coordinated multipoint transmission (CoMP) have shown great potential to realize such a goal. This paper proposes a framework to evaluate the combination of FR and CoMP from a multi-objective performance point of view, where different metrics related to capacity and fairness can be incorporated. This framework rests on a physical layer abstraction derived for the particular case of block diagonalization-based MIMO processing, a widely used technique known to perform close to optimality yet remaining computationally simple. For the derived results to be practically relevant, all wireless channel effects have been considered (e.g., large and small propagation losses, shadowing, and antenna directivity) as well as the existence of per-base power constraints when using CoMP. Numerical simulations show that the design of the FR parameters play a key role in the overall network performance and suggest the use of utility-based functions that combine various metrics as a suitable mechanism to conduct this optimization."
  },
  {
    "year": "2017",
    "abstract": "This paper considers the problem of transmission scheduling of delay-sensitive data over a point-to-point correlated Rayleigh fading channel with channel estimation errors. According to the imperfect channel state information (CSI) and the buffer state, the transmit power and the modulation and coding scheme are determined to jointly maximize the energy efficiency, and minimize transmission delay and overflow probability. To account of the effects of the channel estimation errors, the CSI imperfection is modeled as uncertain sets using the ellipsoidal approximation. Then, the joint optimization problem is formulated using the weighted sum method. Using the idea of online learning, two algorithms are proposed to schedule the delay-sensitive data for the situations with and without the uncertainty bound of channel estimation, respectively. Numerical results indicate that the proposed online learning-based scheduling algorithms can tackle the imperfect CSI issue and improve the system performance in terms of the energy efficiency, transmission delay, and overflow probability. Moreover, the convergence times are very short, which highlights the feasibility of the proposed online learning-based scheduling for practical systems."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a hybrid vision-based reach-to-grasp task planning method for transhumeral prostheses exploiting both vision and electromyography (EMG) signals. The hybrid method mainly consists of 2-1/2D visual servoing module and EMG-based module. The visual servoing intends to align the object on to the center of the palm while correcting its orientation. EMG signals extracted from the remaining muscles of the disabled arm due to amputation are used to control the elbow flexion/extension (FE). While using the 2-1/2D visual servoing module, the object reaching algorithm changes the elbow FE angle to reach the palm toward the object of interest. Initially, the EMG-based module controls the elbow FE. Once an object is detected, the EMG signals emanating from the arm muscles generate a reach request. This process then activates the visual servoing module to bring the palm toward the object. Since both EMGbased module and the visual servoing module are producing elbow FE angles while reaching toward an object, these two modules are integrated to obtain a resultant angle for elbow FE. Experiments are conducted using a simulation environment and a prosthesis to validate the proposed task planning method. The EMGbased module is capable of following the natural elbow FE motion. Moreover, the task planning method is capable of driving the prosthesis toward the object with proper orientation."
  },
  {
    "year": "2017",
    "abstract": "This paper studies a simultaneous wireless information and power transfer multi-input single-output cognitive radio network in which a multi-antenna secondary transmitter sends data streams to multiple single-antenna secondary receivers (SRs) equipped with a power-splitting (PS) structure for information decoding and energy harvesting in the presence of multiple single-antenna primary users (PUs). First, the max-min fair SRs' harvested energy problem is formulated and solved by combining the tight semidefinite relaxation (SDR)-based solution of the transmit power minimization problem with the bisection search method. Second, the balancing problem examines the tradeoff between the worst-user harvested energy at the SR and the interference power at the PU. The proposed solution for this challenging non-convex problem includes two steps. First, the problem with fixed PS ratios is solved using the SDR technique and the tight solution is proved; then, the approximately optimal PS ratios are found using the particle swarm optimization method. Additionally, the closed-form solutions of transmit power minimization and harvested energy maximization problems are derived for the special case where only one SR and one PU are present. Finally, the numerical results demonstrate the effectiveness of the proposed approaches in comparison with two baseline schemes."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the impacts of unreliable backhaul links on the secrecy performance of cooperative single carrier heterogeneous networks in the presence of eavesdroppers are investigated. A two-phase transmitter/relay selection scheme is proposed, where the best transmitter is selected to maximize signal-to-noise ratio at the relays in the first phase and the best relay is chosen in the second phase to minimize the signal-to-interference-plus-noise ratio of the eavesdroppers with the aid of a friendly jammer. Closed-form expressions are derived for the secrecy outage probability, probability of non-zero achievable secrecy rate, and ergodic secrecy rate. The asymptotic performance analysis is furthermore performed to explicitly reveal the impacts of unreliable backhaul links on the secrecy performance. Our results show that the diversity gain cannot be achieved in the presence of imperfect backhaul links."
  },
  {
    "year": "2017",
    "abstract": "Since Cloud Service Provider is a semi-trusted party in cloud storage, to protect data from being disclosed, users' data are encrypted before being uploaded to a cloud server. Undoubtedly, flexible encrypted data sharing is a very important demand required by cloud storage users, whereas few schemes have being designed to satisfy this demand. In this paper, based on conditional proxy broadcast re-encryption technology, an encrypted data sharing scheme for secure cloud storage is proposed. The scheme not only achieves broadcast data sharing by taking advantage of broadcast encryption, but also achieves dynamic sharing that enables adding a user to and removing a user from sharing groups dynamically without the need to change encryption public keys. Moreover, by using proxy re-encryption technology, our scheme enables the proxy (cloud server) to directly share encrypted data to the target users without the intervention of data owner while keeping data privacy, so that greatly improves the sharing performance. Meanwhile, the correctness and the security are proved; the performance is analyzed, and the experimental results are shown to verify the feasibility and the efficiency of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Machine-type communication (MTC) is the key technology to support data transfer among devices (sensors and actuators) in Internet of Things (IoT). Although cellular communication technologies are developed mainly for “human-type”communications, enabling MTC with cellular networks not only improves the connectivity, accessibility, and availability of an MTC network but also has the potential to further drive down the operation cost. However, cellular MTC, especially when applied to low-power massive IoT (mIoT), poses some unique challenges due to the low-cost and low-power nature of an mIoT device. One of the most challenging issues is providing a robust way for an mIoT device to acquire the network under a large frequency offset due to the use of low-cost crystal oscillators and under extended coverage. Although differentiation is a well-known technique for removing impairments caused by frequency offset, its “noise amplification”effect limits its applications in cellular communications due to the fact that cellular communication is typically interference limited. Matched-filter-based detection is, therefore, almost unexceptionally used. We show that the differential technique can actually benefit system acquisition in mIoT, where the use of low-cost crystals is a default. Although the existing system acquisition design in a cellular mIoT system, i.e., NB-IoT, facilitates both techniques, there still remain issues that need to be solved in order to take full advantage of the design. We provide a comprehensive analysis on the performance of two most common techniques when applied in a typical NB-IoT environment based on two factors, the geometry factor and the frequency offset factor. Finally, we derive the operating regions for matched-filter-based detection and differentiation using these two factors, in which the system acquisition performance of the two types of techniques is maximized for NB-IoT."
  },
  {
    "year": "2017",
    "abstract": "Diagonal loading provides a powerful and effective way to improve the robustness of the standard Capon beamformer. Several parameter-free robust adaptive beamformers (RAB) are considered in this paper. We reveal that the performances of them have somewhat degradation when the number of snapshots or that of sensors is large. To solve this problem, we emphatically study the well-known generalized linear combination-based method, the performance of which may degrade severely when the number of sensors increases, and propose a novel parameter-free technique, which is a combination of noise reduction preprocessing technique and truncated minimum mean square error criterion. As most of the parameter-free RAB techniques are very sensitive to the desired signal steering vector mismatch, this paper further proposes to construct a series connection between these RAB techniques and a steering vector estimation (SVE) method, where the SVE is implemented by a convex optimization technique. Simulation results show that the proposed method can achieve a promising performance in comparison with the competing methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate simultaneous wireless information and power transfer in a cooperative communication network consisting of one source, one battery-enabled relay, and one destination node. An amplify-and-forward relaying method is considered, where the relay node harvests energy from the received signal power to charge its battery, which is used to forward the received signal to the destination. We also consider a direct link between the source and the destination. The direct link signal can be combined with the relaying signal at the destination node using maximum ratio combining. Under the delay-limited transmission mode, closed form expressions for outage probability are derived for a battery-enabled relay. Our analytical results reveal the advantage of cooperative relay networks with a direct link. Also, we extend our design to a multiple-relay scenario, where the best relay is selected from the available number of relays, based on the information of relay locations. Finally, we demonstrate from simulation results based on outage probability that our proposed methods are efficient in comparison with Monte Carlo simulations."
  },
  {
    "year": "2017",
    "abstract": "According to the requirement of real-time monitoring of the conversion rate of vinyl chloride in the production process of polyvinyl chloride polymerization and the nonlinearity of the industrial data, the Elman neural network with strong nonlinear performance is chosen to build the soft-sensor model. However, because of the early stage of the Elman neural network to train the connection weights between the layers, the training effect is difficult to guarante with the connection weights. So the whale optimization algorithm (WOA) is adopted to optimize the Elman neural network, to avoid it falling into the local optimum. At the same time, to solve the problem that the position of the search agent is randomly distributed in the initialization process of the WOA algorithm, and to introduce the idea of chaos, a chaos WOA (CWOA) based on the idea of chaos is proposed to improve the diversity of all search agents and egocentricity of agent search by utilizing the chaotic features. At the end of this paper, considering that the input vector dimension is too large, the neural network topology is very large, which will lead to the complexity of the training process. Therefore, the locally linear embedding method is introduced to reduce the dimension of high-dimensional input vectors. The simulation results show that the chaotic whale algorithm can significantly improve the prediction accuracy of economic and technical indexes of PVC polymerization process, which especially has a significant improvement in the prediction effect in the early stage and meets the requirements of real-time control of the production process of the polymerization reactor."
  },
  {
    "year": "2017",
    "abstract": "In recent years, cloud-assisted body area network (CABAN) technologies have made their entrance in the Smart healthcare field, such as Smart home environment, and play a significant role for healthcare data storage, processing, and efficient decision making. However, currently, the CABAN paradigm in the healthcare domain is facing increasing difficulty in handling the huge amount of sensor data that the body sensor devices generate from diverse Smart home applications. Therefore, the challenging is now timely storing, processing, and analyzing of the sensor data in real time to maintain the Quality of Service (QoS) requirements of the caregivers or Smart home applications. QoS, here, is the capacity to support diverse Smart home applications in healthcare with different priorities, performance, and resource requirements. Therefore, in this paper, we present a fast and robust cloud resource allocation model for body sensor devices to ensure QoS for Smart home healthcare applications. We develop the proposed resource allocation algorithm using agent-based modeling (ABM) and ontology. There are few works, which consider ABM and ontology for resource allocation in CABAN platform. Moreover, we used an ABM tool called NetLogo to implement the proposed resource allocation model. The results from the implementation were compared with the results of existing algorithms and found to be promising."
  },
  {
    "year": "2017",
    "abstract": "This paper provides an overview on the rationales in incorporating massive multiple-input multiple-output (MIMO), non-orthogonal multiple access (NOMA), and interleave division multiple access (IDMA) in a unified framework. Our emphasis is on multi-user gain that refers to the advantage of allowing multi-user transmission in massive MIMO. Such a gain can potentially offer tens or even hundreds of times of rate increase. The main difficulty in achieving multi-user gain is the reliance on accurate channel state information (CSI) in the existing schemes. With accurate CSI, both OMA and NOMA can deliver performance not far away from capacity. Without accurate CSI, however, most of the existing schemes do not work well. We outline a solution to this difficulty based on IDMA and iterative data-aided channel estimation (DACE). This scheme can offer very high throughput and is robust against the pilot contamination problem. The receiver cost is low, since only maximum ratio combining (MRC) is involved and there is no matrix inversion or decomposition. Under time division duplex, accurate CSI acquired in the up-link can be used to support low-cost down-link solutions, such as zero forcing. These findings offer useful design considerations for future systems."
  },
  {
    "year": "2017",
    "abstract": "Software-defined satellite network (SDSN) is a novel framework, which brings softwaredefined network technologies in the satellite networks. It has great potential to achieve effective and flexible management in the satellite networks. There are two burning issues to be solved for the flow table management in SDSN. First, the ternary content addressable memory (TCAM) space is limited on satellites and the flow table size should be reduced. Second, the frequent handovers will lead to an increase in the flow table size in SDSN. Due to the limited flow table space, a lot of flows will be dropped if the flow table is full during the handover. To address these issues, we first give a description of our focused flow table management problems. Then, we propose SAT-FLOW, a multi-strategy flow table management method for SDSN. SAT-FLOW considers three key points, limited TCAM space, classified traffic, and handover. SAT-FLOW contains two heuristic algorithms, named dynamic classified timeout (DCT) algorithm and timeout strategybased mobility management (TSMM) algorithm. DCT aims to reduce the flow table size and TSMM aims to reduce the drop flows during the handover. We implement SAT-FLOW and conduct contrast experiments. The experimental results verify the good performance in terms of transmission quality, idle_timeout values distribution, a 15.27%-24.34% decrease in flow table size, an 8.2%-10.4% decrease in drop-flow rate, and a 4.92%-5.7% decrease in table misses for the high priority traffic during the handover."
  },
  {
    "year": "2017",
    "abstract": "Ambient backscatter is a new technology that uses ambient signals to enable communication between battery-free tags (or sensors) and readers. Previous studies on ambient backscatter focused on scenarios with only one tag. In this paper, we investigate the ambient backscatter communication system with multiple tags and analyze the performance of tag selection. Specifically, we formulate a tag selection scheme and design the corresponding detection method. Our results indicate that obtaining the closed-form bit-error rate (BER) in such cases is challenging; hence, we provide a solution for deriving an approximate BER. The simulation results show that the approximated BER curves are in agreement with the exact curves."
  },
  {
    "year": "2017",
    "abstract": "The lack of attention to the correlation between the attributes of usability requirements leads to several problems with software development. This paper presents a novel framework that focuses on the mapping of usability requirements attributes to the linguistic assessment from the users using fuzzy logic. Our proposed framework prioritizes conflicting usability requirements attributes. For implementation, we have used MATLAB Fuzzy Logic Toolbox. This proposed framework is aimed at helping the requirement analyst in taking better decisions by automating the whole process of identifying and resolving usability requirements conflicts. The major task in the proposed system involves determining the numerical value for each attribute considering their respective importance in different quantitative and qualitative evaluation standards. On the basis of numerical value, conflicts and their respective severities are identified."
  },
  {
    "year": "2017",
    "abstract": "Since the noise statistics of large-scale battery energy storage systems (BESSs) are often unknown or inaccurate in actual applications, the estimation precision of state of charge (SOC) of BESSs using extended Kalman filter (EKF) or unscented Kalman filter (UKF) is usually inaccurate or even divergent. To resolve this problem, a method based on adaptive UKF (AUKF) with a noise statistics estimator is proposed to estimate accurately SOC of BESSs. The noise statistics estimator based on the modified Sage-Husa maximum posterior is aimed to estimate adaptively the mean and error covariance of measurement and system process noises online for the AUKF when the prior noise statistics are unknown or inaccurate. The accuracy and adaptation of the proposed method is validated by the comparison with the UKF and EKF under different real-time conditions. The comparison shows that the proposed method can achieve better SOC estimation accuracy when the noise statistics of BESSs are unknown or inaccurate."
  },
  {
    "year": "2017",
    "abstract": "The combined use of ultrasound pulse-echo intensity and Doppler shift frequency is examined as a means to measure strong unsteady three-phase pipe flows of a gas and two liquids. With air, oil, and water as components of the fluid media, particular attention is given to analyze ultrasound responses at the air-oil and oil-water interfaces. Reciprocating slugging is generated inside a 55-mm-diameter circular pipe, of which edges oscillate vertically at a controlled frequency. We use an ultrasound velocity profiler to obtain the 1-D cross-sectional distributions of the instantaneous flow velocity at the sampling rate of 60 Hz. All the measurements are realized by a single ultrasound transducer located outside the pipe. Measurement accuracy is validated using a high-speed camera coupled with particle image velocimetry that is synchronized with the profiler. The results demonstrate that the proposed technique works properly in sensing both interfaces as well as in-phase flow velocity distributions. In addition, multiphase volume flow rates for the constituents are obtained by velocity profile integration assuming vertical phase stratification in an approximation."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel distributed coordination load shedding (DCLS) approach for an islanded microgrid (MG) using sub-gradient algorithm of multi-agent system. The main objective is to achieve practical and optimal LS and obtain an optimum amount of load to be shed in a fully distributed manner under large disturbances. To coordinate the controllable loads (CLs) in an MG, an LS level (LSL) is first defined and evaluated locally to take the CL capacity and the LS willingness into consideration. Then, by updating the LSLs and the local frequency deviation measured based on frequency-inertia dynamics response, the proposed DCLS can be accomplished based on the sub-gradient algorithm. More importantly, only local information is needed to be updated during the entire DCLS process. Hence, the power supply demand balance can be well maintained, the utilization of LS can be significantly improved, and the requirements for communication topology changes can be adaptively met in a fully distributed way. The simulation results indicate that the proposed sub-gradient-based distributed coordination algorithm and corresponding DCLS are effective and adaptive."
  },
  {
    "year": "2017",
    "abstract": "Cloud datacentres are acknowledged as being massive energy consumers, which may have significant environment impacts. Service providers have an ethical responsibility to reduce the environmental impact of server resources and a simultaneous and complementary commercial desire to reduce energy costs. Zombie servers in the datacenters are one of the primary sources of undesirable energy expenditures by incurring idle resources during task execution. This paper investigates the cause, impact and energy-related implications of zombie servers. Important outcomes of this paper are the characterization of the diversity among the workload behaviors in resource consumption and the quantification of the presence of idle CPU and memory resources during task execution causing server zombieness. The undesirable power consumption of zombie servers is determined based on the profiles of currently available servers and their corresponding environmental implications are illustrated in this paper. Empirical analysis shows that cloud workloads are highly heterogeneous in resource consumption pattern and CPU resources may display 75.6% of idleness relative to their allocated level, while memory is 25.5% idle. The report concludes that significant reductions in power consumption and CO2 emission can be achieved by provisioning a realistic level of resources to servers, which are scaled to suit the anticipated workloads."
  },
  {
    "year": "2017",
    "abstract": "Shortest path queries have been widely used in location-based services (LBSs). To calculate the shortest path from an origin to a destination, an LBS provider usually needs to know the map data of the underlying road network, which can be rather costly especially if such data need to be kept continuously and up to date. A cost-effective way is that LBS providers outsource the shortest path query processing to cloud-based mapping services such as Google Maps, by retrieving the detailed path information from them through external requests. Due to the high cost of accessing data through external requests and the usage limits of mapping services, we propose two optimization techniques in this paper, namely, path sharing and path caching, to reduce the number of external requests and the user query response time. Unlike previous work where the underlying road network is given, this paper optimizes path query processing only based on query origins and destinations. The basic idea of path sharing optimization is that the path information of a query can be shared with another query q if q values origin and destination both lie on the path. To achieve this, we propose an effective method to compute whether or not a query origin/destination lies on a path only based on the Euclidean distance between them. Path caching, an extension of path sharing, lets an LBS provider answer path queries directly based on cached paths. To accomplish this, we first formulate the problem of constructing path cache as a knapsack problem and design a greedy algorithm to solve it; then, we devise an effective cache structure to support efficient cache lookup. Extensive experiments on Bing Maps and real data sets are conducted, and the results show the efficiency, scalability, and applicability of our proposed approaches."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, people are overwhelmingly exposed to various kinds of information from different information networks. In order to recommend users with the information entities that match their interests, many recommendation methods have been proposed so far. And some of these methods have explored different ways to utilize different kinds of auxiliary information to deal with the information sparsity problem of user feedbacks. However, as a special kind of information sparsity problem, the “cold start” problem is still a big challenge not well-solved yet in the recommendation problem. In order to tackle the “cold start” challenge, in this paper, we propose a novel recommendation model, which integrates the auxiliary information in multiple heterogeneous information networks (HINs), namely the Cross-HIN Recommendation System (CHRS). By utilizing the rich heterogeneous information from meta-paths, the CHRS is able to calculate the similarities of information entities and apply the calculated similarity scores in the recommendation process. For the information entities shared among multiple information networks, CHRS transfers item latent information from other networks to help the recommendation task in a given network. During the information transfer process, CHRS applies a domain adaptation matrix to tackle the domain difference problem. We conduct experiments to compare our CHRS method with several widely employed or the state-of-art recommendation models, and the experimental results demonstrate that our method outperforms the baseline methods in addressing the “cold start” recommendation problem."
  },
  {
    "year": "2017",
    "abstract": "This paper describes an on-road air quality monitoring and control approach by proposing an agent-based system for modeling the urban road network infrastructure, establishing the real-time and predicted air pollution indexes in different road segments and generating recommendations and regulation proposals for road users. This can help by reducing vehicle emissions in the most polluted road sections, optimizing the pollution levels while maximizing the vehicle flow. For this, we use data sets gathered from a set of air quality monitoring stations, embedded low-cost e-participatory pollution sensors, contextual data, and the road network available data. These data are used in the air quality indexes calculation and then the generation of a dynamic traffic network. This network is represented by a weighted graph in which the edges weights evolve according to the pollution indexes. In this paper, we propose to combine the benefits of agent technology with both machine learning and big data tools. An artificial neural networks model and the Dijkstra algorithm are used for air quality prediction and the least polluted path finding in the road network. All data processing tasks are performed over a Hadoop-based framework: HBase and MapReduce."
  },
  {
    "year": "2017",
    "abstract": "The carrier of the digital watermark expands from audio signals to radio frequency (RF) signals. Unlike audio signals, RF signals, such as the watermark transmission carrier, must be correctly demodulated with the watermark signals so that the distortion of the digital carrier embedded with the watermark is associated with the change in bit error rate. Based on the spread spectrum watermarking scheme, the distortion of the digital carrier signal is redefined, and the channel capacity expression of the watermarking scheme is derived. In addition, the optimal parameters to achieve the maximal channel capacity are discussed, and the constraint relation between the channel capacity and the allowable distortion is investigated."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the deployment of collaborative estimation and actuation scheme of wireless sensor and actuator networks for the agriculture industry. In our proposed scheme, sensor nodes conduct a local estimation based on the Kalman filter for enhancing the estimation stability and further transmit data to the actuator nodes under a multi-rate transmission mode for enhancing the overall energy efficiency of the wireless network. Considering the mutual effect of related clusters, a collaborative actuation scheme of actuator nodes is integrated into our proposed scheme for improving the estimation accuracy and convergence speed. With an accurate estimation of the changes in the environmental parameters, combining the fuzzy neural network with the PID control algorithm, the actuator exerts reliable control over the environmental parameters. Performance evaluations and simulation analysis conducted based on the effects of temperature demonstrate the effectiveness of our proposed scheme in controlling the greenhouse environmental changes for in the agriculture industry."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a supervisory control strategy for resilient chiller plants in the presence of condenser fouling. Fouling results in off-nominal performance of chiller parameters, such as increased refrigerant mass flow rate, compressor motor speed, discharge pressure, and discharge temperature. These effects further lead to faster deterioration of condenser pipes and tubes, and increase the risk of early motor failures. Thus, the main objective of this paper is to provide resilience, i.e., to bring the system parameters back to normalcy, and thereby protect the system from the adverse effects of fouling and improve its life expectancy while ensuring energy efficiency and meeting the desired cooling load. The supervisory control strategy presented here incorporates fault detection and diagnosis (FDD) and resilient control for mitigating the effects of condenser fouling. A computationally efficient and robust FDD scheme enables the estimation of the condenser fouling level using optimal sensor selection and statistical classifiers, thus facilitating condition-based maintenance. On the other hand, the resilient control scheme enables redistribution of load between chillers in order to reduce the load on faulty equipment in an energy-efficient manner, while still providing the required overall cooling load. The performance of this method is tested and validated using a high-fidelity chiller plant model and the proposed strategy is shown to diagnose condenser fouling with a high accuracy and effectively mitigate the effects of fouling at low computational cost. It is shown that the supervisory controller is able to meet the desired building load requirements at lower energy consumption, as compared with no supervisory control."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a thorough literature review on the fault mechanism and diagnostic techniques for a range extender hybrid electric vehicle, which is one of the most feasible electric vehicles. However, extensive fault diagnosis research has been done on the diesel engine or a generator, but studies on the range extender are still limited, which is a coupling device of an engine-generator shaft. It has many coupling faults except to the single failure mode of the diesel engine or the generator. In this paper, the research development of the fault mechanism and fault diagnosis has been reviewed and analyzed. In addition, the trends in fault diagnosis technologies have been discussed, which provides a theoretical foundation for the engineering application of the condition monitoring and fault diagnosis of the electric vehicle range extender."
  },
  {
    "year": "2017",
    "abstract": "The cognitive dynamic system (CDS) is a structured physical model and research tool inspired by certain features of the human brain. One such feature is the predictive adaptation of the organism to the future environment. From an engineering perspective, this property of the brain is of profound practical importance, particularly when the system, in the pursuit of goals or performing tasks, confronts unexpected adverse events or obstacles, which in the aggregate are commonly referred to as risk. To avert risk efficiently, much of the information processed in the past by the CDS is available for processing new information in one of the system's components termed the perceptor. In the face of uncertainty, the perceptor will provide the processed information to the executive in order for the latter to avoid probable risk. To that effect, the executive will be fitted with Bayesian filtering mechanisms that will guide the CDS to its goal through timely risk-avoiding actions. Those mechanisms not only have unique engineering applications but also potential value for understanding the predictive-adaptation property of the brain, which modern neuroscience attributes to the prefrontal cortex."
  },
  {
    "year": "2017",
    "abstract": "A planar cavity is proposed, designed, and implemented with a hybrid substrate integrated waveguide (SIW) and periodically drilled SIW (PDSIW) structure. Air holes are added to synthesize a lower effective permittivity. The periodicity can increase the stored energy and improve the quality factor. The optimal ratio between the two permittivities is investigated. The measured results show that the proposed resonator has an unloaded quality factor (Qu) of 815, which is 53% higher than its standard SIW counterpart. To demonstrate the potential of the proposed PDSIW cavity, a third-order filter is designed and implemented through the proposed cavity, and it is then compared with filters of different orders. The new filter with a cavity shows performance enhancements in terms of both loss and bandwidth. The SIW resonator can be a promising element for use in the design of high-performance microwave filters and oscillators."
  },
  {
    "year": "2017",
    "abstract": "Multimodal data can be used to gain additional perspective on a phenomenon. For applications, such as security and the detection of suspicious activity, the need to aggregate and analyze data from multiple modes is vital. Recent research in suspicious behavior detection has introduced methods for identifying and scoring dense blocks in multivariate tensors, which are consistent indicators of suspicious activity. None yet, however, have proposed a method for the merging and analysis of multiple modes of data for suspicious behavior, especially when the set of items described in each data set do not match-that is, the data is partially paired-which is common when data sets originate from different sources. Neither has a method been described for dealing with the similar case of incomplete data. This paper introduces a technique for multimodal data analysis for suspicious activity detection when the data are only partially paired and/or incomplete. The method is applied to synthetic and real data, demonstrating strong precision and recall even in poorly paired cases."
  },
  {
    "year": "2017",
    "abstract": "Big data analytics has simplified the processing complexity of extremely large data sets through ecosystems, such as Hadoop, MapR, and Cloudera. Apache Hadoop is an open-source ecosystem that manages large data sets in a distributed environment. MapReduce is a programming model that processes massive amount of unstructured data sets over Hadoop cluster. Recently, Hadoop enhances its homogeneous storage function to heterogeneous storage and stores data sets into multiple storage media, i.e., SSD, RAM, and DISK. This development increases the performance of data block placement strategy and allows a client to store large data sets into multiple storage media efficiently than homogeneous storage. However, this evolution increases the consumption of computing capacity and memory usage over MapReduce job scheduling. The scheduler processes MapReduce job into homogeneous container having configuration of CPU, memory, DISK volume, and network I/O, and accesses, processes, and stores data sets over heterogeneous storage media. This produces a processing latency of locating and pairing source data set to MapReduce tasks and results an abnormal high consumption of computing capacity and memory usage in a Datanode. Similarly, when scheduler assigns MapReduce jobs to multiple Datanodes, the same processing latency can severely affect the performance of whole cluster. In this paper, we present Storage-Tag-Aware Scheduler (STAS) that reduces processing latency by scheduling MapReduce jobs into heterogeneous storage containers, i.e., SSD, DISK, and RAM container. STAS endorses job with a tag of storage media, such as JobSSD, JobDISK, and JobRAM and parses them into heterogeneous shared-queues, which assign processing configuration to enlist jobs. STAS manager then schedules shared-queue jobs into heterogeneous MapReduce containers and generates an output into storage media of the cluster. The experimental evaluation shows that STAS optimizes the consumption of computing capacity a..."
  },
  {
    "year": "2017",
    "abstract": "Negative selection algorithm (NSA) is an important method for generating detectors in artificial immune systems. Traditional NSAs randomly generate detectors in the whole feature space. However, with increasing dimensions, data samples aggregate in some specific subspaces, not uniformly distributed in the whole space. The detectors randomly generated by traditional NSAs cannot exactly fall into these specific subspaces, which results in a low coverage of detectors and a poor performance in a high-dimensional space. To overcome this defect, an improved real NSA based on subspace density seeking (SDS-RNSA) is proposed in this paper. In an SDS-RNSA, a subspace density seeking algorithm is adopted to procure the dense subspace regions of samples. Then, detectors are generated in each subspace region to cover up nonself-region efficiently and improve the performance of the algorithm. During the process of detector generation, the redundancy of candidate detectors is calculated, and the redundant is eliminated to minimize the time expense of the algorithm. Experimental results demonstrate that, compared with the classic NSAs, the SDS-RNSA can significantly improve the detection rate with an approximative false alarm rate and a smaller time expense. At the best case, the detection rate of the SDS-RNSA is increased by 14.7%, while the time expense is decreased by 78.1%."
  },
  {
    "year": "2017",
    "abstract": "The chronic growth of networked complexities in today's world, now require highly efficient evolvable systems. However, diverse open issues and inabilities are facing urban planning practice and social sciences due to the limitations of artificial intelligence planning tools. These incapacities have relatively limited our ability to perceive and handle possible present and future temperamental situations in socio-physical contexts and in real-time modes. Here, we theoretically present two simple philosophical and systematic causal models to help software engineers to understand this philosophical and complexity dilemma from an urban planning perspective. The first model evaluates the reliance on perceptual and bounding trajectories. It discusses discrete and finite-expert systems that perceive specific parts of self-organization's complexities, while bounding limited facets only of general intelligence to address certain issues in urban planning and social contexts. This implies the second causal model that is based on aligning to urban self-organizational happenings, by putting philosophical foundations for a responsive artificial superintelligence (ASI). This proposed ASI is based on connecting between complex adaptive systems in our contexts by open-endedly hosting and operating infinite expert systems to reflect different fields and functions, toward asymptotic infinite intellectual capacity."
  },
  {
    "year": "2017",
    "abstract": "Mental stress has become a social issue and could become a cause of functional disability during routine work. In addition, chronic stress could implicate several psychophysiological disorders. For example, stress increases the likelihood of depression, stroke, heart attack, and cardiac arrest. The latest neuroscience reveals that the human brain is the primary target of mental stress, because the perception of the human brain determines a situation that is threatening and stressful. In this context, an objective measure for identifying the levels of stress while considering the human brain could considerably improve the associated harmful effects. Therefore, in this paper, a machine learning (ML) framework involving electroencephalogram (EEG) signal analysis of stressed participants is proposed. In the experimental setting, stress was induced by adopting a well-known experimental paradigm based on the montreal imaging stress task. The induction of stress was validated by the task performance and subjective feedback. The proposed ML framework involved EEG feature extraction, feature selection (receiver operating characteristic curve, t-test and the Bhattacharya distance), classification (logistic regression, support vector machine and naïve Bayes classifiers) and tenfold cross validation. The results showed that the proposed framework produced 94.6% accuracy for two-level identification of stress and 83.4% accuracy for multiple level identification. In conclusion, the proposed EEG-based ML framework has the potential to quantify stress objectively into multiple levels. The proposed method could help in developing a computer-aided diagnostic tool for stress detection."
  },
  {
    "year": "2017",
    "abstract": "Random unitary beamforming (RUB) achieves multiuser diversity gain over multiple-input multiple-output broadcast channels with partial channel state information (CSI). RUB can asymptotically achieve the same growth of rate M log log K as the optimal dirty paper coding or sub-optimal zero-forcing beamforming, which need full CSI at the transmitter. In this paper, we propose energy efficient RUB systems that select the optimal number of streams and transmission power to maximize energy efficiency (EE). In contrast to other beamforming schemes that use full CSI, optimizing RUB in terms of EE is a difficult task due to the CSI constraints. To solve this problem, we first select the EE-optimal number of streams and transmission power by using the statistical characteristics of RUB, which have been studied in previous works. Next, based on partial CSI feedback from users, we propose the method whereby the transmitter of RUB can adaptively control the transmission power. Simulation results demonstrate that our proposed systems can improve the EE performance of RUB and that the analytical results derived in this paper are accurate."
  },
  {
    "year": "2017",
    "abstract": "Many network technologies, including cellular, Wifi, and WiMAX, coexist in wireless networks. With the increasing demand on mobility-based network services on account of the popularity of smart devices, users expect network environments in which they can readily access the Internet at any time and place. An effective handover decision is necessary to provide users with continued services while they are mobile. Existing studies on handover have strived to improve the mobility of the object moving and communicating on the ground. However, a traditional handover decision is not suitable for a drone moving and communicating in 3-D space. Therefore, in this paper, parameters that represent the characteristics of drones communicating within 3-D space are defined, including speed limit and coverage. Using these parameters as input variables, a fuzzy inference method for the handover decision is proposed. A fuzzy inference system is composed of four steps. First, terminal-related information is analyzed to select the factors that can affect the drone handover decision. Second, the input data values are converted into membership functions. Third, the reasoning rules for the handover decision are designed and applied. Finally, the handover is decided by considering the current information of the drone. The computation of the number of handover decisions has shown that considering the terminal-related parameters and the network-related parameters has a positive effect on the handover decision."
  },
  {
    "year": "2017",
    "abstract": "With the popularity of cloud computing and high performance computing, the size and the amount of the datacenter develop rapidly, which also causes the serious challenges on energy consumption. Dynamic voltage and frequency scaling (DVFS) is an effective technique for energy saving. Many previous works addressed energy-officiate task scheduling based on DVFS. However, these works need to know the total workload (execution time) of tasks, which is difficult for some real-time tasks requests. In this paper, we propose a new task model that describes the QoS requirements of tasks with the minimum frequency. In addition, we define energy consumption ratio (ECR) to evaluate the efficiency of different frequencies under which to execute a take. Thus, it is possible to convert the energy-efficient task scheduling problem into minimizing the total ECR. By transforming the problem to the variable size bin packing, we prove that the minimization of ECR is NP-hard in this paper. Because of the difficulty of this problem, we propose task allocation and scheduling methods based on the feature of this problem. The proposed methods dispatch the coming tasks to the active servers by using servers as less as possible and adjust the execution frequencies of relative cores to save energy. When a task is finished, we propose a processor-level migration algorithm to reschedule remaining tasks among processors on an individual server and dynamically balance the workloads and lower the total ECR on this server. The experiments in the real test-bed system and simulation show that our strategy outperforms other ones, which verifies the good performance of our strategy on energy saving."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a scheme to reduce the number of flow entries permanently stored in an OpenFlow switch and the number of configuration messages from a controller in a software-defined network (SDN). In an SDN, a flow table in an OpenFlow switch is used to instruct packets. The flow table consists of flow entries decided by the controller. A flow request is sent from the OpenFlow switch to the controller if the incoming packet does not match any flow entry in the flow table. The controller's central processing unit may be overloaded to handle user requests, since the user requests for different data types have been rapidly increasing. As a result, flow configuration in switches is delayed. Moreover, the control plane may be flooded by configuration messages of those requests. A scheme to permanently keep the flow entries in the switch can reduce the number of requests. However, a large number of permanent flow entries is required. Other switch features may be degraded, since there is not enough memory in the flow table to implement those features. In the proposed scheme, switches in the network are divided into multiple regions. In order to guide packets from sources to destinations, the flow table incorporating the concept of two multiprotocol label switching tags is re-designed. One tag directs a packet from a source switch to an edge switch in the destination region. The other tag directs the packet from that edge switch to another switch in the same region. A mathematical model for the proposed scheme is formulated as an integer linear programming to determine a set of switches in each region so that the total number of permanent flow entries in the network can be minimized. The performance of the proposed scheme is analyzed. Moreover, the proposed scheme is implemented and demonstrated via Japanese Science Information Network 5."
  },
  {
    "year": "2017",
    "abstract": "Advances and commoditization of media generation devices enable capturing and sharing of any special event by multiple attendees. We propose a novel system to collect individual video streams (views) captured for the same event by multiple attendees, and combine them into multi-view videos, where viewers can watch the event from various angles, taking crowdsourced media streaming to a new immersive level. The proposed system is called Cloud-based Multi-View Crowd sourced Streaming (CMVCS), and it delivers multiple views of an event to viewers at the best possible video representation based on each viewer's available bandwidth. The CMVCS is a complex system having many research challenges. In this paper, we focus on resource allocation of the CMVCS system. The objective of the study is to maximize the overall viewer satisfaction by allocating available resources to transcode views in an optimal set of representations, subject to computational and bandwidth constraints. We choose the video representation set to maximize QoE using Mixed Integer Programming. Moreover, we propose a Fairness-Based Representation Selection (FBRS) heuristic algorithm to solve the resource allocation problem efficiently. We compare our results with optimal and Top-N strategies. The simulation results demonstrate that FBRS generates near optimal results and outperforms the state-of-the-art Top-N policy, which is used by a large-scale system (Twitch)."
  },
  {
    "year": "2017",
    "abstract": "To enable multi-stream transmission and increase the achievable rate, a hybrid digital/analog precoding structure is usually adopted in millimeter-wave (mmWave) MIMO systems. However, it may require matrix operations with a scale of antenna size, which is generally large in mmWave communications. Moreover, the channel estimation is also rather time-consuming due to the large number of antennas at both Tx/Rx sides. In this paper, a low-complexity overall channel estimation and hybrid precoding approach is proposed. In the channel estimation phase, a hierarchical multi-beam search scheme is proposed to fast acquire NS (the number of streams) multipath components (MPCs)/clusters with the highest powers. In the hybrid precoding phase, the analog and digital precodings are decoupled. The analog precoding is designed to steer along the NS acquired MPCs/clusters at both Tx/Rx sides, shaping an NS × NS baseband effective channel, while the digital precoding is performed in the baseband with the reduced-scale effective channel. Performance evaluations show that, compared with the state-of-the-art scheme, while achieving a close or even better performance when the number of radio frequency chains or streams is small, both the time complexity of the channel estimation and the computational complexity of the hybrid precoding are reduced."
  },
  {
    "year": "2017",
    "abstract": "NAND flash memory has many advantages, including a small form factor, non-volatility, and high reliability. However, problems caused by physical limitations, such as asymmetric I/O latencies and outof-place updates, still need to be resolved. By using a probability of reference (PR) to select a candidate page as the victim page, this paper presents a novel buffer replacement algorithm called PR least recently used to enhance the flash memory performance. To predict whether a page may be referenced in the future, three variables are used to calculate a page's PR. In addition, we improve the performance overhead of the number of write operations, the hit ratio, and the runtime using a novel PR strategy. The algorithm is implemented and tested on the flash simulation platform Flash-DBSim. The results indicate that our algorithm provides improvements of up to 7% for the hit ratio with an improvement of up to 36.7% for the overall runtime compared with other approaches."
  },
  {
    "year": "2017",
    "abstract": "Le Havre Port Authority is putting into service a multimodal hub terminal with massified hinterland links (trains and barges) in order to restrict the intensive use of roads, to achieve a more attractive massification share of hinterland transportation and to provide a river connection to its maritime terminals that do not currently have one. This paper focuses on the rail-rail transshipment yard of this new terminal. In the current organizational policy, this yard is divided into two equal operating areas, and, in each one, a crane is placed, and it is equipped with reach stackers to enable container moves across both operating areas. However, this policy causes poor scheduling of crane moves, because it gives rise to many crane interference situations. For the sake of minimizing the occurrence of these undesirable situations, this paper proposes a multi-agent simulation model including an improved strategy for crane scheduling. This strategy is inspired by the ant colony approach and it is governed by a new configuration for the rail yard's working area that eliminates the use of reach stackers. The proposed simulation model is based on two planner agents, to each of which a time-horizon planning is assigned. The simulation results show that the model developed here is very successful in significantly reducing unproductive times and moves (undesirable situations), and it outperforms other existing simulation models based on the current organizational policy."
  },
  {
    "year": "2017",
    "abstract": "Future 5G networks will serve a variety of applications that will coexist on the same spectral band and geographical area in an uncoordinated and asynchronous manner. It is widely accepted that using cyclic prefix-orthogonal frequency division multiplexing (CP-OFDM), the waveform used by most current communication systems, will make it difficult to achieve this paradigm. Especially, CP-OFDM is not adapted for spectral coexistence because of its poor spectral localization. Therefore, it has been widely suggested to use filter bank-based multicarrier (FB-MC) waveforms with enhanced spectral localization to replace CP-OFDM. Especially, FB-MC waveforms are expected to facilitate coexistence with legacy CP-OFDM-based systems. However, this idea is based on the observation of the power spectral density of FB-MC waveforms only. In this paper, we demonstrate that this approach is flawed and show that interference between FB-MC and CP-OFDM systems should be rated on precise estimation of the error vector magnitude. Our analysis, which is confirmed through simulations on both flat and frequency selective channels and software radio implementation, shows that the interference caused by FB-MC waveforms on CP-OFDM receivers is multiple orders of magnitude higher than expected in the literature. Finally, our results show that using FB-MC waveforms does not facilitate coexistence with CP-OFDM-based systems to a high extent."
  },
  {
    "year": "2017",
    "abstract": "The smart cities vision is inexorably turning into a reality. Among the different approaches used to realize more intelligent and sustainable environments, a common denominator is the role that information and communication technologies will play. Moreover, if there is one of these technologies that emerges among the rest, it is the Internet-of-Things (IoT). The ability to ubiquitously embed sensing and actuating capabilities that this paradigm enables is at the forefront of the technologies driving the urban environments transformation. However, there are very little practical experiences of the IoT infrastructure deployment at a large scale. This paper presents practical solutions to the main challenges faced during the deployment and management of a city-scale IoT infrastructure, which encompasses thousands of sensors and other information sources. The experience we have gained during the deployment and operation of the IoT-based smart city infrastructure carried out at Santander (Spain) has led to a number of practical lessons that are summarized in this paper. Moreover, the challenges and problems examples, excerpted from our own real-life experience, are described as motivators for the adopted solutions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the problem of distributed fault detection and isolation is considered for multiagent systems with time delays. An adversarial observer is designed for each agent, using local information of the agent, to estimate the external adversaries. By utilizing the adversarial observer, the detection of the faults caused by external incipient adversaries can be handled. Moreover, a software architecture is proposed for each agent; this can guarantee the multi-agent systems immune to the agents intruded by external adversaries. At last, numerical simulations are employed to verify the validity of the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "Due to the advantages of high energy density, no memory effect, and long cycle life, Li-ion batteries are being widely studied and proverbially used as power sources for electric vehicles. The performance of Li-ion battery systems is largely dependent on the thermal conditions and the temperature gradient uniformity inside. In order to tackle with the inconsistency problems of temperature distribution among battery cells in a battery pack, a thermal model for a cylindrical battery based on the finite-element method was developed. Physical structure and electrochemical reactions were both considered, and the initial conditions, boundary conditions, and thermal characteristic parameters of the battery components were determined through theoretical calculation and experiments. The discharge thermal characteristics were further investigated. In addition, the experiments were conducted to verify the accuracy of the presented model. Comparing the theoretical analysis with experimental results, it shows that the relative errors between the simulation and the tests are small at varied ambient temperatures and discharge rates. Therefore, the model can be efficiently applied to predicting the thermal behaviors of Li-ion batteries in practical applications."
  },
  {
    "year": "2017",
    "abstract": "International deep seabed resource surveys have accumulated a large amount of valuable marine geochemical data. These data, however, derive from a number of autonomous heterogeneous information sources that show the characteristics of big data, i.e., multidisciplinary, multidimensional, multisemantic, and with strong correlations. The traditional database federation method is thus not applicable. To achieve marine geochemical data interoperation, an approach is proposed in this paper. The approach first builds a marine sample ontology (MSO) based on marine geochemical metadata standards. With support of the MSO ontology, which serves as a specification for the semantics and model of multisource heterogeneous data, the data integration and unified query APIs are accomplished across different databases. The experiment is applied with three databases: the ICP-AES database model in the ODP project, the PetDB marine petrology database model compiled at the Lamont-Doherty Earth Observatory, and the GEOROC database model operated by the German Max Planck Institute. The experimental results show that this method not only improves the efficiency of the marine geochemical data integration but also realizes the reuse of data and models under the premise of ensuring the independence, security, and timeliness of the data sources."
  },
  {
    "year": "2017",
    "abstract": "One of the most demanding skills for a mobile robot is to be intelligent enough to know its own location. The global localization problem consists of obtaining the robot's pose (position and orientation) in a known map if the initial location is unknown. This task is addressed applying evolutionary computation concepts (Differential Evolution). In the current approach, the distances obtained from the laser sensors are combined with the predicted scan (in the known map) from possible locations to implement a cost function that is optimized by an evolutionary filter. The laser beams (sensor information) are modeled using a combination of probability distributions to implement a non-symmetric fitness function. The main contribution of this paper is to apply the probabilistic approach to design three different cost functions based on known divergences (Jensen-Shannon, Itakura-Saito, and density power). The three metrics have been tested in different experiments and the localization module performance is exceptional in regions with occlusions caused by different obstacles. This fact validates that the non-symmetric probabilistic approach is a suitable technique to be applied to multiple metrics."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a decentralized sampled-data tracking controller design technique for Takagi-Sugeno fuzzy interconnected systems is proposed. The overall large-scale system is assumed to consist of fuzzy subsystems with unknown but norm-bounded interconnections. This paper focuses mainly on the design of a sampled-data decentralized model reference tracking controller based on the exact discretization approach, by which the resulting large-scale error dynamics becomes asymptotically stabilized with a predefined H-infinity performance criterion. To this end, we first design a continuous-time decentralized tracking controller based on the proposed design technique. After that, by using the discrete-time fuzzy Lyapunov function, the proposed design technique is extended to cover a sampled-data tracking controller design. The proposed controller design techniques are formulated in terms of linear matrix inequalities. Finally, numerical examples are given to show the effectiveness of the proposed methods by comparing them with other methods."
  },
  {
    "year": "2017",
    "abstract": "As the population in cities continues to increase rapidly, air pollution becomes a serious issue from public health to social economy. Among all pollutants, fine particulate matters (PM2.5) directly related to various serious health concerns, e.g., lung cancer, premature death, asthma, and cardiovascular and respiratory diseases. To enhance the quality of urban living, sensors are deployed to create smart cities. In this paper, we present a participatory urban sensing framework for PM2.5 monitoring with more than 2500 devices deployed in Taiwan and 29 other countries. It is one of the largest deployment project for PM2.5 monitor in the world as we know until May 2017. The key feature of the framework is its open system architecture, which is based on the principles of open hardware, open source software, and open data. To facilitate the deployment of the framework, we investigate the accuracy issue of low-cost particle sensors with a comprehensive set of comparison evaluations to identify the most reliable sensor. By working closely with government authorities, industry partners, and maker communities, we can construct an effective eco-system for participatory urban sensing of PM2.5 particles. Based on our deployment achievements to date, we provide a number of data services to improve environmental awareness, trigger on-demand responses, and assist future government policymaking. The proposed framework is highly scalable and sustainable with the potential to facilitate the Internet of Things, smart cities, and citizen science in the future."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we mainly study the data transport capacity of mobile networks for mobile social services. Specifically, mobile ad hoc social networks (MAHSNs) with infrastructure support are considered the carrier networks. In MAHSNs with infrastructure support, the underlying physical networks and the upper social relationship networks interact with each other and influence the capacity of this hybrid mobile social communication carrier network together. For the physical networks, we introduce a more practical clustered model to depict the social behavior of users. We consider a virtual home point for each mobile user. For the upper social relationship networks, we propose an improved population-based model, in which we map the home points of the mobile users into the social relationship formation, to solve the social formation problem in the mobile environment. This process comprehensively considers the clustering levels of the degree of friendship and friendship distribution. Finally, from a layered networking perspective, the geographical distribution of the social traffic sessions is analyzed to derive the capacity for social-broadcast sessions of MAHSNs with infrastructure support. The results provide deep insights into the impacts of a user' mobility pattern and social relationship formation on the capacity of MAHSNs with infrastructure support."
  },
  {
    "year": "2017",
    "abstract": "The feedback vertex set problem (FVSP), a combinatorial optimization problem, finds a set of vertices that intersect all cycles of the directed graph. One of the cutting-edge heuristics for this problem is a simulated annealing (SA)-based algorithm named the SA-FVSP. In this paper, we propose an improved variant of the SA-FVSP by applying the nonuniform neighborhood sampling (NNS), namely, the SA-FVSP-NNS. The NNS is a general strategy for improving the SA-based algorithm. Its basic idea is to prioritize the neighbors which are closer to the global optimum by assigning them with higher sampling probabilities. By doing this, these neighbors are more likely to be selected in the sampling process. To apply this general strategy to the SA-FVSP, we propose the concepts of the priority function and the sampling function, respectively. The priority function utilizes the known heuristic rules of the FVSP to estimate and score the quality of neighbors, while the sampling function converts the scores computed by the priority function to sampling probabilities, which can directly guide the NNS process. Experiments indicate that the SA-FVSP-NNS algorithm outperforms the SA-FVSP."
  },
  {
    "year": "2017",
    "abstract": "A number of modern metaheuristic optimization techniques are being exploited to work out a single-objective economic dispatch (ED) problem. The dispatch problems even become more complicated and complex when they consider operational and system constraints, such as network transmission losses, valve-point loading effects originating due to sequential opening of a number of steam admission valves to meet the ever-increasing demand, ramp rate limits, prohibited operating zones, multiple fuel options, spinning reserve, and so on. The heavy constraints make the otherwise convex linear smooth dispatch problem as highly nonconvex nonlinear nonsmooth one. Finding optimal solution for such kind of a constrained nonlinear problem through the deterministic numerical and convex characteristics-based optimization techniques is a difficult task to accomplish. Researchers have frequently employed one of the metaheuristic optimization techniques with powerful computational ability named particle swarm optimization (PSO) to deal with this rather a complicated and toilsome dispatch problem. In Part I of the two-part paper, a comprehensive review or a survey of PSO and its modified versions (involve alterations in the basic structure of PSO) to resolve the constrained ED problem is presented. Part II covers purely the survey of hybrid forms of PSO (hybridization of PSO with other optimization techniques) to tackle the ED problem. The survey is presented in such a way that readers may understand how PSO can be made computationally more efficient."
  },
  {
    "year": "2017",
    "abstract": "Disadvantages inherent to existing guidance systems for scenic areas can be reduced to a partial point traversal problem in the connected graph. This paper presents an intelligent, ant-colony-based path planning algorithm that is applicable to scenic areas. The proposed algorithm modifies the ants' ending tour to achieve partial point traversal of the connected graph by eliminating the restriction of the ant colony algorithm taboo table. A temporary weight matrix is introduced so that the algorithm avoids the repeated selection of smaller-weight paths, improving its overall efficiency. The experimental results show that the improved ant colony algorithm proposed in this paper is more effective and efficient than other algorithms and more suitable to solve the path planning problem in one scenic area with many spots."
  },
  {
    "year": "2017",
    "abstract": "Green networks, which is put forward for the environmental and economic benefits, has received much attention recently because of the vast energy cost in wireless cellular networks. To reduce the energy consumption and simultaneously guarantee the service performance of the dense heterogeneous networks, this paper proposes an energy-saving algorithm with joint user association, clustering, and ON/OFF strategies. First, for the user association subproblem, an optimal association policy, which is related to load balancing and energy efficiency, is designed for the new arriving user equipment (UE) and re-associated UE. Second, based on the locations and load of the base stations (BSs), the clustering subproblem is modeled as an integer linear programming, and the near-optimal clustering results are obtained by using the semidefinite programming. Finally, an intra-cluster ON/OFF strategy for the switching ON/OFF subproblem is designed in which the chosen BSs to be switched OFF are decided by their load effect to other BSs in the clusters. The simulation results demonstrate that, compared with the traditional approaches, the clustering-based energy-saving algorithm can reduce the average network cost by 25.2%-66.7% for different network load conditions."
  },
  {
    "year": "2017",
    "abstract": "An adaptive neuro-fuzzy inference system (ANFIS) of soft computing is an effective method for predicting performance. An statistical analysis and soft computing scheme based on the ANFIS neuro-fuzzy proportional-integral-differential (ANFP) control is proposed to predict the performance of a fuzzy PID controller for a two-axis inertially stabilized platform system. The data are extracted from an unconventional fuzzy PID stabilization controller output of the closed loop, and the model is trained using the Levenberg-Marquardt (LM) training algorithm and compared according to the experimental data from the output results of the ANFP controller. The comparative simulations are expatiated by the statistical values of the mean squared error (MSE) and the coefficient of determination (R) as performance indicators. The experimental results validate that the ANFP soft computing approach contributes to the indispensable improvement for predicting performance in accordance with the error analysis results."
  },
  {
    "year": "2017",
    "abstract": "Given a large graph, like a social network, which k nodes should be immunized (or removed) to make the network safe from the spread of a virus? This is the node immunization problem. One of the classical methods, inspired by immunology, in analyzing this problem relies on the calculation of the largest eigenvalue before and after immunization in order to create the largest difference in eigenvalue. We propose a method that does not rely on a costly calculation of eigenvalues; instead, we rely on the notion of proxies and deterministic routing areas in order to find such nodes to immunize. We show that our results are consistent with the notion of vulnerability and produces equivalent results when compared with the existing algorithms. Furthermore, experimental results show that when a virus is not allowed to die out (controlled by the strength of the virus), our algorithm ensures that more nodes are safe from infection."
  },
  {
    "year": "2017",
    "abstract": "Accurate tagless indoor person localization is important for several applications, such as assisted living and health monitoring. Machine learning (ML) classifiers can effectively mitigate sensor data variability and noise due to deployment-specific environmental conditions. In this paper, we use experimental data from a capacitive sensor-based indoor human localization system in a 3 m × 3 m room to comparatively analyze the performance of Weka collection ML classifiers. We compare the localization performance of the algorithms, its variation with the training set size, and the algorithm resource requirements for both training and inferring. The results show a large variance between algorithms, with the best accuracy, precision, and recall exceeding 93% and 0.05 m average localization error."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the fixed-time group tracking problem for multi-agent systems with unknown inherent nonlinear dynamics is studied. A distributed tracking control protocol is introduced to ensure that the follower agents in each subgroup can track their respective leaders in a prescribed time regardless of the initial conditions. Compared with the existing works on group (tracking) consensus, we do not require the inter-group balance condition, and the leaders are allowed to interact with follower agents in different subgroups. Some conditions have been derived to choose appropriate control gains to achieve the fixed-time group tracking. Finally, numerical simulations are presented to illustrate the availability of our results."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the stability analysis problem for planar periodic switching systems. We characterize the stability margin in the space constituted by the dwell times of the subsystems, by which we can assess the asymptotic stability of the overall system in the necessary and sufficient sense. The mutual constraint conditions on the dwell times in nature depend on the type of equilibrium point of each subsystem. The stability conditions are expressed in terms of a family of transcendental inequalities, which can be numerically solved and precisely depicted in the time-domain space. An example is worked out in detail to illustrate the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "With a wide scope for exploration and research, underwater wireless sensor network (UWSN) is a fast growing research area in current scenario. UWSNs need energy efficient designing approach, because underwater sensor nodes are battery driven. Also the deployed batteries cannot be easily recharged by nonconventional energy resources, like solar energies. Clustering is an effective technique to design an energy efficient UWSNs. Due to the sparse deployment of nodes and dynamic nature of the channel, the clustering characteristics of UWSNs are different from those of terrestrial wireless sensor networks. In this paper, we focused on optimal clustering for UWSNs which are compliant with any one of the acoustic, free space optical (FSO) and electromagnetic (EM) wave-based communication techniques. Besides, we proposed an energy dissipation model of sensor node for FSO and EM wave-based communication and compared with the contemporary energy dissipation model for acoustic-based communication. In particular, the suitability of the above three techniques for underwater communication is investigated and their performance is compared on the basis of energy consumption and optimal clustering."
  },
  {
    "year": "2017",
    "abstract": "Classification in sparsely labeled networks is challenging to traditional neighborhood-based methods due to the lack of labeled neighbors. In this paper, we propose a novel behavior-based collective classification (BCC) method to improve the classification performance in sparsely labeled networks. In BCC, nodes' behavior features are extracted and used to build latent relationships between labeled nodes and unknown ones. Since mining the latent links does not rely on the direct connection of nodes, decrease of labeled neighbors will have minor effect on classification results. In addition, the BCC method can also be applied to the analysis of networks with heterophily as the homophily assumption is no longer required. Experiments on various public data sets reveal that the proposed method can obtain competing performance in comparison with the other state-of-the-art methods either when the network is labeled sparsely or when homophily is low in the network."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the problem of blind separation of sources mixed by multi-input multi-output finite impulse response channels, which is also called convolutive blind source separation (BSS) in short. This problem has been intensively studied in the context that the sources possess certain favourable properties, such as independence and sparsity. However, these properties may not exist in some practical applications. In this paper, we propose a precoding-based convolutive BSS method, which can deal with mutually correlated sources without requiring the sources to be sparse. It is also applicable to mutually independent sources. In the proposed method, the sources are preprocessed in transmitters prior to transmission by order-one precoders. At the receiving side, the second-order statistics of the sources and the Z-domain features of the precoders are exploited to estimate the coded signals, from which the sources are recovered. Simulation results demonstrate the effectiveness of the new convolutive BSS method."
  },
  {
    "year": "2017",
    "abstract": "Synchronization and robust synchronization of fractional-order coupled neural networks (FCNNs) are considered in this paper. Different with the most published works on synchronization based on a special solution of an isolate node of the networks, we remove this restriction and introduce a more widely accepted definition of synchronization. Meanwhile, because of parametric uncertainties of network models, robust synchronization for FCNNs is investigated. In addition, by utilizing pinning control strategies, several sufficient conditions are derived to make sure that the considered networks can realize pinning synchronization and robust pinning synchronization. Finally, the correctness of the obtained results is substantiated by two given numerical examples."
  },
  {
    "year": "2017",
    "abstract": "CubeSats are a class of pico-satellites that have emerged over the past decade as a cost-effective alternative to the traditional large satellites to provide space experimentation capabilities to universities and other types of small enterprises, which otherwise would be unable to carry them out due to cost constraints. An important consideration when planning CubeSat missions is the power budget required by the radio communication subsystem, which enables a CubeSat to exchange information with ground stations and/or other CubeSats in orbit. The power that a CubeSat can dedicate to the communication subsystem is limited by the hard constraints on the total power available, which are due to its small size and light weight that limit the dimensions of the CubeSat power supply elements (batteries and solar panels). To date, no formal studies of the communications power budget for CubeSats are available in the literature, and this paper presents a detailed power budget analysis that includes communications with ground stations as well as with other CubeSats. For ground station communications, we outline how the orbital parameters of the CubeSat trajectory determine the distance of the ground station link and present power budgets for both uplink and downlink that include achievable data rates and link margins. For inter-satellite communications, we study how the slant range determines power requirements and affects the achievable data rates and link margins."
  },
  {
    "year": "2017",
    "abstract": "Via processing the computation intensive applications (apps) at the network edge, mobile edge computing (MEC) becomes a promising technology to enhance the ability of the user equipments (UEs). Most existing works usually focus on whether to offload or where to offload the apps under the premise that sufficient resources are owned by the network edge. However, the demand heterogeneity of UEs and the limitation of resources are usually failed to be considered. Since the limited resources may constrain the number of accessed UEs, how the MEC service providers (SPs) choose the UEs to serve while ensuring UEs' Quality of Service (QoS) is a key issue. Under this context, in this paper, we study the matching problem between the MEC SPs and the UEs in a multi-MEC and multi-UE scenario. Within this scenario, MEC SPs are equipped with limited wireless and computational resources. Auction theory is utilized to model the matching relationship between MEC SPs and UEs as the commodity trading. With this trading, UEs can obtain MEC service from SPs, when they successfully purchase the combinational resources (including computational and wireless resources) from SPs. To complete the auction process, a multi-round-sealed sequential combinatorial auction mechanism is proposed. The properties of the auction are proved and various simulation results are done to show that the proposed approach has better system performance compared with the existing algorithms."
  },
  {
    "year": "2017",
    "abstract": "Cognitive radio (CR) has been introduced to accommodate the steady increment in the spectrum demand. Wireless security in CR network (CRN) is a challenging technical area due to the dynamic and unique characteristics of CRNs. As a cognitive node can dynamically join or leave the spectrum, providing secure communication becomes problematic and requires more investigation. Authentication is a primary security property in wireless networks, wherein the identity of a cognitive node is verified before providing access to available resources. In this paper, a two-level authentication scheme for communication in a CRN is proposed. Before joining the network, a CR node is validated by obtaining security credentials from an authorized point. The proposed scheme relies on publicand symmetric-key cryptography, instead of using a digital signature-based approach. It encrypts data between the communicating nodes in order to improve network security in terms of resource availability and accessibility. This mitigates attacks such as reflection attack, denial of service attack, and man-in-the-middle attack. The scheme has been evaluated and verified in terms of security functionality, its correctness, and the performance, which shows less computation and communication requirements."
  },
  {
    "year": "2017",
    "abstract": "The timely detection of life-threatening ventricular arrhythmias (VAs) is critical for saving a patient's life. General features that characterize ECG waveforms are extracted for VA detection. To take into account the subtle differences in the QRS complexes among different people, new personalized features are proposed in this paper based on the correlation coefficient between a patient-specific regular QRS-complex template and his/her real-time ECG data. Small sets of the most effective features are chosen with support vector machines from 11 newly extracted and 15 previously existing features, for efficient performance and real-time operation. Our proposed new features aveCC and medianCC are verified to be effective in enhancing the performance of existing features under both the record-based and database-based data divisions. Through 50-time random record-based data divisions, all combinations of two features and three features are tested. The top two-feature combination is VFleak and aveCC, which achieves an area under curve (AUC) value of 98.56%±0.89%, a specificity (SP) of 94.80%±2.15%, and an accuracy (ACC) of 94.66% ± 1.97%; the top three-feature combination is VFleak, MEA, and aveCC, which obtains an AUC of 98.98% ± 0.58%, an SP of 95.56% ± 1.45%, and an ACC of 95.46% ± 1.36%; these results outperform the previous top-two and top-three feature combinations. Similar results are obtained on the database-based data division."
  },
  {
    "year": "2017",
    "abstract": "Glaucoma is one among major causes of blindness in working population. Early detection of Glaucoma through automated retinal image analysis helps in preventing vision loss. Optic disk (OD) segmentation from retinal images is the preliminary step in developing the diagnostic tool for early Glaucoma detection. In this paper, we have presented a novel hierarchical technique for fast and accurate OD localization and segmentation. Retinal vasculature and pathologies are delineated and removed by using morphological operations at preprocessing stage followed by circular Hough transform for OD localization. The precise boundary of OD is obtained by calculating the region of interest and applying a novel polar transform-based adaptive thresholding. The methodology is evaluated on a number of publicly available retinal image sets, which includes MESSIDOR, DIARETDB1, DRIONS-DB, HRF, DRIVE, and RIM-ONE, and it has shown considerable improvement over existing methods in terms of accuracy and processing time."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) are currently being used for monitoring and control in smart grids. To ensure the quality of service (QoS) requirements of smart grid applications, WSNs need to provide specific reliability guarantees. Real-time link quality estimation (LQE) is essential for improving the reliability of WSN protocols. However, many state-of-the-art LQE methods produce numerical estimates that are suitable neither for describing the dynamic random features of radio links nor for determining whether the reliability satisfies the requirements of smart grid communication standards. This paper proposes a wavelet-neural-network-based LQE (WNN-LQE) algorithm that closes the gap between the QoS requirements of smart grids and the features of radio links by estimating the probability-guaranteed limits on the packet reception ratio (PRR). In our algorithm, the signal-to-noise ratio (SNR) is used as the link quality metric. The SNR is approximately decomposed into two components: a time-varying nonlinear part and a non-stationary random part. Each component is separately processed before it is input into the WNN model. The probability-guaranteed limits on the SNR are obtained from the WNN-LQE algorithm and are then transformed into estimated limits on the PRR via the mapping function between the SNR and PRR. Comparative experimental results are presented to demonstrate the validity and effectiveness of the proposed LQE algorithm."
  },
  {
    "year": "2017",
    "abstract": "Many researchers expect to see the efficiency of wireless local area networks (WLANs) increased by in-band simultaneous transmit and receive (STR). While insufficient suppression of self-interference has been a major obstacle to implementing the STR capability, an even bigger obstacle is the fact that enabling STR involves significant modification to the current IEEE 802.11 medium access control (MAC) protocol. In this paper, we propose MASTaR, a novel MAC protocol that enables STR in 802.11 WLAN using standard-compliant methods. The feasibility and performance of MASTaR are extensively evaluated via 3-D ray-tracing-based simulation. The simulation results demonstrate that significant performance enhancement, e.g., up to 2.58× higher throughput than the current 802.11 MAC protocol, can be achieved by an STR-capable access point."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel encoder architecture of low-density parity-check (LDPC) generator matrix in frequency modulation-China digital radio (CDR), which was promulgated in August 2013. We utilize the specific structure of LDPC parity matrix to parallelize row and column encoding operations. An optimized method is also proposed to control memories, which can be reused for the LDPC code with different code rates to improve the utilization of hardware resources. The proposed LDPC encoder and decoder are implemented on Xilinx FPGA. According to simulation results of ModelSim and MATLAB, we also verify that the proposed method has the advantages of reduced resource consumption, low power, and high accuracy. The proposed encoder can achieve throughput up to 400 Mbps. In particular, with Lena binary image as the test transmission data, we find that the decoded result meets the error requirements of CDR."
  },
  {
    "year": "2017",
    "abstract": "Wristband-placed physical activity monitors, as a convenient means for counting walking steps, assessing movement, and estimating energy expenditure, are widely used in daily life. There are many consumer-based wristband monitors on the market, but there is not an unified method to compare their performance. In this paper, we designed a series of experiments testing step counting performance under different walking conditions to evaluate these wristband activity monitors. Seven popular brands, including Huawei B1, Mi Band, Fitbit Charge, Polar Loop, Garmin Vivofit2, Misfit Shine, and Jawbone Up, were selected and evaluated with the proposed experiment method in this paper. These experiments include four parts, which are walking in a field at a different walking speed with and without arm swing, walking along a specified complex path, walking on a treadmill, and walking up and down stairs. Experiment results and analysis with nine healthy subjects were reported to show the step counting performance of these seven monitors."
  },
  {
    "year": "2017",
    "abstract": "Virtual training has received a considerable amount of research attention in recent years due to its potential for use in a variety of applications, such as virtual military training, virtual emergency evacuation, and virtual firefighting. To provide a trainee with an interactive training environment, human action recognition methods have been introduced as a major component of virtual training simulators. Wearable motion capture suit-based human action recognition has been widely used for virtual training, although it may distract the trainee. In this paper, we present a virtual training simulator based on 360° multi-view human action recognition using multiple Kinect sensors that provides an immersive environment for the trainee without the need to wear devices. To this end, the proposed simulator contains coordinate system transformation, front-view Kinect sensor tracking, multi-skeleton fusion, skeleton normalization, orientation compensation, feature extraction, and classifier modules. Virtual military training is presented as a potential application of the proposed simulator. To train and test it, a database consisting of 25 military training actions was constructed. In the test, the proposed simulator provided an excellent, natural training environment in terms of frame-by-frame classification accuracy, action-by-action classification accuracy, and observational latency."
  },
  {
    "year": "2017",
    "abstract": "Many metaheuristic algorithms have been proposed to solve combinatorial and numerical optimization problems. Most optimization problems have high dependence, meaning that variables are strongly dependent on one another. If a method were to attempt to optimize each variable independently, its performance would suffer significantly. When traditional optimization techniques are applied to highdependence problems, they experience difficulty in finding the global optimum. To address this problem, this paper proposes a novel metaheuristic algorithm, the entanglement-enhanced quantum-inspired tabu search algorithm (Entanglement-QTS), which is based on the quantum-inspired tabu search (QTS) algorithm and the feature of quantum entanglement. Entanglement-QTS differs from other quantum-inspired evolutionary algorithms in that its Q-bits have entangled states, which can express a high degree of correlation, rendering the variables more intertwined. Entangled Q-bits represent a state-of-the-art idea that can significantly improve the treatment of multimodal and high-dependence problems. Entanglement-QTS can discover optimal solutions, balance diversification and intensification, escape numerous local optimal solutions by using the quantum not gate, reinforce the intensification effect by local search and entanglement local search, and manage strong-dependence problems and accelerate the optimization process by using entangled states. This paper uses nine benchmark functions to test the search ability of the entanglement-QTS algorithm. The results demonstrate that Entanglement-QTS outperforms QTS and other metaheuristic algorithms in both its effectiveness at finding the global optimum and its computational efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we give a unified performance optimization for secrecy wireless information and power transfer over interference channels, where an external eavesdropper is also interested in the confidential message. We propose to perform cooperative energy beamforming between two sources to confuse the eavesdropper while satisfying the requirements on the minimum amounts of individual harvested energy, and the minimum signal-to-interference-plus-noise ratio at the wiretap-free node, even under an adverse condition that there exist channel uncertainties at the transmitters. Considering the maximization of secrecy rate subject to a power constraint and the minimization of power consumption with a minimum secrecy rate requirement are two commonly used design objectives for secure communications, we give a unified performance optimization from the both perspectives. Especially, since there exists channel uncertainty, we propose to optimize the worst performance, so as to satisfy the performance requirements under all channel conditions. To achieve a balance between system performance and implementation complexity, we present a robust cooperative beamforming and power splitting scheme for each secrecy problem while confining the information signal in the null space of the interference channel. Finally, simulation results validate the effectiveness of the proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "Understanding the actions of other people is a key component of social interaction. This paper used an electroencephalography and functional near infrared spectroscopy (EEG-fNIRS) bimodal system to investigate the temporal-spatial features of action intention understanding. We measured brain activation while participants observed three actions: 1) grasping a cup for drinking; 2) grasping a cup for moving; and 3) no meaningful intention. Analysis of EEG maximum standardized current density revealed that brain activation transitioned from the left to the right hemisphere. EEG-fNIRS source analysis results revealed that both the mirror neuron system and theory of mind network are involved in action intention understanding, and the extent to which these two systems are engaged appears to be determined by the clarity of the observed intention. These findings indicate that action intention understanding is a complex and dynamic process."
  },
  {
    "year": "2017",
    "abstract": "Decision fusion is an important issue in wireless sensor networks (WSN), and intuitionistic fuzzy set (IFS) is a novel method for dealing with uncertain data. We propose a multi-attribute decision fusion model based on IFS, which includes two aspects: data distribution-based IFS construction algorithm (DDBIFCA) and the category similarity weight-based TOPSIS intuitionistic fuzzy decision algorithm (CSWBT-IFS). The DDBIFCA is an IFS construction algorithm that transforms the original attribute values into intuitionistic fuzzy measures, and theCSWBT-IFS is an intuitionistic fuzzy aggregation algorithm improved by the traditional TOPSIS algorithm, which combines intuitionistic fuzzy values of different attributes and obtains a final decision for the monitoring target. Both algorithms have benefits, such as low energy consumption and low computational complexity, which make them suitable for implementation in energy-constrained WSNs. Simulation results show the efficiency of intuitionistic fuzzification for the DDBIFCA and a high classification accuracy, compared with traditional fuzzy fusion and other intuitionistic fuzzy aggregation algorithms, for the CSWBT-IFS."
  },
  {
    "year": "2017",
    "abstract": "Visual tracking is a challenging issue in surveillance, human-computer Interaction, and intelligent robotics, among others. Managing appearance changes of the target object, illumination changes, rotations, non-rigid deformations, partial or full occlusions, background clutter, fast motion, and so forth is generally difficult. Among the numerous existing trackers, the correlation-filter-based tracker can achieve appealing performance with a fast speed for fast Fourier transform. Motivated by this property, the spatiotemporal context (STC) learning algorithm was proposed with the consideration of the information from the context around the target, and this algorithm achieved good results. However, STC only utilizes the overall intensity information. In this paper, we propose a multi-channel features STC learning algorithm with an improved scale-adaptive scheme. Our algorithm integrates powerful features, including Histogram of Oriented Gradients and color naming, using kernel methods on the basis of the STC algorithm to further enhance the overall tracking performance. Extensive experimental results obtained from various benchmark data sets demonstrate that the proposed tracker is promising for various challenging scenarios and maintains real-time performance at an average speed of 78 frames/s. According to the test results, our algorithm outperforms the STC algorithm and achieves performance that is competitive with the state-of-the-art algorithms."
  },
  {
    "year": "2017",
    "abstract": "Due to the widespread popularity in both academia and industry, vehicular ad hoc networks (VANETs) have been used in a wide range of applications starting from intelligent transportation to e-health and itinerary planning. This paper proposes a new decentralized lightweight authentication and key agreement scheme for VANETs. In the proposed scheme, there are three types of mutual authentications: 1) between vehicles; 2) between vehicles and their respective cluster heads; and 3) between cluster heads and their respective roadside units. Apart from these authentications, the proposed scheme also maintains secret keys between roadside units for their secure communications. The rigorous formal and informal security analysis shows that the proposed scheme is capable to defend various malicious attacks. Moreover, the ns-2 simulation demonstrates the practicability of the proposed scheme in VANET environment."
  },
  {
    "year": "2017",
    "abstract": "Due to the good filter performance for the non-Gaussian noise, the adaptive filters with error nonlinearities have received increasing attention recently. From the viewpoint of the weighted function, in this paper, the existing least mean square (LMS)-based adaptive algorithms with error nonlinearities are divided into three types, i.e., V-shaped, A-shaped, and M-shaped algorithms. Then, to obtain the merits of the V-shaped and A-shaped algorithms, a new family of robust M-shaped error weighted LMS algorithms is proposed. Their steady-state mean square deviation (MSD) analyses are made, which reveal the learning abilities of error nonlinearities: 1) for the V-shaped algorithm, it can achieve smaller steady state MSD for sub-Gaussian noise than that for super-Gaussian noise; 2) the A-shaped algorithm can be used more effectively for super-Gaussian noise than that for sub-Gaussian noise; and 3) the M-shaped algorithm combines the characteristics of the V-shaped and A-shaped algorithms. Furthermore, based on the proposed robust M-shaped function, a proportionate normalized robust M-shaped algorithm is presented for echo cancellation application. Finally, Monte Carlo simulations are conducted to verify the theoretical results and to demonstrate the efficiency of the proposed algorithms in different environments."
  },
  {
    "year": "2017",
    "abstract": "The Web images and videos are often downsampled and compressed to save the bandwidth and storage. Hence, the low-quality and low-resolution Web images/videos cannot match the high-definition display devices nowadays. Unfortunately, traditional image super-resolution (SR) methods are not very robust to compression artifacts. In this paper, we propose an efficient joint SR and deblocking method based on simple three-step-process, which consists of a block-matching and 3D filtering process, a local binary encoding process, and a mapping reconstruction process. Furthermore, the cascade framework and an extra post-processing are also presented for large magnification factors. Experimental results on real-world Web images with obvious compression artifacts demonstrate that the proposed method can reproduce clear and sharp SR results, and effectively remove the unnatural artifacts at the same time."
  },
  {
    "year": "2017",
    "abstract": "Different from traditional multi-objective evolutionary algorithms (MOEAS), multi-objective cooperative co-evolutionary algorithms (MOCCEAs) divide the decision variables into several subproblems to optimize. Solutions of each subproblem are evaluated by complete solutions formed through combining representative solutions from all subproblems. Therefore, the combination of representative solutions is a key issue in MOCCEAs. To improve the capability of MOCCEAs to complex multi-objective optimization problems, we propose a non-dominated sorting cooperative co-evolutionary differential evolution algorithm (NSCCDE). The proposed NSCCDE uses an external archive for storing complete solutions to establish a new collaboration mechanism, which forms a complete solution by combining collaborators from each subpopulation as well as from the external archive. On the one hand, the external archive is updated continuously through non-dominated sorting of complete solutions, which is conducive to speeding up the convergence. On the other hand, the external archive evolves itself through spatial dispersal and mutation operation to increase the diversity. The performance of proposed NSCCDE is then evaluated on a suite of satellite module layout optimization problem. Experimental results demonstrate that the proposed algorithm outperforms NSCCGA and NSGA- II."
  },
  {
    "year": "2017",
    "abstract": "Bluetooth low energy (BLE)-based indoor localization has attracted increasing interests for its low-cost, low-power consumption, and ubiquitous availability in mobile devices. In this paper, a novel denoising autoencoder-based BLE indoor localization (DABIL) method is proposed to provide high-performance 3-D positioning in large indoor places. A deep learning model, called denoising autoencoder, is adopted to extract robust fingerprint patterns from received signal strength indicator measurements, and a fingerprint database is constructed with reference locations in 3-D space, rather than traditional 2-D plane. Field experiments show that 3-D space fingerprinting can effectively increase positioning accuracy, and DABIL performs the best in terms of both horizontal accuracy and vertical accuracy, comparing with a traditional fingerprinting method and a deep learning-based method. Moreover, it can achieve stable performance with incomplete beacon measurements due to unpredictable BLE beacon lost."
  },
  {
    "year": "2017",
    "abstract": "To fully exploit both multiplexing gain and array gain of massive multiple-input-multipleoutput (MIMO), the channel state information must be obtained accurately at transmitter side (CSIT). However, conventional channel estimation solutions are not suitable for frequency-division duplexing (FDD) multiuser massive MIMO because of overwhelming pilot and feedback overhead. To reduce the pilot and feedback overhead of channel estimation in FDD systems, we propose a compressive channel estimation scheme for FDD massive MIMO systems in this paper, where the beam-blocked sparsity of massive MIMO channels in beamspace is leveraged. Particularly, we first propose a beam-blocked compressive channel estimation scheme, which can reduce the overhead for downlink training. Then, an optimal block orthogonal matching pursuit algorithm at the BS is proposed to acquire reliable CSIT from the limited number of pilots. Furthermore, an efficient algorithm for channel matrix recovery from separately quantized amplitude and phase of received signals is developed to efficiently decrease feedback load. Simulation results demonstrate that our proposed scheme outperforms conventional solutions."
  },
  {
    "year": "2017",
    "abstract": "High precision positioning requires correct carrier phase observation. However, signal block will cause the discontinuity of the carrier phase named as cycle slip, which will severely depress the positioning efficiency and accuracy. Triple-frequency global navigation satellite system measurements bring benefit to the detection and repair of cycle slip. We propose a modified method to detect cycle slip based on combinations of triple-frequency signals. Cycle slips on the three combinations with longer wavelengths and lower noises are determined by the geometry-free model. Then, original cycle slips on three carriers are determined uniquely by the linear equations. To deal with the insensitive cycle slips, an alternative combination is presented as a supplementary. However, the residual of the first-order time-differenced ionospheric error cannot be ignored in this step or will be mistaken as cycle slip if not eliminated. To remove this interference, the residual is compensated by pre-estimations calculated by previous wide-lane combination with no cycle slips have been detected. In the end, real triple-frequency GPS data provided by IGS is processed by this method. The results show that the proposed method can detect all cycle slips in real time even under high ionospheric activity."
  },
  {
    "year": "2017",
    "abstract": "In the era of big scholarly data, citation recommendation is playing an increasingly significant role as it solves information overload issues by automatically suggesting relevant references that align with researchers' interests. Many state-of-the-art models have been utilized for citation recommendation, among which graph-based models have garnered significant attention, due to their flexibility in integrating rich information that influences users' preferences. Co-authorship is one of the key relations in citation recommendation, but it is usually regarded as a binary relation in current graph-based models. This binary modeling of co-authorship is likely to result in information loss, such as the loss of strong or weak relationships between specific research topics. To address this issue, we present a fine-grained method for co-authorship modeling that incorporates the co-author network structure and the topics of their published articles. Then, we design a three-layered graph-based recommendation model that integrates fine-grained co-authorship as well as author-paper, paper-citation, and paper-keyword relations. Our model effectively generates query-oriented recommendations using a simple random walk algorithm. Extensive experiments conducted on a subset of the anthology network data set for performance evaluation demonstrate that our method outperforms other models in terms of both Recall and NDCG."
  },
  {
    "year": "2017",
    "abstract": "The anthropomorphic model observer (MO) plays an important role in the assessment and optimization of medical imaging systems. The MO is a task-based approach; while the abnormality can appear as a hypersignal or a hyposignal for different imaging modalities, sequences, or organs, no MO has been proposed for the hyposignals detection-localization task in the literature. To improve the clinical relevance of the existing MOs, we propose an anthropomorphic MO that can also deal with hyposignals in this paper. In a previous study, we reported a perceptually relevant channelized joint observer (PCJO) for detecting and localizing multiple signals with unknown amplitude, orientation, size, and location. Here, we extend it mathematically to hyposignals task. A free-response study (close to the real-diagnostic procedure) for both hypersignals and hyposignals in cerebral and abdominal CT images was conducted with four radiologists. The equally weighted alternative free-response operating characteristic was used as the figure of merit. Statistical analyses show that the extended PCJO approaches the experts' performances with no significant difference in the studied tasks. The results demonstrate that the extended PCJO is an alternative to replace radiologists for the evaluation and comparison of different medical image processing algorithms. The PCJO has been originally proposed on magnetic resonance imaging but tested on computerized tomography (CT) here; the coherent results show that the PCJO can be generalized to another modality-CT. We also provide in this paper, the reference values of all the parameters in the PCJO to facilitate its future application on magnetic resonance (MR) or CT images."
  },
  {
    "year": "2017",
    "abstract": "In the past years, significant progress has been made in image-based hair modeling, thus producing abundant 3-D hair models. However, on the one hand, the reconstructed hair models could not preserve the structural details of hairstyle. On the other hand, there exists little research on these modeling results. Currently, hair geometry is mostly represented as mass chains of 3-D points. It is difficult to simulate hair directly from this representation. In this paper, we propose a novel approach to convert hair geometry model into helices, which could be easily plugged into dynamic hair simulation. We construct a hair model from a hybrid orientation field, which is generated from four fields. We extract a representative guide hair strand model from this hair geometry. Then, we use adaptive floating tangents fitting algorithm to convert this hair geometry into a physics-based hair model. To initialize this hair model, we calculate a corresponding static equilibrium configuration under external forces, including gravity, frictional contacts, and viscous drag from ambient air. We simulate dynamic hair by the Euler-Lagrange equations. Our approach can preserve structural details of 3-D hair models, and can be applied to simulate various hair geometries."
  },
  {
    "year": "2017",
    "abstract": "Interference suppression and information extraction in pseudorandom code phase modulated pulse Doppler detection system is a practical and challenging problem. In order to extract useful range and velocity in the presence of single-channel multi-component periodic interferences, this paper presents an interference suppression method based on eigenvector analysis and independent component analysis (ICA) by leveraging the characteristic of generalized periodicity of received signal. Using the generalized period of the transmitted signal, we divide the observed received signal into different segments and derive the sample covariance matrix. By computing the eigenvalue decomposition of the sample covariance matrix, we obtain all the eigenvectors and find the corresponding eigenvector with the maximum eigenvalue, which is the sum of the basic waveform components with the same generalized period. Then multi-dimensional matrix can be structured by changing the length of observed signal. The multi-dimensional matrix is used to accomplish ICA so as to separate all the components. Finally, the useful echo signal can be reconstructed; the range and velocity information can be obtained. Simulation results show that the proposed method is effective to excise multi-component periodic interferences and obtain the range and velocity information accurately at high signal to interference ratio (SIR). At low SIR, recursive separation is required. Compared with the existing methods, the proposed method has better performance."
  },
  {
    "year": "2017",
    "abstract": "A robust adaptive backstepping sliding mode control (ABSMC) with recurrent wavelet fuzzy neural network (RWFNN) is proposed for the speed regulation of a six-phase permanent magnet synchronous motor (PMSM) demonstrating parameter perturbations and load disturbances. First, a motor drive system model with lumped uncertainty is developed. Then, a nonlinear robust speed controller using ABSMC and H∞theory is presented. In this technique, ABSMC is employed to guarantee the speed tracking and parameter perturbation suppression; meanwhile, nonlinear H∞is utilized to minimize the influence of dynamic load disturbances on its tracking output. In addition, an uncertainty observer based on the RWFNN is designed to estimate the unknown and improve the robustness of motor drive system further. Ultimately, simulations and AppSIM simulator-based experimental results both indicate that the proposed control scheme can perfectly compensate the parameter perturbations and load disturbances while maintaining speed tracking precision."
  },
  {
    "year": "2017",
    "abstract": "Multilayer feedforward neural networks (MFNNs) have been widely used for classification or approximation of nonlinear mappings described by a data set consisting of input and output samples. In many MFNN applications, a common compressive sensing task is to find the redundant dimensions of the input data. The aim of a regularization technique presented in this paper is to eliminate the redundant dimensions and to achieve compression of the input layer. It is achieved by introducing an L1or L1/2regularizer to the input layer weights training. As a comparison, in the existing references, a regularization method is usually applied to the hidden layer for a better representation of the dataset and sparsification of the network. Gradient-descent method is used for solving the resulting optimization problem. Numerical experiments including a simulated approximation problem and three classification problems (Monk, Sonar, and the MNIST data set) have been used to illustrate the algorithm."
  },
  {
    "year": "2017",
    "abstract": "The recent technology of human voice capture and interpretation has spawned the social robot to convey information and to provide recommendations. This technology helps people obtain information about a particular topic after giving an oral query to a humanoid robot. However, most of the search engines are keyword-matching mechanism-based, and the existing full-text query search engines are inadequate at retrieving relevant information from various oral queries. With only predefined words and sentence-based recommendations, a social robot may not suggest the correct items, if items retrieved along with the information are not predefined. In addition, the available conventional ontology-based systems cannot extract precise data from webpages to show the correct results. In this regard, we propose a merged ontology and support vector machine (SVM)-based information extraction and recommendation system. In the proposed system, when a humanoid robot receives an oral query from a disabled user, the oral query changes into a full-text query, the system mines the full-text query to extract the disabled user's needs, and then converts the query into the correct format for a search engine. The proposed system downloads a collection of information about items (city features, diabetes drugs, and hotel features). The SVM identifies the relevant information on the item and removes anything irrelevant. Merged ontology-based sentiment analysis is then employed to find the polarity of the item for recommendation. The system suggests items with a positive polarity term to the disabled user. The intelligent model and merged ontology were designed by employing Java and Protégé Web Ontology Language 2 software, respectively. Experimentation results show that the proposed system is highly productive when analyzing retrieved information, and provides accurate recommendations."
  },
  {
    "year": "2017",
    "abstract": "With the rapid development of energy-efficient cloud computing technologies, mobile users can share information with each other in different communities. However, due to the ever-increasing population of mobile users and the scale of networks, the energy-efficient delivery of information in mobile social networks (MSNs) becomes a new challenge. Therefore, in this paper, we propose an optimal control theorybased epidemic information spreading scheme for mobile users with energy constraint. First, we divide the social relationships of mobile users into four types based on blood, geography, work, and interest relationship. Second, we develop an analytical model to evaluate the influences of social relationships on the information spreading process in MSNs. Third, we present a control theory-based information spreading scheme to optimize the tradeoff between the consumed energy and delay. Finally, numerical results demonstrate that the presented scheme can save the energy and improve the quality of experience during information spreading for mobile users."
  },
  {
    "year": "2017",
    "abstract": "Traditional machine learning algorithms have made great achievements in data-driven fault diagnosis. However, they assume that all the data must be in the same working condition and have the same distribution and feature space. They are not applicable for real-world working conditions, which often change with time, so the data are hard to obtain. In order to utilize data in different working conditions to improve the performance, this paper presents a transfer learning approach for fault diagnosis with neural networks. First, it learns characteristics from massive source data and adjusts the parameters of neural networks accordingly. Second, the structure of neural networks alters for the change of data distribution. In the same time, some parameters are transferred from source task to target task. Finally, the new model is trained by a small amount of target data in another working condition. The Case Western Reserve University bearing data set is used to validate the performance of the proposed transfer learning approach. Experimental results show that the proposed transfer learning approach can improve the classification accuracy and reduce the training time comparing with the conventional neural network method when there are only a small amount of target data."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, there is an ever-increasing migration of people to urban areas. Health care service is one of the most challenging aspects that is greatly affected by the vast influx of people to city centers. Consequently, cities around the world are investing heavily in digital transformation in an effort to provide healthier ecosystems for people. In such a transformation, millions of homes are being equipped with smart devices (e.g., smart meters, sensors, and so on), which generate massive volumes of fine-grained and indexical data that can be analyzed to support smart city services. In this paper, we propose a model that utilizes smart home big data as a means of learning and discovering human activity patterns for health care applications. We propose the use of frequent pattern mining, cluster analysis, and prediction to measure and analyze energy usage changes sparked by occupants' behavior. Since people's habits are mostly identified by everyday routines, discovering these routines allows us to recognize anomalous activities that may indicate people's difficulties in taking care for themselves, such as not preparing food or not using a shower/bath. This paper addresses the need to analyze temporal energy consumption patterns at the appliance level, which is directly related to human activities. For the evaluation of the proposed mechanism, this paper uses the U.K. Domestic Appliance Level Electricity data set-time series data of power consumption collected from 2012 to 2015 with the time resolution of 6 s for five houses with 109 appliances from Southern England. The data from smart meters are recursively mined in the quantum/data slice of 24 h, and the results are maintained across successive mining exercises. The results of identifying human activity patterns from appliance usage are presented in detail in this paper along with the accuracy of shortand long-term predictions."
  },
  {
    "year": "2017",
    "abstract": "The popularity of smart devices and the increase of access rate are switching Internet from link-centric (host-to-host) to content-centric (user-to-content). Since the primary purpose of users is to find their desired contents from the Internet, the traditional host-to-host structure will cause lots of useless traffic and decrease the network efficiency. Content-centric network (CCN) is then introduced to solve this embarrassed situation. As a new-born technology, CCN has not fully explored its potential to utilize the knowledge embedded in the contents. Hence, we propose to enhance the information extraction capability of CCN with data driving methods. Specifically, we add a label vector containing feature descriptions for each content, and then apply neural network (NN) to model users' behavior and predict their responses to new contents. To further increase prediction accuracy and potential benefits, we group users into different cells. The behavior sets of users in a cell at different time intervals are modeled by a series of NNs. Moreover, we design a new caching policy to improve network caching efficiency. Benefits in other aspects and future research directions are also discussed. Quantitative evaluations of the proposed model and caching policy are presented in the end of this paper."
  },
  {
    "year": "2017",
    "abstract": "A hybrid combining technique is one of the hot topics in the diversity research field because of the excellent overall performance compared with pure combining techniques. A hybrid maximal-ratio-based switch-and-stay combining (M-SSTC) scheme, for dual-branch systems, is proposed in this paper to enhance the existing SSTC-type combining techniques. According to this paper, the problem of the available solutions is that they are valid only when both the branches are poor, leading the performance gain very limited. Thus, we make an attempt to adopt the maximal-ratio combining technique to overcome this disadvantage. By designing reasonable switching logic, M-SSTC can improve the performance of the diversity system as much as possible while keeping its complexity in a low level. Based on the Markovian property of the M-SSTC's output state sequences, the outage probability performance of M-SSTC is analyzed, and the closed-form expression is also presented. Finally, simulation results validate the theoretical results and show the advantages of M-SSTC over the available schemes."
  },
  {
    "year": "2017",
    "abstract": "In recent years, with the development of cloud computing technology, the size of a data center is expanding rapidly. To minimize the energy consumption of a data center, we propose an energy-efficient virtual resource dynamic integration (VRDI) method. In the proposed VRDI method, first, by monitoring the load patterns of the physical machines (PMs) and the corresponding thresholds of PMs calculated using the statistical data, we propose a PM selection algorithm to find a set of PMs, which should be integrated. Furthermore, we propose a virtual machine (VM) selection algorithm based on minimum migration policy to select the VMs that are deployed on the integrated PMs. Finally, to solve the target VM placement, we propose a VM placement algorithm based on an improved genetic algorithm. Using the encoding, crossover and mutation operations of the genetic algorithm, we obtain an effective solution for the VM placement problem. The experiments show that the proposed VRDI method can reduce the energy consumption of data center and ensure the quality of service of the cloud applications developed on the VMs."
  },
  {
    "year": "2017",
    "abstract": "For more than a decade now, radio frequency identification (RFID) technology has been quite effective in providing anti-counterfeits measures in the supply chain. However, the genuineness of RFID tags cannot be guaranteed in the post supply chain, since these tags can be rather easily cloned in the public space. In this paper, we propose a novel product ownership management system (POMS) of RFID-attached products for anti-counterfeits that can be used in the post supply chain. For this purpose, we leverage the idea of Bitcoin's blockchain that anyone can check the proof of possession of balance. With the proposed POMS, a customer can reject the purchase of counterfeits even with genuine RFID tag information, if the seller does not possess their ownership. We have implemented a proof-of-concept experimental system employing a blockchain-based decentralized application platform, Ethereum, and evaluated its cost performance. Results have shown that, typically, the cost of managing the ownership of a product with up to six transfers is less than U.S. $1."
  },
  {
    "year": "2017",
    "abstract": "The user requirements in the future wireless networks are heterogeneous. The resource allocation and user association are crucial factors to meet user requirements and save energy. In this paper, the optimization of resource allocation and user association problem in both low data and high data requirement scenario is studied. In the low data requirement scenario, a network energy consumption minimization problem which considering the signal-to-interference-plus-noise ratio coverage constraints and jointly determines the optimal density of micro base stations (mBSs) and the optimal association bias is formulated. The closed-form solution of the optimal mBSs density and association bias is derived, O(λu-(α/2)) u respectively. Optimal association bias grows like O(λ ) as a function of user density λu (α is path loss factor) and the optimal density of mBSs is a linearly monotone increasing function of the user density. In the high data requirement scenario, a rate coverage maximization problem by adjusting the bandwidth allocation and user association are investigated. The relationship between bandwidth allocation and user association bias is obtained and a dynamic gradient iterative algorithm is used to solve the maximization problem. Simulation results verify the relevant derivations and demonstrate the user density and requirement have an important influence on the optimal resource allocation and optimal association bias."
  },
  {
    "year": "2017",
    "abstract": "Synchrophasor technology has numerous applications ranging from simple grid monitoring/visualization to real-time protection and control. Most legacy phasor measurement units (PMUs) and phasor data concentrators (PDCs) deployed in power grids support the IEEE C37.118.2 communication framework, which is highly vulnerable to cyber attacks due to lack of inherent security mechanisms. The IEC 61850-90-5 recently emerged as new communication framework with support for security features but its use in commercial devices is still very limited. The replacement of legacy PMUs/PDCs in power grids is a big challenge due to cost and deployment complexity. The concept of a gateway has recently been proposed in the literature to enable IEEE C37.118.2 compatible PMUs to send data in IEC 61850-90-5 format. However, the published gateway has limited features and also lacks security functionalities. This paper addresses security, interoperability, and integration issues between legacy and state-of-the-art phasor devices through the design of a security gateway. The security gateway is implemented with flexibility in mind and can be used for PMUs as well as PDCs under different configurations. It provides: 1) protocol conversion functionalities (from IEEE C37.118.2 to IEC 61850-90-5 and vice versa) and 2) security functionalities based on IEC recommended group domain of interpretation security mechanism. The security gateway is very compact in size, based on low-power ARM processor and inexpensive to be deployed in power systems. Through detailed experimental evaluation with real PMU data, this paper also validated the suitability of the security gateway for different types of synchrophasor applications with strict latency and data rate requirements."
  },
  {
    "year": "2017",
    "abstract": "Web service selection for multiple users is an important aspect for achieving efficient operations for web service applications. Its aim is to select optimal solutions, in which each abstract web service in the workflow of a web application is bound to its corresponding concrete web service with the optimal quality of service (QoS), for all users based on their QoS requirements for the workflow. There are a lot of approaches to resolve this problem, but they do not consider each user's different QoS requirements or have prohibitively large overhead for using these approaches. In this paper, we present an approach to significantly improve the efficiency of web service selection by the advanced a-fully polynomial time approximation scheme to calculate the Pareto optimal set, where each solution is not dominated by others. Additionally, this approach reduces its overhead further by adopting artificial bee colony algorithm to select an optimal solution from the Pareto set for each user. Experimental results are presented to show the efficiency of this approach."
  },
  {
    "year": "2017",
    "abstract": "With the development of code obfuscation and application repackaging technologies, an increasing number of structural information-based methods have been proposed for malware detection. Although, many offer improved detection accuracy via a similarity comparison of specific graphs, they still face limitations in terms of computation time and the need for manual operation. In this paper, we present a new malware detection method that automatically divides a function call graph into community structures. The features of these community structures can then be used to detect malware. Our method reduces the computation time by improving the Girvan–Newman algorithm and using machine learning classification instead of a similarity comparison of subgraphs. To evaluate our method, 5040 malware samples and 8750 benign samples were collected as an experimental data set. The evaluation results show that the detection accuracy of our method is higher than that of three well-known anti-virus software and two previous control flow graph-based methods for many malware families. The runtime performance of our method exhibits a clear improvement over the GN algorithm for community structure generation."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the kinematics of free-floating space robots during motion planning for target capture. First, generalized kinematic mapping of free-floating space robots with open-chain multibody structures is established. To predict the reaction movement of spacecraft caused by the motions of its manipulators, a dynamic coupling matrix concept, the main contribution of this paper, is proposed to explicitly express position kinematics. The feasibility and effectiveness of the presented numerical implementation algorithms are then verified by solving forward and inverse kinematics problems. Then, applications in workspace analysis and motion planning are described. Finally, a discussion of the framework is presented."
  },
  {
    "year": "2017",
    "abstract": "A novel dual-broadband dual-polarized base station antenna array with compact structure and low profile is proposed in this paper for the existing mobile communication system operating over 0.79-0.96 GHz (European Digital Dividend/CDMA/GSM) and 1.71-2.17 GHz (DCS/PCS/UMTS). The antenna array is mainly composed of five lower-band elements, ten upper-band elements, some U-shaped metal baffles, and a metal reflector with specific shape. In order to reduce the overall size of the antenna array, lower-band element is designed as octagon aperture shape that upper-band elements can be embedded in it. Two kinds of radiation elements (five for each kind of element) are applied in the antenna array as upper-band elements to achieve better radiation performance. The proposed antenna array achieves electrical downtilt (0°-14° and 0°-10° at lower frequency band and upper frequency band, respectively) by adjusting input amplitude and phase of each array element. Measured results demonstrate that the antenna array has good broadside radiation characteristics, including low voltage standing wave ratio (VSWR <; 1.5), high port-to-port isolation (>28 dB), low backlobe level (>25 dB), high cross-polarization discrimination (>20 dB), and stable radiation pattern with horizontal half-power beamwidth (HPBW) 65° ± 5° at both frequency bands and all electrical downtilt angles. The peak gains of 15.1 and 17.3 dBi are obtained at lower and upper bands respectively. Owing to these advantages, the antenna array is suitable for existing 2G/3G applications in modern mobile communication systems."
  },
  {
    "year": "2017",
    "abstract": "Users in online social networking sites unknowingly disclose their sensitive information that aggravate the social and financial risks. Hence, to prevent the information loss and privacy exposure, users need to find ways to quantify their privacy level based on their online social network data. Current studies that focus on measuring the privacy risk and disclosure consider only a single source of data, neglecting the fact that users, in general, can have multiple social network accounts disclosing different sensitive information. In this paper, we investigate an approach that can help social media users to measure their privacy disclosure score (PDS) based on the information shared across multiple social networking sites. In particular, we identify the main factors that have impact on users privacy, namely, sensitivity and visibility, to obtain the final disclosure score for each user. By applying the statistical and fuzzy systems, we can specify the potential information loss for a user by using obtained PDS. Our evaluation results with real social media data show that our method can provide a better estimation of privacy disclosure score for users having presence in multiple online social networks."
  },
  {
    "year": "2017",
    "abstract": "A form processing application (FPA) automates digitization of information contained in forms. Smaller research groups do not use FPAs as they cannot justify operation of an in-house commercial system. This paper describes the design and testing of a new FPA that is targeted toward the needs of this group, and is released as free open-source software. The new FPA covers form design, printing, scanning, and digitization. It has a flexible plug-in architecture and double-keying is used to reduce transcription error. A common content module (CCM) implements the form design based on the format-independent hierarchical content. The scan module has basic handwriting recognition and can process the input fields used by the CCM. The FPA was field-tested using data from a clinical study to compare the error rate with manual processing. A similar comparison was also made between interviewer and self-administered survey forms. The first comparison shows that the FPA with double-keying had no errors while manual transcription had three errors (0.06%) out of 4952 input fields (p=0.083). The second comparison shows that the FPA with double-keying had no errors for the interviewer-administered form (0/3681 fields, 0%), while the self-administered form had three errors (3/6096 fields, 0.05%) (p=0.178). When double-keying was not used, the error rate for tablet-type fields was not significantly different (p=0.120) between the interviewer (2/3400 fields, 0.06%) and self-administered forms (19/6000 fields, 0.32%). There was, however, a highly significant difference (p<;0.001) for handwriting-type fields between the interviewer (11/881 fields, 1.25%) and self-administered forms (75/1896 fields, 3.96%)."
  },
  {
    "year": "2017",
    "abstract": "An LCL filter utilized in an active front end (AFE) converter can generate significant resonance, which can affect quality and stability of the system. Thus, a proper active or passive damping technique and/or a suitable controller is required to be designed for the converter. The duty cycle constraint—though inevitable in practical inverter systems—is often ignored in most of the existing literature. The effects of measurement noise on filter control system performance must be considered and evaluated under different conditions. Finally, almost all inverter control systems are implemented digitally using microcontrollers. Consequently, the effects of sampling on control system stability and performance should be evaluated as well. Thus, this paper presents stability analysis of an AFE converter-based filter design with a complete practical system configuration, including saturation and sampling blocks and measurement noises. Mathematical analysis and simulations have been carried out to validate the proposed method."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Vehicles (IoVs) is an emerging paradigm aiming to introduce a plethora of innovative applications and services that impose a certain quality of service (QoS) requirements. The IoV mainly relies on vehicular ad-hoc networks (VANETs) for autonomous inter-vehicle communication and road-traffic safety management. With the ever-increasing demand to design new and emerging applications for VANETs, one challenge that continues to stand out is the provision of acceptable QoS requirements to particular user applications. Most existing solutions to this challenge rely on a single layer of the protocol stack. This paper presents a cross-layer decision-based routing protocol that necessitates choosing the best multi-hop path for packet delivery to meet acceptable QoS requirements. The proposed protocol acquires the information about the channel rate from the physical layer and incorporates this information in decision making, while directing traffic at the network layer level. Key performance metrics for the system design are analyzed using extensive experimental simulation scenarios. In addition, three data rate variant solutions are proposed to cater for various application-specific requirements in highways and urban environments."
  },
  {
    "year": "2017",
    "abstract": "As the integration of smart mobile devices to the Internet of Things (IoT) applications is becoming widespread, mobile device usage, interactions with other devices, and mobility patterns of users carry significant amount of information about the daily routines of the users who are in possession of these devices. This rich set of data, if observed over a time period, can be used to effectively verify a user. In previous works, verification of users on personalized electronic devices via biometric properties, such as fingerprint and iris, has been successfully employed to increase the security of access. However, with the integration of social networks with the IoT infrastructure and their popularity on smart handheld devices, identification based on behavior over social networks is emerging as a novel concept. In this paper, we propose an intelligent add-on for the smart devices to enable continuous verification of users. In the experiments, we use data from built-in sensors and usage statistics of five different social networking applications on mobile devices. The collected feature set is aggregated over time and analyzed using machine learning techniques. We show that when smart devices are equipped with continuous verification intelligence, it is possible to verify users with less than 10% false rejection probabilities, and the users can keep using the devices with no interruption for biometric authentication 90% of the time. In the case of anomalous behavioral patterns, the proposed system can verify genuine users with up to 97% success ratio using an aggregated behavior pattern on five different social network applications."
  },
  {
    "year": "2017",
    "abstract": "In science and engineering, many concepts are introduced without a clear physical meaning, e.g., imaginary numbers in mathematics and reactive power in electrical engineering. In this paper, a new operator, coined the ghost operator g, is introduced to physically construct the ghost of a system. It satisfies g2= -1 but is different from the imaginary operator. With the help of the port-Hamiltonian systems theory, it is proved that the ghost of a system behaves exactly in the opposite way as the original system. This brings the ghost of a system into reality and paves the way to reveal the physical meaning of some imaginary concepts. Two applications are given as an example. One is to reveal the physical meaning of reactive power in electrical systems: it is the (real) power of the ghost system, which leads to a significantly simplified instantaneous power theory called the ghost power theory. The other is to define the reactive power for mechanical systems to complete the electrical-mechanical analogy. As a matter of fact, the resulting instantaneous power theory is generic and applicable to any dynamic system that can be described by the port-Hamiltonian model."
  },
  {
    "year": "2017",
    "abstract": "Hybrid precoding is widely studied in millimetre-wave (mmWave) massive MIMO systems due to low cost as well as low power consumption. In general, there are two kinds of hybrid precoding structures: one is fully connected structure (FCS), where each radio frequency (RF) chain is connected to all antennas, and the other is partially connected structure (PCS), where each RF chain is connected to a sub-array. In this paper, we investigate the optimal hybrid precoder design problem for mmWave massive MIMO systems based on PCS, since this kind of structure is more practical for antenna deployment. We first focus on the optimization of analog precoder (AP) and propose two AP design schemes for high signal-to-noise ratio (SNR) condition and low SNR condition, respectively. For each of the schemes, the original optimization problem is reformulated to single-stream optimal transmitter beamforming problem with per-antenna power constraint, which has an optimal solution. Then, the optimal digital precoder is obtained by water-filling algorithm after AP is determined. Moreover, upper bounds of the achievable data rate for the proposed schemes with closed-form expression are derived."
  },
  {
    "year": "2017",
    "abstract": "DC offset in the input of phase-locked loops (PLLs) is a challenging problem since it will result in fundamental frequency oscillations in the estimated phase and frequency. In this paper, a comprehensive analysis and performance evaluation of several advanced second-order generalized integrator (SOGI)based PLL methods in enhancing the dc offset rejection capability for single-phase grid-connected power converters is presented. These methods include the cascade SOGI, modified SOGI, αβ-frame delayed signal cancellation (DSC), complex coefficient filter, in-loop dq-frame DSC, notch filter, and moving average filter-based SOGI-PLL. Main characteristics and design aspects of these methods are presented. Main performance indexes, such as the setting time, frequency or phase errors are defined and these methods are systematically compared under various scenarios with both numerical and experimental results."
  },
  {
    "year": "2017",
    "abstract": "As a general approach to gain electronic trust in business-to-consumer e-commerce, the customers select valid brands based on the authenticity of the Web and regulatory mechanisms in order to facilitate purchase decision process. This approach is not suitable for purchase from small companies without brands active in e-commerce. To purchase from these companies, we should follow other e-trust approaches. One of the approaches applied in information literate is to refer to valid ranking sites like Alexa rank. Here, we have evaluated the correlation between Alexa rank and the formal measures of trust in electronic space, and have suggested a new method for the e-trust that is based on an electronic reputation built on the existing ranking results given by the ranking sites. To this end, we selected 100 store Websites based on regulatory lists, and the formal criteria of trust for them were measured along with the correlation of these criteria with Alexa rank."
  },
  {
    "year": "2017",
    "abstract": "In wireless multi-hop networks, especially large scale wireless multi-hop networks, the feasibility of routing strategies is of vital significance. However, the basic function of routing strategies, the ability of finding a path from source to destination, is seldom researched. In this paper, we apply a Markov chain to model the routing discovery process of wireless multi-hop networks with arbitrary routing strategies. Taking the fading characteristics of wireless channel into consideration, we analyze the impacts of weak links on routing algorithms in wireless multi-hop networks. The probability of routing success and the distribution of hop count are discussed in detail and their close-form solutions are given. Simulation and theoretical results show that, with the increase of the network scale, the impact of weak links gets stronger and even makes the routing strategies unusable. Our research has pointed out the relations between the performance of routing strategies and the network scale under the impact of weak links. The results have important significance for routing strategy designing and network planning."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new class of second-order individually and continuously tunable dual- and triple-band bandpass filters in a single metal cavity. Each passband is realized by two identical metal posts. These dual- and triple-band tunable filters are achieved by putting two or three identical sets of metal-post pair in a single metal cavity. Metal screws are co-designed as a part of the metal posts to control their insertion depth inside the cavity. In this way, the resonant frequencies can be continuously controlled and designed at the desired frequency bands. Moreover, the distance between the two metal posts in a post pair can be freely tuned. Thus, the external quality factor (Qe) and coupling coefficient (k) between the adjacent modes can be easily adjusted to meet the specified requirement in synthesis design. At the bottom of the cavity, some grooves are used to extend the tunable frequency range and make the resonant frequency linearly varied with the height of the metal post. The center frequency of each passband can be independently tuned with a frequency range of 0.8-3.2 GHz and tunable ratio of 4. Finally, the continuously tunable dual- and triple-band bandpass filters prototypes with second order response are designed and fabricated, of which each passband can be individually tuned with a large tuning range."
  },
  {
    "year": "2017",
    "abstract": "Personality is an important psychological construct accounting for individual differences in people. To reliably, validly, and efficiently recognize an individual’s personality is a worthwhile goal; however, the traditional ways of personality assessment through self-report inventories or interviews conducted by psychologists are costly and less practical in social media domains, since they need the subjects to take active actions to cooperate. This paper proposes a method of big five personality recognition (PR) from microblog in Chinese language environments with a new machine learning paradigm named label distribution learning (LDL), which has never been previously reported to be used in PR. One hundred and thirteen features are extracted from 994 active Sina Weibo users’ profiles and micro-blogs. Eight LDL algorithms and nine non-trivial conventional machine learning algorithms are adopted to train the big five personality traits prediction models. Experimental results show that two of the proposed LDL approaches outperform the others in predictive ability, and the most predictive one also achieves relatively higher running efficiency among all the algorithms."
  },
  {
    "year": "2017",
    "abstract": "Wireless powered techniques have been recognized as promising techniques in future wireless communication systems, especially in cognitive radios (CRs) with energy-limit devices. However, most of the existing works focus on CRs with an ideal linear energy harvesting model. In this paper, a wireless powered wideband CR network is considered, and a practical non-linear energy harvesting model is adopted. To maximize the sum throughput of the secondary users, the energy harvesting time, channel allocation, and transmit power are jointly optimized. The closed-form expressions for the optimal transmit power and channel allocation are given. Simulation results show that there is a tradeoff between the harvesting energy and the sum throughput of the secondary users. It is also shown that the performance achieved under the non-linear energy harvesting model may equal to that achieved under the linear energy harvesting model."
  },
  {
    "year": "2017",
    "abstract": "We consider a multiple-input multiple-output (MIMO) communication in a binomial field of nodes scattered in a compact circular region. We first provide closed-form formulas for the Euler transform and Eulerian integral of H-function, which enable us to evaluate the integral in terms of again the H-function. We then derive the exact closed-form expression for the MIMO ergodic capacity between the transmitter and its nth nearest receiver to characterize the spatial ordering achieved by the random locations of nodes in binomial field networks. In high signal-to-noise (SNR) regimes, we also derive a simple mathematical expression for the MIMO capacity in terms of the high-SNR offset. We further analyze the asymptotic capacity when the number of antennas tends to infinity."
  },
  {
    "year": "2017",
    "abstract": "The wireless communications in complex environments, such as underground and underwater, can enable various applications in the environmental, industrial, homeland security, law enforcement, and military fields. However, conventional electromagnetic wave-based techniques do not work due to the lossy media and complicated structures. Magnetic induction (MI) has been proved to achieve reliable communication in such environments. However, due to the small antenna size, the communication range of MI is still very limited, especially for the portable mobile devices. To this end, Metamaterial-enhanced MI (M2I) communication has been proposed, where the theoretical results predict that it can significantly increase the data rate and range. Nevertheless, there exists a significant gap between the theoretical prediction and the practical realization of M2I; the theoretical model relies on an ideal spherical metamaterial, while it does not exist in nature. In this paper, a practical design is proposed by leveraging a spherical coil array to realize M2I communication. The full-wave simulation is conducted to validate the design objectives. By using the spherical coil array-based M2I communication, the communication range can be significantly extended, exactly as we predicted in the ideal M2I model. Finally, the proposed M2I communication is implemented and tested in various environments."
  },
  {
    "year": "2017",
    "abstract": "Distributed multiple-input multiple-output (D-MIMO) systems have drawn considerable attention as they can combine the advantages of point-to-point MIMO with distributed antenna system (DAS). However, the performance analysis of D-MIMO system with zero-forcing (ZF) receivers over semi-correlated K fading channels involves special functions, such as Bessel and Meijer-G functions, which do not enable us to further analysis. In this paper, by using moment matching method, we present a new method that use a Gamma distribution to approximate the K distribution (Rayleigh/Gamma distribution). Using the approximate distribution as a starting point, we derive the approximate analytical expressions on the achievable sum rate (ASR), symbol error ratio (SER), and outage probability (OP) of D-MIMO systems operating in semi-correlated K fading channels employing ZF receivers. To get useful insight into implications of system and fading parameters on the performance, the analytical asymptotic approximations on the ASR in high signal-to-noise ratio (SNR) and low-SNR regime are provided, respectively. Finally, we perform the approximate large-system analysis in the high-SNR and provide asymptotic sum rate expressions when the number of antennas at the base station (BS) grows large, and when the number of antennas at both ends grows large with a fixed and finite ratio. It is demonstrated that the proposed approximate expressions accurately match with the analytical expressions, especially for large-system limit."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a voltage regulation system based on indirect adaptive fuzzy (IAF) control for doubly salient electromagnetic generator (DSEG) is proposed to improve the robustness of the system and reduce output voltage ripple. The operating principle of IAF controller is described in detail subsequently and the stability condition of the system is deduced by Lyapunov function based on the mathematical model and working principle of the generator. Moreover, the selection method of parameters and control strategy are determined with the adaptive fuzzy control law. Finally, a field-circuit coupling simulation model of voltage regulation system for DSEG using IAF controller is constructed by finite element analysis technique and transient solver of control circuit. The simulation results show that DSEG using IAF controller has good static characteristics, high robustness, and low output voltage ripple."
  },
  {
    "year": "2017",
    "abstract": "A two-phase method for image authentication using side information from the communication channel, followed by improved error correction using reliable data, is presented. The functionality of the proposed method is divided into two phases. In the first phase, important fragments of an image, called the region of interest, such as an eye or face, are authenticated using side information from the channel. If the authentication succeeds, the second phase follows. In the second phase, the authenticated fragments are provided as a feedback to the channel decoder. This feedback is used to improve the results of channel decoding. By using a varying length of authenticated fragments at the receiver side, varying levels of coding gains are achieved. The first phase achieves limited image correction, together with the authentication of the region of interest. The second phase improves the decoding results using the image data, which are already declared correct and authentic by the first phase. The image authentication algorithm and error correcting codes mutually benefit from each other in the proposed method: the error correcting codes help in image authentication and successful image authentication helps in improving the results of error correcting codes. The applicability of the proposed scheme is supported by simulation results for images, where bit error rate curves are shown in addition to the visual image enhancements. A security analysis of the proposed method is given in the end."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes the synthesis of Petri net supervisors based on a think-globally-actlocally (TGAL) approach and a vector covering technique for flexible manufacturing systems. Given a Petri net model with deadlocks, the TGAL approach first temporarily adds a global idle place (GP). A GP has initially only one token. Then, we generate the reachability graph of the net model with the GP. If there are deadlocks, we find all the legal markings and first-met bad markings (FBMs). The legal markings and FBMs that need to be considered can be reduced by using a vector covering approach. An integer linear programming problem is formulated to design a set of control places to forbid all FBMs but no legal markings. Meanwhile, the redundancy of the obtained control places is checked to remove the redundant ones. Then, we increase one token in the GP and compute a set of control place again. This process is carried out until the reachable markings of the Petri net model do not increase when the number of tokens in the GP is increased. As a result, we can find a set of control places to make the Petri net model live. Finally, some Petri net examples from the literature are used to demonstrate the proposed methods. It can be verified that the obtained supervisors can lead to more reachable markings, since the obtained control places are maximally permissive at each iteration."
  },
  {
    "year": "2017",
    "abstract": "In many realistic image processing applications, the acquired images often suffer from mixed noises and blurring, which greatly degrade the image quality. In this paper, we propose an iteratively reweighted blind deconvolution method with robust regression for obtaining high quality images with mixed noises present. First, we construct a variational regularization model, including a robust regression data term with an adaptive reweighted least square criterion, which is robust to the mixed noises. To preserve the sharp edges and suppress the noise, a total variation-based regularization term for the image is incorporated into the model. Moreover, a Laplacian regularization term is imposed on the point spread function (PSF) for better smoothness. The subsequent optimization problems for the image and the PSF are solved using the limited-memory BFGS-B algorithm suitable for the large-scale problems. In addition, to improve the practicality of the method, a variant of the generalized cross validation method is derived and adopted to automatically estimate the regularization parameters for the image and the PSF. Experiments on simulated and real images demonstrate that the proposed method is superior to the state-of-the-art methods in terms of both subjective measure and visual quality."
  },
  {
    "year": "2017",
    "abstract": "This paper discusses the problem of robust controller design for two-dimensional (2-D) Markovian jump linear systems. The problem is demonstrated using Fornasini-Marchesini local state-space models, which are affected by uncertainties. The transition-mode probability matrix is homogenous and known. It is assumed that the mode information is available for the controller design and implementation. Then, a mode-dependent state-feedback controller is proposed. By substituting the controller into the 2-D system, a stochastic closed-loop system is obtained, because the stochastic variable, external disturbance, and uncertainties are all included in the closed-loop system. Based on the analysis results, an approach to design the controller and its gains is proposed, and the gains are calculated by solving linear matrix inequalities. In section V, a 2-D case is used to verify the performance of the controller."
  },
  {
    "year": "2017",
    "abstract": "The problem of energy consumption in the cloud related environments has attracted a great deal of attention in research and industry communities. In the past ten years, a large number of studies have been done on energy efficiency algorithms, methods, strategies, or techniques. Over the past five years, many scholars have conducted surveys on those energy efficiency strategies from different perspectives. In this paper, we conduct a survey and build the taxonomy on current existing energy efficiency relevant surveys, that is, a survey on surveys of energy efficiency. We classify current existing surveys into five categories, including surveys on the energy efficiency of the whole cloud related systems, surveys on energy efficiency of the certain level or component of the cloud, surveys on all of energy efficient strategies, surveys on a certain energy efficiency techniques, and other energy efficiency related surveys. The survey and taxonomy on the energy efficient relevant surveys conducted in this paper provide comprehensive knowledge on the current level of this research filed. Furthermore, observations are exhibited by the statistic data graphs exacted from the investigated surveys. The observations hidden in those surveys on energy efficiency will make it clear the future research directions in the energy related research field. Future research directions are listed in the final section."
  },
  {
    "year": "2017",
    "abstract": "The recent increasing evolution of renewable energy technologies makes it possible for common residents to afford the cost of installing renewable energy devices (REDs) and energy storage systems (ESSs) in their own houses. With the prevalence of REDs and ESSs, it is a beneficial and also promising idea for residents in a community to share extra energy with others, especially, when they have different electricity usage patterns. However, considering the unpredictable energy usage patterns, radically intermittent characteristics of renewable energy generation, and dynamic electricity price, it would be difficult for residents in a community to intelligently share their energy with others and thus minimize the overall cost of the whole community. In this paper, we design an online algorithm, which can tackle cost-aware energy sharing among residents in a cooperative community. We formulate the problem as a stochastic constrained problem and the objective is to minimize the time-average cost in the whole community, which includes the cost of purchasing electricity from the main grid, and the cost of charging and discharging ESSs. By exploiting the dynamics of electricity price, we can determine the charging and discharging behaviors of ESSs. We explore our method based on the Lyapunov optimization theory, which does not need any future statistics and possesses low computational complexity. Through theoretical analysis of our algorithm, we can conclude that our strategy can approximate the optimality with provable bounds. Meanwhile, we design a revenue division algorithm based on the Nash bargaining theory to fairly share the revenue among residents. We also conduct extensive trace-driven simulations and results show that our algorithm can obtain nearly 12% of cost reduction for the community when compared with noncooperative algorithms, and ensure the fairness among residents in the meanwhile."
  },
  {
    "year": "2017",
    "abstract": "Optical switching based on wavelength division multiplexing has become a promising network technology to scale the performance of data centers. It provides high bisection bandwidth with low power consumption and low complexity of network wiring. However, it raises new challenges for the flow scheduling problem due to the dynamic arrival of traffic flows with unknown service duration combined with the circuit-switched nature of optical networks and wavelength continuity constraint. While the knowledge of flow service time helps to use resources in a better way to increase the revenue, in practice, the service time cannot be accurately specified. In this paper, we address the problem of flow scheduling in optical data centers considering the above challenges. We first develop an optimization formulation using Markov decision process that can estimate the flow termination time and revenue for cloud providers in a long run under the uncertainty in flow service time. Since solving the optimization formulation is mathematically intractable, we then develop heuristic scheduling algorithms for both scenarios: with known and with unknown flow service time. We use a probabilistic model to address the uncertainty due to unknown flow service time. We design a flow scheduling framework that integrates the proposed algorithms to perform flow scheduling in optical data center networks. We evaluate the proposed algorithms through comprehensive simulations and compare their performance against that of a baseline algorithm. The results show that the proposed algorithms achieve significant performance improvement compared with the baseline algorithm."
  },
  {
    "year": "2017",
    "abstract": "The full-duplex (FD) and two-way relay are promising techniques for their high spectrum efficiency. However, the incompletely self-interference cancellation may reduce the performance gain of two-way relay networks, which operates in FD mode. In this paper, we propose an adaptive amplify-and-forward (AF) and decode-and-forward (DF) selection scheme for FD two-way relay networks, where the relay is allowed to operate in half-duplex (HD) mode. We first derive closed-form formulas of the outage probabilities of the non-adaptive AF and DF schemes for two-way relay networks in both FD and HD modes. To improve the outage performance, an adaptive AF/DF scheme will be proposed for two-way relay networks. However, with the residual self-inference, adaptive FD scheme is not always the best choice for achieving the optimal outage performance. Therefore, we also design an optimal switch scheme between FD and HD modes. The closed form formulas of the outage probability are also derived. The simulation results will not only verify the theoretical derivations, but also illustrate the significant performance gains compared with existing non-adaptive schemes."
  },
  {
    "year": "2017",
    "abstract": "Visualization of cerebral blood vessels is vital for stroke diagnosis and surgical planning. A suitable modality for the visualization of blood vessels is very important for the analysis of abnormalities of the cerebrovascular system, as it is the most complex blood circulation system in the human body and vulnerable to bleeding, infection, blood clot, stenosis, and many other forms of damage. Images produced by current imaging modalities are not promising because of noise, artifacts, and the complex structure of cerebral blood vessels. Therefore, there is a requirement for the accurate reconstruction of blood vessels to assist the clinician in making an accurate diagnosis and surgical planning. This paper presents an overall review of modeling techniques that can be classified into the three categories, i.e., image-based modeling, mathematical modeling, and hybrid modeling. Image-based modeling deals directly with medical images and which involves preprocessing, segmentation, feature extraction, and classification. Mathematical modeling exploits existing mathematical laws and equations, an example being an arterial bifurcation, which is assumed to follow a fractal and cube law, and a system of ordinary differential equations are solved to obtain pressure and velocity estimates in a branching network. Whereas, Hybrid modeling incorporates both image-based and mathematical modeling to attempt to produce a more detailed and realistic arterial structure. From the literature review and the analysis of the results, it can be summarized that hybrid models provide a faster and more robust technique, which can significantly help in diagnosis and surgical planning, such as for finding the shortest path for a stenting procedure."
  },
  {
    "year": "2017",
    "abstract": "The safe and secure operation of critical infrastructure is dependent on appropriate responses to safety, security, and operational priorities into integrated control and safety systems (ICSS), at design stage and throughout the life of the system. Digitization as well as networked automation and control infrastructures have increased in the past years and are leading to remarkable potential security risks. Recent news about serious security incidents, such as the WannaCry ransomware, affecting the whole world are heard more often. The objective of this paper is to come up with an integrated and optimised evaluation framework for ICSS and related subsystems considering cybersecurity and safety. This can be achieved by the alignment of the cybersecurity framework formulated by the National Institute of Standards and Technology with safety and security standards ISA84 (IEC 61511) and ISA99 (IEC 62443), and the novel funnel risk graph method. The need of such alignment between safety and security has been recognized by the research community, the industry, as well as the International Society of Automation (ISA)."
  },
  {
    "year": "2017",
    "abstract": "Learning-based face super-resolution relies on obtaining accurate a priori knowledge from the training data. Representation-based approaches (e.g., sparse representation-based and neighbor embedding-based schemes) decompose the input images using sophisticated regularization techniques. They give reasonably good reconstruction performance. However, in real application scenarios, the input images are often noisy, blurry, or suffer from other unknown degradations. Traditional face super-resolution techniques treat image noise at the pixel level without considering the underlying image structures. In order to rectify this shortcoming, we propose in this paper a unified framework for representation-based face super-resolution by introducing a locality-constrained low-rank representation (LLR) scheme to reveal the intrinsic structures of input images. The low-rank representation part of LLR clusters an input image into the most accurate subspace from a global dictionary of atoms, while the locality constraint enables recovery of local manifold structures from local patches. In addition, low-rank, sparsity, locality, accuracy, and robustness of the representation coefficients are exploited in LLR via regularization. Experiments on the FEI, CMU face database, and real surveillance scenario show that LLR outperforms the state-of-the-art face super-resolution algorithms (e.g., convolutional neural network-based deep learning) both objectively and subjectively."
  },
  {
    "year": "2017",
    "abstract": "Epilepsy is a brain disorder that may strike at different stages of life. Patients' lives are extremely disturbed by the occurrence of sudden unpredictable epileptic seizures. A possible approach to diagnose epileptic patients is to analyze magnetoencephalography (MEG) signals to extract useful information about subject's brain activities. MEG signals are less distorted than electroencephalogram signals by the intervening tissues between the neural source and the sensor (e.g., skull, scalp, and so on), which results in a better spatial accuracy of the MEG. This paper aims to develop a method to detect epileptic spikes from multi-channel MEG signals in a patient-independent setting. Amplitude thresholding is first employed to localize abnormalities and identify the channels where they exist. Then, dynamic time warping is applied to the identified abnormalities to detect the actual epileptic spikes. The sensitivity and specificity of proposed detection algorithm are 92.45% and 95.81%, respectively. These results indicate that the proposed algorithm can help neurologists to analyze MEG data in an automated manner instead of spending considerable time to detect MEG spikes by visual inspection."
  },
  {
    "year": "2017",
    "abstract": "The last decades have seen a considerable progress on workflow scheduling in heterogeneous computing environments. However, existing methods still need to be improved on the performance in the makespan-based metrics. This paper proposes a novel workflow scheduling algorithm named Greedy-Ant to minimize total execution time of an application in heterogeneous environments. First, the ant colony system is applied to scheduling from a new standpoint by guiding ants to explore task priorities and simultaneously assign tasks to machines. Second, forward/backward dependence is defined to indicate the global significance of each node, based on which, a new heuristic factor is proposed to help ants search for task sequences. Finally, a greedy machine allocating strategy is presented. Experimental results demonstrate that Greedy-Ant outperforms the state of the art up to 18% in the metric of speedup."
  },
  {
    "year": "2017",
    "abstract": "Authentication plays a critical role in securing any online banking system, and many banks and various services have long relied on username/password combos to verify users. Memorizing usernames and passwords for a lot of accounts becomes a cumbersome and inefficient task. Furthermore, legacy authentication methods have failed over and over, and they are not immune against a wide variety of attacks that can be launched against users, networks, or authentication servers. Over the years, data breach reports emphasize that attackers have created numerous high-tech techniques to steal users' credentials, which can pose a serious threat. In this paper, we propose an efficient and practical user authentication scheme using personal devices that utilize different cryptographic primitives, such as encryption, digital signature, and hashing. The technique benefits from the widespread usage of ubiquitous computing and various intelligent portable and wearable devices that can enable users to execute a secure authentication protocol. Our proposed scheme does not require an authentication server to maintain static username and password tables for identifying and verifying the legitimacy of the login users. It not only is secure against password-related attacks, but also can resist replay attacks, shoulder-surfing attacks, phishing attacks, and data breach incidents."
  },
  {
    "year": "2017",
    "abstract": "Fetal movement counts have long been used as a measure of fetal well-being but with advancing technology, such counts have been supplanted as the primary measure. Despite the new technologies used in standard clinical practice, the stillbirth rate has not reduced significantly worldwide. Each method of assessing fetal movement has limitations with different methods performing better in different situations. No one method is universally superior. This paper aims to introduce the reader to the broad range of assessment methods, both potential and actual, used to determine fetal movement. These assessment methods are assembled into a taxonomy: maternal involvement, clinician involvement, technology-assisted, and automated technology. A brief historical and technological overview and the expected measurements of each assessment method are described. All reviewed methods have value, but actography appears to offer the most potential by complementing existing approaches. Further research is required to evaluate the suitability of fetal movement assessment and the response to it."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a fractional calculus operator for image denoising is constructed based on the characteristic of local entropy and the gradient feature, and an adaptive fractional calculus image denoising algorithm is proposed. First, the effects on the entropy and gradient by noise are analyzed, respectively. Second, the noise points are regarded as small probability events in an image, and the noise points, edges, texture regions, and smooth regions are divided combining with the local structure. Finally, for improving the image denoising effect, we consider employing different fractional orders to deal with different pixels and a piecewise function is constructed to make the differential order to be adaptive. The function is with respect to the local entropy and gradient on the pixel. The experimental results show that the peak signal-to-noise ratio and the entropy (ENTROPY) of the proposed adaptive fractional calculus image denoising algorithm are higher than that of the other algorithms compared in this paper. The proposed algorithm can not only preserve image edges and texture information while removing the noise, but also obtain a good visual effect."
  },
  {
    "year": "2017",
    "abstract": "One of the essential pre-processing steps of semantic video analysis is the video shot boundary detection (SBD). It is the primary step to segment the sequence of video frames into shots. Many SBD systems using supervised learning have been proposed for years; however, the training process still remains its principal limitation. In this paper, a multi-modal visual features-based SBD framework is employed that aims to analyze the behaviors of visual representation in terms of the discontinuity signal. We adopt a candidate segment selection that performs without the threshold calculation but uses the cumulative moving average of the discontinuity signal to identify the position of shot boundaries and neglect the non-boundary video frames. The transition detection is structurally performed to distinguish candidate segment into a cut transition and a gradual transition, including fade in/out and logo occurrence. Experimental results are evaluated using the golf video clips and the TREC2001 documentary video data set. Results show that the proposed SBD framework can achieve good accuracy in both types of video data set compared with other proposed SBD methods."
  },
  {
    "year": "2017",
    "abstract": "While 4G is speeding up its steps toward global markets, 5G has initiated its full development to satisfy an increasing demand on mobile data traffic and big data bandwidth. Centralized data processing, collaborative radio, real-time cloud infrastructure, and cloud radio access network (C-RAN), along with their excellent advantages are being sought by more and more operators to meet end-user requirements. As a promising mobile wireless network architecture, compared with traditional RAN, C-RAN has incomparable advantages in terms of low power consumption, reduced base station (BS) numbers, and economic capital and operating expenditure. It can also improve network capacity and BS utilization rate. Recently, C-RAN security has aroused special attention and concern. However, the literature still lacks an overall review on it in order to guide current and future research. In this paper, we first overview the architecture, deployment scenarios, and special characteristics of C-RAN. We then provide a thorough review on the existing security studies in the field of C-RAN based on its three logic layers and corresponding security threats and attacks. Particularly, we discuss whether the current literature can satisfy the expected security requirements in C-RAN. Based on this, we indicate open research issues and propose future research trends."
  },
  {
    "year": "2017",
    "abstract": "Cyber-physical systems (CPSs) have dependability requirements that are associated with controlling a physical process. Cyber-attacks can result in those requirements not being met. Consequently, it is important to monitor a CPS in order to identify deviations from normal operation. A major challenge is inferring the cause of these deviations in a trustworthy manner. This is necessary to support the implementation of correct and timely control decisions, in order to mitigate cyber-attacks and other causes of reduced dependability. This paper presents evidential networks as a solution to this problem. Through the evaluation of a representative use case for cyber-physical control systems, this paper shows novel approaches to integrate low-level sensors of different types, in particular those for cyber-attack detection, and reliabilities into evidential networks. The results presented indicate that evidential networks can identify system states with an accuracy that is comparable to approaches that use classical Bayesian probabilities to describe causality. However, in addition, evidential networks provide information about the uncertainty of a derived system state, which is a significant benefit, as it can be used to build trust in the results of automatic reasoning systems."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a general distributed messaging framework for online transaction processing applications in e-business industry, and we name it as Metamorphosis (MetaQ). Specifically, this messaging framework has features of high availability, scalability, and high data throughput. The current implementation of MetaQ supports distributed XA transactions, asynchronous messaging, and multiple ways for storing message offsets. As a consequence, it is suited to the application contexts having a large quantity of messages, transaction-support, and real-time requirements. More important, another branch of MetaQ implementation, i.e., RocketMQ has been deployed and used inTaobao.comandAlipay.com. The real usages in both typical online transaction applications have proven that the nature of MetaQ can perform well for such big Internet applications."
  },
  {
    "year": "2017",
    "abstract": "Due to advancements in the development of wireless medical sensing devices and wireless communication technologies, the wireless body area network (WBAN) has become an eminent part of e-healthcare systems. WBAN uses medical sensors to continuously monitor and collect the physiological parameters of a patient's health and send them to a remote medical server through a portable digital assistance (PDA)/mobile. Due to limitations in communication, such as power, storage, and the computational capabilities of sensors, data aggregation techniques are used to reduce the communication overhead in real-time data transmission in WBAN. However, since the WBAN transmits sensitive health data, data security and data privacy are a major concern. In this paper, we propose a secure privacy-preserving data aggregation (SPPDA) scheme based on bilinear pairing for remote health monitoring systems to improve data aggregation efficiency and data privacy. Our proposed SPPDA scheme utilizes the homomorphic property of the bilinear ElGamal cryptosystem to perform privacy-preserving secure computation and combines it with the aggregate signature scheme, enabling data authenticity/integrity in the WBAN. The proposed SPPDA scheme is proved to be semantically secure under the decisional bilinear Diffie-Hellman assumption. Security analysis demonstrates that our proposed scheme preserves data confidentiality, data authenticity, and data privacy; it also resists passive eavesdropping and replay attacks. A performance evaluation based on simulation results and a comparison of computational cost with related schemes show that data aggregation and batch verification at the PDA significantly reduce communication and transmission overhead and support efficient computation at the remote server."
  },
  {
    "year": "2017",
    "abstract": "With the delayed channel state information at transmitters, an effective interference management approach, realized in the packet interference network and with a specific physical layer model (i.e., destinations have the flexibility to utilize past receptions), began to emerge. Meanwhile, the capacity region of this packet interference network can provide best interference management approach. Thus, in this paper, we concentrate on the capacity region of the two-user interference network with the past reception based physical layer model. To this end, we first derive the capacity outer bound, by exhibiting that the bound for the binary fading interference channel is exactly the desired one for the packet interference network. We then examine its linear network coding (LNC) capacity, by exploiting a linear-space-based approach, which unifies the problem of finding a capacity outer bound and devising the achievability scheme into a single linear programming problem. Finally, by analyzing the properties of linear spaces of coding vectors and some pure algebraic arguments, we prove that the LNC capacity region matches the derived outer bound, implying that the derived LNC capacity region is indeed the true capacity of the studied network."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing satisfies the requirement for large volumes of storage and computing resources to simulate land surface models (LSMs). Thus, the Science Cloud of the Chinese Academy of Sciences, which is based on a data cloud and high performance computing cloud, was adopted to support the simulation of LSMs. In this paper, we take advantage of the software and hardware resources of the Science Cloud to establish a prototype system for LSM applications. First, pre-processing and post-processing are crucial components of LSMs, so we specifically designed a freely available integrated software package called “PPLSMS”(for the pre- and post-processing of LSMs) with different scripting languages and data sets, which can be built on the cloud computing platform. Second, we developed a dedicated Web portal for LSMs based on the cloud computing platform with the representational state transfer application programming interface, which allows the operation of functions, such as parameter and data selection, model configuration, as well as customization of the output, statistics and visualization via a Web browser. Finally, some basic steps were presented to operate the Web portal for LSM applications. The system integrated data sets and approaches may serve as a practical means to facilitate the simulation of LSMs."
  },
  {
    "year": "2017",
    "abstract": "Along with the popularity of online social network (OSN), more and more OSN users tend to create their accounts in different OSN platforms. Under such circumstances, identifying the same user among different OSNs offers tremendous opportunities for many applications, such as user identification, migration patterns, influence estimation, and expert finding in social media. Different from existing solutions which employ user profile or social network structure alone, in this paper, we proposed a novel joint solution named MapMe, which takes both user profile and social network structure feature into account, so that it can adapt more OSNs with more accurate results. MapMe first calculates user similarity via profile features with the Doc2vec method. Then, it evaluates user similarity by analyzing user's ego network features. Finally, the profile features and ego network features were combined to measure the similarity of the users. Consequently, MapMe balances the two similarity factors to achieve goals in different platforms and scenarios. Finally, experiments are conducted on the synthetic and real data sets, proving that MapMe outperforms the existing methods with 10% on average."
  },
  {
    "year": "2017",
    "abstract": "Accurate patient registration is a critical issue in medical image-guided interventions. The neurosurgical robotic system RObotic Neuro-NAvigation (RONNA) uses four retro-reflective spheres, on a marker attached to the patient's cranial bone, for patient registration in physical and image space. In this paper, the algorithm for automatic localization of spherical fiducials in CT scans is presented and clinically evaluated. The developed localization algorithm uses a unique approach, which combines machine vision algorithms, biomedical image filtration methods, and mathematical estimation methods. The performance of the localization algorithm was evaluated in comparison with four skilled human operators. The measurements were based on twelve patient and eight lab phantom CT scans. The localization error of the algorithm in comparison with the human readings was smaller by 49.29% according to the ground truth estimation and by 45.91% according to the intra-modal estimation. Localization processing time was reduced by 84.96%. Reliability in terms of successful localization of the fiducial marker was 100% for 20 different test samples containing a total of 116 spherical fiducials. Based on the tests carried out in clinical conditions, the localization algorithm has demonstrated reliability with a high degree of accuracy and short processing time. The developed algorithm provides fully automated and accurate machine vision-based patient localization for the neurosurgical clinical application of the robotic system RONNA."
  },
  {
    "year": "2017",
    "abstract": "A vehicular ad hoc network (VANET) serves as an application of the intelligent transportation system that improves traffic safety as well as efficiency. Vehicles in a VANET broadcast traffic and safety-related information used by road safety applications, such as an emergency electronic brake light. The broadcast of these messages in an open-access environment makes security and privacy critical and challenging issues in the VANET. A misuse of this information may lead to a traffic accident and loss of human lives at worse and, therefore, vehicle authentication is a necessary requirement. During authentication, a vehicle's privacy-related data, such as identity and location information, must be kept private. This paper presents an approach for privacy-preserving authentication in a VANET. Our hybrid approach combines the useful features of both the pseudonym-based approaches and the group signature-based approaches to preclude their respective drawbacks. The proposed approach neither requires a vehicle to manage a certificate revocation list, nor indulges vehicles in any group management. The proposed approach utilizes efficient and lightweight pseudonyms that are not only used for message authentication, but also serve as a trapdoor in order to provide conditional anonymity. We present various attack scenarios that show the resilience of the proposed approach against various security and privacy threats. We also provide analysis of computational and communication overhead to show the efficiency of the proposed technique. In addition, we carry out extensive simulations in order to present a detailed network performance analysis. The results show the feasibility of our proposed approach in terms of end-to-end delay and packet delivery ratio."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT), which is a network that enables devices in the network to exchange information, has rapidly developed in recent years. Wireless communication technologies on the IoT are the best way to solve the “last mile”problem and gain substantial attention. The low power consumption and low cost are notably important for the IoT devices that are called massive IoT (mIoT). Narrow-band communication is one of the solutions to reduce the cost and power consumption and is considered the solution to large coverage without an available spectrum. Large coverage also implies a long transmission time interval, which makes the random access process in the current LTE system unsuitable for mIoT applications. The random access process in the current LTE system is notably complex with some handshakes to exchange information between the base station and the device. We address the issue in this paper and propose a packet-based preamble to simplify the random access process to decrease battery consumption."
  },
  {
    "year": "2017",
    "abstract": "A novel dual-band 3-dB Wilkinson power divider (WPD) is presented that requires only partial port extension. The design methodology is based on the impedance matching technique and is very simple and intuitive with very simple closed-form formulations. The proposed technique has free variable(s) that add extra flexibility during the design and implementation. Continuous variation of isolation element(s) with band ratio (=f2/f1) is no more required and is a distinct feature of this approach when compared with the conventional port extension technique. To enhance the band-ratio further, a technique, which utilizes port extension on all ports, is also demonstrated through an example. The band ratio of the proposed WPD is moderately wide, starting from 1.5 and going beyond 4. A flowchart of the proposed scheme is also reported that aids the systematic design procedure. The presented theory is validated through design and measurement of a prototype fabricated to operate at 0.9/3.5 GHz concurrently. The simulation and the measurement exhibit good agreement."
  },
  {
    "year": "2017",
    "abstract": "Conventional researches on target coverage in directional sensor networks (DSNs) mainly focus to increase the network lifetime, overlooking the coverage quality of targets, especially they don’t consider the targets that have heterogeneous coverage requirements. Increasing sensing quality is of the utmost importance to ensure comfort living in smart cities. In this paper, we have designed a generalized framework, namely maximizing coverage quality with minimum number of sensors in DSN (MQMS-DSN) that has the ability to maximize the target coverage quality, or the network lifetime, or to make an efficient tradeoff in between the two following application demand. Using a probabilistic model for measuring the sensing coverage quality, we have developed optimal, suboptimal, and greedy solutions for MQMS problem. Empirical evaluations of the proposed MQMS systems have been carried out in network simulator version 3 (ns-3). The results show the effectiveness of the proposed systems compared with the state-of-the-art-works in terms of sensing quality and network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Although copy-move forgery is one of the most common fabrication techniques, blind detection of such tampering in digital audio is mostly unexplored. Unlike active techniques, blind forgery detection is challenging, because it does not embed a watermark or signature in an audio that is unknown in most of the real-life scenarios. Therefore, forgery localization becomes more challenging, especially when using blind methods. In this paper, we propose a novel method for blind detection and localization of copy-move forgery. One of the most crucial steps in the proposed method is a voice activity detection (VAD) module for investigating audio recordings to detect and localize the forgery. The VAD module is equally vital for the development of the copy-move forgery database, wherein audio samples are generated by using the recordings of various types of microphones. We employ a chaotic theory to copy and move the text in generated forged recordings to ensure forgery localization at any place in a recording. The VAD module is responsible for the extraction of words in a forged audio, and these words are analyzed by applying a 1-D local binary pattern operator. This operator provides the patterns of extracted words in the form of histograms. The forged parts (copy and move text) have similar histograms. An accuracy of 96.59% is achieved, and the proposed method is deemed robust against noise."
  },
  {
    "year": "2017",
    "abstract": "Many studies of the mining of big learning data focus on user access patterns and videoviewing behaviors, while less attention is paid to the active video-viewing time. This paper pinpoints this completely different analysis unit, models the extent to which factors influence it and further predicts when a user permanently leaves a course. The goal is to provide new insights and tutorials regarding data analytics and feature subspace construction to learning analysts, researchers of artificial intelligence in education and data mining communities. To this end, we collect video-viewing data from a large-scale e-learning system and use the Cox proportional hazard function to model the leaving time. The models mainly include the interactions between variables, non-linearity assumption and age segmentation. Finally, we use the collected hazard ratios of model covariates as the learning features and predict which users tend to prematurely and permanently leave a course using efficient machine learning algorithms. The results show that, first the modeling can be used as an efficient feature extraction and selection technology for classification problems and that, second the prediction can effectively identify users' leaving time using only a few variables. Our method is efficient and useful for analyzing massive open online courses."
  },
  {
    "year": "2017",
    "abstract": "Biometric systems can identify individuals based on their unique characteristics. A new biometric based on hand synergies and their neural representations is proposed here. In this paper, ten subjects were asked to perform six hand grasps that are shared by most common activities of daily living. Their scalp electroencephalographic (EEG) signals were recorded using 32 scalp electrodes, of which 18 task-relevant electrodes were used in feature extraction. In our previous work, we found that hand kinematic synergies, or movement primitives, can be a potential biometric. In this paper, we combined the hand kinematic synergies and their neural representations to provide a unique signature for an individual as a biometric. Neural representations of hand synergies were encoded in spectral coherence of optimal EEG electrodes in the motor and parietal areas. An equal error rate of 7.5% was obtained at the system's best configuration. Also, it was observed that the best performance was obtained when movement specific EEG signals in gamma frequencies (30-50Hz) were used as features. The implications of these first results, improvements, and their applications in the near future are discussed."
  },
  {
    "year": "2017",
    "abstract": "NAND flash memory is a popular memory device that has many advantages such as high-density, lightweight, shock-resistance, non-volatile, and low-power features. Although NAND flash memory has many attractive features, it still has several limitations due to its architectural characteristics, such as out-of-place update, erase-before-write feature, and limit of erase count. Therefore, various flash translation layers (FTLs) have been proposed to handle the characteristics. An FTL consists of three main functions, such as address translation, garbage collection, and wear-leveling effect. In order to facilitate developers to realize and design the main functions of FTLs, we propose a component-based view to rethink the design of FTLs. With the component-based view, developers can replace inappropriate components to form a new FTL and dynamically replace the present FTL. Therefore, we also propose the transformation of FTLs to adaptively transform a present FTL to a suitable one. In the experiments, we can demonstrate that the revised FTL (by replacing some components) can improve its original performance and the transformed FTL can also improve the performance under the current workload."
  },
  {
    "year": "2017",
    "abstract": "This work introduces a bandwidth broadening technique for full-wave dipole (FWD) antennas and arrays, which are realized by introducing gaps in both two arms of the dipole. Several parameters are analyzed to illustrate the change of input impedance of the proposed FWD and the moving of resonant modes. The proposed FWD array antenna shows advantages in terms of impedance bandwidth, 3-dB gain bandwidth and the complexity of the feeding network, when the four-unit FWD array antenna compares with the eightunit half-wave dipole array antenna. The impedance bandwidth of the proposed FWD array antenna is up to 67.8% with the reflection coefficient <;-10 dB from 3.9 to 7.9 GHz. The 3-dB gain bandwidth of the proposed antenna array is 51.4% with the maximum gain of 14.2 dBi and unidirectional radiation property across the entire operating bandwidth. The proposed methodology is good for a high-gain antenna array design through the reduction of antenna elements so as to minimize the complexity of power distributed network to the array. The ultimate goal of this work is to devote a low-cost and high-efficiency antenna array to broadband wireless communication systems."
  },
  {
    "year": "2017",
    "abstract": "Depth images play an important role in 3-D applications. However, due to the limitation of depth acquisition equipment, the acquired depth images are usually in limited resolution. In this paper, a spatially adaptive tensor total variation-Tikhonov model is proposed to solve this problem. The tensor total variation regularization is adopted to maintain sharp edges that reflect latent discontinuities in the real world, while the Tikhonov regularization ensures that depth changes smoothly inside objects. Furthermore, a fused edge map is proposed to indicate edge regions and balance both regularization terms. In edge regions, tensor total variation regularization is predominant, thus edge blurring artifacts are suppressed. In non-edge regions, Tikhonov regularization plays a more important role to suppress staircasing artifacts. Specifically, texture edges are removed in the fused edge map, and texture copying artifacts are avoided. Experimental results demonstrate the effectiveness and superiority of the proposed framework. Moreover, the proposed method yields much sharper edges and a lower percentage of bad pixels."
  },
  {
    "year": "2017",
    "abstract": "With the explosive growth of Internet traffic and the rapid development of network technology, content delivery has become a significant service in the current Internet. However, the existing content delivery solutions, such as peer-to-peer and content delivery network, have many insufficient aspects. Meanwhile, the collaboration between content delivery and network infrastructures has been considered as a promising technique in network field. From the perspective of collaboration, content delivery systems can make full use of the network characteristics and the effective information provided by the network operators, so as to improve the efficiency of the content distribution and optimize the overall performance of the network. In this paper, we present a comprehensive survey on the collaboration for content delivery and network infrastructures. First, we provide some of the works, which have been done on collaboration solutions from two perspectives: evolutionary and revolutionary. And then, the advantages and disadvantages of these solutions are compared and analyzed from three aspects of technology, business, and standardization. Finally, we outline some challenges and research directions in the future."
  },
  {
    "year": "2017",
    "abstract": "The spectral power distribution (SPD) is considered as the figureprint of a light emitting diode (LED). Based on the analysis on its SPD, a method to predict both lumen depreciation and color shift for the phosphor converted white LEDs (pc-LEDs) is proposed in this paper. First, the entire SPD of a pc-LED is predicted by superimposing two asymmetric double sigmoidal (Asym2sig) models, which represent the decomposed blue light and phosphor converted light peaks, respectively. For a better understanding of how the SPD model affects the photometric and colorimetric characteristics of a pc-LED, a sensitivity study of the SPD parameters is then performed on its luminous flux Φ, color coordinates CIE1976(u', v'). Second, the evolutionary process of the SPD is predicted for a pc-LED with the color temperature as 3000 K under degradation testing. And based on these predicted SPDs, the drift curves of Φ, u', v', and du'v' are further predicted. Finally, lifetimes of the pc-LED due to lumen depreciation and color shift are estimated simultaneously from the predicted Φ and du'v' drift curves."
  },
  {
    "year": "2017",
    "abstract": "Contemporary software applications are developed using cross-language artifacts, which are interdependent with each other. The source code analysis of these applications requires the extraction and examination of artifacts, which are build using multiple programming languages along with their dependencies. A large number of studies presented on multilingual source code analysis and its applications in the last one and half decade. The objective of this systematic literature review (SLR) is to summarize state of the art and prominent areas for future research. This SLR is based on different techniques, tools, and methodologies to analyze multilingual source code applications. We finalized 56 multi-discipline published papers relevant to multilingual source code analysis and its applications out of 3820 papers, filtered through multi-stage search criterion. Based on our findings, we highlight research gaps and challenges in the field of multilingual applications. The research findings are presented in the form of research problems, research contributions, challenges, and future prospects. We identified 46 research issues and requirements for analyzing multilingual applications and grouped them in 13 different software engineering domains. We examined the research contributions and mapped them with individual research problems. We presented the research contributions in the form of tools techniques and approaches that are presented in the form of research models, platforms, frameworks, prototype models, and case studies. Every research has its limitations or prospects for future research. We highlighted the limitations and future perspectives and grouped them in various software engineering domains. Most of the research trends and potential research areas are identified in static source code analysis, program comprehension, refactoring, reverse engineering, detection, and traceability of cross-language links, code coverage, security analysis, cross-language parsing, an..."
  },
  {
    "year": "2017",
    "abstract": "The product warranty has become an indispensable facet of business operations. Burn-in is effective at eliminating infant mortality and improving operational reliability levels for consumers. This paper considers the influence of different failure states and different phases of product reliability and warranty policies on warranty costs from predelivery inspection to the end of the warranty period. We then propose a comprehensive warranty cost model that considers burn-in, free replacement warranty and pro-rata warranty as three phases for repairable products presenting two types of failure (minimal and catastrophic failure) that involve minimal repair and replacement, respectively. Warranty costs are the result of a combination of the three phases, where two types of failure occur individually or simultaneously. Moreover, we developed a framework for the modeling process of warranty costs, and the effects of various parameters, such as the burn-in time, warranty period, and distribution function on warranty costs, were analyzed. Finally, a practical case was examined by using a warranty cost model, and through an after-sales service data analysis, we obtained the failure rate distribution and optimal warranty length by minimizing the average warranty cost, which can serve as a reference for manufacturers when developing warranty policies."
  },
  {
    "year": "2017",
    "abstract": "In the computed tomography (CT) field, image reconstructions from truncated projections acquired by only illuminating the region of interest are an effective method to reduce the radiation dose. Theoretically, it has been proven that the exact interior reconstruction is feasible with some prior knowledge. However, the traditional data-consistency-based motion correction methods cannot be applied to truncated data. In this paper, we propose a locally linear embedding (LLE)-based motion correction method for locally truncated projections. Compared with the fast rotation of the X-ray source, the object motion is relatively slow and can be approximated by a smooth polynomial function. Based on this knowledge, a constraint term is added to optimize the estimated motion parameters. Extensive numerical simulations are performed. Our results demonstrate the feasibility and satisfactory performance of the proposed method. As far as the authors know, this algorithm is the first of its kind for motion parameter estimation only from truncated projections in the CT field."
  },
  {
    "year": "2017",
    "abstract": "Complex wireless transmission systems require multi-dimensional joint statistical techniques for performance evaluation. Here, we first present the exact closed-form results on order statistics of any arbitrary partial sums of gamma random variables with the closed-form results of core functions specialized for independent and identically distributed Nakagami-m fading channels based on a moment generating function-based unified analytical framework. These both exact closed-form results have never been published in the literature. In addition, as a feasible application example in which our new offered derived closed-form results can be applied is presented. In particular, we analyze the outage performance of the finger replacement schemes over Nakagami fading channels as an application of our method. Note that these analysis results are directly applicable to several applications, such as millimeter-wave communication systems in which an antenna diversity scheme operates using a finger replacement schemes-like combining scheme, and other fading scenarios. Note also that the statistical results can provide potential solutions for ordered statistics in any other research topics based on gamma distributions or other advanced wireless communications research topics in the presence of Nakagami fading."
  },
  {
    "year": "2017",
    "abstract": "The presence of faulty valves has been studied in the literature with various machine learning approaches. The impact of using fault data only to train the system could solve the class imbalance problem in the machine learning approach. The data sets used for fault detection contain many independent variables, where the salient ones were selected using stepwise regression and applied to various machine learning techniques. A significant test for the given regression technique was used to validate the outcome. Machine learning techniques, such as decision trees and deep learning, are applied to the given data and the results reveal that the decision tree was able to obtain more than 95% accuracy and performed better than other algorithms when considering the tradeoff between the processing time and accuracy."
  },
  {
    "year": "2017",
    "abstract": "A novel matching network to design quadruplexer is proposed in this paper. The matching network is comprised of two parts and each part consists of a short-circuited transmission line, an open-circuited transmission line, and a series transmission line. The matching network is analyzed to obtain the design curves, which lead to various design parameters. Using this matching network, the quadruplexer can be easily realized by the connection of different bandpass filters without further tuning. Systematic design procedure for quadruplexer is fully presented in this paper. To illustrate the concept, a quadruplexer is designed, fabricated, and measured. Simulated and measured results are found to be in good agreement with each other."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the improvement of the method measuring the junction temperature of lightemitting diodes (LEDs) has been studied experimentally. A practical method is proposed with only three measurement procedures. With the consideration of indium (In) composition and blue shift, the method has a high applicability, which is practical for the LED chips vary from blue to green chips under different currents, including the packaged chips. On the other hand, according to the experimental and derived results, the junction-temperature difference and peak-wavelength shift in both blue-shift and red-shift fields show similar parabolic-like relations. To simplify the experimental processes, dual-wavelength LEDs were fabricated and measured instead of conventional single-wavelength LEDs."
  },
  {
    "year": "2017",
    "abstract": "The emergence of 5G networks will allow cloud computing providers to offer more convenient services. However, security and privacy issues of cloud services in 5G networks represent huge challenges. Recently, to improve security and privacy, a novel primitive was proposed by Ma et al. in TIFS 2015, called public key encryption with equality test supporting flexible authorization (PKEET-FA). However, the PKEET scheme lacks verification for equality test results to check whether the cloud performed honestly. In this paper, we expand the study of PKEET-FA and propose a verifiable PKEET (V-PKEET) scheme, which, to the best of our knowledge, is the first work that achieves verification in PKEET. Moreover, V-PKEET has been designed for three types of authorization to dynamically protect the privacy of data owners. Therefore, it further strengthens security and privacy in 5G networks."
  },
  {
    "year": "2017",
    "abstract": "Recently, short message service (SMS) has become one of the most popular applications for mobile users. However, it provides convenience for worms to spread in mobile networks. Due to the differences between computers and smartphones, the current propagation models of computer worms cannot be employed in the mobile network directly, especially in the SMS scenario. In this paper, we propose a worm propagation model based on SMS, named susceptible-affected-infectious-suspended-recovered. To accurately predict the worm propagation via SMS, first, we add the affected state to represent the state of users who have received the messages but have not clicked the malicious links. Second, since an infected node does not always send malicious messages to others, a novel state, the suspended state, is introduced to describe this situation. Furthermore, related stabilities of the worm-free equilibrium and the endemic equilibrium are studied. The worm-free equilibrium is locally and globally asymptotically stable if the basic reproduction number R0<; 1, whereas the endemic equilibrium is locally asymptotically stable if R0> 1. Finally, comprehensive experiments have been done to support our conclusions and confirm the rationality."
  },
  {
    "year": "2017",
    "abstract": "High-utility itemset mining (HUIM) has become a popular data mining task, as it can reveal patterns that have a high-utility, contrarily to frequent pattern mining, which focuses on discovering frequent patterns. High average-utility itemset mining (HAUIM) is a variation of HUIM that provides an alternative measure, called the average utility, to select patterns by considering both their utilities and lengths. In the last decades, several algorithms have been developed to mine high average-utility itemsets (HAUIs). But most of them consume large amounts of memory and have long execution times, since they generally utilize the average-utility upper-bound (auub) model to overestimate the average utilities of itemsets. To improve the performance of HAUIM, this paper proposes two novel tighter upper-bound models as alternative to the traditional auub model for mining HAUIs. The looser upper-bound model considers the remaining-maximum utility in transactions to reduce the upper bound on the utilities of itemsets. The second upper-bound model ignores irrelevant items in transactions to further tighten the upper bound. Three pruning strategies are also designed to reduce the search space for mining HAUIs by a greater amount compared with the state-of-the-art HAUI-Miner algorithm. Experiments conducted on several benchmark data sets show that the designed algorithm integrating the two novel upper-bound models outperforms the traditional HAUI-Miner algorithm in terms of runtime, memory usage, number of join operations, and scalability."
  },
  {
    "year": "2017",
    "abstract": "Rainbow is one of the most important signature schemes in multivariate public key cryptography. It enjoys a strong security guarantee and is a promising signature scheme in Post-Quantum Cryptography. However, it suffers from large key size. In this paper, we propose Circulant Rainbow with shorter private key and higher signing efficiency. In Circulant Rainbow, we introduce rotating relations into parts of Rainbow private key to speed up the signing procedure and reduce the private key size. We carefully choose security parameters so that our Circulant Rainbow is secure against all known attacks. In our experiment, Circulant Rainbow is about three times faster than original Rainbow and it can reduce the private key size by about 45%. We also make a comparison of Circulant Rainbow with some traditional signature schemes, the results show that Circulant Rainbow is a promising candidate in Post-Quantum Cryptography."
  },
  {
    "year": "2017",
    "abstract": "To settle reactive power sharing inaccuracy among distributed generations (DGs) associated with mismatched lines impedance, a hierarchical control strategy in the framework of multi-agent system (MAS) is proposed. Replace DG by virtual power source (VPS) in droop control and synchronize VPSs voltages by a hierarchical control. Initially, in primary control, improve line feature by defining virtual impedance value, so that VPSs voltages are roughly consistent. Then, design a VPS voltage evaluation index based on reactive power outputs, whose trigger determines whether secondary control is activated. Finally, in secondary control, consensus protocol is used to strictly synchronize actual VPSs voltages with limited voltages information exchange by the sparse communication network. Therefore, MAS is used to provide an appropriate DGs interaction manner and hierarchical control frame. Each DG is associated with a first-level distributed agent to execute primary control. Coordination part is regarded as secondary-level agents to realize secondary control. Hierarchical control provides double safeguards of VPSs voltages synchronization. To verify the effects of control strategy, simulations are carried out on RTLAB and MATLAB/Simulink."
  },
  {
    "year": "2017",
    "abstract": "Security problems have become obstacles in the practical application of wireless sensor networks (WSNs), and intrusion detection is the second line of defense. In this paper, an intrusion detection based on dynamic state context and hierarchical trust in WSNs is proposed, which is flexible and suitable for constantly changing WSNs characterized by changes in the perceptual environment, transitions of states of nodes, and variations in trust value. A multidimensional two-tier hierarchical trust mechanism in the level of sensor nodes (SNs) and cluster heads (CHs) considering interactive trust, honesty trust, and content trust is put forward, which combines direct evaluation and feedback-based evaluation in the fixed hop range. This means that the trust of SNs is evaluated by CHs, and the trust of CHs is evaluated by neighbor CHs and BS; in this way, the complexity of evaluation is reduced without evaluations by all other CHs in networks. Meanwhile, the intrusion detection mechanism based on a self-adaptive dynamic trust threshold is described, which improves the flexibility and applicability and is suitable for cluster-based WSNs. The experiment simulation and evaluation indicate that the mechanism we proposed outperforms the existing typical system in malicious detection and resource overhead."
  },
  {
    "year": "2017",
    "abstract": "A joint multiuser detection (MUD) scheme for wireless sensor networks (WSNs) is proposed to suppress multiple access interference (MAI) caused by a large number of sensor nodes. In WSNs, waveform division multiple access ultra-wideband (WDMA-UWB) technology is well suited for robust communications. Multiple sensor nodes are allowed to transmit modulated signals by sharing the same time periods and frequency bands using orthogonal pulse waveforms. This paper employs a mapping function based on the optimal multiuser detection to map the received bits into the mapping space where error bits can be distinguished. In order to revise error bits caused by MAI, the proposed joint MUD scheme combines the mapping function with suboptimal algorithms. Numerical results demonstrate that the proposed MUD scheme provides good performances in terms of suppressing MAI and resisting near-far effect with low computational complexity."
  },
  {
    "year": "2017",
    "abstract": "With the development of new energy technology, more and more plug-in electric vehicles (PEVs) have appeared in our lives. In vehicle to grid (V2G) information exchange, the method that PEVs use to access the grid for information and vehicular data collection is the key factor that affects the reliability and real-time nature of V2G communication. Vehicular power line communication (VPLC) reuses vehicular power cables as a communication medium, which avoids the need for an additional vehicular communication line and optimizes the in-vehicle space. VPLC is being considered as a more competitive solution to reduce the complexity of design, weight, and cost associated with the rapid growth of electronic devices installed in vehicles, especially for PEVs. Nevertheless, there are factors that impact VPLC in such a way that disrupts reliability and introduces problems. One of these challenges is VPLC channel noise, which can reduce communication reliability. Hence, in this paper, we introduce a V2G information interaction system structure, based on power line communication, to establish a VPLC channel model for the vehicular data collection system. The model is developed in Simulink and leverages various vehicular noise models and binary frequency shift keying (BFSK) modulation; it also analyzes the channel characteristics by examining different types of noise based on BFSK. Our simulation results demonstrate the feasibility of PLC under BFSK modulation and demodulation, often used in PEVs, which could provide guidance to the implementation of VPLC in support of practical engineering."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) is a new technological paradigm that can connect things from various fields through the Internet. For the IoT connected healthcare applications, the wireless body area network (WBAN) is gaining popularity as wearable devices spring into the market. This paper proposes a wearable sensor node with solar energy harvesting and Bluetooth low energy transmission that enables the implementation of an autonomous WBAN. Multiple sensor nodes can be deployed on different positions of the body to measure the subject's body temperature distribution, heartbeat, and detect falls. A web-based smartphone application is also developed for displaying the sensor data and fall notification. To extend the lifetime of the wearable sensor node, a flexible solar energy harvester with an output-based maximum power point tracking technique is used to power the sensor node. Experimental results show that the wearable sensor node works well when powered by the solar energy harvester. The autonomous 24 h operation is achieved with the experimental results. The proposed system with solar energy harvesting demonstrates that long-term continuous medical monitoring based on WBAN is possible provided that the subject stays outside for a short period of time in a day."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a hybrid maximum power point tracking (MPPT) technique for photovoltaic (PV) arrays working under partial shading conditions. This new algorithm can combine a traditional MPPT algorithm, such as perturb and observe, or incremental conductance, with the artificial neural network (ANN) technique. The proposed hybrid MPPT algorithm is based on the ANN and used to predict the global MPP region by estimating its voltage boundaries. Consequently, the conventional MPPT algorithm searches for the MPP in the predicted region. The proposed technique is modeled and simulated using MATLAB/Simulink. The results show the effectiveness of the proposed hybrid MPPT technique to track the global MPP accurately with a rapid response comparing to the ANN; this increases the output power level of the PV array under various shading patterns."
  },
  {
    "year": "2017",
    "abstract": "Recent evidences suggest that complex behavior such as chaos can be observed in a nonlinear system with stable equilibria. However, few studies have investigated chaotic systems with only one stable equilibrium. This paper introduces a new 3-D chaotic system having only one stable equilibrium. Dynamics of the new system are discovered by using phase portraits, basin of attraction, bifurcation diagram, and maximal Lyapunov exponents. It is interesting that the system has a state variable related with the freedom of offset boosting. In addition, we have investigated the anti-synchronization of the system via an adaptive control. Furthermore, the feasibility of the system is also discussed through presenting its electronic circuit implementation."
  },
  {
    "year": "2017",
    "abstract": "Falling is one of the major health threats to the independent living of elders, and falling has received much attention in academia and industry over the past two decades. Previous fall detection methods either require specialized hardware or invade people's daily lives. These limitations make it difficult to widely deploy fall detection systems in houses. On the other hand, a long static case is also one of the health threats to the elderly; these cases indicate that something is abnormal. In this paper, we present the design and implementation of a motion detection system based on passive radio frequency identification tags. The key finding is that static, regular action, and sudden falls make an impact on the RSS and Doppler frequency values differently. Such features help us to detect the status of the elderly. A wavelet transform is used to pre-process the signal data, and a support vector machine is adopted to improve the accuracy of the fall detection. We implemented a prototype monitoring system called TagCare and conducted extensive experiments to demonstrate the accuracy and efficiency of TagCare in movement detection and fall behavior identification for the elderly."
  },
  {
    "year": "2017",
    "abstract": "To enhance the safety and efficiency of civil aviation, special attentions should be paid to pilot's physical and mental health. Existing works used video monitoring and social network mining to find the potential anomalies in pilot's daily life. However, video monitoring suffers from the privacy problems and social network mining is computational complex. To solve the problems of existing works, we propose a novel pilot anomaly detection method using step-sensors. The key idea of this method is that the pilots step information reflects their daily behaviors, and it is also influenced by the behaviors of the pilots social networks; if a pilot step number is extremely different from his historical step numbers or the step numbers of his social networks, this would probably be an anomaly. We, therefore, use the step-sensor to collect pilots step information and use the cluster method to detect anomalies. Experiments are held on 65 pilot candidates, which are divided into two social groups. We collect their step information during 50 days. Using our proposed anomaly detection method, outliers can be successfully detected for further analysis. Our method is also free of privacy problem and is highly efficient."
  },
  {
    "year": "2017",
    "abstract": "Transmission, scattering, and absorption by a layer of dielectric cylinders are studied in the context of microwave propagation through vegetation. The electromagnetic fields are calculated by numerical solutions of 3D Maxwell equations (NMM3D) using the method of Foldy-Lax multiple scattering equations combined with the method of the body of revolution (BOR). Using the calculated transmission, we derive, the “tau”, the optical thickness, which describes the magnitude of the transmission. Two cases are considered: the short-cylinder case and the extended-cylinder case. The case of short cylinders is that the lengths of cylinders are much smaller than the layer thickness, while the case of extended cylinders is that the lengths of the cylinders are the same as or comparable to the layer thickness. Numerical results are illustrated for vertically polarized plane waves obliquely incident on the layer of cylinders. The NMM3D results for the extended-cylinder case show large differences of transmission from the results of the other approaches, such as the effective permittivity (EP), the distorted Born approximation (DBA), and the radiative transfer equation (RTE). For the case of short cylinders, the NMM3D results are in close agreement with those of EP, DBA, and RTE."
  },
  {
    "year": "2017",
    "abstract": "The collection and analysis of data are continuously growing due to the pervasiveness of computing devices. The analysis of such information is fostering businesses and contributing beneficially to the society in many different fields. However, this storage and flow of possibly sensitive data poses serious privacy concerns. Methods that allow the knowledge extraction from data, while preserving privacy, are known as privacy-preserving data mining (PPDM) techniques. This paper surveys the most relevant PPDM techniques from the literature and the metrics used to evaluate such techniques and presents typical applications of PPDM methods in relevant fields. Furthermore, the current challenges and open issues in PPDM are discussed."
  },
  {
    "year": "2017",
    "abstract": "Lithium-ion batteries are crucial to many types of electric equipments. Hence, lithium-ion battery capacity prognostic is significantly important, and it is yet very hard for the measured battery data that are regularly polluted by miscellaneous noises. In this paper, a battery capacity prognostic approach using the empirical mode decomposition (EMD) denoising method and multiple kernel relevance vector machine (MKRVM) approach is presented. The EMD denoising method is employed to process the measured capacity data to produce noise-free capacity data. The battery capacity prediction model using MKRVM is constructed based on the denoised capacity data. The MKRVM's kernel keeps diversity by using multiple heterogeneous kernel learning method. Meanwhile, sparse weights of basic kernel functions are yielded by using particle swarm optimization (PSO) algorithm. The measured battery capacity data are used to demonstrate the effect of EMD denoising method, and battery capacity prediction experiments reveal that the proposed MKRVM approach can predict the battery's future capacity precisely."
  },
  {
    "year": "2017",
    "abstract": "A wearable antenna based on the metal watch strap is proposed. A prototype of a TISSOT classic watch is used for the demonstration. The width of the strap has only a little impact on the radiation patterns. However, the variations of the feeding location would dramatically influence the resonance frequency and the matching performance. The shapes and the graphic patterns of the wristband have contributions on the reflection coefficients as well as the radiation patterns. A fractional bandwidth of 77.8% could be obtained when feeding to the right of the dial at 2.46 GHz, which falls into the ISM (industrial, scientific, and medical) band. The main lobe is fairly wide in both E- and H-planes, which would enable the strap antenna to have a good adaptation for the various postures of the arm. The measurement results show good agreement with that of the simulations, which indicates it a potential option for the applications of wearable systems."
  },
  {
    "year": "2017",
    "abstract": "Demand side management (DSM) will play a significant role in the future smart grid by managing loads in a smart way. DSM programs, realized via home energy management systems for smart cities, provide many benefits; consumers enjoy electricity price savings and utility operates at reduced peak demand. In this paper, evolutionary algorithms-based (binary particle swarm optimization, genetic algorithm, and cuckoo search) DSM model for scheduling the appliances of residential users is presented. The model is simulated in time of use pricing environment for three cases: 1) traditional homes; 2) smart homes; and 3) smart homes with renewable energy sources. Simulation results show that the proposed model optimally schedules the appliances resulting in electricity bill and peaks reductions."
  },
  {
    "year": "2017",
    "abstract": "The tradeoff between the quantum coding rate and the associated error correction capability is characterized by the quantum coding bounds. The unique solution for this tradeoff does not exist, but the corresponding lower and the upper bounds can be found in the literature. In this treatise, we survey the existing quantum coding bounds and provide new insights into the classical to quantum duality for the sake of deriving new quantum coding bounds. Moreover, we propose an appealingly simple and invertible analytical approximation, which describes the tradeoff between the quantum coding rate and the minimum distance of quantum stabilizer codes. For example, for a half-rate quantum stabilizer code having a code word length of n = 128, the minimum distance is bounded by 11 <; d <; 22, while our formulation yields a minimum distance of d = 16 for the above-mentioned code. Ultimately, our contributions can be used for the characterization of quantum stabilizer codes."
  },
  {
    "year": "2017",
    "abstract": "Cloud manufacturing (CMfg) is a new service-oriented production paradigm from the wide application of cloud computing for the manufacturing industry. The aim of this manufacturing mode is to provide resource-sharing and on-demand manufacturing mode to improve operation efficiency. Resource allocation is considered as a crucial technology to implement CMfg. Traditional resource allocation approaches in CMfg mainly focus on the optimal resource selection process, but the energy consumption for manufacturing resources is rarely considered. In response, this paper proposes a hybrid energy-aware resource allocation approach to help requestors acquire energy-efficient and satisfied manufacturing services. The problem description on energy-aware resource allocation in CMfg is first summarized. Then a local selection strategy based on fuzzy similarity degree is put forth to obtain appropriate candidate services. A multi-objective mathematical model for energy-aware service composition is established and the nondominated sorting genetic algorithm (NSGA-II) is adopted to conduct the combinatorial optimization process. Furthermore, a technique for order preference by similarity to an ideal solution is used to determine the optimal composite services. Finally, a case study is illustrated to validate the effectiveness of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "The technology of service-oriented architecture (SOA) and Web service provides a promising method to rapidly develop the distributed interoperable system for E-commerce applications at low cost. Due to the cross-organizational feature, the dynamic replacement of service process is an important way to guarantee the correctness of service software evolution, supporting the capacity of handling unexpected service failures. However, considering the new services used in the reconfigured process may be incompatible, data consistency should be checked to ensure that the original business logics can be accurately simulated. In response to this problem, we propose an approach to data consistency checking for the dynamic replacement of service process. First, the behavioral model and data model for formalizing service process are introduced, and then the data consistency problem of dynamic replacement is discussed. Second, the data replacement patterns are presented to specify different kinds of replacement behaviors. Third, the single-service replacement method is used to check the data consistency of an individual service dynamic replacement, which aims to compute the similarity degree between interface data. The multi-services replacement method is employed to check the data consistency of a set of services dynamic replacements, which explores critical paths to substitute a part of service processes. Finally, a case study and experiments demonstrate the effectiveness and efficiency of the proposed methods in the data consistency of dynamic replacement. Our approach provides fundamental theory guidance to enhance the credibility of service process in the modern service industry."
  },
  {
    "year": "2017",
    "abstract": "Emerging non-volatile memory (NVM) requires refactoring of the hardware and software stacks used on current computer systems. Modern researchers typically rely on simulators to test their innovations. Unfortunately, running a simulation requires orders of magnitude more time than performing a native run, and most simulation platforms are difficult to modify or debug. In this paper, we propose using emulation to reduce the substantial simulation overhead by proposing an extensible lightweight emulation framework called LEEF. Unlike previous NVM emulation implementations, which rely on specific hardware and use simple performance models, LEEF is built on a detailed performance model implemented through performance monitoring events that can be found on most commodity processors. LEEF also exposes a realsystem memory trace generation interface for trace-based memory simulators. Using the traces, simulation results can be analyzed and integrated into future LEEF emulations. The results of experiments show that LEEF is more accurate than prior emulation approaches. We also present two case studies of recent microarchitectural innovations simulated on LEEF. To the best of our knowledge, this is the first work that combines simulation with memory emulation."
  },
  {
    "year": "2017",
    "abstract": "Clustering is fundamental in image processing, machine learning, pattern recognition, and data analysis. For robust clustering, the prerequisite condition is determining the clustering centers robustly. In this paper, we propose to determine the clustering centers from the slope difference distribution of the data. The proposed method comprises two parts: 1) computation of the slope difference distribution from the original data distribution and 2) selection of the peaks of the slope distribution as the clustering centers. We tested the proposed method with two different types of synthesized data sets: 1) data with Gaussian noise and 2) data with salt and pepper noise. Experimental results show that the proposed method is significantly more accurate than the state-of-the-art methods: K-means method, expectation maximization method, and fuzzy C-means method. The significance of determining the clustering centers robustly is also verified by a demonstration."
  },
  {
    "year": "2017",
    "abstract": "A synchronous generator is a key element in maintaining stability in the traditional power system and performs well. However, the high penetration of renewable energy will challenge the stable operation of the future power system, because the characteristics of converter-based resources differ from those of a synchronous generator. As a result, a weak grid caused by a lack of short circuit capacity and inertia, damping, and fault ride-through abilities become important issues for grid stability. To solve these problems, the synchronous motor-generator pair (MGP) was proposed as a possible approach. In this paper, first, state equations considering different frequencies on both sides of the MGP are established. The model for small signal stability is further modified to include the wind generator. On this basis, two systems are tested to investigate the performance of the MGP in small signal stability, torsional modes, rotor angle stability, and voltage support. Finally, on the basis of proposed control strategy, a closed-loop active power control of the MGP is realized by the 3-kW experimental system. The results show that the active power of the system is controllable. The MGP can provide sufficient inertia for frequency stability, restrain oscillation, and maintain rotor angle stability by higher damping and support the voltage."
  },
  {
    "year": "2017",
    "abstract": "Today, a growing number of physical objects in our surroundings are connected to the Internet and provide the digital world with an interface to the physical world through sensors and actuators. At the heart of this trend, smart-* systems and applications leverage this interface to smartly and seamlessly assist individuals in their everyday lives. However, when interacting with the physical world by means of actuators, these applications introduce a methodological disruption. Indeed, in comparison to the classical distributed software applications that operate in the bounded and predictable digital world, these applications operate in and through the physical world, open and subject to uncertainties that cannot be modeled accurately. These uncertainties lead the behavior of the applications to potentially drift at runtime, compromising their intrinsic functionality. In this paper, we propose a framework to estimate the behavioral drift of smart-* systems and applications at runtime. To this end, we first rely on the Moore finite state machine (FSM) modeling framework. This framework is used for specifying the ideal behavior of a smart-* application in terms of the effects, and it is expected to produce within the physical environment as it executes. We then appeal on the control theory and propose a framework for projecting the Moore FSM to its associated continuous density Input/Output hidden Markov model (CD-IOHMM) state observer. By accounting for uncertainties through probabilities, it extends Moore FSM with viability zones, i.e., zones where the effects of a smart-* application within the physical environment are satisfactory without necessarily being perfect. At runtime, the CD-IOHMM state observer can compute the probability of the observed effects, i.e., it gives direct insight into the behavioral drift of the concrete application. We validate our approach on a real data set. The results demonstrate the soundness and efficiency of the proposed approach at es..."
  },
  {
    "year": "2017",
    "abstract": "In Pareto dominance-based multi-objective evolutionary algorithms (PDMOEAs), Pareto dominance fails to provide the essential selection pressure required to drive the search toward convergence in many-objective optimization problems (MaOPs). Recently, the idea of using secondary criterion, such as knee points and so on to enhance the convergence, is becoming popular. In this paper, we propose to employ popular ranking methods-average rank (AR) and weighted sum (WS) of objectives, which are capable of accelerating the convergence as secondary criterion. After nondominated sorting, based on the secondary criterion employed (AR or WS) and a niche radius, nondominated solutions are assigned a rank referred to as priority rank (PR). In other words, among a set of nondominated solutions, solutions that are diverse and best within a neighborhood in terms of ranking method (AR or WS) employed are assigned a better PR. During mating and environmental selections, giving preference to solutions with least PR enables the selection of solutions that are diverse and can improve the convergence speed of MOEA without the need for additional diversity maintenance mechanisms. The performances of proposed PDMOEAs with ranking methods are compared with the state-of-the-art methods to demonstrate the significance of ranking methods in accelerating the convergence. PDMOEA with AR as secondary criterion is referred to as PDMOEA-AR while PDMOEA with WS as secondary criterion is referred to as PDMOEA-WS. From the experimental results, it has been observed that PDMOEAs with ranking methods (PDMOEA-AR and PDMOEA-WS) outperform the state-of-the-art algorithms on benchmark MaOPs, such as DTLZ and WFG. In addition, it has been observed that PDMOEA-AR performs better on a wide variety of MaOPs with diverse characteristics whereas PDMOEA-WS is particularly suitable for only a subclass of MaOPs. In other words, the range-independent nature of AR makes PDMOEA-AR a general-purpose algorithm, which per..."
  },
  {
    "year": "2017",
    "abstract": "Sparse recovery techniques find applications in many areas. Real-time implementation of such techniques has been recently an important area for research. In this paper, we propose computationally efficient techniques based on dichotomous coordinate descent (DCD) iterations for recovery of sparse complex-valued signals. We first consider ℓ2ℓ1optimization that can incorporate a priori information on the solution in the form of a weight vector. We propose a DCD-based algorithm for ℓ2ℓ1optimization with a fixed ℓ1regularization, and then efficiently incorporate it in reweighting iterations using a warm start at each iteration. We then exploit homotopy by sampling the regularization parameter and arrive at an algorithm that, in each homotopy iteration, performs the ℓ2ℓ1optimization on the current support with a fixed regularization parameter and then updates the support by adding/removing elements. We propose efficient rules for adding and removing the elements. The performance of the homotopy algorithm is further improved with the reweighting. We then propose an algorithm for ℓ2ℓ0optimization that exploits homotopy for the ℓ0regularization; it alternates between the least-squares (LSs) optimization on the support and the support update, for which we also propose an efficient rule. The algorithm complexity is reduced when DCD iterations with a warm start are used for the LS optimization, and, as most of the DCD operations are additions and bit-shifts, it is especially suited to real-time implementation. The proposed algorithms are investigated in channel estimation scenarios and compared with known sparse recovery techniques, such as the matching pursuit (MP) and YALL1 algorithms. The numerical examples show that the proposed techniques achieve a mean-squared error smaller than that of the YALL1 algorithm and complexity comparable to that of the MP algorithm."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the operator profit from virtual resource allocation in device-to-device (D2D) communications underlaying long-term evolution networks. By utilizing the power-bandwidth product model as the metric of operator cost, the virtual resource allocation is formulated as a binary integer programming to maximize the difference between the sum rate of all the users and the consumed resources. To reduce the complexity, the formulated problem is decomposed to two subproblems, and for each subproblem, a heuristic algorithm is proposed to transfer the complexity of exponent into polynomial. Simulation results show that the proposed scheme is close to the optimal solution with lower complexity. Meanwhile, it also outperforms the benchmark in terms of the total profit, and enables the desired tradeoff between the operator cost and sum rate of both cellular and D2D users."
  },
  {
    "year": "2017",
    "abstract": "With the application of internet in manufacturing, motion control system is tend to networking. Clock synchronization is a basic requirement to guarantee capability of coordination in networked motion control systems. In this paper, we propose a frequency-tracking clock servo (FTCS) to adjust the local clock to synchronize with the reference clock. The frequency of FTCS can rapidly lock onto the reference frequency and the offset can be fully compensated within a single synchronizing cycle. Simulations and experiments are performed to validate the feasibility and superiority of FTCS. Compared with the proportional-integral clock servo, FTCS can achieve the rapid synchronized speed and better precision with low frequency of sending synchronization messages."
  },
  {
    "year": "2017",
    "abstract": "HBase is a distributed database management system and is becoming increasingly popular for applications that need fast random access to a large amount of data. However, it has a number of performancecritical configuration parameters, which may interact with each other in a complex way, making manually tuning them for optimal performance extremely difficult. In this paper, we propose a novel approach to auto-tune the configuration parameters for a given HBase application, called Auto-Tuning HBase (ATH). The key is an accurate performance model with low cost, which takes configuration parameters as inputs. To this end, we systematically explore different modeling techniques and decide to employ an ensemble learning algorithm to build the performance model. Subsequently, we leverage genetic algorithm to search the optimal configuration parameters for the application by using the performance model. As such, ATH can quickly as well as automatically identify a set of configuration parameter values to make the performance of the application optimal. We validate ATH in a cluster with ten nodes by using five typical applications from Yahoo! Cloud Serving Benchmark. The experimental results show that ATH can improve throughput by 41% on average and up to 97% compared with the default configurations. At the same time, the latency of HBase operations is reduced by 11.3% on average and up to 57%."
  },
  {
    "year": "2017",
    "abstract": "Knowledge of the bubble-forming regime is important for studying the mechanism of gas-liquid two-phase flow. The process of bubble formation through an underwater nozzle at the bottom of a rectangular tank was observed using a high-speed camera. Five bubble-forming regimes were classified by considering both the bubble interaction and the periodic behavior. To automatically identify the bubble-forming regimes, 22 image textural features were extracted based on the grey-level co-occurrence matrix and grey-level gradient co-occurrence matrix. A feature selection method, the mathematical correlation weight algorithm (MCWA), was proposed to select the optimal textural feature subset for bubble-forming regime recognition. Experimental results demonstrated that the identification rates based on the feature subset selected by MCWA were 99.81% and 99.24% for support vector machine and artificial neural network, respectively, which were higher than those by the between-class distance method and the Fisher algorithm. The MCWA proposed in this paper is an effective feature selection method and can be widely used in pattern recognition."
  },
  {
    "year": "2017",
    "abstract": "Cognitive radio technology is an important branch in the field of wireless communication, and automatic identification is a major part of cognitive radio technology. Convolutional neural network (CNN) is an advanced neural network, which is the forefront of application in the digital image recognition area. In this paper, we explore CNN in an automatic system to recognize the cognitive radio waveforms. Excitedly, it is a more effective model with high ratio of successful recognition (RSR) under high power background noise. The system can identify eight kinds of signals, including binary phase shift keying (Barker codes modulation) linear frequency modulation, Costas codes, Frank code, and polytime codes (T1, T2, T3, and T4). The recognition part includes a CNN classifier. First, we determine the appropriate architecture to make CNN effective for proposed system. Specifically, we focus on how many convolutional layers are needed, what appropriate number of hidden units is, and what the best pooling strategy is. Second, we research how to obtain the image features into CNN that based on Choi-Williams time-frequency distribution. Finally, by means of the simulations, the results of classification are demonstrated. Simulation results show the overall RSR is 93.7% when the signal-to-noise ratio is -2dB."
  },
  {
    "year": "2017",
    "abstract": "Starting in July 2016, the Ministry of Science and Technology of China, along with several other national agencies, sponsors a 54-month 45-million RMB (Chinese Yuan) project on knowledge engineering with Big Data (www.bigke.org) for 15 top research and development institutions to study the fundamental theory and the applications of BigKE, a big-data knowledge engineering framework that handles fragmented knowledge modeling and online learning from multiple information sources, nonlinear fusion on fragmented knowledge, and automated demand-driven knowledge navigation. The project seeks to provide petabyte-scale data and knowledge services in identified application domains. In this paper, we discuss our BigKE framework, and present a novel application scenario for BigKE services."
  },
  {
    "year": "2017",
    "abstract": "Content centric network (CCN) is a robust and uncomplicated communication paradigm. It introduces built-in features, such as data authenticity, in-networking caching, mobility, flow balance methods, and multi-cast data delivery. Data packet flooding is a hot research issue due to the broadcast nature of the CCN-based wireless multimedia sensor networks (WMSNs). To mitigate this problem, in this paper, we have proposed a novel protocol, named packet diffusion-limited protocol for CCN-based WMSNs for smart cities. Extensive evaluation of the proposed protocol is performed by using ndnSIM that is based on NS-3 simulator. Simulation results show that proposed protocol not only limits flooding of Data packets as well as speeds up content download time by using a shortest path."
  },
  {
    "year": "2017",
    "abstract": "With the emergence of the fifth generation (5G) wireless networks, not only is the increase in mobile broadband targeted, but also the support of various novel use cases, such as industrial automation, autonomous vehicles, e-health, and Internet of Things together with their requirements leading to highly heterogeneous wireless networks. This requires a re-design of the network architecture to ensure the coexistence of these use cases and guarantee user experience and service requirements. Therefore, 5G networks will be highly flexible and support online learning and autonomous decision making capabilities in a centralized and distributed manner to ensure highly efficient management of wireless and network resources. In this paper, the main features enabling flexibility and autonomy in 5G networks are discussed together with potential applications in different layers of the wireless network."
  },
  {
    "year": "2017",
    "abstract": "The cloud computing paradigm faces the challenges of providing low latency, high availability, and real-time location-aware services where millions of people are mobile with respect to time and geographic location. In this paper, we propose a mobile edge computing framework that can support real-time, location-aware personalized services to a very large crowd. The framework uses a hybrid of cloud at the server end and fog computing terminals (FCTs) at the crowd edge. The concept of FCT is realized by adding a middle layer acting as a proxy between the user end and cloud infrastructure. Each FCT node covers a geographic zone and provides a subset of services and resources based on the geographic location of a mobile user. When a user moves from one FCT-covered zone to another, the secure handshaking of metadata about the user is shared with the new FCT node. The communication between mobile users' terminals, such as smartphone and the FCT, is assumed as 4G/5G networks, while the communication between the FCT and cloud is based on a high speed, always available, and reliable Internet connection. The location of each mobile user is made secure and shared according to our novel privacy policy paradigm. The framework is designed to switch between FCT and cloud, depending on the task, network condition, geographic nearness, and resources available within the client unit. We have implemented the framework to support context-aware services to millions of pilgrims that gather together in a very small area of land each year. We will share the inspiring results that we have gathered after initial deployment."
  },
  {
    "year": "2017",
    "abstract": "This paper presents system modelling and characterization of multiple-band notched ultrawideband (UWB) antennas using the singularity expansion method (SEM). Multiple-band notches in a classical UWB coplanar disc monopole antenna are achieved by introducing systematic defection slots in the coplanar ground structure solely. The antenna uses two dual-band meander ground-defects to create quadruple band notches to avoid possible interference with pre-existing standard services. The SEM with an improved pole-residue extraction scheme is developed to precisely characterize the band-notched antenna in the time and frequency domains. The improved matrix pencil method is applied to the bore sight impulse response of the proposed notched-band UWB antenna to precisely recognize the band-notches and extract the complex poles and residues at the operating bands between the reject-bands. This procedure is validated by reconstructing the impulse response of the antenna from the extracted poles and residues. The obtained simulation and measurement results are in a very good agreement and demonstrate the reliability of the proposed antenna model and characterization method."
  },
  {
    "year": "2017",
    "abstract": "A simple field prediction model based on a combination of a two-parameter propagation formula and a multi-wall model is proposed for fast and yet accurate indoor and indoor-to-outdoor field prediction. The model's approach is based on: simplicity; physical soundness; and adaptability to the available environment-database format. The model is validated versus both ray tracing and measurements in different environments and it is shown to perform very well in all cases. Moreover, the model is very fast and can exploit the accuracy plus of deterministic prediction based on the 3-D indoor building map whenever it is available."
  },
  {
    "year": "2017",
    "abstract": "Dynamic smart grid operations require that utilities that incorporate intermittent renewable energy resources provide creative and inclusive solutions to reduce and shift electrical demand. Commercial building HVAC systems have been used as a dispatchable load, but are limited by the lack of interoperability. Increased operability can be achieved using a secure and reliable interconnection device, which can provide direct bidirectional communications between the utility and the building automation system (BAS) controllers. This paper developed and tested a building automation intrusion detection system (BAIDS) that can provide a cyber-secure connection between public and private BAS networks. The BAIDS was used in a hardware-in-the-loop experiment that connected an actual photovoltaic array with a BAS control test bed and a building zone model. The BAIDS device allowed for critical control signals to pass from the public network directly to a fan controller in a BAS private network. At the same time, the BAIDS device provided intrusion detection monitoring to identify malicious activity. The network traffic was evaluated using an adaptive resonance theory (ART) artificial neural network. The ART algorithm was able to learn normal traffic activity on the private and public networks. The algorithm was then used to detect unauthorized attempts to access the interconnection device and a malicious cyber-physical attack on the BAS."
  },
  {
    "year": "2017",
    "abstract": "One of the most widely studied problems in the analysis of complex networks is the detection of community structures. Many algorithms have been proposed to find communities but the quest to find the best algorithm is still on. More often than not, researchers focus on developing fast and accurate algorithms that can be generically applied to networks from various domains. As the topology of networks changes with respect to domains, community detection algorithms fail to accommodate these changes to detect communities. In this paper, we attempt to highlight this problem by studying networks with different topologies and evaluate the performance of community detection algorithms in the light of these topological changes. To generate networks with different topologies, we used the well-known Lancichinetti-Fortunato-Radicchi (LFR) model, and we also propose a new model named Naïve Scale-Free Clustering to avoid any bias that can be introduced by the underlying network generation model. Results reveal several limitations of the current popular network clustering algorithms failing to correctly find communities. This suggests the need to revisit the design of current clustering algorithms in order to improve their performances."
  },
  {
    "year": "2017",
    "abstract": "E-learning has reshaped traditional education into more flexible and efficient learning in developed nations. However, e-learning remains underutilized and in the rudimentary stages of development in developing countries. Therefore, understanding the critical factors behind the adoption and acceptance of technology is a prime concern in developing countries like Pakistan. This paper provides and examines the adoption and acceptance baseline for e-learning systems by incorporating critical external factors in the technology acceptance model. A conceptual model-the Pakistan E-Learning Adoption Model-is proposed in the context of higher education. Data were collected from 354 learners at the Virtual University of Pakistan and structural equation modeling was employed to test the research hypotheses. The empirical investigation indicates that computer self-efficacy, Internet experience, enjoyment, and system characteristics are significant predictors of perceived ease of use, while system characteristics are a strong predictor of perceived usefulness. Moreover, the subjective norm is not found to be significant for perceived usefulness. The findings provide practical implications for policy makers, practitioners, and developers in successful e-learning systems implementation."
  },
  {
    "year": "2017",
    "abstract": "Multiple-input multiple-output (MIMO) systems capacity is highly influenced by the correlation between antennas, and the high correlation will result in a low capacity. Therefore, the multipolarized antennas have been implemented in MIMO systems to reduce the correlation between antennas and realize the space efficiency. To better understand the performance of multi-polarized MIMO systems, polarization channel modeling is of great importance. In this paper, we establish a 3-D geometrical model for multi-polarized MIMO systems. Antenna cross-polar isolation (XPI), channel cross-polarization discrimination (XPD) and antenna tilt parameters have been considered in our model. The correlation and capacity of multi-polarized MIMO systems are analyzed, and we find that the XPI, XPD, and antenna tilt have an effect on the correlation and capacity simultaneously, which cannot be analyzed separately. Also, we compare our model with the existing measurements for validation, which shows that the proposed model is well in agreement with the measurements. Finally, we compare the performance of multi-polarized MIMO systems with the traditional uni-polarized MIMO systems, which shows that the performance of multipolarized MIMO systems have robustness to the communication environment, and multi-polarized MIMO systems outperform uni-polarized MIMO systems in many communication scenarios."
  },
  {
    "year": "2017",
    "abstract": "Characterization of flow behaviors is one of the most challenging problems in a gas-liquid flow system. In this paper, correlation dimension, a chaotic characteristic indicator, was introduced to characterize the gas-liquid two-phase flow behaviors by using the fluctuating pressure induced by a bluff body. An artificial neural network was trained to help select suitable flow parameters that were combined with correlation dimension to construct a novel gas-liquid flow pattern map, which was able to distinguish between the bubble, bubble/plug transitional, plug, slug, and annular flows with reasonable accuracy. Furthermore, a quantitative correlation with the form of ug= AD2BuCwas established by the universal fitting and the pattern-specific fitting with the coefficients of determination R2approaching to 1. In view of the simplicity and the convenience of vortex generation and pressure measurement, the correlation dimension-based method provides an effective and practical idea to gas-liquid two-phase flows study."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a light-weight rapid control prototyping (RCP) system based on off-the-shelf open source hardware to achieve high performance computing, cost effectiveness, portability, and easy accessiblity. The proposed RCP system consists of a PC-based computer-aided control system design (CACSD) tool for computing control action and tiny palm-sized open source hardware for input and output (I/O) operation and data transfer through a built-in high-speed USB interface. The popular-priced and portable open source hardware is used as a bridge between CACSD tools and real plants to deliver the control and sensor data at the sampling time points. Ten I/O function blocks written in C code are developed based on the CACSD tool employed for the proposed light-weight RCP system in order to handle I/O operation in a simple way. In addition, we suggest two practical strategies, a batch transfer strategy and a variable sampling period method, to increase the sampling rate of the control system. It is shown through experiment that the proposed light-weight RCP system works well up to a sampling rate of 2 kHz without adopting expensive hardware and C code generators. It is expected that the proposed RCP system will be considered as affordable and readily available to schools for mass education."
  },
  {
    "year": "2017",
    "abstract": "The split control and user plane is key to the future heterogeneous cellular network (HCN), where the small cells are dedicated for the most data transmission while the macrocells are mainly responsible for the control signaling. Adapting to this technology, we propose a general and tractable framework of extra cell range expansion (CRE) by introducing an additional bias factor to enlarge the range of small cells flexibly for the extra offloaded macrousers in a two-tier HCN, where the macrocell and small cell users have different required data rates. Using stochastic geometry, we analyze the energy efficiency (EE) of the extra CRE with joint low power transmission and resource partitioning, where the coverages of EE and data rate are formulated theoretically. Numerical simulations verify that the proposed extra CRE can improve the EE performance of HCN, and also show that deploying more small cells can provide benefits for EE coverage, but the EE improvement becomes saturated if the small cell density exceeds a threshold. Instead of establishing the detail configuration, this paper can provide some valuable insights and guidelines to the practical design of future networks, especially for the traffic offloading in HCN."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the effective rate of multiple-input single-output (MISO) systems over independent and identically (i. i. d.) distributed κ-μ shadowed fading channels is studied under delay constraints. We derive an analytical expression for the effective rate of MISO systems over κ-μ shadowed fading channels. The approximate analysis method is further invoked to solve the infinite series problem. Based on the moment matching method, a closed-form expression for the effective rate is obtained. In addition, to capture insights into the effects of the model and fading parameters on the effective rate of the systems, the asymptotic effective rates in the high- and low-signal-to-noise ratio (SNR) regimes are obtained. The analytical results are compared with Monte Carlo simulations, which validate the correctness of the theoretical analysis."
  },
  {
    "year": "2017",
    "abstract": "The developments and applications of wireless body area networks (WBANs) for healthcare and remote monitoring have brought a revolution in the medical research field. Numerous physiological sensors are integrated in a WBAN architecture in order to monitor any significant changes in normal health conditions. This monitored data are then wirelessly transferred to a centralized personal server (PS). However, this transferred information can be captured and altered by an adversary during communication between the physiological sensors and the PS. Another scenario where changes can occur in the physiological data is an emergency situation, when there is a sudden change in the physiological values, e.g., changes occur in electrocardiogram (ECG) values just before the occurrence of a heart attack. This paper presents a centralized approach for the detection of abnormalities, as well as intrusions, such as forgery, insertions, and modifications in the ECG data. A simplified Markov model-based detection mechanism is used to detect changes in the ECG data. The features are extracted from the ECG data to form a feature set, which is then divided into sequences. The probability of each sequence is calculated, and based on this probability, the system decides whether the change has occurred or not. Our experiments and analyses show that the proposed scheme has a high detection rate for 5% as well as 10% abnormalities in the data set. The proposed scheme also has a higher true negative rate with a significantly reduced running time for both 5% and 10% abnormalities. Similarly, the receiver operating characteristic (ROC) and ROC convex hull have very promising results."
  },
  {
    "year": "2017",
    "abstract": "The envisioned dense nano-network inside the human body at terahertz (THz) frequency suffers a communication performance degradation among nano-devices. The reason for this performance limitation is not only the path loss and molecular absorption noise, but also the presence of multi-user interference and the interference caused by utilising any communication scheme, such as time spread ON—OFF keying (TS-OOK). In this paper, an interference model utilising TS-OOK as a communication scheme of the THz communication channel inside the human body has been developed and the probability distribution of signal-to-interference-plus-noise ratio (SINR) for THz communication within different human tissues, such as blood, skin, and fat, has been analyzed and presented. In addition, this paper evaluates the performance degradation by investigating the mean values of SINR under different node densities in the area and the probabilities of transmitting pulses. It results in the conclusion that the interference restrains the achievable communication distance to approximate 1 mm, and more specific range depends on the particular transmission circumstance. Results presented in this paper also show that by controlling the pulse transmission probability and node density, the system performance can be ameliorated. In particular, SINR of in vivo THz communication between the deterministic targeted transmitter and the receiver with random interfering nodes in the medium improves about 10 dB, when the node density decreases one order. The SINR increases approximate 5 and 2 dB, when the pulse transmitting probability drops from 0.5 to 0.1 and 0.9 to 0.5."
  },
  {
    "year": "2017",
    "abstract": "Deployment of commercial computer networks sets high requirements for procedures, tools, and approaches for comprehensive testing of these networks. However, in spite of the great efforts of many researchers, the process of test design/generation still tends to be unstructured and bound to the personal experience and/or intuition of individual engineers. To address the problem, this paper introduces an approach of automated generation of abstract test cases based on the concept of multilayer networks. Test cases of that kind cover network infrastructures, including individual components and component-to-component interactions on all coexisting architectural layers, and provide information for subsequent analysis to ensure that the used formal model is consistent with respect to test requirements."
  },
  {
    "year": "2017",
    "abstract": "Although several efficient learning methods have recently been proposed to handle class drift situations, issues remain in various streaming data applications that possibly deteriorate classification accuracy. Three important issues were considered, that is: 1) lifetime and class changes; 2) high imbalance ratios of streaming data among classes; and 3) classification accuracy of untrained data and class-changed data. A new dynamical learning structure based on hyper-elliptical capsule and multi-stratum network was introduced to cope with these issues. The experimental results on a simulated University of California at Irvine non-concept-drift database and real concept-drift data confirm that the proposed multi-stratum learning provided better accuracy, faster learning speed, and lower structural complexity than other concept-drift algorithms."
  },
  {
    "year": "2017",
    "abstract": "Process capability index (PCI) is used to quantify the process performance and is becoming an attracted area of research. A variability measure plays an important role in PCI. The interquartile range (IQR) or the median absolute deviation (MAD) is commonly used for a variability measure in estimating PCI when a process follows a non-normal distribution In this paper, the efficacy of the IQR and MAD-based PCIs was evaluated under low, moderate, and high asymmetric behavior of the Weibull distribution using different sample sizes through three different bootstrap confidence intervals. The result reveals that MAD performs better than IQR, because the former produced less bias and mean square error. Also, the percentile bootstrap confidence interval is recommended for use, because it has less average width and high coverage probability."
  },
  {
    "year": "2017",
    "abstract": "Compressive sensing (CS) provides a new paradigm for correlated data processing and transmission over wireless sensor networks (WSNs). In this paper, we take a new look to investigate the performance of CS for data gathering from the perspective of in-network computation. We formulate the problem of computing random projections for CS in WSNs as in-network function computation in random geometric networks. We focus on the design and performance analysis of the protocols that are efficient in terms of computation complexity. We first propose an efficient tree-based computation protocol with an optimal refresh rate and characterize the scaling laws of energy and latency requirements, which show that it can reduce energy consumption and latency compared with the traditional approach. Then, we present a more efficient block computation protocol by considering the correlations of temporal measurements in function computation to improve the performance in terms of refresh rate and energy consumption. We also devise a gossip-based scheme to improve the robustness of function computation, which is able to distribute computation results to all the nodes throughout the network. We show that the proposed protocol can improve upon the existing gossip-based schemes in terms of energy consumption. Finally, simulation results are also presented to demonstrate the effectiveness of the proposed protocols."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes an analytical model to evaluate the performance of the listen before talk (LBT) based coexistence scheme in the scenario with multiple LTE small bases (SBSs) over the unlicensed spectrum. Based on the proposed model, we further derive the expressions of the occupancy time of the LTE/Wi-Fi/access overhead and the collision probability. It is shown from numerical results that the LBT-based coexistence scheme is not fair enough for the Wi-Fi system in the coexistence scenario with multiple LTE SBSs, and thus the number of LTE SBSs and the length of the LTE frame should be carefully designed to protect the Wi-Fi system."
  },
  {
    "year": "2017",
    "abstract": "Smart Grids (SGs) have many advantages over traditional power grids as they enhance the way electricity is generated, distributed, and consumed by adopting advanced sensing, communication, and control functionalities that depend on power consumption profiles of consumers. Clustering algorithms (e.g., centralized clustering) are used for profiling individuals' power consumption. Due to the distributed nature and ever growing size of SGs, it is predicted that massive amounts of data will be created. However, conventional clustering algorithms are neither efficient enough nor scalable enough to deal with such amount of data. In addition, the cost for transferring and analyzing large amounts of data is high both computationally and communicationally. This paper thus proposes a power consumption profiling model based on two levels of clustering. At the first level, local power consumption profiles are derived, which are then used by the second level in order to create a global power consumption profile. The followed approach reduces the communication and computation complexity of the proposed two level model and improves the privacy of consumers. We point out that having a good knowledge of the local power profiles leads to more effective prediction model and cost-effective power pricing scheme, especially in a heterogeneous grid topology. In addition, the correlations between the local and global profiles can be used to localize/identify power consumption outliers. Simulation results illustrate that the proposed model is effective in reducing the computational complexity without much affecting its accuracy. The reduction in computational complexity is about 52% and the reduction in the communicational complexity is about 95% when compared with the centralized clustering approach."
  },
  {
    "year": "2017",
    "abstract": "Information centric networking (ICN) has been recently proposed as a prominent solution for content delivery in vehicular ad hoc networks. By caching the data packets in vehicular unused storage space, vehicles can obtain the replicate of contents from other vehicles instead of original content provider, which reduces the access pressure of content provider and increases the response speed of content request. In this paper, we propose a community similarity and population-based cache policy in an ICN vehicle-to-vehicle scenario. First, a dynamic probability caching scheme is designed by evaluating the community similarity and privacy rating of vehicles. Then, a caching vehicle selection method with hop numbers based on content popularity is proposed to reduce the cache redundancy. Moreover, to lower the cache replacement overhead, we put forward a popularity prediction-based cooperative cache replacement mechanism, which predicts and ranks popular content during a period of time. Simulation results show that the performance of our proposed mechanisms is greatly outstanding in reducing the average time delay and increasing the cache hit ratio and the cache hit distance."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the study of sensitivity distribution of the capacitively coupled electrical resistance tomography (CCERT) and the influences of excitation patterns on sensitivity distributions. The sensitivity distributions of a 12-electrode CCERT sensor under three excitation patterns (the one-electrode excitation pattern, the three-electrode excitation pattern, and the five-electrode excitation pattern) are investigated and compared. The simulation study was implemented by the COMSOL Multiphysics FEM simulation software and MATLAB. The research results show that there is no negative region in the sensitivity distributions of the CCERT sensor and all the sensitivity distributions are not uniform. The research results also indicate that as the number of excitation electrodes increases, the sensitivity distributions have higher average sensitivity and better distribution uniformity."
  },
  {
    "year": "2017",
    "abstract": "Combining C4D technique and cross-correlation velocity measurement technique, a new measurement method, which is suitable for the bubble/slug velocity measurement in millimeter-scale pipelines, is proposed. Based on the series resonance principle and the simulated inductor technique, a new C4D sensor is developed. With two conductance signals obtained by two new C4D sensors (the upstream sensor and the downstream sensor), the bubble/slug velocity measurement is implemented by the cross-correlation velocity measurement technique. Experiments are carried out in three pipelines with different inner diameters of 4.50, 5.46, and 6.44 mm, respectively. The experimental results show that the proposed bubble/slug velocity measurement method is effective, the development of the new C4D sensor is successful, and the velocity measurement accuracy is satisfactory. The relative error of bubble velocity measurement is less than 5.41% and the relative error of slug flow velocity measurement is less than 4.90%."
  },
  {
    "year": "2017",
    "abstract": "With the advent of the Internet of Things, lightweight devices necessitate secure and cost-efficient key storage. Since traditional secure key storage is expensive, novel solutions have been developed based on the idea of deriving the key from noisy entropy sources. Such sources when combined with fuzzy extractors allow cryptographically strong key derivation. Information theoretic fuzzy extractors require large amounts of input entropy to account for entropy loss in the key extraction process. It has been shown by Fuller et al. (ASIACRYPT'13) that the entropy loss can be reduced if the requirement is relaxed to computational security based on the hardness of the Learning with Errors problem. Using this computational fuzzy extractor, we show how to construct a device-server authentication system providing outsider chosen perturbation security and pre-application robustness. We present the first implementation of a lossless computational fuzzy extractor, where the entropy of the source equals the entropy of the key on a constrained device. The implementation needs only 1.45 KB of SRAM and 9.8 KB of Flash memory on an 8-b microcontroller. Furthermore, we also show how a device-server authentication system can be constructed and efficiently implemented in our system. We compare our implementation to existing work in terms of security, while achieving no entropy loss."
  },
  {
    "year": "2017",
    "abstract": "Total harmonic distortion, produced with the existing PWM techniques for a Z-source inverter topology, is higher due to the unsymmetrical shoot-through, if separate controls of ac and dc sides are required. This paper proposes the concept of symmetrical shoot-through-based modulation and compares the performance with the case of the popular simple boost control. The proposed modulation method achieves a sinusoidal and symmetrical distribution of shoot-through states. This ensures an improved current and voltage profile at the output, along with the capability of decoupled control for the shoot-through and the modulation index control. The effectiveness of the proposed method has been demonstrated and validated through analysis, simulation, and experimentation. This concept can be applied to all the variants of Z-source-based power conversions."
  },
  {
    "year": "2017",
    "abstract": "There are a variety of complex constraints in the wide application of wireless sensor networks. Traditional coverage models and algorithms have been unable to meet the needs of multi-constrained sensor networks. At the same time, in a complex monitoring environment, a single type of sensor information cannot meet the requirements of reliable monitoring. Hence, in this paper, aiming at the multi-constraints in sensor networks, a compound event barrier coverage algorithm is proposed based on environment Pareto-dominated selection strategy, which can distribute the sensor resources reasonably and find out the coverage ratio efficiently in multi-constraints sensor networks. The proposed algorithm takes advantage of Pareto domination relationship, constraint violation degree, constraint boundary distance, and crowding degree to preserve the outstanding infeasible individuals in the evolutionary process and participate in the mutation operation; we also adopt the adaptive scaling factor and crossover probability strategy to avoid the algorithm into local optimal. The proposed algorithm is proved to be more highly efficient than the latest algorithm in the distribution of sensor resources by experimental results."
  },
  {
    "year": "2017",
    "abstract": "Machine learning has been successfully applied to many areas of science and engineering. Some examples include time series prediction, optical character recognition, signal and image classification in biomedical applications for diagnosis and prognosis and so on. In the theory of semi-supervised learning, we have a training set and an unlabeled data, that are employed to fit a prediction model or learner, with the help of an iterative algorithm, such as the expectation-maximization algorithm. In this paper, a novel non-parametric approach of the so-called case-based statistical learning is proposed in a low-dimensional classification problem. This supervised feature selection scheme analyzes the discrete set of outcomes in the classification problem by hypothesis-testing and makes assumptions on these outcome values to obtain the most likely prediction model at the training stage. A novel prediction model is described in terms of the output scores of a confidence-based support vector machine classifier under class-hypothesis testing. To have a more accurate prediction by considering the unlabeled points, the distribution of unlabeled examples must be relevant for the classification problem. The estimation of the error rates from a well-trained support vector machines allows us to propose a non-parametric approach avoiding the use of Gaussian density function-based models in the likelihood ratio test."
  },
  {
    "year": "2017",
    "abstract": "Industrial buildings are demonstrating increasing rates of energy consumption, with heating, ventilation, and air conditioning (HVAC) typically constituting over 50% of this consumption. However, these energy requirements are heavily influenced by weather conditions based on the season, the time of day, and different in-building activities. These activities take place in industrial setup over 24 h and have different HVAC energy requirements. In this paper, we propose a binary (0,1) integer linear programming approach to efficiently schedule activities based on weather forecasting, thus minimizing the energy required by HVAC. Experimental results show that energy consumption can be reduced by up to 30%."
  },
  {
    "year": "2017",
    "abstract": "Multimedia learning is the process of building mental representation from words associated with images. Due to the intuitiveness and vividness of visual illustration, many texts to picture systems have been proposed. However, we observe some common limitations in the existing systems, such as the retrieved pictures may not be suitable for educational purposes. Also, finding pedagogic illustrations still requires manual work, which is difficult and time-consuming. The commonly used systems based on the best keyword selection and the best sentence selection may suffer from loss of information. In this paper, we present an Arabic multimedia text-to-picture mobile learning system that is based on conceptual graph matching. Using a knowledge base, a conceptual graph is built from the text accompanied with the pictures in the multimedia repository as well as for the text entered by the user. Based on the matching scores of both conceptual graphs, matched pictures are assigned relative rankings. The proposed system demonstrated its effectiveness in the domain of Arabic stories, however, it can be easily shifted to any educational domain to yield pedagogical illustrations for organizational or institutional needs. Comparisons with the current state-of-the-art systems, based on the best keyword selection and the best sentence selection techniques, have demonstrated significant improvements in the performance. In addition, to facilitate educational needs, conceptual graph visualization and visual illustrative assessment modules are also developed. The conceptual graph visualization enables learners to discover relationships between words, and the visual illustrative assessment allows the system to automatically assess the performance of a learner. The profound user studies demonstrated the efficiency of the proposed multimedia learning system."
  },
  {
    "year": "2017",
    "abstract": "Recently, increasing attention has been paid to the detection of spatio-temporal interest points (STIPs), which has become a key technique and research focus in the field of computer vision. Its applications include human action recognition, video surveillance, video summarization, and content-based video retrieval. Amount of work has been done by many researchers in STIP detection. This paper presents a comprehensive review on STIP detection algorithms. We first propose the detailed introductions and analysis of the existing STIP detection algorithms. STIP detection algorithms are robust in detecting interest points for video in the spatio-temporal domain. Next, we summarize the existing challenges in the STIP detection for video, such as low time efficiency, poor robustness with respect to camera movement, illumination change, perspective occlusion, and background clutter. This paper also presents the application situations of STIP and discusses the potential development trends of STIP detection."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel method, referred to as locally linear detail injection (LLDI), for the pansharpening problem, which is based on the assumption that the spatial details of each multispectral (MS) band can be locally and linearly represented by the spatial details of panchromatic images. LLDI first exploits such assumption through scales using the modulation transfer function (MTF) of the MS instrument and then performs detail injections into the available low-resolution MS images. Visual analysis and quantitative evaluation performed on QuickBird and WorldView-2 data sets at both reduced and full scales show that the proposed LLDI achieves superior improvements over its baselines."
  },
  {
    "year": "2017",
    "abstract": "Co-frequency and co-time full-duplex (CCFD) technique claims to be the most potential duplex scheme for the next generation system, since it can double the spectral efficiency. The challenge of CCFD wireless communication systems lies in mitigating the self-interference (SI). In this paper, we focus on the digital SI cancellation (SIC) in the CCFD systems. The performance of the traditional digital cancellation techniques is mainly limited by the nonlinearity of the components of local transmitter. Aiming at the issue an auxiliary receive chain is employed in this paper. In addition, by exploiting the independence between signal of interest and self-interfering signal, two digital SIC algorithms based on independent component analysis are developed for two application scenarios of the CCFD technique, i.e., CCFD satellite communication systems and ground CCFD communication systems. Instead of achieving cancellation by reconstructing self-interfering signal in other works, the proposed algorithms extract desired signal from the received signal. Simulation results indicate that the proposed algorithms outperform conventional least square digital cancellation method."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a blind interference alignment (BIA) scheme in two-cell Z interference multiple-input multiple-output channel where the cell edge user equipment (UE) of the first cell is interfered by the base station of the second cell during downlink transmissions, while the UE of the second cell is free from inter-cell interference. By employing the reconfigurable antennas at receivers, the transmit strategy of the proposed scheme is designed. The achievable degree of freedom (DoF), the achievable rates, and the bit error rate performance of the proposed BIA scheme are analyzed. Simulation results show that the achievable DoF and the throughput of the proposed scheme are improved compared with conventional interference control scheme. Furthermore, in the proposed BIA scheme, all UEs can achieve a good diversity gain to combat fading."
  },
  {
    "year": "2017",
    "abstract": "A state estimation-based dynamic encryption and authentication (SEDEA) approach is proposed to protect the communication between the control center (CC) and remote terminal units (RTUs) in the smart grid, including the measurements reported from RTUs and the commands sent from the CC. The measurements of power systems are selected to generate encryption keys, which are measured on the RTUs, and estimated on CC using state estimation. With the changes of the power system, each RTU updates its key regularly, and the CC estimates the new keys of all RTUs dynamically and synchronously. The pairs of keys between the CC and each RTU are applied to ensure the confidentiality and integrity of their communication. The advantages of SEDEA could be summarized as follows. First, high security-the keys are difficult to predict and steal, since the power measurements, used to generate the keys, are constantly changing and unpredictable, and would never be exchanged in the network. Second, easy implementation-all measuring equipment on RTU and state estimation on the CC are the legacy of the current power system. And the encryption functions applied in SEDEA are simple and low cost for current devices in the power system, such as XOR, hash, and rounding. Thus, SEDEA is considered as a high-security, inherent and light-weight scheme for Smart Grid. In the experiments, we conduct SEDEA on the four-bus system to show the whole process step by step, including state estimation, key generation, and error correction. And the simulations on the IEEE 39-bus system to analyze the computation cost, error correction, and security of SEDEA."
  },
  {
    "year": "2017",
    "abstract": "In the field of recommender systems, the Beer & Nappies is a famous story, which reveals the latent relationships between different categories of items. Though matrix factorization (MF) has demonstrated its great effectiveness in most previous work, it neglects the co-occurrences of items selected by individuals. In most MF-based models, the latent preferences of users (or the latent categories of items) are assumed independent, which thereby leads to the weak correlation between the Beer and the Nappies. It also greatly limits the models' ability in recommendation. In this paper, we propose a pure probabilistic generative model, which applies a Gaussian prior to capture the semantic correlations between the latent factors. We also show that our model theoretically achieves better expressive power than traditional MF-based models. We derive efficient inference and learning algorithms based on variational EM methods. The effectiveness of our proposed model is comprehensively verified on three different public data sets. Experimental results show that our approach achieves significant improvements on prediction quality compared with the current state of the art."
  },
  {
    "year": "2017",
    "abstract": "How to provide efficient information service for high-mobility scenarios, including high-speed railway communications (HSRCs), is one of the most important requirements in future 5G communication networks. In HSRCs, due to pass-loss effect, the information rate between roadside base station (BS) and the moving train closely depends on the distance between the BS and the train, and the high-mobility speed of trains makes the path loss vary fast with time. It is essential to implement time-domain power allocation to mitigate the near-far effect. To explore the information transmission capacity of HSRCs, some power allocation schemes were developed. With the water-filling method, the maximum amount of information (mobile service amount) can be delivered, where, however, most power is allocated to the time interval when the train is nearest to the BS, which causes great unfairness with respect to time. Although the proportional power allocation can achieve much better fairness along the time, it causes a relatively big loss in mobile service amount, resulting in low utilization efficiency of HSRC channels. Enlightened by the definition of Rényi entropy, this paper proposes an novel power allocation scheme called β-fairness power allocation, which is able to achieve relatively high mobile service amount with fairness between the water-filling and proportional power allocation. It is a generalized fairness power allocation, by which the tradeoff between the mobile service amount and fairness can be easily controlled by adjusting the value of β. Particularly, as β = 0, it becomes a traditional water-filling method, while β = 1, it becomes the existing proportional power allocation. To achieve a more general power adjustment with user QoS requirement, the rate-constrained β-fairness power allocation is also investigated, where a closed form of the rough optimal result is first derived and then the precise power allocation is obtained by an efficient algorithm. Besides, we a..."
  },
  {
    "year": "2017",
    "abstract": "Fault feature can be extracted by traditional manifold learning algorithms, which construct neighborhood graphs by Euclidean distance (ED). It is difficult to get an excellent dimensionality reduction result when processed data has strong correlations. In order to improve the effect of dimensionality reduction and increase accuracy of bearing fault diagnosis in mechanical systems, an improved manifold learning method based on Mahalanobis distance (MD) is proposed. In this paper, we use time-domain analysis and frequency-domain analysis to construct high-dimensional feature vectors in the first step. Then, MD is used to replace ED in neighborhood construction of manifold learning. After using the improved manifold learning method, low-dimensional feature vectors can be extracted. Finally, fault diagnosis of rolling element bearing can be made by applying the K-nearest neighbor classifier. In part of experiment, to verify the efficiency of the improved manifold learning methods, artificial data sets and rolling element bearing fault data are adopted. The experimental comparison results of the improved manifold learning algorithm and the traditional algorithm prove that the proposed method is more effective in rolling element bearing fault diagnosis."
  },
  {
    "year": "2017",
    "abstract": "Human facial expressions change with different states of health; therefore, a facial-expression recognition system can be beneficial to a healthcare framework. In this paper, a facial-expression recognition system is proposed to improve the service of the healthcare in a smart city. The proposed system applies a bandlet transform to a face image to extract sub-bands. Then, a weighted, center-symmetric local binary pattern is applied to each sub-band block by block. The CS-LBP histograms of the blocks are concatenated to produce a feature vector of the face image. An optional feature-selection technique selects the most dominant features, which are then fed into two classifiers: a Gaussian mixture model and a support vector machine. The scores of these classifiers are fused by weight to produce a confidence score, which is used to make decisions about the facial expression's type. Several experiments are performed using a large set of data to validate the proposed system. Experimental results show that the proposed system can recognize facial expressions with 99.95% accuracy."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the distributed secure estimation problem over wireless sensor networks subject to random multichannel jamming attacks. Each sensor's measurement is divided into ny (the dimension of measurement signal) components and transmitted via ny relevant wireless channels. The attacker is an active adversary in the sense that sensors' measurements through wireless transmission channels are randomly dropped if the corresponding channels are successfully jammed. By employing a piecewise homogeneous Markov chain, a sophisticated two-level switching multichannel jamming attack model is developed. From the perspective of the attacker, this attack model is promising and makes the wireless channels highly vulnerable, because the attacker can randomly and arbitrarily decide when and where to launch the attacks. We then focus our attention on the secure estimation of a target signal with the caveat that some of the measurements can be incomplete induced by the attacks. A system theoretic framework is then developed to cast the network-based security problem into an H∞estimation theory problem of a piecewise homogeneous Markov jump system. Criteria for analyzing H∞estimation performance and designing resilient estimators against noises and attacks are also presented. The effectiveness of the proposed results is illustrated through a military F404 aircraft engine system."
  },
  {
    "year": "2017",
    "abstract": "Web services have attracted much attention from distributed application designers and developers because of their roles in abstraction and interoperability among heterogeneous software systems, and a growing number of distributed software applications have been published as Web services on the Internet. Faced with the increasing numbers of Web services and service users, researchers in the services computing field have attempted to address a challenging issue, i.e., how to quickly find the suitable ones according to user queries. Many previous studies have been reported towards this direction. In this paper, a novel Web service discovery approach based on topic models is presented. The proposed approach mines common topic groups from the service-topic distribution matrix generated by topic modeling, and the extracted common topic groups can then be leveraged to match user queries to relevant Web services, so as to make a better trade-off between the accuracy of service discovery and the number of candidate Web services. Experiment results conducted on two publicly-available data sets demonstrate that, compared with several widely used approaches, the proposed approach can maintain the performance of service discovery at an elevated level by greatly decreasing the number of candidate Web services, thus leading to faster response time."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the optimal power minimization design of simultaneous wireless information and power transfer systems under non-linear energy harvesting (EH) model, where a multi-antenna hybrid access point (H-AP) simultaneously transmits information and power to multiple heterogeneous users, such as information-energy receivers (IERs), information receivers (IRs), and ERs. Power splitting (PS) receiver architecture is adopted at all IERs. In order to achieve green system design, an optimization problem is formulated to minimize the transmit power of H-AP subject to the required signal-to-interference-plusnoise ratios (SINRs) constraints at IERs and IRs, and the harvested energy constrains at IERs and ERs, by jointly optimizing the beamforming vector at H-AP and the PS ratios at IERs. Since the problem is nonconvex and the employ of the non-linear EH model makes it more difficult to solve, the semidefinite relaxation and variable substitutions are used to handle it. For some cases, we theoretically prove that the globe optimal solution can be guaranteed by using our method, and for rest cases, we discuss its optimality via simulations. Numerical results show that although the traditional linear EH model is feasible for the practical EH circuits in some cases, the corresponding system consumes more transmit power than that under the non-linear model EH. Moreover, the effects of the numbers of users, the required SINRs, and the harvested energy on the system transmit power are also discussed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a hierarchical distributed coordinated control method is proposed based on the multi-agent system for dc ring-bus microgrids to improve the bus voltage performance. First, a two-level multi-agent system is built, where each first-level unit control agent is associated with a distributed energy resource to implement local decentralized control, and the second-level control agent is associated with the first-level agent to implement distributed coordination control together with the first-level agent. Afterward, the assessment index of each distributed energy resource subsystem is established. By the assessment index, the multi-agent system can judge whether the subsystem should implement the local decentralized control or the distributed coordinated control. Furthermore, by means of the assessment index, both the local controller and distributed coordinated controller are designed, respectively, based on two kinds of dynamic models of DER unit. To reduce the communication pressure, the distributed coordinated controller is built by local controller combined with the coordinated control laws. The coordinated control laws are synthesized by using the states from only neighboring subsystems. Considering the effect of communication delays on control performance, a delay-dependent H∞ robust control method is proposed to design the distributed coordinated controller. Finally, the validity of the proposed control scheme is testified by simulation results."
  },
  {
    "year": "2017",
    "abstract": "The design and deployment of a novel mobile network architecture, motivated by the challenges deriving from the explosive increase in data traffic on operator networks, are a pressing problem in today's telecommunications. Distributed mobility management (DMM) introduces a key idea to tackle the traffic bottlenecks that impact current mobile networks by proposing the deployment of distributed mobility anchor points close to terminal locations. There have been many proposals to build DMM solutions, with different focuses and merits for future mobile networks, aimed at overcoming the limitations from current centralized mobility management solutions. To the best of our knowledge, a comprehensive analysis and comparison study systematically analyzing available design options have not yet been provided. In this paper, we identify essential design considerations and their underlying options, comparing their impact on user and network performance. In addition, we provide the recent advances of DMM with emerging trends such as control-/data-plane separation and mobile cloud, which will impact the next generation network paradigm."
  },
  {
    "year": "2017",
    "abstract": "A novel approach to segment corneal layer interfaces using optical coherence tomography images is presented. In this paper, we performed customized edge detection for initial location of interfaces, fitting the initial interfaces to circles via customized Hough transform, and refining interfaces by employing Kalman filtering to model the horizontal projectile motion of interface boundaries. Validation based on 20 B-scan images from 60 volumes shows that three layer interfaces in each image can be segmented within 0.52 s with an average absolute layer interface error below5.4μm. Compared with an existing method, we are able to yield significantly better or similar accuracy at a higher speed with inferior software environment. From the validation experiments based on images from normal human subjects, images with keratoconus and images with laser in situ keratomileusis flap, we showed that the proposed customized Hough transform for circles can represent the corneal layer interfaces more accurately. On the other hand, Kalman filtering can handle the heavy noise exhibited in the image, and can be adapted to shape variation in order to be closer to the real-layer interfaces. In conclusion, our approach can be a potential tool to quantify corneal layer interfaces in a clinical environment with lower computational expenses while maintaining high effectiveness."
  },
  {
    "year": "2017",
    "abstract": "As the electricity demand continues to grow and renewable energy resources are incorporated into the grid, an effective dynamic state estimation is required for monitoring and grid synchronization. This paper proposes a microgrid state estimation approach considering the unreliable communication channels. Particularly, the renewable microgrid incorporating distributed energy resources, such as solar panels, are represented as a state-space linear model. Then, the wireless sensor network is adopted to sense the microgrid states. For long-distance transmission, we propose an innovative smart grid infrastructure, which is easy to design and offers a reliable two-way communication. In this infrastructure, the modulated signal is transmitted over an unreliable channel, which causes signal distortions. After demodulation and dequantization, the received signal at the energy management system is used the fading Kalman filter algorithm. Using the tunable forgetting factor in the predicted error covariance step, this algorithm aims to minimize the estimation errors so the estimated states reflect the true system states. Simulations results indicate that the developed approach estimates the system states within 0.25 seconds."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a low-complexity multi-user communication system based on frequency index modulation that suits Internet of Things applications. This system aims to reduce the transmitted energy and the peak-to-average-power ratio (PAPR) of orthogonal frequency-division multiplexing (OFDM) systems and to perform without sacrificing data rate in comparison with conventional OFDM. In this design, OFDM-like signals are used to make the implementation of the system easy by the virtue of fast Fourier transform (FFT). In the proposed scheme, an OFDM bandwidth ofNFIMtotal sub carriers is divided intoNBequal number of sub-bands, withNsubcarriers in every sub-band. At the transmitter side of each sensor, the outgoing bit stream is divided into two blocks: mapped and modulated. The bits within the mapped block are used to activate the corresponding subcarrier in its predefined sub-band in order to carry the data content of the modulated block, while the otherN−1subcarriers are nulled out. At the receiver, the FFT is performed first, and then the square-law envelope detector is applied to estimate the active frequency index to recover the mapped bits, followed by a conventional demodulation process to demodulate the transmitted bits. Once the system is presented and analyzed, energy efficiency, PAPR and complexity are studied to show the features of the proposed scheme. Moreover, we derive closed-form expressions of the bit error rate performance over Rayleigh fading channels and we validate the outcome by simulation results. With the characteristics exhibited in this paper, the proposed system would constitute an excellent candidate for wireless sensor applications where it represents a simpler substitution for frequency-hopping-based architectures, in which the hops carry extra bits."
  },
  {
    "year": "2017",
    "abstract": "A tremor is an involuntary rhythmic shaking movement of the muscles, which reduces the precision of hand and finger movements. It is difficult for individuals with hand tremors to type accurately using small- and high-density targets, such as keyboard. This research proposes an optical see-through mixed reality system that reduces hand tremors so that the individual can type steadily. The system virtually stabilizes the individual’s hand tremors by optically overlapping the trembling hand with a stabilized virtual hand to produce a realistic typing sensation without any tremors. The simulation experiments proved that the system supports trembling hand typing. By comprehensively investigating both the objective (time and error ratios) and the subjective (the sense of ownership, agency, and pertinence) aspects, the system with a virtual:real intensity ratio of 0.75:0.25 was found to be optimal."
  },
  {
    "year": "2017",
    "abstract": "Techniques for wireless energy harvesting (WEH) are being emerged as a fascinating set of solutions to extend the lifetime of energy-constrained wireless networks. They are commonly regarded as a key functional technique for almost perpetual communications. With the WEH technology, wireless devices are able to harvest energy from, e.g., different light sources or RF signals broadcast by ambient/dedicated wireless transmitters to support their operation and communications capabilities. The WEH technology will have increasingly wider range of use in upcoming applications for, e.g., wireless sensor networks, machine-to-machine (M2M) communications, and the Internet of Things (IoT). In this paper, the usability and fundamental limits of solar cell or photovoltaic harvesting-based M2M communication systems are studied and presented. The derived theoretical bounds are in essence based on the Shannon capacity theorem, combined with selected propagation loss models, assumed additional link nonidealities, as well as the given energy harvesting and storage capabilities. Fundamental performance limits and available capacity of the communicating link are derived and analyzed, together with extensive numerical results evaluated in different practical scenarios, including realistic implementation losses and the state-of-the-art printed supercapacitor performances. In particular, low-power sensor-type communication applications using passive wake-up radio (WuR)-assisted operation are addressed in this paper. The results show the benefits of using passive WuR, especially when the number of nodes is small. Moreover, the presented analysis principles and results establish clear feasibility regions and performance bounds for WEH-based low rate M2M communications in the future IoT networks."
  },
  {
    "year": "2017",
    "abstract": "The classical loop shaping is a design procedure that explicitly involves the shaping of the open loop transfer function L(s), within a desired frequency spectrum by manipulating the poles, zeros, and gain of the controller C(s). Interactive software tools have proven as, particularly, useful techniques with high impact on control education. This kind of interactive tools has demonstrated in the past that students learn in a much more active way. This paper presents the basic functionality of the linear control system design (LCSD), an interactive tool for analysis and design of linear control systems with special emphasis on the classical loop shaping design. The software tool is implemented in Sysquake, a MATLAB-like language with fast execution and excellent facilities for interactive graphics, and is delivered as a stand-alone executable that is readily accessible to students and instructors. Several design problems are used to illustrate the main features of the LCSD tool to perform classical loop shaping."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the secrecy rates and optimal power allocation schemes for a decode-and-forward wiretap relay channel where the transmission from a source to a destination is aided by a relay operating in a full-duplex (FD) mode under practical residual self-interference. By first considering static channels, we address the non-convex optimal power allocation problems between the source and relay nodes under individual and joint power constraints to establish closed-form solutions. An asymptotic analysis is then given to provide important insights on the derived power allocation solutions. Specifically, by using the method of dominant balance, it is demonstrated that full power at the relay is only optimal when the power at relay is sufficiently smaller when compared with that of the source. When the power at the relay is larger than the power at the source, the power consumed at the relay saturates to a constant for an effective control of self-interference. The analysis is also helpful to demonstrate that the secrecy capacity of the FD system is twice as much as that of the half-duplex system. The extension to fast fading channels with channel state information being available at the receivers but not the transmitters is also studied. To this end, we first establish a closed-form expression of the ergodic secrecy rate using simple exponential integrals for a given power allocation scheme. The results also show that with optimal power allocation schemes, FD can significantly improve the secrecy rate in fast fading environments."
  },
  {
    "year": "2017",
    "abstract": "With a wide scope to explore and harness the oceanic sources of interest, the field of underwater wireless sensor networks (UWSNs) is attracting a growing interest of researchers. Owing to the real-time remote data monitoring requirements, underwater acoustic sensor networks (UASNs) emerged as a preferred network to a great extent. In UASN, the limited availability and non-rechargeability of energy resources along with the relative inaccessibility of deployed sensor nodes for energy replenishments necessitated the evolution of several energy optimization techniques. Clustering is one such technique that increases system scalability and reduces energy consumption. Besides clustering, coverage and connectivity are two significant properties that decide the proper detection and communication of events of interest in UWSN due to unstable underwater environment. Underwater communication is also possible with non-acoustic communication techniques like radio frequency, magnetic induction, and underwater free-space optics. In this paper, we surveyed clustering, coverage, and connectivity issues of UASN and qualitatively compared their performance. Particularly, the impact of these non-conventional communication techniques on clustering, coverage, and connectivity aspects is demonstrated. Additionally, we highlighted some key open issues related to the UWSN. This paper provides a broad view of existing algorithms of clustering, coverage, and connectivity based on acoustic communication. It also provides a useful guidance to the researchers in UWSN from various other communication techniques' perspective."
  },
  {
    "year": "2017",
    "abstract": "In recent years, consumers of 4G cellular networks have increased exponentially as they discover that the service is user-friendly. Due to the large users and their frequent demands, it is necessary to use the limited network resources that guarantee the eminent standard quality of service (QoS). Call admission control (CAC) scheme has a major impact in assuring QoS for different users with various QoS requirements in 4G networks. Recently, the reservation-based scheme and bandwidth degradation schemes were proposed with the aim to provide effective use of network resources and assure QoS requirements to admitted calls. However, in spite of these several objectives, these schemes are not efficient as a result of the modeling and approximation method that starve the best effort (BE) traffic. The dynamic threshold value approach adjusts handoff call and new call based on time-varying conditions resulted in a waste of network resources, where bandwidth are reserved for handoff call, but at the network environment, there is little or no handoff calls. In this paper, we propose a novel CAC scheme to provide effective use of network resources and avoid the starvation of BE traffic. The scheme introduces an adaptive threshold value, which adjusts the network resources under heavy traffic intensity. In addition, we proposed reservation and degradation approach to admit many users when there is a limited number of bandwidth, which also achieved effective utilization of network resources. Simulation results show that the proposed scheme significantly outperforms the reservation-based scheme and bandwidth degradation schemes in terms of admitting many calls and guaranteeing QoS to all the traffic types in the network. Numerical results imitate to experimental results with insignificant differences."
  },
  {
    "year": "2017",
    "abstract": "Discovering semantic coherent topics from the large amount of user-generated content (UGC) in social media would facilitate many downstream applications of intelligent computing. Topic models, as one of the most powerful algorithms, have been widely used to discover the latent semantic patterns in text collections. However, one key weakness of topic models is that they need documents with certain length to provide reliable statistics for generating coherent topics. In Twitter, the users' tweets are mostly short and noisy. Observations of word co-occurrences are incomprehensible for topic models. To deal with this problem, previous work tried to incorporate prior knowledge to obtain better results. However, this strategy is not practical for the fast evolving UGC in Twitter. In this paper, we first cluster the users according to the retweet network, and the users' interests are mined as the prior knowledge. Such data are then applied to improve the performance of topic learning. The potential cause for the effectiveness of this approach is that users in the same community usually share similar interests, which will result in less noisy sub-data sets. Our algorithm pre-learns two types of interest knowledge from the data set: the interest-word-sets and a tweet-interest preference matrix. Furthermore, a dedicated background model is introduced to judge whether a word is drawn from the background noise. Experiments on two real life twitter data sets show that our model achieves significant improvements over state-of-the-art baselines."
  },
  {
    "year": "2017",
    "abstract": "Considering the requirement of high accuracy and nonlinear problems in drive systems, a novel adaptive position tracking control approach based on neural networks is presented for permanent magnet synchronous motors with full-state constraints. The neural networks technique is employed to approximate the unknown nonlinear functions. Then, the barrier Lyapunov functions are used to restrict the state variables within a bounded compact set to improve the property of system. The proposed adaptive neural network controllers can guarantee that all closed-loop variables are bounded, and the full state variables do not exceed their constraint spaces. Simulation results show the effectiveness and the potentials of the theoretic results obtained."
  },
  {
    "year": "2017",
    "abstract": "Electric vehicle (EV) becomes a popular choice for its zero air pollutant and high energy efficiency. Nevertheless, the massive penetration of EVs can cause problems, including voltage drop and peak amplification. The charging pattern of EVs also poses a challenge to the reconfiguration work of the power system when failure occurs. Therefore, an EV schedule-control-based strategy is designed to address these issues in order to achieve voltage regulation and load shifting under both normal operation and failure scenarios. The framework involves two agents: a two-stage voltage control agent schedules EVs to perform load shifting and voltage regulation under normal condition and a fault control agent deals with line failure scenarios to recover the power supply of out-of-service basic and EV loads. A three-level queue table mechanism is designed to collaboratively perform EV scheduling. The influence of EV charging locations on the voltage variations of other nodes is considered and alleviated through a voltage sensitivity analysis method. Moreover, graph theory is employed to perform the network reconfiguration process to deal with line failure situations. The effectiveness of the scheme to restore the power supply while maintaining reliable system voltage level has been verified with the simulation results based on a modified IEEE 30 nodes test feeder."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel fingerprint-based localization technique is proposed, which is applicable for positioning user equipments (UEs) in cellular communication networks such as the long-term-evolution (LTE) system. This technique utilizes a unique mapping between the characteristics of a radio channel formulated as a fingerprint vector and a geographical location. A feature-extraction algorithm is applied to selecting channel parameters with non-redundant information that are calculated from the LTE down-link signals. A feedforward neural network with the input of fingerprint vectors and the output of UEs’ known locations is trained and used by UEs to estimate their positions. The results of experiments conducted in an in-service LTE system demonstrate that by using only one LTE eNodeB, the proposed technique yields a median error distance of 6 and 75 meters in indoor and outdoor environments, respectively. This localization technique is applicable in the cases where the Global Navigation Satellite System (GNSS) is unavailable, e.g., in indoor environments or in dense-urban scenarios with closely spaced skyscrapers heavily blocking the line-of-sight paths between a UE and GNSS satellites."
  },
  {
    "year": "2017",
    "abstract": "The wireless capacity crunch will undoubtedly continue as new innovative applications emerge, for instance, augmented reality and massive machine type communications. mmWave promises to deliver gigabits of bandwidth and unprecedented wireless capacity and has created quite the social buzz in both industry and academia. However, mmWave does come with its challenges. Some most prominent issues include high propagation loss, device immaturity, signal processing complexity, and testability. This paper aims to review the current progress on the development of the mmWave technology from seven areas of particular interest/myths with a particular focus on deployment feasibility. We also promote sensible discussions on the potential solutions. Finally, we ask the title question from a network operator's perspective."
  },
  {
    "year": "2017",
    "abstract": "Children with developmental disabilities typically have sensory processing disorders, which may result in considerable discomfort. Sensory stimulation therapy is the most common remedy, but the development of therapy content is challenging because each individual has unique sensory problems and personal characteristics. To provide personalized content, we propose a new app-based authoring system, in which various functionalities provided by different apps can be dynamically combined and reconfigured. Specifically, we develop: 1) an authoring app, which allows authors to reconfigure the functionality of different apps using parameters; 2) an execution app, which dynamically runs various components in different apps; and 3) app packages to stimulate sensory systems, for which a library is provided to support effective app development on our platform. To stimulate the multi-sensory systems of children with developmental disabilities, several items of content were developed with guidance from special education teachers. User studies reveal that the proposed scheme is effective for the development of personalized educational content, thus helping sensory stimulation therapy."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) have gained much attention in today’s research domain for supporting a wide variety of applications including the multimedia applications. Multimedia applications that are regarded as the quality-of-service (QoS)-aware, delay sensitive, and bandwidth hungry applications require enough energy and communication resources. WSNs being the energy-scarce network have now been designed in such a way that they can support these delay-sensitive and time-critical applications. In this paper, we propose an energy-efficient routing protocol for heterogeneous WSNs to support the delay sensitive, bandwidth hungry, time-critical, and QoS-aware applications. The proposed QoS-aware and heterogeneously clustered routing (QHCR) protocol not only conserves the energy in the network, but also provides the dedicated paths for the real-time and delay sensitive applications. The inclusion of different energy-levels for the heterogeneous WSNs also provides the stability in the networks while minimizing the delay for the delay-sensitive applications. Extensive simulations have been performed to validate the effectiveness of our proposed scheme. Our proposed routing scheme outperforms other state-of-the-art schemes in terms of the delay performances."
  },
  {
    "year": "2017",
    "abstract": "Due to the significant growth in transportation industries, the importance of interactions between vehicle technologies and humans from the safety aspect plays an important role in the new developments of complex vehicle systems. Therefore, from academic and industrial viewpoints, increasing attention has been paid to complex vehicle correlative technologies with full consideration of issues like safety, robust performance, impact analysis, optimization, automation, motion control, etc. All aforementioned issues provide a basis for the design and operation of practical vehicle systems in order to achieve desired complex tasks."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a comprehensive comparative study for the tracking control of a class of underactuated nonlinear uncertain systems. A given nonlinear model of the underactuated system is, at first stage, transformed into an input output form and the driving applied control input of the transformed system is then designed via four sliding mode control strategies, i.e., conventional first-order sliding mode control (SMC), second-order SMC, fast terminal SMC, and integral SMC. At the second stage, a ball and beam system is considered and the aforementioned four control design strategies are experimentally implemented. A comprehensive comparative study of the simulation and experimental results is then conducted, which take into account the tracking performance, i.e., settling time, overshoots, robustness enhancement, chattering reduction, sliding mode convergences, and control efforts."
  },
  {
    "year": "2017",
    "abstract": "The advancements in technology have transformed the vehicles moving around us into intelligent machines. These vehicles now have the capabilities to communicate and share useful information with each other under a communication network known as Vehicular Ad hoc Network (VANETs). The aim of this vehicular digitization was to enhance the standard, ease, leisure and safety of passengers, drivers and pedestrians on the roads. Using the power of intelligent decision making and the capability of interconnectivity, VANETs has enabled vehicles to communicate and operate in different modes, such as Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), Vehicle-to-Sensor (V2S), Vehicle-to-broadband cloud (V2B) and Vehicle-to-Human (V2H). Vehicular communications in all these modes rely on vehicular characteristics, diverse road structures and resource management during the operations of VANETs. To meet the quality requirements, the vehicular characteristics and network constrains are always focused to improve VANETs performance. Vehicular communication is established by using infrastructure and devices based on the operational policies defined in the Dedicated Short Range Communications (DSRC), IEEE 802.11p and Wireless Access in Vehicular Environments (WAVE) standards. The standards addresses the VANETs key issues regarding extension of coverage areas, impact of high vehicular velocities and dynamic road conditions on communications. The standards also outline the management of a multi-path phenomena whilst cooperating with multiple ad-hoc networks and providing a suitable environment for the merger of future technologies and applications with VANETs [item 1) in the Appendix]."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel planar printed dual-band magneto-electric dipole antenna is proposed. The proposed antenna is composed of a conventional bow-tie patch as an electric dipole, a semi-circular loop that operates as a magnetic dipole, a coplanar ground plane, and a wideband microstrip-to-coplanar-stripline transition balun. By etching a pair of complementary capacitively loaded loop slots on the bow-tie radiation patch, a notched band is introduced to form the dual-band antenna. And a coplanar ground is adopted to make the entire antenna become a planar printed structure. Additionally, the proposed antenna loads the periodical interdigital capacitance structure on the semi-circular loop for the purpose of making the current flowing along the loop maintain the same phase and improving the performances of the magnetic dipole. The proposed antenna was fabricated and measured. The measured results keep in good accordance with the simulated ones. Consequently, the proposed antenna achieves a dual-band operation at 2.37~2.82 GHz (17.3%) and 3.14~4.10 GHz (26.5%) with the Voltage Standing Wave Ratio (VSWR) less than 2, so it can be applied for WLAN (2.4-2.484 GHz) and WiMAX (2.5-2.69 GHz/3.4-3.69 GHz). Meanwhile, the stable gain, symmetrical, and stable unidirectional radiation patterns, low cross polarization, and low back lobe are also obtained at the dual bands."
  },
  {
    "year": "2017",
    "abstract": "Frequent route pattern mining from personal trajectory data is the basis of location awareness and location services. However, because personal trajectory data is highly uncertain, most existing approaches are only capable of finding short and incomplete route patterns. In this paper, a novel approach is proposed for the discovery of frequent route patterns based on trajectory abstraction. First, trajectory partition, location extraction, data simplification, and common segment discovery are used to abstract trajectory data, convert these trajectories into common segment temporal sequences (STS) and generate 1-frequent itemsets. Then, a pattern mining algorithm is proposed based on the spatial-temporal adjacency relationship. This algorithm uses the constraint mechanism and bidirectional projected database to mine frequent route patterns from STS. Based on the real GeoLife trajectory data, the experimental results indicate that the proposed method has better performance and can find longer route patterns than other currently available methods."
  },
  {
    "year": "2017",
    "abstract": "In order to meet the intense user demands, the 5G networks are evolving, and will be available by 2020. The unfolding cellular technology has raised the energy consumption in mobile networks with the carbon footprint surging to alarming rates. This is causing an adverse effect on the environment and human health. Addressing these aspects, this paper presents a survey on techniques for making the next generation cellular networks GREEN. A number of technologies form a part of the 5G networks, in order to support the drastic user demands, and are receiving substantial attention from the perspective of green communication. These include device-to-device communication, spectrum sharing, ultra dense networks, massive MIMO, and the Internet of Things. Also, a prime concern in the current scenario is the battery life of the mobile terminals. For enhancing the battery life of the user terminals, a proposal is given in this paper, with spectrum sharing as its basis, to overcome the energy crunch. Major research challenges have been discussed, and the ongoing projects and standardization activities also stated in this paper."
  },
  {
    "year": "2017",
    "abstract": "We present numerical simulations of the near-field focusing capabilities of a dynamically reconfigurable holographic metasurface aperture. The aperture consists of a parallel-plate waveguide in which the upper plate is patterned with a number of metamaterial irises that can be dynamically switched between radiating (ON) and non-radiating (OFF) states. A cylindrically symmetric waveguide mode, excited by a coaxial probe in the center of the lower plate, serves to excite the radiating irises, forming a focused spot in the radiating near-field (or Fresnel zone). The layout of the metamaterial elements and their tuning states is determined using holographic design principles, in which the interference pattern of the waveguide (or reference) mode and the desired radiated field pattern leads to the required phase distribution over the surface of the aperture. We also develop an analytical model of the aperture to confirm the numerical simulations, and to illustrate the advantage of the guided-mode as the reference wave versus a plane-wave. We further leverage this analytical model to analyze the diffracted order characteristics of the holographic metasurface aperture, showing high-fidelity focusing patterns even for difficult focusing scenarios across the entire investigated field-of-view."
  },
  {
    "year": "2017",
    "abstract": "Many elderly persons prefer to stay alone in a single-resident house for seeking an independent life and reducing the cost of health care. However, the independent life cannot be maintained if the resident develops dementia. Thus, an early detection of dementia is essential for the elderly to extend their independent lifetime. Early symptoms of dementia can be noticed in everyday activities such as front-door events. For example, forgetting something when the person leaves the house might be an early symptom of dementia. In this paper, we introduce a novel front-door events [exit, enter, visitor, other, and brief-return-and-exit (BRE)] classification scheme that validated by using open data sets (n = 14) collected from 14 testbeds by anonymous wireless binary sensors (passive infrared sensors and magnetic sensors). BRE events occur when four consecutive events (exit-enter-exit-enter) happen in certain time intervals (t1, t2, and t3), and some of them may be the forget events. Each testbed had one older adult (aged 73 and over) during the experimental period (μ = 547.6 ± 370.4 days). The algorithm automatically classifies the resident's front-door events. Experimental results show the events of total exits, daily exits, out-time per exit, as well as the significance of the ti parameters for the number of classified BRE events. Since part of the BRE events may be the forget events, the proposed algorithm could be a useful tool for the forget event detection."
  },
  {
    "year": "2017",
    "abstract": "Serviceability is the ability of a network to serve user equipments (UEs) within desired requirements (e.g., throughput, delay, and packet loss). High serviceability is considered as one of the key foundational criteria toward a successful fog radio access infrastructure satisfying the Internet of Things paradigm in the 5G era. In this paper, we propose an adaptive resource balancing (ARB) scheme for serviceability maximization in fog radio access networks wherein the resource block (RB) utilization among remote radio heads (RRHs) are balanced using the backpressure algorithm with respect to a time-varying network topology issued by potential RRH mobilities. The optimal UE selection for service migration from a high-RB-utilization RRH to its neighboring low-RB-utilization RRHs is determined by the Hungarian method to minimize RB occupation after moving the service. Analytical results reveal that the proposed ARB scheme provides substantial gains compared with the standalone capacity-aware, max-rate, and cache-aware UE association approaches in terms of serviceability, availability, and throughput."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency division multiplexing (OFDM) offers spectral efficiency advantage, however, it is limited by peak-to-average power (PAPR) problem. The PAPR can be reduced using iterative clipping and filtering (ICF) scheme but requires that the same signals are iteratively clipped with a fixed clipping threshold at different clipping iterations. This method warrants that fast-Fourier transform (FFT)/inverse FFT (IFFT) blocks must be driven in the order of iterations many times to attain a desired PAPR threshold which expends the system power and expands the processing time. Using a second order cone program, the number of iterations required to attain the desired PAPR threshold was reduced. This optimized ICF (OICF) was later simplified using Lagrange multiplier (LM). In this paper, we apply an adaptive clipping threshold to the LM scheme to improve the performance of the simplified OICF (SOICF). Our results show significant reduction of the PAPR problem compared with the earlier SOICF scheme albeit with some degradation in the bit error ratio (BER) performance that can be under 1.0 dB depending on the chosen clipping threshold. In addition, we also illustrate the results of the performances and the theoretical relationships between the error vector magnitude (EVM) and PAPR, between clipping ratio (CR) and EVM, and lastly the inter-dependencies of EVM, PAPR, the number of OFDM subcarriers, and the CR."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel thermal-to-visible face alignment method based on edge map. The alignment procedure is inspired by iterative closest points matching. However, iterative closest point (ICP) sometimes converges to the local minimum for edge face alignment. In this paper, pointwise distance, which refers to the linear combination of positional and edge local pattern, is proposed as it gives good initial estimation of the closest points matching in iteration. Another problem is that numerous spurious corresponding points will occur in the closest pairs. Therefore, the selection criteria for partial closest pairs are designed, according to magnitude and orientation of the displacement, to remove the spurious corresponding points caused by edge faces. The alignment performance is evaluated by the bias of facial fiducial points and heterogeneous face recognition. The experimental results, including intra-class and inter-class, are demonstrated to compare partial closest points with local pattern with ICP, manual labeling, and Gaussian fields criterion. The alignment effect of variable expressions and illumination is also tested. Besides, the wearing glasses problem is well solved by glasses replacement."
  },
  {
    "year": "2017",
    "abstract": "Decentralized output-feedback (DOF) event-triggering control for large-scale nonlinear networked systems is examined in this paper. The Takagi-Sugeno model is applied to describe each nonlinear subsystem, where it shares the communication information through networks. A DOF control scheme with event-triggering is proposed, where two event-triggering mechanisms are placed in the sensor and in the actuator, respectively. Our goal is to design the DOF controller, which not only guarantees the stability of closed-loop control system but also reduces the data communication in the sensor-to-controller channels and controller-to-actuator channels. First, a novel model transformation is presented, where the closed-loop control system is reconstructed as a constant-delay system with extra feedback interconnections. By introducing a relaxing Lyapunov-Krasovskii functional combining with the scaled small gain theorem, the co-design consisting of the controller gains, event-triggered parameter, and sampled period is derived in the form of linear matrix inequality. The effectiveness of the proposed method is validated via a numerical example."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the robust secure transmit beamformming design for multiple-input single-output wiretap channels overheard by multiple non-collaborating single-antenna eavesdroppers. Assuming that at the transmitter, the instantaneous legitimate receiver's channel state information (CSI) is imperfect and only the statistical eavesdroppers' CSI is known, we seek to maximize the target secrecy rate R with the total transmit power constraint and the secrecy outage probability constraint. The resulting outage-constrained secrecy rate maximization (O-SRM) is non-convex and difficult to solve. Thus, we develop an efficient algorithm to solve it and determine the robust secure beamforming design. Specifically speaking, we first prove that the original O-SRM problem can be solved by an equivalent outage-constrained power minimization problem (O-PMP), which is easy to perform semi-definite relaxation (SDR) and can be solved by semi-definite program (SDP) consequently. Second, we transform the non-convex secrecy rate outage constraints into deterministic ones by resorting to Bernstein-type inequality II. Finally, by solving the convex approximation of the O-PMP with different Rs and bisection search over R, we convert the original O-SRM problem into a sequence of solvable SDPs. Simulation results are provided to verify the secrecy-rate performance improvement of the proposed robust beamforming compared with the existing worst-case design proposed by Li and Ma and the simple non-robust maximum-ratio transmission."
  },
  {
    "year": "2017",
    "abstract": "The most accurate stereo disparity algorithms take dozens or hundreds of seconds to process a single frame. This timescale is impractical for many applications. However, high accuracy is often not needed throughout the scene. Here, we investigate a “foveation”approach (in which some parts of an image are processed more intensively than others) in the context of modern stereo algorithms. We consider two scenarios: disparity estimation with a convolutional network in a robotic grasping context, and disparity estimation with a Markov random field in a navigation context. In each case, combining fast and slow methods in different parts of the scene improves frame rates while maintaining accuracy in the most task-relevant areas. We also demonstrate a simple and broadly applicable utility function for choosing foveal regions, which combines image and task information. Finally, we characterize the benefits of defining multiple individually placed small foveae per image, rather than a single large fovea. We find little benefit, supporting the use of hardware foveae of fixed size and shape. More generally, our results reaffirm that foveation is a practical way to combine speed with task-relevant accuracy. Foveae are present in the most complex biological vision systems, suggesting that they may become more important in artificial vision systems, as these systems become more complex."
  },
  {
    "year": "2017",
    "abstract": "Realistic public wireless channels and quantum key distribution (QKD) systems are amalgamated. Explicitly, we conceive network coding aided cooperative QKD over free space optical systems for improving the bit error ratio and either the key rate or the reliable operational distance. Our system has provided a 55% key rate improvement against the state-of-the-art benchmarker."
  },
  {
    "year": "2017",
    "abstract": "Existing spectrum-sharing schemes either allow the secondary-network users (SUs) to utilize the spectrum when primary-network users (PUs) remain idle, or require the SUs to coordinate with the PUs, causing signaling overhead. In this paper, we propose a game-theoretic spectrum-sharing scheme, which enables the SUs and PUs to utilize the spectrum simultaneously, without compromising the quality of service (QoS) of the PUs and ensuring reduced signaling overhead. We formulate a multi-priority non-cooperative power-control game by considering a scenario where multiple small cell base stations belonging to either the primary network or secondary network utilize the available spectrum resources at the same time. The base stations are empowered to adjust their transmit powers in an automated manner based on measured interference, until their transmit powers are stabilized. As a key idea, a game parameter, dynamic price coefficient, is designed to give the primary network priority over the secondary network for accessing the spectrum. We determine appropriate bounds for the game parameters to ensure the existence and uniqueness of the Nash equilibrium of the proposed game. Furthermore, we propose a novel dual-mode solution to reduce the real-time signaling overhead between the networks, by minimizing the information exchange during the game required to reach an equilibrium point. Extensive simulation results are presented to prove the convergence of the game to a Nash equilibrium, along with a throughput performance analysis."
  },
  {
    "year": "2017",
    "abstract": "As an important solution to “the last mile”access, digital subscriber loops (DSLs) are still maintained in a huge plant to support low-cost but high-quality broadband network access through telephone lines. The discrete multi-tone (DMT) transmissions constitute a baseband version of the ubiquitous orthogonal frequency division multiplexing. While the DMT is ideally suited to deal with the frequency selective channel in DSL, the presence of bursty impulsive noise tends to severely degrade the transmission performance. In this paper, we analyze the statistics of impulsive noise and its effects on the received signals, with the aid of a hidden semi-Markov process. The closed-form bit error rate expression is derived for the DMT system for Q-ary quadrature amplitude modulation under practical noise conditions and for measured dispersive DSL channels. Instead of relying on the simplified stationary and impulsive noise process, our noise model considers both the temporal and spectral characteristics based on the measurement results. The simulation results confirm the accuracy of the formulas derived and quantify the impact both of the impulsive noise and of the dispersive channel in DSL."
  },
  {
    "year": "2017",
    "abstract": "Software evolution continues throughout the life cycle of the software. During the evolution of software system, it has been observed that the developers have a tendency to copy the modules completely or partially and modify them. This practice gives rise to identical or very similar code fragments called software clones. This paper examines the evolution of clone components by using advanced time series analysis. In the first phase, software clone components are extracted from the source repository of the software application by using the abstract syntax tree approach. Then, the evolution of software clone components is analyzed. In this paper, three models, Autoregressive Integrated Moving Average, back propagation neural network, and multi-objective genetic algorithm-based neural network, have been compared for the prediction of the evolution of software clone components. Evaluation is performed on the large open-source software application, ArgoUML. The ability to predict the clones helps the software developer to reduce the effort during software maintenance activities."
  },
  {
    "year": "2017",
    "abstract": "A reliable wireless sensor network (WSN) is defined as a network that functions satisfactorily, in terms of both its coverage and connectivity to the sink(s), throughout its intended mission time. Deploying reliable WSNs is especially important for critical Internet of Things (IoT) applications, such as industrial, structural health-monitoring, and military applications. In such applications, failure of the WSN to carry out its required tasks can have serious effects, and hence, cannot be tolerated. However, the deployment of reliable WSNs is a challenging problem. This is primarily attributed to the fact that sensor nodes are subject to random failures due to different factors, such as hardware failures, battery depletion, harsh environmental conditions, and so on. In this paper, the problem of deploying a WSN with a specified minimum level of reliability at a minimum deployment cost is addressed. This problem is coined the minimum cost reliability constrained sensor node deployment problem (MCRC-SDP). The MCRC-SDP is proved to be an NP-Complete. An ant colony optimization algorithm coupled with a local search heuristic is proposed as a solution. Extensive experimental results demonstrate the effectiveness of the proposed approach in finding high-quality solutions to the problem."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a smartphone-based hearing assistive system (termed SmartHear) to facilitate speech recognition for various target users, who could benefit from enhanced listening clarity in the classroom. The SmartHear system consists of transmitter and receiver devices (e.g., smartphone and Bluetooth headset) for voice transmission, and an Android mobile application that controls and connects the different devices via Bluetooth or WiFi technology. The wireless transmission of voice signals between devices overcomes the reverberation and ambient noise effects in the classroom. The main functionalities of SmartHear include: 1) configurable transmitter/receiver assignment, to allow flexible designation of transmitter/receiver roles; 2) advanced noise-reduction techniques; 3) audio recording; and 4) voice-to-text conversion, to give students visual text aid. All the functions are implemented as a mobile application with an easy-to-navigate user interface. Experiments show the effectiveness of the noise-reduction schemes at low signal-to-noise ratios in terms of standard speech perception and quality indices, and show the effectiveness of SmartHear in maintaining voice-to-text conversion accuracy regardless of the distance between the speaker and listener. Future applications of SmartHear are also discussed."
  },
  {
    "year": "2017",
    "abstract": "Mobile edge computing (MEC) providing information technology and cloud-computing capabilities within the radio access network is an emerging technique in fifth-generation networks. MEC can extend the computational capacity of smart mobile devices (SMDs) and economize SMDs' energy consumption by migrating the computation-intensive task to the MEC server. In this paper, we consider a multi-mobile-users MEC system, where multiple SMDs ask for computation offloading to a MEC server. In order to minimize the energy consumption on SMDs, we jointly optimize the offloading selection, radio resource allocation, and computational resource allocation coordinately. We formulate the energy consumption minimization problem as a mixed interger nonlinear programming (MINLP) problem, which is subject to specific application latency constraints. In order to solve the problem, we propose a reformulation-linearization-technique-based Branch-and-Bound (RLTBB) method, which can obtain the optimal result or a suboptimal result by setting the solving accuracy. Considering the complexity of RTLBB cannot be guaranteed, we further design a Gini coefficient-based greedy heuristic (GCGH) to solve the MINLP problem in polynomial complexity by degrading the MINLP problem into the convex problem. Many simulation results demonstrate the energy saving enhancements of RLTBB and GCGH."
  },
  {
    "year": "2017",
    "abstract": "The topic of the rank minimization problem with affine constraints has been well studied in recent years. However, in many applications the data can exhibit other structures beyond simply being low rank. For example, images and videos present complex spatio-temporal structures, which are largely ignored by current affine rank minimization (ARM) methods. In this paper, we propose a novel approximate message passing (AMP)-based approach that is capable of capturing additional structures in the matrix entries, and can be implemented in a wide range of applications with little or no modification. Using probabilistic low-rank factorization, we derive our generalized AMP-based algorithm as an approximation of the loopy belief propagation algorithm. In addition, we apply a rank selection strategy and an expectation-maximization estimation strategy that adaptively obtain the optimal value of the algorithmic parameters. Then, we discuss the specializations of our proposed algorithm to the applications of structured ARM problems, such as compressive hyperspectral imaging and compressive video surveillance. Simulation results with both synthetic and real data demonstrate that the proposed algorithm yields the state-of-the-art reconstruction performance while maintaining competitive computational complexity."
  },
  {
    "year": "2017",
    "abstract": "We study the sum-rate maximization problem, under a total power budget, for asynchronous single-carrier bi-directional relay networks, consisting of two transceivers and multiple amplify-and-forward relays. When different transceiver-relay links cause significantly different propagation delays in the signal they convey, the end-to-end channel is not amenable to a frequency-flat modeling; rather, a multi-path channel model is appropriate. Such a multi-path channel model results in inter-symbol-interference at the transceivers. Aiming to maximize the sum-rate of this channel over the relay weights and transceivers' powers, we rigorously prove that such a sum-rate maximization problem leads to a relay selection scheme, where only those relays, which contribute to one of the taps of the end-to-end channel impulse response (CIR), are turned on. Indeed, we prove that the optimal end-to-end CIR has only one non-zero tap, rendering the end-to-end channel frequency-flat. Our proof shows that the mean-squared-error (MSE) optimal joint post-channel equalization, network beamforming, and power allocation scheme is sum-rate-optimal. The equivalence of MSE-optimal and sum-rate-optimal solutions is interesting, as MSE minimization promotes end-to-end reliability, while sum-rate maximization advocates for multiplexing gain. These approaches often pull the design of communication systems in different directions. For the aforementioned scenario, these approaches are identical as we prove."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose the mitigating scheme to reduce the effects of phase noise in multi-input multi-output-orthogonal frequency division multiplexing system with independent oscillator in each RF chain. Our proposed schemes consist of two stages; channel estimation stage and data decoding stage. In the first stage, we propose the channel estimation algorithm based on maximum a posteriori (MAP) estimator and a method of selecting the training sequence for channel estimation and we provide the mathematical analysis of our proposed scheme. In the second stage, MAP estimators are used to jointly estimate phase noise at TX and RX and detect data symbols. For analysis of mean square error (MSE) performances, we derive Bayesian Cramėr-Rao bound for multi-parameter estimation problem in each stage. At the end of this paper, we demonstrate from our simulation results that our mathematical analysis is accurate and the proposed algorithm improves the bit-error-rate performance and MSE performance compared with existing schemes."
  },
  {
    "year": "2017",
    "abstract": "In practical radio transmissions, channel capture is a dominating factor that affects wireless network performance. The capture effect can occur in wireless network when packets arrive with different powers. Packets with high power can effectively swamp low power packets, such that they are received successfully, when otherwise a collision would have occurred. We present a vehicular network performance-prediction model for a Rayleigh capture channel in Drive-thru Internet scenario. The model incorporates the capture effect into a 2-D Markov chain modeling the high-node mobility and distributed coordination function broadcast scheme. The performance-prediction model unveils the impacts of mobility velocity and number of vehicles on the throughput in a Rayleigh capture channel. We use a vehicular traffic flow model to predict vehicular movement on road by aggregating all vehicles into a flow. Simulation results confirm that our performance-prediction model accurately predicts the performance of traveling vehicles with Rayleigh capture channel in the Drive-thru Internet scenario. We demonstrate that using our performance-prediction model, we can obtain optimal contention window value, by which the best system throughput can be reached without wasting contention time. This is also proved by Anastasi et al."
  },
  {
    "year": "2017",
    "abstract": "In traditional wireless communications, multiuser diversity gain comes from the diversified channel power gains across different users. In energy harvesting wireless systems, the various energy levels at different transmitters may lead to another type of diversity gain. In this paper, multiuser gain with the emphasis on energy diversity is studied for multiuser energy harvesting communications, where the scaling law of the expected throughput over the number of users is investigated. Three access schemes are considered: two centralized schemes (fixed TDMA, where users transmit in a fixed order; and energy-greedy, where the user with the highest energy level is picked for transmission) and a contention-based distributed scheme (where each user contends for the channel with a certain probability). Under both centralized schemes, it is shown that the expected throughput scales on the order oflog(N), whereNis the number of users. For the distributed scheme, the scaling of throughput depends on the contention probability. Particularly, when each user contends the transmission with probability1/N, the throughput also scales on the order oflog(N)but with a discount factor1/e. Our analytical and numerical results reveal that compared with the point-to-point energy harvesting communication system, the multiuser throughput gain comes from two aspects: the power gain due to the increase of total energy arrivals; and the diversity gain due to the increase of energy arrival dynamics."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an integrated design method for pedestrian avoidance by considering the interaction between trajectory planning and trajectory tracking. This method aims to reduce the need for control calibration by properly considering plant uncertainties and tire force limits at the design stage. Two phases of pedestrian avoidance-trajectory planning and trajectory tracking-are designed in an integrated manner. The available tire force is distributed to the feedforward part, which is used to generate the nominal trajectory in trajectory planning phase, and to the feedback part, which is used for trajectory tracking. The trajectory planning problem is solved not by searching through a continuous spectrum of steering/braking actions, but by examining a limited set of “motion primitives,” or motion templates that can be adopted in sequence to avoid the pedestrian. An emergency rapid random tree (RRT) methodology is proposed to quickly identify a feasible solution. Subsequently, in order to guarantee accuracy and provide safety margin in trajectory tracking with presence of model uncertainties and exogenous disturbance, a simplified LQR-based funnel algorithm is proposed. Simulation results provide insight into how pedestrian collisions can be avoided under given initial vehicle and pedestrian states."
  },
  {
    "year": "2017",
    "abstract": "The two-level nested array geometry, which systematically nests two uniform linear subarrays, is proved to offer O(N2) degrees of freedom (DOFs) with only N sensors. In this paper, a novel sparse extension array geometry for nested multiple-input multiple-output radar is proposed to provide O(N4) DOFs with N sensors. In the proposed geometry, both the transmitter and receiver are equipped with the two-level nested arrays, where we particularly extend the inter-element spacing of the transmitter with a sparse extension factor, leading to a great increase of DOF. Furthermore, we derive the closed-form expressions for the sensor locations and the available DOFs. Spatial smoothing-based MUSIC algorithm is employed to validate the effectiveness and superiority of the proposed sparse extension array for direction of arrival estimation."
  },
  {
    "year": "2017",
    "abstract": "In Internet of Things, various things realize interconnection and intercommunication by the wireless sensor network (WSN). The time-division multiple-access (TDMA) slot scheduling algorithm for WSN is a crucial technology for improving network efficiency and prolonging network lifetime. Considering the industrial field of WSN, the problems of limited energy and changed topology restrict the development of the centralized resource allocation. Although some traditional distributed time slot allocation algorithms solve the network topology change to a certain extent, there are still some problems and challenges in terms of efficiency and energy consumption. In this paper, we propose a distributed TDMA slot scheduling algorithm based on energy and topology factor. By analyzing and summarizing the distributed randomized time slot assignment algorithm, it is found that energy and topology information of network nodes are very important for TDMA slot scheduling. Then the definition of energy-topology (E-T) factor is proposed, which is based on the influence of residual energy and topology on the time slot allocation. Moreover, the distributed TDMA slot scheduling algorithm based on E-T factor is proposed by taking the number of neighbors and residual energy of network nodes into consideration to reduce the execution time and energy consumption of algorithm. Finally, we simulate the proposed scheme to evaluate its performance. The experimental results indicate that the proposed algorithm can reduce the message complexity, time complexity, and energy consumption, and improve the efficiency of TDMA slot scheduling."
  },
  {
    "year": "2017",
    "abstract": "To meet the fast-growing energy demand and, at the same time, tackle environmental concerns resulting from conventional energy sources, renewable energy sources are getting integrated in power networks to ensure reliable and affordable energy for the public and industrial sectors. However, the integration of renewable energy in the ageing electrical grids can result in new risks/challenges, such as security of supply, base load energy capacity, seasonal effects, and so on. Recent research and development in microgrids have proved that microgrids, which are fueled by renewable energy sources and managed by smart grids (use of smart sensors and smart energy management system), can offer higher reliability and more efficient energy systems in a cost-effective manner. Further improvement in the reliability and efficiency of electrical grids can be achieved by utilizing dc distribution in microgrid systems. DC microgrid is an attractive technology in the modern electrical grid system because of its natural interface with renewable energy sources, electric loads, and energy storage systems. In the recent past, an increase in research work has been observed in the area of dc microgrid, which brings this technology closer to practical implementation. This paper presents the state-of-the-art dc microgrid technology that covers ac interfaces, architectures, possible grounding schemes, power quality issues, and communication systems. The advantages of dc grids can be harvested in many applications to improve their reliability and efficiency. This paper also discusses benefits and challenges of using dc grid systems in several applications. This paper highlights the urgent need of standardizations for dc microgrid technology and presents recent updates in this area."
  },
  {
    "year": "2017",
    "abstract": "The accuracy of localization methods based on the arrival time difference is usually affected by the iterative algorithm, the initial value, and the pre-measured wave velocity. The analytical solutions are non-unique because of the square root operations in the calculating process for source coordinates. To solve these significant problems, the nonlinear equations were simplified to the linear equations. An analytical localization method without the pre-measured velocity or the square root operations was developed. The explicit formulas for analytical solutions were resolved for the six sensors network. The source coordinates can be solved for real time by substituting the arrival times and coordinates of sensors. Focusing on the practical engineering where the number of sensors is greater than six, the comprehensive analytical solutions were proposed on account of sensor networks, which formed through the combination of different sensors, and the logistic probability density function. The blasting tests in two mines verified its effectiveness and accuracy. Results show that the locating accuracy of three dimensional comprehensive analytical solutions is superior to the traditional methods. The assumed examples proved that the proposed method performs well under different scales of arrival time errors. This proposed method highlights four advantages: without iterative algorithm, without pre-measured velocity, without initial value, and without square root operations."
  },
  {
    "year": "2017",
    "abstract": "Outdoor images acquired under poor weather conditions are usually contaminated by suspended particles and aerosols in the atmosphere. These captured images easily suffer from contrast reduction, low visibility, and color distortion. In this paper, we develop a novel single image dehazing method based on large sky region segmentation and multiscale opening dark channel model (MODCM). First, a simple but effective method for large sky region detection based on SVM classification is presented, which can be considered as the first step of atmospheric light estimation. Then, two different strategies are utilized for obtaining a more accurate estimate of the atmospheric light according to the mentioned detection result. Furthermore, MODCM can adaptively make use of different patch sizes to calculate the dark channel according to different edge levels, which can prevent halo artifacts near edges of depth discontinuity. In addition, the gradient domain guided filter is adopted to refine the initial transmission map due to its accuracy near edges. Finally, the haze-free image can be obtained through correcting the colors of the sky region and combining the sky and non-sky region. Experimental results on different kinds of hazy images indicate that our proposed approach can produce the visually desirable results with genuine color and high scene visibility, even superior than the other state-of-the-art dehazing methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we use mid-rectangular quadrature rules to solve multidimensional weakly singular integrals of product type (MWSIP) and construct corresponding multi-step and multi-parameter asymptotic expansions of errors. The convergence order can turn from O(hiαi+1) to O(h04), -1 ≤ αi≤ 0, h0= max1≤i≤s{hi} by using extrapolation and splitting extrapolation algorithm. Moreover, we address a posterior error estimate and formulate self-adaptive algorithm. Numerical results illustrate that the method is of high accuracy and efficiency for solving MWSIP."
  },
  {
    "year": "2017",
    "abstract": "Interactive live-streaming applications and platforms face particular challenges: the actions of the viewer's affect the content of the stream. A minimal capture-render delay is critical. This is the case of applications, such as remote laboratories, which allow students to view specific hardware through a webcam, and interact with it remotely in close to real time. It is also the case of other applications, such as videoconferencing or remote rendering. In the latest years, several commercial live-streaming platforms have appeared. However, the most of them have two significant limitations. First, because they are oriented toward standard live-streaming, their capture-render delay tends to be too high for interactive live-streaming. Second, their architectures and sources are closed. That makes them unsuitable for many research and practical purposes, especially when customization is required. This paper presents the requirements for an interactive live-streaming platform, focusing on remote lab needs as a case study. Then, it proposes an architecture to satisfy those requirements that relies on Redis to achieve high scalability. The architecture is based on open technologies, and has been implemented and published as open source. From a client-side perspective, it is web-based and mobile-friendly. It is intended to be useful for both research and practical purposes. Finally, this paper experimentally evaluates the proposed architecture through its contributed implementation, analyzing its performance and scalability."
  },
  {
    "year": "2017",
    "abstract": "With the trend that the Internet is becoming more accessible and our devices being more mobile, people are spending an increasing amount of time on social networks. However, due to the popularity of online social networks, cyber criminals are spamming on these platforms for potential victims. The spams lure users to external phishing sites or malware downloads, which has become a huge issue for online safety and undermined user experience. Nevertheless, the current solutions fail to detect Twitter spams precisely and effectively. In this paper, we compared the performance of a wide range of mainstream machine learning algorithms, aiming to identify the ones offering satisfactory detection performance and stability based on a large amount of ground truth data. With the goal of achieving real-time Twitter spam detection capability, we further evaluated the algorithms in terms of the scalability. The performance study evaluates the detection accuracy, the true/false positive rate and the F-measure; the stability examines how stable the algorithms perform using randomly selected training samples of different sizes. The scalability aims to better understand the impact of the parallel computing environment on the reduction of the training/testing time of machine learning algorithms."
  },
  {
    "year": "2017",
    "abstract": "Stereo video streaming is an emerging topic ever since the popularity of stereo video in the recent years. In this paper, we consider the anaglyph video, which displays the red channel in left view and green/blue channel in right view, respectively. The traditional anaglyph streaming system transmits full RGB components of both views and those results in greater bandwidth consumption. In this paper, we present two novel algorithms to improve the traditional anaglyph system. For the first, we transmit the color channels that will be viewed by the users, and then we rearrange the data to adapt to the standard video compression format. For the second, we propose to perform video demosaicing in the post-processing stage instead of the pre-processing stage as in the traditional system. In addition, we develop a gradient-based stereo matching technique integrated with our demosaicing algorithm for better retrieval of observed data. Experimental results demonstrate that the proposed anaglyph video streaming system outperforms the state-of-the-art algorithms in both objective and subjective comparisons."
  },
  {
    "year": "2017",
    "abstract": "The mHealth trend, which uses mobile devices and associated technology for health interventions, offers unprecedented opportunity to transform the health services available to people across the globe. In particular, the mHealth transformation can be most disruptive in the developing countries, which is often characterized by a dysfunctional public health system. Despite this opportunity, the growth of mHealth in developing countries is rather slow and no existing studies have conducted an in-depth search to identify the reasons. We present a comprehensive report about the factors hindering the growth of mHealth in developing countries. Most importantly, we outline future strategies for making mHealth even more effective. We are also the first to conduct a case study on the public health system of Pakistan showing that mHealth can offer tremendous opportunities for a developing country with a severe scarcity of health infrastructure and resources. The findings of this paper will guide the development of policies and strategies for the sustainable adoption of mHealth not only in Pakistan but also for any developing country in general."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad hoc networks (VANETs), which are deployed along roads, make traffic systems safer and more efficient. The existing theoretical results on capacity scaling laws provide insights and guidance for designing and deploying VANETs. As a new paradigm of VANETs, software-defined vehicular ad hoc networks (SDVANETs) separate the data plane from the control plane. For many prospective applications, software-defined technology will be used in VANETs to achieve some general targets, such as network management. Therefore, a capacity analysis is critical and necessary for SDVANETs. In this paper, we propose a new fundamental framework named real vehicular wireless network model (RVWNM), which enables a more realistic capacity analysis in SDVANETs. We first introduce a Euclidean planar graph that can be constructed from any real map of an urban area and that represents the practical geometry structure of the urban area. Then, an interference relationship graph is abstracted from the Euclidean planar graph, which considers the transmission interference relations among the nodes in the network. Finally, we theoretically analyze the interference relationships in the interference relationship graph. A practical geometrical structure is used to calculate the asymptotic capacity of SDVANETs. To verify the feasibility of RVWNM, we calculate the asymptotic capacity of social-proximity urban networks. We also consider the social-proximity-based mobility of vehicles, and we derive asymptotic capacity bounds for sparse SDVANETs and constant bounds for high-density SDVANETs."
  },
  {
    "year": "2017",
    "abstract": "Most, if not all, existing studies on power line communication (PLC) systems as well as industrial PLC standards are based on orthogonal multiple access schemes, such as orthogonal frequency-division multiplexing and code-division multiple access. In this paper, we propose non-orthogonal multiple access (NOMA) for decode-and-forward cooperative relaying PLC systems to achieve higher throughput and improve user fairness. To quantitatively characterize the proposed system performance, we also study conventional cooperative relaying (CCR) PLC systems. We evaluate the performance of the two systems in terms of the average capacity. In this respect, accurate analytical expressions for the average capacity are derived and validated with Monte Carlo simulations. The impact of several system parameters, such as the branching, impulsive noise probability, cable lengths, the power allocation coefficients, and input signal-to-noise ratio, is investigated. The results reveal that the performance of the proposed NOMA-PLC scheme is superior compared with that of the CCR-PLC system. It is also shown that the NOMA-PLC system can be more effective in reducing electromagnetic compatibility associated with PLC and that increasing the network branches can considerably degrade the performance. Moreover, optimizing the power allocation coefficients is found to be of utmost importance to maximize the performance of the proposed system."
  },
  {
    "year": "2017",
    "abstract": "We study the total transmit power minimization problem for a two-way relay network under two constraints on the transceivers' received signal-to-noise-ratios. The network considered herein consists of multiple multi-antenna relay nodes and two single-antenna transceivers. Each relay transforms the vector of its received signals, by multiplying this vector with a complex beamforming matrix, thereby obtaining a new vector whose entries are transmitted over different antennas of that relay. Assuming the relay beamforming matrices and the transceivers' transmit powers as the design parameters, we first study the total power minimization problem under the assumption that the relay beamforming matrices are symmetric. Under such an assumption, we show that the total power minimization problem is amenable to a semi-closed-form solution, and thus, it can be solved efficiently. We then consider the case, where the relay beamforming matrices may not be symmetric and show that in this case, the total power minimization problem can be solved using a computationally prohibitive algorithm which involves a 2-D search over a grid in the space of the transceivers' transmit powers and semi-definite programming at each vertex of this grid. Our numerical results show that the symmetric assumption on the relay beamforming matrices incurs only insignificant loss, while this assumption allows us to significantly reduce the computational burden of solving the total power minimization problem."
  },
  {
    "year": "2017",
    "abstract": "A fast dual polarization hopping (FDPH) system is designed to enhance the physical layer secure transmission in fixed down-link satellite communications. In order to prevent the eavesdropper from detecting transmitted signals, a pair of dual polarization states is chosen to carry the modulated signal by the designed FDPH pattern. The polarized signal is transmitted through orthogonal dual polarized parabolic antennas by the virtual polarization technique. Due to the assumption that the designed FDPH pattern is synchronous among the legitimate users, the legitimate receivers apply oblique projection polarization filter to suppress one of dual polarization states, and then have a polarization match to recover the scalar modulated signal and demodulate the scalar signal, whereas the eavesdropper cannot match the right polarization state. Therefore, the eavesdropper receives random amplitudes signal owing to the fast polarization hopping. If the modulation scheme is ASK and quadrature amplitude modulation, the demodulation performance of the eavesdropper would be very poor, resulting in a high bit error rate. Moreover, there is severe distinction in orthogonal dual polarized channel. The legitimate users would have a pre-linear compensation with perfect channel state information, which further worsen eavesdropping. Thus, the eavesdropper cannot even demodulate the phase-shift keying signal because of the time varying orthogonal dual polarized channel and auxiliary polarized angle. Simulation results demonstrate the secure performance of our design."
  },
  {
    "year": "2017",
    "abstract": "An improved full-wave multilevel Green's function interpolation method (MLGFIM) with RBF-QR technique is proposed for the fast evaluation of electromagnetic field. The difficulty in applying the interpolation approach with radial basis functions (RBFs) lies in solving the increasingly singular matrix equation with the increase of the number of interpolation points. The compromise of making the basis functions relatively less smooth was used in the previous RBF implementations to address this problem. In this paper, a new interpolation scheme, the RBF-QR technique is applied to the interpolation of Green's function to resolve the ill-conditioning issue without such a compromise. A better conditioned basis function is generated by the QR-factorization technique, and it also solves the sensitivity of the basis function to the value of shape parameter. Moreover, a new hybrid interpolation pattern is adopted to optimize the grid pattern, e.g., reduce the number of interpolation points required and the boundary interpolation errors. The employment of the proposed RBF-QR technique in conjunction with hybrid interpolation pattern makes the efficiency of the MLGFIM greatly improved. The proposed algorithm is used for the analysis of problems involving objects, such as patch arrays, photonic bandgap structures, metasurface structures, double negative metamaterial and so on. Five numerical examples are given to validate this new algorithm, and show the accuracy and efficiency of the improved MLGFIM."
  },
  {
    "year": "2017",
    "abstract": "In recent years, the identification and application of strong and weak ties in social networks has drawn increasing attention. The traditional definitions of strong ties (with two endpoints in the same community) and weak ties (with two endpoints in different communities) are being challenged by overlapping community structures. Because of their unique nature, the relationships between overlapping nodes and non-overlapping nodes are difficult to classify as strong or weak. In view of this, it is here proposed that the coefficient indicator for overlapping communities was used to redefine node relationships and enable the quantification of strong and weak ties. Next, changes in the quantities of strong and weak ties were analyzed by varying the threshold values of the overlap coefficient. Finally, the effect of weak ties in information dissemination was assessed in overlapping and non-overlapping situations, respectively. Results demonstrated that the overlap coefficient proposed in this paper could better characterize the strong and weak attributes of edges under overlapping community structures."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing has become a significant research area in large-scale computing, because it can share globally distributed resources. Cloud computing has evolved with the development of large-scale data centers, including thousands of servers around the world. However, cloud data centers consume vast amounts of electrical energy, contributing to high-operational costs, and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) using live migration and putting idle nodes in sleep mode allows cloud providers to optimize resource utilization and reduce energy consumption. However, aggressive VM consolidation may degrade the performance. Therefore, an energy-performance tradeoff between providing high-quality service to customers and reducing power consumption is desired. In this paper, several novel algorithms are proposed for the dynamic consolidation of VMs in cloud data centers. The aim is to improve the utilization of computing resources and reduce energy consumption under SLA constraints regarding CPU, RAM, and bandwidth. The efficiency of the proposed algorithms is validated by conducting extensive simulations. The results of the evaluation clearly show that the proposed algorithms significantly reduce energy consumption while providing a high level of commitment to the SLA. Based on the proposed algorithms, energy consumption can be reduced by up to 28%, and SLA can be improved up to 87% when compared with the benchmark algorithms."
  },
  {
    "year": "2017",
    "abstract": "The communication in the Smart Home Internet of Things (SH-IoT) comprising various electronic devices and sensors is very sensitive and crucial. In addition, the key requirements of the SH-IoT include channel security, handover support, mobility management, and consistent data rates. Proxy mobile IPv6 (PMIPv6) is considered as one of the core solutions to handle extreme mobility; however, the default PMIPv6 cannot ensure performance enhancement in SH-IoT scenarios, i.e., Route Optimization (RO). The existing security protocols for PMIPv6 cannot support secure RO for smart home IoT services, where mobile nodes (MNs) communicate with home IoT devices not belonging to their domain. Motivated by this, a secure protocol is proposed, which uses trust between PMIPv6 domain and smart home to ensure security as well as performance over the path between MNs and home IoT devices. The proposed protocol includes steps for secure RO and handover management, where mutual authentication, key exchange, perfect forward secrecy, and privacy are supported. The correctness of the proposed protocol is formally analyzed using BAN-logic and Automated Validation of Internet Security Protocols and Applications (AVISPA). Furthermore, network simulations are conducted to evaluate the performance efficiency of the proposed protocol. The results show that the proposed approach is capable of providing secure transmission by resolving the RO problem in PMIPv6 along with the reduction in handover latency, end to end delay and packet loss, and enhancement in throughput and transmission rate even during the handover phase."
  },
  {
    "year": "2017",
    "abstract": "The growth of mobile devices has provided significant opportunities for developing healthcare apps based on the mobile device ability to collect data. Unfortunately, the data collection is often intermittent. Missing data present significant challenges to trend analysis of time series. Straightforward approaches consisting of supplementing missing data with constant or zero values or with linear trends can severely degrade the quality of the trend analysis. In this paper, we present a robust adaptive approach to discover the trends from fragmented time series. The approach proposed in this paper is based on the hypothesis-testingbased adaptive spline filtering (HASF) trend analysis algorithm, which can accommodate non-uniform sampling and is therefore inherently robust to missing data. HASF adapts the nodes of the spline based on hypothesis testing and variance minimization, which adds to its robustness. Further improvement is obtained by filling gaps by data estimated in an earlier trend analysis, provided by HASF itself. Three variants for filling the gaps of missing data are considered, the best of which seems to consist of filling significantly large gaps with linear splines matched for continuity and smoothness with cubic splines covering datadense regions. Small gaps are ignored and addressed by the underlying cubic spline fitting. Finally, the existing measurements are weighted according to their importance by simply transferring the importance of the missing data to their existing neighbors. The methods are illustrated and evaluated using heart rate data sets, blood pressure data sets, and noisy sine data sets."
  },
  {
    "year": "2017",
    "abstract": "It is of interest to analyze urban spatial structure by identifying urban subcenters, for which published literature proposes many methods. Although these methods are widely applied, they demonstrate obvious shortcomings that restrict further application. Therefore, it is of great value to propose a new urban subcenter identification method that can overcome these shortcomings. In this paper, we introduce an alternative method. Unlike two-stage procedures and other arbitrary methods, our method is not based on arbitrary cutoff values and is entirely parameter free. We first calculate the commuting fluxes for each pair of census tracts and use the fluxes to represent a local density. After that, the census tracts are partitioned into several clusters using a clustering algorithm. Finally, subcenters are derived from the clusters through a circularly shaped spatial scan statistic. We apply this method to 2010 and 2015 census data sets for Wuhan, China. The identification and comparison results demonstrate that our proposed method is effective and can be applied toward future research."
  },
  {
    "year": "2017",
    "abstract": "As a new software paradigm, cloud computing provides services dynamically according to user requirements. However, it tends to disclose personal information due to collaborative computing and transparent interactions among software as a service (SaaS) services. We propose a private data disclosure checking method that can be applied to the collaboration interaction process. First, we describe the privacy requirement with ontology and description logic. Second, with dynamic description logic, we validate whether SaaS services are authorized to obtain a user's privacy attributes, to prevent unauthorized services from obtaining their private data. Third, we monitor authorized SaaS services to guarantee privacy requirements. Therefore, we can prevent users' private data from being used and propagated illegally. Finally, we propose privacy disclosure checking algorithms, and demonstrate their correctness and feasibility by experiments."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency division multiplexing (OFDM) index modulation (IM) is a novel multicarrier modulation, which employs both the indices of the active subcarriers and conventional constellation symbols to convey information. Although OFDM-IM shows advantages in many aspects, it cannot provide transmit diversity (TD). To address this problem partly, in this paper, we propose a modified scheme, termed as OFDM-IM with TD (OFDM-IM-TD), through utilizing silent subcarriers and multiple signal constellations (SCs). Specifically, in OFDM-IM-TD, besides the active subcarriers, the same information is transmitted over the silent subcarriers, while using a different SC. The design of the SC for the silent subcarriers is further illustrated. Next, the union bound of the average bit error probability is derived, based on which the transmit diversity gain of the proposed scheme over OFDM-IM is theoretically verified. Moreover, a low-complexity log-likelihood ratio-based detector is developed. Finally, simulation results are given to demonstrate the performance of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Electromagnetic simulation-based channel modeling is presently considered as a promising option for wireless body area network (WBAN) channel modeling. The benefits of simulation-based channel modeling are obvious: realistic channel characteristics for required environments and situations are provided flexibly and cheaply. In addition, the use of simulation-based channel modeling may overcome several challenges related to the use of measurement data, such as uncertainties and inaccuracies due to cabling, unintentional changes in the position of the test person or the antennas and so on. There are several numerical methods suitable for simulation based-channel modeling, both full-wave and an asymptotic solutions. The choice of the numerical approach depends on the nature of the communication links of the wireless body network being considered. This paper presents a general overview, including recent progress, of the electromagnetic simulation-based WBAN channel modeling techniques. Advantages, disadvantages, and the most appropriate applications are described. Furthermore, the features of the different techniques are compared."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new area-based prior value technique for the improvement of automatic visual inspection in hard disk drive manufacturing. Micro-contaminations are detected on the air-bearing surface of the head gimbal assembly. The new area-based prior value technique uses the locations of contaminations that appear in the inspection area. The experimental results validate the efficiency of the new detection method on low-resolution images, as the proposed method yielded 93.1% accuracy."
  },
  {
    "year": "2017",
    "abstract": "In modern defense technology, signal intelligence plays an important role in military operations as an intelligence source. Among its target signals, telemetry and telecommand signals can use line-coding schemes for their advantageous properties in the presentation of binary data of transmission systems. Therefore, in a non-cooperative context, blind classification of the line-coding scheme is the final crucial step in recovering target information from an unknown received signal. In this paper, we examine the characteristic features of line-coding schemes and then propose a simple blind classification algorithm for the schemes. We also analyze correct classification probabilities of the proposed algorithm in a noiseless and noisy environment through computer simulations. The proposed method can discern line-coding schemes, allowing reconstruction of the original information data."
  },
  {
    "year": "2017",
    "abstract": "Quasi-Z-source inverters (qZSIs) are nowadays increasingly used owing to advantages such as single-stage operation, lower component rating, and continuous input current and common dc rail. These benefits lead to investigate this converter for grid-connected applications. This paper presents a grid-connected qZSI with both ac and dc side control. Sliding mode control (SMC)-based controller for capacitor voltage regulation has been proposed to ensure a fast and dynamic response for wide variations in input voltage, output load, and reference controlled quantity. A detailed mathematical model of the system is presented. A stable and fast response of SMC has been demonstrated using simulation and is validated by experimental results."
  },
  {
    "year": "2017",
    "abstract": "This paper considers the problem of deriving a time-division multiple-access (TDMA) schedule for multi-hop wireless networks that allow nodes to perform multiple transmissions/receptions to/from all of their neighbors simultaneously over the same frequency. To date, there are a number of link schedulers for the networks in question but they do not consider flow rate or any notion of fairness when deriving a TDMA schedule. Henceforth, we address this critical gap by proposing a link scheduler, called Algo-Fair, that, in addition to maximizing the number of links in each slot, also provides fairness among flows. In addition, it uses a novel augmentation step to distribute spare capacity fairly among flows. We believe this step is general and can be applied readily in other forms of wireless networks. Apart from that, Algo-Fair generates a schedule directly while yielding a fair rate allocation. This is different from existing methods that first use a flow contention graph to compute a fair share before deriving the corresponding schedule, which may not exist. Numerical results show Algo-Fair has higher fairness, minimum rate, and average total throughput than competing approaches, and low end-to-end delay."
  },
  {
    "year": "2017",
    "abstract": "Human behavior analysis has become a critical area of research in computer vision and artificial intelligence research community. In recent years, video surveillance systems of crowd scenes have witnessed an increased demand in different applications, such as safety, security, entertainment, and personal mental health. Although many methods have been proposed, certain limitations exist, and many unresolved issues remain open. In this paper, we proposed a novel spatio-temporal sparse coding representation, based on sparse coded features with k-means singular value decomposition for robust classification of crowd behaviors. Extensive experiments have shown that dictionary learning method with sparsely coded features captured vital structures of video scenes and yielded discriminant descriptors for classifications than conventional bag-of-visual-features. Relying on the measurable features of crowd scenes and motion characteristics, we can represent different attributes of the crowd scenes. Experiments on hundreds of video scenes were carried out on publicly available datasets. Quantitative evaluation indicates that the proposed model display superior accuracy, precision, and recall in classifying human behaviors with linear support vector machine when compared with the state-of-the-art methods. The proposed method is conceptually simple and easy to train: thereby achieving an accuracy of 93.50%, a precision of 93.40%, and a recall of 95.96%."
  },
  {
    "year": "2017",
    "abstract": "Collaborative applications of physical systems and algorithms bring the rapid development of cyber physical systems (CPS). Establishing CPS with image classification systems, however, is difficult, because both categories of algorithms, deep learning methods and traditional feature extraction methods, are independent and individual currently. Therefore, in this paper, we propose a fast feature fusion algorithm to satisfy the requirement of CPS in the area of image classification from a comprehensive perspective. First, we fuse the shallow-layer network feature, large pre-trained convolutional neural network feature and traditional image features together by genetic algorithm, in order to guarantee high accuracy with little training time and hardware cost. Second, we increase the distance between different centers by dynamic weight assignment to improve distinguishability of different classes. Third, we propose a partial selection method to reduce the length of the fused feature vectors and to improve the classification accuracy further by centralizing the features within the same class. Finally, experimental results show that our method can achieve high classification accuracy with lower training time and hardware consumption, which can greatly improve the efficiency and flexibility of image classification in cyber physical systems."
  },
  {
    "year": "2017",
    "abstract": "Recent advancement in digital and communication technologies has brought privacy aspects to the forefront. Although e-health has many advantages and it facilitates the patients and health service providers significantly, the possibility of privacy breaches can allow sensitive health care information to move into the wrong hands. Designing robust privacy preserving policies to strengthen the trust of patients in electronic health records is imperative for its wide spread acceptance and success. In this paper, we propose, a framework to solve the privacy problem in a heterogeneous network of many clinical institutions while preserving data utility and patients' privacy. The contributions of this paper include: (1) scalable privacy-enabled architecture supporting re-identification of patient identity, and (2) context-aware privacy-preserving scheme supporting named and anonymous linked access to medical data stored at one or more health service providers. Moreover, to demonstrate the correctness of proposed privacy-aware scheme, we performed formal modeling and verification using high-level Petri nets and Z3 Solver."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a distributed global connectivity maintenance and control framework of multi-robot networks, which can adapt connectivity online. Based on a series of energy functions, the control framework can make each robot autonomously move along the direction of gradient descent of the energy functions in order to reach the desired global connectivity of the multi-robot networks. This framework has enhanced adaptability and flexibility of multi-robot systems, because adapting connectivity online enables the system to maintain, promote or degrade connectivity at different stages of an integrated mission which require different desired connectivity values. Online connectivity adaptation can also help to change connectivity when the environment becomes more complicated, unknown and dynamic. Theorems are proposed to prove that the framework can not only maintain global connectivity, but can also effectively adapt global connectivity to desired values online, which has rarely been studied. Furthermore, connectivity promotion in the presence of bounded external control terms, such as collision avoidance, is also investigated, which helps to expand the scope of the framework. Finally, simulation and experiment results are presented so as to validate our unified control framework."
  },
  {
    "year": "2017",
    "abstract": "Sweden is planning to store nuclear spent fuel in long-term geological repositories. Copper canisters with a ductile iron insert will preserve the fuel for thousands of years at a depth of about 500 m in Swedish bedrock. The International Atomic Energy Agency (IAEA) and Euratom safeguards inspectorates have to maintain the continuity of knowledge (CoK) during transport and deposition of canisters from the encapsulation plant to the final repository. The aim of this paper is then oriented to provide such CoK for canisters by an identification and authentication based on ultrasound. This paper describes an authentication method oriented to prevent falsification of copper canisters. According to the ultrasonic investigation of the friction stir welding process of the copper lid onto the cylindrical tube, the ultrasonic response of the remaining gap partially filled during the welding is used as a unique pattern for authentication. The analysis of various measurements made on angular sections of copper lids friction stir welded onto the tube revealed the feasibility of acquisition of a valuable signal from the reflection of the internal gap. Following the observations on this data set, a possible technical design is detailed, where the identification and authentication methods can be combined with immersion probes."
  },
  {
    "year": "2017",
    "abstract": "Social networks (SNs) have become a powerful tool for the jihadism as they serve as recruitment assets, live forums, psychological warfare, as well as sharing platforms. SNs enable vulnerable individuals to reach radicalized people, hence triggering their own radicalization process. There are many vulnerability factors linked to socio-economic and demographic conditions that make jihadist militants suitable targets for their radicalization. We focus on these vulnerability factors, studying, understanding, and identifying them on the Internet. Here, we present a set of radicalization indicators and a model to assess them using a data set of tweets published by several Islamic State of Iraq and Sham sympathizers. Results show that there is a strong correlation between the values assigned by the model to the indicators."
  },
  {
    "year": "2017",
    "abstract": "Future networks are promising to solve current issues and provide new features. Self-organizing network (SON) paradigm is one of the anticipated solutions. It involves the use of cognition concept and optimization techniques to enhance the network performance. In this paper, we propose the use of two multi-objective optimization techniques, namely, the multi-objective particle swarm optimization (MOPSO) and the multi-objective central force optimization (MOCFO) in future SON to manage system resources efficiently. Therefore, the used system design and implementation are provided. In addition, the evaluation results of the proposed two methods are compared with those obtained using the non-dominated sorting genetic algorithm (NSGA-II). Extensive simulations carried out using MATLAB package showed that MOPSO is comparable to NSGA-II and outperforms MOCFO in the network throughput. In addition, considering the needed computation time for algorithm convergence, MOPSO is faster than NSGA-II and MOCFO by 5.8 times and 9.9 times on average, respectively. Moreover, this paper provides a study on algorithm convergence rate, solution diversity, and station load."
  },
  {
    "year": "2017",
    "abstract": "In non-continuous orthogonal frequency division multiplexing (NC-OFDM)-based cognitive radio system, the sidelobe suppression methods use the fixed length rectangular windowing functions for canceling carriers (CCs) like the extended active interference cancellation (EAIC) and active interference cancellation (AIC) methods. The AIC and its EAIC methods reduce the interference a lot, but the CCs in different frequency have a non-uniform assignment for sidelobe suppression. To overcome this problem a novel variable basis function proposed in which the CCs are grouped by frequency positions and modeled with different waveforms of different length to suppress NC-OFDM side lobes effectively while reducing inter carrier interference (ICI) at the same time. Simulation results show that using variable basis functions of the proposed method, -60-dB sidelobe suppression depth is reached even with higher order 64-QAM symbol mapping and the ICI caused by the subcarriers is almost negligible."
  },
  {
    "year": "2017",
    "abstract": "Internet of things (IoT) is expanding its outreach to almost every aspect of our daily life. By utilizing network coding in IoT, the IoT energy consumption can be reduced. Thus it is worthwhile studying and improving the applications in IoT, where network coding is incorporated. In this paper, we optimize the performance of network coding-based communication and reliable storage in two important components of IoT, including the IoT core network, where data is sensed and transmitted, and the distributed cloud storage, where the data generated by the IoT core network is stored. First, we propose an adaptive network coding scheme in the IoT core network to improve the transmission efficiency. We demonstrate the efficacy of the scheme and the performance advantage over existing schemes through simulations. Second, we introduce the optimal storage allocation problem in the network coding-based distributed cloud storage, which aims at searching for the most reliable allocation that distributes the n data components into N data centers, given the failure probability p of each data center. Finally, we propose a polynomial-time optimal storage allocation (OSA) scheme to solve the problem. Both the theoretical analysis and the simulation results show that the storage reliability could be greatly improved by the OSA scheme."
  },
  {
    "year": "2017",
    "abstract": "Cloud resource management research and techniques have received relevant attention in the last years. In particular, recently numerous studies have focused on determining the relationship between server-side system information and performance experience for reducing resource wastage. However, the genuine experiences of clients cannot be readily understood only by using the collected server-side information. In this paper, a cloud resource management framework with two novel turnaround time driven auto-scaling mechanisms is proposed for ensuring the stability of service performance. In the first mechanism, turnaround time monitors are deployed in the client-side instead of the more traditional server-side, and the information collected outside the server is used for driving a dynamic auto-scaling operation. In the second mechanism, a schedule-based auto scaling preconfiguration maker is designed to test and identify the amount of resources required in the cloud. The reported experimental results demonstrate that using our original framework for cloud resource management, stable service quality can be ensured and, moreover, a certain amount of quality variation can be handled in order to allow the stability of the service performance to be increased."
  },
  {
    "year": "2017",
    "abstract": "Implantable wireless body area networks (WBANs) are gaining considerable attention to the researchers due to their high potential in healthcare applications. However, one of the biggest challenges of WBANs is the heat produced by wireless implants because of the continuous sensing of physiological parameters that could cause thermal impairment to the human tissue. Again, an implantable WBAN can be equipped with heterogeneous nodes having diverse throughput, fidelity, and latency demands. Also, un-controlled traffic reporting rate could cause high contention as well as congestion in nodes, which are usually organized forming a many-to-one routing paradigm in a WBAN. The problem of congestion not only restrains in satisfying the desired QoS requirements of the diverse healthcare applications, but also increases the dissipated energy and the temperature of an implant biosensor. This paper proposes a novel rate control mechanism with the aim of providing a unified solution for both congestion and hotspot avoidance in an implantable WBAN. The proposed scheme also presents a scheduling rate allocation mechanism reflecting the relative priority of biosensors. The performance of the protocol is evaluated using simulations, which demonstrate that the proposed protocol maintains lower temperature rise as well as avoid the creation of hotspot(s). The results also indicate that the proposed protocol significantly improves the performance of healthcare applications in terms of throughput, reliability, latency, as well as energy consumption."
  },
  {
    "year": "2017",
    "abstract": "Power line communication (PLC) has made remarkable strides to become a key enabler of smart grid and its applications. Existing PLC systems are based on orthogonal frequency division multiplexing (OFDM), which has a high peak-to-average power ratio (PAPR). This paper presents vector OFDM (VOFDM) with advanced signal processing at the receiver to improve the energy efficiency of the PLC system. Results show that, due to its low PAPR properties, VOFDM is less sensitive to impulsive noise and provides a reduction of 5.8 dB in transmit power requirement relative to conventional OFDM. Furthermore, unlike the existing impulsive noise cancellation methods, the adopted signal processing technique also improves the SNR at the receiver by 2.1 dB, which further reduces the power requirement of the PLC transceiver. Together, these can simplify design, reduce cost, and improve energy efficiency of future PLC transceivers."
  },
  {
    "year": "2017",
    "abstract": "Multicarrier phase ranging (MCPR) technique has been widely used in radio navigation, telemetry, radar, and many other fields. In an MCPR system, unique range estimation can be obtained within only the so-called unambiguous distance (UD) because of phase ambiguity. As a metric gauging, the measurable distance of an MCPR system, the UD has been well studied under two common configurations: the linearly spaced frequencies and the proportionally spaced frequencies. In this paper, we propose to apply the frequency hopping (FH) waveform to the MCPR systems for an enhanced antijamming capability, which has been a key criterion in military and other mission critical applications. It is, however, difficult to define the UD with randomly spaced frequencies (RSF) led by the FH waveform. Under the RSF configuration, the UD becomes a random variable. We try to depict its statistical property with a deterministic value and find that the upper bound of the random UD plays an important role. We prove that, without phase noise, the UD can reach its upper bound with a large probability when only a dozen of carriers are employed, as long as the hop set of FH waveform is large enough. Simulations further show that even in the presence of phase noise and multipath fading scenarios the UD under the RSF configuration can also achieve its upper bound asymptotically if the number of carriers is moderately increased from a dozen to several dozens. Our paper uncovers the feasibility of applying the FH waveform to the MCPR systems."
  },
  {
    "year": "2017",
    "abstract": "This paper compares programming environments that exploit heterogeneous systems to process a large amount of data efficiently. Our motivation is to investigate the feasibility of the adaptive, transparent migration of intensive computation for a large amount of data across heterogeneous programming languages and processors for high performance and programmability. We compare a variety of programming environments composed of programming languages, such as Java and C, memory space models, such as distinct and shared memory, and parallel processors, such as general-purpose CPUs and graphics processing units (GPUs) to examine their performance-programmability tradeoffs. In addition, we introduce a software-based shared virtual memory that creates a view of the host memory inside GPU kernels to enable seamless computation offloading from the host to the device. This paper reveals a programmability-performance hierarchy in which programs increase their performance at the cost of decreasing programmability. The experimental results suggest the desirability of a well-balanced system."
  },
  {
    "year": "2017",
    "abstract": "Human-robot interaction is a growing area of research as robotic applications expand into unstructured environments. However, much of the current research has focused on tasks involving limited degrees of freedom (DOF), while not allowing the human the ability to choose the DOF on which they wish to focus. In this paper, a controller that allows human-robot cooperation in six-DOF Cartesian space is presented, which allows the human to direct their focus as they desire. The developed scheme was tested using a virtual reality system while maintaining physical interaction with the robot. Overall, the subjects were 100% successful in completion of the tasks and were able to exchange leader/follower roles with the robot bidirectionally. In addition, a reinforcement learning algorithm was shown to decrease the estimated mechanical power applied by the human to exchange roles. The latter proves the efficiency of the proposed scheme and makes it a strong candidate for applications that involve sophisticated human-robot interaction in collaborative tasks found in a plethora of cases, e.g., industry, manufacturing, semi-autonomous driving, and so on."
  },
  {
    "year": "2017",
    "abstract": "A measurement-based novel statistical path-loss model with a height-dependent factor and a body obstruction (BO) attenuation factor for off-body channel under a hospital environment at 6-8.5 GHz is proposed. The height-dependent factor is introduced to emulate different access point (AP) arrangement scenarios, and the BO factor is employed to describe the effect caused by different body-worn positions. The height-dependent path-loss exponent is validated to fluctuate from 2 to 4 with AP height increasing by employing both computer simulation and classical two-ray model theory. As further validated, the proposed model can provide more flexibility and higher accuracy compared with its existing counterparts. The presented channel model is expected to provide wireless link budget estimation and to further develop the physical layer algorithms for body-centric communication systems under hospital environments."
  },
  {
    "year": "2017",
    "abstract": "With the rapid development of smart factory of Industry 4.0, all kinds of industrial devices are adopted in smart factory. As a result, the complexity of cooperative behaviors among industrial devices increases rapidly. It becomes more and more difficult for practicing engineers to ensure temporal correctness of cooperative behaviors. At the same time, smart factory has made its way into the domain of safety-critical systems, where there is a higher requirement for temporal correctness of cooperative behaviors. Therefore, it faces great challenges for practicing engineers to ensure temporal correctness of cooperative behaviors. Nowadays, some methods have been proposed for analysis of cooperative behaviors. They can use graphic methods and formal methods to create the graphic model and formal model to analyze and ensure the temporal correctness. However, these methods lack the capability of multi-perspective analysis that is exactly necessary for those systems that have a higher requirement for temporal correctness. To address this issue, in this paper, we propose a multi-perspective method that can analyze cooperative behaviors from the macroscopic perspective and the microscopic perspective. Comparing to existing methods, it can provide a more thorough analysis for cooperative behaviors. The usage of our method is illustrated by a semiconductor manufacturing scenario."
  },
  {
    "year": "2017",
    "abstract": "The main purpose of this paper is to investigate the feasibility of using field programmable gate arrays (FPGAs) chips as alternatives for the conventional CPUs to accelerate the numerical solution of the fluid dynamics differential equations. FPGA is an integrated circuit that contains an array of logic blocks, and its architecture can be reprogrammed and reconfigured after manufacturing. Complex circuits for various applications can be designed and implemented using FPGA hardware. The reconfigurable hardware used in this paper is a system on a chip FPGA type that integrates both microprocessor and FPGA architectures into a single device. In this paper, typical computational fluid dynamics problems, such as the Laplace and 1-D Euler equations, are implemented and solved numerically on both reconfigurable hardware and CPU. The precision of results and speedups of the calculations is compared together. In some cases, the computational process on FPGA is up to 20 times faster than a conventional CPU, with the same data precision. Several numerical and analytical solutions are used to validate the results."
  },
  {
    "year": "2017",
    "abstract": "In recent years, the Smart City concept has become popular for its promise to improve the quality of life of urban citizens. The concept involves multiple disciplines, such as Smart health care, Smart transportation, and Smart community. Most services in Smart Cities, especially in the Smart healthcare domain, require the real-time sharing, processing, and analyzing of Big Healthcare Data for intelligent decision making. Therefore, a strong wireless and mobile communication infrastructure is necessary to connect and access Smart healthcare services, people, and sensors seamlessly, anywhere at any time. In this scenario, mobile cloud computing (MCC) can play a vital role by offloading Big Healthcare Data related tasks, such as sharing, processing, and analysis, from mobile applications to cloud resources, ensuring quality of service demands of end users. Such resource migration, which is also termed virtual machine (VM) migration, is effective in the Smart healthcare scenario in Smart Cities. In this paper, we propose an ant colony optimization-based joint VM migration model for a heterogeneous, MCC-based Smart Healthcare system in Smart City environment. In this model, the user’s mobility and provisioned VM resources in the cloud address the VM migration problem. We also present a thorough performance evaluation to investigate the effectiveness of our proposed model compared with the state-of-the-art approaches."
  },
  {
    "year": "2017",
    "abstract": "We consider the challenging problem of joint angle estimation and signal reconstruction for coherently distributed (CD) sources in massive multiple-input-multiple-output (MIMO) systems employing uniform rectangular arrays. A simplified method inspired by the two-dimensional (2-D) unitary estimating signal parameters via rotational invariance technique (ESPRIT) is proposed to estimate both the central angle and the angular spread without the need for a spectrum peak search and covariance matrix matching process. We first approximate the 2-D generalized steering vector expressed as a Schur-Hadamard product by a pair of one-dimensional generalized steering vectors. Then, we obtain two approximate rotational invariance relationships with respect to the central angles of the CD sources using a linear approximation of the individual generalized steering vectors of the azimuth and elevation subarrays. With the aid of this approximate decomposition, a new unitary ESPRIT-inspired algorithm is conceived to automatically pair the 2-D central angle estimations and a novel method capable of bypassing the high-complexity search process is proposed for angular spread estimation. Furthermore, the closed-form approximate Cramer-Rao lower bounds are derived for the estimators of both the central angles and the angular spreads. The complexity of the proposed estimator is also analyzed. Additionally, the orthogonality of the generalized steering vectors is proved, which enables us to propose a low-complexity method to reconstruct the CD signal matrix by replacing the inversion operator with the conjugate transpose operator. The simulation results demonstrate the efficiency of our proposed approach."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a fully ear-worn long-term blood pressure (BP) and heart rate (HR) monitor to achieve a higher wearability. Moreover, to enable practical application scenarios, we present a machine learning framework to deal with severe motion artifacts induced by head movements. We suggest situating all electrocardiogram (ECG) and photoplethysmography (PPG) sensors behind two ears to achieve a super wearability, and successfully acquire weak ear-ECG/PPG signals using a semi-customized platform. After introducing head motions toward real-world application scenarios, we apply a support vector machine classifier to learn and identify raw heartbeats from motion artifacts-impacted signals. Furthermore, we propose an unsupervised learning algorithm to automatically filter out residual distorted/faking heartbeats, for ECG-to-PPG pulse transit time (PTT) and HR estimation. Specifically, we introduce a dynamic time warping-based learning approach to quantify distortion conditions of raw heartbeats referring to a high-quality heartbeat pattern, which are then compared with a threshold to perform purification. The heartbeat pattern and the distortion threshold are learned by a K-medoids clustering approach and a histogram triangle method, respectively. Afterward, we perform a comparative analysis on ten PTT or PTT&HR-based BP learning models. Based on an acquired data set, the BP and HR estimation using the proposed algorithm has an error of -1.4±5.2 mmHg and 0.8±2.7 beats/min, respectively, both much lower than the state-of-the-art approaches. These results demonstrate the capability of the proposed machine learning-empowered system in ear-ECG/PPG acquisition and motion-tolerant BP/HR estimation. This proof-of-concept system is expected to illustrate the feasibility of ear-ECG/PPG-based motion-tolerant BP/HR monitoring."
  },
  {
    "year": "2017",
    "abstract": "There is an increasing interest in upgrading the E-Model, a parametric tool for speech quality estimation, to the wideband and super-wideband contexts. The main motivation behind this has been to quantify the quality gain lent by various new codecs and communication situations. There have been numerous such contributions, and all of them have been more or less successful. This paper reports on an extension of the E-Model to the mixed narrowband/wideband (NB/WB) context. More specifically, we take a novel approach toward deriving effective equipment impairment factors (Ie,WB,eff ) by considering additional impairments related to the underlying communications network. These additional impairments are the pause and jump temporal discontinuities along with network-related loss and pure codec-related impairments. While the effect of loss is a thoroughly studied topic and has been integrated into the E-Model, pauses and jumps have been given little attention. Pauses and jumps manifest themselves as temporal dilation and contraction, respectively, in the resulting speech signal that is presented to the listener and are normally caused by jitter and jitter buffer interaction. In this paper, we initially present a fourstate Markov model to characterize, and also emulate, loss, pause, and jump impairments. Then, we present alternative models for computing effective equipment impairment models. A large number of test stimuli were generated using different NB and WB codecs. WB-PESQ was used to evaluate the stimuli. Genetic programming was employed to derive equipment impairment factors. The proposed models have a high correlation with WB-PESQ. We claim that the models proposed by us outperform the existing E-Model by a factor of approximately 29% while using WB-PESQ as a reference model. The models also outperform the E-Model against results from auditory tests. It is also shown that the models outperform the results of multiple linear regressions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present an analytical framework to evaluate the accuracy of a vertical handoff algorithm based on a decision tree in a heterogeneous vehicle network. To quantify the effects of errors in the decisions made by this analytical framework, we consider two key design features: 1) the probability of a false alarm and 2) the probability of missing an alarm. Then, we propose using the Kalman filtering algorithm to obtain more accurate parameters. The probability threshold interval model is designed to characterize the errors in vertical handoff decisions made under imprecise information conditions. The accuracy of vertical handoff decisions based on a decision tree under Gaussian and linear models is analyzed. These analytical results are applied to evaluate the performance of the vertical handoff model based on the decision tree. Finally, we propose a robust vertical handoff algorithm based on the decision tree to improve the decision accuracy. A theoretical analysis shows that the proposed algorithm improves handoff decision accuracy. In addition, we conducted comprehensive simulations to validate the theoretical results. The simulation results demonstrate that our algorithm substantially improves the handoff performance in a heterogeneous vehicle network."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a scalable estimation theoretic framework to address the time-sensitive truth discovery problem with accuracy assessment in social sensing applications. Social sensing has emerged as a new application paradigm that provides us with an unprecedented opportunity to collect observations about the physical world from humans or devices on their behalf. A fundamental challenge in social sensing applications lies in ascertaining the correctness of claims and the reliability of data sources without knowing either of them a priori, which is referred to as truth discovery. While significant progress has been made to solve the truth discovery problem, there exists three important limitations: (1) The information of users and claims in time dimension has not been fully exploited in the truth discovery solutions; (2) An analytical framework to rigorously assess the accuracy of the truth discovery results is lacking; and (3) Many current truth discovery schemes perform sequential operations, which are not scalable to large-scale social sensing events. To address the above limitations, we propose a scalable time-sensitive truth discovery (TS-TD) scheme that explicitly incorporates the source responsiveness and the claim lifespan into an estimation theoretical framework. Furthermore, we develop new confidence bounds to rigorously assess the accuracy of the truth discovery results. We also implement a parallel TS-TD algorithm on a graphic processing unit platform with thousands of cores to improve the computational efficiency. Finally, we evaluate the TS-TD scheme through three real-world case studies using Twitter data feeds and a simulation study. The evaluation results demonstrate the effectiveness and efficiency of our scheme."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a new cluster-based on-demand routing protocol to support multihop communication in Bluetooth low energy ad hoc networks. The proposed scheme includes the topology configuration procedure, topology recovery scheme, and on-demand routing protocol. The topology configuration procedure consists of node discovery, piconet configuration, and scatternet formation in a randomly distributed environment. The proposed on-demand routing protocol is designed to minimize the number of route request messages by forwarding them to a master and relay nodes in each cluster during the route request procedure. The performance evaluation shows that our proposed scheme substantially reduces energy consumption, which is the most critical issue on energy constrained networks."
  },
  {
    "year": "2017",
    "abstract": "We investigate the problem of sketch generation for sketch-based image retrieval (SBIR). Solving this problem is important to obtain better retrieval results, because a powerful feature extraction algorithm is inefficient. Transforming photos from raw pixels into pseudo-sketches closes the gap between these two domains and plays a significant role in SBIR. This problem is relatively challenging because of: 1) the complexity of the image background and 2) the complexity of the resulting edge map. In this paper, we develop a system to generate pseudo-sketches from photos. Saliency detection is used to extract the major objects from a photo. Then, a Gabor filter is designed to further capture the “real-major” object. Finally, the Sobel operator is used to obtain the final pseudo-sketch. Experiments are conducted using the Flickr15k data set. The results show that the obtained pseudo-sketches are reasonable and that the SBIR process produces the state-of-the-art results in certain categories."
  },
  {
    "year": "2017",
    "abstract": "With the exponential growth of traffic demand, ultra-dense networks are proposed to increase the network capacity. However, the high-density access point (AP) deployment will increase the complexity of AP coordination, and AP cluster (APC) needs to be considered in practical implementations. Due to the dynamic changes in spatiotemporal distribution of users and service demand, we propose a social-energy-based cluster management (SECM) scheme in order to reduce APC update frequency. Specifically, in social domain, we propose a congeniality-based personalized recommendation (CPR) algorithm to predict users' incoming requests. We further propose a CPR-based AP cluster algorithm to solve the matching problem among users, APs, and content. In energy domain, we propose an inter-cluster energy cooperation scheme to avoid the shutting down of members in AP cluster and reduce the update of clusters. Numerical results demonstrate that our proposed scheme can achieve a gain of 77.8% in the APC management utility averagely, without loss of fairness compared with the other state-of-the-art schemes."
  },
  {
    "year": "2017",
    "abstract": "This paper was intended as an article of a practical solution. The settings of a ventilation system for a production line in a hard disk drive (HDD) factory were inappropriate leading to a condensation problem in a work area causing the finished products to be defective and unsalable. This paper describes an attempt to solve this problem and the outcome. Computational fluid dynamics (CFD) was used to simulate the airflow from a ventilation system in an HDD factory. The simulation results were validated with actual values measured with instruments readily available at the factory. The simulation results showed that the airflow patterns and temperature distribution of the air above and around some areas in the production line were not proper. The old temperature setting of the system for the air coming out of the inlet caused the temperature of the air above the said areas to be in the range of 13-20.5 °C, which was lower than the dew point temperature thus causing a condensation problem. From the results of the simulation, we recommended the factory to increase the inlet air temperature to be around 16.5-22 °C, so that the temperature of the air above and around the work areas would be higher than the dew point temperature and more uniform. The factory implemented our recommendation and found that it not only solved the problem satisfactorily but also saved the air-conditioning cost."
  },
  {
    "year": "2017",
    "abstract": "Body area networks, including smart sensors, are widely reshaping health applications in the new era of smart cities. To meet increasing security and privacy requirements, physiological signalbased biometric human identification is gaining tremendous attention. This paper focuses on two major impediments: the signal processing technique is usually both complicated and data-dependent and the feature engineering is time-consuming and can fit only specific datasets . To enable a data-independent and highly generalizable signal processing and feature learning process, a novel wavelet domain multiresolution convolutional neural network is proposed. Specifically, it allows for blindly selecting a physiological signal segment for identification purpose, avoiding the complicated signal fiducial characteristics extraction process. To enrich the data representation, the random chosen signal segment is then transformed to the wavelet domain, where multiresolution time-frequency representation is achieved. An auto-correlation operation is applied to the transformed data to remove the phase difference as the result of the blind segmentation operation. Afterward, a multiresolution 1-D-convolutional neural network (1-D-CNN) is introduced to automatically learn the intrinsic hierarchical features from the wavelet domain raw data without datadependent and heavy feature engineering, and perform the user identification task. The effectiveness of the proposed algorithm is thoroughly evaluated on eight electrocardiogram datasets with diverse behaviors, such as with or without severe heart diseases, and with different sensor placement methods. Our evaluation is much more extensive than the state-of-the-art works, and an average identification rate of 93.5% is achieved. The proposed multiresolution 1-D-CNN algorithm can effectively identify human subjects, even from randomly selected signal segments and without heavy feature engineering. This paper is expected to demonstrate the feasibili..."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an efficient implementation of multivariate empirical mode decomposition (MEMD) algorithm, a multivariate extension of EMD algorithm. Analogous to EMD, MEMD decomposes a multivariate signal into its intrinsic mode functions using joint rotational mode. The algorithm is computationally intensive because of its recursive nature and any increase in input data size results in anonlinear increase in its execution time. Therefore, it is extremely time-consuming to obtain a decomposition of signal, such as EEG into its intrinsic modes using MEMD. As the interest in applying MEMD algorithm in various domains is increasing, there is a need to develop an optimized implementation of the algorithm, since it requires repeated execution of the same operations and computationally extensive interpolations on each projected vector. This can be done using GPGPU, because it has the power to process similar function on different blocks of data. We have compared the optimized implementation of MEMD, using GPU, with the MATLAB implementation for hexa-variate and hexa-deca-variate data sets, and observed that the GPU-based optimized implementation results in approximately 6× ~ 16× performance improvements in terms of time consumption."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address the problem of energy-efficient power allocation in MIMO systems. In fact, the widely adopted water-filling power allocation does not ensure the maximization of the energy efficiency (EE). Since the EE maximization is a non-convex problem, numerical methods based on fractional programming were introduced to find the optimal power solutions. In this paper, we present a novel and simple power allocation scheme based on the explicit expressions of the optimal power. We also present a low-complexity algorithm that complements the proposed scheme for low circuit-power regime. Furthermore, we analyze power-constrained and rate-constrained systems and present the corresponding optimal power control. In the numerical results, we show that the presented analytical expressions are accurate and that the algorithm converges within two iterations. We also show that as the number of antennas increases, the system becomes more energy-efficient. Also, a saturation of the EE is observed at high-power budget and low minimal rate regimes."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal experimental design (OED) is a powerful method for identifying the best combination of factors, and considerably reduces the required number of experimental samples. Researchers have combined OED with evolutionary techniques, such as the genetic algorithm, particle swarm optimization, and artificial bee colony algorithm, resulting in significantly better performance. In this paper, we study the combination of OED and differential evolution (DE). We present a modification to the orthogonal design strategy, and propose a modified orthogonal differential evolution (MODE) technique. Two variants of MODE are developed, one which acts on the crossover operation and a second that operates on the selection stage. These enhance the DE aspect in different ways to improve the discovery of dimensional information during the evolution process. We first construct the basic MODE, which combines the orthogonal design strategy with the basic DE algorithm, and then employ a variant with a self-adaptive parameter strategy. The results of comparative experiments demonstrate the effectiveness of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Mobile ad hoc network (MANET) is a collection of wireless mobile nodes that dynamically form a temporary network without the reliance of any infrastructure or central administration. Energy consumption is considered as one of the major limitations in MANET, as the mobile nodes do not possess permanent power supply and have to rely on batteries, thus reducing network lifetime as batteries get exhausted very quickly as nodes move and change their positions rapidly across MANET. This paper highlights the energy consumption in MANET by applying the fitness function technique to optimize the energy consumption in ad hoc on demand multipath distance vector (AOMDV) routing protocol. The proposed protocol is called AOMDV with the fitness function (FF-AOMDV). The fitness function is used to find the optimal path from source node to destination node to reduce the energy consumption in multipath routing. The performance of the proposed FF-AOMDV protocol has been evaluated by using network simulator version 2, where the performance was compared with AOMDV and ad hoc on demand multipath routing with life maximization (AOMR-LM) protocols, the two most popular protocols proposed in this area. The comparison was evaluated based on energy consumption, throughput, packet delivery ratio, end-to-end delay, network lifetime and routing overhead ratio performance metrics, varying the node speed, packet size, and simulation time. The results clearly demonstrate that the proposed FF-AOMDV outperformed AOMDV and AOMR-LM under majority of the network performance metrics and parameters."
  },
  {
    "year": "2017",
    "abstract": "Cyber-physical systems (CPSs) are a new class of engineered systems based on interactions between cyber and physical components, by integrating three main components: communications, control, and computing. When these systems are brought to the nanoscale, some design and implementation issues arise. A high level of complexity is due to the use of biological components in a CPS, such as engineered cells, which may play the role of sensors, actuators, or even controllers. In this paper, we study the effectiveness of control solutions implemented through the usage of molecular communications in a biological nanoscale cyber-physical system, where a biological nanomachine plays the role of actuator, that releases drug molecules, and another acts as both sensor and controller. The goal of the proposal is to control the release rate, so that target cells can receive the desired amount of drug in a given time, by limiting potential side effects. Basically, we aim to limit congestion, which can arise when large amounts of molecules are released toward a target. To this aim, we propose a simple congestion detection scheme, and compare different rate control algorithms used to throttle the molecules release rate at the transmitter upon the reception of a feedback signal sent by the receiver. We validate the proposed techniques against delivery efficiency and delivery time of molecules by means of an extensive simulation campaign."
  },
  {
    "year": "2017",
    "abstract": "An accurate and robust altitude controller is critical for vertical takeoff and landing (VTOL) unmanned aerial vehicles (UAVs) in achieving quasi-stationary flight. Most UAV altitude control designs neglect the rotor dynamics. Therefore, they cannot be used for a tail-sitter UAV equipped with turbine engines because of the complicated engine dynamics with an apparent time delay. In this paper, we develop an integrated altitude controller that considers the engine dynamics. The new controller consists of a proportional-derivative (PD) control term and an acceleration feedback term. The stability region in the parameter space is analyzed and the controller is designed to achieve specific gain and phase margins. A UAV hover flight experiment is conducted and the results are presented to demonstrate the effectiveness of the proposed altitude controller."
  },
  {
    "year": "2017",
    "abstract": "Given the rapid increase in Internet streaming services to access multimedia content, to the detriment of traditional cable, satellite, and terrestrial, it is to be expected that this traffic will affect the performance of the Internet at several levels. One such level is the communication between autonomous systems that is primarily based on border gateway protocol (BGP). In order to understand this impact, a tool was developed to detect the problems that occur during a specific time period. This tool is able to identify and classify flapping events providing information about the networks potentially involved in the disruptions. The main focus of this paper is the analysis of the BGP updates registered during Super Bowl 2016 in order to understand how a large streaming event affects the Internet at the BGP level. Those results show that an increase in the number of updates happened during key times when a large number of concurrent viewers connected to the game. Many dampening and flapping events were observed accordingly. From those events, networks potentially affected were detected and categorized. The results of our study suggest that the Internet is not prepared to accommodate the potential streaming traffic generated during major events. This is of utmost importance for content providers and content delivery networks in designing their broadcast strategies which should take into consideration not only the scalability of their own servers but also the way in which data reaches the viewer."
  },
  {
    "year": "2017",
    "abstract": "Today, one of the main challenges of big data research is the processing of big time-series data. Moreover, time data analysis is of considerable importance, because previous trends are useful for predicting the future. Due to the considerable delay when the volume of the data increases, the presence of redundancy, and the innate lack of time-series structures, the traditional relational data model does not seem to be adequately able to analyze time data. Moreover, many traditional data structures do not support time operators, which results in an inefficient access to time data. Therefore, relational database management systems have difficulty in dealing with big data-it may require massively parallel software that runs on many servers. This has led us to implement Chronos Software, an in-memory background-based time database for key-value pairs; this software was implemented using C++ language. An independent design has been suggested through appropriately using temporal algorithms, parallelism algorithms, and methods of data storage in RAM. Our results indicate that the employment of RAM for storing the data and of the Timeline Index algorithm for getting access to the time background of the keys in Chronos translate into an increase of about 40%-90% in the efficiency as compared with other databases, such as MySQL and MongoDB."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a real-time monitoring system for switchgear contacts (switchgear contact monitoring system) with continuous thermal monitoring is presented instead of infrequent scanning with a handheld infrared (IR) camera or IR window. Attention is focused on mediumand low-voltage switchgear contacts due to the importance of their thermal behaviors in the power system. A binocular IR camera (BIRC), whose size is only 3 cm × 3 cm × 4 cm, is installed near switchgear contacts and collects both visible-light images and IR array data of switchgear contacts. The BIRC is powered by a remote Power over Ethernet switch connected to it using one cable. At the same time, all data transmitted from the BIRC to the remote-control unit are provided by the same cable. To detect localized thermal conditions or hotspots within switchgear contacts, the IR-fusion module fuses temperature array data and image data collected by the BIRC and produces an IR-fusion image. The system design and laboratory test results are presented."
  },
  {
    "year": "2017",
    "abstract": "For energy-efficient resource management, void node avoidance is one of the key objectives in the energy constrained underwater wireless sensor networks (UWSNs). In this paper, we propose two new routing protocols for the UWSN which is one of the end parts of a cloud. The first protocol is avoiding void node with adaptive hop-by-hop vector based forwarding (AVN-AHH-VBF), and the second is cooperation-based AVN-AHH-VBF (CoAVN-AHH-VBF). In both schemes, sensor nodes forward data packets in multihop fashion within a virtual pipeline. The nodes outside the pipeline do not forward data packets to avoid flooding in the network. At each hop, forwarding toward void region of the network is avoided by utilizing two hop information. Results of extensive simulations show that our proposed schemes significantly improve the network performance in terms of delivery ratio, energy expenditure and delay as compared with the selected existing scheme (AHH-VBF)."
  },
  {
    "year": "2017",
    "abstract": "Current blood glucose monitoring (BGM) techniques are invasive as they require a finger prick blood sample, a repetitively painful process that creates the risk of infection. BGM is essential to avoid complications arising due to abnormal blood glucose levels in diabetic patients. Laser light-based sensors have demonstrated a superior potential for BGM. Existing near-infrared (NIR)-based BGM techniques have shortcomings, such as the absorption of light in human tissue, higher signal-to-noise ratio, and lower accuracy, and these disadvantages have prevented NIR techniques from being employed for commercial BGM applications. A simple, compact, and cost-effective non-invasive device using visible red laser light of wavelength 650 nm for BGM (RL-BGM) is implemented in this paper. The RL-BGM monitoring device has three major technical advantages over NIR. Unlike NIR, red laser light has ~30 times better transmittance through human tissue. Furthermore, when compared with NIR, the refractive index of laser light is more sensitive to the variations in glucose level concentration resulting in faster response times ~7-10 s. Red laser light also demonstrates both higher linearity and accuracy for BGM. The designed RL-BGM device has been tested for both in vitro and in vivo cases and several experimental results have been generated to ensure the accuracy and precision of the proposed BGM sensor."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an adaptive global fast terminal sliding mode control method using fuzzy-neural-network (FNN) is proposed for a single-phase photovoltaic (PV) grid-connected transformerless system that is mainly composed of a boost chopper and a dc-ac inverter. A maximum power point tracking is accomplished in the boost part in order to extract the maximum power from the PV array. A global fast terminal sliding mode control strategy is proposed for an H-bridge inverter so that the tracking error between a grid reference voltage and the output voltage of the inverter can converge to zero in finite time. FNN is used to estimate the uncertainties of the system in real time since uncertainties in the system are difficult to obtain. The network weights are updated according to the adaptive law in real time to adapt to the variations of system uncertainties, enhancing the robustness of the system. Finally, a PV grid-connected system model is built in Simulink to verify the effectiveness of the proposed adaptive global fast terminal sliding mode control method."
  },
  {
    "year": "2017",
    "abstract": "Online shopping is becoming more and more common in our daily lives. Understanding users' interests and behavior is essential to adapt e-commerce Web sites to customers' requirements. The information about users' behavior is stored in the Web server logs. The analysis of such information has focused on applying data mining techniques, where a rather static characterization is used to model users' behavior, and the sequence of the actions performed by them is not usually considered. Therefore, incorporating a view of the process followed by users during a session can be of great interest to identify more complex behavioral patterns. To address this issue, this paper proposes a linear-temporal logic model checking approach for the analysis of structured e-commerce Web logs. By defining a common way of mapping log records according to the e-commerce structure, Web logs can be easily converted into event logs where the behavior of users is captured. Then, different predefined queries can be performed to identify different behavioral patterns that consider the different actions performed by a user during a session. Finally, the usefulness of the proposed approach has been studied by applying it to a real case study of a Spanish e-commerce Web site. The results have identified interesting findings that have made possible to propose some improvements in the Web site design with the aim of increasing its efficiency."
  },
  {
    "year": "2017",
    "abstract": "Aiming at the serious impact of the typical network attacks caused by the limited energy and the poor deployment environment of wireless sensor network (WSN) on data transmission, a trust sensing-based secure routing mechanism (TSSRM) with the lightweight characteristics and the ability to resist many common attacks simultaneously is proposed in this paper, at the same time the security route selection algorithm is also optimized by taking trust degree and QoS metrics into account. Performance analysis and simulation results show that TSSRM can improve the security and effectiveness of WSN."
  },
  {
    "year": "2017",
    "abstract": "Early prediction of job failures and specific disposal steps in advance could significantly improve the efficiency of resource utilization in large-scale data center. The existing machine learning-based prediction methods commonly adopt offline working pattern, which cannot be used for online prediction in practical operations, in which data arrive sequentially. To solve this problem, a new method based on online sequential extreme learning machine (OS-ELM) is proposed in this paper to predict online job termination status. With this method, real-time data are collected according to the sequence of job arriving, the job status could be predicted and the operation model is thus updated based on these data. The method with online incremental learning strategy has fast learning speed and good generalization. Comparative study using Google trace data shows that prediction accuracy of the proposed method is 93% with updating model in 0.01 s. Compared with some state-of-the-art methods, such, as support vector machine (SVM), ELM, and OS-SVM, the method developed in this paper has many advantages, such as less time-consuming in establishing and updating the model, higher prediction accuracy and precision, and better false negative performance."
  },
  {
    "year": "2017",
    "abstract": "Social networks have a large amount of data available, but often, people do not provide some of their personal data, such as age, gender, and other demographics. Although the sentiment analysis uses such data to develop useful applications in people's daily lives, there are still failures in this type of analysis, either by the restricted number of words contained in the word dictionaries or because they do not consider the most diverse parameters that can influence the sentiments in a sentence; thus, more reliable results can be obtained, if the users profile information and their writing characteristics are considered. This research suggests that one of the most relevant parameter contained in the user profile is the age group, showing that there are typical behaviors among users of the same age group, specifically, when these users write about the same topic. A detailed analysis with 7000 sentences was performed to determine which characteristics are relevant, such as, the use of punctuation, number of characters, media sharing, topics, among others; and which ones can be disregarded for the age groups classification. Different learning machine algorithms are tested for the classification of the teenager and adult age group, and the deep convolutional neural network had the best performance, reaching a precision of 0.95 in the validation tests. Furthermore, in order to validate the usefulness of the proposed model for classifying age groups, it is implemented into the enhanced sentiment metric (eSM). In the performance validation, subjective tests are performed and the eSM with the proposed model reached a root mean square error and a Pearson correlation coefficient of 0.25 and 0.94, respectively, outperforming the eSM metric, when the age group information is not available."
  },
  {
    "year": "2017",
    "abstract": "Fog computing is deemed as a highly virtualized paradigm that can enable computing at the Internet of Things devices, residing in the edge of the network, for the purpose of delivering services and applications more efficiently and effectively. Since fog computing originates from and is a non-trivial extension of cloud computing, it inherits many security and privacy challenges of cloud computing, causing the extensive concerns in the research community. To enable authentic and confidential communications among a group of fog nodes, in this paper, we propose an efficient key exchange protocol based on ciphertext-policy attribute-based encryption (CP-ABE) to establish secure communications among the participants. To achieve confidentiality, authentication, verifiability, and access control, we combine CP-ABE and digital signature techniques. We analyze the efficiency of our protocol in terms of security and performance. We also implement our protocol and compare it with the certificate-based scheme to illustrate its feasibility."
  },
  {
    "year": "2017",
    "abstract": "Ciphertext policy attribute-based encryption (CP-ABE) is a promising cryptographic technique for fine-grained access control of outsourced data in the cloud. However, some drawbacks of key management hinder the popularity of its application. One drawback in urgent need of solution is the key escrow problem. We indicate that front-end devices of clients like smart phones generally have limited privacy protection, so if private keys are entirely held by them, clients risk key exposure that is hardly noticed but inherently existed in previous research. Furthermore, enormous client decryption overhead limits the practical use of ABE. In this paper, we propose a collaborative key management protocol in CP-ABE. Our construction realizes distributed generation, issue and storage of private keys without adding any extra infrastructure. A fine-grained and immediate attribute revocation is provided for key update. The proposed collaborative mechanism effectively solves not only key escrow problem but also key exposure. Meanwhile, it helps markedly reduce client decryption overhead. A comparison with other representative CP-ABE schemes demonstrates that our scheme has somewhat better performance in terms of cloud-based outsourced data sharing on mobile devices. Finally, we provide proof of security for the proposed protocol."
  },
  {
    "year": "2017",
    "abstract": "The IEEE 802.22 standard regulates wireless regional area network (WRAN) operating at the very high frequency and ultrahigh frequency television white space (TVWS) bands. WRAN supports extensible authentication protocol (EAP)-based authentication schemes. However, due to its public key cryptography operations, a full EAP-based authentication scheme is time-consuming, which is unacceptable for the WRAN handover process. In this paper, an efficient EAP-based pre-authentication scheme for inter-WRAN handovers (EPW) in TVWS is proposed. By applying the proposed pre-authentication scheme, the customer premises equipment and the target secondary user base station can accomplish a seamless handover using symmetric key. Through logic derivation by Burrows, Abadi, and Needham logic and formal verification by automated validation of Internet security protocols and applications, we conclude that the proposed EPW scheme can obtain mutual authentication and maintain key secrecy with a high resistance to attack. Additionally, the performance of the EPW scheme has been investigated by simulation experiments. The results show that the EPW scheme provides a lower computation delay than that mandated by the security scheme regulation of the IEEE 802.22 standard."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the problem of fault detection and diagnosis in sensors considering erratic, drift, hard-over, spike, and stuck faults. The data set containing samples of the above mentioned fault signals was acquired as follows: normal data signals were obtained from a temperature-to-voltage converter by using an Arduino Uno microcontroller board and MATLAB. Then, faults were simulated in normal data to get 100 samples of each fault, in which one sample is composed of 1000 data elements. A support vector machine (SVM) was used for data classification in a one-versus-rest manner. The statistical time-domain features, extracted from a sample, were used as a single observation for training and testing SVM. The number of features varied from 5 to 10 to examine the effect on accuracy of SVM. Three different kernel functions used to train SVM include linear, polynomial, and radial-basis function kernels. The fault occurrence event in fault samples was chosen randomly in some cases to replicate a practical scenario in industrial systems. The results show that an increase in the number of features from 5 to 10 hardly increases the total accuracy of the classifier. However, using ten features gives the highest accuracy for fault classification in an SVM. An increase in the number of training samples from 40 to 60 caused an overfitting problem. The k-fold cross-validation technique was adopted to overcome this issue. The increase in number of data elements per sample to 2500 increases the efficiency of the classifier. However, an increase in the number of training samples to 400 reduces the capability of SVM to classify stuck fault. The receiver operating characteristics curve comparison shows the efficiency of SVM over a neural network."
  },
  {
    "year": "2017",
    "abstract": "Full electrification of large ports and intelligent energy networks compose a very promising solution, not only for limiting the in-port greenhouse gas emissions but also for the improvement of their efficiency and electric power system operation support. Large ports comprise a variety of flexible loads like refrigerated containers, electric vehicles, onshore electric power supply to ships at berth, and so on, while they usually have great potential for local energy generation from renewable energy resources, like offshore wind, tides, waves, and so on. Smart grids can be proved very efficient in increasing port power demand flexibility and controllability. The main goal of this paper is to propose an innovative decentralized demand response method that eventually turns a port comprising flexible loads and power generation from renewable energy sources to a prosumer Microgrid. The proposed method is applied to a realistic case study of a large port comprising a large number of flexible loads and one offshore wind park. The efficiency of the proposed method is evaluated by detailed simulations."
  },
  {
    "year": "2017",
    "abstract": "Classification is one of the most popular topics in remote sensing. Consider the problems that the remote sensing data are complicated and few labeled training samples limit the performance and efficiency in the classification of remote sensing image. For these problems, a huge number of methods were proposed in the last two decades. However, most of them do not yield good performance. In this paper, a remote sensing image classification algorithm based on the ensemble of extreme learning machine (ELM) neural network, namely, stacked autoencoder (SAE)-ELM, is proposed. First, due to improve the ensemble classification accuracy, we adopt feature segmentation and SAE in the sample data to create high diversity among the base classifiers. Furthermore, ELM neural network is chosen as a base classifier to improve the learning speed of the algorithm. Finally, to determine the final ensemble-based classifier, Q-statistics is adopted. The experiment compares the proposed algorithm with Bagging, Adaboost, Random Forest et al., which results show that the proposed algorithm not only gets high classification accuracy on low resolution, medium resolution, high resolution and hyperspectral remote sensing images, but also has strong stability and generalization on UCI data."
  },
  {
    "year": "2017",
    "abstract": "The emerging Tactile Internet (TI) will enable control-oriented networks for remotely accessing or manipulating objects or devices. One major challenge in this context is how to achieve ultra-low-delay communication between the local operator and the remote object/device to guarantee the stability of the global control loop and to maximize the user's quality-of-experience (QoE). Being one of the major human-in-the-loop applications of the TI, haptic teleoperation inherits its delay-sensitive nature and requires the orchestration of communication and control approaches. In this paper, we focus on the radio access protocol, and its impact on the latency of wireless communication. We propose a novel soft resource reservation mechanism for the uplink scheduling of mobile networks that can significantly reduce the latency compared with the current legacy scheme. By leveraging the characteristics of teleoperation data traffic, and reserving resources accordingly, the proposed soft reservation scheme maintains the spectral efficiency while the human operator's QoE is improved. The simulation results confirm the efficiency of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the recovery and demixing problem of signals that are sparse in some general dictionary. Involved applications include source separation, image inpainting, super-resolution, and restoration of signals corrupted by clipping, saturation, impulsive noise, or narrowband interference. We employ the ℓq-norm (0 ≤ q <; 1) for sparsity inducing and propose a constrained ℓq-minimization formulation for the recovery and demixing problem. This nonconvex formulation is approximately solved by two efficient first-order algorithms based on proximal coordinate descent and alternative direction method of multipliers (ADMM), respectively. The new algorithms are convergent in the nonconvex case under some mild conditions and scale well for high-dimensional problems. A convergence condition of the new ADMM algorithm has been derived. Furthermore, the extension of the two algorithms for multichannels joint recovery has been presented, which can further exploit the joint sparsity pattern among multichannel signals. Various numerical experiments showed that the new algorithms can achieve considerable performance gain over the ℓ1-regularized algorithms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we examine the impact of four voice over long term evolution adaptive multi-rate wideband codec mode-sets on coverage at pedestrian and vehicular speeds. Industry-standardized mean opinion scores were used as a metric for voice quality. Controlled laboratory experiments simulating pedestrian speeds indicated that there was an improvement in voice quality when mode-set eight was employed. At vehicular speeds, mode-set eight outperformed the other mode-sets for path losses less than 130 dB; however, all four mode-sets experienced a significant decline in voice quality when the path loss was greater than 130 dB. Based on the current implementations, there are no significant benefits to lowering the mode-sets or deploying dynamic codec rate adaptation."
  },
  {
    "year": "2017",
    "abstract": "With the development of the wearable brain-computer interface (BCI), a few-channel BCI system is necessary for its application to daily life. In this paper, we proposed a bimodal BCI system that uses only a few channels of electroencephalograph (EEG) and functional near-infrared spectroscopy (fNIRS) signals to obtain relatively high accuracy. We developed new approaches for signal acquisition and signal processing to improve the performance of this few-channel BCI system. At the signal acquisition stage, source analysis was applied for both EEG and fNIRS signals to select the optimal channels for bimodal signal collection. At the feature extraction stage, phase-space reconstruction was applied to the selected three-channel EEG signals to expand them into multichannel signals, thus allowing the use of the traditional effective common spatial pattern to extract EEG features. For the fNIRS signal, the Hurst exponents for the selected ten channels were calculated and composed of the fNIRS data feature. At the classification stage, EEG and fNIRS features were joined and classified with the support vector machine. The averaged classification accuracy of 12 participants was 81.2% for the bimodal EEG-fNIRS signals, which was significantly higher than that for either single modality."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a utilization technique for enhancing the capabilities of dynamic voltage restorers (DVRs). This paper aims to enhance the abilities of DVRs to maintain acceptable voltages and last longer during compensation. Both the magnitude and phase displacement angle of the synthesized DVR voltage are precisely adjusted to achieve lower power utilization. The real and reactive powers are calculated in real time in the tracking loop to achieve better conditions. This technique results in less energy being taken out of the dc-link capacitor, resulting in smaller size requirements. The results from both the simulation and experimental tests illustrate that the proposed technique clearly achieved superior performance. The DVR's active action period was considerably longer, with nearly five times the energy left in the dc-link capacitor for further compensation compared with the traditional technique. This technical merit demonstrates that DVRs could cover a wider range of voltage sags; the practicality of this idea for better utilization is better than that of existing installed DVRs."
  },
  {
    "year": "2017",
    "abstract": "The distribution-level electric network frequency (ENF) extracted from an electric power signal is a promising forensic tool for multimedia recording authentication. Local characteristics in ENF signals recorded in different locations act as environmental signatures, which can be potentially used as a fingerprint for location identification. In this paper, a reference database is established for distribution-level ENF using FNET/GridEye system. An ENF identification method that combines a wavelet-based signature extraction and feedforward artificial neural network-based machine learning is presented to identify the location of unsourced ENF signals without relying on the availability of concurrent signals. Experiments are performed to validate the effectiveness of the proposed method using ambient frequency measurements at multiple geographic scales. Identification accuracy is presented, and the factors that affect identification performance are discussed."
  },
  {
    "year": "2017",
    "abstract": "A real-time awareness of an individual's affective state is the goal of the affect-aware city. Being aware of different affective states can be useful to enhance a citizen's quality of life and their experiences. In this paper, we aim to provide new insight to the affect-aware city and analyze individual experiences in regards to basic human needs. We propose a theoretical based multi-layer framework for a psychological needs analysis that is guided by research in the field of motivational psychology. The framework's layers are constructed to identify the psychological needs, measure their satisfaction level, and assess the individual's surrounding environment in different aspects of life. We created a psychological needs corpus: a collection of Twitter posts annotated based on three universal needs proposed by the self-determination theory framework. Several techniques were employed to encourage high-quality annotations. We provide descriptive statistics of the annotated corpus. This corpus can be used in the development of automatic detection systems and predication models to detect individual needs and measure their satisfaction. It can also be used to better interpret and understand the individual's surrounding social contexts."
  },
  {
    "year": "2017",
    "abstract": "Solving problems with small sample sizes during training for feature extraction and the dimensionality reduction method will not produce high face recognition accuracy using the locality graph embedding (LGE) algorithm. Thus, we introduced a new algorithm named “multi-manifold locality graph embedding algorithm based on the maximum margin criterion” (MLGE/MMC) by combining the ideas of the maximum margin criterion (MMC) and multiple manifolds. First, each image is divided into multiple small images; this small image configuration constitutes a manifold and multiple images constitute multiple manifolds. Second, through maximizing the inter-class distance, while minimizing the intra-class distance to find the best class projection matrix, we build the multiple manifolds inter-class scatter matrix and the multiple manifolds intra-class scatter matrix, respectively. Finally, the objective function was constructed within the framework of the MMC to find the optimal solution by iteration and the experimental results demonstrate the effectiveness of the proposed algorithm using the ORL, Yale, and AR face image databases."
  },
  {
    "year": "2017",
    "abstract": "Despite the recent advances in manufacturing automation, the role of human involvement in manufacturing systems is still regarded as a key factor in maintaining higher adaptability and flexibility. In general, however, modeling of human operators in manufacturing system design still considers human as a physical resource represented in statistical terms. In this paper, we propose a human in the loop (HIL) approach to investigate the operator's choice complexity in a mixed model assembly line. The HIL simulation allows humans to become a core component of the simulation, therefore influencing the outcome in a way that is often impossible to reproduce via traditional simulation methods. At the initial stage, we identify the significant features affecting the choice complexity. The selected features are in turn used to build a regression model, in which human reaction time with regard to different degree of choice complexity serves as a response variable used to train and test the model. The proposed method, along with an illustrative case study, not only serves as a tool to quantitatively assess and predict the impact of choice complexity on operator's effectiveness, but also provides an insight into how complexity can be mitigated without affecting the overall manufacturing throughput."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses a partial spatial-differencing (PSD) approach for the direction of arrival estimation in a low-grazing angle (LGA) condition. By dividing the sample covariance matrix into several column subvectors, we first form the corresponding reconstructed subarray covariance matrices (RSCMs). We then calculate the spatial differencing matrix for the noise parts of RSCMs, while the non-noise parts are kept completely. That is, we build a PSD matrix. Compared with the existing spatial smoothing and full spatial-differencing methods, the PSD approach can use all the data information of the sample covariance matrix and also suppress the effect of additive white or colored noise more effectively. Simulation results show that our method provides a higher estimation accuracy and resolution than the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Ultra wideband communication is proposed as an alternative to increase the data rate for in-body to on-body communication compared with existing narrowband standards. However, up to now, it is unknown, which maximum data rates can be achieved in this environment. The channel capacity is a theoretic tool that allows quantifying this limit. In a frequency-dependent environment like the human body, it is necessary to know the frequency dependence of the communication channel to calculate the channel capacity. As there are no reproducible models available in literature that enable the calculation of the channel capacity, we propose a new channel modeling technique based on a plane wave propagating through a multi-layered dielectric. From this simplified model, the frequency-dependent path loss for various in- and on-body locations can be calculated analytically. Thus, the channel capacity can be determined. In addition, this approach offers the possibility to determine the optimum position of multiple receive antennas on the abdominal surface. Results show that a single receive antenna gives nearly no improvement compared to existing standards. However, if the number of antennas is increased to 5, the 10%-outage capacity can be improved by several orders of magnitude."
  },
  {
    "year": "2017",
    "abstract": "Educational data preprocessing from log files represents a time-consuming phase of the knowledge discovery process. It consists of data cleaning, user identification, session identification, and path completion phase. This paper attempts to identify phases, which are necessary in the case of preprocessing of educational data for further application of learning analytics methods. Since the sequential patterns analysis is considered suitable for estimating of discovered knowledge, this paper tries answering the question, which of these preprocessing phases has a significant impact on discovered knowledge in general, as well as in the meaning of quality and quantity of found sequence patterns. Therefore, several data preprocessing techniques for session identification and path completion were applied to prepare log files with different levels of data preprocessing. The results showed that the session identification technique using the reference length, calculated from the sitemap, had a significant impact on the quality of extracted sequence rules. The path completion technique had a significant impact only on the quantity of extracted sequence rules. The found results together with the results of the previous systematic research in educational data preprocessing can improve the automation of the educational data preprocessing phase as well as it can contribute to the development of learning analytics tools suitable for different groups of stakeholders engaged in the educational data mining research activities."
  },
  {
    "year": "2017",
    "abstract": "Heuristic search is an important part of modern dynamic symbolic execution (DSE) tools, as heuristic search can be used to effectively explore the large program input space. Searching task remains one of several research challenges due to the fact that the input space grows exponentially with the increase of program size, and different programs may have very different structures. The challenge is compounded in a cyber-physical system or cloud-based Internet of Things environment. In this paper, we propose a novel heuristic search algorithm, which analyzes the program execution history and uses the refined history information to inform the search. This paper is based on the observation that the branch and input history generated during dynamic symbolic execution can help memorize the explored input space, and infer the partial structure of the program. With a summarized branch history, the proposed heuristic search makes informed (and better) decisions about which input area to search next for better efficiency. To evaluate the search algorithm, we implement the core DSE engine, integrated with modules to perform execution history collection and analysis. To make our method practical, we incorporate taint analysis and constraint solving statistics to guide the search algorithm. Experimental results demonstrate that with the rich history information, the new search algorithm can explore the input space more effectively, thus resulting in detecting software defects faster."
  },
  {
    "year": "2017",
    "abstract": "Applications of Internet of Things underwater wireless sensor networks, such as imaging underwater life, environmental monitoring, and supervising geological processes on the ocean floor, demand a prolonged network lifetime. However, these networks face many challenges, such as high path loss, limited available bandwidth, limited battery power, and high attenuation. For a longer network lifetime, both balanced and efficient energy consumption are equally important. In this paper, we propose a new routing protocol, called balanced energy adaptive routing (BEAR), to prolong the lifetime of UWSNs. The proposed BEAR protocol operates in three phases: 1) initialization phase; 2) tree construction phase; and 3) data transmission phase. In the initialization phase, all nodes share information related to their residual energy level and location. In the tree construction phase, our proposed BEAR exploits the location information for: a) selecting neighbour nodes and b) choosing the facilitating and successor nodes based on the value of cost function. In order to balance the energy consumption among the successor and the facilitator nodes, BEAR chooses nodes with relatively higher residual energy than the average residual energy of the network. The results of our extensive simulations show that BEAR outperforms its counterpart protocols in terms of network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Major challenges anticipated in the future C4ISR (command, control, communications, computers, intelligence, surveillance, and reconnaissance) operations involve rapid mission planning/ re-planning in highly dynamic, asymmetric, unpredictable, and network-centric environments. Developing decision support for such complex mission environments requires automated processing, interpretation, and development of proactive decisions using large volumes of structured, unstructured, and semi-structured data, while simultaneously decreasing the time necessary to arrive at a decision. To overcome this data deluge, there is a need for mastering information dominance via acquisition, fusion, and transfer of the right data/information/knowledge from the right sources in the right mission context to the right decision-maker (DM) at the right time for the right purpose (6R). The fundamental challenge in achieving the 6R is to conceive a generic framework that encompasses the dynamics of relevant contextual elements, their interdependence and correlation to the current and evolving situation, while taking into account the cognitive status of the DM. In this paper, we propose a context-driven proactive decision support (PDS) framework that comprises: 1) adaptive model-based dynamic graph models (e.g., Dynamic Hierarchical Bayesian Networks) and the concomitant inference algorithms for context representation, inference, and forecasting, 2) information selection, valuation, and prioritization methods for context-driven operations, including uncertainty management approaches, and 3) application of PDS concepts for courses of action recommendations across representative maritime operations."
  },
  {
    "year": "2017",
    "abstract": "A pair of salient tradeoffs have driven the multiple-input multiple-output (MIMO) systems developments. More explicitly, the early era of MIMO developments was predominantly motivated by the multiplexing-diversity tradeoff between the Bell Laboratories layered space-time and space-time block coding. Later, the linear dispersion code concept was introduced to strike a flexible tradeoff. The more recent MIMO system designs were motivated by the performance-complexity tradeoff, where the spatial modulation and space-time shift keying concepts eliminate the problem of inter-antenna interference and perform well with the aid of low-complexity linear receivers without imposing a substantial performance loss on generic maximum-likelihood/max a posteriori -aided MIMO detection. Against the background of the MIMO design tradeoffs in both uncoded and coded MIMO systems, in this treatise, we offer a comprehensive survey of MIMO detectors ranging from hard decision to soft decision. The soft-decision MIMO detectors play a pivotal role in approaching to the full-performance potential promised by the MIMO capacity theorem. In the near-capacity system design, the soft-decision MIMO detection dominates the total complexity, because all the MIMO signal combinations have to be examined, when both the channel's output signal and the a priori log-likelihood ratios gleaned from the channel decoder are taken into account. Against this background, we provide reduced-complexity design guidelines, which are conceived for a wide-range of soft-decision MIMO detectors."
  },
  {
    "year": "2017",
    "abstract": "Driven by the development of cloud computing and mobile Internet, network-based applications have become diverse. Besides the usual immediate reservation (IR) applications, which need to be served immediately, advance reservation (AR) applications have been introduced to support initial-delay-tolerance services, such as grid computing, virtual machine backup, and so on. The provisioning mechanism of AR applications is different from that of IR applications, because AR requests don't require to be served immediately, and the network operator must decide the exact serving time in the AR service provisioning process. Based on the scheduling features of AR requests, this paper formulates a resource model and sets up a control framework for elastic optical networks to support AR services. We propose an optimization algorithm with three reprovisioning policies to dynamically reprovision the AR applications, which have already been scheduled. Both the proposed control framework and algorithm are developed on the basis of an open network operating system, which is an open-source software-defined networking controller. Also, the performance of the proposed algorithm is evaluated via software simulation. Demonstration results show the benefits of reprovisioning, and simulation results show that the reprovisioning optimization algorithm can improve the efficiency of network spectrum resource."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a multiple-input and multiple-output (MIMO) antenna system for deployment in the closed hinge slot region of notebook computers for long-term evolution (LTE)/wireless wide area network (WWAN)/wireless local area network (WLAN) applications. This antenna system was placed in the closed hinge slot region formed by the full metal cover, metal ground plate, and metal hinges. The MIMO antenna system, includes a main antenna (Ant 1), an auxiliary antenna (Ant 2), and an isolation element. The main and auxiliary antennas were integrated with the metal surrounding them and were used to excite several resonance modes of the closed hinge slot. Excellent antenna efficiency was achieved using the small antennas. Although Ant1 and Ant2 are only 25 mm × 5 mm in size, they could cover LTE/WWAN or WLAN operating bands by switching feed points in the same antenna pattern. The isolation element-a 10 mm × 6 mm metal sheet-was placed at the center of the closed hinge slot region, and enhanced isolation by more than 7 dB. The isolation levels exceeded 18 dB for LTE700/2300/2500 bands and 15 dB for 2.4/5.2/5.8 GHz WLAN bands."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the spectra of the adjacency matrix and Laplacian matrix for an artificial complex network model—the generalized random graph. We deduce explicit expressions for the first four asymptotic spectral moments of the adjacency matrix and the Laplacian matrix associated with a generalized random graph with independent and identically distributed vertex weights. An estimate for the upper bound of the spectral radius is obtained on the basis of the fourth asymptotic spectral moment of the adjacency matrix, as well as the Laplacian matrix. These expressions are applied to study the behavior of a viral infection in a generalized random graph. On the basis of our results, we can design generalized random graphs with good antivirus ability when facing an initial virus infection. Numerical simulations agree with our analytical predictions."
  },
  {
    "year": "2017",
    "abstract": "The existing social recommendation models mostly utilize various explicit user-generated information. Although there exist a few studies adopting the implicit relationship between users for social recommendation, however, these studies do not consider the deeper social relationship, nor simultaneously take into account two or more deeper relationships between users from different angles. To this end, we propose a new deeper membership and friendship awareness for social recommendation. Specifically, we first calculate the deeper membership similarity between users utilizing the improved Jaccard similarity coefficient and the deeper friendship similarity between users using the proposed two-hop random walk algorithm. Second, the deeper membership similarity and the deeper friendship similarity are combined in a unified way to form a comprehensive deeper social relation similarity. Third, we adopt the matrix factorization method incorporating the deeper membership and the deeper friendship between users as a regularization term for social recommendation, and the corresponding comprehensive deeper social relationship similarity is regarded as the regularization parameter. Experiments on two real-world datasets demonstrate the superiority of the proposed recommendation model."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a scalable and cooperative medium access control (MAC) protocol (SCMAC) is proposed to support the periodic beaconing over the control channel in vehicular ad hoc networks. The main concerned aspects in SCMAC are communication reliability and protocol scalability. The communication reliability is guaranteed by cooperative beaconing. When broadcasting a beacon, the node embeds the slot state information into the beacon so that surrounding nodes can determine the availability of each slot. Together with the contention window, collisions can be alleviated. The protocol scalability is achieved by the slot access method and the proactive slot reservation. On one hand, the slot access method reduces the average delay by using the smaller beaconing period as the node density is decreasing. On the other hand, the proactive slot reservation always keeps enough idle slots so that more nodes can quickly join the network. Correspondingly, the beaconing period will increase and all nodes can gain chances to broadcast beacons. The simulation results show that SCMAC can achieve the reliable and scalable periodic beaconing in vehicular environments."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a fast discrete Curvelet transform (FDCT)-based technique for multi-focus image fusion to address two problems: texture selection in FDCT domain and block effect in spatial-based fusion. First, we present a frequency-based model by performing FDCT on the input images. Considering the human visual system characteristics, a union of pulse coupled neural network and sum-modified-Laplacian algorithms are proposed to extract the detailed information of frequencies. Then, we construct a hybrid spatial-based model. Unlike other spatial-based methods, we combine the image difference and the detailed information extracted from input images to detect the focused region. Finally, to evaluate the robustness of proposed method, we design a completed evaluation process considering the misregistration, noise error, and conditional focus situations. Experimental results indicate that the proposed method improves the fusion performance and has less computational complexity compared with various exiting frequency-based and spatial-based fusion methods."
  },
  {
    "year": "2017",
    "abstract": "Recently, there has been a rapid growth of the online auctions in e-commerce platforms, in which small and/or medium-sized enterprises (SMEs) heavily depend on the advertising systems. In this paper, we design flexible mechanisms to reduce the competition of SMEs without affecting competitive large companies in order to maximize the profit of e-commerce platform and to keep the ecosystem healthy. A probabilistic pricing mechanism design approach is investigated for online auctions. Utilizing this approach, we introduce the notation of simple mechanisms as a tool for designing new mechanisms. Based on a simple and a classical, the proposed mechanism probabilistic mechanisms are designed and their properties are analyzed. Furthermore, we devise two mechanism design algorithms for different application scenarios. Experiments are presented to demonstrate the flexibility and the effectiveness of the proposed probabilistic mechanism design approach."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we analyze the problems produced by temporal variations of infrared face images when used in face recognition systems. The temporal variations present in thermal face images are mainly due to different environmental conditions, physiological changes of the subjects, and differences of the infrared detectors' responsivity at the time of the capture, which affect the performance of infrared face recognition systems. To perform this paper, we created two thermal face databases that include capture sessions with real and variable conditions. We also propose two criteria to quantify the temporal variations between data sets. The thermal face recognition systems have been developed using the following five methods: local binary pattern (LBP), Weber linear descriptor (WLD), Gabor jet descriptors, scale invariant feature transform, and speeded up robust features. The results indicate that the local matching-based methods (WLD and LBP) are mostly immune to temporal variations, which is noticeable when the face images have been acquired with a time lapse, while the rest of the methods are clearly affected and are not suitable for practical infrared face recognition."
  },
  {
    "year": "2017",
    "abstract": "Quaternion rotation is a powerful tool for rotating vectors in 3-D; as a result, it has been used in various engineering fields, such as navigations, robotics, and computer graphics. However, understanding it geometrically remains challenging, because it requires visualizing 4-D spaces, which makes exploiting its physical meaning intractable. In this paper, we provide a new geometric interpretation of quaternion multiplication using a movable 3-D space model, which is useful for describing quaternion algebra in a visual way. By interpreting the axis for the scalar part of quaternion as a 1-D translation axis of 3-D vector space, we visualize quaternion multiplication and describe it as a combined effect of translation, scaling, and rotation of a 3-D vector space. We then present how quaternion rotation formulas and the derivative of quaternions can be formulated and described under the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the secure transmission of wireless relaying systems with multidestinations and an eavesdropper (Eve) in Nakagami-m fading channels. To protect the confidential message from leaking to the Eve, an intentional interference is sent from a selected destination. We propose two jammer selection schemes under two typical communication scenarios: the channel state information (CSI) of the Eve is unknown, where ajammer is selected based on the CSI between the selected legitimate receiver and the other destination users and the CSI of the Eve is available, where a jammer is selected based on the CSI between the Eve and the other destination users. To assess the performance of the two proposed schemes, we first derive the exact closed-form expressions of intercept probability and outage probability to evaluate the security and the reliability of the system, respectively. In addition, to evaluate the security and reliability as a whole, we propose a new definition of the security-reliability tradeoff, which allows us to easily optimize the power allocation and improve the performance. Finally, simulation results are provided to verify the availability of the proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "Interference is one of the fundamental aspects that makes wireless communication challenging, which has attracted great research attention for decades. To solve this interference problem, many interference management (IM) techniques have been developed. Nevertheless, interference can also provide some benefits to wireless networks if it is properly utilized according to the latest research advances. Wireless signal can carry information as well as energy, and thus the redundant resource of interference can be exploited using energy harvesting (EH) to provide the power to support the operation of wireless nodes. In this paper, we provide a comprehensive survey on the research works of exploiting interference for wireless EH. Some fundamental aspects are first reviewed, including the receiver architecture, antenna dimension, network topology, and IM techniques, for wireless EH systems that exploit interference. Then, two IM techniques for wireless EH, beamforming optimization and interference alignment, are discussed in detail. In addition, several research issues are also presented, including the adversarial jamming signal and artificial noise for EH. Finally, some research challenges of exploiting interference for wireless EH are discussed."
  },
  {
    "year": "2017",
    "abstract": "The recognition accuracy of ligature-based Urdu language optical character recognition (OCR) systems highly depends on the accuracy of segmentation that converts Urdu text into lines and ligatures. In general, lines and ligatures-based Urdu language OCRs are more successful as compared to characters-based. This paper presents the techniques for segmenting Urdu Nastaleeq text images into lines and subsequently to ligatures. Classical horizontal projection-based segmentation method is augmented with a curved-line-split algorithm for successfully overcoming the problems, such as text line split position, overlapping, merged ligatures, and ligatures crossing line split positions. Ligature segmentation algorithm extracts connected components from text lines, categorizes them into primary and secondary classes, and allocates secondary components to the primary class by examining width, height, coordinates, overlapping, centroids, and baseline information. The proposed line segmentation algorithm is tested on 47 pages with 99.17% accuracy. The proposed ligature segmentation algorithm is mainly tested on a large Urdu-printed text images data set. The proposed algorithm segmented Urdu-printed text images data set to 189 000 ligatures from 10 063 text lines having 332 000 connected components. A total of about 142 000 secondary components have been successfully allocated to more than 189 000 primary ligatures with accuracy rate of 99.80%. Thus, both of the proposed segmentation algorithms outperform the existing algorithms employed for Urdu Nastaleeq text segmentation. Moreover, the proposed line segmentation algorithm is also tested on Arabic, for which it also extracted lines correctly."
  },
  {
    "year": "2017",
    "abstract": "This paper sets up a framework for designing a massive multiple-input multiple-output (MIMO) testbed by investigating hardware (HW) and system-level requirements, such as processing complexity, duplexing mode, and frame structure. Taking these into account, a generic system and processing partitioning is proposed, which allows flexible scaling and processing distribution onto a multitude of physically separated devices. Based on the given HW constraints such as maximum number of links and maximum throughput for peer-to-peer interconnections combined with processing capabilities, the framework allows to evaluate modular HW components. To verify our design approach, we present the Lund University Massive MIMO testbed, which constitutes the first reconfigurable real-time HW platform for prototyping massive MIMO. Utilizing up to 100 base station antennas and more than 50 field programmable gate array, up to 12 user equipment are served on the same time/frequency resource using an LTE-like orthogonal frequency division multiplexing time-division duplex-based transmission scheme. Proof-of-concept tests with this system show that massive MIMO can simultaneously serve a multitude of users in a static indoor and static outdoor environment utilizing the same time/frequency resource."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces a novel technique to enhance the gain of the basic monopole antenna by using broadband gradient refractive index (GRIN) metamaterial. The proposed GRIN is designed by using a parallel-line unit cell metamaterial with different refractive index. A seven GRIN lens is placed on the omnidirectional printed basic monopole antenna, perpendicularly. Due to the non-resonant and subwavelength properties of the parallel-line elements, the proposed GRIN metamaterial lens has a broad bandwidth property with low loss. The simulation and measurement results confirmed that the beam is more directive with narrow beam width. The measured reflection coefficient of the GRIN antenna is below -10 dB over the frequency bandwidth of 3.4-11 GHz. Due to GRIN lens, the peak gain of the basic monopole antenna is increased by 5.3 dB at 8.8 GHz."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel feature representation method by a new feature descriptor, named patterns of oriented motion flow (POMF) from the optical flow information, to recognize the proper facial expression from the facial video. The POMF computes different directional motion information and encodes the directional flow information with enhanced local texture micro patterns. As it captures the spatial temporal changes of facial movements through optical flow and enables us to observe both local and global structures, it shows its robustness in recognizing facial information. Finally, the POMF histogram is used to train the expression model through the hidden Markov model (HMM). To train through the HMM, the objective sequences are produced by the generation of a codebook using the K-means clustering technique. The performance of the proposed method has been evaluated over the RGB and depth camera-based video. Experimental results demonstrate that the proposed POMF descriptor is more robust in extracting facial information and provides a higher classification rate than other existing promising methods."
  },
  {
    "year": "2017",
    "abstract": "Conventional error detection schemes, such as the repetition code, parity bit, and Hamming code, have been used to detect bit errors in data. These conventional schemes require the insertion of additional bits to detect bit errors, but the code rate decreases in proportion to the number of additional bits. In order to avoid this problem, in this paper, we introduce three special bit patterns in Lempel-Ziv-Storer-Szymanski (LZSS) compressed data. In addition, based on the three bit patterns, we propose a novel error detection algorithm for LZSS compressed data, which does not need to use additional bits to detect bit errors. In the simulation, it is demonstrated that the compression ratio and running time of the proposed algorithm are better than those of the conventional schemes, such as repetition code, parity bit, and Hamming code. In addition, it is shown that when more than/equal to seven bit errors occur, the proposed algorithm nearly always detects the presence of errors in the LZSS compressed data."
  },
  {
    "year": "2017",
    "abstract": "Fog computing is an architectural style in which network components between devices and the cloud execute application-specific logic. We present the first review on fog computing within healthcare informatics, and explore, classify, and discuss different application use cases presented in the literature. For that, we categorize applications into use case classes and list an inventory of application-specific tasks that can be handled by fog computing. We discuss on which level of the network such fog computing tasks can be executed, and provide tradeoffs with respect to requirements relevant to healthcare. Our review indicates that: 1) there is a significant number of computing tasks in healthcare that require or can benefit from fog computing principles; 2) processing on higher network tiers is required due to constraints in wireless devices and the need to aggregate data; and 3) privacy concerns and dependability prevent computation tasks to be completely moved to the cloud. These findings substantiate the need for a coherent approach toward fog computing in healthcare, for which we present a list of recommended research and development actions."
  },
  {
    "year": "2017",
    "abstract": "Fractional calculus is finding increased usage in the modeling and control of nonlinear systems with the enhanced robustness. However, from the implementation perspectives, the simultaneous modeling of the systems and the design of controllers with fractional-order operators can bring additional advantages. In this paper, a fractional order model of a nonlinear system along with its controller design and its implementation on a field programmable gate array (FPGA) is undertaken as a case study. Overall, three variants of the controllers are designed, including classical sliding mode controller, fractional controller for an integer model of the plant, and a fractional controller for a fractional model of the plant (FCFP). A high-level synthesis approach is used to map all the variants of the controllers on FPGA. The integro-differential fractional operators are realized with infinite impulse response filters architecturally implemented as cascaded second-order sections to withstand quantization effects introduced by fixed-point computations necessary for FPGA implementations. The experimental results demonstrate that the fractional order sliding mode controller-based on fractional order plant (FCFP) exhibits reduced dynamics in sense of fractional integration and differentials. It is further verified that the FCFP is as robust as the classical sliding mode with comparable performance and computational resources."
  },
  {
    "year": "2017",
    "abstract": "Owing to the signal structure difference between the filter bank multicarrier with offset quadrature amplitude modulation (FBMC/OQAM) and the orthogonal frequency-division multiplexing (OFDM) systems, the existing technologies to reduce the peak-to-average power ratio (PAPR) for OFDM systems are not suitable for the FBMC/OQAM systems. This paper considers the problem of PAPR in the FBMC/OQAM systems, and to reduce the PAPR of the FBMC/OQAM signal, we propose an improved joint optimization scheme combined with the linear (i.e., partial transmit sequence (PTS)) and nonlinear (i.e., clipping and filtering (CF)) methods, named improved bilayer partial transmit sequence and iterative clipping and filtering (IBPTS-ICF) scheme. The main idea of this joint optimization scheme is clipping and filtering the processed FBMC/OQAM signal, whose probability of the peak value has been reduced by the IBPTS technique. Meanwhile, aided by the knowledge of convex optimization, the IBPTS-ICF joint optimization scheme can effectively reduce the signal distortion. The excellent PAPR reduction performance of the proposed scheme has been confirmed in our simulations."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel method to identify the presence of malaria parasites in human peripheral blood smear images using a deep belief network (DBN). This paper introduces a trained model based on a DBN to classify 4100 peripheral blood smear images into the parasite or non-parasite class. The proposed DBN is pre-trained by stacking restricted Boltzmann machines using the contrastive divergence method for pre-training. To train the DBN, we extract features from the images and initialize the visible variables of the DBN. A concatenated feature of color and texture is used as a feature vector in this paper. Finally, the DBN is discriminatively fine-tuned using a backpropagation algorithm that computes the probability of class labels. The optimum size of the DBN architecture used in this paper is 484-600-600-600-600-2, in which the visible layer has 484 nodes and the output layer has two nodes with four hidden layers containing 600 hidden nodes in every layer. The proposed method has performed significantly better than the other state-of-the-art methods with an F-score of 89.66%, a sensitivity of 97.60%, and specificity of 95.92%. This paper is the first application of a DBN for malaria parasite detection in human peripheral blood smear images."
  },
  {
    "year": "2017",
    "abstract": "Telemedicine provides a transformative practice for access to and delivery of timely and high-quality healthcare in resource-poor settings. In a typical scenario of telesurgery, surgical tasks are performed with one surgeon situated at the patient's side and one expert surgeon from a remote site. In order to make telesurgery practice realistic and secure, reliable transmission of medical videos over large distances is essential. However, telesurgery videos that are communicated remotely in real time are vulnerable to distortions in signals due to data compression and transmission. Depending on the system and its applications, visual content received by the surgeons differs in perceived quality, which may incur implications for the performance of telesurgery tasks. To rigorously study the assessment of the quality of telesurgery videos, we performed both qualitative and quantitative research, consisting of semi-structured interviews and video quality scoring with human subjects. Statistical analyses are conducted and results show that compression artifacts and transmission errors significantly affect the perceived quality; and the effects tend to depend on the specific surgical procedure, visual content, frame rate, and the degree of distortion. The findings of the study are readily applicable to improving telesurgery systems."
  },
  {
    "year": "2017",
    "abstract": "Lightweight virtualization technologies have revolutionized the world of software development by introducing flexibility and innovation to this domain. Although the benefits introduced by these emerging solutions have been widely acknowledged in cloud computing, recent advances have led to the spread of such technologies in different contexts. As an example, the Internet of Things (IoT) and mobile edge computing benefit from container virtualization by exploiting the possibility of using these technologies not only in data centers but also on devices, which are characterized by fewer computational resources, such as single-board computers. This has led to a growing trend to more efficiently redesign the critical components of IoT/edge scenarios (e.g., gateways) to enable the concept of device virtualization. The possibility for efficiently deploying virtualized instances on single-board computers has already been addressed in recent studies; however, these studies considered only a limited number of devices and omitted important performance metrics from their empirical assessments. This paper seeks to fill this gap and to provide insights for future deployments through a comprehensive performance evaluation that aims to show the strengths and weaknesses of several low-power devices when handling container-virtualized instances."
  },
  {
    "year": "2017",
    "abstract": "Recently, the use of intelligent technologies in clinical decision making in the telehealth environment has begun to play a vital role in improving the quality of patients' lives and helping reduce the costs and workload involved in their daily healthcare. In this paper, an effective medical recommendation system that uses a fast Fourier transformation-coupled machine learning ensemble model is proposed for short-term disease risk prediction to provide chronic heart disease patients with appropriate recommendations about the need to take a medical test or not on the coming day based on analysing their medical data. The input sequence of sliding windows based on the patient's time series data are decomposed by using the fast Fourier transformation in order to extract the frequency information. A bagging-based ensemble model is utilized to predict the patient's condition one day in advance for producing the final recommendation. A combination of three classifiers-artificial neural network, least squares-support vector machine, and naive bayes-are used to construct an ensemble framework. A real-life time series telehealth data collected from chronic heart disease patients are utilized for experimental evaluation. The experimental results show that the proposed system yields a very good recommendation accuracy and offers an effective way to reduce the risk of incorrect recommendations as well as reduce the workload for heart disease patients in conducting body tests every day. The results conclusively ascertain that the proposed system is a promising tool for analyzing time series medical data and providing accurate and reliable recommendations to patients suffering from chronic heart diseases."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a broadband 60-GHz millimeter-wave 4 x 1 microstrip patch antenna array using the gap-coupled technique is presented and analyzed. In order to meet the challenging requirement of reduced size related to this kind of technique, and facilitate the integration with other integrated passive or active devices, the proposed antenna array has been designed on a thin ceramic substrate (εr= 9.9 and h = 127 μm), using an miniature hybrid microwave integrated circuits (MHMIC) fabrication process. The proposed structure is based on a modified shape of a gap-coupled patch element with curved radiating edges. For further analysis, the performances of the latter in terms of impedance bandwidth, gain, and radiation efficiency were investigated and compared with a conventional structure of a rectangular gap-coupled patch antenna. The obtained results clearly show that the proposed gap-coupled array structure provides an improved bandwidth (7%) and an enhanced gain (10.7 dB), while maintaining a reduced size (5.2 mm x 9.5 mm). All these benefits make it an attractive candidate for the future integrated millimeter-wave RF front-end circuits; it can, however, be connected directly to various MHMIC passive circuits, or active devices through using the wire bonding technology, on a standard thin-film alumina substrate."
  },
  {
    "year": "2017",
    "abstract": "A novel millimeter-wave (mm-wave) 90° phase-compensated hybrid coupler using the ridge-gap waveguide (RGW) technology is studied and developed. The coupler is low-loss at mm-wave frequency bands, whereas using conventional transmission lines, such as microstrip or substrate integrated waveguides, yields relatively a high amount of insertion loss. The proposed coupler is designed using large coupling apertures, which with their phase variation over the apertures can compensate for the progressive phase of the coupler and achieve a low output-phase error. The ridge-gap 3-db 90° hybrid coupler is suitable for designing mm-wave beamforming networks, such as the Butler matrix beamformer, where the cross-over transmission lines present a difficulty in designing such networks. In this paper, the dispersion diagram of the RGW is extracted, and a multicoupling aperture technique is formulated for designing the coupler. The coupler is fabricated and measured. The simulated and measured results show a good agreement."
  },
  {
    "year": "2017",
    "abstract": "The mutual coupling between two antennas within a human body model is studied. Our multilayer cylindrical body model includes highly lossy body tissues under which a biocompatible metal implant is inserted. This cylindrical bio-metal implant serves as the common ground plane for the conformal antennas. The mutual coupling between two such conformal microstrip antennas is studied and quantified for different spacing between them. Three methods are proposed to reduce mutual coupling between the two antennas. Each of them are investigated in details and their effectiveness is compared."
  },
  {
    "year": "2017",
    "abstract": "Augmented reality smart glasses (ARSG) are increasingly popular and have been identified as a vital technology supporting shop-floor operators in the smart factories of the future. By improving our knowledge of how to efficiently evaluate and select the ARSG for the shop-floor context, this paper aims to facilitate and accelerate the adoption of the ARSG by the manufacturing industry. The market for ARSG has exploded in recent years, and the large variety of products to select from makes it not only difficult but also time consuming to identify the best alternative. To address this problem, this paper presents an efficient step-by-step process for evaluating the ARSG, including concrete guidelines as to what parameters to consider and their recommended minimum values. Using the suggested evaluation process, manufacturing companies can quickly make optimal decisions about what products to implement on their shop floors. This paper demonstrates the evaluation process in practice, presenting a comprehensive review of currently available products along with a recommended best buy. This paper also identifies and discusses topics meriting research attention to ensure that the ARSG are successfully implemented on the industrial shop floor."
  },
  {
    "year": "2017",
    "abstract": "We investigate the uplink (UL) performance of multicell massive MIMO (maMIMO) communication systems in frequency-selective fading channels, when the channel estimates are corrupted by pilot contamination, and the receiver employs maximum-ratio combining (MRC). Specifically, two fundamental schemes (receivers/waveforms) are considered: the time-reversal MRC (TRMRC) under single-carrier, and the conventional frequency-domain MRC (FDMRC) for orthogonal frequency-division multiplexing. We first derive approximate analytical expressions for the UL signal-to-interference-plus-noise ratio (SINR) performance of maMIMO systems, deploying both TRMRC and FDMRC. Then, lower bounds for the achievable rates of both systems are presented, and the derived expressions are validated by means of Monte–Carlo simulations. The performance of the investigated systems are compared regarding the variation of several parameters, such as the number of base station (BS) antennasM, number of users for each cellK, UL transmit powerρu, and the number of taps of the time-dispersive channelL. Our results demonstrate that the attained SINR performance of both schemes are very similar, but, in terms of achievable rates, TRMRC in general outperforms FDMRC by not requiring cyclic prefix transmission. On the other hand, our computational complexity analysis demonstrates that the TRMRC scheme demands somewhat higher processing resources (O(LMK)) than FDMRC (O(MK)). Thus, we propose a reduced complexity implementation for the TRMRC receiver, by employing the fast convolution with overlap-and-add technique, which is able to achieve the same result of TRMRC with a complexity ofO(log2(2L)MK). For a practical maMIMO setup, the complexity reduction is about 50%. Finally, based on the derived expressions, we propose an iterative way to obtain the number of users that is able to maximize the sum rate of the cell, and investigate its be..."
  },
  {
    "year": "2017",
    "abstract": "The increase in the availability of multimode devices for ubiquitous network access and the need for larger bandwidth have created a thrust for the utilization of simultaneous network connections. Unfortunately, the standard transport layer protocols such as the transmission control protocol and user datagram protocol have structural constraints. As a result, an Internet application can use only one interface at a time. The stream control transmission protocol (SCTP) provides support for concurrent multipath transfer (SCTP-CMT). In this paper, we present the mathematical modeling of simultaneous multipath transmission (SMT) schemes using the deterministic time Markov chain (DTMC) model. In this DTMC model, receiver buffer size is used for the first time to estimate the sending data rate. The DTMC model of SMT schemes are compared with the SCTP-CMT using probability-based packet dropped scenarios. DTMC modeling is used to mathematically verify simulation results of SMT Schemes i.e., modified fast retransmit (SMT-MFR) and adaptive modified fast retransmit (SMT-AMFR). The analytical model results revealed that SMT-MFR outperformed SCTP-CMT by 8.54% gain in average throughput. SMT-AMFR outperformed the SCTP-CMT and SMT-MFR by 19.65% and 11.15% gain in average throughput, respectively."
  },
  {
    "year": "2017",
    "abstract": "Cryptographic hash functions have become the basis of modern network computing for identity authorization and secure computing; protocol consistency of cryptographic hash functions is one of the most important properties that affect the security and correctness of cryptographic implementations, and protocol consistency should be well proven before being applied in practice. Software verification has seen substantial application in safety-critical areas and has shown the ability to deliver better quality assurance for modern software; thus, applying software verification to a protocol consistency proof for cryptographic hash functions is a reasonable approach to prove their correctness. Verification of protocol consistency of cryptographic hash functions includes modeling of the cryptographic protocol and program analysis of the cryptographic implementation; these require a dedicated cryptographic implementation model that preserves the semantics of the code, efficient analysis of cryptographic operations on arrays and bits, and the ability to verify large-scale implementations. In this paper, we propose a fully automatic software verification framework, VeriHash, that brings software verification to protocol consistency proofs for cryptographic hash function implementations. It solves the above challenges by introducing a novel cryptographic model design for modeling the semantics of cryptographic hash function implementations, extended array theories for analysis of operations, and compositional verification for scalability. We evaluated our verification framework on two SHA-3 cryptographic hash function implementations: the winner of the NIST SHA-3 competition, Keccack; and an open-source hash program, RHash. We successfully verified the core parts of the two implementations and reproduced a bug in the published edition of RHash."
  },
  {
    "year": "2017",
    "abstract": "In order to disclose possible links and implications pertaining to aircraft performance, flight safety, and human factors in the aviation system, an optimal controller, a robust controller, and an adaptive decision maker were devised and organized within the pattern-oriented framework of human strategy modeling, to provide adaptive decision and robust control with dynamic input tactics and parallel precedence for better phase-and-amplitude responses, as invoked and measured by the human-like characteristics of hoping for the best, being prepared for the worst, and ensuring for the average. Our human strategy model was applied for a flight mission consisting of the final approach and the landing flare of a large commercial aircraft on our fast-time computation platform. The experiment results demonstrated that the synthesized intelligent behavior for the mission tasks met the expectations of these human-like characteristics, which suggested that the human strategy model could play a better role in advancing the computational analysis of human-machine interaction."
  },
  {
    "year": "2017",
    "abstract": "We consider a cluster-based collaborative spectrum sensing (CSS) scheme in energy harvesting cognitive wireless communication network (EH-CWCN), where cognitive nodes (CNs) are clustered based on their received power levels for enhancing sensing performance. In CSS scheme, time resource is limited and shared by energy harvesting, spectrum sensing, and data transmission. The purpose of this paper is to maximize the average throughput of EH-CWCN by identifying the optimal parameter set, including the durations of energy harvesting and spectrum sensing, local detection threshold, and the number of CNs. Moreover, it is hard to confirm the optimal local detection threshold at CNs with different received power levels. By constructing a fictitious cognitive node (FCN), which is assumed to have the same sensing performance as the sink node, the process for finding the optimal local detection threshold can be converted into the process for searching the optimal received signal-to-noise ratio of the FCN. Then, we formulate the general optimization problem under the collision constraint and energy constraint. Then, the existence and uniqueness of time fractions for energy harvesting and spectrum sensing are proved in this paper. The optimal parameter set is achieved by using the bisection method and a simplified linear search method. Finally, the theoretical analysis and the impact of the optimized parameters on the system performance are verified and shown through numerical simulations."
  },
  {
    "year": "2017",
    "abstract": "We design and numerically analyze a coherent computational imaging system that utilizes a sparse detector array of planar, frequency-diverse, metasurface antennas designed to operate over the W-band frequency range (75-110 GHz). Each of the metasurface antennas consists of a parallel plate waveguide, into which a center coaxial feed is inserted into the lower plate, launching a cylindrical guided wave. A dense array of metamaterial resonators patterned into the upper plate couples energy from the waveguide to free space radiative modes. The resonance frequency of each element, determined by its specific geometry, can be positioned anywhere within the W-band. The geometry of each element is chosen to produce a resonance frequency selected randomly from the W-band. Since a random subset of elements is resonant at any given frequency, the metasurface antenna forms a sequence of spatially diverse radiation patterns as a function of the excitation frequency. We analyze the metasurface aperture as an imaging system, optimizing key parameters relevant to image quality and resolution, including: aperture size; density and quality factor of the metamaterial resonators; number of detectors and their spatial distribution; bandwidth; and the number of frequency samples. A point-spread function analysis is used to compare the metasurface imager with traditional synthetic aperture radar. The singular value spectrum corresponding to the system transfer function and the mean-square-error associated with reconstructed images are both metrics used to characterize the system performance."
  },
  {
    "year": "2017",
    "abstract": "Multiple-input multiple-output (MIMO) radar equipped with a frequency diverse array (FDA) can produce a range-dependent beampattern and increase the degrees-of-freedom of the antenna array. In this paper, a new method of designing the MIMO radar beampattern with sparse frequency waveforms is proposed for the FDA, which randomly samples multiple distance points such that the MIMO radar beampattern with the both sparse frequency spectrum and constant modulus constraints are realized by the proposed beampattern design framework. The main steps are as follows. We first obtain the covariance matrix of the transmitted signal by a given ideal beampattern, and formulate the problem of designing the realizable beampattern as a nonconvex optimization problem, which includes the constraints of the both constant modulus of transmitted signals and sparse frequency spectrum. Then, a cyclic optimization algorithm is proposed, which guarantees the monotonic decrease of the objective function as the algorithm proceeds. The simulation results illustrate that the proposed method can achieve smaller errors than the traditional method, which does not consider the frequency diversity."
  },
  {
    "year": "2017",
    "abstract": "Hexagonal boron nitride intercalated multilayer grapheme (hBN-IMLG) promises one of the potential materials for high performance tunable passive components in terahertz (THz) band, due to its good electrical properties and impressive tunability with electrostatic biasing. In this paper, the high-frequency characteristics of the hBN-IMLG-based structure and tunable THz resonator are systematically investigated with the multiconductor transmission line (MTL) model. The MTL model is employed to calculate the resonant frequency, unloaded Q-factor and to investigate the tunable characteristics of the THz resonator. Simulated results indicate that by applying a biasing voltage of 0.8 V, the THz resonator based on the experimentally achievable hBN-IMLG parameters can provide a tuning ratio up to 4.74% with the Q-factor larger than 20. By properly selecting the geometry of resonator and the electrical parameters of graphene, a large tuning ratio up to 21% can be realized. There is a tradeoff between the Q-factor and the tuning ratio."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the optimal energy beamforming and time assignment in radio frequency (RF) energy harvesting (EH) wireless powered sensor networks for smart cities, where sensor nodes (SNs) first harvest energy from a sink node, and then transmit their collected data to the sink node via time-division-multiple-access (TDMA) manner by using the harvested energy. In order to achieve green system design, we formulate a problem to minimize the energy requirement of the sink node to support transmission between the sink node and the SNs under data amount constraint and EH constraint. For practical design, the energy consumed by circuit and information processing is also considered. Since the problem is non-convex, we use semidefinite relaxation (SDR) method to relax it into a convex optimization problem and then solve it efficiently. We theoretically prove that when the number of SNs are not greater than two, the relaxed problem guarantees rank-one constraint and when the number of SNs exceeds two, our obtained results are very close to the optimal ones. Simulation results show that when the data amount is relatively small, the energy consumed by circuit and information processing affects the system performance greatly, but for a relatively large data amount, the energy requirement of the sink node on its own signal processing is affected very limited and the system energy requirement is dominated by the transmit power consumption at the SNs. Furthermore, we also discuss the effects of the other parameters on the system performance, which provide some useful insights in future smart city planning."
  },
  {
    "year": "2017",
    "abstract": "The rapid development of high-speed railways (HSRs) all over the world is drawing much more attention on high-mobility wireless communication. For the wireless links that connect the passengers on the train to the cellular network, it is very essential to employ an appropriate power allocation strategy to guarantee the reliability and efficiency of information transmission. Therefore, this paper concentrates on evaluating the transmission performance of wireless links in the HSRs and attempting to derive an optimal power allocation strategy of this scenario. Considering the fact that the information transmitted between the train and the base station usually has diverse quality-of-service (QoS) requirements for various services, a QoS-based achievable rate region is utilized to characterize the transmission performance in this paper to instead of traditional single throughput. Based on it, a QoS-distinguished power allocation algorithm is derived to achieve the largest achievable rate region. It is proved that the traditional water-filling algorithm and the channel inverse algorithm can be regarded as two specific cases of this new algorithm. Besides, the robust performance of the proposed strategy is also discussed in detail under a non-uniform motion scenario, and its relative performance loss is evaluated in terms of energy consumption. Finally, we present a typical implementation example in a Rice fading environment when the data rate requirements are prior known."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel strategy for designing passively adaptive, statically stable walking robots with full body mobility that are exactly constrained and non-redundantly actuated during stance. In general, fully mobile legged robots include a large number of actuated joints, giving them a wide range of controllable foot placements but resulting in overconstraint during stance, requiring kinematic redundancy and redundant control for effective locomotion. The proposed design strategy allows for the elimination of actuation redundancy, thus greatly reducing the weight and complexity of the legged robots obtained and allowing for simpler control schemes. Moreover, the underconstrained nature of the resulting robots during swing allows for passive adaptability to rough terrain without large contact forces. The strategy uses kinematic mobility analysis tools to synthesize leg topologies, underactuated robotics design approaches to effectively distribute actuation constraints, and elastic elements to influence nominal leg behavior. Several examples of legged robot designs using the suggested approach are thoroughly discussed and a proof-of-concept of a non-redundant walking robot is presented."
  },
  {
    "year": "2017",
    "abstract": "There have been a lot of studies on the text input system using the image-based hand gesture recognition. However, hand gesture languages such as sign languages, finger alphabets, and aerial handwriting treated in the previous works have some problems to be commonly used. The aerial handwriting requires much time for writing and recognition. The sign languages and finger alphabets demand quite a knowledge and practice for using it, which results in restricting the number of their users. As a solution to the problems, this paper proposes a new character input system based on hand tapping gestures for Japanese hiragana and English characters that can be used to facilitate human-computer interaction. The hand tapping gestures are motions for tapping keys on aerial virtual keypads by hands, which can be effectively used as a hand alphabet by anyone, including hearing impaired individuals. For hiragana characters, the hand used for tapping a key and the number of stretched fingers of the hand decide the consonant part of characters, and thereby the aerial virtual keypad. The character to be entered is determined by tapping the key on the virtual keypad corresponding to the desired vowel. Because we adopt a key layout similar to the Japanese and English flick keyboard of smart phones, our hand tapping gestures can be easily used by anyone with only a brief description. The users can effectively interact with computers by using our non-touch input system where only the Kinect sensor is used without any keyboard, mouse or body-worn device. We expect that our character input system will open a new channel for human-computer interaction."
  },
  {
    "year": "2017",
    "abstract": "Mixed traffic is a common phenomenon in developing countries such as China. Understanding bicycles' moving behavior when it conflicts with motor vehicles/bicycles/pedestrians at unsignalized intersections is important for developing mixed traffic flow simulation models. Observations and analysis of bicycle movements when they conflict with those of vehicles/pedestrians at mixed traffic unsignalized intersections were made in our study. Field data from actual bicycle movements were captured from video data. We then proposed a plausible cyclist conflict avoidance movement model in mixed traffic flow situations based on fuzzy logic and the discrete choice method. Field data were used for model calibration and validation, and the results were promising."
  },
  {
    "year": "2017",
    "abstract": "Amplify-and-forward (AF) relaying is an efficient way to extend radio range and improve link reliability with a low implementation cost. While the research on the AF relaying in a single-antenna scenario has matured, its application to broadband radio transmission utilizing multiple-input multiple-output techniques still needs more effort to overcome several practical challenges, such as large overheads for channel estimation and vulnerability to the channel estimation errors. This paper reviews some recently proposed linear transceiver designs based on the minimum mean squared error (MSE) criterion and shows that the proposed MSE decomposition and relaxation method can lead to an efficient solution for those challenges. Insightful observations and comprehensive discussions are also made on both analytical and numerical results from practical implementation perspectives."
  },
  {
    "year": "2017",
    "abstract": "The emergence of ubiquitous sensing and the Internet of Things (IoT) have inspired the development of “smart” everyday objects, which offer tremendous opportunities for maintaining the quality of life in ambient assisted living (AAL) environments. Inspired by the future possibilities of connected everyday devices, we envision a peripheral activity-based awareness system that captures human activity information and renders this information to enhance context awareness and support social connectedness between the elderly and their caregivers. Leveraging ambient intelligence and IoT technologies, ambient displays can convey activity information in the periphery of our attention. In particular, light has been used as a means to display ambient information and there is scientific evidence that it can enhance well-being, interconnectedness, and improve productivity. In this paper, we undertake two studies, first through an exploratory study we investigate the features of light suitable for conveying subtle activity information within the periphery of the users' attention for promoting context awareness. Also, we examine the preferences, perceptions, and interpretations of ambient lighting configurations of prospective caregiver's for conveying the activity information of older adults. In a second study, we assess the implications of activity awareness through lighting on cognitive performance, moods, and social connectedness. The set-up and design decisions of the second study were partly informed by previous research and by the outcomes of the first experiment. Together, these studies provide additional design guidelines for representing activity information with ambient lighting and highlight potential benefits and usage possibilities for lighting displays within the AAL domain. Furthermore, the results indicate a significant effect of activity awareness on cognitive performance. However, there were no significant effects of activity awareness through lighting on moods ..."
  },
  {
    "year": "2017",
    "abstract": "Blind source extraction (BSE) is often posed as the maximization of a statistical criterion under a unitary constraint. This paper addresses the convergence problem of a kurtosis-based criterion in the presence of noise. We present the stationary points of such criterion, and show that these extrema are simplified as the minimum mean square error (MMSE) solutions with some approximations. Moreover, we introduce a robust preprocessing approach, which allows one to find the MMSE separation matrix up to an orthogonal factor. The excellent performance of the BSE algorithm based on this preprocessing approach shows that the analysis of the stationary point is reliable."
  },
  {
    "year": "2017",
    "abstract": "Most of the resource allocation literature on the energy-efficient orthogonal frequency division multiple access (OFDMA)-based wireless communication systems assume continuous power allocation/control, while, in practice, the power levels are discrete (such as in 3GPP LTE). This convenient continuous power assumption has mainly been due to either the limitations of the used optimization tools and/or the high computational complexity involved in addressing the more realistic discrete power allocation/control. In this paper, we introduce a new optimization framework to maximize the energy efficiency of the downlink transmission of cellular OFDMA networks subject to power budget and quality-of-service constraints, while considering discrete power and resource blocks (RBs) allocations. The proposed framework consists of two parts: 1) we model the predefined discrete power levels and RBs allocations by a single binary variable and 2) we propose a close-to-optimal semidefinite relaxation algorithm with Gaussian randomization to efficiently solve this non-convex combinatorial optimization problem with polynomial time complexity. We notice that a small number of power levels suffice to approach the energy efficiency performance of the continuous power allocation. Based on this observation, we propose an iterative suboptimal heuristic to further reduce the computational complexity. Simulation results show the effectiveness of the proposed schemes in maximizing the energy efficiency, while considering the practical discrete power levels."
  },
  {
    "year": "2017",
    "abstract": "Trusted hardware sharing (THS) system can provide multiple trusted execution environments (TEE) via sharing the trusted hardware (e.g., sharing trusted platform module via virtualization) for stand-alone and isolation scenarios. However, the trusted function requests (TFRs) sent to the trusted hardware are emitted by multiple TEEs, which have to be processed by THS. Since different applications in different TEEs have different security requirements, the data in TFRs need to be protected from being leaked or modified in an unauthorized manner. To address this issue, we present a secure scheme for THS systems based on an information flow model that protects the sensitive data in TFRs. Each TFR is assigned a security level according to their owner, and processed in isolated environments with different security levels. We implement the prototype and conduct the experiments in both shared memory and isolated environments. The results indicate that the introduction of security mechanisms can lead to more time consumption on processing TFRs with the increase in the dimension of security levels. However, this degradation in performance is still acceptable and can be mitigated in the real world, because intensive TFR requests are not present as they are in the experimental environment."
  },
  {
    "year": "2017",
    "abstract": "The fourth industrial revolution, also known as Industry 4.0, brings many advantages including innovative applications and services, new technologies and advanced features, increased operational benefits, and reduced installation costs. However, this technological advancement also exposes several challenges pertaining to the development of cyber-physical industrial architectures, resilient communication systems, and secure data exchange. This paper develops a systematic methodology for designing intrusion detection systems (IDS) specially tailored to address the cyber and physical dimensions of these systems. The approach is aimed at reducing the number of monitored parameters by adopting a three-phase design strategy embracing sensitivity analysis, cross-association, and optimal IDS design. To this end, phase 1 embraces sensitivity analysis to identify sensitive variables to specific interventions (e.g., control signals and cyber attacks), phase 2 adopts the cross-association assessment to optimally structure the process variables in groups that are the most sensitive to groups of interventions, and finally, phase 3 optimally assigns the most sensitive process variables to IDS, while enforcing the IDS capacity limitations and redundancy requirements. Numerical results on a realistic vinyl acetate monomer process show that the approach can reduce the number of variables by 76.8%, thus reducing the complexity and the costs of the detection infrastructure."
  },
  {
    "year": "2017",
    "abstract": "The conditions of the environment where a person lives have a great impact on his wellness state. When buying a new house, it is important to select a place that aids in improving the wellness state of the buyer or, at least, keeps it at the same level. A deficient wellness state implies an increase of stress and the appearance of some effects associated with it. Heart rate variability (HRV) allows measuring the stress or wellness levels of a person by measuring the difference in time between heartbeats. A low HRV is related to high stress levels whereas a high HRV is associated with a high wellness state. In this paper, we present a system that measures the wellness and stress levels of home buyers by employing sensors that measure the HRV. Our system is able to process the data and recommend the best neighborhood to live in considering the wellness state of the buyer. Several tests were performed utilizing different locations. In order to determine the best neighborhood, we have developed an algorithm that assigns different values to the area in accordance with the HRV measures. Results show that the system is effective in providing the recommendation of the place that would allow the person to live with the highest wellness state."
  },
  {
    "year": "2017",
    "abstract": "With the development of online shopping and the demand for automated packaging systems, we propose an Internet of Things (IoT)-based automated e-fulfillment packaging system and a 3-D adaptive particle swarm optimization (PSO)-based packing algorithm. The proposed system leverages the IoT to connect the data collection and conversion layer, the packaging management layer, the decision-making layer, and the application layer. A cyber network connects each robot, sensor, and smart machine to achieve high velocity, flexibility of procedures, and real-time information exchange. When customers order merchandise online, the orders are received and rearranged, and the deployment of items in a box is planned by the system. The proposed packing algorithm controls the arrangement of items. It compares the size and volume of items and boxes to choose a box of suitable size, as well as deciding on the optimal arrangement of items. This algorithm solves the difficult 3-D Multiple Bin Size Bin Packing Problem (3-DMBSBPP) by integrating an adaptive PSO-based configuration algorithm. Our simulation results show that the packing algorithm can deploy items appropriately, with all items packed inside their box without overlap and with an overall center-of-gravity close to the bottom center of the box. When all the items cannot be packed into a single box, the proposed dividing strategies split the items into groups to pack into two or more boxes of similar size. Furthermore, comparing with the real packages we assessed, the proposed algorithm has a competitive performance. Lastly, our robotic experiments show that the proposed packing algorithm can be implemented and executed by a robot and a manipulator. It also demonstrates the efficiency of this system, in which all devices communicate well with each other and the robots accomplish the packaging task successfully and cooperatively."
  },
  {
    "year": "2017",
    "abstract": "Acoustic feedback is a very common problem in hearing instruments. Not only does it occur in common behind-the-ear or in-the-ear hearing aids, it also affects bone conduction implants, middle ear implants, and more recent devices, such as the direct acoustic cochlear implant (DACI). In this paper, we present the data and analysis relating to the feedback path characterization of the Cochlear™ Codacs™ DACI, performed on fresh frozen cadaver heads in four different measurement sessions. The general objectives were the following: 1) To measure and analyze the feedback path of the system and check for possible specimen-dependent variabilities; 2) To assess whether this feedback path is affected by an incorrect implantation; 3) To check for nonlinear behavior; and 4) To determine differences between tissular and airborne feedback. The data analysis reveals that the feedback seems to be dependent on the specific head morphology of the implanted specimen, and that an incorrect implantation might strongly affect the feedback path; additionally, the analysis reveals that some nonlinear behavior at high stimulus levels can be expected and, finally, that the feedback path is characterized by a tissular feedback component with a rather different frequency content compared to the airborne feedback component."
  },
  {
    "year": "2017",
    "abstract": "In oil pipeline leak detection and location, noise in the pressure signal collected at the end of the pipeline affects the accuracy of leak detection and the error of leakage location. To reduce the noise interference, an improved local mean decomposition signal analysis method is proposed. The production functions (PFs) that are related to the leak signal can be exacted, and it is necessary to know the characteristics of leak signals or noise in advance. According to the cross-correlation function, there is a significant peak between the measured signals, which are decomposed into a number of PFs. These reconstructed principal PF components are obtained, and a wavelet analysis is used to remove the noise in the reconstructed signal. On this basis, the signal features are extracted according to the time-domain feature and the waveform feature, which are input into the least squares twin support vector machine (LSTSVM), to recognize pipeline leaks. According to the reconstructed signal after wavelet denoising, the time-delay estimate of the negative pressure signal at the end of the pipeline is obtained by the cross-correlation function, and the leak location is ultimately calculated by combining the time delay with the leak signal propagation velocity. A flow model for pipeline leakage is proposed based on the Flowmaster software, where the collected data of the different working conditions are processed. The experimental results show that the proposed method can effectively identify different working conditions and accurately locate the leakage point."
  },
  {
    "year": "2017",
    "abstract": "Traffic volumes in mobile networks are rising and end-user needs are rapidly changing. Mobile network operators need more flexibility, lower network operating costs, faster service roll-out cycles, and new revenue sources. The 5th Generation (5G) and future networks aim to deliver ultra-fast and ultra-reliable network access capable of supporting the anticipated surge in data traffic and connected nodes in years to come. Several technologies have been developed to meet these emergent demands of future mobile networks, among these are software defined networking, network function virtualization, and cloud computing. In this paper, we discuss the security challenges these new technologies are prone to in the context of the new telecommunication paradigm. We present a multi-tier component-based security architecture to address these challenges and secure 5G software defined mobile network (SDMN), by handling security at different levels to protect the network and its users. The proposed architecture contains five components, i.e., secure communication, policy-based communication, security information and event management, security defined monitoring, and deep packet inspection components for elevated security in the control and the data planes of SDMNs. Finally, the proposed security mechanisms are validated using test bed experiments."
  },
  {
    "year": "2017",
    "abstract": "A new driving method for small size legged robots was proposed and tested in this paper, in which the resonant vibrations of four flexible cantilever beams were used to generate the driving forces. The driving principle was elaborated as two sub principles, based on vertical bending vibrations and horizontal bending vibrations, respectively. According to the mode analysis and the harmonic analysis by the finite-element method, a prototype named Resbot was designed and fabricated. Experiments were carried out on two kinds of surfaces. The size of the Resbot was 99 mm×148mm×28mm, and its maximum speed was measured to be about 17.2 cm/s, which proved the feasibility of the proposed driving method for small legged robots. The relationship between the frequency of the driving force and the velocity of the Resbot demonstrated the availabilities of the two different driving sub-principles. The advantages of the proposed Resbot were that it was not only simple in structure for no intermediate transmission system, but also easy to be miniaturized, since there was no need to design the gaits; furthermore, it used an extremely simple control system."
  },
  {
    "year": "2017",
    "abstract": "The ever expanding the usage of cloud computing environments, connected applications and Internet of Things-based devices have progressively increased the amount of data that travels through our networks. Software-defined network (SDN) is an emergent paradigm that aims to support next-generation networks through its flexible and powerful management mechanisms. One of the biggest threats faced by these services nowadays is security management. Attacks based on the denial of service (DoS) are particularly efficient against this paradigm due to its centralized control characteristic. Once this controlling system receives a massive amount of malicious requests, the overall performance of the network operation is impaired. Although several researches propose to address this problem, most of them are reactive approaches, detecting the attacks and warning the network administrators, i.e., after the network is already compromised. This paper presents an autonomic DoS/DDoS defensive approach for SDNs called Game Theory (GT)-Holt-Winters for Digital Signature (HWDS), which unites the anomaly detection and identification provided by an HWDS system with an autonomous decision-making model based on GT. Real collected data and simulated attacks are used by the system to measure its effectiveness and efficiency. Furthermore, we also use a heuristic Fuzzy-GADS method for anomaly detection instead of HWDS, aiming to compare the achieved performance and evaluate the behavior of the presented game theoretical approaches a standalone mitigation module."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the performance of the analog multi-tap (MT) canceller, where the tap coefficients are calculated based on the estimated self-interference (SI) channel state information (CSI). In this paper, both the time-invariant and the time-varying SI channels scenarios are investigated, considering the dynamic range of the analog-to-digital converter (ADC) and the linearity of the receiver chain. Closed-form expressions are first developed to calculate the residual SI power after the MT cancellation, characterizing the joint effects of the imperfect SI CSI, reconstruction errors on the estimated SI CSI, and the variation of the SI channels. Then, the achievable rate of the full-duplex transceivers is derived as a function of the residual SI power after the MT cancellation, dynamic range of the ADC, and the linearity of the receiver chain. Theoretical and simulated results show that with imperfect SI CSI, deploying more taps may harm the amount of analog SI cancellation. The sensitivity of the canceller to the doppler frequency shift reduces the amount of analog SI cancellation, and thus brings rate gain loss even with a doppler negligible in conventional communications."
  },
  {
    "year": "2017",
    "abstract": "Fault detection in induction motors operating in non-stationary regimes has become a need in today's industry. Most of the works published deal with line-fed motors. Nevertheless, the number of inverter-fed induction motors has significantly increased in recent years. Therefore, several fault detection techniques have been proposed lately for this type of motors, based mainly on an adequate input signal processing to obtain fault signatures in the time-frequency domain. In this paper, a comparison of time-frequency techniques applied to fault detection in inverter-fed induction motors in a transient state is presented. For that purpose, the techniques are applied to two current signals acquired from two induction motors with two types of faults: bar breakage and mixed eccentricity. The paper shows the particularities and special difficulties of diagnosing under this type of feeding, reviewing the works related to each technique. The strengths and weaknesses of these techniques are discussed with the goal of providing a criterion for its application in an industrial environment and guidance for future developments in this field."
  },
  {
    "year": "2017",
    "abstract": "Data is growing at an enormous rate in the present world. One of the finest and most popular technologies available for handling and processing that enormous amount of data is the Hadoop ecosystem. Enterprises are increasingly relying on Hadoop for storing their valuable data and processing it. However, Hadoop is still evolving. There is much vulnerability found in Hadoop, which can question the security of the sensitive information that enterprises are storing on it. In this paper, security issues associated with the framework have been identified. We have also tried to give a brief overview of the currently available solutions and what are their limitations. At the end a novel method is introduced, which can be used to eliminate the found vulnerabilities in the framework. In the modern era, information security has become a fundamental necessity for each and every individual. However, not everyone can afford the specialized distributions provided by different vendors to their Hadoop cluster. This paper presents a cost-effective technique that anyone can use with their Hadoop cluster to give it 3-D security."
  },
  {
    "year": "2017",
    "abstract": "A novel nonintrusive statistical approach, known as the stochastic reduced order model (SROM) method, is applied to efficiently estimate the statistical information of the terminal response (i.e., the induced current) in transmission lines excited by a random incident plane-wave field. The idea of the SROM method is conceptually simple, i.e., to represent the uncertain input space dimensioned by random variables using the SROM-based input model. This input model consists of a very small number of selected samples with assigned probabilities. Thus, only these input samples in the model need to be evaluated using the deterministic solver. The SROM-based output model can be constructed to approximate the propagated uncertainty to the real output response with elementary calculation. The efficiency and accuracy of the SROM method to obtain the statistics of the induced current are analyzed using two examples, where the complexity of the uncertain input space gradually increases. The performance of the SROM method is compared with that of the traditional Monte Carlo (MC) method. The stochastic collocation (SC) method based on sparse grid sampling strategy computed via the Smolyak algorithm is also implemented to fairly evaluate the SROM performance. The result shows that the SROM method is much more efficient than the MC method to obtain accurate statistics of the induced current, and even shows a faster convergence rate compared with that of the SC method in the examples considered. Therefore, the SROM method is a suitable approach to investigate the variability of radiated susceptibility in electromagnetic compatibility problems with a random incident wave."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing systems require massive storage infrastructures, which have significant implications on power bills, carbon emissions, and the logistics of data centers. Various proprietary “cold storage” services, based on spun-down disks or tapes, offer reduced tariffs but also lead to extended times to first access. One way to improve cold-storage systems is to build them on a file system that allows for the I/O patterns of storage devices. We have developed a cold-storage test-bed for mobile messenger services, which takes into account the power consumption of each hard disk in the system. We analyzed a trace of I/O requests from a messenger service and found that they had a strongly skewed Zipfian distribution and that most of the stored data is cold. Current cloud benchmarking tools cannot reproduce this pattern of I/O. Therefore, we have developed a tool for benchmarking cold-storage systems that emulates this type of long-tail distribution and can contribute to reducing the power consumption of mobile messenger services."
  },
  {
    "year": "2017",
    "abstract": "We propose a multiple-voting-based joint detection-decoding algorithm for nonbinary low-density parity-check (LDPC)-coded modulation systems. This algorithm is inspired from the reliability-based JDD algorithm for nonbinary LDPC-coded modulation systems, that has been proposed recently, in which the accumulated reliability of symbols based on one-step majority-logic decoding algorithm and the Chase-like local list decoding algorithm are used. However, the reliability-based JDD algorithm still has a significant performance degradation of at least 1 dB with low column weight (dv≤4). In order to reduce the performance degradation with low column weight, the proposed algorithm allows unfixed number of variable nodes to pass two symbols to the associated check node, in contrast with the reliability-based JDD algorithm, which allows only one variable node to pass two symbols to check node, when updating variable-to-check messages. Moreover, the votes are weighted differently according to the components of the list in the check-sum computation. Simulations show that the proposed algorithm yields better performance with low column weight, while still maintaining the low complexity feature."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with low-complexity joint channel estimation and decoding for faster-than-Nyquist (FTN) signaling over frequency selective fading channels. The inter-symbol interference (ISI) imposed by FTN signaling and the frequency selective channel are intentionally separated to fully exploit the known structure of the FTN-induced ISI. Colored noise due to the faster sampling rate than that of the Nyquist signaling system is approximated by autoregressive process. A Forney style factor graph representation of the FTN system is developed and Gaussian message passing is performed on the graph. Expectation propagation (EP) is employed to approximate the message from channel decoder to Gaussian distribution. Since the inner product between FTN symbols and channel coefficients is infeasible by belief propagation (BP), we propose to perform variational message passing (VMP) on an equivalent soft node in factor graph to tackle this problem. Simulation results demonstrate that the proposed low-complexity hybrid BP-EP-VMP algorithm outperforms the existing methods in FTN system. Compared with the Nyquist counterpart, FTN signaling with the proposed algorithm is able to increase the transmission rate by over 40%, with only negligible BER performance loss."
  },
  {
    "year": "2017",
    "abstract": "With the advent of big data era, complex optimization problems with many objectives and large numbers of decision variables are constantly emerging. Traditional research about multi-objective particle swarm optimization (PSO) focuses on multi-objective optimization problems (MOPs) with small numbers of variables and less than four objectives. At present, MOPs with large numbers of variables and many objectives (greater than or equal to four) are constantly emerging. When tackling this type of MOPs, the traditional multi-objective PSO algorithms have low efficiency. Aiming at these multi-objective large-scale optimization problems (MOLSOPs) and many-objective large-scale optimization problems (MaOLSOPs), we need to explore thoroughly parallel attributes of the particle swarm, and design the novel PSO algorithms according to the characteristics of distributed parallel computation. We survey the related research on PSO: multi-objective large-scale optimization, many-objective optimization, and distributed parallelism. Based on the aforementioned three aspects, the multi-objective large-scale distributed parallel PSO and many-objective large-scale distributed parallel PSO methodologies are proposed and discussed, and the other future research trends are also illuminated."
  },
  {
    "year": "2017",
    "abstract": "In recent years, privacy-preserving data mining (PPDM) has received a lot of attention in the field of data mining research. While some sensitive information in databases cannot be revealed, PPDM can discover additional important knowledge and still hide critical information. There are different ways to approach this exhibited in previous research, which applied addition and deletion operations to adjust an original database in order to hide sensitive information. However, it is an NP-hard problem to find an appropriate set of transactions/itemsets for hiding sensitive information. In the past, evolutionary algorithms were developed to hide sensitive itemsets by building an appropriate database. Genetic-based algorithms and a particle swarm optimization-based algorithm, proposed in previous works, not only hide sensitive itemsets but also minimize the side effects of sanitization processes. In this paper, an ant colony system (ACS)-based algorithm called ACS2DT is proposed to decrease side effects and enhance the performance of the sanitization process. Each ant in the population will build a tour for each iteration and each tour indicates the deleted transactions in the original database. The proposed algorithm introduces a useful heuristic function to conduct each ant to select a suitable edge (transaction) for the current situation and also designs several termination conditions to stop the sanitization processes. The proposed heuristic function applies the pre-large concept to monitor side effects and calculates the degree of hiding information to adjust the selecting policy for deleted transactions. The experimental results show that the proposed ACS2DT algorithm performs better than the Greedy algorithm and other two evolutionary algorithms in terms of runtime, fail to be hidden, not to be hidden, not to be generated and database similarity on both real-world and synthetic data sets."
  },
  {
    "year": "2017",
    "abstract": "Full-duplex (FD) technology is currently under consideration for adoption in a range of legacy communications standards due to its attractive features. On the other hand, cellular networks are becoming increasingly heterogeneous as operators deploy a mix of macrocells and small cells. With growing tendency toward network densification, small cells are expected to play a key role in realizing the envisioned capacity objectives of emerging 5G cellular networks. From a practical perspective, small cells provide an ideal platform for deploying FD technology in cellular networks due to its lower transmit power and lower cost for implementation compared with the macrocell counterpart. Motivated by these developments, in this paper, we analyze a two-tier heterogeneous cellular network, wherein the first tier comprises half-duplex macrobase stations and the second tier consists of the FD small cells. Through a stochastic geometry approach, we characterize and derive the closed-form expressions for the outage probability and the rate coverage. Our analysis explicitly accounts for the spatial density, the self-interference cancellation capabilities, and the interference coordination based on enhanced inter-cell interference coordination techniques. Performance evaluation investigates the impact of different parameters on the outage probability and the rate coverage in various scenarios."
  },
  {
    "year": "2017",
    "abstract": "A statistical model is derived for the equivalent signal-to-noise ratio of the Source-to-Relay-to-Destination (S-R-D) link for Amplify-and-Forward (AF) relaying systems that are subject to block Rayleigh-fading. The probability density function and the cumulated density function of the S-R-D link SNR involve modified Bessel functions of the second kind. Using fractional-calculus mathematics, a novel approach is introduced to rewrite those Bessel functions (and the statistical model of the S-R-D link SNR) in series form using simple elementary functions. Moreover, a statistical characterization of the total receive-SNR at the destination, corresponding to the S-R-D and the S-D link SNR, is provided for a more general relaying scenario in which the destination receives signals from both the relay and the source and processes them using maximum ratio combining (MRC). Using the novel statistical model for the total receive SNR at the destination, accurate and simple analytical expressions for the outage probability, the bit error probability, and the ergodic capacity are obtained. The analytical results presented in this paper provide a theoretical framework to analyze the performance of the AF cooperative systems with an MRC receiver."
  },
  {
    "year": "2017",
    "abstract": "Recently, distributed mobility management (DMM) solutions have been proposed to address the drawbacks of centralized mobility management (CMM) solutions. The Internet engineering task force (IETF) has stated that extending and reusing CMM protocols are one of the considerations for DMM solutions design, where it is less faulty and more effective. Therefore, IETF has proposed a network-based DMM solution based on the well-known network-based CMM protocol: Proxy Mobile IPv6 (PMIPv6). However, network-based DMM has marginal improvements over the handover latency and packet loss of PMIPv6. Thus, this paper enhances the handover procedure of network-based DMM using the HO-initiate process and the IEEE 802.21 media-independent handover services. We tackle the issue of binding registration latency by performing the HO-initiate process proactively. Moreover, we mitigate the latency of discovering next access network and candidate mobile anchor access routers (MAARs) with the support of the lower three layers' information of the mobile user and surrounded MAARs. A neighbors network information container is introduced to store and retrieve the link and network layers' information of neighboring networks. A candidate access networks cache is defined at the serving-MAAR to decrease the prediction time. Furthermore, we propose a candidate access network selector to facilitate smart handover decision making by using the information of required and available resources in the candidate networks. We derive an analytical expression to evaluate the proposed solution compared with DMM and fast handover for DMM mechanisms. Simulation is also performed to verify the analytical results, where we consider realistic urban and highway environments. Numerical and simulation results prove that the proposed solution decreases 74.61% of the overall handover latency in DMM."
  },
  {
    "year": "2017",
    "abstract": "This paper theoretically analyzes the impact of the antenna sub-reflector focus excursion technique on the antenna pattern. First, we derive relevant formulas and analyze pattern variation based on the focus excursion. On this base, this paper then proposes a novel structure of antenna sub-surface focus excursion and investigates the concrete engineering realization. Experimental results based on the test-bed of the antenna show that the proposed focus excursion scanning technique improves the system performance and thus has a high-practical engineering value."
  },
  {
    "year": "2017",
    "abstract": "Fog computing (FC) and Internet of Everything (IoE) are two emerging technological paradigms that, to date, have been considered standing-alone. However, because of their complementary features, we expect that their integration can foster a number of computing and network-intensive pervasive applications under the incoming realm of the future Internet. Motivated by this consideration, the goal of this position paper is fivefold. First, we review the technological attributes and platforms proposed in the current literature for the standing-alone FC and IoE paradigms. Second, by leveraging some use cases as illustrative examples, we point out that the integration of the FC and IoE paradigms may give rise to opportunities for new applications in the realms of the IoE, Smart City, Industry 4.0, and Big Data Streaming, while introducing new open issues. Third, we propose a novel technological paradigm, the Fog of Everything (FoE) paradigm, that integrates FC and IoE and then we detail the main building blocks and services of the corresponding technological platform and protocol stack. Fourth, as a proof-of-concept, we present the simulated energy-delay performance of a small-scale FoE prototype, namely, the V-FoE prototype. Afterward, we compare the obtained performance with the corresponding one of a benchmark technological platform, e.g., the V-D2D one. It exploits only device-to-device links to establish inter-thing “ad hoc” communication. Last, we point out the position of the proposed FoE paradigm over a spectrum of seemingly related recent research projects."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the issues of resource allocation and co-channel interference management for coexistence of, and cooperation between, two long term evolution (LTE) networks. In the Republic of Korea, the LTE-based public safety (PS-LTE) network is being built for the 700-MHz frequency band. However, the same band is also allocated to the LTE-based high-speed railway (LTE-R) network, so immense interest and useful researches into co-channel interference management schemes are immediately needed. In this paper, we focus on the downlink system of coexisting PS-LTE and LTE-R networks by considering LTE-R radio access network (RAN) sharing and non-RAN sharing by PS-LTE users equipment (UEs) to analyze the co-channel interference. We also utilize cooperative communications schemes, such as coordinated multipoint (CoMP) and inter-cell interference coordination (ICIC) in order to resolve the problem of co-channel interference. We categorize the coexistence of PS-LTE and LTE-R networks into five different scenarios, and evaluate the performance of each scenario based on various performance indexes, such as UE average throughput, UE received interference, and UE outage probability. Moreover, users can achieve high throughput as well as obtain a better channel condition by using RAN sharing. In addition, we always provide the higher priority to railway user while allocating the resources for coexisting public safety and railway networks using LTE-R RAN sharing by PS-LTE UEs, because train control signal needs more reliable communication as well as low latency in order to fulfil its mission-critical service (MCS) demands. By employing coordinated scheduling (CS) CoMP, the highest throughput performance can be attained with RAN sharing. Furthermore, the dynamic ICIC enhances cell-edge UE performance and reduces UE received interference, as well as the outage probability, by using the partial reuse band and bonus band allocation."
  },
  {
    "year": "2017",
    "abstract": "Personal and business users prefer to use e-mail as one of the crucial sources of communication. The usage and importance of e-mails continuously grow despite the prevalence of alternative means, such as electronic messages, mobile applications, and social networks. As the volume of business-critical e-mails continues to grow, the need to automate the management of e-mails increases for several reasons, such as spam e-mail classification, phishing e-mail classification, and multi-folder categorization, among others. This paper comprehensively reviews articles on e-mail classification published in 2006-2016 by exploiting the methodological decision analysis in five aspects, namely, e-mail classification application areas, data sets used in each application area, feature space utilized in each application area, e-mail classification techniques, and the use of performance measures. A total of 98 articles (56 articles from Web of Science core collection databases and 42 articles from Scopus database) are selected. To achieve the objective of the study, a comprehensive review and analysis is conducted to explore the various areas where e-mail classification was applied. Moreover, various public data sets, features sets, classification techniques, and performance measures are examined and used in each identified application area. This review identifies five application areas of e-mail classification. The most widely used data sets, features sets, classification techniques, and performance measures are found in the identified application areas. The extensive use of these popular data sets, features sets, classification techniques, and performance measures is discussed and justified. The research directions, research challenges, and open issues in the field of e-mail classification are also presented for future researchers."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a digital-to-time converter (DTC) based on the principle of quantified phase shift resolution (QPSR) is proposed and tested. The QPSR principle is realized by analyzing the phase relationship between two periodic signals, which distinguishes the proposed DTC from conventional DTCs. For performance evaluation, the proposed DTC is implemented on Xilinx Virtex-5 and Virtex-6 field programmable gate array (FPGA) chip, respectively. The obtained resolution of the DTC implemented on Virtex-5 FPGA is 27.1 ps, and the differential nonlinearity (DNL) and integral nonlinearity (INL) are −0.269~+0.247 least significant bit (LSB) and −0.387~+0.171 LSB. Meanwhile, the DTC implemented on Virtex-6 FPGA can achieve a resolution of 3.93 ps, a dynamic range of 43 s, a DNL of −0.327~+0.358 LSB, and an INL of −2.6093~+2.4754 LSB. Experimental results prove that the proposed DTC features high-accuracy, low-cost, and easy implementation."
  },
  {
    "year": "2017",
    "abstract": "A coalitional game is proposed for multicell multi-user downlink beamforming. Each base station intends to minimize its transmission power while aiming to attain a set of target signal-to-interference-plus-noise-ratio (SINR) for its users. To reduce power consumption, base stations have incentive to cooperate with other base stations to mitigate intercell interference. The coalitional game is introduced where base stations are allowed to forge partial cooperation rather than full cooperation. The partition form coalitional game is formulated with the consideration that beamformer design of a coalition depends on the coalition structure outside the considered coalition. We first formulate the beamformer design for a given coalition structure in which base stations in a coalition greedily minimize the total weighted transmit power without considering interference leakage to users in other coalitions. This can be considered as a non-cooperative game with each player as a distinct coalition. By introducing cost for cooperation, the coalition formation game is considered for the power minimization-based beamforming. A merge-regret-based sequential coalition formation algorithm has been developed that is capable of reaching a unique stable coalition structure. Finally, an α-Modification algorithm has been proposed to improve the performance of the coalition formation algorithm."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new robust Student's t-based stochastic cubature filter (RSTSCF) is proposed for a nonlinear state-space model with heavy-tailed process and measurement noises. The heart of the RSTSCF is a stochastic Student's t-spherical radial cubature rule (SSTSRCR), which is derived based on the third-degree unbiased spherical rule and the proposed third-degree unbiased radial rule. The existing stochastic integration rule is a special case of the proposed SSTSRCR when the degrees of freedom parameter tends to infinity. The proposed filter is applied to a maneuvering bearings-only tracking example, in which an agile target is tracked and the bearing is observed in clutter. Simulation results show that the proposed RSTSCF can achieve higher estimation accuracy than the existing Gaussian approximate filter, Gaussian sum filter, Huber-based nonlinear Kalman filter, maximum correntropy criterion-based Kalman filter, and robust Student's t-based nonlinear filters, and is computationally much more efficient than the existing particle filter."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel theoretical characterization of the pilot-assisted (PA) technique proposed for peak-to-average-power-ratio (PAPR) reduction in optical orthogonal frequency division multiplexing (O-OFDM). The two systems considered are direct-current biased O-OFDM (DCO-OFDM) and asymmetrically clipped O-OFDM (ACO-OFDM) in optical wireless communications. The DCO-OFDM and ACO-OFDM time-domain signals approach Gaussian and half-Gaussian distributions, respectively. The PA technique uses P iterations of a pilot sequence to rotate the phase of U data symbols within a PA O-OFDM frame and select the frame with the least PAPR. Thus, we utilize order statistics to characterize the PAPR distributions of the PA DCO-OFDM and ACO-OFDM system. The PA technique results in higher reduction in PAPR for high P but at the expense of increased complexity. In the theoretical framework developed, we are able to determine P that gives reasonable PAPR reduction gain. The theoretical analysis of PAPR reduction effects on the average optical and electrical signal power is studied. Results show that the PA technique is capable of reducing the optical energy per bit to noise power spectral density Eb(opt)/N0ratio required to meet target bit-error-rate in an additive white Gaussian noise channel. Comparisons of the analytical results of PA O-OFDM signal with that of computer simulations show very good agreement."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a cable driven astronaut rehabilitative training (ART) robot, which can provide astronauts with multiple physical exercises including bench press, running, and deep squat to alleviate and resist the adverse effects induced by space adaptation syndrome. First, the modular reconfiguration of the ART driven by a cable is proposed to simulate the load characteristics of the gravity environment. Second, in order to improve the accuracy of the ART, the force control strategy is presented. The controller consists of two parts: high-level controller, which to calculate the desired cable tension and low-level controller, which to make each cable achieve the desired tension. Finally, to validate the effect of the ART, three (adult male) weight lifters were recruited to perform several bench press exercises with the barbell and ART. The analysis of the surface electromyography (sEMG) of triceps brachii and pectoralis major during real bench press and bench press simulated by the ART was conducted. The performance of the ART and the data of sEMG demonstrate the controller is effective and the ART can effectively assist astronauts to carry out bench press exercises in space."
  },
  {
    "year": "2017",
    "abstract": "The learning ability of neural networks (NNs) enables them to solve time series prediction problems. Off-line training can be applied to design the structure and weights of NNs when sufficient training data are available. However, this may be inadequate for applications that operate in real time, possess limited memory size, or require online adaptation. Furthermore, the structural design of NNs (i.e., the number of hidden neurons and connected topology) is crucial. This paper presents a novel algorithm, called the symbiotic structure learning algorithm (SSLA), to enhance a feedforward neural-network-aided grey model (FNAGM) for real-time prediction problems. Through symbiotic evolution, the SSLA evolves neurons that cooperate well with each other, and constructs NNs from the neurons with hyperbolic tangent and linear activation functions. During construction, the hidden neurons with the linear activation function can be simplified to a few direct connections from the inputs to the output neuron, leading to a compact network topology. The NNs share the fitness value with participating neurons, which are further evolved through neuron crossover and mutation. The proposed SSLA was evaluated through three real-time prediction problems. Experimental results showed that the SSLA-derived FNAGM possesses a partially connected NN with few hidden neurons and a compact topology. The evolved FNAGM outperforms other methods in prediction accuracy and continuously adapts the NN to the dynamic changes of the time series for real-time applications."
  },
  {
    "year": "2017",
    "abstract": "This paper discusses a new waveform synthesis technique particularly suitable for low altitude ultra-wideband (UWB) synthetic aperture radar (SAR) systems. The proposed technique synthesizes a phase-coded UWB chirp by transmitting a burst of coherent phase-coded sub-band chirp pulses and combining the collected echoes using a special digital signal processing (DSP) algorithm. A lab prototype is built for the feasibility study and validation of the proposed technique. From the results, it is clearly shown that 1) the proposed technique can synthesize UWB chirp pulses; 2) the proposed DSP algorithm can combine the collected sub-band echoes into an echo of a wider bandwidth; and 3) the proposed technique can improve the range resolution of the SAR system without altering much of its system design. The main advantage of the proposed technique is that it can improve the range resolution of an existing SAR system without the need to increase the baseband bandwidth of the system."
  },
  {
    "year": "2017",
    "abstract": "“Track and Accumulate” (T&A) is an alternative astronomical image capture method where exposures are combined during imaging by aligning on a reference star. The benefit is an increased dynamic range, thus allowing both bright and dim objects to be captured in the same image. The main limitation is that correlated noise from the frames will form squiggles on the combined image as the result of telescope drift, especially when using narrowband filters. In general, the advantages of the T&A method are insufficient to outweigh this limitation, and most astrophotographers prefer to take individual images and combine later. In this paper, several enhancements to the original T&A method are detailed, which improve on the process as well as reduce correlated noise. An algorithm is proposed where most postprocessing is integrated into the T&A procedure. These improvements simplify the imaging process, reduce hardware costs, and lower the technical bar for producing quality astronomical photos. The algorithm has been field tested on a variety of astronomical objects, and the resultant images are as good as those produced by the traditional method, yet require less imaging and processing time."
  },
  {
    "year": "2017",
    "abstract": "There is increasing demand for continued development in personal mobility vehicles, because many people want to use them to improve their life. For example, wheelchair users, including people with disabilities, need powered wheelchairs for their daily activities, and elderly people expect to use mobile platforms for better quality of life. There are two main research targets for these types of vehicles: more intelligence and higher mobility performance. This paper discusses the latter topic. The vehicle proposed in this paper has high mobility performance on rough terrain; notably, it has the capability of traversing steps obliquely, even though conventional vehicles are supposed to move on steps only from the very front of the steps, not obliquely. Its performance for climbing up/down steps is evaluated in this paper, which is an evaluation for climbing up steps that consists of seven patterns of approach angles to the step for one step and two steps. Tests for climbing down steps were also conducted. Through those tests, the ability of our vehicle to traverse steps obliquely was confirmed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a deep belief network (DBN)-deep neural network (DNN) with mimic features based on the bootstrap inspired technique to learn the complex nonlinear relationship between the mimic feature vectors obtained from the oscillometry signals and the target blood pressures. Unfortunately, we have two problems in utilizing the DBN-DNN technique to estimate the systolic blood pressure (SBP) and diastolic blood pressure (DBP). First, our set of input feature vectors is very small, which is a fatal drawback to training based on the DBN-DNN technique. Second, the special pre-training phase can also trigger an unstable estimation, because there are still a lot of random initialized assigns, such as the training data set, weights, and biases. For these reasons, we employ the bootstrap-inspired technique as a fusion ensemble estimator based on the DBN-DNN-based regression model, which is used to create the mimic features to estimate the SBP and DBP. Our DBN-DNN-based ensemble regression estimator provides a lower standard deviation of error, mean error, and mean absolute error for the SBP and DBP as compared with those of the conventional methods."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the beamforming designs for simultaneous wireless information and power transfer systems in two-way relaying (TWR) channels. The system consists of two energy-constrained source nodes which employ the power splitting (PS) to receive the information and the energy simultaneously from the power-supply relay. To maximize the weighted sum energy subject to the constraints of the quality of service and the transmit powers, three well-known relaying protocols, i.e., amplify-and-forward, bit level XOR-based decode-and-forward (DF), and symbol level superposition coding-based DF, are considered. For each relaying protocol, we formulate the joint relay beamforming, the source transmit power, and the PS ratios optimization as a nonconvex quadratically constrained problem. To solve the complex nonconvex problem, we decouple the objective problem into two subproblems in which one is to optimize the beamforming vectors while another is to optimize the remaining parameters. We show that the optimal solution of each subproblem can be obtained in the closed-form expressions. The solution is finally obtained with the proposed convergent iterative algorithm. Extensive numerical results demonstrate the advantage of adapting the different relaying strategies and weighted factors to harvest energy in TWR channels."
  },
  {
    "year": "2017",
    "abstract": "Large-scale data centers are major infrastructures in the big data era. Therefore, a stable and optimized architecture is required for data center networks (DCNs) to provide services to the applications. Many studies use software-defined network (SDN)-based multipath TCP (MPTCP) implementation to utilize the entire DCN's performance and achieve good results. However, the deployment cost is high. In SDN-based MPTCP solutions, the flow allocation mechanism leads to a large number of forwarding rules, which may lead to storage consumption. Considering the advantages and limitations of the SDN-based MPTCP solution, we aim to reduce the deployment cost due to the use of an extremely expensive storage resource-ternary content addressable memory (TCAM). We combine MPTCP and segment routing (SR) for traffic management to limit the storage requirements. And to the best of our knowledge, we are among the first to use the collaboration of MPTCP and SR in multi-rooted DCN topologies. To explain how MPTCP and SR work together, we use four-layer DCN architecture for better description, which contains physical topology, SR over the topology, multiple path selection supplied by MPTCP, and traffic scheduling on the selected paths. Finally, we implement the proposed design in a simulated SDN-based DCN environment. The simulation results reveal the great benefits of such a collaborative approach."
  },
  {
    "year": "2017",
    "abstract": "This paper is mainly concerned with cluster tracking control for robotic networks whose dynamics are modeled by a Lagrangian equation with multiple leaders. An adaptive distributed pinning tracking control protocol is presented to realize cluster consensus, and the corresponding convergence analysis is given by utilizing the property of directed acyclic networks topology. Furthermore, by developing a recursive analysis method, a criterion that ensures the convergence for proposed algorithm is given. Subsequently, simulations conducted on the seven two-link revolute arms are presented to illustrate the effectiveness of the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "In previous work, a new network switch architecture, hybrid circuit-switched (HCS) network, has been proposed and evaluated. In doing so, it has been studied for use in a multi-processor system, with a focus on power and throughput. However, cache coherence and its connection with chip reliability have not been fully studied previously for multi-processor systems. In this paper, we study this problem by discussing the implementation of cache coherence on a HCS-based chip multi-processor and present a way to model the reliability of these protocols based on fault tree analysis and two-terminal networking models. We focus our efforts on three cache coherence protocols: Write-Once, Modified, Exclusive, Shared, Invalid (MESI), and Modified, Owned, Exclusive, Shared, Invalid (MOESI), and obtain expressions for the reliability probabilities of the system. Our results show that the Write-Once protocol is 14% less reliable than MOESI, while the MESI protocol is 2.5% less reliable than MOESI. We also demonstrate that the reliability of these protocols are 40.22% and 59.83% better, on average, when implemented on an HCS network rather than an elastic buffer-based network or a bus-based network, respectively."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider an outdoor visible light communications relaying system in which the relay node needs to transmit both its own information and the information from a source node simultaneously. A superimposed relaying (SR) strategy and the corresponding constellation design are presented. We derive the closed-form dominant term of average bit error rate (BER) for the system, and obtain an optimal power allocation to minimize the average BER. Simulation results demonstrate that SR can improve the error performance of the system significantly."
  },
  {
    "year": "2017",
    "abstract": "A supply of minerals is critical to socioeconomic development. However, such a supply also induces negative impacts on environment and ecology, e.g., leading to dust emission and deposition. An ultra-low-grade magnetite has been exploited as a new iron type since 2001 in China. In this paper, two Landsat images were used for monitoring foliar dust in Changhe River Mining Area, China. First, models were established to estimate foliar dust using vegetation indices (VIs) differences according to laboratory spectral measurements; normalized differenced VI was selected as an optimal VI for estimating foliar dust amount based on both field and laboratory spectral measurements (RMSE = 6.58 g/m2), and finally, the spatial patterns of foliar dust were analyzed by using ancillary high-resolution data. The result showed that most foliar dust distributed near ore transportation roads and around mining sites and tailings ponds, which was related to ultra-low-grade characteristics of the iron ore due to large-area extraction and tailings occupation, and large-amount dust emission released from ore transportation. The remote sensing method for estimating foliar dust may be beneficial for environmental management in mining areas."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the problem of resource allocation in a dense small-cell network. Each small-cell base station is powered by a renewable energy source and operates in the full-duplex mode. We account for the rate-dependent energy term for data decoding into the total energy consumption at the small-cell base station. Owing to this new energy term, the transmitter and receiver operations now draw the energy from a common source. For a new energy consumption model and high interference scenario, which arises due to full-duplex communications, we formulate an energy and load aware resource management optimization problem under the energy causality and total transmit power constraints of the small-cell base station and uplink user equipments. In particular, the problem minimizes the data queue length of each network user equipment by jointly designing the beamformers, power, and sub-carrier allocation and their scheduling. Owing to the non-convexity of the problem, a global solution is inefficient; thus, we opt for the successive parametric convex approximation method to obtain a sub-optimal solution. This method solves for the convex approximate of the non-convex problem in each iteration and leads to faster convergence. For practical implementation, we further develop a distributed algorithm by using the dual decomposition framework, which relies on limited exchange of information between the involved base stations. Numerical simulations compare the network scenario which accounts for uplink channel rate-dependent energy consumption with that which ignores it. Results advocate the need for redesigning of the resource allocation scheme. In addition, numerical simulations also validate the usefulness of full-duplex communications over the half-duplex communications in terms of minimizing the sum data queue length of the users."
  },
  {
    "year": "2017",
    "abstract": "One of the main research questions in the field of wave energy technologies concerns the development of an efficient control strategy that can enhance the economic competitiveness of these technologies. Numerous control strategies have been proposed in the past three decades of which only a few are deemed practical. This paper proposes a novel online damping control strategy that is based on the development of an explicit relation for controlling the damping force of a permanent magnet linear generator (PMLG) in real time. The strategy controls the duty cycle of a single-switch three-phase boost rectifier connected at the output terminals of the PMLG. Simulations were conducted to assess the performance of the wave energy converter after applying the proposed strategy under different operating conditions. The results showed satisfactory performances for different sea-state and electrical-loading conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper reports that a miniaturized chiral meta-atom has 5.14-GHz bandwidth and applicable for C-band applications. The meta-atom is developed by an electric inductive-capacitive resonator, where the inverse E-shape structure is combined with the outer ring resonator. The dimension of the proposed single unit cell structure is 6.0×6.0 mm2that is printed on a Rogers RT 5880 material. Finite integration technique-based CST Microwave Studio has been utilized to design, simulation, and investigation purposes. An Agilent N5227A vector network analyser is used to retrieval the effective parameters and the measured and simulated results are well arranged together. The negative refraction bandwidth of 5.14 GHz (from 4.0 to 9.14 GHz) and the effective medium ratio 6.96 make the designed meta-atom is suitable for practical applications."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we minimize the transmit power for multiple-input single-output and nonorthogonal multiple access systems. In our analysis, a large number of users are partitioned into multiple user clusters/pairs with small size and uniform power allocation across the clusters and each cluster is associated with a beamforming vector. The considered optimization problem involves how to optimize beamforming vectors, power allocation, and user clustering. Considering the high computational complexity in solving the whole problem, we decompose the problem into two parts, and design a joint algorithm to iteratively optimize them. First, given a user partition, we formulate the beamforming and power allocation problem under a set of practical constraints. The problem is nonconvex. To tackle it, we reformulate, transform, and approximate the nonconvex problem to a quadratically constrained optimization problem, and develop ajoint beamforming and power allocation algorithm based on semidefinite relaxation to solve it. Second, to address the issue of high complexity in obtaining the optimal clusters, we propose a low-complexity algorithm to efficiently identify a set of promising clusters, forming as a candidate user partition. Based on these two algorithms, we design an algorithmic framework to iteratively perform them and to improve performance. By the algorithm design, the produced user partition can be further improved in later iterations, in order to further reduce power consumption. Numerical results demonstrate that the performance of the proposed solution with iterative updates for user clustering, and joint beamforming and power allocation optimization outperforms that of previous schemes."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a numerical solution of 2-D time-dependent coupled nonlinear system is discussed. Both Crank-Nicholson and alternating direction implicit methods were used to address the problems associated with nonlinear system. These schemes depict the second-order accuracy in space and time. Moreover, system of these equations that is concerned with the implicit scheme is very efficient and reliable for solving 2-D nonlinear coupled convection diffusion equations. In this system, algebraic difference equations are solved at each time level. In fact, in this paper, these methodologies were unified with iterative methods to resolve nonlinear systems. The procedures have been analyzed for their stability and convergence. Numerical results showed that the proposed alternating direction implicit scheme was very efficient and reliable for solving 2-D nonlinear coupled convection diffusion equations. The proposed methods can be implemented for fixing nonlinear problems arising in engineering and physics."
  },
  {
    "year": "2017",
    "abstract": "Resource allocation, or scheduling, is one of the main challenges that face supporting machine-to-machine (M2M) communications on long term evolution networks. M2M traffic has unique characteristics. It generally consists of a large number of small data packets, with specific deadlines, generated by a potentially massive number of devices contending over the scarce radio resources. In this paper, we introduce a novel M2M scheduling metric that we term the “statistical priority”. Statistical priority is a term that indicates the uniqueness of the information carried by certain data packets sent by machine-type communications devices (MTCDs). If an MTCD data unit is significantly dissimilar to the previously sent data, it is considered to carry non-redundant information. Consequently, it would be assigned higher statistical priority, and this MTCD should then be given higher priority in the scheduling process. Using this proposed metric in scheduling, the scarce radio resources would be used for transmitting statistically important information rather than repetitive data, which is a common situation in M2M communications. Simulation results show that our proposed statistical priority-based scheduler outperforms the other baseline schedulers in terms of having the least number of deadline misses (less than 4%) for critical data packets. In addition, our scheduler outperforms the other baseline schedulers in non-redundant data transmission as it achieves a success ratio of at least 70%."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a study on physical layer authentication problem for in vivo nano networks at terahertz (THz) frequencies. A system model based on envisioned nano network for in vivo body-centric nano communication is considered and distance-dependent pathloss based authentication is performed. Experimental data collected from THz time-domain spectroscopy setup shows that pathloss can indeed be used as a device fingerprint. Furthermore, simulation results clearly show that given a maximum tolerable false alarm rate, detection rate up to any desired level can be achieved within the feasible region of the proposed method. It is anticipated that this paper will pave a new paradigm for secured, authenticated nano network for future applications, e.g., drug delivery and Internet of nano-things-based intelligent office."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study a cooperative wireless relay network in which multiple sourcedestination pairs communicate via a decode-and-forward relay, which harvests energy from the source transmissions in the presence of an interfering signal. The goal is to efficiently distribute the relay's power among the different relay-destination (R - D) links. The outage probability and the throughput in the delaysensitive transmission mode are derived for the non-shared and several shared power allocation schemes. Numerical results show that the studied shared allocation schemes outperform the non-shared allocation scheme in terms of outage probability and throughput. Different shared allocation schemes are compared against each other in terms of outage probability, throughput, and fairness. The R - D channel dependent and the weighted-sum-rate maximization schemes achieve the best outage and throughput performances but require knowledge of the statistical channel state information at the relay node. The results also illustrate the tradeoff between the throughput and fairness of the different shared allocation schemes."
  },
  {
    "year": "2017",
    "abstract": "The development of mobile cloud computing technology has made location-based service (LBS) increasingly more popular. Given the continuous requests to cloud LBS servers, the amounts of location and trajectory information collected by LBS servers are continuously increasing. Privacy awareness for LBS has been extensively studied in recent years. Among the privacy concerns about LBS, trajectory privacy preservation is particularly important. Based on privacy preservation models, previous work have mainly focused on peer-to-peer and centralized architectures. However, the burden on users is heavy in peer-to-peer architectures, because user devices need to communicate with LBS servers directly. In centralized architectures, a trusted third party (TTP) is introduced, and acts as a bridge between users and the LBS server. Anonymity technologies, such as k-anonymity, mix-zone, and dummy technologies, are usually implemented by the TTP to ensure safety. There are certain drawbacks in TTP architectures: Users have no physical control of the TTP. Moreover, the TTP is more attractive to adversaries, because substantially more sensitive information is stored by the TTP. To solve the above-mentioned problems, in this paper, we propose a fog structure to store partial important data with the dummy anonymity technology to ensure physical control, which can be considered as absolutely trust. Compared with cloud computing, fog computing is a promising technique that extends the cloud computing to the edge of a network. Moreover, fog computing provides local computation and storage abilities, wide geo-distribution, and support for mobility. Therefore, mobile users' partial important information can be stored on a fog server to ensure better management. We take the principles of similarity, intersection, practicability, and correlation into consideration and design a dummy rotation algorithm with several properties. The effectiveness of the proposed method is validated through extensi..."
  },
  {
    "year": "2017",
    "abstract": "The ambulatory monitoring of human movement can provide valuable information regarding the degree of functional ability and general level of activity of individuals. Since walking is a basic everyday movement, automatic step detection or step counting is very important in developing ambulatory monitoring systems. This paper is concerned with the development and the preliminary validation of a step counter (SC) designed to operate also in conditions of slow and intermittent ambulation. The SC was based on processing the accelerometer data measured by a Gear 2 smartwatch running a custom wearable app, named ADAM. A data set of eight users, for a total of 80 trials, was used to tune ADAM. Finally, ADAM was compared with two different commercial SCs: the native SC running on the Gear 2 smart watch and a waist-worn SC, the Geonaute ONSTEP 400. A second data set of eight additional users for a total of 80 trials was used for the assessment study. The three SCs performed quite similarly in conditions of normal walking over long paths (1%-3% of mean absolute relative error); ADAM outperformed the two other SCs in conditions of slow and intermittent ambulation; the error incurred by ADAM was limited to 5%, which is significantly lower than errors of 20%-30% incurred by the two other SCs."
  },
  {
    "year": "2017",
    "abstract": "The adoption of Agile software development approaches has been widespread. One well-known Agile approach is extreme programming, which encompasses twelve practices of which pair programming is one of them. Although various aspects of pair programming have been studied, we have not found, under a traditional setting of pair programming, studies that examine the impact of using a tool support, such as an integrated development environment (IDE) or a simple text editor. In an attempt to obtain a better understanding of the impact of using an IDE in this field, we present the results of a controlled experiment that expose the influence on quality, measured as the number of defects injected per hour, and cost, measured as the time necessary to complete a programming assignment, of pair and solo programming with and without the use of an IDE. For quality, our findings suggest that the use of an IDE results in significantly higher defect injection rates (for both pairs and solos) when the programming assignment is not very complicated. Nevertheless, defect injection rates seem to decrease when pairs work on more complicated programming assignments irrespective of the tool support that they use. For cost, the programming assignment significantly affects the time needed to complete the assignment. In relation to the programming type, pairs and solos performed in a similar way with regards to quality and cost."
  },
  {
    "year": "2017",
    "abstract": "Desertification is one of the most important problems driven by global climatic change. There are many factors that contribute to the environmental degradation of the Sahara desert surroundings. The first one is related to human activities, such as change of land use. Other factors include natural degradation due to change in temperature, humidity, and wind. All of these complex causes may lead to the movement of sand from the desert to other places, such as cities and roads, affecting everyday life. For that reason, desertification is being analyzed by governmental agencies in the affected countries. This paper studies this phenomenon in the city of Biskra, Algeria, using optical satellite images taken from the freely available Landsat program. It presents a methodology that could help in the temporal evaluation of the desertification process. Land use and land cover change detection in a period of 25 years has been carried out using a support vector machine per object classification. Change indices have been also employed for assessing the degradation. Excellent results using low human operator cost have been fully validated by visual inspection."
  },
  {
    "year": "2017",
    "abstract": "High-frequency pulsating dc-link inverter has higher power density than the conventional fixed dc-link inverter (FDCLI), and more complicate modulation methods owing to the coupling between the front end and the last stage links. This paper analyzes the zero portion effects on the output voltage of the railway auxiliary inverter with pulsating dc-link based on the approximately independent hybrid modulation technique, and proposes a carrier phase-shift optimization strategy. Average mathematical models of output voltage are built, and Fourier series of the voltage difference is derived for further analysis. The output voltage performances under different conditions are compared in time-domain simulation. The results of simulation and experiments show that the proposed phase-shift approach reduces the zero portion effects and performs as well as that of FDCLI."
  },
  {
    "year": "2017",
    "abstract": "End-to-end transmission is an essential pattern in current Internet. It had brought obvious conveniences and potential hazard simultaneously. New network technology provides plenty of opportunities to avoid the harmful influences. After reviewing the identifier-based network, a candidate solution of future network, we proposed a smart collaborative connection management scheme for improving the dependability. Comparing with the conventional approaches, our scheme can protect the hosts via intermediate network equipments. During transmission process, the current usage pattern will not be influenced. Traditional unicast can be easily and smoothly enabled. The details of the scheme design are presented via four perspectives of connection identifier, i.e., communication mode, generation, distribution, and deployment. Then the supporting approaches of multipath transport, service migration, network mobility, P2P distribution, and application layer multicast are carefully investigated. The results of implementation and validation illustrate that the performances of new scheme are acceptable. We expect that this paper could provide a compatible and effective solution for both current and future Internet."
  },
  {
    "year": "2017",
    "abstract": "A new nonlinear robust control scheme is proposed and investigated for the trajectory tracking control problem of an underwater vehicle-manipulator system (UVMS) using the discrete time delay estimation (DTDE) technique. The proposed control scheme mainly has two parts: the DTDE part and the desired dynamics part. The former one is applied to properly estimate and compensate the complex unknown lumped dynamics of the system, using the intentionally time-delayed system's information. The latter one is used to obtain the desired dynamic characteristic of the closed-loop control system. Thanks to the DTDE technique, the proposed control scheme no longer requires the detailed system dynamic information or the acceleration signals, bringing in good feasibility for actual applications and satisfactory control performance. The stability of the closed-loop control system is analyzed and proved using the bounded input bounded out stability theory. Finally, nine degree of freedoms (DOFs) simulation and seven DOFs pool experiment studies were conducted to demonstrate the effectiveness of the proposed control scheme with an UVMS developed in our laboratory. Corresponding results show that our proposed control scheme can ensure satisfactory control performance with relative small control gains and obtain a precision of 0.064 m for the end effector in the task space."
  },
  {
    "year": "2017",
    "abstract": "Epidemic dynamics, a kind of biological mechanisms describing microorganism propagation within populations, can inspire a wide range of novel designs of engineering technologies, such as advanced wireless communication and networking, global immunization on complex systems, and so on. There have been many studies on epidemic spread, but most of them focus on closed regions where the population size is fixed. In this paper, we proposed a susceptible-exposed-infected-recovered model with a variable contact rate to depict the dynamic spread processes of epidemics among heterogeneous individuals in open finite regions. We took the varied number of individuals and the dynamic migration rate into account in the model. We validated the effectiveness of our proposed model by simulating epidemics spread in different scenarios. We found that the average infected possibility of individuals, the population size of infectious individuals in the regions, and the infection ability of epidemics have great impact on the outbreak sizes of epidemics. The results demonstrate that the proposed model can well describe epidemics spread in open finite regions."
  },
  {
    "year": "2017",
    "abstract": "We propose a dynamical way to set the process error covariance matrix (Q) for a constant velocity (CV) model Kalman filter. We are able to achieve the best possible solution for the estimated state, in the sense of forecast error, while significantly reducing the convergence time at no significant computational cost. No assumptions regarding the statistical nature of the observed process are made and no prior knowledge of the system is required. To achieve this, we adopt a recently proposed performance index for the Kalman filter, we map the best Q for an ample range of model deviations (accelerations) and dynamically set the best possible Q for the CV filter by identifying the average acceleration of the measured signal online. We demonstrate our scheme ability by filtering simulated trajectories with low, medium, and high signal-to-noise ratios. We also track a real erratic target and compare our filter prediction with the best possible a posteriori CV filter."
  },
  {
    "year": "2017",
    "abstract": "We design and implement a novel network virtualization hypervisor (NVH), which leverages source routing (SR) and provides network programmability based on the protocol-oblivious forwarding flow instruction set (POF-FIS), to realize protocol-independent virtual software-defined networks (vSDNs). The NVH, namely SR-PVX, uses a novel SR-based mechanism to ensure that the substrate switches can process packets from vSDNs with very small flow-table consumption. We design the network architecture, packet format, and packet processing procedure, and implement them to experimentally demonstrate that SR-PVX can control substrate POF switches to accomplish the SR-based vSDN slicing. We also perform an experiment to show that the POF-enabled vSDN created by SR-PVX can easily realize a stateful firewall with its POF-FIS programmability."
  },
  {
    "year": "2017",
    "abstract": "Enhanced with wireless power transfer capability, cloud radio access network (C-RAN) enables energy-restrained mobile devices to function uninterruptedly. Beamforming of C-RAN has potential to improve the efficiency of wireless power transfer, in addition to transmission data rates. In this paper, we design the beamforming jointly for data transmission and energy transfer, under finite fronthaul capacity of C-RAN. A non-convex problem is formulated to balance the fronthaul requirements of different remote radio heads (RRHs). Norm approximations and relaxations are carried out to convexify the problem to second-order cone programming (SOCP). To improve the scalability of the design to large networks, we further decentralize the SOCP problem using the alternating direction multiplier method (ADMM). A series of reformulations and transformations are conducted, such that the resultant problem conforms to the state-of-the-art ADMM solver and can be efficiently solved in real time. Simulation results show that the distributed algorithm can remarkably reduce the time complexity without compromising the fronthaul load balancing of its centralized counterpart. The proposed algorithms can also reduce the fronthaul bandwidth requirements by 25% to 50%, compared with the prior art."
  },
  {
    "year": "2017",
    "abstract": "The (n, k) combination property (CP) is defined as follows: k source packets are mapped into n ≥ k packets and any k out of these n packets are able to recover the information of the original k packets. This (n, k) CP is extensively needed by cloud storage service providers. Reed-Solomon (RS) codes possess CP at the cost of high encoding and decoding complexity for two reasons: operation over a large-size finite field and time-consuming matrix inversion operation. By operating within the binary field and by allowing only zigzag decoding at the decoder, binary zigzag decoding that possesses CP lowers the decoding complexity significantly. The drawback is that storage room overhead is needed. Corresponding to this storage room overhead, in the data reconstruction process, intuitively fetching k whole stored packets will consume overhead bandwidth. In this paper, a data reconstruction scheme that is optimal in terms of bandwidth consumption is designed, where optimal means the bandwidth consumption is equal to the volume of data to be reconstructed, namely, no overhead bandwidth is needed. To do that, a universal method of fetching sub-packet is proposed, and its corresponding decoding method is also designed."
  },
  {
    "year": "2017",
    "abstract": "Regenerating codes (RGCs) have recently been proposed to reduce the repair traffic of (n,k) erasure-coded distributed storage systems. Moreover, RGCs can also be used in a scalable distributed storage scenario wherenis increased (decreased) to upgrade (degrade) redundancy while maintaining the maximum distance separable property of erasure codes. In this paper, we propose a new application of minimum storage regenerating (MSR) codes in storage scalability. The connection between repairing invalid nodes and adding new nodes suggests that the two processes can be unified in the same framework. We consider both single and multiple node situations, and two methods for constructing multiple nodes are proposed: concurrent and sequential. We focus on proving the achieved capability of concurrent MSR that can consume minimum traffic for generating multiple nodes. Because concurrent MSR is sensitive to both the number of helpers and added nodes, sequential methods make scalable MSR generalizable. The examples show that the scalable MSR codes have the same advantage of saving network traffic as repairing failures."
  },
  {
    "year": "2017",
    "abstract": "An automatic tonsillitis monitoring and detection system aims for personal use and requires mobility, a compact size, and a light weight with reliable functionality. This paper proposes the design and implementation of automatic tonsillitis monitoring and detection system. In this system, a pipeline concept is utilized for data transmission among processes, and parallel processing is employed for feature extraction by dividing an image into an appropriate number of blocks for processing. The performance of the proposed method was evaluated by experiments using prototype software and hardware systems of our design, and the results show accuracies of 96.4% and 91.8%, respectively, for 159 tonsillitis samples."
  },
  {
    "year": "2017",
    "abstract": "Background subtraction is a key prerequisite for a wide range of image processing applications due to its pervasiveness in various contexts. In particular, video surveillance highly requires the reliable background subtraction for further operations, such as object tracking and recognition, and thus, enormous efforts for this task have been devoted in recent decades. However, the path of technological evolution for background subtraction has now faced with an important issue that has started to be resolved: sensitivity to dynamic changes of scene contexts (e.g., illumination variations and moving backgrounds). Such dynamic changes are hardly tolerated by most of traditional background models, since they yield the drastically different statistics of pixel values even onto the relevant position between consecutive frames. To resolve this problem, many researchers in this field have developed robust and efficient methods. The goal of this paper is to provide a comprehensive review with a special attention to schemes related to handling varying illuminations frequently occurring in the outdoor surveillance scenario. This paper covers a systematic taxonomy, methodologies, and performance evaluations on benchmark databases, and also provides constructive discussions for the smart video surveillance under unconstrained outdoor environments."
  },
  {
    "year": "2017",
    "abstract": "Just noticeable difference (JND) model plays an important role in removing perceptual redundancies for image/video compression. However, the existing subband-based JND models have two limitations: one is the evaluation of contrast masking (CM) effect is not comprehensive; the other is that the operation within cross domain is computational complexity. In this paper, we propose a new orientation regularity-based JND model to solve these problems in the discrete cosine transform (DCT) domain. Inspired by the structure regularity extraction in the human brain, we suggest that orientation features play an important role in the analysis of visual content. By deducing the DCT function, the orientation information is first analyzed with the DCT coefficients along different directions, and the orientation regularity is calculated with the coefficient distribution. Then, according to the orientation regularity and the frequency texture energy, the DCT blocks are classified into five types, i.e., smooth, orderly edge, disorderly edge, orderly texture, and disorderly texture. By combining these block types with their human visual system sensitivities, a more accurate CM model is proposed in a DCT domain. Finally, by incorporating the contrast sensitivity function and luminance adaptation effect, a novel DCT-based JND model is established. Since the proposed model introduces a more accurate CM model and performs only in a DCT domain, it is more efficient and concise than the state-of-the-art DCT-based JND models in theory and practice. The experimental results also show that the proposed JND model has a superior performance without cross domain."
  },
  {
    "year": "2017",
    "abstract": "Online hyper-heuristic selection is a novel and powerful approach to solving complex problems. This approach dynamically selects, based on the state of a given solution, the most promising operator (from a pool of operators) to continue the search process. The dynamic selection is usually based on the analysis of the latest applications of a given operator during actual execution, estimating the potential success of the operator at the current solution state. The estimation can be made by evolvability metrics. Calculating an evolvability metric is computationally expensive since it requires the generation and evaluation of a neighborhood of solutions. This paper aims to estimate the potential success of an operator for a given solution state by using a pre-trained neural network; known as a parallel perceptron. The proposal accelerates the online selection process, allowing us to achieve better performance than hyper-heuristic models, which directly use evolvability functions."
  },
  {
    "year": "2017",
    "abstract": "This paper evaluated three methods of atrial fibrillation (AF) detection in Korean patients using 149 records of photoplethysmography signals from 148 participants: the k-nearest neighbor (kNN), neural network (NN), and support vector machine (SVM) methods. The 149 records are preprocessed to calculate the root-mean square of the successive differences in the R-R intervals and Shannon entropy which are validated from x-means and Massachusetts Institute of Technology and Beth Israel Hospital database for the features for AF detection. A smartphone camera was used to obtain photoplethysmography signals. Clinicians labeled 29 records by referring to the electrocardiogram signals. These labeled records were used as a ground truth set to evaluate the accuracy of each method. In the experiments, the kNN, NN, and SVM methods achieved 98.65%, 99.32%, and 97.98% accuracies, respectively."
  },
  {
    "year": "2017",
    "abstract": "Light detection and ranging (LIDAR) has become a part and parcel of ongoing research in autonomous vehicles. LIDAR efficiently captures data during day and night alike; yet, data accuracy is affected in altered weather conditions. LIDAR data fusion with sensors, such as color camera, hyperspectral camera, and RADAR, proves to be a viable solution to improve the quality of data and add spectral information. LIDAR 3-D point cloud containing intensity data are transformed to 2-D intensity images for the said purpose. LIDAR produces large point cloud, but, while generating images for limited field of view, data sparsity results in poor quality images. Moreover, 3-D to 2-D data transformation also involves data reduction, which further deteriorates the quality of images. This paper focuses on generating intensity images from LIDAR data using interpolation techniques, including bi-linear, natural neighbor, bi-cubic, kriging, inverse distance, and weighted and nearest neighbor interpolation. The main focus is to test the suitability of interpolation methods for 2-D image generation, and analyze the quality of the generated 2-D image. Image similarity metrics, such as root mean square error, normalized least square error, peak signal-to-noise ratio, correlation, difference entropy, mutual information, and structural similarity index measurement, are utilized for camera and LIDAR image matching, and their ability to compare images from heterogeneous sensors is also analyzed. Generated images can further be used for data fusion purpose. Images generated using LIDAR points have a relevant distance matrix as well, which can be used to find the distance of any given pixel from the image. In addiiton, the accuracy of interpolated distance data is evaluated as well by comparing it with the original distance values of traffic cones placed in front of vehicle. Results show that the inverse distance weighted interpolation outperforms other selected methods in 2-D image quality, and i..."
  },
  {
    "year": "2017",
    "abstract": "Based on the limbic system theory of mammalian emotional brain, supervised brain emotional learning-based pattern recognizer (BELPR) has been recently proposed for multi-input and multi-output classification problems. It offers features like: decreased time and spatial complexity, faster training and higher accuracy. BELPR has been deployed to classify a number of benchmark datasets and has demonstrated its superior performance compared with the conventional multilayer perceptron network. The goal of this paper is to further enhance the classification accuracy of BELPR through integration with Neo-Fuzzy Neurons (NFN). The network built using NFN shares many of the same characteristics as BELPR, such as: simplicity, transparency, accuracy, and lower computational complexity. With this view in mind, this paper proposes a new neuro-fuzzy hybrid classification network: Neo-Fuzzy supported brain emotional learning-based pattern recognizer (NFBELPR), which will preserve the features of both networks, while simultaneously improving the performance of BELPR. The NFBELPR model can be considered as a group of two networks depending upon the level of integration of NFN and BELPR. When the integration of NFN is only considered in the orbitofrontal cortex section of BELPR, the resulting classification model is termed as partially integrated NFBELPR. In cases, when the integration is considered both in the OFC and amygdala sections of BELPR, the resulting classification model becomes fully integrated NFBELPR. The proposed NFBELPR networks are implemented in MATLAB®R2009b programming environment to classify a number of benchmark datasets. They are found to achieve higher classification accuracy when compared with BELPR and some state of the art classification networks."
  },
  {
    "year": "2017",
    "abstract": "Content dissemination in opportunistic networks has attracted much attention in recent years. A critical challenge associated with content dissemination in opportunistic networks is delay optimization. We discover that the address-based content dissemination is a major reason for delays because one message travels to one node at a time. We further discover that a message sometimes does not reach subscribers because nodes are sparse in opportunistic networks. Motivated by group purchase online, we propose a group-purchase scheme (GPSCH) to solve this problem. In GPSCH, nodes participate in group purchase to subscribe for messages, whereas message carriers publish messages to nodes upon subscription. In addition, we study the communication probabilities between messages and nodes to forward messages. We also provide a delay analysis of our proposed scheme. Our theoretical analysis and simulation results demonstrate that the GPSCH performs well in reducing delay time, by at least 75%, compared with typical routing schemes."
  },
  {
    "year": "2017",
    "abstract": "Visual place recognition (VPR) in changing environments is an urgent challenge for long-term autonomous navigation. One recent ConvNet landmark-based approach exploits region landmarks coupled with ConvNet features to match images, and the approach has shown promising results under significant environmental and viewpoint changes. In this paper, we propose a robust ConvNet landmark-based system for VPR in changing outdoor roadway environments by extension of this approach from the following two aspects. First, our method utilizes more discriminative landmarks obtained by a novel refinement method called SemLandmarks, which leverages roadway scene semantic information to screen landmarks directly detected by an existing object proposal method. Second, our method improves the accuracy of image matching by introducing consistent spatial constraints based on the use of geometry-preserving landmark pairs. Experimental results demonstrate that our method significantly improves the state of the art in VPR in terms of recognition accuracy on three challenging benchmark data sets with various environmental and viewpoint changes."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an enhanced efficiency 3-D convolution operator based on optimal field programmable gate array (FPGA) accelerator platform. The proposed system takes advantages of the intermediate data delay lines, implemented in an FPGA, to avoid loading repetition of the input feature maps. This 3-D convolution accelerator performs 268.07 giga operations per second at 100-MHz operation frequency, with 330-mW power consumption. We experimentally demonstrate the enhanced efficiency of the proposed convolution accelerator, in comparison with the conventional technologies. The proposed 3-D convolution accelerator may find interesting applications in neural networks and video processing."
  },
  {
    "year": "2017",
    "abstract": "Inspired by the importance of self-representation and structure-preserving ability of features, in this paper, we propose a novel unsupervised feature selection algorithm named structure-preserving non-negative feature self-representation (SPNFSR). In this algorithm, each feature in high-dimensional data can be represented by the linear combination of other features. Then, to exploit the structure-preserving ability of features, we construct a low-rank representation graph, which takes the local and global structures into consideration to maintain the intrinsic structure of the data space. Finally, an l2,1-norm regularization and the non-negative constraint are imposed on the representation coefficient matrix with the goal of achieving feature selection in the batch mode. Moreover, we provide a simple yet efficient iterative update algorithm to solve SPNFSR, as well as the convergence analysis of the proposed algorithm. The performance of the proposed approach is illustrated by six publicly available databases. In comparison with the state-of-the-art approaches, the extensive experimental results show the advantages and effectiveness of our approach."
  },
  {
    "year": "2017",
    "abstract": "The most well-known conventional speech enhancement algorithms introduce unwanted artifact noise and speech distortion to the enhanced signal. Reducing the effects of such issues require more robust linear and non-linear estimators. This paper proposes new optimum linear and non-linear Laplacian distribution-based estimators. The proposed estimators are derived based on a minimum mean squared error (MMSE) sense to minimize the distortion in different conditions of the underlying speech. Thus, artifact noise is reduced without compromising the noise reduction process. The analytical solutions of the Laplacian distribution-based estimators, linear bilateral Laplacian gain estimator (LBLG), and non-linear bilateral Laplacian gain estimator (NBLG), are presented. The proposed estimators are implemented in three steps. First, the observation signal is decorrelated through a real transform domain to obtain its transform coefficients. Second, the proposed estimators are applied to estimate the clean speech signal from the noisy signal in the decorrelated domain. Finally, the inverse of the real transform is applied to obtain the original speech signal in the time domain. Two conditions in these estimators account for interference events between the speech signal and noise coefficients in the decorrelated domain. Moreover, a mathematical aspect of mean square error of LBLG is evaluated, which presents a significant improvement over other methods. Furthermore, a comprehensive description of the whole variations of the LBLG and NBLG gains characteristics is presented. A comparative evaluation is performed with effective quality metrics, segmental signal-to-noise ratio and perceptual evaluation of speech quality, to demonstrate the advantage and effectiveness of the proposed estimators. The performance of the proposed estimators outperformed other methods, which are the traditional MMSE approach, perceptually motivated Bayesian estimator, dual gain Wiener estimator, and dual M..."
  },
  {
    "year": "2017",
    "abstract": "Far-edge analytics refers to the enablement of data mining algorithms in far-edge mobile devices that are part of mobile edge cloud computing (MECC) systems. Far-edge analytics enables data reduction in mobile environments, hence reducing the data transfer rate and bandwidth utilization cost for mobile-edge communication. In addition, far-edge analytics facilitates local knowledge availability to enable personalized mobile data stream mining applications. Existing literature mainly addresses classification and clustering problems in far-edge mobile devices, but the problem of frequent pattern mining (FPM) remains unexplored. This paper presents the results of an experimental study on the performance profiling of frequent pattern mining algorithms. We developed a real mobile application for performance analysis and profiling of 21 FPM algorithms with various real data sets in terms of execution time, storage complexity, sparsity, density, and data set size. According to the experimental results, large-sized data sets with high sparsity increase computational and storage cost in far-edge mobile devices. To address these issues, we propose a framework and discuss the relevant research challenges for seamless execution of FPM algorithms in MECC systems."
  },
  {
    "year": "2017",
    "abstract": "Global Positioning System technology has been widely used in vehicle tracking and road planning applications. An enormous amount of data concerning the trajectories of vehicles has been collected and stored for tracking purposes. A trajectory contains not only the footprints of a moving object but also additional information, such as speed and stopping points. Therefore, the large-scale trajectory data sets provide rich information and are currently attracting considerable attention; there have been many successful studies of event detection based on trajectory data. However, most of these studies have focused only on vehicles traveling in a road network and have note considered maritime trajectories. A maritime trajectory also contains auxiliary data (e.g., speed and rotation) in addition to the movements of a ship. However, ships are not bound to road networks, and consequently, it is difficult to apply traditional mining algorithms based on road networks. In addition, even if the amount of maritime trajectory data is very large, these data are also spatially sparse, which will significantly reduce the effectiveness of most existing mining algorithms. In this paper, we propose a new method of abnormal trajectory detection to address this problem. This method can detect abnormal vessel trajectories from Automatic Identification System (AIS), records for vessels via our feature learning algorithm. To reduce the search space, we invoke reference points as well as the Piecewise Linear Segmentation (PLS), algorithm to compress the trajectories without losing important information. A time-aware and spatially correlated collaborative algorithm is proposed to increase the density of the trajectories to improve the accuracy of the detection algorithm, which is based on Dynamic Time Warping (DTW). Finally, we report experiments conducted on a real-world data set, which demonstrate that the proposed detection method can detect anomalous trajectories effectively."
  },
  {
    "year": "2017",
    "abstract": "A data-driven modeling approach is proposed for using system integration scaling factors and positioning performance of an exposure machine system to build models for predicting positioning errors and for analyzing parameter sensitivity. The proposed approach uses a uniform experimental design (UED), multiple regression (MR), back-propagation neural network (BPNN), adaptive neuro-fuzzy inference system (ANFIS), and analysis of variance (ANOVA). The UED reduces the number of experimental runs needed to collect data for modeling. The MR, BPNN, and ANFIS are used to construct positioning models of an exposure machine system. The significant system integration scaling factors are determined by ANOVA. The inputs to the data-driven model are system integration scaling factors fx, fy, and fq, and the output is the positioning error. The UED was used to collect 41 experimental data, which comprised 0.0595% of the full-factorial experimental data. Performance tests demonstrated the excellent performance of the UED in collecting data used to build the MR, BPNN, and ANFIS data-driven models. The data-driven models can accurately predict positioning errors during validation. In addition, a sensitivity analyses of parameters showed that design parameters fxand fyhave the greatest influence on positioning performance."
  },
  {
    "year": "2017",
    "abstract": "Electrification of transportation has drawn increasing attention for the sake of low-pollution emission and high-fuel economy. Scientific scale forecasting of electric vehicles (EVs) is fundamental to promote EVs’ integration for transportation and electric power industries. To capture the evolution pattern, a system dynamics (SD) approach is proposed to simulate and forecast the scale of the EVs. The proposed SD model can integrate various factors and quantify their relationship by comprehensive reasoning. Causal loop diagrams are designed to describe the relationship between factors and variables, and their quantifications are formulated by different business models and surveys. The main procedure for simulation includes survey, problem analysis, variable definition, feedback analysis, and model building. The effectiveness of the SD approach is verified by case studies. Furthermore, sensitivity analysis of the key factors, such as fuel price, subsidy policy, and so on, is also conducted."
  },
  {
    "year": "2017",
    "abstract": "Current resource allocation techniques in cellular networks are largely based on single-slope path loss model, which falls short in accurately capturing the effect of physical environment. The phenomenon of densification makes cell patterns more irregular; therefore, the multi-slope path loss model is more realistic to approximate the increased variations in the links and interferences. In this paper, we investigate the impacts of multi-slope path loss models, where different link distances are characterized by different path loss exponents. We propose a framework for joint user association, power and subcarrier allocation on the downlink of a heterogeneous network (HetNet). The proposed scheme is formulated as a weighted sum rate maximization problem, ensuring the users' quality-of-service requirements, namely users' minimum rate, and the base stations' (BSs) maximum transmission power. We then compare the performance of the proposed approach under different path loss models with demonstrate the effectiveness of dual-slope path loss model in comparison to the single-slope path loss model. Simulation results show that the dual-slope model leads to significant improvement in network's performance in comparison to the standard single-slope model by accurately approximating the path loss exponent dependence on the link distance. Moreover, it improves the user offloading from macrocell BS to small cells by connecting the users to nearby BSs with minimal attenuation. It has been shown that the path loss exponents significantly influence the user association lying across the critical radius in the case of the dual-slope path loss model."
  },
  {
    "year": "2017",
    "abstract": "Existing extended one-versus-rest multi-label support vector machine (OVR-ESVM) adopting non-linear kernel is seriously restricted by excessive training time when it is applied to large-scale data set. In order to overcome this problem, we improve the OVR-ESVM by introducing the principle of approximate extreme points and new approximate ranking loss to construct a novel extended OVR-ESVM using approximate extreme points (AEML-ESVM). By optimizing only on the representative set which can be acquired via adopting the approximate extreme points method, the AEML-ESVM classification algorithm can substantially shorten the training time and its classification performance is comparable to that of the OVR-ESVM classification algorithm. And it uses the new approximate ranking loss as empirical loss term to exploit label correlation of individual instance directly. Experimental study on three benchmark large-scale data sets illustrates that AEML-ESVM classification algorithm can reduce training time greatly and achieve comparable classification performance with OVR-ESVM classification algorithm. And it is also superior to the existing fast multi-label SVM classification algorithms in terms of classification performance and training time."
  },
  {
    "year": "2017",
    "abstract": "We theoretically analyze outage probabilities of the lossy-forward (LF), decode-andforward (DF), and adaptive decode-and-forward (ADF) relaying techniques, with the aim of characterizing the impact of the spatial and temporal correlations of the fading variations. First, the exact outage probability expressions are analytically obtained for LF, DF, and ADF relaying assuming each link suffers from statistically independent Rayleigh fading. Then, approximated, yet accurate closed-form expressions of the outage probabilities for the relaying schemes are derived. Based on the expressions, diversity and coding gains are found. The mathematical methodology for the derivation of the explicit outage probability is further extended to the case, where the account is taken of the spatial and temporal correlations of the fading variations. The diversity gains with LF, DF, and ADF are then derived in the presence of the correlations. It is found out that the three techniques can achieve full diversity, as long as the fading variations are not fully correlated. We then investigate the optimal relay location and the optimal power allocation for the three relaying techniques. It is shown that the optimal solutions can be obtained under the framework of convex optimization. It is revealed that in correlated fading, the relay should move close to the destination or allocate more transmit power to the relay for achieving lower outage probabilities, compared with the case in independent fading."
  },
  {
    "year": "2017",
    "abstract": "A large number of new consumer and industrial applications are likely to change the classic operator’s business models and provide a wide range of new markets to enter. This paper analyzes the most relevant 5G use cases that require ultra-low latency, from both technical and business perspectives. Low latency services pose challenging requirements to the network, and to fulfill them, operators need to invest in costly changes in their network. In this sense, it is not clear whether such investments are going to be amortized with these new business models. In light of this, specific applications and requirements are described and the potential market benefits for operators are analyzed. Conclusions show that the operators have clear opportunities to add value and position themselves strongly with the increasing number of services to be provided by 5G."
  },
  {
    "year": "2017",
    "abstract": "Conventional compressive sensing-based data gathering (CS-DG) algorithms require a large number of sensors for each compressive sensing measurement, thereby resulting in high energy consumption in clustered wireless sensor networks (WSNs). To solve this problem, we propose a novel energy-efficient CS-DG algorithm, which exploits the better reconstruction accuracy of the adjacency matrix of an unbalanced expander graph. In the proposed CS-DG algorithm, each measurement is the sum of a few sensory data, which are jointly determined by random sampling and random walks. Through theoretical analysis, we prove that the constructed M × N sparse binary sensing matrix is the adjacency matrix of a (k, ε) unbalanced expander graph when M = O (k log N/k) and t = O (Nc/(kq)) for WSNs with Nc clusters, where 0 ≤ q ≤ 1 and Nc> k. Simulation results show our proposed CS-DG has better performance than existing algorithms in terms of reconstruction accuracy and energy consumption. When hybrid energy-efficient distributed clustering algorithm is used, to achieve the same reconstruction accuracy, our proposed CS-DG can save energy by at least 27.8%."
  },
  {
    "year": "2017",
    "abstract": "Reliability is one of the most important communication metrics in wireless body area networks especially for medical applications. However, traditional one-hop transmission power control methods failed to guarantee the reliability when the transmission distance is large. Two-hop relaying transmission can provide reliable transmission but energy consumptions for relay nodes are high resulting in the reduction of network lifetime. In this paper, a relay-aided transmission power control method is proposed to provide reliable transmission and at the same time alleviate the relaying burden on relay nodes. The proposed method automatically switches transmitter's transmission strategy between the direct transmission and the relay-aided transmission based on the channel condition to address long distance problem and then adaptively adjusts the transmission power according to the received signal strength indicator feedback to guarantee the reliable transmission and conserve the energy of relay nodes as much as possible. In addition, parameters in the proposed method are tunable according to the application scenarios to make tradeoff between reliability and energy efficiency. The simulation results demonstrate that the proposed method can effectively guarantee the transmission reliability and conserve the energy of relay nodes, which in turn prolongs the network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Security of global navigation satellite systems (GNSS) is important since the navigation capability provided by the GNSS is a key enabler for many civilian and military applications. Spoofing attacks threaten the GNSS security and have caught much attention recently. The spatial processing method is one of the most robust GNSS spoofing countermeasures, which detects spoofing signals with a moving antenna or multi-antenna, but it cannot work in a static single-antenna receiver. In this paper, we propose a spoofing countermeasure based on the power measurements of a single rotating antenna, which can be implemented in a static receiver. The method takes advantages of the anisotropy of the antenna's gain pattern to detect spoofing signals. When the antenna is rotating, the power measurements of the spoofing signals coming from the same direction change similarly and the correlation coefficients between them are close to 1, but the power measurements of the authentic signals are uncorrelated. Since it is not easy to evaluate the anti-spoofing performance of the correlation coefficient, another metric named phase difference of power measurements is proposed. Its theoretical performance is derived based on generalized likelihood ratio test and validated with simulations. Actual experiments indicate that both the simulated and meaconing spoofing signals can be distinguished from the authentic ones, and the method can be implemented in a static or low-dynamic conventional receiver, only with an additional low-cost rotary table."
  },
  {
    "year": "2017",
    "abstract": "Turbo compressed sensing (Turbo-CS) is an efficient iterative algorithm for sparse signal recovery with partial orthogonal sensing matrices. In this paper, we extend the Turbo-CS algorithm to solve compressed sensing problems involving a more general signal structure, including compressive image recovery and low-rank matrix recovery. A main difficulty for such an extension is that the original Turbo-CS algorithm requires a prior knowledge of the signal distribution that is usually unavailable in practice. To overcome this difficulty, we propose to redesign the Turbo-CS algorithm by employing a generic denoiser that does not depend on the prior distribution, and hence the name denoising-based Turbo-CS (D-Turbo-CS). We then derive the extrinsic information for a generic denoiser by following the Turbo-CS principle. Based on that, we optimize the parametric extrinsic denoisers to minimize the output mean-square error (MSE). Explicit expressions are derived for the extrinsic SURE-LET denoiser used in image denoising and also for the singular value thresholding denoiser used in low-rank matrix denoising. We find that the dynamics of D-Turbo-CS can be well described by a scaler recursion called MSE evolution, similar to the case for Turbo-CS. Numerical results demonstrate that D-Turbo-CS considerably outperforms the counterpart algorithms in both reconstruction quality and running time."
  },
  {
    "year": "2017",
    "abstract": "The periocular region has recently emerged as a standalone biometric trait, promising attractive tradeoff between the iris alone and the entire face, especially for cases where neither the iris nor a full facial image can be acquired. This advantage provides another dimension for implementing a robust biometric system performed in non-ideal conditions. Global features [local binary pattern (LBP), Histogram of Gradient (HOG)] and local features have been introduced; however, the performance of these features can deteriorate for images captured in unconstrained and less-cooperative conditions. A particular set of higher order spectral (HOS) features have been proved to be invariant to translation, scale, rotation, brightness level shift, and contrast change. These properties are desirable in the periocular recognition problem to deal with the non-ideal imaging conditions. This paper investigates the HOS features in different configurations for the periocular recognition problem under non-ideal conditions. Specifically, we introduce a new sampling approach for the periocular region based on an elliptical coordinate. This non-linear sampling approach is then combined with the robustness of the HOS features for encoding the periocular region. In addition, we also propose a new technique for combining left and right perioculars. The proposed feature-level fusion approach is based on the state-of-the-art bilinear pooling technique to allow efficient interaction between the features of both perioculars. We show the validity of the proposed approach in encoding discriminant features outperforming or comparing favorably with the state-of-the-art features on the two popular data sets: Face Recognition Grand Challenge and Japanese Female Facial Expression."
  },
  {
    "year": "2017",
    "abstract": "The baseline concept for a multispectral drone detection (MSDD) system for use in airports is generated. The baseline development process is based on a modified system of systems architecting with ilities (SAI) method. The solution uses multiple independent sensors, which when the sensor outputs are combined, provide functionality that the individual systems were never intended to provide. Also, several sensors are pre-existing and have their own funding, operations, and management. The problem of drone detection is described and examples are given, which justify the need for the system. Then the specific need for airport protection is described. The result is a feasible baseline design that is capable of meeting the need."
  },
  {
    "year": "2017",
    "abstract": "Human brain has a complex structure with the billions of neurons, so it is a difficult and challenging task to predict the behavior of human brain. Different methods and classifiers are used to measure and classify the brain activities with higher accuracy and reliability. In this paper, instead of using mostly used classifier (support vector machine), prediction of the brain activity is done by estimating the match score densities. This method is based on likelihood ratio test which helps in finding the optimal combination of match scores. The distributions of match scores are modeled for different classes based on density score fusion in which the densities of different classes are estimated from the training data set and match scores are found by fusing the estimated densities with the testing data. The fusion is done with the data extracted from distributed activation patterns using multivariate pattern analysis (MVPA) against a visual task. MVPA is an intense strategy which helps in better understanding of the human brain. The match score-based technique is used in different biometric systems but never been used for the prediction of brain activity. In order to test the performance of proposed method, prediction accuracy is compared with the support vector machine using two data sets of different modalities, one is electroencephalography (EEG) and the other is functional magnetic resonance imaging (fMRI). The results show that the proposed method predicts the novel data with improved accuracy of 66.1% and 69.3% compared with support vector machine which have 64.15% and 65.7% for fMRI and EEG data sets, respectively."
  },
  {
    "year": "2017",
    "abstract": "The high implementation complexity of multiband orthogonal frequency-division multiplexing (MB-OFDM) ultra-wideband (UWB) technology is the major hurdle for applying it to vehicular communications. This paper presents a comprehensive synchronizer with low complexity and high performance for the MB-OFDM UWB. A low-complex overall architecture is proposed, in which the sub-functions are divided into amplitude-detection-based functions and phase-detection-based functions. All of the amplitude-detection-based functions are implemented based on a simplified cross correlation-based matched filter, and a serial structure-based auto-correlation block is designed exclusively for carrier frequency offset estimation. Several effective methods for the sub-functions are proposed based on the proposed overall architecture. Evaluation results show that the proposed synchronizer has high performance with low complexity."
  },
  {
    "year": "2017",
    "abstract": "Spatial modulation utilizes the diversity of multiple-input multiple-output channel to improve the spectral efficiency. In time-variant wireless channels, its performance degrades due to the inaccuracy of channel estimation (CE). In this paper, a data-aided channel tracking (DACT) method is proposed to improve its CE accuracy in time-variant wireless channels. Specifically, the demodulated data at current time slot are used to update the subsequent channel state information. Two different DACT methods with different pilot insertion patterns are proposed: 1) feedback DACT (FDACT) where when a symbol error is detected, the receiver will inform the transmitter to insert pilots and estimate the channel again; 2) periodical DACT (PDACT) where pilots are inserted periodically. Theoretical analysis of the CE error in time-variant channels is presented, which indicates that the CE accuracy could be significantly improved in comparison to the conventional counterpart. Moreover, the closed-form expressions of bit error rate for FDACT and frame error rate for PDACT are derived. Simulations are conducted to verify the efficiency of the proposed DACT methodologies."
  },
  {
    "year": "2017",
    "abstract": "Mobile communications (e.g., emails, Snapchat and Facebook) over a wireless connection is a norm in our Internet-connected society. Ensuring the security of communications between devices is an ongoing challenge. A number of authenticated key exchange (AKE) protocols have been proposed to verify the authenticity of a user and the integrity of messages sent over an insecure wireless communication channel. Recently, Tsai et al. proposed two AKE protocols designed for wireless network systems. In this paper, we demonstrate that their protocols are vulnerable to off-line password guessing attacks through presenting concrete attacks, contrary to their claims."
  },
  {
    "year": "2017",
    "abstract": "Vascular diseases cause a wide range of severe health problems. Vessel images are often corrupted by intensity inhomogeneity and blurry boundary, which makes it difficult to segment vessel image to identify vascular lesions. Integrating the fuzzy decision and a special local energy functional, in this paper, a robust active contour model is proposed to segment preprocessed vessel images. First, as for the blurry boundary problem, unlike the traditional method, a fractional-order differential method is used to enhance the original image for accurate segmentation utilizing fully high-frequency marginal features. Then, to deal with intensity inhomogeneity, a novel energy functional is formulated by considering the local fuzzy statistical information of boundaries. At the same time, a double-well potential function is designed to automatically limit the values of the membership function in the range [0, 1] during the curve evolution. Finally, Experiments on synthetic and real images are carried out, showing the accuracy of the proposed model and the robustness to the initial contour when working on vascular images."
  },
  {
    "year": "2017",
    "abstract": "The boom in the capabilities and features of mobile devices, like smartphones, tablets, and wearables, combined with the ubiquitous and affordable Internet access and the advances in the areas of cooperative networking, computer vision, and mobile cloud computing transformed mobile augmented reality (MAR) from science fiction to a reality. Although mobile devices are more constrained computationalwise from traditional computers, they have a multitude of sensors that can be used to the development of more sophisticated MAR applications and can be assisted from remote servers for the execution of their intensive parts. In this paper, after introducing the reader to the basics of MAR, we present a categorization of the application fields together with some representative examples. Next, we introduce the reader to the user interface and experience in MAR applications and continue with the core system components of the MAR systems. After that, we discuss advances in tracking and registration, since their functionality is crucial to any MAR application and the network connectivity of the devices that run MAR applications together with its importance to the performance of the application. We continue with the importance of data management in MAR systems and the systems performance and sustainability, and before we conclude this survey, we present existing challenging problems."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) is set to become one of the key technological developments of our times provided we are able to realize its full potential. The number of objects connected to IoT is expected to reach 50 billion by 2020 due to the massive influx of diverse objects emerging progressively. IoT, hence, is expected to be a major producer of big data. Sharing and collaboration of data and other resources would be the key for enabling sustainable ubiquitous environments, such as smart cities and societies. A timely fusion and analysis of big data, acquired from IoT and other sources, to enable highly efficient, reliable, and accurate decision making and management of ubiquitous environments would be a grand future challenge. Computational intelligence would play a key role in this challenge. A number of surveys exist on data fusion. However, these are mainly focused on specific application areas or classifications. The aim of this paper is to review literature on data fusion for IoT with a particular focus on mathematical methods (including probabilistic methods, artificial intelligence, and theory of belief) and specific IoT environments (distributed, heterogeneous, nonlinear, and object tracking environments). The opportunities and challenges for each of the mathematical methods and environments are given. Future developments, including emerging areas that would intrinsically benefit from data fusion and IoT, autonomous vehicles, deep learning for data fusion, and smart cities, are discussed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the topology configuration methods for heterogeneous optical satellite networks are investigated. Our objectives are to maximize weighted algebraic connectivity with respect to both network initialization and reconfiguration scenarios subject to onboard hardware constraints. The problems are not strictly convex and have been proven as NP-hard. In order to solve the problems in polynomial time, the original problems are relaxed to a convex optimization problem. Specifically, the relaxed problem is transformed to a positive semidefinite programming form, which can be solved exactly and more efficiently. Furthermore, based on the perturbation theory of matrices, we propose two greedy heuristic methods to deal with the initialization and reconfiguration case from the relaxed solutions, respectively. Simulation results show that the proposed algorithms are able to accomplish network initialization and reconfiguration correctly in the overwhelming majority of situations. The final sub-optimal solutions can also be obtained under low computational complexity."
  },
  {
    "year": "2017",
    "abstract": "European Telecommunications Standard Institute (ETSI) Technical Committee (TC) Smart Body Area Network (SmartBAN) defines and specifies low-power physical and medium access control layers for SmartBANs. Several use cases have been defined for SmartBAN, such as sleep monitoring, fall monitoring, and apnea monitoring. The specialist task force 511, working under ETSI TC SmartBAN, studied the performance of the system and evaluated coexistence with other wireless systems. In this paper, the simulator model based on the SmartBAN specification is introduced. Based on the simulation results, the receiver sensitivity for the SmartBAN system is defined. In addition, the interference model extracted from the measurements in the Oulu university hospital is discussed. This paper presents the summary of the simulation results based on the above-mentioned interference models. The simulation results showed that when there is a high interference in a communication channel, the SmartBAN system cannot gain an acceptable frame error level without a physical layer protocol data unit repetition technique and a high signal-to-interference power ratio level (SIR). In a low interference scenario, repetition is also needed when SIR is less than 9 dB."
  },
  {
    "year": "2017",
    "abstract": "The establishment of cloud computing and big data in a wide variety of daily applications has raised some privacy concerns due to the sensitive nature of some of the processed data. This has promoted the need to develop data protection techniques, where the storage and all operations are carried out without disclosing any information. Following this trend, this paper presents a new approach to efficiently compare variable-length data in the encrypted domain using homomorphic encryption where only encrypted data is stored or exchanged. The new variable-length-based algorithm is fused with existing fixed-length techniques in order to obtain increased comparison accuracy. To assess the soundness of the proposed approach, we evaluate its performance on a particular application: a multi-algorithm biometric template protection system based on dynamic signatures that complies with the requirements described in the ISO/IEC 24745 standard on biometric information protection. Experiments have been carried out on a publicly available database and a free implementation of the Paillier cryptosystem to ensure reproducibility and comparability to other schemes."
  },
  {
    "year": "2017",
    "abstract": "The nonlocal means (NLM) algorithm is one of the best image denoising algorithms because of its superior capability to retain the texture details of an image and is widely used in remote sensing (RS) image preprocessing. However, the time complexity of the algorithm is very high due to its nonlocality when searching for similar pixels. As a result, the NLM algorithm cannot satisfy the near real-time requirements of some specific applications. To resolve this issue, a parallel NLM algorithm based on Intel Xeon Phi hardware with Intel's many integrated cores (MIC) architecture was designed and implemented in this paper. The parallel algorithm achieved satisfactory speedup, but the speedup obtained showed a step-like distribution for different image sizes. This result was not expected based on the theoretical analysis, which predicted that the speedup should be independent of input data set size. To address this problem, the parallel algorithm was further optimized by adding pretreatment approaches and cutting down the number of nested loops in the MIC. Finally, experiments using the standard and optimized versions were carried out using the RS images of different sizes. Several conclusions could be drawn from the experimental results: 1) the standard parallel algorithm can obtain better speedup with only one MIC card and 2) the optimized parallel algorithm can completely eliminate the step distribution of the speedup and can also accelerate RS image processing significantly."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we tackle the problem of jointly separating instantaneous linear underdetermined mixtures of latent sources from multiple data sets, where the number of sources exceeds that of observations in each data set. Currently available blind source separation (BSS) methods, including joint BSS (JBSS) and underdetermined BSS (UBSS), cannot address this underdetermined problem effectively. We exploit the second-order statistics of observations, and present a novel BSS method, referred to as underdetermined joint BSS for multiple data sets (UJBSS-m), as a generalization of our previous work on two data sets. In this paper, the cross correlation between each pair of data sets is modeled by a third-order tensor in which a set of spatial covariance matrices corresponding to different time delays are stacked. Considering the latent common structure of these constructed tensors, the mixing matrices are jointly estimated via joint canonical polyadic decomposition of these specialized tensors. Furthermore, we recover the sources from each data set separately based on the estimated mixing matrices. Simulation results demonstrate that the proposed UJBSS-m method yields superior performances when compared with commonly used single-set UBSS and JBSS methods."
  },
  {
    "year": "2017",
    "abstract": "To improve smoke detection accuracy, we combine local binary pattern (LBP) like features, kernel principal component analysis (KPCA), and Gaussian process regression (GPR) to propose a novel data processing pipeline for smoke detection. The data processing pipeline consists of three steps including original feature extraction, dimensionality reduction, and classification. We use LBP-like methods to extract original features. To obtain a more discriminant feature, KPCA is used to non-linearly map the original features into a discriminant feature space, where manifold structures are embedded. Finally, in order to improve generalization performance, we apply GPR to model classification as a Gaussian process by imposing Gaussian priors on both data and hyper-parameters. In addition, we can replace any steps of the pipeline by similar methods for further improvement or exploration, so the pipeline is flexible and extensible. Experimental results show that KPCA and GPR are truly able to improve the performance of smoke detection and texture classification, and our method obviously outperforms the same features with Support Vector Machine (SVM)."
  },
  {
    "year": "2017",
    "abstract": "A telecare medicine information system (TMIS) for health-care delivery service requires information exchange among multiple IT systems, where different types of users with different access privileges are involved. In TMIS, users generally communicate via public channels. Hence, authentication is essential to provide access to the genuine users. However, access rights for the correct information and resources for different services to the genuine users can be provided with the help of efficient user access control mechanism. The existing user authentication protocols designed for TMIS only provide authentication, but for this kind of application, it is required that the authorized users should also have unique access privilege to access specific data. This paper puts forwards a new fine grained access control with user authentication scheme for TMIS. We present the formal security analysis using both the widely accepted real-or-random model and Burrows-Abadi–Needham logic. The proposed scheme supports user anonymity, forward secrecy, and efficient password change without contacting the remote server. In addition, the proposed scheme is comparable with respect to communication and computation costs as compared with other related schemes proposed in TMIS. Moreover, better tradeoff among security and functionality features, and communication and computation costs makes the proposed scheme suitable and practical for telecare medicine environments as compared with other existing related schemes."
  },
  {
    "year": "2017",
    "abstract": "With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013-2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8% with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm."
  },
  {
    "year": "2017",
    "abstract": "The generalizedl1greedy algorithm was recently proposed and shown to outperform the standard reweightedl1-minimization andl1-greedy algorithms for image reconstruction in computed tomography (CT). Herein, this algorithm is extended as a semisoft generalizedl1greedy algorithm by adapting the wavelet technique of semisoft thresholding. The extended algorithm can also be applied to image reconstruction by incorporating it into the BCPCS framework, resulting in a semisoft generalized total variation minimization (SSGTV) algorithm for CT. Numerical tests indicate that the proposed SSGTV algorithm improves the image reconstruction for CT."
  },
  {
    "year": "2017",
    "abstract": "A magnetic induction-based angular rate measurement method is proposed to address the need for internal measurement of high-speed angular rate of carriers. This method relies on the rotational periodicity fed back by the magnetic field. Three coils aligned orthogonal one to another are employed as the feedback module that supplies the rotational periodicity information, the physical characteristic that contains the periodic signals, which in turn reflect the highly dynamic rotation of the carrier in its accelerating process. The periodic, instantaneous start point is extracted from the magnetic signal using zero-phase threshold technique, whereby the signal periodicity is established, enabling experimental measurement of the rotational angular rate of a high-speed rotation object. A semi-physical simulation was conducted at different speeds using a low maximum speed high-precision rotary table, and the results demonstrate that this measurement method is capable of measuring angular rate varying dynamically between 1 and 100 r/s, with a measurement error within 20/00of the full scale. This method also provides a means for evaluating angular rate of other types of rotational movement."
  },
  {
    "year": "2017",
    "abstract": "Medical information retrieval plays an increasingly important role to help physicians and domain experts to better access medical-related knowledge and information, and support decision making. Integrating the medical knowledge bases has the potential to improve the information retrieval performance through incorporating medical domain knowledge for relevance assessment. However, this is not a trivial task due to the challenges to effectively utilize the domain knowledge in the medical knowledge bases. In this paper, we proposed a novel medical information retrieval system with a two-stage query expansion strategy, which is able to effectively model and incorporate the latent semantic associations to improve the performance. This system consists of two parts. First, we applied a heuristic approach to enhance the widely used pseudo relevance feedback method for more effective query expansion, through iteratively expanding the queries to boost the similarity score between queries and documents. Second, to improve the retrieval performance with structured knowledge bases, we presented a latent semantic relevance model based on tensor factorization to identify semantic association patterns under sparse settings. These identified patterns are then used as inference paths to trigger knowledge-based query expansion in medical information retrieval. Experiments with the TREC CDS 2014 data set: 1) showed that the performance of the proposed system is significantly better than the baseline system and the systems reported in TREC CDS 2014 conference, and is comparable with the state-of-the-art systems and 2) demonstrated the capability of tensor-based semantic enrichment methods for medical information retrieval tasks."
  },
  {
    "year": "2017",
    "abstract": "Contrary to the most existing works about the full-duplex (FD) relaying with perfect channel state information (CSI), this paper studies the outage performance of the two-way FD decode-and-forward relay network under the joint effects of the residual self-interference and imperfect CSI. We first derive the exact closed-form expressions of the system outage probability, based on which we obtain the outage probability under the perfect self-interference cancellation to investigate the impacts of the imperfect CSI on the system performance. In addition, to gain more insights about the imperfect CSI, we analyze the optimal power allocation scheme and an optimal relay node placement strategy, which minimize the system outage probability. The results reveal that the imperfect CSI will only affect the optimal power allocation, and the optimal relay node placement is related to the power ratio between the user nodes. Finally, analytical evaluations are performed to verify the theoretical results, and Monte Carlo simulations guarantee the correctness of the analytical evaluations."
  },
  {
    "year": "2017",
    "abstract": "Machining of hard and brittle materials is usually troublesome due to their high stiffness. In order to improve the processing speed of hard and brittle materials, ultrasonic assisted processing was developed. This paper reports a novel ultrasonic drill method, where longitudinal-bending hybrid ultrasonic vibration is used instead of single longitudinal or bending vibration. The cutting tool in this process is a core drill attached to an ultrasonic transducer, which generates longitudinal and bending vibrations. Thus an elliptical movement with ultrasonic frequency that is vertical to the working surface is formed at the cutting edge. The longitudinal vibration can help the cutting edge impact the workpiece and thus crush it. With the rotation of the cutting tool, the cutting edge scratches a groove on the working surface. While the bending vibration speeds up the movement of the cutting edge toward the workpiece in the working surface so as to amplify the fracture region. Moreover, a radial clearance assisting chip removal is made by the bending vibration. Merits of this machining method, including improved processing speed and avoidance of jamming are verified by experiment."
  },
  {
    "year": "2017",
    "abstract": "In a typical mobile environment, the varying speeds of transmit-receive pairs make traditional channel estimation methods inefficient due to continuously altering requirement of high density reference symbols. It has been largely instrumental in driving efforts to formulate innovative solutions, which are appropriate for such situations. Previously, with high computational cost, autoregressive moving average (ARMA) models of the stochastic wireless channels though appeared to be effective but could not efficiently incorporate the true nonlinearities observed in a practical situation. Therefore, nonlinear ARMA models based on artificial neural networks gained popularity. Yet certain challenges continue to exist, which are related to approximating all aspects of a real time situation, encompassing the non-linearities observed in a stochastic wireless channel, reducing training latency, enhancing processing capability, and deriving appropriate neuro-computational topologies. Modified functional link neural network with linearized activation function (FLNNLA) with nonlinear functional expansion is found to be more suitable for modeling stochastic wireless channels and removing the above-mentioned shortcomings. The proposed FLNNLA models the nonlinear tap gain process efficiently, reduces computational complexity, and enhances receiver performance with less learning cycles, better spectral efficiency and emerges as a strong candidate for being a part of upcoming receiver designs."
  },
  {
    "year": "2017",
    "abstract": "Combining powerful sensors and near ubiquitous distribution, the smartphone has become an irreplaceable part of modern day life. Using its pervasive sensing capabilities, the smart-phone guides us to our destination with precise step-by-step directions, advises us on what to have for lunch, and improves our photography skills through stabilizing our camera. Using the popular augmented reality (AR) smartphone app Pokemon Go as a case study, we explore the world of pervasive sensing. In this paper, we show both the current state of the art that enable applications such as Pokemon Go to thrive, as well as the limitations and opportunities inherent in current pervasive sensing applications."
  },
  {
    "year": "2017",
    "abstract": "Event-triggered consensus problem is studied for a class of heterogeneous first-order multi-agent system, which contains multiple single integrators with different nominal velocities, and an adaptive consensus algorithm in the leader-following structure is adopted. Under the event-triggered mechanism, the agents' inputs are only updated at discrete times determined by a centralized event-triggered function. By constructing proper Lyapunov function, sufficient consensus conditions are gained for the asymptotic consensus convergence. Furthermore, the consensus problem subject to identical input delay is considered, and consensus conditions in the form of linear matrix inequalities are obtained. Numerical simulations show the effectiveness of the event-triggered consensus control strategy."
  },
  {
    "year": "2017",
    "abstract": "Most existing trust-based security schemes for mobile ad-hoc networks (MANETs) consider packet loss an indicator of possible attacks by malicious nodes. There may be several reasons for packet losses, such as interference, queue overflow, and node mobility. Identifying the real underlying cause of a packet loss event is important for any security solution. To detect truly malicious nodes, it is necessary to carry out a fine-grained analysis (FGA) to determine the underlying cause of such loss. Without such analysis, the performance of any security solution may degrade, due to the punishment of innocent nodes while actual malicious nodes may remain undetected. Therefore, approaches are required that can correctly identify the reason for packet losses and can react accordingly. In this paper, we present a scheme that is able to correctly identify malicious nodes, using network parameters to determine whether packet losses are due to queue overflows or node mobility in MANETs. The contributions of this paper include the FGA scheme for packet loss and the development of a comprehensive trust model for malicious node identification and isolation. Our proposed FGA scheme is evaluated in terms of effectiveness and performance metrics under different network parameters and configurations. The experimental results show that our proposed trust model achieves a significant reduction in false positives rate and an increase in the rate of detection of truly malicious nodes compared with traditional non-FGA schemes."
  },
  {
    "year": "2017",
    "abstract": "A control chart of monitoring the number of failures is proposed with a moving average scheme, when the life of an item follows a Weibull distribution. A specified number of items are put on a time truncated life test and the number of failures is observed. The proposed control chart has been evaluated by the average run lengths (ARLs) under different parameter settings. The control constant and the test time multiplier are to be determined by considering the in-control ARL. It is observed that the proposed control chart is more efficient in detecting a shift in the process as compared with the existing time truncated control chart."
  },
  {
    "year": "2017",
    "abstract": "Data deduplication is a lossless compression technology that has been widely used in storage systems for space optimization. However, due to the removal of redundant data, the data deduplication has negative influences on data writing, data reading, and data reliability. In this paper, we propose a multi-objective-based performance evaluation framework to analyze the data deduplication performances and evaluate existing well-known deduplication approaches with multiple performance objectives, including compression ratio, data read performance, data write performance, and data reliability. Based on the proposed multi-objective framework and the obtained evaluation results, we further propose a multi-objective-based optimization method. Though our extensive experimental evaluation driven by real-world data sets, it is shown that this method can improve data read/write performance and data reliability while at the cost of little compression ratio."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address the hybrid flow shop scheduling problem with multiprocessor tasks. The objective is to minimize the maximum completion time. This problem is encountered in manufacturing, parallel and distributed computing, and real-time machine vision systems. This problem is strongly NP-hard, and consequently, several heuristics and meta heuristics were proposed in the literature in order to provide a near optimal solution. Assessing the performance of these heuristics requires efficient lower bounds. Surprisingly, few lower bounds with moderate performance were proposed. Because of this reason, we propose in this paper a new efficient destructive lower bound. This lower bound is based on the concept of revisited energetic reasoning, which is basically a feasible test with window time adjustments. The efficiency of the proposed lower bound is assessed throughout an extensive computational experiments conducted on a benchmark of 2,100 instances with up to ten centers. The numerical results provide evidence that the proposed lower bound consistently improves the best existing ones."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) is being deployed for a plethora of use-case scenarios. In any deployment, a number of configuration choices are available that achieve the mission goal. However, IoT security incidents have demonstrated that different configurations are vulnerable to varied risk levels. We propose the IoTRiskAnalyzer framework to formally and quantitatively analyze these risks using probabilistic model checking. IoTRiskAnalyzer takes vulnerability scores, candidate IoT configurations, and attacker's capabilities as inputs. It then generates the system and threat models to compute attack likelihood and attacker cost for each configuration. Evaluation indicates that IoTRiskAnalyzer is efficient and automatically prioritizes the input configurations on the basis of risk exposure."
  },
  {
    "year": "2017",
    "abstract": "A decision support system with data-driven methods is of great significance for the prognosis of scoliosis. However, developing an accurate and interpretable data-driven decision support system is challenging: 1) the scoliosis data collected from clinical environments is heterogeneous, unstructured, and incomplete; 2) the cause of adolescent idiopathic scoliosis is still unknown, and the effects of some measured indicators are not clear; and 3) some treatments like wearing a brace will affect the progression of scoliosis. The main contributions of the paper include: 1) propose and incorporate different imputation methods like Local Linear Interpolation (LLI) and Global Statistic Approximation (GSA) to deal with complicated types of incomplete data in clinical environments; 2) identify important features that are relevant to the severity of scoliosis with embedded method; and 3) establish and compare the scoliosis prediction models with multiple linear regression, k nearest neighbor, tree, support vector machine, and random forest algorithms. The prediction performance is evaluated in terms of mean absolute error, root mean square error, mean absolute percentage error, and the Pearson correlation coefficient. With only a few critical features, the prediction models can achieve satisfactory performance. Experiments show that the models are highly interpretable and viable to support the decision-making in clinical environments."
  },
  {
    "year": "2017",
    "abstract": "Volume rendering is an important technique of scientific visualization that can help people analyze and understand multivariable volume data effectively. Since, the previous visualization methods of multivariable volume data are not intuitive and difficult to operate, we propose a novel framework of visualizing multivariable volume data, which combines subspace clustering with radial coordinate visualization (RadViz) from the global pattern analysis to the local feature exploration. Since multivariable data generally have a large data size, the feature sampling is performed to extract some representative points. In order to explore the features interactively, the sample points extracted from high-dimensional space are projected into a low-dimensional space. Through selecting different sample points interactively, users can switch and explore different subspaces in real-time. For the further analysis of the local details in the selected subspace, we utilize the RadViz technique to present the data patterns in the subspace. Thus, the relationships of the data among different dimensions can be recognized intuitively. The result of the experiment shows that our method can help users explore the complex features in volume data deeply and express the data patterns among different dimensions exactly. The constructed system based on subspace analysis and multidimensional projection visualization can improve the efficiency of analyzing multivariable volume data and guarantee the real-time volume rendering."
  },
  {
    "year": "2017",
    "abstract": "A balanced armature (BA) receiver has the advantages of small size and high sound quality, which appeal to today's trend of portability and better acoustic quality for hearing aids and earphones. Previous studies on BA receivers have usually used the lumped parameter method or the equivalent magnetic circuit method, but they are not sufficient to describe the complicated behavior of the coupling effects of the electromagnetic, mechanical vibration, and acoustic behavior, especially in the high frequency range. Furthermore, the sound pressure level (SPL) cannot be predicted accurately at high frequency due to the vibration mode of the membrane. This paper proposes a new simulation method based on the 3-D finite-element method (FEM) and the 3-D boundary-element method (BEM) for a BA receiver. FEM was used to analyze the electromagnetic circuit and the mechanical modal analysis, while BEM was used in the acoustic analysis. The results show the trends of nonlinear parameters, such as the cogging force, inductance, speedance, and force factor in consideration of the nonlinear permeability of soft magnet materials. The coupling effects among the electromagnetic, mechanical, and acoustic behaviors are considered in the analyses. The simulation results were experimentally verified and showed good matchings. This simulation method provides a tool for predicting the SPL in the design process of a BA receiver."
  },
  {
    "year": "2017",
    "abstract": "Deciding how to prevent discrete event systems (DESs) from reaching forbidden states is an important problem in the field of DES supervisory control. For DESs with uncontrollable events, linear constraint transformation becomes a popular technique for solving the forbidden state problem when Petri nets are used as a modeling tool and control specifications are given in the form of linear constraints. This paper proposes a novel linear constraint transformation approach that is applicable to PT-ordinary Petri nets with uncontrollable subnets being forward-concurrent-free. For such nets, a linear constraint can be transformed into an optimal transformed one (i.e., a linear constraint that exactly characterizes the admissible marking set) by using the proposed approach, which is computationally shown to be of polynomial complexity with respect to the net size. An example is presented to illustrate the developed technique."
  },
  {
    "year": "2017",
    "abstract": "This paper considers the implementation and application possibilities of a compact full duplex multiple-input multiple-output (MIMO) architecture, where direct communication exists between users, e.g., device-to-device (D2D) and cellular link coexisting on the same spectrum. For the architecture of the compact full duplex radio, we combine an analog self-interference canceler-based dual polarization with high cross-polarization discrimination and long-term evolution (LTE)-based per-subcarrier digital self-interference canceler. While we consider the compactness and power efficiency of an analog solution, we focus on the digital canceler design with robustness to a frequency-selective channel and high compatibility with a conventional LTE system. For an over-the-air wireless experiment of full duplex testbed with a two-user-pair, we implement a full duplex MIMO physical layer, supporting 20-MHz bandwidth, on an Field-Programmable Gate Array-based software-defined radio platform. Furthermore, we propose a novel timing synchronization method to construct a more viable full duplex MIMO link. By having the full duplex link prototype fully operating in real time, we present the first characterization of the proposed compact full duplex MIMO performance depending on the transmit power of the full duplex node. We also show the link quality between nodes. One of the crucial insights of this paper is that the full duplex operation of a user is capable of acquiring the throughput gain if the user has self-interference capability with guaranteed performance."
  },
  {
    "year": "2017",
    "abstract": "The radiation behavior of the fractional-order, resonant mode within a circular sector cavity radiator is revealed at first, and then, it is employed to design a novel, planar quasi-isotropic magnetic dipole antenna. A set of closed-form formulas is derived and employed to determine the key parameters of the proposed antenna. The resultant circular sector magnetic dipole antenna operates at its dominant TM(2/3), 1 mode. It is numerically verified and experimentally validated at the 2.45-GHz band. It is seen that the antenna exhibits a good non-uniformity of less than 5.7 dB within the three principal planes, and an average radiation efficiency up to 82% within its impedance bandwidth from 2.4 to 2.5 GHz (for reflection coefficient smaller than -10 dB). Good agreement between the theoretical, simulated, and measured results has evidently verified the proposed antenna design approach."
  },
  {
    "year": "2017",
    "abstract": "Over these past years, formal reasoning about contracts between parties participating in a transaction has been increasingly explored in the literature. There has been a shift of view from one viewing contracts simply as properties to be satisfied by the parties, to one in which contracts are considered as first class syntactic objects and which can be reasoned about independently of the parties' behavior. In this paper, we present a contract calculus to reason about contracts abstracting the parties' behavior using a simulation relation-effectively a calculus of contracts regulating interaction between parties. We show how the calculus can be used to support the runtime monitoring of contracts and apply it to a plane boarding system case study."
  },
  {
    "year": "2017",
    "abstract": "The performance of surface textures with dimensional uncertainty due to the manufacturing process is investigated with statistical models. The uncertainty parameters are geometrical dimensions (i.e., dimple diameter, area ratio, and dimple depth) and the performance parameters include the friction force, the load-carrying capacity, and the coefficient of friction. The results show that logarithmic models provide an excellent fit to the data and can explain more than 99.98% of the variance in data. The most critical geometric parameter for the coefficient of friction and the load-carrying capacity is found to be the dimple diameter, whereas the most critical geometric parameter for the friction force is the area ratio. Manufacturing errors that follow normal distribution with three-sigma quality are found to be insignificant. Under the conditions simulated, it is determined that a dimple diameter of 1883 μm and a dimple depth of 5.5~6.5 μm yield optimal performance when operating in the hydrodynamic lubrication regime. The area ratio is the key parameter and must be determined based on the requirements of the load-carrying capacity and the coefficient of friction."
  },
  {
    "year": "2017",
    "abstract": "A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks. There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method, which we call smart augmentation and we show how to use it to increase the accuracy and reduce over fitting on a target network. Smart augmentation works, by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network. Smart augmentation has shown the potential to increase accuracy by demonstrably significant measures on all data sets tested. In addition, it has shown potential to achieve similar or improved performance levels with significantly smaller network sizes in a number of tested cases."
  },
  {
    "year": "2017",
    "abstract": "Fog radio access networks (F-RANs) are becoming an emerging and promising paradigm for fifth generation cellular communication systems. In F-RANs, distributed edge caching techniques among remote radio heads (RRHs) and user equipment (UE) can effectively alleviate the burdens on the fronthaul toward the base band unit pool and the bandwidth of the RANs. However, it is still not clear as to how social relationships affect the performance of edge caching schemes. This paper attempts to analyze the impact of mobile social networks (MSNs) on the performance of edge caching in F-RANs. We propose a Markov-chain-based model to analyze edge caching among edge nodes (i.e., RRHs and MSNs), as well as data sharing among the potential MSNs from the viewpoint of content diffusion in the F-RANs. Moreover, we analyze the edge caching schemes among UE to minimize the bandwidth consumption in the RANs. Finally, the optimal edge caching strategies among RRHs in terms of caching locations and time are introduced to minimize the bandwidth consumption of fronthaul and storage costs in the F-RANs. Simulation results show that the proposed edge caching schemes among UE and RRHs are able to reduce the bandwidth consumption of RANs and fronthaul effectively."
  },
  {
    "year": "2017",
    "abstract": "Traditional machine learning approaches to drug sensitivity prediction assume that training data and test data must be in the same feature space and have the same underlying distribution. However, in real-world applications, this assumption does not hold. For example, we sometimes have limited training data for the task of drug sensitivity prediction in multiple myeloma patients (target task), but we have sufficient auxiliary data for the task of drug sensitivity prediction in patients with another cancer type (related task), where the auxiliary data for the related task are in a different feature space or have a different distribution. In such cases, transfer learning, if applied correctly, would improve the performance of prediction algorithms on the test data of the target task via leveraging the auxiliary data from the related task. In this paper, we present two transfer learning approaches that combine the auxiliary data from the related task with the training data of the target task to improve the prediction performance on the test data of the target task. We evaluate the performance of our transfer learning approaches exploiting three auxiliary data sets and compare them against baseline approaches using the area under the receiver operating characteristic curve on the test data of the target task. Experimental results demonstrate the good performance of our approaches and their superiority over the baseline approaches when auxiliary data are incorporated."
  },
  {
    "year": "2017",
    "abstract": "Research and development on participatory sensing that accumulates a large amount of data acquired from users on the cloud and handles them as big data has proceeded due to the spread of sensor devices with miniaturized and advanced functions typified by smartphones. However, in service configuration models based on the current participatory sensing for which the cloud is a core component, there is a problem in that it is not possible to flexibly distribute information according to the data provisioning policy. In this paper, we propose a new sensor-based application platform based on a service configuration model that does not use a server or a cloud. In addition, we design and implement a contract-oriented information flow protocol, which realizes flexible reflection of the provisioning policy on that platform. Furthermore, we discuss feasibility and scope of the proposed protocol through simulation experiments."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the physical layer security for amplify-and-forward relay networks with simultaneous wireless information and power transfer. Specifically, by considering the dual-functional desired receiver, which is capable of decoding information and energy harvesting (EH), and assuming that only imperfect eavesdroppers' channel state information can be attained, we propose a joint robust cooperative beamforming, artificial noise, and power splitting scheme. We formulate the relay power minimization problem under both the secrecy rate constraint and the EH constraint, which is non-convex and hard to tackle. To tackle this problem, we propose a two-level optimization approach, which involves 1-D search and the semi-definite relaxation. In addition, we testify that the SDR can obtain the rank-one optimal solution. Simulation results show that the proposed robust scheme achieves better secrecy performance than other schemes."
  },
  {
    "year": "2017",
    "abstract": "The paper develops a neuromorphic system on a Spartan 6 field programmable gate array (FPGA) board to generate locomotion patterns (gaits) for three different legged robots (biped, quadruped, and hexapod). The neuromorphic system consists of a reconfigurable FPGA-based architecture for a 3G artificial neural network (spiking neural network), which acts as a Central Pattern Generator (CPG). The locomotion patterns, are then generated by the CPG through a general neural architecture, which parameters are offline estimated by means of grammatical evolution and Victor-Purpura distance-based fitness function. The neuromorphic system is fully validated on real biped, quadruped, and hexapod robots."
  },
  {
    "year": "2017",
    "abstract": "Multifocus image fusion generates a single image by combining redundant and complementary information of multiple images coming from the same scene. The combination includes more information of the scene than any of the individual source images. In this paper, a novel multifocus image fusion method based on extreme learning machine (ELM) and human visual system is proposed. Three visual features that reflect the clarity of a pixel are first extracted and used to train the ELM to judge which pixel is clearer. The clearer pixels are then used to construct the initial fused image. Second, we measure the similarity between the source image and the initial fused image and perform morphological opening and closing operations to obtain the focused regions. Lastly, the final fused image is achieved by employing a fusion rule in the focus regions and the initial fused image. Experimental results indicate that the proposed method is more effective and better than other series of existing popular fusion methods in terms of both subjective and objective evaluations."
  },
  {
    "year": "2017",
    "abstract": "Emerging memristor technology is recently drawing widespread attention due to its potential for diverse applications. Due to the lack of real solid-state memristive devices, there have been many initiatives to develop memristor emulators to study their behavior and applications. One of the most widely used ideal memristor models developed by the HP Lab does not fit the anticipated nonlinear behaviors of a real memristor. In this paper, we propose the concept and the design of a practical memristor emulator, which can be used to mimic the behavior of the well-known current controlled memristor models like-Simmons tunneling barrier model and the ThrEshold adaptive memristor model. Our proposed emulator model mimics the behavior of the electrical nonlinearity of the fabricated memristor. Prior emulators can only emulate the linear electrical behavior. In addition to the mathematical modeling and analysis of the proposed emulator, we provide SPICE simulation and experimental results. Furthermore, the proposed emulator has been used to verify some applications like Wien Oscillators. Finally, a brief comparison with the previously published emulators is presented to highlight the advantages of the proposed design."
  },
  {
    "year": "2017",
    "abstract": "In recent years, a new concept of network architecture with control/data plane separation is introduced to the future network, which can effectively improve the mobility robustness and reduce the handover failure by providing the data plane services under the umbrella of a macro cell coverage layer. However, in the ultra dense network, frequent data plane handovers would still introduce huge signaling exchanges and latencies. In this paper, we propose a universal predictive mobility management scheme for urban ultra-dense networks to speed up the data plane handover process. We utilize the probability suffix tree model to save and analyze the transition relationships between small cells in terms of variable markov chains, and pre-configure a cluster of small cells with larger handover probabilities for the users. To accommodate different versions of the users, a compatible network-controlled predictive mobility management procedure and an advanced user-autonomous predictive mobility management procedure are proposed to support the proposed predictive mobility management scheme. The simulation results show that the proposed scheme can significantly improve the prediction accuracy with a lower redundant configuration cost and can effectively speed up the data plane handover process compared with the traditional mobility management."
  },
  {
    "year": "2017",
    "abstract": "Although the promising 5G cell network technology has increased the transmitting rate greatly, it has also brought some challenges. The energy efficiency has become an important topic in 5G networks. In this paper, the energy efficiency of small cell networks is analyzed, and the existing objective functions are classified in order to minimize the energy consumption, and to maximize the energy efficiency, harvested energy, and energy-aware transmission. Commonly used metrics were analyzed on equipment, base station, and network levels, respectively. Moreover, the methods for energy efficiency improvement were introduced according to above-mentioned metrics. Afterward, the relationships between energy efficiency, spectrum efficiency, and space efficiency were discussed. In order to improve efficiency on equipment, base station, and network levels, the energy and spectrum market is proposed and guidelines for the future research on metrics, methods, and market are presented. The proposed market was verified by simulations, and the simulation results have shown that the proposed market improves the energy efficiencies effectively."
  },
  {
    "year": "2017",
    "abstract": "Machine-to-machine communication has emerged as a new communication paradigm to support a variety of applications of Internet of Things (IoT). Meanwhile, energy harvesting (EH) is an increasingly attractive source of power for green networks. In this paper, we study an online strategy of adaptive traffic offloading and bandwidth allocation for EH IoT networks, where machines are powered by grid and green energy jointly. First, we study the energy-aware and adaptive traffic offloading strategy to adaptively balance the non-uniform renewable energy arriving, with the purpose of minimizing the average on-grid energy consumption. Furthermore, the bandwidth allocation strategy to maximize the average sum-rate is proposed. Finally, we validate this paper by simulations and show that the proposed strategy can achieve 55% reduction of the average on-grid energy consumption and over 100% increase of the average sum-rate."
  },
  {
    "year": "2017",
    "abstract": "Manufacturing Internet of Things (MIoT) represents the manufacturing oriented to Internet of Things with two important characteristics, resource sharing and process collaboration. Access control in resource sharing is very important for MIoT operation safety. This paper presents an access control model for resource sharing based on the role-based access control intended for multidomain MIoT. In multidomain systems, in order to response on the assigning request for permission for the certain role from the certain user, an authority action sequence named the authorization route is employed to determine an appropriate authorization state. In this paper, the best authorization route with the least spread of permissions is defined as an optimal authorization route. We employed an intelligent planning theory to model the authorization route problem and to develop a solution algorithm called PGAO*, which can support external evaluation of both single-goal-role authorization routes and multi-goal-role authorization routes. In addition, some simple policies for solving the authorization route problem are presented. The proposed access control model provides a quick and efficient authorization decision support for administrators in collaborative domain and ensures a secure access in resource sharing in MIoT."
  },
  {
    "year": "2017",
    "abstract": "The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data."
  },
  {
    "year": "2017",
    "abstract": "Although the massive MIMO enabled heterogeneous networks (HetNets) can intensify the spectral efficiency benefits, the proper user association and resource allocation are both crucial to achieve desirable performance since the power consumption of base station (BS) scales with the large number of antennas. This paper aims to investigate joint design of user association and power allocation with loads constraint and transmit power constraint for the massive MIMO HetNets by considering proportional fairness about the spectral efficiency under imperfect channel state information. First, we derive a closed-form lower bound on the ergodic spectral efficiency with linear zero-forcing beamforming, based on which, a mixed-integer nonlinear programming problem is formulated. It is difficult to efficiently obtain an exact solution since it is non-convex and combinational. To solve this NP-hard problem, an effective algorithm with guaranteed convergence is proposed, where the original problem is decomposed into the corresponding subproblems, which can be solved by low complexity approaches, respectively. Numerical results show that how the number of antennas and the number of BSs affect the spectral efficiency, and our proposed algorithm outperforms other algorithms in terms of the spectral efficiency and load balancing."
  },
  {
    "year": "2017",
    "abstract": "On the basis of doublet and its properties, a class of multiple-mode narrow band bandpasss filter is designed and fabricated by simultaneously exploiting the three resonant modes in a single rectangular cavity: TE101, TE011, and TM110 modes. The input/output ports of the proposed filter are fed by coupling a microstrip line to a slot on the side wall of a rectangular cavity. Different modes are excited by changing the position and shape of the two slots at input and output of the rectangular cavity without any intra-cavity coupling. Besides three poles within the passband, a pair of transmission zeros (TZs) is achieved, which can be controlled independently by setting the positions of the two TZs at the lower and/or upper stopband. High stopband attenuation and high filtering selectivity are achieved by considerably allocating three transmission poles and two zeros. In order to verify the proposed theory, two filter prototypes are fabricated and measured."
  },
  {
    "year": "2017",
    "abstract": "Direction of arrival (DOA) estimation of quasi-stationary signals (QSS) is discussed in this paper, and an algorithm using unfolded coprime array is proposed. Coprime array consists of two uniform linear subarrays with coprime relationship, and the two subarrays of the unfolded coprime array in this paper are arranged along the positive axis and negative axis, respectively. Through the vectorization of the low dimensional cross-covariance matrix and the further exploiture of the non-circularity within the second-order statistics of QSS, 2MN-1 degrees of freedom can be achieved with M+N physical elements. The uniqueness of the DOA estimation based on the non-continuous virtual elements generated from the unfolded coprime array is proved, and unitary polynomial root finding technique is employed to estimate the DOA. The proposed algorithm has low complexity, and it can obtain better DOA estimation performance and handle more sources than Khatri-rao subspace approach and original coprime array-based method. Simulation results verify the effectiveness of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Proactively pushing content to users is a promising way of coping with the explosively growing traffic demand of next-generation mobile networks. However, it is unclear whether content pushing can improve the energy efficiency of delay-constrained wireless communication systems over fading channels. With pushing, the energy consumption can be reduced due to the extended transmission time duration. But if the user never needs the pushed content, pushing may lead to wasted energy. Based on the random content request delay, this paper derives the user request probability thresholds that determine whether a content file should be pushed under two different quality-of-service requirements, namely, average delay and delay-outage constraints. Moreover, optimal strategies to allocate transmission power in content pushing and on-demand delivery stages are also proposed. It is shown that the energy efficiency of systems with pushing can be significantly improved as the content request probability increases. Numerical results validate the effectiveness of the proposed power allocation strategies for different delay constraints, compared with the corresponding on-demand schemes."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the throughput maximization problem for a three-node buffer-aided relay channel with non-ideal circuit power. In particular, the half-duplex decode-and-forward relaying scheme is adopted. Moreover, the buffers at the relay own the capability to temporarily store the data received from the source. The throughput maximization problem over infinite time horizon for the considered system is investigated, considering the extra power consumption by the circuits during transmissions. The optimal power allocation is obtained by examining two cases on whether the relay can support the source transmissions, and is then shown to be with an “on-off” structure, i.e., the source and the relay transmit with certain probabilities, respectively. Next, the dynamics of the stored data at the relay is modeled under the derived optimal power allocation, and the minimum buffer size required for data storage is quantified. Finally, numerical results validate the analysis."
  },
  {
    "year": "2017",
    "abstract": "The whale optimization algorithm (WOA) has been shown to be powerful in searching for an optimal solution. This paper proposes an improvement to the whale optimization algorithm that is based on a Lévy flight trajectory and called the Lévy flight trajectory-based whale optimization algorithm (LWOA). The LWOA makes the WOA faster and more robust and avoids premature convergence. The Lévy flight trajectory is helpful for increasing the diversity of the population against premature convergence and enhancing the capability of jumping out of local optimal optima. This method helps obtaining a better tradeoff between the exploration and exploitation of the WOA. The proposed algorithm is characterized by quick convergence and high precision, and it can effectively get rid of a local optimum. The LWOA is further compared with other well-known nature-inspired algorithms on 23 benchmarks and solving infinite impulse response model identification. The statistical results on the benchmark functions show that the LWOA can significantly outperform others on a majority of the benchmark functions, especially in solving an optimization problem that has high dimensionality. Additionally, the superior identification capability of the proposed algorithm is evident from the results obtained through the simulation study compared with other algorithms. All the results prove the superiority of the LWOA."
  },
  {
    "year": "2017",
    "abstract": "Night time pedestrian detection is more and more important in advanced driver assistant systems (ADAS). Traditional pedestrian detection algorithms in far infrared (FIR) images lack accuracy and have long processing times. Focusing on this issue, in this paper, a visual saliency-based pedestrian detection algorithm is proposed. First, areas that contain suspected pedestrians are detected using a fusion saliency-based method. Then, the sub-image of the suspected pedestrian is used as an input to a histogram of local intensity difference feature and cross kernel-based support vector machine classifier to make a final determination. Experiments performed using a real FIR road image data set demonstrated that the proposed fusion saliency-based region of interest (ROI) detection method has the largest pedestrian inclusion rate and the smallest ROI proportion compared with three other methods. Besides, compared with existing state-of-the-art pedestrian detection algorithms, the proposed method demonstrates a much higher pedestrian detection rate with a comparably short processing time."
  },
  {
    "year": "2017",
    "abstract": "Smartphones are increasingly used for storing a large amount of sensitive used data. Users can protect their sensitive data through encryption and locking screen. A pattern lock is one of the ways to lock a screen. This method is used by most users because of its ease of use and memorization. However, a pattern lock with low security level is inadequate to protect the sensitive data of the user when it encounters a brute force or other physical attack (e.g., smudge attack). Furthermore, it bypasses all of the protection measures of mobile device when users are coerced into disclosing their passwords. Steganographic techniques and deniable encryption are designed to protect the sensitive data of the user as well as secure communications and can hide sensitive data on a disk or during communication with other devices. To overcome these deficiencies that mobile devices present, we present a novel, practical safe framework called MobiMimosa that is based on plausible deniable encryption. MobiMimosa enables multiple hidden encryption volumes and dynamic mounting of hidden volumes, which facilitates the transfer of sensitive data from a normal volume to a hidden volume. Simultaneously, to meet the personalized needs of the security of the mobile device, MobiMimosa enables a strategy to be set that can trigger the uninstalling of a sensitive app and the destruction of sensitive data. MobiMimosa also greatly alleviates corruption of the cross-volume boundary that is present in previous smartphone PDE schemes. We implemented a prototype system on the android device."
  },
  {
    "year": "2017",
    "abstract": "Network densification is seen as a necessary trend in the evolution toward 5G networks to cope with future high-traffic demands. In particular, the use of femtocells seems to be the most feasible solution for hotspot areas where high traffic is concentrated. However, femtocell densification will face a number of technical challenges. Among others, the co-tier interference arises as an old acquaintance with a new significance. In point of fact, the interference characteristics and the role of aggressor and victim depend on a large extent on the density scenario, especially when femtocells share the same channel and operate in a Closed Subscriber Group (CSG) mode. In this regard, identification of victim and aggressor femtocells is a prerequisite to design an effective interference management scheme for ultra-dense femtocell networks (UDFNs). This paper implements a new approach for radio resource utilization and management for victim femtocells in an ultra-dense network environment. The proposed semi-clustering of victim-cell (SCVC) approach focuses mainly on users' status whether critical or non-critical to categorize victim femtocells and their aggressors. After identifying the victim femtocells, the SCVC scheme semi-cluster each victim femtocell based on the status of each user. Then, it smartly allocates the appropriate radio resources in a dynamic manner, which allows ranging from shared use of resources for critical users to the frequency reuse one for non-critical users, thereby ensuring minimum co-tier interference and enhancement of spectrum efficiency. Simulation results show that our approach outperforms one of the prominent related schemes, namely, femtocell cluster based resource allocation (FCRA), in terms of the mean throughput of critical users, the average capacity of victim femtocells, and the percentage of resource utilization by an approximate average gain of 185%, 64%, and 31%, respectively."
  },
  {
    "year": "2017",
    "abstract": "It is always advantageous to include additional bandpass filtering functionality within different circuits and components in the wireless communication system, and thus, a novel circular patch loaded with vias and stubs is proposed as the basic element to achieve this function integration, as well as the performance enhancement. Owing to the introduction of a new operation mode and flexibility of the proposed patch element in locating the frequencies of different operation modes, excellent bandpass characteristics can be implemented with simplicity in structure. First, the proposed patch element is used to implement a triple-mode bandpass filter with a very wide harmonic suppression. As an extension, a novel rectifying circuit with extended input power range and bandpass filtering property is implemented based on a bandpass filtering power divider, which is also implemented using the basic patch configuration. To verify the validity of the proposed patch configurations, three different kinds of circuits have been designed, fabricated, and measured. All measured results are found to be in good agreement with the simulation results."
  },
  {
    "year": "2017",
    "abstract": "As cloud computing becomes increasingly popular, cloud providers compete to offer the same or similar services over the Internet. Quality of service (QoS), which describes how well a service is performed, is an important differentiator among functionally equivalent services. It can help a firm to satisfy and win its customers. As a result, how to assist cloud providers to promote their services and cloud consumers to identify services that meet their QoS requirements becomes an important problem. In this paper, we argue for QoS-based cloud service recommendation, and propose a collaborative filtering approach using the Spearman coefficient to recommend cloud services. The approach is used to predict both QoS ratings and rankings for cloud services. To evaluate the effectiveness of the approach, we conduct extensive simulations. Results show that the approach can achieve more reliable rankings, yet less accurate ratings, than a collaborative filtering approach using the Pearson coefficient."
  },
  {
    "year": "2017",
    "abstract": "Intelligent metering systems are being rolled-out on a large-scale worldwide, enabling consumer to make informed choices about consumption patterns and energy saving, while supporting the development of new retail services and products. Unfortunately, the lack of established and shared international standards represents a serious hindrance to be overcome for a complete development of a profitable market. The identification of suitable communication protocols and cost-effective network architectures represent a challenging aspect. In this framework, different network design solutions for wireless smart metering systems at 169 MHz are considered and investigated in this paper, aiming at cost efficient deployment based on extensive re-use of existing infrastructures in urban scenarios, namely, macro-cellular and lighting networks. Coverage assessment and frequency planning issues are addressed, together with an ad hoc measurement campaign carried out to fill the gap in the knowledge of urban propagation in the 169 MHz band. Results show that cost-effective deployment of the intelligent metering network is achievable. Notably, a spatial reuse factor larger than the overall number of available frequency channels might be necessary, thus meaning that the spectral resources shall be also allocated according to a time division scheme, where the hubs are switched off at turn. Anyway, this requirement should not affect the overall reading rate in practical applications."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel unsupervised classification approach suited to hyperspectral remote sensing image data sets that usesK-means clustering combined with the neighboring union histogram (NUH). The approach is implemented in five main steps as follows: 1) dividing the hyperspectral image data intt uncorrelated groups based on the correlation coefficient matrix; 2) extracting the first few principal component analysis (PCA) components from each group; 3) computing the NUHs of every group; 4) obtaining several relatively rough clustering results by employing the first-stageK-means procedure to classify every group’s NUHs; and 5) using the second-stageK-means procedure to refine the rough clustering results for the final clustering map. The NUH indicates the regional statistical features of a point, thereby making the proposed approach insensitive to noise and abnormal data. The two-stage clustering technique improves the recognition rate of similar land cover classes. The proposed approach is compared with five other unsupervised methods. The experimental results on two different types of real-world hyperspectral remote sensing images validate the high accuracy of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Power models are a critical element in current research regarding the effect of program-offloading decision making on the energy consumption of mobile devices. Several utilization-based power models have been proposed for measuring the energy consumption of locally running programs. However, the main challenge of utilization-based methods is that the models must be retrained for program units that use hardware components not addressed in the training phase. This paper proposes a paired sampling-based power model to address this critical challenge. The proposed power model estimates the energy consumption of an OSGi service asynchronously invoked in a multithreading environment on the basis of the overall remaining battery energy information at runtime without a connected power meter or energy profile for each specific hardware component of different devices. On the basis of the power model, an offloading decision model is proposed to dynamically determine whether a service invocation should be offloaded to a nearby mobile device over Bluetooth to conserve energy. The proposed approach was experimentally assessed regarding the correctness of decision making, energy gained by offloading service invocations, and weighted absolute percentage error of the estimated energy consumption compared with actual one."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a decoding method of joint zero-forcing and successive interference cancellation (ZF-SIC) is put forward to assist the study of the individual secrecy in the quasi-static Rayleigh fading single-input multiple-output multiple access wiretap channel. We first evaluate the individual secrecy performance by deriving the closed-form expressions in terms of positive secrecy capacity probability, secrecy outage probability, and effective secrecy throughput (EST). Besides the expected impact of the SIC order, we find, in high signal-to-noise ratio (SNR) regime, the secrecy performance is only determined by the transmitter’s relative distance to eavesdropper over legitimate receiver rather than the SNR. Such a result prompts us to propose an SIC order scheduling scheme (alternative scheme) on basis of the transmitters’ relative distances from the shortest to the longest. It is proved optimal in achieving total maximum EST in high SNR regime. Finally, we also investigate the problem of optimal power allocation to each transmitter under the constraint of the limited total power. An interesting solution to this problem is disclosed with the aid of numerical analysis."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the fabrication of an inductorless wideband low-noise amplifier (LNA). The LNA includes two branches in parallel: a common-source (CS) path and a common-gate (CG) path. The CS path is responsible for providing enough power gain, while the CG path is used to achieve the input impedance matching. To eliminate the noise contribution of the CG path, the noise cancellation technique is applied. Therefore, the overall noise figure (NF) is improved. The phase mismatch between the two paths is also quantitatively analyzed to investigate its effect on gain and NF. The analytical results agree well with the simulation results. The LNA has been fabricated by a commercial 0.18-μmCMOS process. The measurement results show that the LNA has achieved a maximum gain of 14.5 dB with 1.7-GHz 3-dB gain bandwidth and a minimum NF of 3 dB. The tested input 1-dB gain compression point (IP1 dB) is −10.4 dBm at 1 GHz and the input third-order intercept point is 0.25 dBm. With 1.8-V supply, the LNA draws only 6-mA dc current."
  },
  {
    "year": "2017",
    "abstract": "We study the achievable rate of an uplink MIMO cognitive radio system where the primary user (PU) and the secondary user (SU) aim to communicate to the closest primary base station (BS) via a multi-access channel through the same unmanned aerial vehicle (UAV) relay. The SU message is then forwarded from the primary BS to the secondary network with a certain incentive reward as a part of the cooperation protocol between both the networks. A special linear precoding scheme is proposed to enable the SU to exploit the PU free eigenmodes. We analyze two scenarios in which the UAV relay gain matrix is either fixed or optimized. We derive the optimal power allocation that maximizes the achievable rate of the SU respecting power budget, interference, and relay power constraints. Numerical results highlight the cognitive rate gain of our proposed scheme with respect to various problem parameters. We also highlight the effect of UAV altitude on the SU and PU rates. Finally, when the relay matrix is optimized, we show that the PU rate is remarkably enhanced and that the SU rate is only improved at high-power regime."
  },
  {
    "year": "2017",
    "abstract": "We investigate the impact of the wireless network's physical layer (PHY) security and reliability on demand-side management operation in the smart grid. We assume that consumers communicate their energy demands with the utility, and we investigate the tradeoff between the wireless network's PHY security and reliability. We consider passive and active attacks on the smart grid, and show their impacts on both the wireless communications system's reliability and security. To improve the wireless communications system's security, we propose an artificial-noise (AN)-aided scheme for orthogonal-division multiplexing-based wireless systems. We show that increasing the PHY security of the legitimate transmissions decreases the communication reliability between the smart meters and the meter data-management system since to secure the transmissions, a portion of the transmit powers will be assigned to AN signal transmissions. To further secure the smart meters' transmissions and enhance their reliability, we propose a new encoding scheme where the data are encoded over the available smart meters' communication (i.e., non-idle) times in a given hour."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a distributed control strategy based on fuzzy-sliding mode control (FSMC) for power control of an infrastructure integrated with a dc-microgrid, which includes photovoltaic, fuel cell, and energy storage systems with plug-in electric vehicles (PEVs). In order to implement the proposed control strategy, first, a general nonlinear modeling of a dc-microgrid based on related dc-dc converters to each dc power sources is introduced. Second, a power management strategy based on fuzzy control for regulating the power flow between the hybrid dc sources, PEVs is proposed. Third, to retain the balance between the requested power and the output power, adaptive FSMC strategy, for controlling the battery energy storage and fuel cell, is suggested. Finally, experimental results are presented to validate the potential of the proposed power flow control strategy."
  },
  {
    "year": "2017",
    "abstract": "In delay tolerant networks (DTNs), the delivery rate and delivery speed are restricted by node selfishness. To promote the delivery rate and reduce the delivery delay in DTNs, we propose a hybrid incentive trade model (HITM), which uses reputation compensation to stimulate nodes to give up their temporary benefits and transfer their forwarding missions to other more qualified nodes. Furthermore, HITM gives credit payment and reputation promotion to nodes whose mission transferring behaviors are capable of reducing delivery delay or promoting delivery reliability, and conversely punishes nodes whose mission transferring behaviors could prolong the delivery delay or impair the delivery reliability. Trace-driven experiments are performed to compare HITM with previous representative incentive schemes. The experiment results demonstrate that the HITM can effectively limit node selfishness, thereby promoting the delivery rate as well as reducing the delivery delay."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) connects sensing devices to the Internet for the purpose of exchanging information. Location information is one of the most crucial pieces of information required to achieve intelligent and context-aware IoT systems. Recently, positioning and localization functions have been realized in a large amount of IoT systems. However, security and privacy threats related to positioning in IoT have not been sufficiently addressed so far. In this paper, we survey solutions for improving the robustness, security, and privacy of location-based services in IoT systems. First, we provide an in-depth evaluation of the threats and solutions related to both global navigation satellite system (GNSS) and non-GNSS-based solutions. Second, we describe certain cryptographic solutions for security and privacy of positioning and location-based services in IoT. Finally, we discuss the state-of-the-art of policy regulations regarding security of positioning solutions and legal instruments to location data privacy in detail. This survey paper addresses a broad range of security and privacy aspects in IoT-based positioning and localization from both technical and legal points of view and aims to give insight and recommendations for future IoT systems providing more robust, secure, and privacy-preserving location-based services."
  },
  {
    "year": "2017",
    "abstract": "Logical Petri nets (LPNs) can well describe and analyze batch processing functions and pass the value indeterminacy in cooperative systems. Their structure is simpler than their equivalent inhibition PNs. To analyze them, a vector matching method was given previously. We present interactive LPNs (ILPNs) in this paper. Their liveness and boundedness are analyzed for the first time. Compatibility is analyzed for a composed system and reflects the possibility of correct/proper interactions among its subsystems. To characterize different cooperative abilities in practice, compatibility is defined for ILPNs. Some relationships among compatibility, liveness, boundedness, and conservativeness are revealed. An example is presented to discuss the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "During the past several years, as one of the most successful applications of sparse coding and dictionary learning, dictionary-based face recognition has received significant attention. Although some surveys of sparse coding and dictionary learning have been reported, there is no specialized survey concerning dictionary learning algorithms for face recognition. This paper provides a survey of dictionary learning algorithms for face recognition. To provide a comprehensive overview, we not only categorize existing dictionary learning algorithms for face recognition but also present details of each category. Since the number of atoms has an important impact on classification performance, we also review the algorithms for selecting the number of atoms. Specifically, we select six typical dictionary learning algorithms with different numbers of atoms to perform experiments on face databases. In summary, this paper provides a broad view of dictionary learning algorithms for face recognition and advances study in this field. It is very useful for readers to understand the profiles of this subject and to grasp the theoretical rationales and potentials as well as their applicability to different cases of face recognition."
  },
  {
    "year": "2017",
    "abstract": "Risk management in the development of medical software and devices is one of the most crucial processes in ensuring accurate diagnoses and treatment of disease. The consequences of wrong decisions that happen in our daily life might be unembellished. However, wrong decisions in healthcare based on unreliable evidence due to erroneous software could result in loss of life. Dysphonic patients suffering from various vocal fold disorders might have a threat of life due to inaccurate diagnosis. Some voice disorders, such as keratosis, are precancerous, and can become cancerous in cases that involve inaccurate diagnosis due to software failure. The objective of this paper is to design and implement a healthcare software for the detection of voice disorders in nonperiodic speech signals. Occurrences of potential risks during the design and development of the proposed software are taken into account to avoid failure. The software is implemented by applying the local binary pattern (LBP) operator on the textures of nonperiodic signals. The textures are obtained through the recurrence plot. The LBP operator computes the histograms for normal persons and dysphonic patients, and these histograms are used with the support vector machine for the automatic classification of dysphonic patients. The software is evaluated and tested by using the Massachusetts Eye and Ear Infirmary voice disorder database. The success rate of the proposed healthcare system is 97.73% ± 1.2, and the area under the receiver operating characteristic curve is 0.98 ± 0. The performance of the proposed healthcare system is much better than the existing commercial software used for screening dysphonic patients."
  },
  {
    "year": "2017",
    "abstract": "In recent years, many researchers have examined dynamic optimization problems (DOPs). The key challenge lies in the fact that the optimal solution of a DOP typically changes over time. This paper focuses on using query-based learning dynamic particle swarm optimization (QBLDPSO) to solve DOPs. QBLDPSO is mainly used for improving multi-population-based PSO; our QBL mechanism includes two learning strategies that integrate the concepts of diversity and memory into PSO. The first learning strategy, QBL quantum parameter adaptation (QBLQPA), is used to apply the concept of diversity to the multi-population based algorithm. This is different from typical diversity-based PSO approaches, which passively maintain the diversity of particles in the solution space. We actively adapt the ratio of quantum particles and neutral particles to achieve diversity without analyzing the distribution of optima in the solution space. The second learning strategy is query-based learning optima prediction (QBLOP). Although QBLOP exploits the concept of memory, we do not need to analyze the history of all particles. We select the k nearest particles to the current best solution and use a minimum encompassing circle as the possible prediction region. Our experimental results are based on the generalized dynamic benchmark generator (GDBG), which is adopted as a benchmark for the DOP. The proposed method outperforms two state-of-the-art multi-population-based PSO methods with the average improvements of 11.37% and 8% using QBLQPA. In particular, for the recurrent problems in GDBG, our method improves performance by 35.06%."
  },
  {
    "year": "2017",
    "abstract": "Asymptotic orthogonality of channel vectors, also called favorable propagation (FP), plays a key role in massive multiple-input multiple-output (MIMO) systems, allowing linear processing to achieve optimality and maximize the information rate. Much research on the FP condition emerges under different assumptions, most of which has been proved to satisfy the FP condition for some massive MIMO implementations. A generic channel model without mutual coupling is proposed to study more general implementations than previously investigated. Two theorems establish: 1) conditions on the steering matrix alone that are sufficient to guarantee the FP condition holds and 2) that a simple condition on the steering matrix alone is sufficient to guarantee FP for all practical massive MIMO implementations. Then the uniform linear array, uniform planar array (UPA), and uniform circular array (UCA) antenna configurations are studied. Theoretical analyses indicate how close and how fast the inner product of different steering vectors converges to zero for a finite number of base station (BS) antennas, and prove that the FP condition is satisfied for the antenna configuration considered for an unlimited number of BS antennas only if the antenna spacing is not proportional to the reciprocal of the number of antennas. The analysis shows that the UCA has the shortest distance from the FP condition among the three antenna structures, while the UPA is especially suitable for massive MIMO systems for 5G owing to its good FP performance and compact physical size. Simulation results validate the theory."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a point-to-point communication system in a wireless body area network capable of harvesting radio-energy is studied. We investigate two scenarios for transmission, which are in normal circumstance and in abnormal circumstance. We consider power splitting protocol in normal circumstance and time switching protocol in abnormal circumstance at the sensor, respectively. Based on two protocols, the optimal power splitting and time switching ratios are derived in each scenario. The goal of this paper is to maximize the information throughput from the sensor to the access point in uplink by balancing the time duration among the command transfer phase, the energy harvesting phase, and the information transfer phase while satisfying energy harvesting and consumption balance constraint at the sensor. Numerical results demonstrate the effectiveness of the optimal solution."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an effective approach for mitigating the near-field coupling between four-port circularly polarized (CP) antennas in a 30-GHz multiple-input, multiple-output (MIMO) system is suggested and investigated. This is obtained by incorporating a two-layer transmission-type frequency selective surface (FSS) superstrate based on planar crossed-dipole metal strips. This paper presents a comparison between the mutual coupling when the patches are radiating in free space and in the presence of the FSS layers. The simulated results, when the FSS layers are applied, show an average of 6-12-dB improvement in the isolation between four adjacent CP-MIMO antennas. In addition, an accurate study is carried out on the insignificant reflections produced by the FSS layers to redirect those and also prevent any interference. The proposed 2 x 2 CP-MIMO antenna along with the superstrate is implemented and tested to validate the simulation results. Experimental results of the coupling and reflection coefficients and axial ratio show an acceptable agreement with the corresponding simulated ones."
  },
  {
    "year": "2017",
    "abstract": "Despite the promising role of orthogonal frequency-division multiplexing (OFDM) in communication systems, the optimal and practical spectrum sensing of OFDM signals for cognitive radio systems over multipath fading channels remains an important and challenging issue. This paper presents the Neyman-Pearson detection scheme of OFDM signals employing continuous pilot subcarriers. Since there are many unknown parameters in the Neyman-Pearson detector to be resolved, we also present a generalized log-likelihood ratio test (GLRT) spectrum sensor. The considered problem is complex and leads to a joint detection and estimation problem. The proposed GLRT spectrum sensor only needs received samples. Moreover, the proposed GLRT spectrum sensor is robust to the frequency selectivity of fading channels and symbol timing offset and carrier frequency offset. Simulations confirm the advantages of the proposed detector."
  },
  {
    "year": "2017",
    "abstract": "Switching operations in gas-insulated switchgear (GIS) substations generate transient electromagnetic fields in the GIS pipes. These fields leak out discontinuities of the GIS and induce electromagnetic disturbance voltages on the cables and ports of secondary circuits. In smart GIS substations, secondary devices especially, such as the intelligent component of electronic instrument transformer, are vulnerable to electromagnetic interference. In this paper, the disturbance voltages induced on the ports of intelligent component of electronic instrument transformer had been measured in three 500-kV GIS substations, respectively. The disturbance was generated either during disconnector (DS) switching operations or circuit breaker (CB) operations. Then, the time-domain and frequency-domain characteristics of the disturbance waveforms have been analyzed. The micro-pulses of disturbance voltages have been extracted from the raw data. The waveform parameters, including peak voltage, rise-time, dominated frequency, and duration, have been calculated by the statistical analysis. The comparison between disturbance during DS switching operations and that of CB operations has been made. Also, the differences and similarities of disturbances between the three GIS substations have been displayed. Furthermore, the differences between measured waveforms and the IEC 61000-4-18 immunity test standard waveform have been discussed."
  },
  {
    "year": "2017",
    "abstract": "The next generation of wireless communications, which is proposed to operate in the mmWave region of the electromagnetic spectrum, offers the potential of high-data rate and increased coverage in response to a rapid growth of mobile data traffic. Operation in an mmWave channel is subject to physical and current technical limitations compared with conventional terrestrial microwave channel propagation. In this paper, the effects of antenna misalignment are considered in an mmWave channel through polarization mismatch. Tri-orthogonal polarization diversity is suggested as a means for mitigating misalignment effects and offering increased link performance over a majority of antenna orientations. A known physically realized planar antenna design offering such diversity is highlighted."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a hybrid one-way full-duplex (OWFD)/two-way half-duplex (TWHD) relaying scheme to improve the performance of the relay system with asymmetric channel gains and traffic requirements. In the proposed scheme, the transmit time interval is decomposed to three subintervals, and in each subinterval the relay operates in OWFD or TWHD mode. The duration of each subinterval is optimized to minimize the system outage probability. We show that the subinterval time optimization can be formulated as a linear programming problem. By exploiting the structure of the problem, the closed-form solution of the problem was derived. We also present a power control scheme to mitigate the effect of residual self-interference (RSI) when the relay is operated in the OWFD mode. Simulation results show that the hybrid scheme achieves better outage performance under the asymmetric environment when compared with the traditional schemes. Moreover, the scheme is robust to the RSI caused by the full-duplex operation."
  },
  {
    "year": "2017",
    "abstract": "This paper describes the use of ArF immersion lithography to verify the feasibility of a self-developed freeform illumination source that exposes features on masks and forms resist patterns. After development inspection (ADI) was used to measure the results and inspect whether the critical dimension (CD), process window, line-edge roughness (LER), and line-width roughness (LWR) of the resist pattern attained the standards of existing manufacturing processes. The testing features include nine horizontal and eight vertical features. Ant colony optimization (ACO) can provide optimal freeform illumination sources for these horizontal and vertical features. This paper considers each feature's particular weighting in order to test the complexity and adaptability of the ACO algorithm applied to semiconductor manufacturing processes. The results of source calculations show that all 17 testing features can be satisfied with the X symmetry freeform source. When using this freeform source in an ArF lithography system, the ADI resist CD of all testing features is located within ±10% target CD tolerance. The ADI target CD set by dense patterns is 40 nm. Resist pattern ADI CD measurements show that, under a through-focus condition, the resist pattern CD between 40 and 42 nm is within tolerance, the depth of focus can reach up to 0.1 μm , LER is approximately 5 nm, and LWR is approximately 7 nm. These ADI CD measurements show that this ACO-based freeform source can be integrated into existing advanced semiconductor lithography processes."
  },
  {
    "year": "2017",
    "abstract": "Soft-decision-aided multi-set steered space-time shift keying intrinsically amalgamated with channel coding is proposed in order to attain near capacity-performance. Multi-set space-time shift keying (MS-STSK) is a multiple-input multiple-output scheme, which combines the concepts of spatial modulation (SM) and STSK for the sake of achieving high data rates and enhanced system integrity. Furthermore, an MS-STSK is combined with orthogonal frequency-division multiplexing (OFDM) as well as single-carrier frequency domain equalization (SC-FDE) and additionally enhanced by analog beamforming in order to support communications at millimeter-wave (mmWave) frequencies. Given that OFDM-based SM systems cannot directly benefit from the reduced number of RF chains of SM due to the spreading effects of the fast-Fourier transform and they suffer from a high peak-to-average power ratio, we opt for employing the SC-based arrangement. The soft-decision-aided detector of the SC-based MS-STSK is combined with recursive systematic convolutional encoding and iterative detection at the receiver side in order to achieve excellent performance within 1.1 dB and 1.4 dB, respectively, from the capacity limit for the soft-decision MS-STSK system and within 1.1 dB from the capacity limit for the SC-FDE-aided soft-decision MS-STSK. We also use extrinsic information transfer charts for analyzing our systems and evaluate their achievable rates."
  },
  {
    "year": "2017",
    "abstract": "Dose-volume (DV)-based objectives are widely used in most intensity-modulated radiation therapy treatment planning, because numerous DV endpoints have been utilized. In clinical practice, DV-based optimization (DVO) with uniform or random initial intensity distributions is utilized, but without considering the non-convexity of the DV objectives. To improve the quality of DVO radiotherapy plan and reduce the local minimum error generated by non-convexity of the DV objective, we proposed an efficient method (an organ-model-based optimization guiding DVO) to determine the initial intensity distributions for DVO. The new approach includes two steps. First, fluence map optimization, based on the organ model that adopts our proposed increasing objective function, to assure organ evaluation criteria Pareto surface, was performed. Second, DVO procedure was performed by using the initial intensity distributions determined in the first step. We demonstrated this technique in two kinds of clinical cases. DV histogram metrics were adopted as the criterion to evaluate the treatment plans. Compared with the conventional DVO plan with uniform initial intensity distributions, the improved DVO plan provided better protection of organ at risk (OAR); the planning target volume coverage was similar. Moreover, the improved DVO plan was better than the plan generated in the first step. The proposed method, with advantages in determining the initial intensity distributions, was highly efficient to improve DVO plans."
  },
  {
    "year": "2017",
    "abstract": "Smart TV in China as an important component of the smart home, does not only have the functions of the traditional TV, but also have the functions, such as distance education, remote monitoring, E-business, and media playing, which brings about its software to be more complex in structure and larger in scale, accordingly, the total testing efficiency becomes lower when using traditional testing methods, and the deep-hidden software defects cannot be detected efficiently and effectively. A novel automatic software testing method based on system design specifications is proposed to improve the smart TV software testing efficiency. First, the behavior of the smart TV is modeled, based on the system design specification with hierarchical state transition matrixes (HSTMs). The scale of the state model of the smart TV is lowered by setting the group state according to the choice of the key nodes based on the importance of the nodes in the network; then, the HSTM model is converted into an expanded regular expression (ERE) with the memory property. Second, every closure operator in the ERE is replaced recursively with a certain integral value, according to the cyclomatic complexity of an ERE in the closure to generate a simplified ERE. Then, a test case is generated from the simplified ERE. Finally, the test cases are converted into python script, and a test platform is designed to send the python script to the Android smart TV automatically through its android debug bridge interface. The practical application shows that the test period is shortened, and comparing with the traditional manual test methods, more errors can be tested."
  },
  {
    "year": "2017",
    "abstract": "Gas leakage is one of the most frequent types of accidents in the petrochemical industry. It is imperative to use mobile sensors to monitor such an accident area. The new and effective way is to use drones and helicopters that spray wireless sensors from the air to monitor harmful gases and to locate the gas leaking source. However, the sprayed wireless sensors will be distributed randomly around the accident area, and it is a challenge to obtain effective coverage. This paper proposes a gravitation-based redeployment algorithm for sensors (GRSS) that considers the virtual boundary forces and the gas concentration in a 3-D accident monitoring area. A priority-based redeployment algorithm for sensors (PRSS) is proposed to further improve the coverage and simplify the 3-D redeployment problem. PRSS considers the layer priorities of the monitoring area to control the movements of the mobile sensors. The simulation results show that the GRSS and PRSS methods can achieve better coverage and utilize less distance compared with the random algorithm and 3-D self-deployment."
  },
  {
    "year": "2017",
    "abstract": "A study of coupling characteristic between circular corrugated waveguide and rectangular smooth waveguide has been presented in this paper, which aims to develop a directional coupler integrated into a miter bend for an electron cyclotron resonance heating system on EAST. The performances of the several aperture array distributions are analyzed based on the aperture diffraction theory in detail. The broadband, good in-band coupling flatness, and excellent directivity are achieved by using the proposed novel aperture array on the mirror surface. For verification purpose, a prototype of the directional coupler has been designed and fabricated."
  },
  {
    "year": "2017",
    "abstract": "The active front steering (AFS) technique is one of the effective methods to handle the stability of a vehicle. In this paper, some AFS control schemes have been proposed. First, a two degree of freedom mathematical model for the vehicle dynamics has been introduced in order to calculate the desired yaw rate. On this basis, the actual sideslip angle is further identified and estimated by constructing a sliding-mode observer. Then, two kinds of baseline AFS controllers are proposed by using PID and terminal sliding mode techniques, such that the actual yaw rate will approach its reference value as closely as possible. To further improve the performance of the closed-loop AFS control system, taking the uncertainties and external disturbances into account, the composite control schemes are developed by combining the previous designed state-feedback controllers and feedforward compensation term generated by the disturbance observer. The effectiveness of the designed AFS control schemes is verified by using the Carsim Software. It has been verified that the performance under two composite controllers is better than both baseline controllers."
  },
  {
    "year": "2017",
    "abstract": "High-performance single-ended wideband and balanced bandpass filters loaded with steppedimpedance stubs are proposed in this paper. For the proposed wideband filter and the differential mode of the proposed balanced filter, two transmission zeros near the passband are realized by using simple stepped-impedance stubs, which enhances the passband selectivity of these new filters. The analytical and accurate design equations for transmission poles and zeros of these single-ended and balanced filters are provided based on the scattering-parameters theory. The single-ended bandpass filter, employing a T-shaped structure to produce a wide passband, is achieved with 3-dB fractional bandwidth of 79.33%, 19-dB passband return loss, and 35-dB harmonic suppression (1.56f0-2.51f0, f0is the center frequency of the wide passband). The 3-dB differential-mode fractional bandwidth of 33% with 22-dB passband return loss and the 30-dB harmonic suppression (1.29f0-2.67f0) are obtained in the proposed balanced bandpass filter. In addition, by inserting open-circuit stubs into the proposed balanced bandpass filter, over 25-dB common-mode suppression is obtained from 0 to 2.67f0. Good agreement is observed between the simulation and measurement results."
  },
  {
    "year": "2017",
    "abstract": "This paper seeks to optimize customer attraction for mobile apps in m-commerce. We model this problem as a mobile-oriented catalog (MOC) segmentation problem. We use query-based learning (QBL) to develop MOCs and aim to attract most number of customers through minimal number of MOCs. This paper illustrates how to design attractive MOCs to recommend items by using QBL genetic algorithm (QBLGA). We propose preference modeling, Product2Vec, Transaction2Vec, and their variations as our oracles of QBLGA. These oracles can aggregate similar purchasing experiences to optimize combination of products for MOC construction. We divide these oracles into major oracle and minor oracles, and then, QBLGA uses these two types of oracles to produce high-attractive products. Experiments show that QBLGA outperforms the state-of-the-art algorithm to attract the greatest number of customers."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the secure degree of freedom (SDOF) of the multiway relay wiretap system K-user MIMO Y wiretap channel, where each legitimate user equipped with M antennas intends to convey independent signals via an intermediate relay with N antennas. There exists an eavesdropper which is equipped with Ne antennas close to the legitimate users. In order to eliminate the multiuser interference and keep the system security, interference alignment is mainly utilized in the proposed broadcast wiretap channel (BWC) and multi-access BWC (MBWC), and cooperative jamming is adopted as a supplementary approach in the MBWC model. The general feasibility conditions of the interference alignment are deduced as M ≥ K - 1, 2M > N and N ≥ ((K(K - 1))/2). In the BWC model, we have deduced the secure degrees of freedom (SDOF) as K min{M, N} - min{Ne, K(K - 1)/2}, which is always a positive value. While in the MBWC model, the SDOF is given by K min{M, N}. Finally, since the relay transmits the synthesized signals of the legal signal and the jamming signal in the MBWC model, we propose a power allocation scheme to maximize the secrecy rate. Simulation results demonstrate that our proposed power allocation scheme can improve secrecy rate under various antenna configurations."
  },
  {
    "year": "2017",
    "abstract": "Intelligent transportation systems (ITSs) providing efficient road-transportation strategies have recently become a very active research area. Efficient transportation of visitors to/from highly congested sites is one of the most important challenges addressed by ITS. A transportation-system analysis is presented here and is applied on an urban city ring road network that encompasses a major attraction site characterized by correlated network-intersections and large vehicle-pedestrian movement conflicts. The presented model analysis first examines the influences exerted by network-correlations at intersection-points, and second, presents case-study evacuation scenarios examined under varying circumstances and flow-requirements within each segment of the modeled network. The significance of this paper is clearly evident in emergency/evacuation scenarios or in design considerations in which the influence of correlated network-intersections must be known beforehand. As a main contribution, a mathematical model was developed with simulations evaluating the current system using real-life data as statistical input to our model. Results had demonstrated the counter-propagation effect between adjacent intersections along the ring road of an urban congested city. Furthermore, the study modeled and investigated two emergency-evacuation scenarios within chosen segments at road network sites entering and exiting the central area in order to demonstrate how efficient evacuation can be conducted during an emergency scenario. It is expected that the results of this model can also be extended and applied for evacuation analyses for other sites with similar practical conditions or in other congested cities in which correlated intersections have a significant presence that must be included in the real-life analysis of a transportation system."
  },
  {
    "year": "2017",
    "abstract": "We optimize an image sensor-based indoor visible light positioning (VLP) system by improving the positioning algorithm. Specifically, we derive a close-form expression to determine the receiver's position and orientation using the singular value decomposition (SVD) technique, which speeds up the positioning process and enhances the robustness. Simulation results show that the proposed SVD-based noniterative positioning algorithm is 50-80 times faster than the conventional iterative Levenberg-Marquardt-based algorithm and avoids the possible failures caused by the bad initial guesses. Meanwhile, we theoretically investigate the VLP system by deriving the Cramer-Rao lower bound and the root mean square error bound as the positioning accuracy limit and study the impact of system parameters on the positioning error. Finally, we experimentally evaluate the performance of the improved VLP system. It achieves highly robust and fast 3-D positioning with centimeter-level accuracy."
  },
  {
    "year": "2017",
    "abstract": "Data dissemination finds a wide range of appealing applications in disaster alert, event notification, and content distribution. In particular, with the evolution of mobile networks and the popularity of online social networks, mobile social networks (MSNs) offer a promising paradigm to facilitate data dissemination. Traditional data dissemination approaches focus on how to leverage the resources in the physical networks, such as opportunistic contacts in delay tolerant networks and opportunistic networks, or the infrastructure in the cellular networks. In contrast, social-aware data dissemination approaches also exploit the valuable information from the social networks and take into consideration the complex requirements of human users. A systematic review of the existing approaches for data dissemination can provide insightful information and motivate more in-depth studies in this area. In this paper, we first review some traditional approaches as a basis for comparison. Then, we introduce some fundamental background on MSNs, device-to-device (D2D) communication, game theory, and matching theory, which have been used in existing studies on social-aware data dissemination. The technical and mathematical information is helpful for readers to follow our discussions in the main body of this paper, which surveys many social-aware approaches in the literature. We group our discussions based on the theoretical models for various problems in data dissemination. Also, we separate the problems, initial source selection and incentive design, from others to emphasize their importance. In the end, we highlight some interesting research directions for future study on data dissemination."
  },
  {
    "year": "2017",
    "abstract": "A compact and high-gain SIW-fed circularly polarized (CP) slot-antenna array with a stacked feed structure is presented for the application of Ku-band high-data-rate satellite communications. First, a novel probe-fed SIW cavity with four slots etched on the top surface is proposed as a high-gain radiating element for the array. The four slots in the cavity act as a 2 x 2 array, and its directivity is 2.15 and 1.43 dB greater than that of the cavity-backed antenna of the same size using ring slot and split ring slot, respectively. Second, a compact 1-4 SIW power divider is designed for exciting a subarray. Third, the 2 x 2 subarray is further expanded to an 8 x 16 array by adopting an additional layer of 1-32 SIW feeding network to meet the gain requirement of the Ku-band mobile satellite TV reception. Finally, experiments are carried out to verify the designed prototypes. Measured results show that proposed 128-element array has a relative impedance bandwidth of 4.8% (11.84 to 12.42 GHz), AR bandwidth of 130 MHz (12.01 to 12.14 GHz), and a peak gain of 26.8 dBic at 12.06 GHz. Owing to the simple feeding networks and the compact radiating element, the antenna has a compact size of 6.04λ0x 11.96λ0x 0.1λ0. Experimental results show that the proposed CP antenna array is suitable for applications of Ku-band mobile satellite TV reception."
  },
  {
    "year": "2017",
    "abstract": "Project managers need to determine the appropriate operations for solving problems in project management. In order to obtain the necessary skills for determining these operations, project managers learn and practice the theory of project management, which requires great deal of time and money. To provide more efficient training for project managers, we developed a skill-up simulator to allow the project manager to practice such operations on a computer. However, the simulator did not show the project manager which operations need to be improved. Our proposed method identifies the operations that need to be improved in comparison to other operations. Because it is time-consuming to collect operations from other project managers, agent programs automatically generate the operations in the proposed method. By inputting the generated operations to the simulator, the proposed method obtains project results for the operations. Operations to be improved are identified by a decision tree trained with other operations and evaluations. The experimental results confirm that the proposed method can correctly identify operations that need to be improved."
  },
  {
    "year": "2017",
    "abstract": "A convolutional network (CN) code can be described by either global encoding kernels (GEKs) or local encoding kernels (LEKs). In the literature, the multicast property of a CN code is described using GEKs, so the design algorithms for multicast CN codes employ GEKs to check this property. For cyclic networks, using GEKs makes the design algorithms time-consuming. In this paper, a new approach is proposed for the design of multicast CN codes for networks with cycles. First, a formula is presented to describe the multicast property using LEKs rather than GEKs. Then, this formula is used to develop a design algorithm for multicast CN codes. This algorithm does not use GEKs, which makes it more efficient than GEK-based algorithms, particularly for large cyclic networks."
  },
  {
    "year": "2017",
    "abstract": "Increasing operational and security demands changed biometrics by shifting the focus from single to multi-biometrics. Multi-biometrics are mandatory in the current context of large international biometric databases and to accommodate new emerging security demands. Our paper is a comprehensive survey on multi-biometrics, covering two important topics related to the multi-biometric field: fusion methods and security. Fusion is a core requirement in multi-biometric systems, being the method used to combine multiple biometric methods into a single system. The fusion section surveys recent multi-biometric schemes categorized from the perspective of fusion method. The security section is a comprehensive review of current issues, such as sensor spoofing, template security, and biometric encryption. New research trends and open challenges are discussed, such as soft, adaptive contextual-based biometrics. Finally, an implementation blueprint for a multi-biometric system is presented in the form of a list of questions to be answered when designing the system."
  },
  {
    "year": "2017",
    "abstract": "The presence of 3-D maps of remote environments offers realistic visualization of both front and surrounding views. The surrounding view allows operators to observe different side views by controlling their viewpoint. Viewpoint control can be achieved by using the orientation of the operators' input device, which is mostly akin to gamepad controller. This kind of method assumes that binding the gamepad orientation to the 3-D map could benefit the operators during tasks; therefore, assessing operators' performance is required to validate this assumption. This paper assessed the effect of using gamepad orientation for controlling 3-D map viewpoint during remote navigation. The evaluation was conducted by comparing a tethered viewpoint against a controllable viewpoint within a simulated telerobot situation. The evaluation resulted in a contradictive state, where participants' positive opinions and preferences were against their actual workloads (d = 0.299, 95% CI [-0.200, 0.792]). The contradiction indicated the presence of naïve realism on using gamepad orientation for rapidly controlling viewpoint of 3-D map views. Meanwhile, shifts in participants' navigation behavior were also observed."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate a coverage extension scheme based on orthogonal random precoding (ORP) for the downlink of massive multiple-input multiple-output systems. In this scheme, a precoding matrix consisting of orthogonal vectors is employed at the transmitter to enhance the maximum signal-to-interference-plus-noise ratio of the user. To analyze and optimize the ORP scheme in terms of cell coverage, we derive the analytical expressions of the downlink coverage probability for two receiver structures, namely, the single-antenna receiver and multiple-antenna receiver with antenna selection. The simulation results show that the analytical expressions accurately capture the coverage behaviors of the systems employing the ORP scheme. It is also shown that the optimal coverage performance is achieved when a single precoding vector is used under the condition that the threshold of the signal-to-noise ratio of the coverage is greater than one. The performance of the ORP scheme is further analyzed when the different random precoder groups are utilized over multiple time slots to exploit precoding diversity. The numerical results show that the proposed ORP scheme over multiple time slots provides a substantial coverage gain over the space-time coding scheme despite its low feedback overhead."
  },
  {
    "year": "2017",
    "abstract": "High-mobility adaption and massive multiple-input multiple-output (MIMO) application are two primary evolving objectives for the next generation high-speed train (HST) wireless communication system. In this paper, we consider how to design a location-aware beamforming for the massive MIMO system in the high traffic density HST network. We first analyze the tradeoff between beam directivity and beamwidth, based on which we present the sensitivity analysis of positioning accuracy. Then, in order to guarantee a high efficient transmission, we derive an optimal problem to maximize the beam directivity under the restriction of diverse positioning accuracies. After that, we present a low-complexity beamforming design by utilizing location information, which requires neither eigendecomposing (ED) the uplink channel covariance matrix (CCM) nor ED the downlink CCM. Finally, we study the beamforming scheme in the future high traffic density HST network, where a two HSTs encountering scenario is emphasized. By utilizing the real-time location information, we propose an optimal adaptive beamforming scheme to maximize the achievable rate region under limited channel source constraint. Numerical simulation indicates that a massive MIMO system with less than a certain positioning error can guarantee a required performance with satisfying transmission efficiency in the high traffic density HST scenario and the achievable rate region when two HSTs encounter is greatly improved as well."
  },
  {
    "year": "2017",
    "abstract": "AA compact microstrip low-pass filter (LPF) with an ultra-wide stopband and its design procedure are proposed in this paper. Using three-stepped impedance stubs(SISs), multiple transmission zeros are introduced in the stopband and can be freely controlled by tuning the impedance ratio of the SISs. Without using the defected ground structures to expand the stopband, three additional open-circuited stubs are used to suppress more spurious passbands of the LPF. To illustrate the concept, an experimental stopband LPF with cut-off frequency (fc) at 0.9 GHz is designed, simulated, fabricated, and measured. A metallic box with absorbent material is used to load the lowpass filter with wide stopband. The measured results are found in good agreement with the simulated results, and indicated good performance: broad stopband (> 17.6fc) with attenuation higher than 22.4 dB, low-passband insertion loss (<;0.5 dB), and compact size."
  },
  {
    "year": "2017",
    "abstract": "The Rao-Blackwellized particle filtering (RBPF) offers a general tracking framework with linear/nonlinear state space models, which outperforms the standard particle filtering in nonlinear and non-Gaussian tracking scenarios. Unfortunately, in conventional radar systems, the observations contain no information about the linear part of target state. In these cases, the RBPF algorithm fails to catch the real trajectories, because we cannot obtain the enough information to correctly update the linear part of target state in the tracking procedure. To overcome such an issue, this paper proposes a Kalman estimation-based BRPF (KE-BRPF) algorithm. In KE-RBPF, the correlation between linear and nonlinear parts of target state is investigated. Benefitting from such investigation, we derive a new set of formulea to present the correlation in terms of means and variances. By utilizing these formulas, our KE-RBPF algorithm correctly tracks the linear part of target state based on the nonlinear one. Finally, the simulation results verify that, our KE-RBPF performs better than other state-of-the-art tracking methods in nonlinear and non-Gaussian radar tracking scenarios, with at least 18% reduction in terms of the means and central tendency of error of tracking root-mean-square-error."
  },
  {
    "year": "2017",
    "abstract": "The in-network caching strategy in named data networking can not only reduce the unnecessary fetching of content from the original content server deep in the core network and improve the user response time, but also ease the traffic in the core network. However, challenges exist in in-network caching, such as the distributed locations of storage and relatively small cache space which limit the hit rate, and the cache management introduces further overhead. In this paper, we propose a two-layer hierarchical cluster-based caching solution to improve in-network caching efficiency. A network is grouped into several clusters, then, a clusterhead is nominated for each cluster to make caching decision. The clustering approach offers scalability and permits multiple aspects of inputs to be used for decision making. Our solution jointly considers the location and content popularity for caching. We implement our strategy in ndnSIM and test it on GEANT-based network and AS3967 network. Our simulation results show significant improvement over its peers."
  },
  {
    "year": "2017",
    "abstract": "Model predictions are presented to evaluate the electrodynamic parameters as expected at the orbit of the China Seismic-Electromagnetic Satellite (CSES). The main objective of this paper is that of improving the accuracy of the electric field detectors (EFDs), which are installed on CSES and will measure the field vector in a wideband from dc up to 3.5 MHz. The electric field components are derived from the probe floating potential readings, thus an accurate characterization of the space environment is needed to model the currents collected from the ionosphere and establish the EFD probe response. The plasma environment and the magnetic field along the orbit are determined using the standard IRI and IGRF models. Simulations are used to determine the bias currents, which have to be applied to the probes to minimize the contact impedance between the EFDs and the ionospheric plasma. Correction voltages required to remove the v⃗ × B⃗ electric field from the EFD measurements are also estimated."
  },
  {
    "year": "2017",
    "abstract": "Fog and mobile edge computing have gained considerable attention from the research and development community. The problems related to security and privacy of biometric content are simpler to solve through edge computing resulting in improved security and privacy of biometric and other critically private information. Zero-watermarking has been proposed as a solution to help protect the ownership of multimedia content that is easy to copy and distribute. Visual cryptography is another approach to secure data that is to be shared through generating multiple shares. This paper is concerned with developing a biometric security solution for face images, using visual cryptography and zero-watermarking, that does not adversely impact the visual quality of the image. The original face image is not modified through the zero-watermarking and visual encryption procedures and this in turn does not adversely impact the recognition rate."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new method of designing RF ring oscillator using current-mode technology is presented. The current-mode low frequency oscillator theory is transferred to facilitate the design of RF ring oscillator. As an example, a current-mode RF quadrature ring oscillator (RFQRO) for L -band wireless communication applications is presented. The current-mode RFQRO consists of two first-order all-pass filters, and it provides four quadrature RF sinusoidal outputs. The proposed current-mode RFQRO is verified with GlobalFoundries' 0.18 μm 1P6M CMOS RF process. The simulated and measured results demonstrate that the proposed RFQRO works at 1.03 GHz, and its frequency tuning range is from 648.9 MHz to 1.17 GHz by adjusting the bias voltage from 0.62 to 1 V. The measured phase noise of the RFQRO is -105.5 dBc/Hz at 1 MHz offset, and it consumes 2.5 mW from 1 V supply voltage."
  },
  {
    "year": "2017",
    "abstract": "By connecting devices, people, vehicles, and infrastructures everywhere in a city, governments and their partners can improve community well-being and other economic and financial aspects (e.g., cost and energy savings). Nonetheless, smart cities are complex ecosystems that comprise many different stakeholders (network operators, managed service providers, logistic centers, and so on), who must work together to provide the best services and unlock the commercial potential of the so-called Internet of Things (IoT). This is one of the major challenges that faces today's smart city movement, and the emerging “API economy.” Indeed, while new smart connected objects hit the market every day, they mostly feed “vertical silos” (e.g., vertical apps, siloed apps, and so on) that are closed to the rest of the IoT, thus hampering developers to produce new added value across multiple platforms and/or application domains. Within this context, the contribution of this paper is twofold: (1) present the strategic vision and ambition of the EU to overcome this critical vertical silos' issue and (2) introduce the first building blocks underlying an open IoT ecosystem developed as part of an EU (Horizon 2020) Project and a joint project initiative (IoT-EPI). The practicability of this ecosystem, along with a performance analysis, is carried out considering a proof-of-concept for enhanced sporting event management in the context of the forthcoming FIFA World Cup 2022 in Qatar."
  },
  {
    "year": "2017",
    "abstract": "Android-based Internet-of-Things devices with excellent compatibility and openness are constantly emerging. A typical example is Android Things that Google supports. Compatibility based on the same platform can provide more convenient personalization services centering on mobile devices, while this uniformity-based computing environment can expose many security vulnerabilities. For example, new mobile malware running on Android can instantly transition to all connected devices. In particular, the Android platform has a structural weakness that makes it easy to repackage applications. This can lead to malicious behavior. To protect mobile apps that are vulnerable to malicious activity, various code obfuscation techniques are applied to key logic. The most effective one of this kind involves safely concealing application programming interfaces (API). It is very important to ensure that obfuscation is applied to the appropriate API with an adequate degree of resistance to reverse engineering. Because there is no objective evaluation method, it depends on the developer judgment. Therefore, in this paper, we propose a scheme that can quantitatively evaluate the level of hiding of APIs, which represent the function of the Android application based on machine learning theory. To perform the quantitative evaluation, the API information is obtained by static analysis of a DEX file, and the API-called code executed in Dalvik in the Android platform is dynamically extracted. Moreover, the sensitive APIs are classified using the extracted API and Naive Bayes classification. The proposed scheme yields a high score according to the level of hiding of the classified API. We tested the proposed scheme on representative applications of the Google Play Store. We believe it can be used as a model for obfuscation assessment schemes, because it can evaluate the level of obfuscation in general without relying on specific obfuscation tools."
  },
  {
    "year": "2017",
    "abstract": "In this paper, considering the practical channel impairments known as pilot contamination and channel aging induced by both Doppler shift and phase noise, we analyze the uplink spectral efficiency of multi-cell multi-user distributed massive multi-input multi-output (MIMO) systems with linear receivers. A joint channel model is first provided, which allows studying the impacts of these impairments on the achievable rate performance of distributed massive MIMO systems simultaneously. Based on this model, using the properties of Gamma distributions together with the approximate methods for non-isotropic vectors, we derive tractable but accurate closed-form expressions for the uplink achievable rate with maximum ratio combining (MRC) and zero-forcing (ZF) receivers in distributed massive MIMO systems. User ultimate achievable rate is also given when the ratio of total number of transmit antennas to the number of users is very large. It is shown that MRC and ZF receivers achieve the same ultimate achievable rate in the presence of the practical channel impairments. Numerical results show that channel aging has a greater impact on ZF receiver and the impact of the Doppler shift is more detrimental than that of the phase noise."
  },
  {
    "year": "2017",
    "abstract": "From the literature review, it is apparent that there is a gap in quantifying the performances of multitone waveforms specifically for radar applications and experimental results not commonly found. This paper focuses on the radar performance analysis of multitones with P3 phase-codes in simulation and experimentally to determine the effect of hardware on radar performances. For this purpose, a software-defined radar (SDR) approach has been used, including a digital core with hardware in-the-loop controlled by MATLAB and an analog front end that uses bandpass sampling and a reference channel. The proposed radar setup with processing algorithm has been evaluated in terms of processing time, showing that a real-time implementation on the latest field programmable gate array chipsets is feasible. This approach is flexible and entirely arbitrary waveforms can be generated with an instantaneous bandwidth up to 800 MHz. All the experimental results presented in Section IV are beyond the state of the art and bring novel insight into the impairment of SDR."
  },
  {
    "year": "2017",
    "abstract": "In recent years, distributed photovoltaic (PV) systems have witnessed rapid development worldwide. Nevertheless, the diffusion of distributed PV systems in a specific region is still indefinite and hard to predict, which bring uncertainties to the planning and operation of electricity distribution network. This paper investigates the diffusion tendency and forecasting approach of distributed PV systems from macro- and micro-aspects. Macroscopic analysis includes spatial clustering of PV systems and quantitative analysis of PV adoption drivers in the time-dimension. Shanghai, Pudong in China is studied in this paper to offer some insights. Analysis reveals that the capacity and location of PV systems are clustered. These clusters continuously spread to the surrounding with changes of size and location, under the impact of internal and external factors. This indicates that diffusion of PV systems can be simulated by a cellular automation model. For microscopic analysis, a data-driven forecasting approach of PV diffusion is proposed based on cellular automation. Analysis shows that the developing state of PV cells can be forecasted based on multi-source datasets. Besides, statistical distribution of newly installed PV capacity per cell tends to be stable, so that it can also be considered as a predictor of distributed PV systems diffusion."
  },
  {
    "year": "2017",
    "abstract": "The wireless energy transfer, which is a promising technology for the wireless sensor networks (WSNs), can efficiently solve the energy scarcity that results from the application boosting. However, not only the energy scarcity, but also the quality of service (QoS) guarantees need to be taken into account for the WSNs. Different types of applications in the WSNs impose the new challenge on heterogeneous QoS provisioning for the WSNs. To solve the above problem, in this paper, we develop the joint downlink energy assignment and uplink power control scheme with the heterogeneous statistical QoS provisioning (HeP) for wireless powered sensor networks (WPSNs). In particular, we build up the HeP model, where the aggregate effective capacity (AEC) is defined as the aggregate throughput under the statistical QoS constraints for the WPSNs. Based on the mode, we formulate the AEC maximization problems for uniformed time division and dynamic time allocation scenarios, respectively. For the uniformed time division scenario, we divide the AEC maximization problem into the hybrid access point determined downlink energy assignment problem and the sensor node determined uplink power control problem. Then, we solve these problems and obtain the corresponding closed-form solutions. For the dynamic time allocation scenario, we develop the joint time allocation, downlink energy assignment, and uplink power control scheme to maximize the AEC and iteratively derive the scheme. Extensive simulations are conducted to demonstrate the effect of heterogeneous statistical QoS on our developed resource allocation schemes for WPSNs. The results show that the HeP resource allocation schemes are superior to the schemes with homogeneous statistical QoS guarantees."
  },
  {
    "year": "2017",
    "abstract": "Optimal multi-objective design of proportional-integral-derivative controller parameters for a small power system using epsilon multi-objective genetic algorithm (ε -MOGA) has been presented in this paper. The small power system includes a wind turbine generator (WTG), a diesel generator, a battery energy storage system (BESS), and a load. The proposed scheme is applied for controlling the pitch angle system of the WTG to minimize the wind turbine mechanical blades stress, reduce the wind output power deviation, control the system frequency, and decrease the size of BESS by regulating its charging level. The deviations of input wind power are considered in a frequency domain. The low-frequency component is reduced by the pitch angle control system of WTG, while the high-frequency component is mitigated by the charge/discharge of the BESS, respectively. The input of the pitch angle control system of WTG is determined according to the low-frequency component of the input wind power deviation and the BESS state of charge. The output power of BESS is determined according to its state of charge, the high-frequency component of the input wind power deviation, and the frequency deviations. The effectiveness of the proposed controller is confirmed by numerical simulations."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the energy-efficient transmission problem with non-first-in-first-out (FIFO) packets for a point-to-point additive white Gaussian noise channel with processing cost. This work can be considered as a generation of previous work in terms of the assumption of the FIFO transmission order, which means the earlier arrived packet must have an earlier deadline. Assuming non-causal data arrival information, we first formulate the objective as a non-convex optimization problem, and then investigate the necessary and sufficient conditions of the optimal offline transmission schedule. Based on the optimal properties of these conditions, an efficient offline algorithm that finds the optimal transmission schedule minimizing the total energy consumption is proposed. Next, we identify the optimality of the proposed offline algorithm by proving it satisfies the sufficient conditions of optimality, and further, respectively, analyze the computational complexity in the best case:O(N2)and in the worse case:O(N3), whereNis the packet number of the sequence. Finally, based on the insights obtained from the offline transmission schedule, an efficient heuristic online algorithm performing close to the offline transmission schedule is proposed under the assumption that the data arrival information is known causally at the transmitter."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a procedure for designing a mechanical training and rehabilitation gait system centered on ankle trajectories for children with cerebral palsy or any other psycho-motor limitation. With the aim of developing a reconfigurable device adjustable to the anthropometric characteristics of the user, an analytic model for the generation of ankle trajectories was elaborated, taking as a base the experimental data reported in literature. A dimensional synthesis for a mechanism to follow the drop type trajectories was carried out as a constrained numerical optimization problem that was solved with both the mathematical programming method and an evolutive algorithm, sequential quadratic programming (SQP) and differential evolution (DE), respectively. The comparative analysis of the results from both methods for this case study shows that DE outperforms SQP because of the limited feasibility space derived from the problem constrains and boundaries. The best result from DE was simulated with a computer-aided design package using a real size model for manufacturing."
  },
  {
    "year": "2017",
    "abstract": "Considering a rapidly increasing seaborne trade and drastic climate changes due to emissions, produced by oceangoing vessels and container handling equipment, marine container terminal operators not only have to improve effectiveness of their operations to serve the increasing demand, but also to account for the environmental impact associated with the terminal operations. This paper proposes a novel mixed integer mathematical model for the berth scheduling problem, which minimizes the total service cost of vessels, including the total carbon dioxide emission cost due to container handling. The latter pollutant is a primary greenhouse gas that causes global warming. A Hybrid Evolutionary Algorithm, which deploys a set of local search heuristics, is developed to solve the problem. Computational experiments showcase that the optimality gap of the proposed solution algorithm does not exceed 1.61%. It is further shown that the application of additional local search heuristics allows efficient discovery of promising solutions throughout the search process. Results from numerical experiments also indicate that changes in the carbon dioxide emission cost may significantly affect the design of berth schedules. The developed mathematical model and the proposed solution algorithm can thus be adopted as effective planning tools by the marine container terminal operators and improve the environmental sustainability of the terminal operations."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a method for fusing multi-exposed images that can operate on digital cameras or smartphones. The proposed method consists of an automatic exposure bracketing algorithm that determines which exposures to capture and a newly proposed multi-exposure image fusion algorithm. This fusion algorithm attempts to improve the fusion performance on the basis of the recently proposed no-reference image-quality metrics, noting that the exposure change affects the change in the local luminance details, contrast, and colorfulness of a pixel. Experimental results of various sample image sequences show the superiority of the proposed fusion algorithm in terms of both objective and visual evaluations. By using the proposed method, users can capture high-dynamic range images directly on digital cameras or smartphones, without using offline image-processing software."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a comparison of the expected lifetime for Internet of Things (IoT) devices operating in several wireless networks: the IEEE 802.15.4/e, Bluetooth low energy (BLE), the IEEE 802.11 power saving mode, the IEEE 802.11ah, and in new emerging long-range technologies, such as LoRa and SIGFOX. To compare all technologies on an equal basis, we have developed an analyzer that computes the energy consumption for a given protocol based on the power required in a given state (Sleep, Idle, Tx, and Rx) and the duration of each state. We consider the case of an energy constrained node that uploads data to a sink, analyzing the physical (PHY) layer under medium access control (MAC) constraints, and assuming IPv6 traffic whenever possible. This paper considers the energy spent in retransmissions due to corrupted frames and collisions as well as the impact of imperfect clocks. The comparison shows that the BLE offers the best lifetime for all traffic intensities in its capacity range. LoRa achieves long lifetimes behind 802.15.4 and BLE for ultra low traffic intensity; SIGFOX only matches LoRa for very small data sizes. Moreover, considering the energy consumption due to retransmissions of lost data packets only decreases the lifetimes without changing their relative ranking. We believe that these comparisons will give all users of IoT technologies indications about the technology that best fits their needs from the energy consumption point of view. Our analyzer will also help IoT network designers to select the right MAC parameters to optimize the energy consumption for a given application."
  },
  {
    "year": "2017",
    "abstract": "Gaussian approximation (GA) is widely used to construct polar codes. However, when the code length is long, the subchannel selection inaccuracy due to the calculation error of conventional approximate GA (AGA), which uses a two-segment approximation function, results in a catastrophic performance loss. In this paper, new principles to design the GA approximation functions for polar codes are proposed. First, we introduce the concepts of polarization violation set (PVS) and polarization reversal set (PRS) to explain the essential reasons that the conventional AGA scheme cannot work well for the long-length polar code construction. In fact, these two sets will lead to the rank error of subsequent subchannels, which means that the orders of subchannels are misaligned, which is a severe problem for polar code construction. Second, we propose a new metric, named cumulative-logarithmic error (CLE), to quantitatively evaluate the remainder approximation error of AGA in the logarithm. We derive the upper bound of CLE to simplify its calculation. Finally, guided by PVS, PRS, and CLE bound analysis, we propose new construction rules based on a multi-segment approximation function, which obviously improve the calculation accuracy of AGA so as to ensure the excellent performance of polar codes especially for the long code lengths. Numerical and simulation results indicate that the proposed AGA schemes are critical to constructing high-performance polar codes."
  },
  {
    "year": "2017",
    "abstract": "An efficient and training-sample-reducing space-time adaptive processing (STAP) algorithm based on sparse representation for ground clutter suppression in airborne radar is proposed in this paper. First of all, the principle and problems of sample matrix inversion-based STAP and sparse representation (SR)-based STAP algorithms are reviewed. Then, the conception of the local space-time spectrum (LSTS) of clutter is considered by exploiting the intrinsic sparsity nature of clutter in local beams and the Doppler domain. To estimate the LSTS using the sparse representation technique in a cost-effective way, a variable space-time mask matrix is designed. Finally, the reduced-dimension clutter plus noise covariance clutter matrix and the corresponding adaptive weight vector are calculated based on the estimated LSTS. Numerical results with both simulated data and Mountain-Top data demonstrate that the new algorithm provides an excellent performance of clutter suppression and moving target detection with only one training range cell and significant computational savings compared with existing SR-based STAP algorithms."
  },
  {
    "year": "2017",
    "abstract": "The topic of subcarrier and power allocation in the downlink of an orthogonal frequency division multiple access decode-and-forward relaying system is presented with the objective of encompassing system stability and interference limitations in one inclusive problem. The introduced model is designed to maximize the overall throughput of the cell-edge users that are served by relay stations. We analyze the stability requirement of buffers in the base station and the corresponding relay stations, and define the rate constraints in order to guarantee queue stability without requiring a priori knowledge of arrival traffic's statistics. The explained model results in a nonconvex optimization problem, and therefore, we employ a time-shared technique to achieve the closed form solution, which is only applicable when subcarriers can be shared by the users during one time-slot. In the case where the subcarriers are not allowed to be time-shared, we introduce a computationally efficient optimal binary subcarrier and power allocation method, in addition to a power conservative allocation mechanism. Using geometric-programming and monomial approximation techniques, we show that the proposed conservative approach, although nonconvex, can be solved in polynomial time. We also study the impact of adjustable time-slot division and interference-tolerance parameters on improving system performance. The extensive simulation results demonstrate the success of the proposed methods in terms of stabilizing the queues, improving the throughput by 30% and energy efficiency gain by 90%, in comparison with the existing similar models in the literature."
  },
  {
    "year": "2017",
    "abstract": "Over the past few decades, the art of secretly embedding and communicating digital data has gained enormous attention because of the technological development in both digital contents and communication. The imperceptibility, hiding capacity, and robustness against attacks are three main requirements that any video steganography method should take into consideration. In this paper, a robust and secure video steganographic algorithm in discrete wavelet transform (DWT) and discrete cosine transform (DCT) domains based on the multiple object tracking (MOT) algorithm and error correcting codes is proposed. The secret message is preprocessed by applying both Hamming and Bose, Chaudhuri, and Hocquenghem codes for encoding the secret data. First, motion-based MOT algorithm is implemented on host videos to distinguish the regions of interest in the moving objects. Then, the data hiding process is performed by concealing the secret message into the DWT and DCT coefficients of all motion regions in the video depending on foreground masks. Our experimental results illustrate that the suggested algorithm not only improves the embedding capacity and imperceptibility but also enhances its security and robustness by encoding the secret message and withstanding against various attacks."
  },
  {
    "year": "2017",
    "abstract": "The implementation of safety applications in vehicular ad hoc networks (VANETs) depends on the dissemination of safety-related messages. A self-sorting MAC protocol is proposed for high-density scenarios. The protocol allows vehicles to sort with others in a collision-tolerance manner before data transmission. The vehicles establish a logic queue by the self-sorting process, and the queue is able to access the channel once the length reaches the set threshold. Vehicles in the queue will access the channel by time-division multiple access when the queue occupies the channel. A queue will compete for accessing the channel on behalf of all the nodes in the queue, which greatly alleviates the contention for access from all nodes. In contrast with completely random access, the slot a queue selects to access the channel depends on the completion time of the self-sorting process. In this case, the queue accomplishing the self-sorting process first can avoid collisions with other queues, since they are still in the self-sorting process. The performance of the proposed protocol is evaluated compared with other typical MAC protocols in VANET. The analysis and simulation results in highway and city scenarios show that the proposed protocol can significantly reduce packets loss and delay especially in dense scenarios."
  },
  {
    "year": "2017",
    "abstract": "Single-instruction set architecture (ISA) heterogeneous multi-processor architecture is promising for developing multi-processor system-on-chips (MPSoCs). In this architecture, all processors execute the same instruction set, yet with various performance and power behavior, since processors may have various micro-architectures. Therefore, systems with this architecture have the advantages of easy to develop new functions as the homogeneous architecture, and easy to customize the resource allocation to achieve high energy efficiency as the heterogeneous architecture. However, for an MPSoC utilizing the target architecture, a key design issue is how to select the set of processors so that the target system can achieve good performance while the cost of the chip is constrained to the expected value. To solve this, in this paper, we propose a processor allocation method for MPSoCs with single-ISA heterogeneous multi-core architecture. The goal of the proposed method is to automatically synthesize the allocation of cores for the given workload so that the performance is optimized while the resource constraint is met. To the best of our knowledge, this is the first work that tackles the processor allocation problem for MPSoCs with the target architecture. To bring out the best performance of a hardware configuration, the proposed algorithm also synthesizes the software design of task mapping for a selected hardware configuration. The experimental results show that, compared with the homogeneous architecture with the least cost and lowest performance cores only, even if the number of core is set to the maximum parallelism degree of the target workload, the proposed method achieves up to 8.25% of performance improvement among all the cases we evaluated while the area constraint is met. Compared with the architecture with all high performance but large cores, when the number of cores is also set to the same as the maximum parallelism degree of the target workload, the propos..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new, complete, and comprehensive breast phantom measurement system is presented. A side slotted vivaldi antenna is used for breast phantom measurement. The radiating fins are modified by etching six side slots to enhance the electrical length and produce stronger directive radiation with higher gain. This approach reduces the lower operating frequency and increases the gain and efficiency without compromising the size of the antenna. The overall size of the antenna is 8.8 (L) × 7.5 (W) cm2or approximately 0.4λ × 0.5λ at the first resonant frequency of 1.79 GHz. The results show that the antenna has a fractional bandwidth of approximately 127% from 1.54 to 7 GHz for return loss less than 10 dB with a directional radiation pattern. The average gain of the proposed prototype is 8.5 dBi, and the radiation efficiency is approximately 92% on average over the operating bandwidth. The fidelity factor for face to face is 0.98, and that for side by side is 0.4479, which proves the directionality and lower distortion of the signal. The prototype is successfully simulated, fabricated, and analyzed. The radiating fins of the proposed prototype are optimized to achieve the desired properties for breast phantom measurement. The antenna is used as the transceiver in a breast phantom measurement system to detect unwanted tumor cells inside the breast. An automated electromechanical imaging system with the necessary data post processing makes it an easy and suitable tool for microwave imaging to detect breast tumors."
  },
  {
    "year": "2017",
    "abstract": "Ultra dense network (UDN) is the extreme densification of heterogeneous radio access technologies (RATs) that are deployed closely in a coordinated or uncoordinated manner. The densification of RATs forms an overlapping zone of signal coverage, leading user equipment (UE) to frequent signal handovers among the available RATs. Consequently, this degrades the overall system performance. The traditional approach of RAT selection is network-centric and the decision is primarily focused on the signal aspect. However, the next generation of digital wave is a paradigm shift to being user-centric. In this paper, a context-aware multi-attribute RAT (CMRAT) selection approach is proposed to eliminate unnecessary handover of UE among RATs and determine the best RAT as the next point of attachment among the available ones in the UDN. CMRAT integrates the context-aware concept with multi-attribute decision making (MADM) theory in RAT selection. CMRAT is formed with two mechanisms, including, first, a context-aware analytical hierarchy process mechanism to prioritize the criteria for obtaining the weight. Then, a context-aware technique for order preference by similarity to an ideal solution mechanism is employed to choose the best RAT amongst the available RATs. The proposed CMRAT mechanism was implemented and validated using MATLAB. The obtained simulation findings demonstrate that the proposed CMRAT approach outperforms classic MADM methods, namely TOPSIS, SAW, and GRA with respect to the number of handovers and ranking abnormality metrics. Hence, this paper paves the way to choose RAT based on context information comprising network and user preference criteria information."
  },
  {
    "year": "2017",
    "abstract": "The recent rapid development of Web technology, multimedia content, and interactive data has considerably expanded the size of the Internet transmissions. Benefiting from the paradigm-shifting technology of software defined networking (SDN), the administrators are now able to easily manage network flows by customizing flow rules over SDN. Inspired by this, we propose a UDP-based reliable transmission framework to improve efficiency of transmission control protocol (TCP) transmission on an SDN-enabled network. The main idea of our framework is to convert the TCP transmission into UDP packets to decrease the overhead during communications, such as handshaking, acknowledgment, and header overhead while using TCP. To guarantee reliability, we have leveraged the power of SDN to designate packets under our protocol to flow in predefined routes and monitor them to avoid possible packet loss. Our proposal is composed of a series of designs and implementations, including the packet format transformations, packet buffering, and retransmission mechanisms on switches. For users, this means that they are transmitting data with TCP, while the overhead of the TCP traffic is reduced significantly through a reliable and lightweight UDP transmission mechanism on the SDN-enabled network. Our evaluation results show that our framework provides a more efficient bandwidth usage and guarantees the reliability of packets as in TCP transmissions."
  },
  {
    "year": "2017",
    "abstract": "The nature of autonomy and openness of E-commerce in online social (ECOS) networks poses a challenge to the security of transactions as it is difficult to ensure the reliability and trustworthiness of parties on both ends. Transactions in ECOS may, therefore, be conducted in an unreliable environment and be vulnerable to frauds. Trust management schemes, naturally, have come as feasible solutions. With a view to making improvement on the existing trust management mechanisms, we, in this paper, propose a factor-enrichment-based hybrid trust framework for trust measurement in ECOS, in which three levels of trust are used to establish trustworthy opinions among individuals for their transactions: (1) private reputation, which is defined as subjective trustworthy impression among individuals with respect to its feature of dynamic evolution; (2) common reputation, which is defined as collective and sharable trust degree and is proposed with two factors, a consistency factor and a continuity factor, introduced for enhancing the reliability of common reputation; and (3) the hybrid trust, which is proposed to obtain integrated trustable impressions based on private reputation and common reputation, with anti-fraud factor and confidence factor presented to further determine the trustworthiness of hybrid trust. Finally, we list the results of a series of examinations to further verify the performance of our mechanism."
  },
  {
    "year": "2017",
    "abstract": "Metamaterials are artificial structures that have recently enabled the realization of novel electromagnetic components with engineered and even unnatural functionalities. Existing metamaterials are specifically designed for a single application working under preset conditions (e.g., electromagnetic cloaking for a fixed angle of incidence) and cannot be reused. Software-defined metamaterials (SDMs) are a much sought-after paradigm shift, exhibiting electromagnetic properties that can be reconfigured at runtime using a set of software primitives. To enable this new technology, SDMs require the integration of a network of controllers within the structure of the metamaterial, where each controller interacts locally and communicates globally to obtain the programmed behavior. The design approach for such controllers and the interconnection network, however, remains unclear due to the unique combination of constraints and requirements of the scenario. To bridge this gap, this paper aims to provide a context analysis from the computation and communication perspectives. Then, analogies are drawn between the SDM scenario and other applications both at the micro and nano scales, identifying possible candidates for the implementation of the controllers and the intra-SDM network. Finally, the main challenges of SDMs related to computing and communications are outlined."
  },
  {
    "year": "2017",
    "abstract": "Recently, correlation filter-based tracking algorithms have attracted much attention for its high efficiency and robustness. However, achieving fast and accurate scale estimation remains a challenging problem. Most existing scale estimation approaches are inefficient and time-consuming. Besides, these existing trackers perform poorly when the object is under fast motion and partial occlusion due to limited searching area. In this paper, an independent scale filter is proposed to estimate the scale of an object, and the dimensionality reduction strategy is used to reduce computational cost. In addition, a local search strategy is proposed to expand the searching area of the tracker, which can effectively solve the problem caused by fast motion and occlusion. Extensive experiments have been conducted on three large-scale benchmarks, and it is shown that our proposed tracker outperforms the most state-of-the-art trackers. It achieves an average precision score of 87.2%, and an average success score of 65.2% on the object tracking benchmark-2013 benchmark. Moreover, our proposed tracker can run at a speed of nearly 80 frames/s on a single CPU, exceeding most competitive trackers by several times."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad-hoc networks (VANETs) play an important role in intelligent transportation systems for improving security and efficiency. However, due to dynamic characteristics of the vehicular environment, routing remains a significant challenge in the VANETs. While single-layer routing protocols based on the traditional layered open systems interconnection (OSI) model are readily available, they often do not make use of important parameters at the lower three layers of the OSI model when making routing decision. Hence, for making optimal routing decision to gain superior network performance, there is a need to design cross-layer routing that allows information exchange between layers. In this article, a survey of the existing single-layer and cross-layer routing techniques in VANETs is presented, emphasizing on cross-layer routing protocols that utilize information at the physical, medium access control and network layers as routing parameters. An overview and challenges of routing are given, followed by a brief discussion of single-layer routing with more focus on geographic routing. Cross-layer routing protocols are then discussed in detail. The article then elaborates on some advantages and disadvantages of the existing routing approaches, cross-layer routing parameter selection and cross-layer design issues. Finally, some open research challenges in developing efficient routing protocols in the VANETs are highlighted."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an approach of model-based design for implementing a digital communication system on a field programmable gate array (FPGA) for a software defined radio (SDR). SDR is a popular prototyping platform for wireless communication systems due to its flexibility and utility. A traditional SDR system performs nearly all computations and signal processing tasks on the host computer, and then sends the waveform to the RF front end. For complex algorithms or high data rate, the host computer becomes the processing bottleneck and FPGA is often employed as a hardware accelerator. This paper demonstrates the procedure of using model-based design for SDR targeted on FPGA hardware. A complete digital communication system, including a transmitter with convolutional encoder and a receiver with Viterbi decoder, is implemented on an FPGA-based SDR platform and validated by over-the-air demonstration. Synchronization algorithms, such as carrier frequency offset, phase offset, and time recovery, are also optimized for hardware efficiency."
  },
  {
    "year": "2017",
    "abstract": "In recent years, the chaos-based cryptographic algorithms have attracted a lot of attention. Specially, chaotic tent map (CTM)-based schemes show some good performances in randomness properties and security level. However, several shortcomings still can be found from them. In this paper, based on the security analysis of the pure CTM-based scheme, we propose a novel image encryption algorithm by using the combination of the rectangular transform and the CTM principle. It encrypts the three channels of the plain image at the same time, and these channel encryptions associate with each other. In addition, by generating the key streams related to both the secret keys and the plain image, its key-sensitivity has been further improved. The security of the proposed scheme has been verified by security analysis and experimental evaluations, and our results show that many drawbacks of pure CTM-based schemes have been overcome."
  },
  {
    "year": "2017",
    "abstract": "Fog computing, an extension of cloud computing services to the edge of the network to decrease latency and network congestion, is a relatively recent research trend. Although both cloud and fog offer similar resources and services, the latter is characterized by low latency with a wider spread and geographically distributed nodes to support mobility and real-time interaction. In this paper, we describe the fog computing architecture and review its different services and applications. We then discuss security and privacy issues in fog computing, focusing on service and resource availability. Virtualization is a vital technology in both fog and cloud computing that enables virtual machines (VMs) to coexist in a physical server (host) to share resources. These VMs could be subject to malicious attacks or the physical server hosting it could experience system failure, both of which result in unavailability of services and resources. Therefore, a conceptual smart pre-copy live migration approach is presented for VM migration. Using this approach, we can estimate the downtime after each iteration to determine whether to proceed to the stop-and-copy stage during a system failure or an attack on a fog computing node. This will minimize both the downtime and the migration time to guarantee resource and service availability to the end users of fog computing. Last, future research directions are outlined."
  },
  {
    "year": "2017",
    "abstract": "For a given base graph, the lifted graph can be obtained by a copy-and-permute procedure. If the permutation is cyclic, the lifted graph corresponds to a quasi-cyclic (QC) protograph low-density parity-check (LDPC) code. The girth of the QC protograph LDPC code is determined by the girth of the base graph and the permutation shifts. In this paper, we first derive a lower bound on the lifting degree to achieve a large girth lifted graph. Then, motivated by the cycle searching and girth maximizing features of the progressive edge-growth (PEG) algorithm, we introduce the permutation shifts determining (PSD) PEG algorithm, which can construct large girth base graph and determine the optimal permutation shifts, simultaneously. It is shown that the computational complexity of PSD-PEG algorithm is much lower than that of the PEG algorithm and the PEG-QC algorithm for the same codeword length. Furthermore, we show that the PSD-PEG algorithm can also be used to construct nonbinary QC protograph LDPC codes without low weight codes. Simulation results show that the binary and nonbinary QC protograph LDPC codes constructed by the PSD-PEG algorithm have good bit error rate performance and frame error rate performance over the additive white Gaussian noise channel."
  },
  {
    "year": "2017",
    "abstract": "The radio transceiver of an Internet of Things (IoT) device is often where most of the energy is consumed. For this reason, most research so far has focused on low-power circuit and energy-efficient physical layer designs, with the goal of reducing the average energy per information bit required for communication. While these efforts are valuable per se, their actual effectiveness can be partially neutralized by ill-designed network, processing, and resource management solutions, which can become a primary factor of performance degradation, in terms of throughput, responsiveness, and energy efficiency. The objective of this paper is to describe an energy-centric and context-aware optimization framework that accounts for the energy impact of the fundamental functionalities of an IoT system and that proceeds along three main technical thrusts: 1) balancing signal-dependent processing techniques (compression and feature extraction) and communication tasks; 2) jointly designing channel access and routing protocols to maximize the network lifetime; and 3) providing self-adaptability to different operating conditions through the adoption of suitable learning architectures and of flexible/reconfigurable algorithms and protocols. After discussing this framework, we present some preliminary results that validate the effectiveness of our proposed line of action, and show how the use of adaptive signal processing and channel access techniques allows an IoT network to dynamically tune lifetime for signal distortion, according to the requirements dictated by the application."
  },
  {
    "year": "2017",
    "abstract": "Comprehensive theories of conflict in the cyber world have not yet been developed, but the utilization of traditional military strategy and operational concepts in lieu of existing strategies in this realm can mislead, resulting in spurious assessments and unfavorable outcomes. Four tenets of the cyber world present profound challenges for the application of traditional military strategies in cyber conflicts. The cyber world is characterized by the following: 1) a lack of object permanence, which undermines the concept of maneuver; 2) limited or absent measurement of effectiveness in offensive cyber; 3) conflicts that are executed at computational speed, thus removing the time window for meaningful strategic leadership; and 4) anonymity, which makes the parties to the conflict unknown. As a result, the use of traditional military thinking and path-dependent behavior in cyber is likely to lead to incorrect conclusions regarding strategic achievements and abilities in the pre-conflict stage, and increase the risk of strategic failure during conflict and provide an opportunity for an adversary's strategic surprise."
  },
  {
    "year": "2017",
    "abstract": "The open nature of radio propagation makes wireless transmissions exposed to unauthorized users and become vulnerable to both the jamming and eavesdropping attacks. In industrial environments, wireless transmissions are also adversely affected by the presence of large-bodied obstructing machinery, metallic friction-induced impairments, and equipment noise. This may result in the failure of wireless transmissions and thus wastes the precious energy resources for industrial wireless sensor networks (IWSNs). This paper is motivated to present a review on the challenges and solutions of improving the physical-layer security and reliability for IWSNs. We first discuss some wireless reliability enhancement techniques for mitigating the background interference, path loss, multipath fading, and link failure. Then, we provide an overview of wireless jamming and eavesdropping attacks along with their countermeasures, where a jammer attempts to emit an interfering radio signal for disrupting the desired communications between a wireless sensor and its sink, while an eavesdropper intends to tap the confidential sensor-sink transmissions. Additionally, we evaluate the tradeoff between the security and reliability, called security-reliability tradeoff, in the context of wireless sensor-sink transmissions. Finally, we discuss a range of open challenges and future trends for IWSNs, including the energy-efficient security and reliability designs, joint jamming-and-eavesdropping defense mechanisms, as well as the energy harvesting for IWSNs."
  },
  {
    "year": "2017",
    "abstract": "Due to the advantages of control over shape and properties, multimaterial parts have potential for a broad range of biomedical engineering applications. A type of multimaterial part processing method based on digital design and manufacturing has been put forward to solve the problems associated with multimaterial part formation. A modeling platform for a heterogeneous object (HEO) part based on a material distribution control function and hierarchical contour loop was designed and utilized to characterize the material distribution in the HEO model. The hierarchical algorithm of the point color and surface texture based on the topological structure was studied and provided the basic data for the material construction area. An HEO part was fabricated using a custom-made 3-D printing system. The results showed that the digital processing method could effectively solve the problem of HEO part material definition and could realize the integrated design and manufacture of the geometry, material and function of biological parts."
  },
  {
    "year": "2017",
    "abstract": "Hybrid metaheuristics, explored in recent literature, are optimization methods that combine a global search metaheuristic with algorithms for refinement that in turn can be stochastic or deterministic. Although initially they were applied to combinatorial optimization, nowadays there are hybrid algorithms for a wide range of numerical problems: static or dynamic, mono or multi-objective, unconstrained or constrained, among others. In this paper a novel application of a hybrid method, MemMABC, is applied as a tool in a case study for the synthesis of an end effector presented as a constrained optimization problem, using a model for a two-finger gripper. The objective is to show the ability of hybrid metaheuristics as an alternative method for solving hard problems, specifically of numerical optimization. MemMABC is a memetic algorithm, that uses the modified artificial bee colony algorithm(MABC) for global searching and a version of random walk as local searcher, adapted to handle design constraints with an ε-constraint scheme. Grippers are end effectors used in a wide variety of robots, and are a good example of hard optimization problems. The simulation of results shows an accurate control of the gripping force along the opening range of the calculated mechanisms, suggesting that MemMABC can produce quality solutions for real-world engineering cases."
  },
  {
    "year": "2017",
    "abstract": "Although the number of cloud projects has dramatically increased over the last few years, ensuring the availability and security of project data, services, and resources is still a crucial and challenging research issue. Distributed denial of service (DDoS) attacks are the second most prevalent cybercrime attacks after information theft. DDoS TCP flood attacks can exhaust the cloud's resources, consume most of its bandwidth, and damage an entire cloud project within a short period of time. The timely detection and prevention of such attacks in cloud projects are therefore vital, especially for eHealth clouds. In this paper, we present a new classifier system for detecting and preventing DDoS TCP flood attacks (CS_DDoS) in public clouds. The proposed CS_DDoS system offers a solution to securing stored records by classifying the incoming packets and making a decision based on the classification results. During the detection phase, the CS_DDOS identifies and determines whether a packet is normal or originates from an attacker. During the prevention phase, packets, which are classified as malicious, will be denied to access the cloud service and the source IP will be blacklisted. The performance of the CS_DDoS system is compared using the different classifiers of the least squares support vector machine (LS-SVM), naïve Bayes, K-nearest, and multilayer perceptron. The results show that CS_DDoS yields the best performance when the LS-SVM classifier is adopted. It can detect DDoS TCP flood attacks with about 97% accuracy and with a Kappa coefficient of 0.89 when under attack from a single source, and 94% accuracy with a Kappa coefficient of 0.9 when under attack from multiple attackers. Finally, the results are discussed in terms of accuracy and time complexity, and validated using a K-fold cross-validation model."
  },
  {
    "year": "2017",
    "abstract": "The protection of cyber-physical networks is a topic of increasing importance. The evolution of IT (cyber) systems that control and supervise the underlying physical system has grown over decades, whereas security has not become a concern until quite recently. Advanced persistent threats (APTs) have proven to be a difficult but significant challenge for practitioners. This paper adopts a game-theoretic modeling of APTs and applies it to the (sub) problem of physical intrusion in an infrastructure. The gap between defining a good theoretical model and practically instantiating it is considered in particular. The model description serves to illustrate what is needed to put it into practice. The main contribution of this paper is the demonstration of how simulation, physical understanding of an infrastructure, and theoretical methods can be combined toward a practical solution to the physical intrusion avoidance problem. Numerical results are given to show how the physical intrusion game is being set up, and how the results obtained from its analysis can be interpreted and used for an optimized defense."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider large multi-pair relay networks with K fixed source-destination pairs and M relays randomly distributed in a given area, where each node is equipped with a single antenna and works on half duplex. Each source communicates with its corresponding destination under the aid of the relays. With the conventional two-slot relaying protocol, the sum capacity was found to scale as (K/2) log(M) + O(1), where K is fixed and M → ∞. This paper proves that the capacity scaling law can be further improved to K log(M) + O(1) with successive relaying protocol, as if the relays became \"full duplex.\" To prove the scaling law, a distributed amplify-and-forward scheme is proposed, which only requires local channel state information (CSI) at each relay and statistical global CSI at the sources and destinations. Furthermore, we prove that imperfect CSI at the relays would not affect the scaling law."
  },
  {
    "year": "2017",
    "abstract": "In 2015, the international telecommunication union (ITU) proposed 11 candidate millimeterwave bands between 24 and 86 GHz for the deployment of future fifth mobile generation (5G) broadband systems. Furthermore, the ITU called for spectrum-sharing studies in these bands. Since 5G specifications are not yet defined, the utilization of radio spectrum by 5G mobile systems will assist in identifying these specifications. This paper introduces Malaysia as a case study for the deployment of 5G systems. This includes a discussion of the current status of the Malaysian telecommunication market. Then, we investigate the current services that are already deployed in the proposed bands. Our investigation shows that the fixed (F) service is the most deployed as a primary service in the candidate bands. For this reason, a preliminary spectrum-sharing study is conducted on the basis of a modified 5G spectrum-sharing model to evaluate the feasibility of coexistence between 5G and F services in the 28-GHz band. Our modified methodology can be used for spectrum-sharing studies between 5G and any other services for an initial spectrum-sharing investigation. The results show that the F service will be severely affected by the 5G system transition in the 28-GHz band, especially in the base station (BS)-to-BS sharing scenario. The best band from the perspective of current spectrum allocation for 5G systems is the 45-GHz (i.e., 45.5-47 GHz) band, since it is already reserved for mobile service for primary allocation and not utilized. This paper is carried out concurrently with current worldwide efforts investigating spectrum sharing, as requested by the ITU in agenda item 1.13 for the next world radio conference 2019."
  },
  {
    "year": "2017",
    "abstract": "In various disciplines, hierarchical clustering (HC) has been an effective tool for data analysis due to its ability to summarize hierarchical structures of data in an intuitive and interpretable manner. A run of HC requires multiple iterations, each of which needs to compute and update the pairwise distances between all intermediate clusters. This makes the exact algorithm for HC inevitably suffer from quadratic time and space complexities. To address large-scale data, various approximate/parallel algorithms have been proposed to reduce the computational cost of HC. However, such algorithms still rely on conventional linkage methods (such as single, centroid, average, complete, or Ward's) for defining pairwise distances, mostly focusing on the approximation/parallelization of linkage computations. Given that the choice of linkage profoundly affects not only the quality but also the efficiency of HC, we propose a new linkage method named NC-link and design an exact algorithm for NC-link-based HC. To guarantee the exactness, the proposed algorithm maintains the quadratic nature in time complexity but exhibits only linear space complexity, thereby allowing us to address million-object data on a personal computer. To underpin the extensibility of our approach, we showthat the algorithmic nature of NC-link enables single instruction multiple data (SIMD) parallelization and subquadratic-time approximation of HC. To verify our proposal, we thoroughly tested it with a number of large-scale real and synthetic data sets. In terms of efficiency, NC-link allowed us to perform HC substantially more space efficiently or faster than conventional methods: compared with average and complete linkages, using NC-link incurred only 0.7%-1.75% of the memory usage, and the NC-link-based implementation delivered speedups of approximately 3.5 times over the centroid and Ward's linkages. With regard to clustering quality, the proposed method was able to retrieve hierarchical structures from..."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) is envisioned to bring the Internet connection to every object/ service/process to seamlessly and efficiently observe, manage, and control pervasive systems. This necessitates the employment of wireless standalone devices in excessive numbers. However, periodic maintenance of thousands, maybe millions of batteries will add massive workload and replenishment costs to the operation. In order to alleviate this problem, we introduce a totally new energy harvesting paradigm based on utilizing ambient electric-field in the vicinity of lighting elements. A low voltage prototype is designed, constituted, and evaluated on a generic4×18W-T8 ceiling-type fluorescent troffer. Empirical results disclose the availability of 1.5 J of energy that can be gathered in 30 min when a copper plate, i.e., the harvester, covered by a reflective dielectric is employed. The design issues to achieve the best performance attainable are addressed in both theoretical and experimental manners. The physical model of the proposed technique and an applicable circuit diagram for its execution are provided. We also point out possible application areas, and protocol stack requirements specific to our proposal to conveniently enable self-configuring IoT services, which are free from battery constraints."
  },
  {
    "year": "2017",
    "abstract": "This paper presents preliminary results toward translating gait and control design for bipedal robots to decentralized control of an exoskeleton aimed at restoring mobility to patients with lower limb paralysis, without the need for crutches. A mathematical hybrid dynamical model of the human-exoskeleton system is developed and a library of dynamically feasible periodic walking gaits for different walking speeds is found through nonlinear constrained optimization using the full-order dynamical system. These walking gaits are stabilized using a centralized (i.e., full-state information) hybrid zero dynamics-based controller, which is then decentralized (i.e., control actions use partial state information) so as to be implementable on the exoskeleton subsystem. A control architecture is then developed so as to allow the user to actively control the exoskeleton speed through his/her upper body posture. Numerical simulations are carried out to compare the two controllers. It is found that the proposed decentralized controller not only preserves the periodic walking gaits but also inherits the robustness to perturbations present in the centralized controller. Moreover, the proposed velocity regulation scheme is able to reach a steady state and track desired walking speeds under both, centralized, and decentralized schemes."
  },
  {
    "year": "2017",
    "abstract": "Millimeter wave (mm-wave) frequencies have been proposed to achieve high capacity in 5G communications. Although meaningful research on the channel characteristics has been performed in the 28-, 38-, and 60-GHz bands in both indoor and short-range scenarios, only a small number of trials (experiments) have been carried out in other mm-wave bands. The objective of this paper is to study the viability and evaluate the performance of the 94-GHz frequency band for MIMO-OFDM transmission in an indoor environment. Starting from a measurement campaign, the performance of MIMO algorithms is studied in terms of throughput for four different antenna configurations."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new heuristic for the data clustering problem. It comprises two parts. The first part is a greedy algorithm, which selects the data points that can act as the centroids of well-separated clusters. The second part is a single-solution-based heuristic, which performs clustering with the objective of optimizing a cluster validity index. Single-solution-based heuristics are memory efficient as compared with population-based heuristics. The proposed heuristic is inspired from evolutionary algorithms (EAs) and consists of five main components: 1) genes; 2) fitness of genes; 3) selection; 4) mutation operation; and 5) diversification. The attributes of the centroids of clusters are considered as genes. The fitness of a gene is a function of two factors: 1) difference between its value and the same attribute of the mean of the data points assigned to its cluster and 2) the frequency with which it has been mutated in previous iterations. The genes that have low fitness values should be updated through the mutation operation. The mutation operation performs small change (positive or negative) in the value of the gene. The mutants are accepted if they are better (with respect to objective function) than their parents. However, diversification in the search process is maintained by allowing, with a small probability, the mutants to replace their parents even they are not better than them. The objective functions used in the proposed heuristic are Calinski Harabasz index and Dunn index. The proposed algorithm has been experimented using real-life numeric data sets of UCI repository. The number of data points and number of attributes in the datasets lie between 150-11 000 and 4-60, respectively. The results indicate that the proposed algorithm performs better than two standard EAs: 1) simulated annealing algorithm and 2) differential evolution algorithm and a genetic algorithm-based clustering method."
  },
  {
    "year": "2017",
    "abstract": "Citations play an important role in ranking of authors, journals, institutions, and organizations. Sometimes, citing documents cite a reference many times in their full-text, which is further used in many application scenarios, such as: 1) finding relationship between cited and citing papers; 2) identifying influential cited paper from set of references in citing paper; 3) identification of suitable citation functions; and 4) study of in-text citations in different logical sections of papers to conclude different findings. The accurate identification of in-text citations remained an open area of research. Recently, the complexities involving automatic identification of in-text citations have been reported with an accuracy rate of 58%. This is due to many issues as highlighted by the state-of-the-art research. This paper investigates such issues in further details: 1) by taking benefits from the previous research; 2) by analyzing different referencing formats; and 3) by experimenting on a comprehensive data set. Based on the investigation, this paper proposes a taxonomy and workable system, which utilizes a set of heuristics build from detailed study. The proposed model is then applied on unseen diversified data set taken from the Journal of Universal Computer Science and CiteSeer. The proposed model was able to achieve an average F-score of 0.97 as compared with the baseline 0.58."
  },
  {
    "year": "2017",
    "abstract": "To further liberalize the retail electricity market, this paper establishes a novel active distribution system market (ADSM) to encourage the new entries of micro virtual power plants (μVPPs) as prosumers. μVPPs compete with traditional retailers by submitting price-quantity bids/offers for energy and reserve resources. The joint operation of energy and reserve market is modeled as a bilevel equilibrium problem with equilibrium constraints (EPEC) with an upper-level objective that maximizes all μVPPs' profit and a lower level objective that maximizes social welfare of the market clearing process. A coevolutionary approach is successfully employed to determine the pure strategy Nash equilibrium of the EPEC model. The case studies demonstrate the effectiveness of the coevolutionary method and show that μVPPs' bidding/offering strategies depend significantly on the penetration level of distributed energy resources and renewable energy sources and they can be considerably influenced by rivals' strategies. This paper then compares μVPPs' performances under different market structures and addresses the advantages of the proposed ADSM in terms of higher asset utilization rate, higher economic profit, and more secured return on investment."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an aggregator-assisted model for machine-to-machine (M2M) communications is proposed. The data aggregator plays the role of a third party that transmits aggregated M2M data to a cognitive operator, which does not own the radio spectrum but rather leases it from a spectrum owner. In the studied system, the cognitive operators for machine services are considered to dynamically appear in the network and compete with one another, each of them having uncertain backhual M2M data traffic. The aggregator can then decide to select one operator with whom to set up either a long-term (LT) or a short-term (ST) service relationship, by anticipating the result of the auction in the second period. Under an ST relationship, the aggregator maintains the option of switching to a new operator in the next period, thereby incurring possible packet losing costs. In contrast, with an LT relationship, the aggregator commits to an operator over a long period of time, but may loss the opportunities to choose an operator with a possible lower operation cost. The optimal decision that maximizes the aggregator’s expected utility is derived. The proposed M2M access model allows the aggregator accounting for both the switching cost for M2M communications, and, the benefit of a long-term service contract. Moreover, it is shown that an LT relationship may induce a higher accessed number of machines than an ST relationship when the cost of switching between operators is relatively high. Simulation results show that the spectrum sharing for the aggregator-assisted M2M model can significantly increase the number of accessed machines in a certain time duration, as well as bring extra revenues for the spectrum owner, the operator, and the aggregator."
  },
  {
    "year": "2017",
    "abstract": "Underwater optical cameras are widely used for security monitoring in ocean, such as earthquake prediction and tsunami alarming. Optical cameras recognize objects for autonomous underwater vehicles and provide security protection for sea-floor networks. However, there are many issues for underwater optical imaging, such as forward and backward scattering, light absorption, and sea snow. Many underwater image processing techniques have been proposed to overcome these issues. Among these techniques, the depth map gives important information for many applications of the post-processing. In this paper, we propose a Kinect-based underwater depth map estimation method that uses a captured coarse depth map by Kinect with the loss of depth information. To overcome the drawbacks of low accuracy of coarse depth maps, we propose a corresponding reconstruction architecture that uses the underwater dual channels prior dehazing model, weighted enhanced image mode filtering, and inpainting. Our proposed method considers the influence of mud sediments in water and performs better than the traditional methods. The experimental results demonstrated that, after inpainting, dehazing, and interpolation, our proposed method can create high-accuracy depth maps."
  },
  {
    "year": "2017",
    "abstract": "In this paper, two techniques to compensate inphase/quadrature-phase imbalance (IQI) are investigated in the uplink-quantized massive multiple-input and multiple-output (MIMO) systems for different models of randomized IQI parameters. One is referred to as combined-signal-based channel estimation and compensation (CCEC) and the other is denoted by effective channel estimation and compensation (ECEC). First, an independent automatic gain control (AGC) scheme is proposed to calibrate the dynamic range of both the I branch and the Q branch. By doing that, different quantization steps are used for analog-to-digital converters following the AGCs in these two branches at each receive antenna. Second, considering the impacts of both quantization and IQI, we give the details of channel estimation and IQI compensation for both the CCEC and the ECEC using bilinear generalized approximate message passing (Bi-GAMP). Moreover, to exploit the Bi-GAMP for ECEC reasonably, we theoretically derive the probability density function PDF of the elements in the effective channel for the case where only RX IQI is considered. Furthermore, we extend the ECEC to the case where both RX IQI and TX IQI are incorporated into the systems and derive the similar pdf as well. Finally, we use the numerical results to testify the validity of our theoretical analysis and the fact that the analytic PDF can be approximated by a Gaussian distribution when the IQI parameters are relatively small. Compared with other classical methods, the proposed methods can obtain better performance based on the Monte Carlo simulation results."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a total-amount synchronous control (TASC) strategy for nonlinear systems with uncertainty based on finite-time control theory. In combination with a new type of terminal sliding-mode control strategy, finite-time convergence of TASC is realized. First, the specific mathematical expression of the system terminal sliding-mode surface is given. On the basis of this, according to the sliding-mode surface expression, the sliding-mode variable structure control laws of n regular nonlinear systems are derived, avoiding the singularity problem that can easily appear in ordinary terminal sliding-mode controllers. Meanwhile, the initial system is located on the sliding-mode surface. The approach process in sliding-mode control is eliminated, and the existence of the sliding phase is proved according to the Lyapunov stability theory. Finally, the effectiveness of the algorithm is verified by a numerical example."
  },
  {
    "year": "2017",
    "abstract": "Arc consistency is the most popular filtering technique for solving constraint satisfaction problems. Constraint check plays a central role in establishing arc consistency. In this paper, we propose a method to save constraint checks in maintaining coarse-grained arc consistency during backtracking search for solving the constraint satisfaction problems. We reduce the support searching range by utilizing the information generated by an AC3.1 algorithm at preprocessing step. Compared with the existing maintaining arc consistency (MAC) algorithms, the proposed MAC3bealgorithm saves constraint checks without maintaining additional data structures at each search tree node. Our experimental results show that MAC3besaves both constraint checks and CPU time while solving some benchmark problems."
  },
  {
    "year": "2017",
    "abstract": "The detection of anomalies in network traffic, such as low volume attacks and abnormalities, has become a pressing problem in today's large volume of Internet traffic. To this end, various anomaly detection techniques have been developed, including techniques based on long-range dependence (LRD) behavior estimation of network traffic. However, the existing LRD-based techniques analyze the aggregated WHOLE (control plus data) traffic, which might not be sufficient to detect short-duration and low-volume attacks and abnormalities in the traffic. This is because such anomalies might pass unnoticed in large volume of the normal background traffic. To address this issue, we propose a method that examines the LRD behavior of control and data planes traffic separately, which improves the detection efficacy. For LRD behavior analysis, the proposed method integrates the correlation structures of second-order self-similar and fractional autoregressive integrated moving average models. The performance of the proposed method is empirically evaluated and validated over a relatively recent real Internet traffic captured at King Saud University's network. The analysis and results demonstrate that the proposed method efficiently detects such low volume and short duration attacks and abnormalities in the traffic, which would not be detected by merely analyzing the aggregated WHOLE traffic without decomposing it into control and data planes traffic."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we first exploit the inter-user interference and inter-cell interference as useful references to develop a robust transceiver design based on interference alignment for a downlink multi-user multi-cell multiple-input-multiple-output interference network under channel estimation error. At transmitters, we propose a two-tier transmit beamforming strategy, and we first achieve the inner beamforming direction and allocated power by minimizing the interference leakage as well as maximizing the system energy efficiency, respectively. Then, for the outer beamformer design, we develop an efficient conjugate gradient Grassmann manifold subspace tracking algorithm to minimize the distances between the subspace spanned by interference and the interference subspace in the time-varying channel. At receivers, we propose a practical interference alignment based on the fast and robust Fast Data Projection method subspace tracking algorithm to achieve the receive beamformer under channel uncertainty. Numerical results show that our proposed robust transceiver design achieves better performance compared with some existing methods in terms of the sum rate and the energy efficiency."
  },
  {
    "year": "2017",
    "abstract": "In the absence of end-to-end paths and without the knowledge of the whole network, packet forwarding, including forwarding decision (i.e., forwarding or dropping the packet) and relaying selection, is crucial to be made by the individual of the node based on the packet-forwarding protocol in autonomous mobile social networks (MSNs). In this paper, we investigate the adaptive packet forwarding in MSNs afflicted with potential selfish nodes. When considering the various selfish behaviors of network nodes in multi-hop MSNs, an incentive compatible multiple-copy packet forwarding (ICMPF) protocol is proposed to maintain a satisfied packet delivery probability while reducing the delivery overhead. Considering the fact that the node's forwarding decision in the ICMPF protocol is affected by its available resources (i.e., bandwidth and location privacy) and network environment (i.e., other nodes' actions and social ties), an evolutionary game framework is exploited for modeling the complicated interactions among nodes to guide their forwarding behaviors. Meanwhile, we portray the forwarding behavior dynamics and develop the evolutionary stable strategy (ESS) for this game-theoretic framework. Then, we prove that the strategy dynamics converge to the ESS and further develop a distributed learning algorithm for nodes to approach to the ESS. Simulation results show that our system converges to the ESS and also is robust to the learning error induced by the communication noise."
  },
  {
    "year": "2017",
    "abstract": "With the development of high-throughput interaction detection techniques such as tandem affinity purification (TAP) and yeast two-hybrid (Y2H), the available genome-wide protein-protein interactions (PPIs) data have been increasing in recent years. Using mathematical, physical, and artificial-intelligence methods, some researchers in computational biology focused on uncovering the evolutionary ages of proteins according to present PPI networks (PINs), but improving their accuracy was challenging. A plausible explanation is that they solved biological problems with non-biological techniques and did not provide much attention to biological backgrounds and meanings of proteins or their relationships. In this paper, we propose two ways to improve the accuracy of age predicting and skillfully “embedding”multisource biological information in each iteration of an archaeology algorithm for yeast PIN. On the one hand, we reduce the probability of reversing errors by decreasing the non-duplication protein pairs, which are obtained from 460 gene trees constructed by means of a multiple sequence alignment and the neighbor joining algorithm. On the other hand, the reliable crossover standard from different biological information sources can decrease local random errors of alternative treatment. The application of the novel algorithm to simulation data and real yeast PINs shows a marked improvement in accuracy. Our research strongly suggests that putting non-biological methods into the “biological context”will bear more favorable results."
  },
  {
    "year": "2017",
    "abstract": "Data delivery in opportunistic networks requires robustness and resiliency due to the mobility and probabilistic propagation channels caused by fading. Besides the 100% data delivery, delivery with minimum delay, overhead, buffer consumption, and controlling unnecessary transmissions/replications are equally important. In this paper, we propose a data delivery solution for opportunistic networks. The solution comprises two main algorithms: store-carry-cooperative forward routing and information epidemic control. In the data forwarding, nodes proactively monitor and exploit the direct/two-hop cooperative forwarding opportunities and adaptively switch between the cooperative forwarding and reactive store-carry-forward routing. An information epidemics control algorithm, which provides earlier control signal distribution time and faster recovery rate, is also proposed. The susceptible-infected-recovered model is used to study the effectiveness of the proposed mechanism. Extensive network performance evaluation is conducted under a wide range of scenarios, which include fading environments, obstacle-constrained environments, and mobile social network environments. We show that: 1) the information epidemics control mechanism provides higher vaccination rate and recovery rate; 2) proactive replication incurs a number of unnecessary transmissions; 3) monitoring the vicinity and exploiting the opportunity shorten the data delivery delay; and 4) with the integrated solution, a robust data delivery is achieved and a substantial amount of unnecessary transmissions are well deterred."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we model and analyze a cellular network that operates in the licensed band of the 3.5-GHz spectrum and consists of a licensed and an unlicensed operator. Using tools from stochastic geometry, we concretely characterize the performance of this spectrum sharing system. We model the locations of the licensed base stations (BSs) as a homogeneous Poisson point process with protection zones (PZs) around each BS. Since the unlicensed BSs cannot operate within the PZs, their locations are modeled as a Poisson hole process. In addition, we consider carrier sense multiple access with collision avoidance-type contention-based channel access mechanism for the unlicensed BSs. For this setup, we first derive an approximate expression and useful lower bounds for the medium access probability of the serving unlicensed operator BS. Furthermore, by efficiently handling the correlation in the interference powers induced due to correlation in the locations of the licensed and unlicensed BSs, we provide approximate expressions for the coverage probability of a typical user of each operator. Subsequently, we study the effect of different system parameters on area spectral efficiency of the network. To the best of our knowledge, this is the first attempt toward accurate modeling and analysis of a citizens broadband radio service system using tools from stochastic geometry."
  },
  {
    "year": "2017",
    "abstract": "Provisioning fault-tolerant scheduling in computational grid is a challenging task. Most of the existing fault tolerant scheduling schemes are either geared toward proactive or reactive. Proactive schemes emphasize on the reasons responsible for generating faults, whereas reactive mechanisms come into effect after failure detection. Unlike most existing mechanisms, we present a novel, dynamic, adaptive, and hybrid fault-tolerant scheduling scheme based on proactive and reactive approaches. In the proactive approach, the resource filtration algorithm picks resources based on resource location, availability, and reliability. Unlike most existing schemes, which rely on remotely connected resources, the proposed algorithm prefers to employ locally available resources as they might have less failure tendency. To cope with the frequent turnover problem, the proposed scheme calculates resource availability time based on various newly identified parameters (e.g., mean time between availability) and picks highly available nodes for task execution. Resource reliability is an indispensable consideration in the proposed scheme and is calculated based on parameters such as jobs success or failure ratio and the types of failures encountered. We employ an optimal resource identification algorithm to determine and select optimal resources for job execution. The performance of the proposed scheme is validated through the GridSim toolkit. Compared with contemporary approaches, experimental results demonstrate the effectiveness and efficiency of the proposed scheme in terms of various performance metrics, such as wall clock time, throughput, waiting and turnaround time, number of checkpoints, and energy consumption."
  },
  {
    "year": "2017",
    "abstract": "In this paper, metallic plasmonic nano-antennas are modeled and analyzed for wireless optical communication. More specifically, a unified mathematical framework is developed to investigate the performance in transmission and reception of metallic nano-dipole antennas. This framework takes into account the metal properties, i.e., its dynamic complex conductivity and permittivity; the propagation properties of surface plasmon polariton waves on the nano-antenna, i.e., their confinement factor and propagation length; and the antenna geometry, i.e., length and radius. The generated plasmonic current in reception and the total radiated power and efficiency in transmission are analytically derived by utilizing the framework. In addition to numerical results, the analytical models are validated by means of simulations with COMSOL Multi-physics. The developed framework will guide the design and development of novel nano-antennas suited for wireless optical communication."
  },
  {
    "year": "2017",
    "abstract": "Due to the global warming and energy crisis, the renewable distributed energy resources, such as wind turbines, are integrated into the grid. We model an AC microgrid with energy generating units, local loads, and electronic devices. Then, the set of non-linear differential equations are expressed as a state-space model. As the microgrid is located in the customer premises or remote areas, its condition needs to monitor in real-time. So, the smart sensor requires to deploy around the microgrid, and its sensing information transmits to the energy management system via the Internet as the sensing information is a massive amount of data. Combining the Internet of Things elements, such as sensors (Internet emended), and the Internet as a transmission medium will form the Internet of Energy, which is considered as a sign interest nowadays. Basically, the energy management center estimates the microgrid states to know the operating conditions of these foreseeable intermittent resources. For estimating the microgrid states, the H-infinity-based Mimi-max filter is proposed, which will no need to know the exact process and measurement noise statistics. Simulation results show that the proposed approach can well estimate the system states compared with the existing Kalman filter. As a result, this framework will assist to design a suitable microgrid framework and provides effective dynamic state estimations."
  },
  {
    "year": "2017",
    "abstract": "Advanced Persistent Threats (APTs) represent stealthy, powerful, long-term, and well-funded attacks against cyber systems, such as data centers and cloud storage. Evolutionary game theory is used to capture the long-term continuous behavior of the APTs on the cloud storage devices. Two APT defense games with discrete strategies are formulated, in which both an APT attacker and a defender compete to control one or multiple storage devices regarding their attack or defense intervals. The dynamical stability of each defense and attack strategy pair is studied according to the replicator dynamics criteria to characterize the locally asymptotically stable equilibrium strategies. The evolutionary stable strategy is discussed in each game, which is a subset of the asymptotically stable Nash equilibrium (NE). The phase portraits provide the locally asymptotically stable points of the APT defense game, which represent the NE showing the relationship between the asymptotic stability and evolutionary stability."
  },
  {
    "year": "2017",
    "abstract": "Clustering analysis has the very broad applications on data analysis, such as data mining, machine learning, and information retrieval. In practice, most of clustering algorithms suffer from the effects of noises, different densities and shapes, cluster overlaps, etc. To solve the problems, in this paper, we propose a simple but effective density-based clustering framework (DCF) and implement a clustering algorithm based on DCF. In DCF, a raw data set is partitioned into core points and non-core points by a neighborhood density estimation model, and then the core points are clustered first, because they usually represent the center or dense region of the cluster structure. Finally, DCF classifies the non-core points into initial clusters in sequence. In experiments, we compare our algorithm with Dp and DBSCAN algorithms on synthetic and real-world data sets. The experimental results show that the performance of the proposed clustering algorithm is comparable with DBSCAN and Dp algorithms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a novel method to detect saliency on face images. In our method, face and facial features are extracted as two top-down feature channels, linearly integrated with three traditional bottom-up features of color, intensity, and orientation, to yield final saliency map of a face image. By conducting an eye tracking experiment, a database with human fixations on 510 face images is obtained for analyzing the fixation distribution on face region. We find that fixations on face regions can be well modeled by a Gaussian mixture model (GMM), corresponding to face and facial features. Accordingly, we model face saliency by the GMM, learned from the training data of our database. In addition, we investigate that the weights of face feature channels rely on the face size in images, and the relationship between the weights and face size is, therefore, estimated by learning from the training data of our eye tracking database. The experimental results validate that our learning-based method is capable of dramatically improving the accuracy of saliency detection on face images over other ten state-of-the-art methods. Finally, we apply our saliency detection method to compress face images, with an improvement on visual quality or saving on bit-rate over the existing image encoder."
  },
  {
    "year": "2017",
    "abstract": "Our diverse team of educators at Colorado State University are redefining what it means to teach and learn in the Department of Electrical and Computer Engineering. Supported by a five-year “RED” grant from the National Science Foundation, we are, in effect, throwing away courses to overcome the challenges of the current engineering educational system. Approaching the degree from a holistic perspective, we no longer view our program as a set of disparate courses taught by autonomous (and isolated) faculty, but as an integrated system that fosters collaboration among faculty and students. This paper describes our new organizational and pedagogical model, which emphasizes knowledge integration and interweaves thematic content threads throughout the curriculum. We also share our process for implementing the new approach, along with the successes and challenges that we have experienced along the way. Through this project, we strive to become a catalyst for change in engineering education."
  },
  {
    "year": "2017",
    "abstract": "Voluminous amounts of data have been produced, since the past decade as the miniaturization of Internet of things (IoT) devices increases. However, such data are not useful without analytic power. Numerous big data, IoT, and analytics solutions have enabled people to obtain valuable insight into large data generated by IoT devices. However, these solutions are still in their infancy, and the domain lacks a comprehensive survey. This paper investigates the state-of-the-art research efforts directed toward big IoT data analytics. The relationship between big data analytics and IoT is explained. Moreover, this paper adds value by proposing a new architecture for big IoT data analytics. Furthermore, big IoT data analytic types, methods, and technologies for big data mining are discussed. Numerous notable use cases are also presented. Several opportunities brought by data analytics in IoT paradigm are then discussed. Finally, open research challenges, such as privacy, big data mining, visualization, and integration, are presented as future research directions."
  },
  {
    "year": "2017",
    "abstract": "A sentiment analysis has received a lot of attention from researchers working in the fields of natural language processing and text mining. However, there is a lack of annotated data sets that can be used to train a model for all domains, which is hampering the accuracy of sentiment analysis. Many research studies have attempted to tackle this issue and to improve cross-domain sentiment classification. In this paper, we present the results of a comprehensive systematic literature review of the methods and techniques employed in a cross-domain sentiment analysis. We focus on studies published during the period of 2010-2016. From our analysis of those works, it is clear that there is no perfect solution. Hence, one of the aims of this review is to create a resource in the form of an overview of the techniques, methods, and approaches that have been used to attempt to solve the problem of cross-domain sentiment analysis in order to assist researchers in developing new and more accurate techniques in the future."
  },
  {
    "year": "2017",
    "abstract": "In recent years, demands for rich multimedia services over mobile networks have been soaring at a tremendous pace. Traditional dedicated networking equipment may not be able to efficiently support the phenomenal growth of the traffic load and user demand dynamics while consuming an unnecessarily large amount of energy resources. Recently, mobile content caching, whereby popular contents are cached inside the mobile front-haul and back-haul networks so that demands for these contents from users in proximity can be easily accommodated without redundant transmissions from the remote sources, has emerged as an efficient technique for multimedia content delivery. Mobile content caching is particularly suitable for fifth generation (5G) mobile systems that are being designed to incorporate advanced cloud computing technologies and network function virtualization techniques. Therefore, in this paper, we first propose the concept of “Caching-as-a-Service” (CaaS) based on cloud-based radio access networks, and virtualized evolved packet core, which provides the capability to cache anything at anytime, anywhere in the cloud-based 5G mobile systems to satisfy user demands from any service location with high elasticity and adaptivity, and to empower third-party service providers with flexible controllability and programmability. Then, we study the potential techniques related to the virtualization of caching, and discuss the technical details of virtualization and optimization of CaaS in 5G mobile networks. Some novel schemes for CaaS are proposed to target different mobile applications and services. We also explore new opportunities and challenges for further research."
  },
  {
    "year": "2017",
    "abstract": "Diagnostic ultrasound offers great improvements in diagnostic accuracy and robustness. However, it is difficult to make subjective and uniform diagnoses, because the quality of ultrasound images can be easily influenced by machine settings, the characteristics of ultrasonic waves, the interactions between ultrasound and body tissues, and other uncontrollable factors. In this paper, we propose a novel liver fibrosis classification method based on transfer learning (TL) using VGGNet and a deep classifier called fully connected network (FCNet). In case of insufficient samples, deep features extracted using TL strategy can provide sufficient classification information. These deep features are then sent to FCNet for the classification of different liver fibrosis statuses. With this framework, tests show that our deep features combined with the FCNet can provide suitable information to enable the construction of the most accurate prediction model when compared with other methods."
  },
  {
    "year": "2017",
    "abstract": "Patient monitoring in intensive care units requires collection and processing of high volumes of data. High sensitivity of sensors leads to significant number of false alarms, which cause alarm fatigue. Reduction of false alarms can lead to better reaction time of medical personnel. This paper aims to develop a method for false alarm suppression and evaluate it on a publicly available data set with manually annotated alarms. First, an automated feature engineering was performed using the signal for arterial blood pressure (ABP) and a processed signal that contained the times of each heartbeat from the ABP signal. Next, support vector machines, random forest, and extreme random trees classifiers were trained to create classification models. The best suppression performance was achieved for the extreme tachycardia alarm, for which 90.3% of the false alarms were suppressed, while only 0.54% of the true alarms were incorrectly suppressed. This paper demonstrates that alarm suppression can be achieved with high accuracy using an automated feature engineering coupled with machine learning algorithms. The proposed approach can be utilized as aid to medical personnel and experts, allowing them to be more productive and to respond to alarms in a more timely manner."
  },
  {
    "year": "2017",
    "abstract": "The dense deployment of heterogeneous networks (HetNets) has shown to be a promising direction to cope with the capacity demands in the future 5G wireless networks. The large number of small cell base stations (SBSs) in HetNets intended to help in achieving the capacity requirement of 5G networks can also result in a significant increase in energy consumption. This is due to the fact that there might be few associated users in certain SBSs, intelligently switching them to low energy consumption modes, or turning them off without seriously degrading system capacity is desirable in order to improve the energy savings in the HetNets. Also, the unnecessary handovers caused due to this dynamic power level switching in the SBS should not be neglected. In this paper, fuzzy logic-based game-theoretic framework is utilized to address these issues and examine the energy efficiency improvements in HetNets. We design fuzzy inference rules for handover decisions, and target base station selection is performed through a fuzzy ranking technique, while simultaneously considering both energy/spectral efficiency and signaling overhead. The results show that energy consumption can be improved considerably especially for high user velocities, while also managing ping-pong handovers."
  },
  {
    "year": "2017",
    "abstract": "Under grid-voltage dips, there exist dc and negative sequence components in the stator and rotor flux of doubly-fed induction generator (DFIG). As a result, higher transient overcurrent is generated in the rotor. To enhance the low-voltage ride-through (LVRT) ability of the DFIG, a synchronous flux weaken control strategy with flux linkage prediction is proposed to suppress the transient overcurrent. In the proposed control strategy, the deadbeat predictive control is used to realize rapid synchronization and weak interaction between the stator and rotor flux by flux linkage prediction under grid-voltage dips. A series of research is carried out on a typical 1.5-MW DFIG system, and comparisons are made with the LVRT control strategy based on proportional-resonant (PR) controller to validate the proposed control strategy. The results indicate that the proposed control strategy is effective in suppressing overcurrent in the stator and rotor and reducing oscillations in torque, which largely improves the performance of the DFIG during grid-voltage dips."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose time series prediction methods for depth-averaged current velocities (DACVs) of underwater gliders. Based on historical DACV data, these methods can predict the DACVs of future profiles with good performance. Regarding DACVs as time series, we use backpropagation neural network and least squares support vector machine (LSSVM) methods to predict the DACVs. To obtain better prediction performance, the features of DACVs are considered, and we use empirical mode decomposition (EMD) to decompose the time series into several sub-series. Then, the two methods are reused to predict each sub-series, and the results of all the sub-series with each method are added. Based on the real-time DACVs obtained from the simulation environment and the DACVs obtained from sea trials, we test and verify the four methods. The results demonstrate that all the methods exhibit a good prediction performance for conditions in which ocean currents are relatively regular; whereas in other cases, EMD-LSSVM shows inherent robustness and superiority compared with the other three methods."
  },
  {
    "year": "2017",
    "abstract": "This study explores the impact of high-photovoltaic (PV) penetration on the inter-area oscillation modes of large-scale power grids. A series of dynamic models with various PV penetration levels are developed based on a detailed model representing the U.S. Eastern Interconnection (EI). Transient simulations are performed to investigate the change of inter-area oscillation modes with PV penetration. The impact of PV control strategies and parameter settings on inter-area oscillations is studied. This paper finds that as PV increases, the damping of the dominant oscillation mode decreases monotonically. It is also observed that the mode shape varies with the PV control strategy and new oscillation modes may emerge under inappropriate parameter settings in PV plant controls."
  },
  {
    "year": "2017",
    "abstract": "Massive multi-core processing has recently attracted significant attention from the research community as one of the feasible solutions to satisfy constantly growing performance demands. However, this evolution path is nowadays hampered by the complexity and limited scalability of bus-oriented intra-chip communications infrastructure. The latest advantages of terahertz (THz) band wireless communications providing extraordinary capacity at the air interface offer a promising alternative to conventional wired solutions for intra-chip communications. Still, to invest resources in this field manufacturers need a clear vision of what are the performance and scalability gains of wireless intra-chip communications. Using the comprehensive hybrid methodology combining THz ray-tracing, direct CPU traffic measurements, and cycle-accurate CPU simulations, we perform the scalability study of x86 CPU design that is backward compatible with the current x86 architecture. We show that preserving the current cache coherence protocols mapped into the star wireless communications topology that allows for tight centralized medium access control a few hundreds of active cores can be efficiently supported without any notable changes in the x86 CPU logic. This important outcome allows for incremental development, where THz-assisted x86 CPU with a few dozens of cores can serve as an intermediate solution, while the truly massive multi-core system with broadcast-enabled medium access and enhanced cache coherence protocols can be an ultimate goal."
  },
  {
    "year": "2017",
    "abstract": "In the design of trustworthy software for real-time embedded systems, the interrupt mechanism plays an important role. Due to the randomness and non-determinism of interrupt handling behaviors, the performance evaluation of embedded software is an important but challenging problem. To solve this problem, we propose a performance model for embedded software based on extended deterministic and stochastic Petri nets (EDSPN), which is a semantic expansion of DSPN that add non-deterministic time transitions. In this manner, the performance model can effectively express interrupt handling behaviors, including random requests, responses according to priority, interrupt nesting, and non-deterministic execution times. In addition, we also provide a performance evaluation method for the EDSPN model based on Markov regenerative theory and demonstrate the analysis process via a specific example. Finally, we analyze the performance of embedded software, taking into account all types of the impact factors of interrupts through experimentation."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates optical camera communication (OCC) technologies, targeting new spectrum, multiple-input-multiple-output diversity, transmission access, and novel architectures with augmented reality user experience for the extended 5G wireless network. It provides the current OCC research status and trend pertaining to these technologies, especially an inside view on the revision of IEEE 802.15.7-2011 known as the IEEE 802.15.7m (TG7m) Optical Wireless Communication Task Group. Such standardization activities have a major impact on the development of OCC technologies. In addition, it provides a detailed review of the related literature. Herein, OCC technologies are classified into five categories to elucidate their operations and technical characteristics. Furthermore, a concise performance analysis, numerical simulations, and some comparison of the results obtained for associated systems are presented, and the future directions of research and development are discussed."
  },
  {
    "year": "2017",
    "abstract": "In recent years, with the widespread of Internet and digitized processing of multi-script documents worldwide, script identification techniques have become more important in the pattern recognition field. Script identification concerns methods for identifying different scripts in multi-lingual, multi-script documents. This paper presents a comprehensive overview on research activities in the field and focuses on the most valuable results obtained so far. The most vital processes in script identification are addressed in detail: identification and discriminating methods, features extraction (local and global), and classification. Different kinds of approaches have been developed and promising results have been achieved. This paper reports SoA performance results. This paper reports methods concerning handwritten, printed, and hybrid document processing. More research is necessary to meet the performance levels essential for everyday applications."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a supervised data imputation based on the class-dependent matrix factors, which are generated during matrix factorization. The proposed ridge alternating least squares imputation uses class information to create substituted values, which approximate the characteristics of their corresponding classes, for missing entries. In the training phase, the incomplete data with label information are divided into different classes based on their labels, such that basis matrices become class-dependent. Subsequently, iterative projection pursuit is proposed to perform imputation for testing data by computing the linear combination of these class-dependent basis matrices and their corresponding reconstruction weights. The class-dependent basis matrix with the minimum loss during reconstruction is regarded as the correct imputation for a testing sample, of which the substituted values are derived from the matrix factors of its class. Experiments on open data sets showed that the proposed method successfully decreased the imputation error by 40.52% on average, better than typical unsupervised collaborative filtering, while maintaining classification accuracy."
  },
  {
    "year": "2017",
    "abstract": "The quality of experience (QoE) perceived by users is a critical performance measure for Web browsing. “Above-The-Fold” (ATF) time has been recently recognized and widely used as a direct measure of user-end QoE by a number of studies. To reduce the ATF time, the existing works mainly focus on reducing the delay of networking. However, we observe that the webpage structures and content orders can also significantly affect theWeb QoE. In this paper, we propose a novel optimization framework that reorders the webpage objects to minimize the user-end ATF time. Our core idea is to first identify the webpage objects that consume the ATF time but have no impact on the page experience and then change the positions of these objects to achieve the minimum ATF time. We implement this framework and evaluate its performance with popular websites. The results show that the ATF time is greatly reduced compared with the existing works, especially for complex webpages."
  },
  {
    "year": "2017",
    "abstract": "Extracting stable features to enhance object representation has proved to be very effective in improving the performance of object tracking. To achieve this, mining techniques, such as K-means clustering and data associating, are often adopted. However, K-means clustering needs the pre-set number of clusters. Real scenarios (heavy occlusion and so on) often make the tracker lose the target object. To handle these problems, we propose an intraframe clustering and interframe association (ICIA)-based stable feature mining algorithm for object tracking. The value (in HSV space) peak contour is employed to automatically estimate the number of clusters and classify value and saturation colors of the object region to get connected subregions. Every subregion is described with observation and increment models. Multi-feature distances-based subregion association, between the current object template and the current observation, is then utilized to mine stable subregion pairs and obtain feature change ratio. Stable subregion displacements, and current detected and historical trajectories are systematically fused to locate the object. And, stable and unstable subregion features are updated separately to restrain the accumulative error. Experimental comparisons are conducted on six test sequences. Compared with several relevant state-of-the-art algorithms, the proposed ICIA tracker most accurately locates objects in four sequences and shows the second-best performance in the other two sequences with only less 1 pixel distance difference than the best method."
  },
  {
    "year": "2017",
    "abstract": "Analytic envelope is the most prevalent definition of envelopes of real-valued signals. However, analytic signals are not adopted by some envelope detectors in application. This paper investigates the envelopes of real-valued signals from a signal processing perspective. We show that the upper and lower envelopes of signals can be obtained by signal reconstruction after extrema sampling on signals. We prove that extrema sampling is a sub-Nyquist sampling. We then conclude that the envelopes of real-valued signals contain two parts, some low-frequency components of the original signal and some new components generated by sub-Nyquist extrema samplings. Some examples are presented to compare with the analytic envelope of signals."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we proposed thermal- and performance-aware address mapping (TPAMAP) for the multi-channel 3-D DRAM systems. TPAMAP reduces the thermal problem from the vertical stacking of the active banks in different DRAM channels and supports the mappings with the design tradeoffs of the temperature and performance. In our experiments, the peak temperature can be reduced by 1.1 °C ~ 12.3 °C for the 3-D DRAM system using TPAMAP. The cost function for the constraints of the temperature and performance is also proposed. In hardware design, we demonstrate the low-cost feature of TPAMAP in our hardware design."
  },
  {
    "year": "2017",
    "abstract": "A reconfigurable loop antenna with two parasitic grounded strips for modern smartphone devices is presented in this paper. The most essential merit of this proposed reconfigurable antenna is that it can keep the intactness of the outer metal rim. In addition, it can generate multiantenna modes. The outer metal rim generates three loop modes and the inner parasite grounded strips can provide two monopole modes. By merging these two types of antenna modes, it can offer two wide bandwidths to cover GSM850/900, DCS/PCS/UMTS2100, and LTE2300/2500 operations with a compact antenna size of 945 mm2. The detailed operating principles and design considerations of this proposed reconfigurable antenna are described. In order to validate this proposed antenna, it was fabricated and tested. The measured antenna efficiencies and gains are satisfied with the requirements for the modern communication devices."
  },
  {
    "year": "2017",
    "abstract": "Communication between vehicles enables a wide array of applications and services ranging from road safety to traffic management and infotainment. Each application places distinct quality of service (QoS) constraints on the exchange of information. The required performance of the supported services differs considerably in terms of bandwidth, latency, and communication reliability. For example, high-bandwidth applications, such as video streaming, require highly reliable communication. However, the attenuation of the IEEE 802.11p/DSRC communication link, due to static and mobile obstructing objects, degrades the link quality and can compromise the QoS requirements of the supported applications. On the other hand, a dual-interface hybrid architecture may have a failover or backup mechanism and benefit from more reliable alternatives, such as cellular networks for occasionally offloading data transmission by radio access technology (RAT) selection and vertical handover process. Since 4G/Long-Term Evolution (LTE) is generally not free, it is, therefore, highly desirable to minimize the time during which the cellular interface is used and to return to the IEEE 802.11p/DSRC interface. This paper proposes a hybrid communication approach based on 4G/LTE and the IEEE 802.11p technologies to support a V2X video streaming application. The proposed approach includes details on the underlying communication architecture, a procedure for selecting the best RAT, a real test platform complemented by a standard software protocol stack, and finally an extensive performance evaluation of the proposed solution based on field test measurements. The results indicate that the proposed approach significantly improves the overall reliability of communication with respect to packet and frame delivery metrics."
  },
  {
    "year": "2017",
    "abstract": "We consider a heterogeneous network (HetNet) containing primary users (PUs) and secondary users (SUs). Ordinary cellular users are characterized as PUs, while SUs are the unlicensed users, sensors, or some other Internet of Things equipments. The PUs occupy all the channels in the HetNet and the SUs try to reuse the channels of PUs. We consider two transmission modes for SUs, i.e., the SU can associate with the base station (BS) directly or through the help of its cooperative relay. The optimization of energy efficiency (EE) of SUs is considered. Particularly, we focus on user association (BS selection, channel allocation, and mode selection) and power control to optimize the uplink EE of the communication between the SU and the BS. The original problem is formulated as a non-convex and mixed-integer optimization problem. To get a tractable solution, we propose an iterative optimization algorithm. The alterative optimization method decomposes the original problem into three subproblems. In each iteration, the three subproblems are solved by using the sum-of-ratios programming algorithm, the parametric Dinkelbach algorithm, and convex optimization. Then, the proposed scheme repeats the iteration until convergence. Numerical results confirm that the proposed method can improve the uplink EE performance for SUs."
  },
  {
    "year": "2017",
    "abstract": "Full-duplex (FD) communication is promoted to double the spectral efficiency when compared with the half-duplex counterpart. In the context of cellular networks, however, FD communication exacerbates the aggregate uplink (UL) and downlink (DL) interference, which diminishes the foreseen FD gains. This paper considers a flexible duplex system, denoted by α-duplex system, wherein a fine-grained bandwidth control for each UL/DL channel pair in each base station (BS) is allowed, which also leads to partial spectrum overlap between the UL and DL channels. This paper addresses the resulting interference management problem by maximizing a network-wide rate-based utility function subject to UL/DL power constraints, so as to determine user-to-BS association, user-to-channel scheduling, the UL and DL transmit powers, and the fraction of spectrum overlap between UL and DL for every user, under the assumption that the number of available channels and users is equal. This paper solves such a non-convex mixed-integer optimization problem in an iterative way by decoupling the problem into several sub-problems. Particularly, the user-to-BS association problem is solved using a matching algorithm that is a generalization of the stable marriage problem. The scheduling problem is solved by an iterative Hungarian algorithm. The power and spectrum overlap problem is solved by successive convex approximation. The proposed iterative strategy guarantees an efficient one-to-one user to BS and channel assignment. It further provides optimized flexible duplexing and power allocation schemes for all transceivers. Simulations results show appreciable gains when comparing the proposed solution with different schemes from the literature."
  },
  {
    "year": "2017",
    "abstract": "It is important to determine when and why stereotyped movements indicative of developmental disabilities occur in order to provide timely medical treatment. However, these behaviors are unpredictable, which renders their automatic detection very useful. In this paper, we propose a machine learning system that runs on a smartwatch and a smartphone to recognize stereotyped movements in children with developmental disabilities. We train a classifier by tagging data from an accelerometer and a gyroscope in a smartwatch to one of six stereotyped movements made by children and recognized by special educational needs teachers. This classifier can then recognize when a child wearing a smartwatch is making one of the stereotyped movements. These schemes were implemented as a suite of apps used by parents and caregivers. In tests on children and young people with developmental disabilities, the system achieved an average recognition accuracy of 91% when individual training data was used."
  },
  {
    "year": "2017",
    "abstract": "This paper is focused on training sequence design for efficient channel estimation in multiple-input multiple-output filterbank multicarrier (MIMO-FBMC) communications using offset quadrature amplitude modulation (OQAM). MIMO-FBMC is a promising technique to achieve high spectrum efficiency as well as strong robustness against dispersive channels due to its feature of time-frequency localization. A salient drawback of FBMC/OQAM signals is that only real-field orthogonality can be kept, leading to the intrinsic imaginary interference being a barrier for high-performance channel estimations. Also, conventional channel estimations in the MIMO-FBMC systems mostly suffer from high training overhead especially for large number of transmit antennas. Motivated by these problems, in this paper, we propose a new class of training sequences, which are formed by concatenation of two identical zero-correlation zone sequences whose auto-correlation and cross correlation are zero within a time-shift window around the in-phase position. Since only real-valued symbols can be transmitted in MIMO-FBMC systems, we propose “complex training sequence decomposition (CTSD)” to facilitate the reconstruction of the complex-field orthogonality of MIMO-FBMC signals. Our simulations validate that the proposed CTSD is an efficient channel estimation approach for practical preamble-based MIMO-FBMC systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the structural controllability of the systems over F(z) is studied using a new mathematical method-matroids. First, a vector matroid is defined over F(z). Second, the full rank conditions of [sI - A|B](s ∈ p) are derived in terms of the concept related to matroid theory, such as rank, base, and union. Then, the sufficient condition for the linear system and composite system over F(z) to be structurally controllable is obtained. Finally, this paper gives several examples to demonstrate that the married-theoretic approach is simpler than other existing approaches."
  },
  {
    "year": "2017",
    "abstract": "Many wireless sensor networks (WSNs) applications, techniques, and algorithms require the position of the sensor nodes. Sensor nodes mainly rely on localization algorithms to determine their own physical location. Usually, these sensor nodes are equipped with a limited power source. Therefore, a localization algorithm used by a WSN should be an energy-aware algorithm. One of the energy efficient localization algorithms that has been proposed recently is an efficient localization algorithm for wireless ad hoc sensor networks with high accuracy (ALWadHA). In this paper, we investigate the impact of using three techniques by ALWadHA in improving the energy efficiency of ALWadHA: first, a single-estimation approach whereby a node estimates its position only once; second, dynamic power control whereby reference nodes reduce their transmission power based on their distance to the node that broadcasts the location request; and third an incremental and exponential requesting rate approach, which controls the frequency rate of sending the location request. Simulation results show that the final approach reduces the energy consumption of ALWadHA by 51.5%, without compromising the accuracy of the position estimation."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a system to determine the placement of a smartphone by using the acoustic properties of the surface materials nearby. Detecting the surrounding materials allows the smartphone to change its notification method automatically, based on situational factors. Researchers have studied how to recognize the position in which smartphones are worn while walking, using accelerometer data; however, it is difficult to identify a smartphone's position while stationary, because the accelerometer value does not change significantly when the smartphone is put down. In this paper, we developed a method to recognize surface materials close to a smartphone, using echoes; this method is based on the assumption that echoes of a selected frequency will differ in their properties, depending on the smartphone's placement and the surface materials nearby. Through our experiment, we found that our proposed method can classify 12 kinds of placement with 82.1% accuracy."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present an eight round distinguisher for four-branch type-2 generalized Feistel network (GFN) with double-SP (DSP) functions and two distinguishers for eight-branch type-2 GFN with single-SP (SSP) functions in a known key attack (KKA) model. We improved the result presented by Sasaki in Indocrypt 2012 by extending the number of rounds attacked from seven to eight for four-branch GFN. Furthermore, for eight-branch type-2 GFN with SSP functions, we present the first known key distinguishers. Our attack works up to 15 rounds of this GFN for all practical parameters. Subsequently, we extend the attack to 17 rounds for the same GFN, which works for most practical parameters. On the basis of our second result and the number of rounds attacked, we conclude that eight-branch type-2 GFN with SSP functions is weaker than four-branch type-two GFN with DSP functions in the KKA model. We apply rebound attack technique to mount all three distinguishers. However, a limitation of all the distinguishers presented in this paper is that they are useful only if the input size of S-boxes in bits is greater than or equal to the number of S-boxes in one S-box layer."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the effect of hardware impairments on the performance of dual-hop amplify-and-forward (AF)/decode-and-forward (DF) multiple relaying networks using switch-and-examine combining with post-selection (SECps) scheduling scheme in shadowed-Rician (SR) channel. Moreover, we consider a more general network, where the hard impairments are both considered at source, relays, and destination. Specifically, to decrease the high-implementation cost, the SECps scheme is adopted to choose an appropriate relay. To evaluate the performance of the considered system, we derive the novel closed-form expression of the outage probability for the AF and DF protocol, respectively. We also derive the asymptotic outage probability results at high SNRs for the DF protocol, which provides a fast way to evaluate the impact of hardware impairments on the dual-hop relay networks in the SR channel. In addition, simulation results are given to validate the correctness of the analytical results."
  },
  {
    "year": "2017",
    "abstract": "Currently, most of the processing techniques for the conventional location-based queries focus only on a single type of objects. However, in real-life applications, the user may be interested in obtaining information about different types of objects, in terms of their neighboring relationship. We term the different types of stationary objects closer to each other the heterogeneous neighboring objects (HNOs). Efficient processing of the location-based queries on the HNOs is more complicated than that on a single data source, because the neighboring relationship between the HNOs inevitably affects the query result. In this paper, we present useful and important location-based aggregate queries on the HNOs, which can provide useful object information by considering both the spatial closeness of objects to the query object and the neighboring relationship between objects. The location-based aggregate queries consist of four queries: the shortest average-distance (SAvgD) query, the shortest minimal-distance (SMinD) query, the shortest maximal-distance (SMaxD) query, and the shortest sum-distance (SSumD) query. To process the location-based aggregate queries, we devise two heuristics, the HNOs-qualifying heuristic and the HNOs-pruning heuristic, to efficiently determine the HNOs sets. According to different query types, we further propose four heuristics, the SAvgD-pruning heuristic, the SMinD-pruning heuristic, the SMaxD-pruning heuristic, and the SSumD-pruning heuristic, to effectively reduce the number of distance computations required for query processing. Comprehensive experiments are conducted to demonstrate the effectiveness of the heuristics and the efficiency of the proposed approaches."
  },
  {
    "year": "2017",
    "abstract": "End users' quality of experience (QoE) is one of the most crucial requirements to be considered in device-to-device communication. Users' QoE is affected by the ratio of the amount of received data to the amount of shared data. The ratio should be approximate to 1. To achieve this, we propose an evolutionary algorithm-based cooperative content caching and communication (EACCC) scheme. This scheme works by finding the maximum 1-factor of a directed weighted graph, where each edge's weight corresponds to the mean opinion score of the connection between two users. Finding the maximum 1-factor of graph-based communication is a problem that is difficult to solve optimally, but an evolutionary algorithm can quickly converge to a high-quality solution. Each user provides an opinion score of incoming and outgoing connection, and the maximum 1-factor corresponds to the scheme that maximizes overall QoE. The proposed EACCC scheme achieves optimal connections among users in a vast and complex network, due to strong mutual communication. The simulation results verify that our proposed scheme outperforms traditional QoE optimization schemes. Moreover, our scheme can be implemented easily in a realistic scenario."
  },
  {
    "year": "2017",
    "abstract": "Fatigued driving detection, which employs pattern recognition to discover the state of a driver's fatigue, is considered a key technique to improve road safety. However, the widely used frontal face recognition systems have problems, such as low recognition accuracy, poor real-time ability, and highly complex algorithms. In this paper, a new color space modeling, which uses multi-threshold decision criteria, is used to enhance facial skin extraction performance, and a three-step strategy is designed to eliminate noise and other adverse effects. Experiments show that the proposed algorithm can extract side face contour lines effectively and provide a scientific basis for real-time tracking of fatigue."
  },
  {
    "year": "2017",
    "abstract": "Today’s content delivery networks (CDNs) use large sets of globally distributed servers, advanced routing techniques, and dynamic server selection to provide users with low delay, reliable access to Web, and streaming content. These strategies allow CDNs to extend their reach and performance into large numbers of networks around the globe. However, nearly 20% of Internet users reside in China, where local regulations and network policies make it challenging for global CDNs to serve foreign content from servers in China and limit the effectiveness of their traditional strategies for low-latency content delivery. Recently, a number of China-specific CDNs have partnered with global CDNs to provide service in the country. However, little is known about how CDNs in China are implemented, nor their impact on performance. In this paper, we are the first to investigate the impact of China’s unique policy and networking environment on CDN implementations and deployments. We find that deployments inside China exhibit different client-mapping behavior than global ones, namely, through static server selection for clients given a customer site, and through region-specific clients partitioning and mapping rather than using live network information. We also show that ignoring these properties can significantly impact server selection quality. Our results can be useful for optimization of CDNs in China."
  },
  {
    "year": "2017",
    "abstract": "Recent advances in wireless sensor networks for ubiquitous health and activity monitoring systems have triggered the possibility of addressing human needs in smart environments through recognizing human real-time activities. While the nature of streams in such networks requires efficient recognition techniques, it is also subject to suspicious inference-based privacy attacks. In this paper, we propose a framework that efficiently recognizes human activities in smart homes based on spatiotemporal mining technique. In addition, we propose a technique to enhance the privacy of the collected human sensed activities using a modified version of micro-aggregation approach. An extensive validation of our framework has been performed on benchmark data sets yielding quite promising results in terms of accuracy and privacy-utility tradeoff."
  },
  {
    "year": "2017",
    "abstract": "Wireless cellular networks have seen dramatic growth in number of mobile users. As a result, data requirements, and hence the base-station power consumption has increased significantly. It in turn adds to the operational expenditures and also causes global warming. The base station power consumption in long-term evolution (LTE) has, therefore, become a major challenge for vendors to stay green and profitable in competitive cellular industry. It necessitates novel methods to devise energy efficient communication in LTE. Importance of the topic has attracted huge research interests worldwide. Energy saving (ES) approaches proposed in the literature can be broadly classified in categories of energy efficient resource allocation, load balancing, carrier aggregation, and bandwidth expansion. Each of these methods has its own pros and cons leading to a tradeoff between ES and other performance metrics resulting into open research questions. This paper discusses various ES techniques for the LTE systems and critically analyses their usability through a comprehensive comparative study."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study fingerprinting-based indoor localization in commodity 5-GHz WiFi networks. We first theoretically and experimentally validate three hypotheses on the channel state information (CSI) data of 5-GHz OFDM channels. We then propose a system termed BiLoc, which uses bi-modality deep learning for localization in the indoor environment using off-the-shelf WiFi devices. We develop a deep learning-based algorithm to exploit bi-modal data, i.e., estimated angle of arrivings and average amplitudes (which are calibrated CSI data using several proposed techniques), for both the off-line and online stages of indoor fingerprinting. The proposed BiLoc system is implemented using commodity WiFi devices. Its superior performance is validated with extensive experiments under three typical indoor environments and through comparison with three benchmark schemes."
  },
  {
    "year": "2017",
    "abstract": "The rock physics model of coalbed methane (CBM) reservoir is significant for the study of CBM content. However, because of the adsorption and dissociation of the CBM reservoir, it is difficult to establish models. In addition, the studies on rock physics modeling of the CBM reservoir are scarce. This paper proposes the basic modeling process. First, the coal rock minerals and methane in adsorbed state are used to calculate elastic parameters of coal rock matrix. Then, the differential equivalent medium model is used to get elastic parameters of the dry rock skeleton. The free methane is mixed with water, and finally the Gassmann equation is applied to obtain elastic parameters of the CBM reservoir model. The study on the CBM reservoir rock physics model's response characteristics has found that there is a sensitive negative correlation between CBM content and P-wave velocity and density. The higher CBM content goes with larger absolute values of intercept, gradient, and seismic amplitude, because their seismic attributes are more sensitive to higher CBM content, whereas the response characteristics are opposite with the lower CBM content. The relationship among the CBM content and absolute values of intercept, gradient, and seismic amplitude in the real data of Qinshui Basin is largely consistent with the response characteristics of the established rock physics model, indicating that the CBM reservoir rock physics model proposed in this paper has a certain feasibility, and the response characteristics of its intercept, gradient, and seismic amplitude are more sensitive to predicting CMB reservoirs."
  },
  {
    "year": "2017",
    "abstract": "This paper characterizes the performance metrics of MU-MIMO systems under Rayleigh fading channels in the presence of both cochannel interference and additive noise with unknown channel state information and known correlation matrices. In the first task, we derive analytical expressions for the cumulative distribution function of the instantaneous signal-to-interference-plus-noise ratio (SINR) for any deterministic beamvectors. As a second task, exact closed-form expressions are derived for the instantaneous capacity, the upper bound on ergodic capacity, and the Gram-Schmidt orthogonalization-based ergodic capacity for similar intra-cell correlation coefficients. Finally, we present the utility of several structured-diagonalization techniques, which can achieve the tractability for the approximate solution of ergodic capacity for both similar as well as different intra-cell correlation matrices. The novelty of this paper is to formulate the received SINR in terms of indefinite quadratic forms, which allows us to use complex residue theory to characterize the system behavior. The analytical expressions obtained closely match simulation results."
  },
  {
    "year": "2017",
    "abstract": "Context: GitHub, nowadays the most popular social coding platform, has become the reference for mining Open Source repositories, a growing research trend aiming at learning from previous software projects to improve the development of new ones. In the last years, a considerable amount of research papers have been published reporting findings based on data mined from GitHub. As the community continues to deepen in its understanding of software engineering thanks to the analysis performed on this platform, we believe that it is worthwhile to reflect on how research papers have addressed the task of mining GitHub and what findings they have reported. Objective: The main objective of this paper is to identify the quantity, topic, and empirical methods of research works, targeting the analysis of how software development practices are influenced by the use of a distributed social coding platform like GitHub. Method: A systematic mapping study was conducted with four research questions and assessed 80 publications from 2009 to 2016. Results: Most works focused on the interaction around coding-related tasks and project communities. We also identified some concerns about how reliable were these results based on the fact that, overall, papers used small data sets and poor sampling techniques, employed a scarce variety of methodologies and/or were hard to replicate. Conclusions: This paper attested the high activity of research work around the field of Open Source collaboration, especially in the software domain, revealed a set of shortcomings and proposed some actions to mitigate them. We hope that this paper can also create the basis for additional studies on other collaborative activities (like book writing for instance) that are also moving to GitHub."
  },
  {
    "year": "2017",
    "abstract": "With the development of speech synthesis techniques, automatic speaker verification systems face the serious challenge of spoofing attack. In order to improve the reliability of speaker verification systems, we develop a new filter bank-based cepstral feature, deep neural network (DNN) filter bank cepstral coefficients, to distinguish between natural and spoofed speech. The DNN filter bank is automatically generated by training a filter bank neural network (FBNN) using natural and synthetic speech. By adding restrictions on the training rules, the learned weight matrix of FBNN is band limited and sorted by frequency, similar to the normal filter bank. Unlike the manually designed filter bank, the learned filter bank has different filter shapes in different channels, which can capture the differences between natural and synthetic speech more effectively. The experimental results on the ASVspoof 2015 database show that the Gaussian mixture model maximum-likelihood classifier trained by the new feature performs better than the state-of-the-art linear frequency triangle filter bank cepstral coefficients-based classifier, especially on detecting unknown attacks."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study the secrecy performance of a half-duplex cognitive relay network in the presence of multiple eavesdroppers and multiple primary users. In particular, generic K th best relay selection schemes for opportunistic relay selection (ORS) and partial relay selection (PRS) are proposed. Exact closed-form and asymptotic expressions for secrecy outage probability (SOP) of the considered schemes are derived. The outcome shows that ORS is able to achieve full secrecy diversity order while PRS obtains unit diversity order. Besides, the order of the selected relay is proved to affect the secrecy diversity order in the ORS scheme but not the PRS scheme, while the number of primary users does not have influence on the diversity order. Additionally, the significance of the change in the number of relays on the SOP enhances at higher orders of selected relay. Nevertheless, increasing the number of eavesdroppers reduces the secrecy diversity gain of the considered system in both schemes."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new attribute control chart using multiple-dependent state repetitive sampling is designed. The operational procedure and structure of the proposed control chart is given. The required measures to determine the average run length for in-control and out-of-control processes are given. Tables of ARLs are reported for various control chart parameters. The proposed control chart is more sensitive in detecting a small shift in the process as compared with the existing attribute control charts. The simulation study shows the efficiency of the proposed chart over the existing charts. An example is given for illustration purpose."
  },
  {
    "year": "2017",
    "abstract": "The determination of optimal packet size (OPS) for a cognitive radio-assisted sensor networks (CRSNs) architecture is non-trivial. State of the art in this area describes various complex techniques to determine OPS for CRSNs. However, it is observed that under high interference from the surrounding users, it is not possible to determine a feasible OPS of data transmission under the simple point-to-point CRSN topology. This is contributed primarily to the peak transmit power constraint of the cognitive nodes. To address this specific challenge, this paper proposes a multiple-input multiple output-based CRSNs (MIMO-CRSNs) architecture for futuristic technologies, such as Internet of Things and machine-to-machine communications. A joint optimization problem is formulated, considering network constraints, such as the overall end-to-end latency, interference duration caused to the non-cognitive users, average BER, and transmit power. We propose our Algorithm 1 based on the generic exhaustive search technique to solve the optimization problem. Furthermore, a low complexity suboptimal Algorithm 2 based on solving classical Karush-Kuhn-Tucker conditions is proposed. These algorithms for MIMO-CRSNs are implemented in conjunction with two different channel access schemes. These channel access schemes are time-slotted distributed cognitive medium access control denoted as MIMO-DTS-CMAC and CSMA/CA-assisted centralized common control channel-based cognitive medium access control denoted as MIMO-CC-CMAC. Simulations reveal that the proposed MIMO-CRSN outperforms the conventional point-to-point CRSN in terms of overall energy consumption. Moreover, the proposed Algorithm 1 and Algorithm 2 show a perfect match, and the implementation complexity of Algorithm 2 is less than Algorithm 1. Algorithm 1 takes almost 680 ms to execute and provides OPS value for a given number of users, whereas Algorithm 2 takes 4-5 ms on average to find the OPS for the proposed MIMO-CRSN framework."
  },
  {
    "year": "2017",
    "abstract": "The failure detection rate (FDR) is the most common testability index used to evaluate the equipment testability level. According to the testability test theory of FDR, a widespread supposition is that the FDR value of a system is an unknown constant. However, there have been a few attempts to research the sample property of failure detection and the statistical characteristics of FDR to prove this fundamental premise. Considering the real maintenance effects on the failure occurrence process, the value of FDR catches time-varying characteristics, which can be depicted as a special statistical process. A failure occurrence model based on the non-homogeneous Poisson process (NHPP) is proposed to depict failure occurrence samples under the assumption of minimal maintenance policy. The binominal cumulative probability function (CDF) is used to depict the each failure detection action. Combining the NHPP based failure occurrence model and the failure detection model based on a binominal distribution, we can simulate the failure detection samples and statistical characteristics of FDR based on the Monte Carlo method. This paper mainly focuses on the expectation and variance of FDR, which are two key statistical characteristics. To validate the FDR time-varying characteristics, we perform a simulation using two Shop Replaceable Units in a level flight indicator of a helicopter to evaluate the FDR value. Based on theoretic and simulative methods, the FDR expectation of the level flight indicator has an increasing or decreasing tendency in the early stages and tends to be a constant in later stages, while the variation of FDR keeps monotonously decreasing. Under the assumptions made in this paper, the supposition that the FDR value of a system is a certain value is not suitable in all stages of the failure occurrence process."
  },
  {
    "year": "2017",
    "abstract": "Spatial modulation (SM) has emerged as a low-complexity and energy-efficient multiple-input multiple-output transmission technique, where the information bits are not only transmitted by amplitude phase modulation but also conveyed by the index of activated transmit antenna (TA). By deploying SM in downlink multi-user (DL-MU) scenarios, conventional orthogonal multiple access-based SM (OMA-SM) allocates exclusive time-frequency resources to users, but suffers from low spectral efficiency. TA grouping-based SM (TAG-SM) divides TAs into sub-groups to serve different users independently, but suffers from severe inter-user interference. By introducing non-OMA (NOMA) into SM for DL-MU transmission, NOMA-based SM (NOMA-SM) is proposed to mitigate inter-user interference, while maintaining high spectral efficiency. Specifically, by applying successive interference cancellation at user side, the inter-user interference could be effectively eliminated with the sacrifice of increased computational complexity. Afterward, based on a symbol error rate analysis, a low-complexity power allocation scheme is provided to achieve high spectral efficiency through power domain multiplexing. When considering near-far effect from user distribution, user pairing issue is also discussed. Numerical simulation compares NOMA-SM with OMA-SM and TAG-SM, and verifies the effectiveness of the proposed low-complexity power allocation and user pairing methodologies."
  },
  {
    "year": "2017",
    "abstract": "Conceptual design plays an important role in a product development process. Significant development of technologies in the cyber-physical system (CPS) provides innovative approaches for product conceptual design. This paper proposes an architecture of CPS for conceptual design that realizes the acquisition of real-time physiological data from the physical world and the feedback of psychological states from the cyber world. As understanding and meeting the needs of customers have been recognized as significant aspects for conceptual design, an intelligent psycho-physiological approach that incorporates electroencephalogram (EEG) into the Kano model is adopted in this CPS for real-time customer needs analysis. The sample entropy (SampEn) extracted from EEG data is an endogenous neural indicator for customers' psychological states. A support vector machine using this SampEn as input is trained for classifying different categories of quality attributes defined in the Kano model. A case study is conducted to testify the feasibility of the approach proposed in this paper."
  },
  {
    "year": "2017",
    "abstract": "In order to meet the ever increasing data rate demands, the next generation of wireless communication systems is being designed for exploiting the large amounts of unused spectrum in the millimeter-wave (mm-wave) band. Since operating at mm-wave frequencies imposes several challenges, such as high-path loss, as well as both spatial and temporal channel sparsity, there is a significant research interest focused on designing feasible solutions for establishing reliable and high-throughput links at mm-wave frequencies. In this paper, we consider a cellular system relying on hybrid beamforming aided base station (BS) as well as user equipment and study the user selection problem, which has not been hitherto studied in the literature. More specifically, we study the problem of selectingK′-users by the BS for communication out ofK-users whilst ensuring that the sum rate is maximized. Specifically, we propose a user selection algorithm, which relies on the knowledge of both the channel gains and the angle of departure (AoD) of the channel paths spanning to the various users, which is termed the AoD aided user selection (AoD-US). Furthermore, we devise a pair of subspace metrics based on: 1) the angle between the subspaces spanned by the BS array response vectors; 2) the ratio of interference and signal space dimensions of various users, in order to reduce the user search space in AoD-US. This modified user selection algorithm is termed the AoD aided user selection with user set pruning (AoD-US-P). Furthermore, we study the attainable sum-rate performance of the block-diagonalization aided downlink and show that the proposed selection algorithms guarantee both multiuser diversity and multiplexing gains. Additionally, the proposed algorithms are studied in the round-robin scheduling scenario, where all theK-users are scheduled for achieving fairness. Our simulation results revealed that the AoD-US-P achieves nearly the same performance as that achieved ..."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a hybrid structure for multi-stream large-scale multi-input multi-output (MIMO) beamforming systems, in single-user scenario, using a Hadamard radio frequency (RF) codebook with low-bit resolution phase shifters. We show that Hadamard transform can be used in RF beamsteering/beamcombining to achieve better performance in terms of average achievable spectral efficiency and low hardware cost using 1- or 2-b resolution APSs. In contrast, the state-of-the-art RF codebook designs available in the literature requires more than 7-b resolution to achieve the same performance as the proposed scheme, for large antenna arrays with up to 256 elements. The performance gains of the proposed RF codebook design is thoroughly investigated using MATLAB simulations for typical mmWave MIMO system, and the simulation results are closely verified by the analytical expressions."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a carrier-sensing multiple access protocol for asynchronous multiple-packet reception (MPR), which enables wireless receivers to correctly decode partially time-overlapping packets. Unlike previous studies, which require back-off nodes to constantly monitor the channel, our design requires only that each node sense the number of transmitting nodes after the completion of the back-off period for determining whether to begin transmission in the next time slot. In addition, we develop an analytical model to evaluate relevant parameters and performance metrics of the proposed protocol. Our model relies on the channel-sensing probability of a node in a randomly chosen slot, rather than channel-accessing probability adopted in previous models for asynchronous MPR. The results are validated through numerical study under a variety of network conditions. We also show that the proposed protocol is quite robust to imperfect estimation in channel sensing, and is more energy-efficient than other similar threshold-based protocols."
  },
  {
    "year": "2017",
    "abstract": "As the explosive growth of smart devices and the advent of many new applications, traffic volume has been growing exponentially. The traditional centralized network architecture cannot accommodate such user demands due to heavy burden on the backhaul links and long latency. Therefore, new architectures, which bring network functions and contents to the network edge, are proposed, i.e., mobile edge computing and caching. Mobile edge networks provide cloud computing and caching capabilities at the edge of cellular networks. In this survey, we make an exhaustive review on the state-of-the-art research efforts on mobile edge networks. We first give an overview of mobile edge networks, including definition, architecture, and advantages. Next, a comprehensive survey of issues on computing, caching, and communication techniques at the network edge is presented. The applications and use cases of mobile edge networks are discussed. Subsequently, the key enablers of mobile edge networks, such as cloud technology, SDN/NFV, and smart devices are discussed. Finally, open research challenges and future directions are presented as well."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a neuromorphic person re-identification (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system. In the observation module, a semantic partitioning scheme is introduced to segment a pedestrian into several logical parts, and an exhaustive set of experiments have been carried out to select the best possible complementary feature cues. In the cognition module, an unsupervised procedure is suggested to partition the gallery candidates into multiple consensus clusters with high intra-cluster and low inter-cluster similarity. A supervised classifier is then deployed to learn the relationship between each gallery candidate and its associated cluster, which is subsequently used to identify a set of inlier consensus clusters. This module also includes weighing of contribution of each feature channel toward defining a consensus cluster. Finally, in the contemplation module, the contributory weights are employed in a correlation-based similarity measure to find the corresponding match within the inlier set. The proposed framework is compared with several state-of-the-art methods on three challenging data sets: VIPeR, iLIDS-VID, and CUHK01. The experimental results, with respect to recognition rates, demonstrate that the proposed framework can obtain superior performance as compared with the counterparts. The proposed framework, along with its low-rank bound property, further establishes its suitability in practical scenarios through yielding high cluster hit rate with low database penetration."
  },
  {
    "year": "2017",
    "abstract": "Pervasive social networking (PSN) aims at bridging the gap between the services and users by providing a platform for social communication irrespective of the time and location. With the advent of a new era of high-speed telecommunication services, mobile users have evolved to a large extent demanding secure, private, and trustworthy services. Online social networks have evolved as pervasive online social networks (POSNs), which uses a common platform to connect users from hybrid applications. Trust has always been a concern for these networks. However, existing approaches tend to provide application-specific trust management, thus resulting in the cost of excessive network resource utilization and high computations. In this paper, a pervasive trust management framework is presented for POSNs, which is capable of generating high trust value between the users with a lower cost of monitoring. The proposed approach uses a flexible mixture model to develop the system around six different properties, and then utilizes the concept of osmotic computing to perform computational offloading, which reduces the number of computations as well as computational time. The novel concepts of lock door policy and intermediate state management procedure are used to allow trust visualization by providing efficient identification of trustworthy and untrustworthy users. The proposed approach is capable of predicting user ratings efficiently with extremely low errors, which are in the range of ±2. The effectiveness of the proposed approach is demonstrated using theoretical and numerical analyses along with data set-based simulations."
  },
  {
    "year": "2017",
    "abstract": "Network function virtualization (NFV) is a new network architecture framework that implements network functions in software running on a pool of shared commodity servers. NFV can provide the infrastructure flexibility and agility needed to successfully compete in today's evolving communications landscape. Any service is represented by a service function chain (SFC) that is a set of VNFs to be executed according to a given order. The running of VNFs needs the instantiation of VNF instances (VNFIs) that are software modules executed on virtual machines. This paper deals with the migration problem of the VNFIs needed in the low traffic periods to turn OFF servers and consequently to save energy consumption. Though the consolidation allows for energy saving, it has also negative effects as the quality of service degradation or the energy consumption needed for moving the memories associated to the VNFI to be migrated. We focus on cold migration in which virtual machines are redundant and suspended before performing migration. We propose a migration policy that determines when and where to migrate VNFI in response to changes to SFC request intensity. The objective is to minimize the total energy consumption given by the sum of the consolidation and migration energies. We formulate the energy aware VNFI migration problem and after proving that it is NP-hard, we propose a heuristic based on the Viterbi algorithm able to determine the migration policy with low computational complexity. The results obtained by the proposed heuristic show how the introduced policy allows for a reduction of the migration energy and consequently lower total energy consumption with respect to the traditional policies. The energy saving can be on the order of 40% with respect to a policy in which migration is not performed."
  },
  {
    "year": "2017",
    "abstract": "Continuous practices, i.e., continuous integration, delivery, and deployment, are the software development industry practices that enable organizations to frequently and reliably release new features and products. With the increasing interest in the literature on continuous practices, it is important to systematically review and synthesize the approaches, tools, challenges, and practices reported for adopting and implementing continuous practices. This paper aimed at systematically reviewing the state of the art of continuous practices to classify approaches and tools, identify challenges and practices in this regard, and identify the gaps for future research. We used the systematic literature review method for reviewing the peer-reviewed papers on continuous practices published between 2004 and June 1, 2016. We applied the thematic analysis method for analyzing the data extracted from reviewing 69 papers selected using predefined criteria. We have identified 30 approaches and associated tools, which facilitate the implementation of continuous practices in the following ways: (1) reducing build and test time in continuous integration (CI); (2) increasing visibility and awareness on build and test results in CI; (3) supporting (semi-) automated continuous testing; (4) detecting violations, flaws, and faults in CI; (5) addressing security and scalability issues in deployment pipeline; and (6) improving dependability and reliability of deployment process. We have also determined a list of critical factors, such as testing (effort and time), team awareness and transparency, good design principles, customer, highly skilled and motivated team, application domain, and appropriate infrastructure that should be carefully considered when introducing continuous practices in a given organization. The majority of the reviewed papers were validation (34.7%) and evaluation (36.2%) research types. This paper also reveals that continuous practices have been successfully applied to b..."
  },
  {
    "year": "2017",
    "abstract": "The robust multi-object tracking problem is a challenging issue in the field of computer vision. In this paper, we propose a multi-object tracking algorithm with temporal-spatial information and trajectory of confidence. The whole process is divided into local and global association. Trajectories with high confidence are associated with the detection result of the current frame during local association, whereas trajectories with low confidence are associated with the detection results of the current frame are not matched during global association. We determine the association results using a combined model. By utilizing the information of spatial-temporal correlation, the model is more robust and can deal with missed detection. In addition, we measure the reliability of the spatial information by the confidence map smoothing constraint and the peak sidelobe ratio criterion. We conduct experiments using a challenging public data set, and the results show that our proposed algorithm is superior to many other popular algorithms when dealing with problems, such as missed detection and poor tracker robustness."
  },
  {
    "year": "2017",
    "abstract": "Formally defined Specification and Description Language (SDL) is used for the design and specification of complex safety-critical systems. Each change in the specification of the product should be immediately checked formally against the requirements' specification. This paper presents semi-automated system abstraction, automated model extraction, simulation, and formal verification of real-life complex SDL specification. Sound algorithms implemented in our sdl2pml automated model extraction tool preserve all properties of the SDL system. Sdl2pml includes our model of discrete time, abstraction, and support for all relevant SDL functionality and constructs such as dynamic process creation, rational data types, and communication with more than one process instance. To the best of our knowledge, most of them are not supported by any other known approach. We use our SpinRCP tool for simulation and formal verification of the extracted model with the Spin model checker. We demonstrate the applicability of our approach on ISDN User adaptation protocol from SI3000 Softswitch. The extracted Promela model is the largest one ever processed by Spin. We have shown that Spin simulation and model checking can be applied successfully to such huge models."
  },
  {
    "year": "2017",
    "abstract": "It proves to be increasingly promising to evaluate the network coverage and network capacity via applying data generated by network interaction provided by the mobile operators in recent years. Self-organized optimization of network coverage and network capacity is a key solution to cope with the rapid growth of mobile data services and user expectation. In this paper, a network performance anomaly detection model based on service feature clustering is proposed. First, the complexity of the wireless network environment and the difference of user behavior are fully considered, an ensemble clustering algorithm is adopted for scene classification by combining the features of various data services with multi-dimensional physical scene characteristics, and, then, the cell categories with different characteristics are marked. Second, each category matches the corresponding network indicators and the weights of each indicators, which are trained from historical data. Finally, network performance anomaly detection is conducted on the basis of these indicators in every scene so that a new approach to evaluate the performance of wireless network can be realized. We apply this method to our long term evolution network, and the actual operation results have confirmed that the algorithm in question is highly effective and relevant."
  },
  {
    "year": "2017",
    "abstract": "Ambient-assisted living (AAL) is promising to become a supplement of the current care models, providing enhanced living experience to people within context-aware homes and smart environments. Activity recognition based on sensory data in AAL systems is an important task because 1) it can be used for estimation of levels of physical activity, 2) it can lead to detecting changes of daily patterns that may indicate an emerging medical condition, or 3) it can be used for detection of accidents and emergencies. To be accepted, AAL systems must be affordable while providing reliable performance. These two factors hugely depend on optimizing the number of utilized sensors and extracting robust features from them. This paper proposes a generic feature engineering method for selecting robust features from a variety of sensors, which can be used for generating reliable classification models. From the originally recorded time series and some newly generated time series [i.e., magnitudes, first derivatives, delta series, and fast Fourier transformation (FFT)-based series], a variety of time and frequency domain features are extracted. Then, using two-phase feature selection, the number of generated features is greatly reduced. Finally, different classification models are trained and evaluated on an independent test set. The proposed method was evaluated on five publicly available data sets, and on all of them, it yielded better accuracy than when using hand-tailored features. The benefits of the proposed systematic feature engineering method are quickly discovering good feature sets for any given task than manually finding ones suitable for a particular task, selecting a small feature set that outperforms manually determined features in both execution time and accuracy, and identification of relevant sensor types and body locations automatically. Ultimately, the proposed method could reduce the cost of AAL systems by facilitating execution of algorithms on devices with limited ..."
  },
  {
    "year": "2017",
    "abstract": "Collective behavior in human society is attracting a lot of attention, particularly as the result of novel emergent phenomena associated with online social media and networks. In effect, although crowd wisdom and herding behavior have been well studied in social science, the rapid development of Internet computing and e-commerce brings further needs of in-depth comprehension of their consequences and impact from a technological perspective. Based on social learning, an analytical knowledge originated in social science, we re-examine the well-known phenomenon of information cascade, whereby rational agents can ignore personal knowledge to follow a predominant social behavior triggered by earlier decisions made by peers. Moreover, we look into the cascade behavior from a communication theoretic perspective, interpreting social learning as a distributed data processing scheme. This perspective enables the development of a novel framework, which allows a characterization of the conditions that trigger information cascades and trace their impact on the accuracy of the collective inference. Finally, potential applications and examples of information cascade have been presented under various cyber technological scenarios, illustrating the prolific interplay between communication technology and computational social science."
  },
  {
    "year": "2017",
    "abstract": "Meter data collection and management in smart grid has the potential for underlying security risks, e.g., low-sparsity unobservable attacks. Thus, it is crucial to investigate the vulnerability of smart grid through various exposure tests associated with these unobservable attacks. Recently, much attention has been paid to low-sparsity unobservable attacks with complete knowledge of the system matrix. In this paper, the unobservable attack exposure analysis is based on a relaxed condition, i.e., an incomplete knowledge of the system matrix. Furthermore, a data-driven attack scheme is designed to demonstrate that such knowledge can be learned with a two-stage strategy. In the first stage, a sequence of intercepted meter data is utilized to learn about the incomplete system matrix with a blind identification approach. In the second stage, the estimated system matrix at hand is used for the attack vector construction with a sparsity-exploiting method. Finally, the validity of the proposed data-driven attack scheme is tested through various experiments. The proposed result reveals the potential risk of meter data leakage to the security of the smart grid."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the sequence estimation problem of binary and quadrature phase shift keying faster-than-Nyquist (FTN) signaling and propose two novel low-complexity sequence estimation techniques based on concepts of successive interference cancellation. To the best of our knowledge, this is the first approach in the literature to detect FTN signaling on a symbol-by-symbol basis. In particular, based on the structure of the self-interference inherited in FTN signaling, we first find the operating region boundary defined by the root-raised cosine pulse shape, its roll-off factor, and the time acceleration parameter of the FTN signaling where perfect estimation of the transmit data symbols on a symbol-by-symbol basis is guaranteed, assuming noise-free transmission. For noisy transmission, we then propose a novel low-complexity technique that works within the operating region and is capable of estimating the transmit data symbols on a symbol-by-symbol basis. To reduce the error propagation of the proposed successive symbol-by-symbol sequence estimator (SSSSE), we propose a successive symbol-by-symbol with go-back-K sequence estimator (SSSgbKSE) that goes back to re-estimate up to K symbols, and subsequently improves the estimation accuracy of the current data symbol. Simulation results show that the proposed sequence estimation techniques perform well for low intersymbol interference scenarios and can significantly increase the data rate and spectral efficiency. Additionally, results reveal that choosing the value of K as low as 2 or 3 data symbols is sufficient to significantly improve the bit-error-rate performance. Results also show that the performance of the proposed SSSgbKSE, with K = 1 or 2, surpasses the performance of the lowest complexity equalizers reported in the literature, with reduced computational complexity."
  },
  {
    "year": "2017",
    "abstract": "Various advanced 5G techniques are bringing us even closer to the era of smart vehicular ad hoc networks (VANETs), among which enabling secure communication for any vehicle pair is a necessary prerequisite. However, due to the unique features of fast moving and high dynamics in VANETs, the time for key establishment between a vehicle pair is rather limited. Consequently, traditional shared or public key-based mechanisms, which rely heavily on underlying infrastructure and are usually time-consuming, cannot be adopted for key establishment between vehicles. Toward this end, we propose in this paper an efficient physical layer key extraction method utilizing the received signal strength to generate secret keys, which is able to achieve high bit generation rate and 0-b disagreement, as corroborated by extensive experimental results."
  },
  {
    "year": "2017",
    "abstract": "Distributed antenna systems (DASs) have been widely implemented in the state-of-the-art cellular communication systems to cover dead spots. Recent studies have also indicated that DAS has advantages in wireless energy transfer (WET). In this paper, we study simultaneous wireless information and power transfer for a multiple-input single-output DAS in the downlink, which consists of arbitrarily distributed remote antenna units (RAUs). In order to save the energy cost, we adopt the energy cooperation of energy harvesting (EH) and two-way energy flows to let the RAUs trade their harvested energy through the smart grid network. Under individual EH constraints, per-RAU power constraints, and various smart grid considerations, we investigate a power management strategy that determines how to utilize the stochastically spatially distributed harvested energy at the RAUs and how to trade the energy with the smart grid simultaneously to supply maximum wireless information transfer (WIT) with a minimum WET constraint for a receiver adopting power splitting. Our analysis shows that the optimal design can be achieved in two steps. The first step is to maximize a new objective that can simultaneously maximize both WET and WIT, considering both the smart grid profitable and smart grid neutral cases. For the grid-profitable case, we derive the optimal full power strategy and provide a closed-form result to see under what condition this strategy is used. On the other hand, for the grid-neutral case, we illustrate that the optimal power policy has a double-threshold structure and present an optimal allocation strategy. The second step is then to solve the whole problem by obtaining the splitting power ratio based on the minimum WET constraint. Simulation results are provided to evaluate the performance under various settings and characterize the double-threshold structure."
  },
  {
    "year": "2017",
    "abstract": "Multi-scale-based image fusion is one of main fusion methods, in which multi-scale decomposition tool and feature extraction play very important roles. The quaternion wavelet transform (QWT) is one of the effective multi-scale decomposition tools. Therefore, this paper proposes a novel multimodal image fusion method using QWT and multiple features. First, we perform QWT on each source image to obtain low-frequency coefficients and high-frequency coefficients. Second, a weighted average fusion rule based on the phase and magnitude of low-frequency subband and spatial variance is proposed to fuse the low-frequency subbands. Next, a choose-max fusion rule based on the contrast and energy of coefficient is proposed to integrate the high-frequency subbands. Finally, the final fused image is constructed by inverse QWT. The proposed method is conducted on multi-focus images, medical images, infrared-visible images, and remote sensing images, respectively. Experimental results demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "This paper is a study of the inhomogeneity reduction for near-field acquisition in high-resolution magnetic resonance imaging (MRI) systems. The acquisition homogeneity in MRI imaging modality is an open issue concerning the optimal MRI image generation in terms of the RF signal acquisition. The acquisition inhomogeneity is related to the radiation patterns of the receiving antennas and its location in the MRI system, among other relevant aspects. The acquisition inhomogeneity is translated into two main effects: pattern ripples at the outer cylindrical rings and radial inhomogeneity when comparing the center value (maximum) with the rest of the pattern. To overcome these effects, two strategies are proposed. In the first one, it is proposed to progressively vary the antenna location in the azimuthal array distribution. In the second one, it is proposed to progressively vary the antenna amplitude and phase feeding in the array distribution. To compute a figure of merit of the pattern radial uniformity and the ripples, two metrics are defined in this paper. It is proved that both the progressive modification in the location at each array ring and the variation of the feeding phase of each array ring reduce the pattern ripples and radial inhomogeneity. Optimal values for either the angular rotation or the feeding phase values can be calculated, depending on the particular dimensions of the cylinder that conforms the region of interest."
  },
  {
    "year": "2017",
    "abstract": "Efficient disturbance detection is important for power system security and stability. In this paper, a new detection method is proposed based on a time series analysis technique known as k-nearest neighbor (kNN) analysis. Advantages of this method are that it can deal with the electrical measurements with oscillatory trends and can be implemented in real time. The method consists of two stages, which are the off-line modeling and the on-line detection. The off-line stage calculates a sequence of anomaly index values using kNN on the historical ambient data and then determines the detection threshold. Afterward, the online stage calculates the anomaly index value of presently measured data by readopting kNN and compares it with the established threshold for detecting disturbances. To meet the real-time requirement, strategies for recursively calculating the distance metrics of kNN and for rapidly picking out the kth smallest metric are built. Case studies conducted on simulation data from the reduced equivalent model of the Great Britain power system and measurements from an actual power system in Europe demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Cell planning (CP) is the most important phase in the life cycle of a cellular system as it determines the operational expenditure, capital expenditure, as well as the long-term performance of the system. Therefore, it is not surprising that CP problems have been studied extensively for the past three decades for all four generations of cellular systems. However, the fact that small cells, a major component of future networks, are anticipated to be deployed in an impromptu fashion makes CP for future networks vis-a-vis 5G a conundrum. Furthermore, in emerging cellular systems that incorporate a variety of different cell sizes and types, heterogeneous networks (HetNets), energy efficiency, self-organizing network features, control and data plane split architectures (CDSA), massive multiple input multiple out (MIMO), coordinated multipoint (CoMP), cloud radio access network, and millimetre-wave-based cells plus the need to support Internet of Things (IoT) and device-to-device (D2D) communication require a major paradigm shift in the way cellular networks have been planned in the past. The objective of this paper is to characterize this paradigm shift by concisely reviewing past developments, analyzing the state-of-the-art challenges, and identifying future trends, challenges, and opportunities in CP in the wake of 5G. More specifically, in this paper, we investigate the problem of planning future cellular networks in detail. To this end, we first provide a brief tutorial on the CP process to identify the peculiarities that make CP one of the most challenging problems in wireless communications. This tutorial is followed by a concise recap of past research in CP. We then review key findings from recent studies that have attempted to address the aforementioned challenges in planning emerging networks. Finally, we discuss the range of technical factors that need to be taken into account while planning future networks and the promising research directions that necessitate..."
  },
  {
    "year": "2017",
    "abstract": "Visible light communication (VLC) is regarded as a promising technology for indoor communications due to its safety, availability, and efficiency. By deploying multiple light-emitting diodes (LEDs) at the transmitter, high data rate can be achieved. On the other hand, the dimming control is necessary in VLC systems to meet the lighting requirements, and puts an additional constraint to the system design. Thus, providing required communication quality while preserving the maximum dimming control capability becomes the baseline design philosophy for VLC systems. In this paper, we focus on multi-user multiple-input multiple-output VLC systems and propose a joint beamforming and direct current bias design. The proposed scheme can be formulated as an optimization problem and finds the minimum dimming level subject to the transmission rate requirement as well as the lighting constraints. Semi-definite program method and concave-convex procedure are exploited to solve the optimization problem efficiently. The impacts of locations of LEDs and users to the dimming control are also studied with numerical results."
  },
  {
    "year": "2017",
    "abstract": "We consider a multiple-input multiple-output wiretap channel with one transmitter, one receiver, one cooperative jammer, and one eavesdropper whereby each node is equipped with multiple antennas. Eigenbeam-space division multiplexing (E-SDM) and cooperative jamming are known as techniques for improving secrecy rate. E-SDM enables the transmitter and the legitimate receiver to communicate with each other in parallel using channel state information known to them to maximize the legitimate receiver's mutual information. On the other hand, cooperative jamming is to jam only the eavesdropper to degrade the eavesdropper's mutual information. However, co-channel interference and residual interference from the cooperative jammer are caused by channel estimation errors, which degrade the legitimate receiver's mutual information. How these interferences affect the secrecy capacity has not been clarified. In this paper, we derive a lower bound on secrecy capacity using the legitimate receiver's mutual information in the presence of channel estimation errors and the mutual information of the eavesdropper who uses a minimum mean square error receiver. We analyze the effect of co-channel interference and residual interference from the cooperative jammer on the secrecy rate."
  },
  {
    "year": "2017",
    "abstract": "Quantitative risk assessment has recently been proposed to assess the impact of a new radio service allocation on incumbents. This paper demonstrates its viability by performing a risk-informed interference assessment in a recent U.S. case: the protection of meteorological satellite earth stations from interference by cellular mobile transmitters. We find that the hazard selected by policy makers (co-channel interference with the receiving antenna at 5° elevation) was not the most severe, and that their worst case approach overlooked more significant risks, notably adjacent band interference. We begin with an inventory of the performance hazards. We survey consequence metrics that quantify the severity of interference, and select the interference protection criteria defined in Recommendation ITU-R SA.1026-4. We then use Monte Carlo modeling to calculate probability distributions of resulting interference due to co-channel and adjacent band transmissions. We identify a co-channel exclusion distance that keeps interference risk below the SA.1026-4 criteria. We show that the binding constraint is not the ITU-R “long-term” interference mode (5° antenna elevation), but rather the “short-term” interference when the elevation is 13°. We give an extensive sensitivity analysis showing that the propagation modeling, and particularly the choice of clutter model, can have a significant effect on the results. We conclude that quantitative risk assessment yields useful insights for analyzing coexistence. Protection criteria that combine an interfering power level with statistical exceedance limits were essential to our analysis, and we recommend that policy makers adopt statistical service rules more widely to support future risk analysis. Our analysis was limited by the unavailability of baseline values for service metrics, and the lack of transparency in previous studies, notably ITU-R recommendations. We recommend that regulators encourage parties to provide baseline values an..."
  },
  {
    "year": "2017",
    "abstract": "Due to serious risks for network, security improvement has become an essential measure for next-generation network. To improve the security environment effectively, we propose a novel security service path (SSP) construction scheme based on reconfigurable mechanism in this paper. Initially, we present the concept of security service atomization and adaptiveness. Subsequently, considering different network security factors, a novel SSP selection method with corresponding model is established and performed to optimize the path. The results demonstrate that the proposed solution meets the security requirements and greatly improves the efficiency of network resources."
  },
  {
    "year": "2017",
    "abstract": "Elastic scaling and load balancing with efficient switch migration are critical to enable the elasticity of software-defined networking (SDN) controllers, but learning how to improve migration efficiency remains a difficult problem. To address this issue, a switch migration-based decision-making (SMDM) scheme is put forward that could be made aware of the load imbalance by a switch migration trigger metric; the migration efficiency model for this scheme is built to make a tradeoff between migration costs and the load balance rate. An efficiency-aware switch migration algorithm based on greedy method is designed to utilize the migration efficiency model and thus guide the choice of possible migration actions. We implement a proof of the scheme and present a numerical evaluation using Mininet emulator to demonstrate the effectiveness of our proposal."
  },
  {
    "year": "2017",
    "abstract": "For sparse code multiple access (SCMA) with traditional codebooks, the initial information of message passing algorithm (MPA) receiver is easily susceptible to noise and multipath fading, and the convergence reliability of the first detected user in each decision process is unsatisfactory. Driven by these problems, an optimized codebook design for SCMA is presented in this paper. In the proposed SCMA codebook design, we first use turbo trellis coded modulation technology to design a basic complex multi-dimension constellation, which can increase the minimum Euclidean distance. Then, phase rotation and coordinate interleaving are added on the constellation to increase diversity and coordinate product distance between any constellation points. Based on these, we propose a novel criterion to select the most appropriate permutation set, which can capture as large as the sum of distance between dimensions of interfering codewords multiplexed on each resource node and maximize the diversity over the set of the sums of distance between dimensions of interfering codewords multiplexed on all resource nodes. Benefiting from the proposed codebook design, the quality of initial information of MPA receiver on each resource node and the convergence reliability of the first detected user in each decision process will be improved. Simulation results show that the bit error rate performance of SCMA with the proposed codebooks outperforms SCMA with traditional codebooks, low-density signature, and orthogonal frequency division multiple access under the same load."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) have greatly contributed to human-associated technologies. The deployment of WSNs has transcended several paradigms. Two of the most significant features of WSNs are the intensity of deployment and the criticalness of the applications that they govern. The tradeoff between volume and cost requires justified investments for evaluating the multitudes of hardware and complementary software options. In underwater sensor networks (USNs), testing any technique is not only costly but also difficult in terms of full deployment. Therefore, evaluation prior to the actual procurement and setup of a WSN and USN is an extremely important step. The spectrum of performance analysis tools encompassing the test-bed, analysis, and simulation has been able to provide the prerequisites that these evaluations require. Simulations have proven to be an extensively used tool for analysis in the computer network field. A number of simulation tools have been developed for wired/wireless radio networks. However, each simulation tool has several restrictions when extended to the analysis of WSNs. These restrictions are largely attributed to the unique nature of each WSN within a designated area of research. In addition, these tools cannot be used for underwater environments with an acoustic communication medium, because there is a wide range of differences between radio and acoustic communications. The primary purpose of this paper is to present, propose, and develop a discrete event simulation designed specifically for mobile data gathering in WSNs. In addition, this simulator has the ability to simulate 2-D USNs. This simulator has been tailored to cater to both mobile and static data gathering techniques for both topologies, which are either dense or light. The results obtained using this simulator have shown an evolving efficient simulator for both WSNs and USNs. The developed simulator has been extensively tested in terms of its validity and scope of govern..."
  },
  {
    "year": "2017",
    "abstract": "Eye movements have been proven the most frequent of all human activities; therefore, research on a relationship between different eye movement patterns become a hotspot in human-computer interface fields. The motivation of this paper is to develop a reading auxiliary apparatus by measuring and analyzing the electrooculography signals. We first describe the saccade detection algorithm based on the wavelet packet decomposition and the derivation blink detection algorithm. Furthermore, consecutive blinks were used to control the system's working state and a magnifier, whose position is adjusted according to the results of saccade detection. Experiential results on six participants show that recognition accuracy ratio (F1 score) is 90.096%, which reveal that the proposed system has a good recognition performance on reading activity detection and analysis."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the algorithmic design, experimental evaluation, and very large scale of integration (VLSI) implementation of Geosphere, a depth-first sphere decoder able to provide the exact maximum-likelihood solution in dense (e.g., 64) and very dense (e.g., 256, 1024) quadrature amplitude modulation (QAM) constellations by means of a geometrically inspired enumeration. In general, linear detection methods can be highly effective when the multiple input, multiple output (MIMO) channel is well-conditioned. However, this is not the case when the size of the MIMO system increases and the number of transmit antennas approaches the number of the receive antennas. Via our wireless open access research platform (WARP) testbed implementation, we gather indoor channel traces in order to evaluate the performance gains of sphere detection against zero-forcing and minimum mean-square errors (MMSE) in an actual indoor environment. We show that Geosphere can nearly linearly scale performance with the number of user antennas; in 4 × 4 multi-user MIMO for 256-QAM modulation at 30-dB SNR, there is a 1.7 × gain over MMSE and 2.4 × over zero-forcing and a 14% and 22% respective gain in 2 × 2 systems. In addition, by using a new node labeling-based enumeration technique, low-complexity integer arithmetic, and fine-grained clock gating, we implement for up to 1024-QAM constellations and compare in terms of area, delay, power characteristics, the Geosphere VLSI architecture, and the best-known best-scalable exact ML sphere decoder. Results show that Geosphere is twice as area-efficient and 70% more energy efficient in 1024-QAM. Even for 16-QAM, Geosphere is 13% more area-efficient than the best-known implementation for 16-QAM, and it is at least 80% more area-efficient than the state-of-the-art K-best detectors for 64-QAM."
  },
  {
    "year": "2017",
    "abstract": "ISO 26262, an automotive functional safety standard, ensures the functional safety of automotive systems by providing requirements and processes to govern the software lifecycle. Each functional system must be classified in terms of safety goals, risks, and automotive safety integrity level (ASIL: A, B, C, and D), with ASIL D, denoting the most stringent safety level. As the risk of the system increases, the ASIL level increases, and the standard highly recommends more stringent methods to ensure safety. ISO 26262 highly recommends that ASIL C and D-classified systems utilize semiformal and formal verification among other techniques to verify software unit design and implementation. In this paper, we compare industrial design verification steps of WatchDog Manager in an effort to be ASIL B-compliant with a proposed nondisruptive methodology to semiformally verify WatchDog Manager UML design via an automated formal framework backbone. This semiformal verification framework will allow automotive software to comply with ASILs C and D formal and semiformal unit design and implementation verification recommended guidelines in ISO 26262. Semiformal UML finite-state machines are automatically compiled into formal notations based on the Symbolic Analysis Laboratory formal notation. We capture requirements in the UML design and compile them automatically into theorems. Model checkers are run against the compiled formal model and theorems to detect counterexamples that violate the requirements in the UML model. We show that semi-formal verification of the design allows us to uncover issues that were detected in testing and production stages of ASIL B-compliant Watchdog Manager existing implementation."
  },
  {
    "year": "2017",
    "abstract": "In view of the facts that traditional traffic models are less effective in describing the new mobile internet applications and that the mobile user service behavior among regions with different levels of economic development are always different, a new modeling methodology of user service behavior specifically for mobile internet applications is proposed in this paper. Based on the crowdsourcing measurement data of the service behavior collected through massive end users in live mobile networks of China, the properties of three typical mobile internet services in three typical geographical regions are analyzed and compared with each other, by utilizing the proposed modeling methodology. And the relationships between some key properties of service behavior are analyzed with the maximal information coefficient method and the Pearson correlation coefficient method. The key parameters, differences, and internal relations among these services in typical geological regions of China are then identified. It provides a solid foundation for wireless product design, network planning, and optimization of mobile Internet services-oriented networks specifically in China, and is also a valuable reference for other countries of the similar situation."
  },
  {
    "year": "2017",
    "abstract": "We propose a method for improving the classification performance of a classifier, termed the classifier graph, by embedding it in a graph of classifiers. Our graph-based method has the advantage of enabling delicate classification from different levels of interpretation and abstraction. For the problem that thresholds corresponding to different classifiers are correlated and thus have mutual effects on the final performance, we provide a generalization of the receiver operator characteristic curve that properly tunes them jointly to obtain optimal performance. This method is successfully applied to the detection of noise artifacts (glitches) in the gravitational-wave data. We thus obtain an improvement up to 10% on the classification performance compared with that of a single classifier. The methods of this paper provide an effective way to improve the classification performance with multiple classifiers."
  },
  {
    "year": "2017",
    "abstract": "To address the vast variety of user requirements, applications, and channel conditions, flexibility support is strongly highlighted for 5G radio access technologies (RATs). For this purpose, usage of multiple orthogonal frequency division multiplexing (OFDM) numerologies, i.e., different parameterization of OFDM-based subframes, within the same frame has been proposed in the third-generation partnership project discussions for 5G new radio. This concept will likely meet the current expectations in multiple service requirements to some extent. However, since the quantity of wireless devices, applications, and heterogeneity of user requirements will keep increasing toward the next decade, the sufficiency of the aforementioned flexibility consideration remains quite disputable for future services. Therefore, novel RATs facilitating much more flexibility are needed to address various technical challenges, e.g., power efficiency, massive connectivity, latency, spectral efficiency, robustness against channel dispersions, and so on. In this paper, we discuss the potential directions to achieve further flexibility in RATs beyond 5G, such as future releases of 5G and 6G. In this context, a framework for developing flexible waveform, numerology, and frame design strategies is proposed along with sample methods. We also discuss their potential role to handle various upper-level system issues, including the ones in orthogonal and nonorthogonal multiple accessing schemes and cellular networks. By doing so, we aim to contribute to the future vision of designing flexible RATs and to point out the possible research gaps in the related fields."
  },
  {
    "year": "2017",
    "abstract": "Forward error correction (FEC) codes followed by an interleaver play a significant role in improving the error performance of the digital systems by counteracting random and burst errors. In most of the applications, interleaver and FEC code parameters are known at the receiver to successfully de-interleave and decode the information bits. However, in certain non-cooperative applications, only partial information about the code and interleaver parameters is known. Furthermore, in cognitive radio applications, an intelligent receiver should adapt itself to the transmission parameters. Hence, there is a need to blindly estimate the FEC code and interleaver parameters in the mentioned applications from the received data stream with the availability of partial knowledge about the transmission parameters at the receiver. In this paper, a blind recognition of convolutional and helical interleaver parameters is carried out using innovative algorithms for unsynchronized, convolutionally encoded data in the presence of bit errors. In addition, the proposed algorithms also estimate the starting bit position for achieving proper synchronization. In a nutshell, it has been observed from the numerical results that the interleaver parameters have been estimated successfully over erroneous channel conditions from the proposed algorithms. Finally, the performances of the proposed algorithms for both the interleavers considering various bit error rate values have also been analyzed."
  },
  {
    "year": "2017",
    "abstract": "LTE usage is rapidly increasing with the increased demand for high data rate services. LTE cells with high load would be insufficient to handle all users' traffic. This may cause blocking for some users or degrade the quality for others. Several techniques are adopted to increase the capacity of LTE cells. This paper will address specifically the use of some users as relays to others in order to increase the capacity of a specific cell. The result is a two-hop topology network with some users connected directly to the base station (BS) and others using some of the already connected users as relays to access the BS. Different techniques could be used to configure the users in such a topology. The paper proposes a new algorithm for relay selection in a multi-cell scenario based on K-means and selection strategy."
  },
  {
    "year": "2017",
    "abstract": "The individual-activation-factor memory proportionate affine projection algorithm (IAF-MPAPA) provides a good solution for echo cancelation. However, the IAF-MPAPA with fixed regularization factor requires a tradeoff between fast convergence rate and low steady-state misalignment. In this paper, the mathematical relationship between the regularization factor and the steady-state mean square error (MSE) of the IAF-MPAPA was deduced. The mathematical formula of the steady-state MSE indicates that it is inversely proportional to the value of regularization factor. Then, inspirited by the evolutionary method, the IAF-MPAPA with evolving regularization (ERIAF-MPAPA) was proposed. The ERIAF-MPAPA increases or decreases the regularization factor by comparing the power of output error with a threshold which contains the information of the steady-state MSE. For highly sparse impulse responses, simulation results demonstrate that the proposed ERIAF-MPAPA offers better convergence performance than other proportionate-type APAs in terms of convergence rate and steady-state misalignment."
  },
  {
    "year": "2017",
    "abstract": "Accelerated degradation testing (ADT) is commonly used to obtain degradation data of products by exerting loads over usage conditions. Such data can be used for estimating component lifetime and reliability under usage conditions. The design of ADT entails to establish a model of the degradation process and define the test plan to satisfy given criteria under the constraint of limited test resources. Bayesian optimal design is a method of decision theory under uncertainty, which uses historical data and expert information to find the optimal test plan. Different expected utility functions can be selected as objectives. This paper presents a method for Bayesian optimal design of ADT, based on the inverse Gaussian process and considering three objectives for the optimization: relative entropy, quadratic loss function, and Bayesian D-optimality. The Markov chain Monte Carlo and the surface fitting methods are used to obtain the optimal plan. By sensitivity analysis and a proposed efficiency factor, the Bayesian D-optimality is identified as the most robust and appropriate objective for Bayesian optimization of ADT."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an integrity-oriented content offloading (ICO) problem with variable modulation and coding schemes is proposed for relay-assisted vehicular sensor network. To accurately describe the link duration properties, a finite-state Markov chain-based model is built by jointly considering the mobility and radio propagation characteristics. Considering the ICO problem is NP-hard, our solution divides it into two offloading sub-problems with direct link and relay-assisted path, respectively. These two sub-problems are solved heuristically, and the corresponding results are combined to achieve a near-optimal result as the ICO scheme. While the analytical model is validated by Monte Carlo simulations and chi-square goodness fit test, the performance of our proposed ICO scheme is verified through simulations and comparisons, showing that our ICO solution can reduce the integral content offloading time compared with two other selected schemes and an upper performance bound."
  },
  {
    "year": "2017",
    "abstract": "Medical researchers have always been interested in heart rate (HR) and heart rate variability (HRV) analysis. However, nowadays, investigators from a variety of other fields are also probing the subject. Recent advancements in non-contact HR and HRV measurement techniques will likely further boost interest in emotional estimation through HRV. Such measurement methods involve the extraction of the photoplethysmography (PPG) signal from the human's face through a camera. The latest approaches apply independent component analysis (ICA) on the color channels of video recordings to extract a PPG signal. Other investigated methods rely on Eulerian video magnification (EVM) to detect subtle changes in skin color associated with the PPG. To the best of our knowledge, EVM has not been successfully employed to extract HRV features from a video of a human face. In this paper, we present a comparison between our two approaches, one which is based on the ICA and the other is based on EVM. Final results show that the proposed ICA-based method yields better results when it comes to the high frequency (HF) and low frequency over high-frequency (LF/HF) HRV parameters [mean absolute error (MAE) of 0.57 and 0.419] when compared with the EVM-based method (MAE 0.76 and 1.69); however, the second method showed better MAE results for low frequency (LF) and higher correlation with the ground truth. Also our proposed ICA method showed better results in general by improving HF estimates, but the EVM-based method might be more appropriate when motion is involved or when the HF component is not important."
  },
  {
    "year": "2017",
    "abstract": "Increasing trend of peering at Internet exchange points (IXPs) provides a topological and network management advantage to the Internet service providers (ISPs) that is otherwise not possible through individual peering arrangements with their neighboring domains. ISPs keep analyzing potential advantages to peer at geographically diversified IXPs. Increasing degree of multihoming in ISPs requires extensive coordination among ISPs in different roles (access and transit), for mutual benefit. We propose a novel approach to build a conducive inter-networking ambiance for future data centric applications. Our approach exploits edge multiplicity of transit ISPs present across different IXPs to leverage a cross layer coordination between network stack at access ISP subscribers and the network infrastructure. Software defined networking provides a useful apparatus to control IXP fabric and also empowers our multipath forwarding strategy for an optimal network resource utilization in the inter-domain configuration. Contributions of this paper include the derivation of abstracted overlay graph from an IXP centric inter-domain connectivity model. This graph is used to provide multipath forwarding for increased reliability and throughput over abstracted graph. Adaptive cross layer coordination increases the efficiency of the proposed framework and provides an online mechanism of forwarding the traffic across the domains. We have observed as high as 54% increase in throughput using proposed scheme as compared with single path routing and forwarding strategy currently employed at the Internet backbone."
  },
  {
    "year": "2017",
    "abstract": "Heterogeneous networks (HetNets) consisting of macrocells overlaid with small cells (e.g. femtocell, picocell, microcell, and relay) are conceived as an appealing technology to cope with the explosive growth of service traffic in future cellular networks. However, the backhaul limitation has become a bottleneck in HetNets, which affects the network performance and users' quality of experience. Wireless edge caching that caches popular contents at the network edge (e.g., base stations (BSs)) can effectively unblock the bottleneck and further unleash the potential of HetNets. In this paper, considering a cache-enabled two-tier HetNet, we resort to the stochastic geometry theory to model and analyze the energy efficiency performance of the HetNet with closed-access policy under cochannel and orthogonal channel deployment scenarios. Specifically, the exact closed-form expressions of outage probability, throughput and energy efficiency are derived, respectively. Numerical results show that the larger small-cell local cache capability may not always lead to higher network energy efficiency due to the caching power cost. The results also show that with a given cache capacity for small cells, there exists an optimal small BS density that maximizes the network energy efficiency."
  },
  {
    "year": "2017",
    "abstract": "Gesture recognition aims to recognize meaningful movements of human bodies, and is of utmost importance in intelligent human-computer/robot interactions. In this paper, we present a multimodal gesture recognition method based on 3-D convolution and convolutional long-short-term-memory (LSTM) networks. The proposed method first learns short-term spatiotemporal features of gestures through the 3-D convolutional neural network, and then learns long-term spatiotemporal features by convolutional LSTM networks based on the extracted short-term spatiotemporal features. In addition, fine-tuning among multimodal data is evaluated, and we find that it can be considered as an optional skill to prevent overfitting when no pre-trained models exist. The proposed method is verified on the ChaLearn LAP large-scale isolated gesture data set (IsoGD) and the Sheffield Kinect gesture (SKIG) data set. The results show that our proposed method can obtain the state-of-the-art recognition accuracy (51.02% on the validation set of IsoGD and 98.89% on SKIG)."
  },
  {
    "year": "2017",
    "abstract": "As a promising candidate non-orthogonal multiple access scheme for the fifth generation (5G) wireless communication system, pattern division multiple access (PDMA) has received considerable attention recently. Using pattern matrix (GPDMA[2,3], as an example, is used in this paper), PDMA directly maps the information bits of different users to radio resources, such as code, power, time and frequency, and space resource. PDMA can meet the requirements of massive connectivity and higher spectral efficiency for the 5G mobile network. In order to further improve transmission reliability and enhance the coverage, an uplink cooperative PDMA (Co-PDMA) scheme with half-duplex decode and forward relay is proposed. The analytical expressions of outage probability (OP) and sum data rate are derived to characterize the performance of the proposed scheme. The results show that the proposed Co-PDMA scheme achieves superior outage performance, with gains of 8 and 12 dB over the nonCo-PDMA and cooperative orthogonal multiple access (Co-OMA), respectively, @ OP = 0.1. Besides, the scheme is found to outperform two other schemes in terms of higher sum data rate and achieve an almost maximum 50% gain over Co-OMA when every user has the same target data rate."
  },
  {
    "year": "2017",
    "abstract": "Emotion-aware computing can recognize, interpret, process, and simulate human affects. These programs in this area are compute-intensive applications, so they need to be executed in parallel. Loops usually have regular structures and programs spend significant amounts of time executing them, and thus loops are ideal candidates for exploiting the parallelism of sequential programs. However, it is difficult to decide which set of loops should be parallelized to improve program performance. The existing research is one-size-fits-all strategy and cannot guarantee to select profitable loops to be parallelized. This paper proposes a novel loop selection approach based on machine learning (ML-based) for selecting the profitable loops and paralleling them on multi-core by speculative multithreading (SpMT). It includes establishing sufficient training examples, building and applying prediction model to select profitable loops for speculative parallelization. Using the ML-based loop selection approach, an unseen emotion-aware sequential program can obtain a stable, much higher speedup than the one-size-fits-all approach. On Prophet, which is a generic SpMT processor to evaluate the performance of multithreaded programs, the novel loop selection approach is evaluated and reaches an average speedup of 1.87 on a 4-core processor. Experiment results show that the ML-based approach can obtain a significant increase in speedup, and Olden benchmarks deliver a better performance improvement of 6.70% on a 4-core than the one-size-fits-all approach."
  },
  {
    "year": "2017",
    "abstract": "The futuristic Internet paradigm, named data networking (NDN), was recently introduced to solve the severe issues of current Internet architecture, such as complex usage, poor resource utilization, inefficient mapping, scalability, location dependence, and so on. Communication in NDN is based on content names decoupling from their locations. NDN also provides strong built-in functionalities, like multi-path routing, security primitives, flow balance mechanisms, and in-networking caching. Similarly, NDN-based mobile ad hoc networks are highly dynamic in nature whereby the participating nodes have experienced highly challengeable environments and constraints, such as channel fluctuations, intermittent connectivity, and low battery power. In this environment, if a node has limited residual energy, after sending a few packets, it will die soon. Furthermore, all of its pending request entries are also destroyed, which further exacerbates the communication process. To cope with this problem, we have proposed a novel protocol called the on-demand energy-based forwarding strategy (OEFS) that takes the residual energies of the nodes into account during the entire communication process. For the performance evaluations, we have used NDNSIM, which is specially designed for NDN-based networks. The simulation results show that the our OEFS outperform the existing state-of-the-art protocol in terms of content download time, interest retransmissions, the total number of Interest propagation, and data redundancy in the network. We also find the effect of OEFS on the energy threshold and show that OEFS enables mobile nodes to consume less amount of energy."
  },
  {
    "year": "2017",
    "abstract": "Massive multiple-input multiple-output (MIMO) is a potential candidate key technology for the 5G of wireless communication systems. In research to date, different power loss and shadowing effects on different antenna elements across the large arrays have been neglected. In this paper, based on an idealized propagation model, a new large scale attenuation (LSA) model is proposed, by which the large scale losses (path loss and shadowing effect) over the antenna array can be considered when establishing a massive MIMO channel model. By using this model, the spectral efficiency (in terms of bits/s/Hz sum-rate) of the maximum ratio combining (MRC) detector is derived for the uplink. The spectral efficiency performance of the zero forcing (ZF) detector also can be derived in the same manner. It can be found that the sum-rate performance (MRC and ZF) of our proposed channel model (assuming independent shadowing on all elements of the array) exceeds that of the conventional model (where the LSA effect is not included). Based upon our theoretical and simulation analysis, we have found that the spectral efficiency gap is mainly from the mean value of different shadowing effects across different elements, and the different path losses experienced by different antenna elements provide negligible contribution. This LSA model and the derived performance results could be beneficial and informative for the research, design and evaluation of the next generation of wireless communication system employing a massive MIMO configuration."
  },
  {
    "year": "2017",
    "abstract": "Smart cities aim to improve the quality of urban services and their energy efficiency by utilizing information and communication technologies. In such context, drones can be utilized to support various services, such as traffic monitoring, search/rescue, and surveillance, by communicating with many different smart objects like sensors. Securing such communications is crucial to making correct decisions and requires efficient cryptographic protocols. However, the design of such protocols must consider: 1) the mobility and the limited battery of drones and 2) the constrained resources of smart objects. In this paper, a suite of cryptographic protocols is presented to deal with three different communication scenarios: one-to-one, one-to-many, and many-to-one. For one-to-one, we propose an efficient Certificateless Signcryption Tag Key Encapsulation Mechanism (eCLSC-TKEM) that supports authenticated key agreement, non-repudiation, and user revocation. eCLSC-TKEM reduces the time required to establish a shared key between a drone and a smart object by minimizing the computational overhead at the smart object. For one-to-many, we propose a Certificateless Multi-Recipient Encryption Scheme (CL-MRES) by which a drone can efficiently send privacy-sensitive data to multiple smart objects. For many-to-one, we present a Certificateless Data Aggregation (CLDA) protocol, which allows drones to efficiently collect data from hundreds of smart objects. Also, for efficiency, we propose a dual channel strategy that allows many smart objects to concurrently execute our protocols. We evaluate eCLSC-TKEM via a smart parking management test-bed. Also, we have implemented CL-MRES and CLDA on a board with a graphics processing unit (GPU) and show their GPU-accelerated performance."
  },
  {
    "year": "2017",
    "abstract": "Burning state directly determines the clinker quality index in the rotary kiln sintering process. A simulated feedback mechanism-based rotary kiln burning state cognition intelligence method and a calculating model are explored for the purpose of imitating the human cognition process with repeated comparison and inference. The flame image feature space is optimized progressively using the evaluation of uncertain cognition results with different values of cognition demand to realize the simulated feedback cognition mode from global to local. First, the simulated feedback mechanism-based rotary kiln burning state cognition intelligence method with the coupling operation of the training layer and cognition decision layer is proposed, and the framework of the model is described. Second, the evaluation index system of uncertain cognition results based on the bag of words model, latent semantic analysis method, and entropy theory is constructed. Third, the simulated feedback mechanism based on the evaluation of uncertain cognitive results is established, and a concrete calculation model is given. Fourth, the simulated feedback mechanism-based rotary kiln burning state cognition intelligence system is designed, and the relevant cognition intelligence algorithm is provided. Finally, a simulation experiment is carried out with the collected burning zone flame image of a rotary kiln. An average recognition accuracy of 92.32% is achieved with a minor standard deviation in accuracy. The experimental results show that our method is effective and outperforms other open-loop recognition methods with the global configuration feature of flame image."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the multicast capacity for vehicular ad hoc networks with directional antennas and the end-to-end delay constraint. We consider a torus of unit area with n vehicles (nodes), there are nsmulticast sessions and each session contains one source vehicle which is associated with p destinations. We study the 2D and 1D random walk mobility models with two different time scales, i.e., fast and slow mobility. Given a delay constraint D and assuming that each vehicle is equipped with a directional antenna, we obtain the multicast capacity of the two mobility models with two different time scales in the order of magnitude, respectively. We then characterize the impact of the network parameters (i.e., the endto-end delay constraint D, the beamwidth of directional antenna 8, and the number of destinations p in each session) on the multicast capacity. Moreover, we find that the unicast capacity can be considered as a special case of our multicast results when the beamwidth of directional antenna 8 tends to 2π and the number of destinations p tends to 1 in the sense of probability."
  },
  {
    "year": "2017",
    "abstract": "Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions."
  },
  {
    "year": "2017",
    "abstract": "Multiple-input multiple-output (MIMO) radar has received much attention due to its potentials in offering improved performance for target detection and parameter estimation. It has been shown that the performance of direction finding techniques can be considerably enhanced in MIMO radar, since an extended virtual array can be employed. In general, the performance gain is achieved by assuming that both the transmitter and receiver are well calibrated without uncertainties. However, in practice, both the transmitter and receiver may suffer from various array imperfections such as mutual coupling. Hence, the problem of direction finding in MIMO radar with unknown mutual coupling is investigated in this paper. Computationally efficient algorithms are developed to estimate the directions-of-arrival by exploiting the structure of mutual coupling matrix of the transmitter and receiver equipped with uniform linear arrays. Moreover, it is shown that the proposed methods can be applied to scenarios in which the transmitter or receiver has other imperfections, for example, sensor position perturbations or gain/phase mismatches. Simulation results demonstrate that the proposed methods are able to effectively eliminate the negative influence of unknown mutual coupling on direction finding and offer improved performance over the existing methods."
  },
  {
    "year": "2017",
    "abstract": "The aim of this paper is to present results on output power level distributions of 4G user equipment (UE) using data applications based on a very large number of samples collected over seven days in a long-term evolution (LTE) operating network. The output power data have been obtained through network-based measurements conducted for about 7000 UE connected to 41 LTE radio base stations located in rural, suburban, urban, and indoor environments in Sweden. More than 300 000 power samples were collected. In rural environments, the 95th percentile time-averaged output power values were found to be 2.2% of the maximum available power for LTE UE, while the corresponding values were less than 1% in other environments. The mean output powers in all the environments were found to be less than 1% of the maximum available output power. These values are in line with results obtained for 3G UE despite an almost tenfold increase in the achievable peak data throughput. The findings show that knowledge on realistic power levels is important for accurate assessments of the radio frequency electromagnetic field exposure from mobile communication equipment."
  },
  {
    "year": "2017",
    "abstract": "Many real-world applications, such as bioinformatics, data mining, pattern recognition, and social network analysis, benefit from efficient solutions for the graph similarity search problem. Existing methods have limited scalability when they handle the large graph databases, for example, those with millions or billions of graphs that cannot fit in main memory. In this paper, we study the problem of graph similarity search under the graph edit distance constraint in external memory. We present an efficient framework for arbitrary q-gram-based representations of a graph. Specifically, we propose a q-gram matrix index stored in hybrid layout in external memory to achieve efficient query processing, by converting the q-gram counting filter into a sparse matrix-vector multiplication problem. Furthermore, we also boost the query performance by transforming the global filter to a 2-D query rectangle, which allows us to perform a query in a reduced region, significantly reducing the number of query I/Os in practice. Extensive experiments on real data sets confirm that 1) our method can compete with the state-of-the-art in-memory methods in index size and filtering ability, and outperform them on scalability of coping with the PubChem data set including 25 million chemical structure graphs and 2) compared with the popular q-gram-based external inverted index, our external index structure needs much fewer number of query I/Os on the PubChem data set."
  },
  {
    "year": "2017",
    "abstract": "Considering the internal and external disturbances in wind energy conversion systems, a predictive active disturbance rejection control (PADRC) strategy for a direct-driven permanent magnet synchronous generator (PMSG)-based wind energy conversion system, is proposed to maximize the wind power extraction in this paper. First, the proposed PADRC method can successfully deal with the effects of the uncertainties in the internal dynamics, modeling error, external forces and the variety of wind speeds, since it inherits the merits of active disturbance rejection control (ADRC). Second, the introduction of Smith Predictor can overcome the time delay in wind turbine system to guarantee the maximum power tracking performance for different wind speeds. Finally, simulation studies are conducted to evaluate power tracking performances of the proposed control strategy. It is shown that the proposed PADRC strategy exhibits significant improvements in both maximum power tracking performance and anti-disturbance ability compared with the traditional ADRC approach."
  },
  {
    "year": "2017",
    "abstract": "Full-duplex (FD) has emerged as a new communication paradigm with the potential advantage of enhancing the capacity of the wireless communication systems. In this paper, we consider an FD relay-enhanced cellular network, wherein the residual self-interference, the uplink-downlink interference, as well as the relay-access-link interference are the vital restrictions to network performance. To this end, we investigate power control design for the FD relay-enhanced cellular networks, so as to maximize the system spectral efficiency while fulfilling the quality of service (QoS) requirements of both the uplink and downlink user equipments (UEs). We characterize the properties of the optimal transmit power allocation, and propose a power control algorithm based on signomial programming to coordinate the transmit power of the uplink UE, base station, and relay stations to mitigate the interference. Meanwhile, we also derive the closed-form optimal transmit power allocation for the conventional half-duplex (HD) transmission mode. Moreover, we conduct extensive simulation experiments to study the network-level gain of the FD mode over the HD mode in the relay-enhanced cellular networks. Simulation results demonstrate that FD relaying outperforms HD relaying on improving the spectral and energy efficiency, as well as provisioning QoS guarantees for both the uplink and downlink users."
  },
  {
    "year": "2017",
    "abstract": "Energy harvesting enables the wireless devices to obtain energy for communication from the ambient environment. A general theme in prior works is to investigate the power scheduling policies to increase the utility ratio of the harvested energy, which arrives at random. One key assumption is the infinite data backlog, which means that as long as there is energy, there is data to transmit. However, in real systems, the buffer size is limited, and the arrival of data is also random. When the data backlog fills up the buffer, the subsequent arrival packets will be discarded directly. Therefore, we are motivated to jointly consider the data arrival and energy arrival processes in an energy harvesting communication system (EHCS). Specifically, we first derive the maximum average throughputr¯that EHCS can support with a simple online power scheduling scheme. Then, given a data arrival process whose average rateλ<r¯, we characterize the average data backlog for both constant and random data arrivals. Some further analyses are conducted to the variation of data backlog. To achieve a same packet drop rate, the buffer size needed for constant data arrivals is much smaller than that for random data arrivals, which can be seen from both our theoretical and simulation results. The analysis in this paper initiates a first step towards a more dynamic energy harvesting system, where data arrivals are of importance."
  },
  {
    "year": "2017",
    "abstract": "Online social databases are rich sources to retrieve appropriate information that is subsequently analyzed for forthcoming trends prediction. In this paper, we identify rising stars in cricket domain by employing machine learning techniques. More precisely, we predict rising stars from batting as well as from bowling realms. For this intent, the concepts of co-players, team, and opposite teams are incorporated and distinct features along with their mathematical formulations are presented. For classification purpose, generative and discriminative machine learning algorithms are employed, and two models from each category are evaluated. As a proof of applicability, the proposed approach is validated experimentally while analyzing the impact of individual features. Besides, model and categorywise assessment is also performed. Employing cross validation, we demonstrate high accuracy for rising star prediction that is both robust and statistically significant. Finally, ranking lists of top ten rising cricketers based on weighted average, performance evolution, and rising star scores are compared with the international cricket council rankings."
  },
  {
    "year": "2017",
    "abstract": "Heterogeneous network (HetNet), employing massive multiple-input multiple-output (MIMO), has been recognized as a promising technique to enhance network capacity, and to improve energy efficiency for the fifth generation of wireless communications. However, most existing schemes for coordinated beamforming (CoBF) for a massive MIMO HetNet unrealistically assume the availability of perfect channel state information (CSI) on one hand, and cascade of each antenna with a distinct radio-frequency chain in massive MIMO is neither power nor cost-efficient on the other hand. In this paper, we consider a massive MIMO-enabled HetNet framework, consisting of one macrocell base station (MBS) equipped with an analog beamformer, followed by a digital beamformer, and one femtocell base station (FBS) equipped with a digital beamformer. In the presence of Gaussian CSI errors, we propose a robust hybrid CoBF (HyCoBF) design, including an analog beamforming design for MBS, and a digital CoBF design for both MBS and FBS. To this end, an outage probability-constrained robust HyCoBF problem is formulated by minimizing the total transmit power. The analog beamforming mechanism at MBS is a newly devised low-complexity beam selection scheme by selecting analog beams from a discrete Fourier transform matrix codebook. Then, a conservative approximate CoBF solution is obtained via semidefinite relaxation and an extended Bernsteintype inequality. Furthermore, a distributed implementation for the obtained CoBF solution using alternating direction method of multipliers is proposed. Finally, numerical simulations are provided to demonstrate the efficacy of the proposed robust HyCoBF algorithm."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate secure simultaneous wireless information and power transfer (SWIPT) in a two-tier downlink heterogeneous network (HetNet), wherein the ambient interference signals are exploited for both secure communications and wireless energy harvesting. We assume one macrocell base station (MBS) and several femtocell base stations (FBSs) simultaneously send information to their macrocell users (MUs) and femtocell users, respectively. Meanwhile, the FBSs also transfer energy to some energy receivers, who act as the potential eavesdroppers and are able to wiretap the confidential messages to one MU via the cross-tier interference links. Exploiting interference in the considered HetNet, we jointly optimize the beamforming vectors and artificial noise of the MBS and the FBSs to maximize the secrecy rate of the eavesdropped MU under the quality-of-service, energy harvesting, and transmit power constraints at relevant receivers/transmitters. In particular, we first investigate the ideal case with perfect eavesdropper's channel state information (ECSI) and the optimization problem turns out to be nonconvex. By using the tools of semidefinite relaxation (SDR) and one-dimensional line search, we successfully transfer the original problem into a more tractable two-stage problem to obtain the optimal solution. Furthermore, we extend our study to the imperfect ECSI case, where the worst-case based solution is obtained with the aid of SDR and successive convex approximation. Simulation results demonstrate the effectiveness of the proposed algorithms and also bring useful insights into the design of secure SWIPT in the presence of interference."
  },
  {
    "year": "2017",
    "abstract": "In the recent years, the user activities over online social networks (OSNs) have increased tremendously. A large number of users share information across the different social networking platforms. The information across the OSNs is easy to access, and thus, can be easily used by the fraudulent users for misleading the entire community. Such fraudulent users are termed anomalies. In this paper, a problem of cross-platform anomalies is considered, which possesses different behaviors by an individual with different users across the multiple OSNs. The variation in the behavior and activity makes it difficult to identify such anomalies. A solution to this problem is proposed on the basis of cognitive tokens, which provide an intelligent sensing model for anomalies detection (ISMA) by deliberately inducing faulty data to attract the anomalous users. A common login system for different OSNs is also suggested as a part of collaborative anomaly identification across different OSNs. A fair play point approach is used for the determination of anomalies. Both simulations and email-based real data sets are used to measure the performance of the proposed approach. Furthermore, as an example of implementation, a case study is presented for anomaly detection in Internet of Things. The proposed approach is able to provide the highest accuracy at the rate of 99.2%; this is 25.1% higher as compared with the SVM-RBF and sigmoid approach, and 22% higher than that of the k-nearest neighbor approach. Furthermore, the proposed ISMA also caused less error in detecting the anomalies, which were within the range of 0.1% to 2.8%. The error in identification is reduced up to 96.6% in comparison with the SVM and k-nearest neighbor approaches. The gains in comparative results validate the efficiency of the ISMA in identification and classification of anomalies in cross-platform OSNs."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a destination-assisted jamming and beamforming (DAJB) scheme for physical layer security in a one-way cooperative amplify-and-forward (AF) relay communication system. The system model consists of one source, one destination, one eavesdropper, and N relay nodes, with the individual power constraint of each relay node and the destination-assisted jamming node as well as unknown instantaneous channel state information (CSI) of the eavesdropper. Due to the half-duplex constraint of the relay nodes, there are two phases in our proposed DAJB scheme. In the first phase, the source node broadcasts information signal and all N relay nodes listen simultaneously. In the meantime, the destination node transmits the jamming signal to confuse the potential eavesdropper. In the second phase, all N relay nodes amplify and forward the received signals, covered by the artificial noise (AN), to the destination using the distributed beamforming technology. The optimal beamformer weights and power allocation are obtained by solving the second-order convex cone programming (SOCP) together with a linear programming (LP) problem. Furthermore, the performance of the DAJB scheme is analyzed in terms of the achievable secrecy rate. Compared with the scheme that selects a relay node as the jammer, we obtain larger power gain to achieve higher secrecy rates. Finally, the simulation results verify that the DAJB scheme greatly improves the secrecy rate of a one-way cooperative AF relay communication system."
  },
  {
    "year": "2017",
    "abstract": "Whispered speech, as an alternative speaking style for normal phonated (non-whispered) speech, has received little attention in speech emotion recognition. Currently, speech emotion recognition systems are exclusively designed to process normal phonated speech and can result in significantly degraded performance on whispered speech because of the fundamental differences between normal phonated speech and whispered speech in vocal excitation and vocal tract function. This study, motivated by the recent successes of feature transfer learning, sheds some light on this topic by proposing three feature transfer learning methods based on denoising autoencoders, shared-hidden-layer autoencoders, and extreme learning machines autoencoders. Without the availability of labeled whispered speech data in the training phase, in turn, the three proposed methods can help modern emotion recognition models trained on normal phonated speech to reliably handle also whispered speech. Throughout extensive experiments on the Geneva Whispered Emotion Corpus and the Berlin Emotional Speech Database, we compare our methods to alternative methods reported to perform well for a wide range of speech emotion recognition tasks and find that the proposed methods provide significant superior performance on both normal phonated and whispered speech."
  },
  {
    "year": "2017",
    "abstract": "Concentrating on the influence of DDoS applied to ad hoc networks, we introduced three classic queue management algorithms: Drop-Tail, random early detection (RED), and random exponential marking (REM). We analyzed and compared the defensive abilities of these algorithms applied to ad hoc networks with NS2 under DDoS attack. The results showed that active queue management algorithms, such as REM and RED, exhibited stronger defensive abilities than the passive queue management algorithm Drop-Tail under medium- and small-scale DDoS attacks; however, under large-scale DDoS attack, all three algorithms exhibited insufficient defensive capabilities. This means that other defense schemes, such as network detection, must be integrated into security schemes to defeat DDoS attacks."
  },
  {
    "year": "2017",
    "abstract": "In vehicular networks, safety applications allow people to avoid hazardous situations based on the state of the vehicles in their proximity. Such proximity awareness is realized by allowing each vehicle to collect safety messages called beacons, which are periodically and locally broadcasted from its neighboring vehicles. Hence, the reliability of beacon transmissions is a crucial factor that makes safety applications effective in practice. Particularly, in respect of avoiding risky situations, lossy and scarce vehicular channel should be utilized primarily for reliable delivery of beacons from neighboring vehicles, which are more likely to cause dangerous situations such as collision. However, without consideration to such a requirement of safety applications, existing retransmission schemes treat every vehicles equally and are focusing on improving the retransmission performance in terms of loss recovery. In this paper, we therefore propose a new network coding-based repetition scheme called Context-Aware Network COded REpetition (CANCORE) for maximizing the effectiveness of safety applications. Using knowledge of contextual information (i.e., position, heading, and so on) of vehicles, CANCORE generates coded repetitions allowing more receivers to acquire beacons useful for avoiding impending dangerous situations. Our simulation study verified that CANCORE outperforms existing schemes in terms of its impact on the application-level performance (i.e., the accuracy of proximity awareness)."
  },
  {
    "year": "2017",
    "abstract": "To cope with the ongoing trend in data traffic asymmetry of uplink (UL) and downlink (DL) transmissions, bidirectional dynamic networks (BDNs) have been proposed to facilitate simultaneous UL and DL communications. Moreover, the large-scale distributed antenna system (L-DAS) is considered to improve the spectral efficiency (SE). Aiming at maximizing the SE in the BDN with the L-DAS, in this paper, we propose a novel distributed antenna (DA) clustering strategy named flexible antenna clustering (FAC) to allow each user to choose the most effective DAs. This also provides a low-complexity solution to solve the antenna clustering problem in the L-DAS. In FAC, the operation mode (UL or DL transmission) of the DAs can be flexibly changed, which is determined by the baseband processor units. By taking both the homogeneous and heterogeneous interferences into consideration, we propose two novel metrics for the user and DA selection orders. To the best of our knowledge, this is the first time that the user selection order is considered in solving the antenna clustering problem. Compared with the time division duplex system, our FAC strategy used in the BDN is verified to have improved efficiency in achieving better SE performance. Therefore, the BDN with the L-DAS is suitable in practical communication systems thanks to its SE gain. Based on these results, we further provide some specific suggestions for the practical network configuration."
  },
  {
    "year": "2017",
    "abstract": "The precise estimation of the motor parameter is essential to design the appropriate controller. The main goal of this paper is to estimate the parameters of permanent magnet dc (PMDC) motor used in a wheelchair, applying standard as well as a dynamic particle swarm optimization (PSO), ant colony optimization (ACO), and artificial bee colony (ABC) along with experimental methods. The electromechanical, mechanical, and electrical parameters, such as torque constant, back-emf constant, moment of inertia, viscous friction coefficient, armature inductance, and resistance are estimated using both the experimental and optimization methods. The motor is modeled in Matlab/Simulink R2015a using the estimated motor parameters and studied the performance with different loading conditions starting from no-load to full-load. The simulated results of motor performance with estimated parameters are compared with the experimental load test results. The results showed that the PMDC motor parameters estimated from dynamic PSO with varying inertia weight as well as ABC algorithm have comparatively very less speed and current error than standard PSO, dynamic PSO with constant inertia weight, and ACO algorithms. Furthermore, parameters from dynamic PSO with varying inertia weight showed speed as well as current error less than 0.5%, and the ABC algorithm shown current error slightly more than 0.5%. However, the analysis of variance tests shown no significant difference in current and speed performance with parameter estimated from ABC and dynamic PSO with varying inertia weight. Furthermore, ABC algorithm convergence is faster than dynamic PSO with varying inertia weight. But parameters estimated from dynamic PSO with varying inertia weight are precise and may be appropriate for the design of the motor controllers."
  },
  {
    "year": "2017",
    "abstract": "With the occurrence of Internet of Things (IoT) era, the proliferation of sensors coupled with the increasing usage of wireless spectrums especially the ISM band makes it difficult to deploy real-life IoT. Currently, the cognitive radio technology enables sensors transmit data packets over the licensed spectrum bands as well as the free ISM bands. The dynamic spectrum access technology enables secondary users (SUs) access wireless channel bands that are originally licensed to primary users. Due to the high dynamic of spectrum availability, it is challenging to design an efficient routing approach for SUs in cognitive sensor networks. We estimate the spectrum availability and spectrum quality from the view of both the global statistical spectrum usage and the local instant spectrum status, and then introduce novel routing metrics to consider the estimation. In our novel routing metrics, one retransmission is allowed to restrict the number of rerouting and then increase the routing performance. Then, the related two routing algorithms according to the proposed routing metrics are designed. Finally, our routing algorithms in extensive simulations are implemented to evaluate the routing performance, and we find that the proposed algorithms achieve a significant performance improvement compared with the reference algorithm."
  },
  {
    "year": "2017",
    "abstract": "In recent years, a new trend has come up, which is that of reading the digital Quran online. This text was revealed more than 1400 years ago in the Arabic language and has been protected from all possible ways of distortion until today. Unfortunately, driven by the desire to make profit or gain publicity, fraudsters have started modifying certain Quranic verses. These alterations are misleading many people who are thus deprived of the original and accurate message of the Holy Quran. This paper focuses on systematically analyzing and categorizing existing research related to preserving and verifying the content integrity of the Quran. This paper further assesses these existing studies in terms of their evaluation parameters and findings. We find that the existing studies can be classified according to their format and methods, i.e., the online formats in which the Quranic content is available, methods employed to protect the Quranic content from modification, and last methods of verification. This paper concludes with the issue of future challenges and their possible solutions."
  },
  {
    "year": "2017",
    "abstract": "Millimeter waves (MMWs), operating at 30-300 GHz band, are very promising to the next-generation 5G wireless communication systems, enabling data rates of multi Gbps per user. Photonic technology is increasingly considered to play a key role in a wide range of MMW devices, modules, and subsystems that are essential to successfully build next generation MMW-based 5G networks. This work considers the switching function of MMWs exploiting nonlinearity in photonic devices. In this paper, we perform a systematic investigation of the optimum operating conditions that enable an optical single sideband wavelength conversion, by exploiting the nonlinear effects in a semiconductor optical amplifier (SOA). This principle of switching carefully exploits SOA's four-wave mixing, cross-gain modulation in addition to self-phase modulation effects. The key parameters under investigation include the injection current, the wavelength spacing between the probe and the pump signals in addition to their respective powers. We experimentally determine the optimal operating conditions that maximize the sideband suppression ratio and simultaneously reduce the useless left sideband signal intensity, leading to a dispersion free transmission in optical fiber. Further, we experimentally demonstrate a photonic-based MMW switch of MMW signals having 30 GHz frequency and carrying 3 Gbaud/QPSK modulated signals. A 14-dB sideband suppression ratio of modulated signal is reported."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a coordinated framework of prepared data packet transmission in a transmission session. Automated guide vehicles (AGVs) with an onboard 1-km range APC transmitter are used to establish the network environment for testing the prepared packet transmission session. An evaluation technique of the dataflow through the network was carried out. The captured transmission parameters offer an inbound and outbound limit of dataflow through which the AGVs communicate with each other. The findings of this paper indicate that the ideal transmission rates at the frequency of 434 MHz and at a baud rate of 19200 bps was found to be 25 ms in between each 56-B data packets. The range of distance between the transmitter and the receiver was 0.5 to 970 m. The transmitter had a 1-km range limitation. As the applications for which the communication model was developed did not require long distances, the transmitter's range limitation was sufficient. Further tests validated these transmission session parameters values. The proposed techniques can be implemented as logistic and automation solutions in the manufacturing industry."
  },
  {
    "year": "2017",
    "abstract": "Virtual instruments is a program that implements functions of an instrument by software which could replace the work of real instruments to save resources. The functions of these sensor-based systems are limited and they commonly cannot manage related information, such as sensors and monitoring objects, due to special requirements. The procedure of development and integration often suffers from low efficiency because of non-standard technologies. To solve the aforementioned problems, an integrated system architecture based on complex virtual instruments (CVI) is proposed, which could not only extend the function of virtual instruments but also ease the development procedure of the system. By analyzing the characters of existing virtual instruments systems, this paper presents the data interaction standard, which has been applied by two IEEE standards, and the architecture, which consists of configuration subsystem, data collection simulation subsystem, Web service registration center, and so on. We also offer a light universal client which could dynamically load the DynamicLinkLibrary of different CVIs, in order to replace the complex integration procedure by scheduling different components. To valid the architecture, three existing systems are reconstructed by the proposed prototype subsystems. The result shows that the proposed architecture is efficient and feasible."
  },
  {
    "year": "2017",
    "abstract": "Time-reversal (TR) is a beamforming technique for wireless frequency-selective channels, which has received increasing attention due to its high energy efficiency and low computational complexity. In this paper, we present two contributions on TR beamforming for single-user indoor wideband MISO systems. First, we provide novel analyses of a baseband TR system using two commonly used indoor propagation channel models. We derive closed-form approximations for the inter-symbol interference (ISI) with these channel models in order to characterize the influence of propagation conditions (such as the power-delay profile, delay spread, and bandwidth) on TR performance metrics. In particular, we analyze spatial focusing and time compression performance of TR beamforming, and their impact on the bit error rate (BER). As a second contribution, we introduce an equalized TR (ETR) technique that mitigates the ISI of conventional TR. The proposed ETR utilizes a zero-forcing pre-equalizer at the transmitter in a cascade configuration with the TR pre-filter. Unlike previous approaches to ISI mitigation in TR systems, we derive theoretical performance bounds for ETR and show that it greatly enhances the BER performance of conventional TR with minimal impact to its beamforming capabilities. By means of numerical simulations, we verify our closed-form approximations and show that the proposed ETR technique outperforms conventional TR with respect to the BER under any SNR."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the interplay of cloud computing, fog computing, and Internet of Things (IoT) in control applications targeting the automation industry. In this context, a prototype is developed to explore the use of IoT devices that communicate with a cloud-based controller, i.e., the controller is offloaded to cloud or fog. Several experiments are performed to investigate the consequences of having a cloud server between the end device and the controller. The experiments are performed while considering arbitrary jitter and delays, i.e., they can be smaller than, equal to, or greater than the sampling period. This paper also applies mitigation mechanisms to deal with the delays and jitter that are caused by the networks when the controller is offloaded to the fog or cloud."
  },
  {
    "year": "2017",
    "abstract": "Many real world decision making problems often involve uncertainty data, which mainly originating from incomplete data and imprecise decision. The soft set theory as a mathematical tool that deals with uncertainty, imprecise, and vagueness is often employed in solving decision making problem. It has been widely used to identify irrelevant parameters and make reduction set of parameters for decision making in order to bring out the optimal choices. In this paper, we present a review on different parameter reduction and decision making techniques for soft set and hybrid soft sets under unpleasant set of hypothesis environment as well as performance analysis of the their derived algorithms. The review has summarized this paper in those areas of research, pointed out the limitations of previous works and areas that require further research works. Researchers can use our review to quickly identify areas that received diminutive or no attention from researchers so as to propose novel methods and applications."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the cluster synchronization problem of linearly coupled complex networks via aperiodically intermittent control (AIC). The dynamical behaviors of nodes in different clusters are assumed to be governed by different dynamical functions, while the dynamical behaviors of nodes in the same cluster are the same. Moreover, the original functions of nodes are defined by continuous-time ordinary differential equations with time-varying delays. As for the coupling matrix, we assume it is a Metzler matrix with zero row sums. The main contribution is that we pin some simple AIC to realize the cluster synchronization. Furthermore, as for the pinning control gains, both static and adaptive control cases are considered and some criteria are obtained. We also present some numerical simulations to verify the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "A routing algorithm is the pivotal and core issue in network communication. Traditional networks often use distributed routing algorithms that lead to difficulties in controlling network routes and accessing information concerning global topology. A software-defined network (SDN) is a new network framework that separates the network control plane from the forwarding/data plane. SDNs can access global topology through SDN controllers and make forwarding decisions based on flow tables. In this paper, we propose a box-covering-based routing (BCR) algorithm using a renormalization method that is applied to research the fractal dimensions of large-scale networks. We divide the entire SDN network into some subnets using a box-covering method, find the shortest path in every subnet and between subnets, and embed the proposed BCR algorithm code inside the SDN controller. We then design a testbed based on the Ryu controller and the Mininet platform for this algorithm. The results show that the proposed BCR algorithm has good low-latency performance and is suitable for a large-scale SDN."
  },
  {
    "year": "2017",
    "abstract": "The beat radio interferometry (BRI) is a novel ranging scheme that achieves high accuracy with low-cost devices. A major problem with BRI is the lack of an efficient range estimation method that is valid in general measurement configurations and accommodates large-scale scenarios. In this paper, we present a new model of BRI and reveal that range estimation in it is equivalent to single tone frequency estimation. Such a revelation has two natural outcomes: the first is the Cramer-Rao lower bound (CRLB) of BRI range estimation; the second is an efficient fast Fourier transform (FFT)-based method that works in arbitrary measurement configurations and large-scale scenarios. Simulation results show that the FFT-based method asymptotically attains the CRLB and is orders of magnitude faster than currently available methods."
  },
  {
    "year": "2017",
    "abstract": "Finding knowledge from large data sets to use in intelligent systems becomes more and more important in the Internet era. Pattern mining, classification, text mining, and opinion mining are the topical issues. Among them, pattern mining is an important issue. The problem of mining erasable patterns (EPs) has been proposed as a variant of frequent pattern mining for optimizing the production plans of factories. Several algorithms have been proposed for effectively mining EPs. However, for large threshold values, many EPs are obtained, leading to large memory usage. Therefore, it is necessary to mine a condensed representation of EPs. This paper first defines erasable closed patterns (ECPs), which can represent the set of EPs without information loss. Then, a theorem for fast determining ECPs based on dPidset structure is proposed and proven. Next, two efficient algorithms [erasable closed pattern mining (ECPat) and dNC_Set based algorithm for erasable closed pattern mining (dNC-ECPM)] for mining ECPs based on this theorem are proposed. Experimental results show that ECPat is the best method for sparse data sets, while dNC-ECPM algorithm outperforms ECPat algorithm and a modified mining erasable itemsets algorithm in terms of the mining time and memory usage for all remaining data sets."
  },
  {
    "year": "2017",
    "abstract": "Software size estimation plays a key role in the planning of projects at the time of project inception. This paper describes the derivation, validation, and usage of a parametric model meant for estimating the size of board-based desktop games. This model is derived using forward stepwise multiple linear regression on a data set comprising over 60 open source board-based games collected from multiple open source repositories. A variety of prediction accuracy metrics (e.g., MMRE, PRED(x), MdMRE, and so on) are used to assess this model and K-fold cross-validation is used to validate this model. Model assessment and validation exercises yield promising results. The utility of this model is demonstrated by presenting a worked-out game size estimation example followed by some size-related what-if analyses."
  },
  {
    "year": "2017",
    "abstract": "The wideband underwater acoustic multipath channel can be modeled as a multi-scale multi-lag (MSML) channel because signals from different paths might experience different Doppler scales. This brings great challenge to channel parameter estimation. In this paper, we propose a novel algorithm for parameter estimation of MSML channels. This new algorithm is a modified particle swarm optimization (MPSO) algorithm, which can estimate the parameters of the Doppler scale, the time delay, and the amplitude simultaneously for each individual path. Comparing to PSO algorithm, MPSO algorithm uses a multipath list to record positions and fitness values of particles whose fitness values are selected as lbests, and uses these lbests to update particles’ velocities at each iteration. As for training sequence, we employ the zero correlation zone sequence which has excellent correlation properties. Computer simulation is used to evaluate the proposed algorithm in comparison with the matching pursuit (MP)-based method and the fractional Fourier transform (FrFT)-based method. Simulation results confirm that the proposed MPSO algorithm outperforms both MP-based method and FrFT-based method in estimation accuracy as well as computation complexity."
  },
  {
    "year": "2017",
    "abstract": "As modern systems continue to increase in size and complexity, current systems security practices lack an effective approach to prioritize and tailor systems security efforts to successfully develop and field systems in challenging operational environments. This paper uniquely proposes seven system-agnostic security domains, which assist in understanding and prioritizing systems security engineering (SSE) efforts. To familiarize the reader with the state-of-the-art in SSE practices, we first provide a comprehensive discussion of foundational SSE concepts, methodologies, and frameworks. Next, the seven system-agnostic security domains are presented for consideration by researchers and practitioners. The domains are intended to be representative of a holistic SSE approach, which is universally applicable to multiple systems classes and not just a single-system implementation. Finally, three examples are explored to illustrate the utility of the system-agnostic domains for understanding and prioritizing SSE efforts in information technology systems, Department of Defense weapon systems, and cyber-physical systems."
  },
  {
    "year": "2017",
    "abstract": "Sina Weibo has become an important data resource for opinion mining. However, this data resource is polluted with un-opinionated posts. Detecting posts containing opinions in Sina Weibo faces two challenges. One is the short text in Sina Weibo that leads to insufficient textual features. The other challenge is the absence of ground-truth data for training models. In this paper, we propose a weakly supervised framework named graph-based opinioned post detector (GOPD) to detect the opinioned posts in Sina Weibo. GOPD utilizes three types of user interactions, which include reposting, responding, and referring, to construct the opinioned similarity graph (OSG) that describes the opinioned similarity between posts. On the OSG, opinioned post detection is formulated as a classification problem. The pairwise Markov random field model and the loopy belief propagation algorithm are employed to solve the problem. GOPD is evaluated on the manually labeled real-world datasets. Results show that the GOPD efficiently detects opinioned posts and transfers cross topics."
  },
  {
    "year": "2017",
    "abstract": "This paper considers a device-to-device (D2D) network with time-splitting protocol, where a D2D transmitter (Tx) first harvests energy from a multiple-antenna power beacon (PB) and ambient radio frequency sources, and then uses that harvested energy to transmit data to the D2D receiver (Rx). To improve the energy transfer efficiency, the PB is equipped with multiple antennas for energy transfer, and Tx is equipped with multiple antennas for energy harvesting. Two beamforming techniques, called best antenna-based beamforming and optimal beamforming vector, are proposed to use at the PB. We derive novel analytical expressions for the average harvested energy, power outage probability, and the outage probability of the information transfer link, considering the effect of co-channel interference from homogeneous Poison distributed interferes and the short-range propagation model for the path loss. We show that by deploying multiple harvesting energy antennas at Tx and by implementing optimal beamforming vector scheme at the PB, the system performance improves substantially. Furthermore, Monte-Carlo simulations are provided and verify the accuracy of our analytical results."
  },
  {
    "year": "2017",
    "abstract": "Secure the cooperative transmission is studied for an automatic repeat request (ARQ)-based wireless network against a jamming-aided eavesdropper. The eavesdropper utilizes the jamming attack to assist its eavesdropping by forcing the legitimate transmitter to retransmit its confidential messages under poor wiretap channel quality. Then, utilizing these retransmission opportunities, the eavesdropper will eavesdrop the confidential message under good wiretap channel quality. To address the threat from the jamming-aided eavesdropper in the ARQ-based wireless network, we propose an adaptive cooperative relaying and jamming secure transmission scheme to protect the confidential messages. In the proposed scheme, the legitimate receiver adopts the energy detection method to detect the jamming-aided eavesdropper’s action and a cooperative node will aid the secure transmission through cooperative relaying under jamming attack or cooperative jamming under eavesdropping attack. By taking into account of the detection errors, we investigate the transmission outage probability and the secrecy outage probability, and derive their closed-form expressions for both one retransmission and multiple retransmissions scenarios. Numerical results are presented to verify the derived analytical results and demonstrate the performance superiority of the proposed scheme in terms of the secrecy outage probability."
  },
  {
    "year": "2017",
    "abstract": "Key form features are relative to the style of product, and the expression on style features depicts the product description and is a measurement of attribute knowledge. The uncertainty definition leads to an improved and effective product style retrieval when combined with fuzzy sets. First, a style knowledge and features database are constructed using fuzzy case-based reasoning technology; a similarity measurement method based on case-based reasoning and fuzzy model of the fuzzy proximity method may be defined by the fuzzy nearest-neighbor algorithm for obtaining the style knowledge extraction. Second, the linguistic variables (LV) are used to assess the product characteristics to establish the product style evaluation database for simplifying the style presentation and decreasing the computational complexity. Third, the model of product style feature set, extracted by fuzzy analytic hierarchy process (FAHP), and the final style related form features set are acquired using LV. This research involves a case study for extracting the key form features of the style of high heel shoes. The proposed algorithms are generated by calculating the weights of each component of high heel shoes using FAHP with LV. The case study and results established that the proposed method is feasible and effective for extracting the style of the product."
  },
  {
    "year": "2017",
    "abstract": "We consider the problem of controlling a smart lighting system of multiple luminaires with collocated occupancy and light sensors. The objective is to attain illumination levels higher than specified values (possibly changing over time) at the workplace by adapting dimming levels using sensor information, while minimizing energy consumption. We propose to estimate the daylight illuminance levels at the workplace based on the daylight illuminance measurements at the ceiling. More specifically, this daylight estimator is based on a model built from data collected by light sensors placed at workplace reference points and at the luminaires in a training phase. Three estimation methods are considered: regularized least squares, locally weighted regularized least squares, and cluster-based regularized least squares. This model is then used in the operational phase by the lighting controller to compute dimming levels by solving a linear programming problem, in which power consumption is minimized under the constraint that the estimated illuminance is higher than a specified target value. The performance of the proposed approach with the three estimation methods is evaluated using an open-office lighting model with different daylight conditions. We show that the proposed approach offers reduced under-illumination and energy consumption in comparison to existing alternative approaches."
  },
  {
    "year": "2017",
    "abstract": "In order to solve the input nonlinearity of the hydraulic active suspension system, a master- slave control law is proposed through a nonlinear separation strategy. A Robust H∞control is used as the master controller and an adaptive backstepping control scheme is designed as the slave controller. The robust H∞master controller is studied to deal with the problems of input delay, parameter uncertainties, and multi-objective optimization in the linear system. A desired active control force is calculated by the master controller to guarantee the performances of the closed-loop system within allowable constraint ranges. The slave controller is applied to solve the problems of nonlinearity and the time constant uncertainty of the hydraulic actuator, an actual control law is obtained in this step. A quarter-car model with the hydraulic active suspension system is considered and the effectiveness of the proposed approach is illustrated by a realistic design example."
  },
  {
    "year": "2017",
    "abstract": "Multicarrier faster-than-Nyquist (MFTN) signaling is a spectral efficient modulation scheme for future communication systems. In MFTN signaling, the intersymbol interference (ISI) and intercarrier interference (ICI) are introduced intentionally by the time interval packing between adjacent symbols and frequency spacing packing between adjacent subcarriers. It is known that for multicarrier transmission over ISI and ICI channel, conventional rectangular lattice is not the optimal lattice structure. In this paper, the optimal hexagonal lattice-based MFTN signaling scheme is proposed. By appropriate staggering for conventional rectangular lattice, it is shown that the minimum Euclidean distance (or 2-DMazo limit) performance can be improved than conventional rectangular lattice-based MFTN signaling scheme. Moreover, a simple symbol-by-symbol receiver coupled with successive soft interference cancellation has been employed to recover the MFTN signals. Numerical results demonstrate that the hexagonal MFTN owns better bit error rate performance than conventional rectangular MFTN signaling scheme."
  },
  {
    "year": "2017",
    "abstract": "With the recent proliferation of powerful mobile devices, such as smart phones and tablets, data traffic on mobile networks is growing explosively. To cope with the challenges brought by the explosive growth of mobile traffic, mobile network operators tend to deploy and operate their own content distribution system within their existing network infrastructure. In this paper, we present a novel content distribution architecture called ISP-Controlled In-network Content Distribution (ICICD) to improve the content delivery performance in mobile network, which benefits from content request aggregation, hybrid cache decision mechanism, distributed load balancing, and seamless mobility support. Content request aggregation is used to decrease duplicate transmission. Hybrid cache decision mechanism enables the ICICD to cache content more efficiently. Distributed load balancing is able to ensure the overall performance and reliability of the content distribution architecture. Seamless mobility support function enables service continuity when mobile users move from one eNodeB to another. In this paper, we first give a detailed description about the key components of the ICICD architecture and then discuss a number of challenges in deploying the proposed ICICD architecture. Finally, simulation results are presented to show the performance and benefits of the proposed mobile content distribution architecture."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) are almost everywhere, they are exploited for thousands of applications in a densely distributed manner. Such deployment makes WSNs one of the highly anticipated key contributors of the big data nowadays. Hence, data aggregation is attracting much attention from researchers as efficient way to reduce the huge volume of data generated in WSNs by eliminating the redundancy among sensing data. In this paper, we propose an efficient data aggregation technique for clustering-based periodic wireless sensor networks. Further to a local aggregation at sensor node level, our technique allows cluster-head to eliminate redundant data sets generated by neighbouring nodes by applying three data aggregation methods. These proposed methods are based on the sets similarity functions, the one-way Anova model with statistical tests and the distance functions, respectively. Based on real sensor data, we have analyed their performances according to the energy consumption and the data latency and accuracy, and we show how these methods can significantly improve the performance of sensor networks."
  },
  {
    "year": "2017",
    "abstract": "Software product line (SPL) is extensively used for reusability of resources in family of products. Feature modeling is an important technique used to manage common and variable features of SPL in applications, such as Internet of Things (IoT). In order to adopt SPL for application development, organizations require information, such as cost, scope, complexity, number of features, total number of products, and combination of features for each product to start the application development. Application development of IoT is varied in different contexts, such as heat sensor indoor and outdoor environment. Variability management of IoT applications enables to find the cost, scope, and complexity. All possible combinations of features make it easy to find the cost of individual application. However, exact number of all possible products and features combination for each product is more valuable information for an organization to adopt product line. In this paper, we have proposed binary pattern for nested cardinality constraints (BPNCC), which is simple and effective approach to calculate the exact number of products with complex relationships between application's feature models. Furthermore, BPNCC approach identifies the feasible features combinations of each IoT application by tracing the constraint relationship from top-to-bottom. BPNCC is an open source and tool-independent approach that does not hide the internal information of selected and non-selected IoT features. The proposed method is validated by implementing it on small and large IoT application feature models with “n” number of constraints, and it is found that the total number of products and all features combinations in each product without any constraint violation."
  },
  {
    "year": "2017",
    "abstract": "Owing to the traffic pattern of wireless sensor networks (WSNs), cluster heads (CHs) around the sink node have larger relaying loads and consume their energy more quickly. This paper first analyzes the corona model. Based on analysis results, we find that nearly balanced energy consumption of WSNs can be achieved with the additional help of arranging different initial conditions. We then propose the energy-balanced node deployment with a balanced energy (END-BE) algorithm and END with a maximum life-time (END-MLT) scheme, which determine the cluster density for each corona according to the energy consumption of each CH. Simulation results show that the energy consumption is nearly balanced by implementing END-BE, and the network lifetime is greatly improved by adopting END-MLT."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a sensitivity-based group-wise parameter identification algorithm for the electrical model of Li-ion battery. A global sensitivity analysis method is first performed in the entire parameter space to evaluate the identifiability of the model parameters. Then, the parameters are sorted and grouped by the global sensitivity indices. Finally, a group-wise method embedded with the Levenberg-Marquardt algorithm is followed to identify the parameters. Numerical simulation results and comparisons demonstrate that the proposed group-wise identification algorithm can serve as a reliable tool for extracting parameters."
  },
  {
    "year": "2017",
    "abstract": "Next generation wireless standards will exploit the wide bandwidth available at the millimeter-wave (mm-Wave) frequencies, in particular theE-band (71–76 and 81–86 GHz). This large available bandwidth may be converted into multi-gigabit capacity, when efficient and computationally affordable transceivers are designed to cope with the constrained power budget, the clustered fading, and the high level of phase noise, which actually characterize mm-wave connections. In this paper, we propose a viable multiple-input multiple-output (MIMO) solution for high bit-rate transmission in theE-band with application to small-cell backhaul based on space-time shift keying (STSK) and orthogonal frequency division multiplexing. STSK provides an efficient tradeoff between diversity and multiplexing without inter-channel interference and without the need for large antenna arrays. These features make STSK theoretically preferable over other throughput-oriented space-time coding techniques, namely, spatial multiplexing and spatial modulation, which were recently considered in the literature for mm-wave MIMO applications. In this paper, we consider the most significant channel impairments related to small-cell backhaul in dense urban environment, namely, the correlated fading with and without the presence the line-of-sight, the phase noise, the rain attenuation, and shadowing. In addition, we consider small-size MIMO systems (2×2and4×4), and low-cost base station equipments in the perspective of easily deployable small-cell network components. Comparative results, obtained by intensive simulations targeted at assessing link performance and coverage, have clearly shown the superior performance of STSK against counterpart techniques, although obtained at the cost of a somewhat reduced spectral efficiency."
  },
  {
    "year": "2017",
    "abstract": "How to capture distinctive features from facial images when there are large variations in illumination, poses, and expressions is important for the face recognition problems. This paper introduces a novel algorithm called fuzzy linear regression discriminant projection (FLRDP) for face recognition. The proposed algorithm FLRDP seeks to generate an efficient subspace for the LRC method and could effectively handle variations between facial images. To be specific, FLRDP first computes the gradual membership degrees of each sample to corresponding classes, and then incorporates such membership degree information into the construction of the fuzzy between-class and within-class reconstruction errors. Finally, the criterion function is derived via maximizing the ratio of the fuzzy between-class reconstruction error to the fuzzy within-class reconstruction error. Experimental results carried out on the ORL, CMU PIE, and FERET face databases show the superiority of our proposed method over other state-of-the-art algorithms."
  },
  {
    "year": "2017",
    "abstract": "Current evolutions in the Internet of Things and cloud computing make it believable to build smart cities and homes. Smart cities provide smart technologies to residents for the improved and healthier life, where smart healthcare systems cannot be ignored due to rapidly growing elderly people around the world. Smart healthcare systems can be cost-effective and helpful in the optimal use of healthcare resources. The voice is a primary source of communication and any complication in the production of voice affects the personal as well as professional life of a person. Early screening of voice through an automatic voice disorder detection system may save life of a person. In this paper, an automatic voice disorder detection system to monitor the resident of all age group and professional backgrounds is implemented. The proposed system detects the voice disorder by determining the source signal from the speech through the linear prediction analysis. The analysis calculates the features from normal and disordered subjects. Based on these features, the spectrum is computed, which provided distribution of energy in normal and voice disordered subjects to differentiate between them. It is found that lower frequencies from 1 to 1562 Hz contributes significantly in the detection of voice disorders. The system is developed by using sustained vowel and running speech so that it can be deployed in a real world. The obtained accuracy for the detection of voice disorder with the sustained vowel is 99.94% ± 0.1, and that is for running speech is 99.75% ± 0.8."
  },
  {
    "year": "2017",
    "abstract": "The ever-increasing demand for wireless services and the continual improvements in wireless technology has led to the emergence of different types of wireless networks. These emerging networks include 5G networks [item 4) in the Appendix], Internet-of-Things (IoT) [item 5) in the Appendix], communication networks for smart grid, etc. 5G networks are envisioned to adopt a number of emerging concepts and technologies such as dense small cells and heterogeneous networks, device-to-device (D2D) communications, energy-efficient algorithms and protocols, multiband and full duplex transmission, and new multiple access techniques like non-orthogonal multiple access (NOMA) technique, etc. The IoT is an emerging concept in which a variety of intelligent objects or things around us such as mobile phones, sensors, actuators, and radio frequency identification tags, etc., will be seamlessly integrated and will communicate and interact with each other to achieve common goals [item 5) in the Appendix]. In general, these networks aim at providing wireless services to all network users with good quality-of-service, and ubiquitous and high data rate connectivity. Along with their envisioned benefits, these emerging network bring numerous challenges, such as allocation and management of radio spectrum, co-existence of different networks, and explosively increased energy consumption, etc. The effective deployment of these networks and coping with the associated challenges rely on the optimal modeling and design of the networks as well as on optimization method and algorithms for optimal management and utilization of radio spectrum and consumption of energy resource."
  },
  {
    "year": "2017",
    "abstract": "To maintain the straightness of an unmanned longwall mining face, a track geometry surveying model of the scraper conveyor was constructed based on the position of the shearer. A surveying instrument was developed employing an inertial measurement unit and axial encoder. Surveying tests were conducted using a longwall mining face mock-up, and the 3-D accuracy of the surveying instrument based on the mean radial spherical error and the spherical error probable (SEP) radius was determined to be 20.78 mm and 16.57 mm, respectively. The accuracy of the surveying system satisfied the requirements of a longwall mining face."
  },
  {
    "year": "2017",
    "abstract": "Pervasive social networking (PSN) supports instant social activities anywhere and at any time with the support of heterogeneous networks, where privacy preservation is a crucial issue. One of the effective methods to achieve privacy preservation is anonymous authentication on trust. However, few literatures pay attention to it. In this paper, we propose an anonymous authentication scheme based on group signature for authenticating trust levels rather than identities of nodes in order to avoid privacy leakage and guarantee secure communications in PSN. The scheme achieves secure anonymous authentication with anonymity and conditional traceability with the support of a trusted authority (TA). We also provide a mechanism to guarantee communications among nodes when TA is not available for some nodes. In addition, the utilization of batch signature verification further improves the efficiency of authenticity verification on a large number of messages. Performance analysis and evaluation further prove that the proposed scheme is effective with regard to privacy preservation, computation complexity, communication cost, flexibility, reliability, and scalability."
  },
  {
    "year": "2017",
    "abstract": "Relaying over power line communication (PLC) channels has the potential to improve the reliability and robustness of many PLC-based applications. In particular, this paper proposes to enhance the energy efficiency (EE) of a dual-hop relaying PLC system in the presence of impulsive noise by considering energy-harvesting (EH) at the relaying modem. Amplify-and-forward (AF) relaying and time-switching relaying EH protocols are deployed in this paper. The PLC modems are assumed to have the capability to go on low-power consumption sleep mode when they are neither transmitting nor receiving. The system performance is evaluated in terms of EE and average outage probability for which analytical expressions are derived. Using the derived expressions, several system parameters are investigated, such as the channel gain, which is related to the number of network branches, EH time factor and impulsive noise characteristics. Particularly, the optimization problem of the EH time is addressed thoroughly in order to maximize the achievable gains. Results reveal that the proposed system can offer considerable improvements compared with the conventional AF relaying scheme."
  },
  {
    "year": "2017",
    "abstract": "Beamforming has the potential to improve the efficiency of simultaneous wireless information and power transfer (SWIPT) systems. Existing beamforming techniques have been focused on the downlink of SWIPT systems. In this paper, we optimize the beamformers and transmit duration to maximize the weighted sum rate of both the downlink and uplink in a multiuser multiple-input multiple-output (MIMO) SWIPT system. Specifically, we formulate and transform the problem into a weighted sum mean square error minimization, conduct difference of convex programming to decouple the downlink and uplink, and convert the problem to quadratic programming (QP), which can be solved iteratively in a centralized fashion. We also decentralize the QP problem using dual decompositions, and reduce the time-complexity without compromising the data rate. Moreover, our algorithms are extended to the case under imperfect channel state information. Confirmed by simulations, the proposed decentralization can dramatically reduce the time-complexity by orders of magnitude. The scalability of the proposed approach can be substantially enhanced to support medium to large networks."
  },
  {
    "year": "2017",
    "abstract": "Vehicular social networks, as one type of new future networks, integrate mobile wireless communications and social networks together, and they have attracted a plenty of interest from researchers. This paper argues that vehicular social networks joined with cloud and fog computing platforms can serve as recommenders and play a significant role in social lives. A new application for recommender systems that selects vehicles as recommenders is proposed to support marketers in improving marketing effectiveness. Then, we propose three algorithms to enhance the marketers' marketing effectiveness based on different evaluation standards. The first algorithm selects those vehicles that can obtain maximum benefits for the marketers, in which the vehicles are selected based on passing regions with more benefits. However, this selection method may lose some potential markets because of region limitations. The second algorithm selects those vehicles that can reach the maximum coverage ratio in the city and bring the marketers more marketing effectiveness in the future, although the current benefits are not the best. The third algorithm combines the two prior algorithms, finding a tradeoff between coverage and benefits. We finally evaluate the effectiveness of the proposed algorithm with real-world data to show the effectiveness and efficiency of the \"On Selecting Vehicles as Recommenders for Vehicular Social Networks\" scheme: for the scheme based on the benefit factor, the performance criteria of the benefit ratio can be improved by 21% over the existing selection methods; for the scheme based on the coverage factor, the performance criteria of the coverage ratio can be improved by 13% over the existing selection methods; and for the third selection algorithm based on the two factors, the performance criteria of the benefit ratio and the metric 9 can be improved by 18.9% and 13.7%, respectively."
  },
  {
    "year": "2017",
    "abstract": "With the development of the latest technologies and changes in market demand, the wireless multi-sensor system is widely used. These multi-sensors are integrated in a way that produces an overwhelming amount of data, termed as big data. The multi-sensor system creates several challenges, which include getting actual information from big data with high accuracy, increasing processing efficiency, reducing power consumption, providing a reliable route toward destination using minimum bandwidth, and so on. Such shortcomings can be overcome by exploiting some novel techniques, such as clustering, data fusion, and coding schemes. Moreover, data fusion and clustering techniques are proven architectures that are used for efficient data processing; resultant data have less uncertainty, providing energy-aware routing protocols. Because of the limited resources of the multi-sensor system, it is a challenging task to reduce the energy consumption to survive a network for a longer period. Keeping challenges above in view, this paper presents a novel technique by using a hybrid algorithm for clustering and cluster member selection in the wireless multi-sensor system. After the selection of cluster heads and member nodes, the proposed data fusion technique is used for partitioning and processing the data. The proposed scheme efficiently reduces the blind broadcast messages but also decreases the signal overhead as the result of cluster formation. Afterward, the routing technique is provided based on the layered architecture. The proposed layered architecture efficiently minimizes the routing paths toward the base station. Comprehensive analysis is performed on the proposed scheme with state-of-the-art centralized clustering and distributed clustering techniques. From the results, it is shown that the proposed scheme outperforms competitive algorithms in terms of energy consumption, packet loss, and cluster formation."
  },
  {
    "year": "2017",
    "abstract": "Full dimension multiple-input-multiple-output (FD-MIMO) is one of the key technologies proposed in the third Generation Partnership Project (3GPP) for the fifth generation communication systems. The reason can be attributed to its ability to yield significant performance gains through the deployment of active antenna elements at the base station in the vertical as well as the conventional horizontal directions, enabling several elevation beamforming strategies. The resulting improvement in spectral efficiency largely depends on the orthogonality of the sub-channels constituting the FD-MIMO system. Accommodating a large number of antenna elements with sufficient spacing poses several constraints for practical implementation, making it imperative to consider compact antenna arrangements that minimize the overall channel correlation. Two such configurations considered in this paper are the uniform linear array (ULA) and the uniform circular array (UCA) of antenna ports, where each port is mapped to a group of physical antenna elements arranged in the vertical direction. The generalized analytical expression for the spatial correlation function (SCF) for the UCA is derived, exploiting results on spherical harmonics and Legendre polynomials. The mutual coupling between antenna dipoles is accounted for and the resulting SCF is also presented. The second part of this paper compares the spatial correlation and mutual information (MI) performance of the ULA and UCA configurations in the 3GPP 3-D urban-macro and urban-micro cell scenarios, utilizing results from random matrix theory on the deterministic equivalent of the MI for the Kronecker channel model. Simulation results study the performance patterns of the two arrays as a function of several channel and array parameters and identify applications and environments suitable for the deployment of each array."
  },
  {
    "year": "2017",
    "abstract": "Survivability in the OpenFlow-based software-defined elastic optical networks (SD-EONs) are more challenging than that in the conventional optical networks because failures can affect control plane operations. Meanwhile, traffic grooming is enabled by sliceable transponders can reduce power consumption and obtain higher spectrum efficiency. In this paper, we study the survivable grooming routing and spectrum allocation in SD-EON. First, provide an integer linear programming formulation to minimize both the required transponders and the maximum number of occupied frequency slots. Then, we develop a heuristic algorithm called shared backup path grooming protection (SBPGP) to get enough protection and less resources consumption. Extensive simulations are performed to study the power consumption of optical elements in data plane. Numerical results show that the proposed SBPGP scheme achieves better performances than the traditional shared backup path protection without grooming."
  },
  {
    "year": "2017",
    "abstract": "Currently, context awareness has become essential in software applications and services owing to the high demand by users, especially for mobile computing applications. This need to provide context awareness requires a software infrastructure not only to receive context information but also to make use of it so that it provides advantageous services that may be customized according to user needs. In this paper, we provide an event-driven service-oriented architecture supported by an enterprise service bus, which will facilitate the incorporation of Internet of Things data and provide real-time context-aware services. The result, which has been validated through a real-world case study, is a scalable context-aware architecture which can be applied in a wide spectrum of domains."
  },
  {
    "year": "2017",
    "abstract": "Using the Kinect sensor device and its related Microsoft software development kit (SDK), a Kinect-SDK speech recognition system can be easily established. However, such speech recognition systems exhibit substandard recognition performance and unreliable recognition decision-making because of the arbitrary placement of only one Kinect sensor. For sensing and control in Industry 4.0, correctness of the command recognized via sensing is essential for target control. For enhancing conventional Kinect-SDK speech recognition, this paper presents a client-server Kinect-SDK speech recognition scheme in which sensor deployment strategies and sensor fusion calculations are implemented using a TCP/IP decision server and multiple TCP/IP Kinect sensor clients. For sensor deployment, three deployment strategies are proposed: central, face-to-face, and diagonal-corner deployment. For sensor fusion calculations, three data fusion algorithms are proposed: sensor fusion by voting, voice energy comparisons, and voice energy comparisons with thresholds. The recognition performance of the conventional Kinect-SDK approach can be significantly improved by finely hybridizing sensor deployments and sensor data fusion; experimental results showed that Kinect-SDK speech recognition using the diagonal-corner deployment strategy hybridized with sensor fusion by voice energy comparisons with thresholds had the highest average recognition accuracy, which was significantly higher than that of the conventional Kinect SDK-speech recognition approach (14.93%). In addition, we implemented this strategy for the operation control of a remote multimedia player and a two-wheel automobile car in a laboratory office space."
  },
  {
    "year": "2017",
    "abstract": "The interest of indoor localization based on the IEEE 802.11 wireless local area network signal increases remarkably to support pervasive computing applications, but the process of fingerprints calibration, which is point-by-point conducted manually, is time consuming and labor intensive. To address this problem, we propose to use a novel improved semi-supervised manifold alignment approach by integrating the execution characteristic function to reduce both the number of reference points (RPs) and sampling time involved in the radio map construction. Specifically, the radio map is constructed from a small number of calibrated fingerprints and a batch of user traces, which are sporadically collected in the target environment. The user traces enable to compensate for the effort of reducing the calibration cost as well as improving the effectiveness of radio map. In addition, the cubic spline interpolation approach is applied to enrich the radio map with the limited number of RPs. Extensive experiments show that the proposed approach is capable of not only reducing the effort of fingerprints calibration remarkably, but also guaranteeing the high localization accuracy."
  },
  {
    "year": "2017",
    "abstract": "Electrical connectors are widely used in many kinds of main equipment. It is very difficult, costly, and time consuming for the off-line diagnosis of intermittent faults (IFs) in connectors. To realize the on-line diagnosis by the traditional method, the voltage drop between two ends of the connector should be measured continuously at a high sample rate. This continuous measurement requires enormous testing resources, which is impractical in engineering fields. To solve this problem, this paper proposes an on-line diagnosis method in condition of the single-end test for the electrical connector IFs. To determine the fault threshold of the electrical contact resistance (ECR), first the impact of the ECR on high-speed transmission is studied, and then the connector fault feature in condition of the single-end test, which is called the insertion loss increment (ILI), is extracted. The measurement method of the ILI is also presented. Based on the above analysis, an ILI-based on-line diagnosis method for the connector IFs is specified. According to the qualitative and quantitative tests, the proposed diagnosis method is verified. The verification results show that the cumulative insertion loss increment, which is calculated from the ILI can truly exhibit the variation of ECR, and the error of the ILI-based diagnosis method is only about 1%."
  },
  {
    "year": "2017",
    "abstract": "Device-to-device (D2D) communication has become a key technology in the fifth-generation cellular networks. Resource allocation is critical to ensure satisfactory performance. However, most existing resource allocation policies focus on delay-unaware performance metrics, such as throughput and power consumption, thus being effective only in delay-insensitive scenarios. To overcome this problem, in this paper, we consider an orthogonal frequency division multiple access-based cellular network, where multiple cellular users and D2D pairs along with delay quality-of-service (QoS) requirements coexist to share multiple sub-channels. We propose an effective resource allocation and source adaptation policy to maximize the system throughput while satisfying each user's delay QoS requirement. Specifically, we formulate a constraint optimization problem and solve it using the Lagrangian approach. In the dual domain, the key problem is solving for the dual function under given dual variable. This is a mixed integer non-linear programming problem with non-concave function and is non-linearly coupled over layers, thus being very difficult to solve. In response, we propose effective algorithms based on an alternating optimization method, successive convex approximation method, and outer approximation method. Analysis on the convergence and optimality of the proposed algorithms is given. Simulation results show that our proposed policy can improve the QoS-guaranteed system throughput significantly compared with the baselines."
  },
  {
    "year": "2017",
    "abstract": "Condition monitoring and incipient fault diagnosis of rolling bearing is of great importance to detect failures and ensure reliable operations in rotating machinery. In this paper, a new multi-speed fault diagnostic approach is presented by using self-adaptive wavelet transform components generated from bearing vibration signals. The proposed approach is capable of discriminating signatures from four conditions of rolling bearing, i.e., normal bearing and three different types of defected bearings on outer race, inner race, and roller separately. Particle swarm optimization and Broyden-Fletche-Goldfarb-Shanno-based quasi-Newton minimization algorithms are applied to seek optimal parameters of Impulse Modeling-based continuous wavelet transform model. Then, a 3-D feature space of the statistical parameters and a nearest neighbor classifier are, respectively, applied for fault signature extraction and fault classification. Effectiveness of this approach is then evaluated, and the results have achieved an overall accuracy of 100%. Moreover, the generated discriminatory fault signatures are suitable for multi-speed fault data sets. This technique will be further implemented and tested in a real industrial environment."
  },
  {
    "year": "2017",
    "abstract": "Content caching at base stations is a promising solution to address the large demands for mobile data services over cellular networks. Content caching is a challenging problem as it requires predicting the future popularity of the content and the operating characteristics of the cellular networks. In this paper, we focus on constructing an algorithm that improves the users' quality of experience (QoE) and reduces network traffic. The algorithm accounts for users' behavior and properties of the cellular network (e.g. cache size, bandwidth, and load). The constructed content and network aware adaptive caching scheme uses an extreme-learning machine neural network to estimate the popularity of content, and mixed-integer linear programming to compute where to place the content and select the physical cache sizes in the network. The proposed caching scheme simultaneously performs efficient cache deployment and content caching. Additionally, a simultaneous perturbation stochastic approximation method is developed to reduce the number of neurons in the extreme-learning machine method while ensuring a sufficient predictive performance is maintained. Using real-world data from YouTube and a NS-3 simulator, we demonstrate how the caching scheme improves the QoE of users and network performance compared with industry standard caching schemes."
  },
  {
    "year": "2017",
    "abstract": "The main challenge in the vehicular ad hoc network vehicle-to-vehicle (V2V) multi-hop dissemination is to control the number of vehicles, that relay the broadcast message. Proper selection of relay nodes governs high delivery ratio, acceptable overall end-to-end delay, and efficient bandwidth usage. To date, several protocols have been proposed to identify appropriate relay vehicles. However, such approaches neglect the fact that vehicle transmission ranges are typically heterogeneous due to different transmission power values or dynamic adjustment of power to alleviate congestion and/or control energy consumption. In this paper, we introduce area-based dissemination protocols that work in heterogeneous transmission powers. The transmissions between relay vehicles are ordered in way that ensures that the node with high potential new coverage area transmits first. This eliminates useless transmission and retransmission that could be contained by other transmission. The new potential coverage area is computed as a function of the common overlap areas. In addition, we propose more reliable approaches by relaying duplicate received message. Thus, we introduce a geometric taxonomy for all possible overlap patterns in wireless environment, which is an apparently hitherto unsolved geometrical problem. Accordingly, we deduce the criteria used to define each pattern and relevant algebraic expression to compute the potential additional coverage area."
  },
  {
    "year": "2017",
    "abstract": "Due to massive mobile terminal devices and ubiquitous communication, the Internet of things (IoT) has become an inevitable trend. Given that the fifth generation (5G) wireless networks expects to drive the proliferation of the IoT and may extend the access functions and systems of the IoT, it makes the IoT a vitally important part in future 5G wireless networks. Simultaneously, the limit of the bandwidth and power of the 5G would adversely affect the widespread promotion of the IoT. However, wireless caching techniques could remarkably resolve this issue. Recently, using fog nodes to improve the capacity of caching has become a trend in caching system. However, node-based caching systems may suffer from malicious access and destruction. To protect caching from sabotage and to further ensure its reliability, we propose a new lightweight label-based access control scheme (LACS) that authenticates the authorized fog nodes to ensure protection. Specifically, the LACS can authenticate the fog nodes by verifying the integrity of the shared files that are embedded label values, and only the authenticated fog nodes can access the caching service. The analysis shows that the proposed scheme is verifiable (the malicious fog node cannot cheat the caching server to pretend to be a legal node) and efficient in both computation and verification. Moreover, simulation experiments show that the LACS can reach the millisecond-level verification and it has a good accuracy."
  },
  {
    "year": "2017",
    "abstract": "Nano-devices have great potential to play a vital role in future medical diagnostics and treatment technologies because of its non-invasive nature and ability to reach delicate body sites easily as compared with conventional devices. In this paper, a novel concept of cooperative communication for in vivo nano-network is presented to enhance the communication among these devices. The effect on the system outage probability performance is conducted for various parameters, including relay placement, number of relays, transmit power, bandwidth, and carrier frequency. Results show approximately a tenfold increase in the system outage performance whenever an additional relay is included in the cooperative network, and hence show a great potential of using cooperative communication to enhance the performance of nano-network at terahertz frequencies."
  },
  {
    "year": "2017",
    "abstract": "The identification of influential nodes is essential to research regarding network attacks, information dissemination, and epidemic spreading. Thus, techniques for identifying influential nodes in complex networks have been the subject of increasing attention. During recent decades, many methods have been proposed from various viewpoints, each with its own advantages and disadvantages. In this paper, an efficient algorithm is proposed for identifying influential nodes, using weighted formal concept analysis (WFCA), which is a typical computational intelligence technique. We call this a WFCA-based influential nodes identification algorithm. The basic idea is to quantify the importance of nodes via WFCA. Specifically, this model converts the binary relationships between nodes in a given network into a knowledge hierarchy, and employs WFCA to aggregate the nodes in terms of their attributes. The more nodes aggregated, the more important each attribute becomes. WFCA not only works on undirected or directed networks, but is also applicable to attributed networks. To evaluate the performance of WFCA, we employ the SIR model to examine the spreading efficiency of each node, and compare the WFCA algorithm with PageRank, HITS, K-shell, H-index, eigenvector centrality, closeness centrality, and betweenness centrality on several real-world networks. Extensive experiments demonstrate that the WFCA algorithm ranks nodes effectively, and outperforms several state-of-the-art algorithms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a rateless superposition spinal code for binary erasure channel, which can provide unequal error protection (UEP) and unequal recovery time (URT) properties. By the superposition operation, the information of the more important bits is conveyed by more coded symbols than that of the less important bits, which leads to the UEP property. Moreover, a superposition parameter is introduced, which can be adjusted to meet different UEP requirements. Furthermore, we provide upper bound on the error probability for each priority level of the proposed code under maximum likelihood decoding. Simulation results show that the proposed code can provide UEP and URT properties, and the derived upper bound can well estimate the error probability of each priority level."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a very large-scale integration (VLSI) circuit design of a micro control unit (MCU) for wireless body sensor networks (WBSNs) in cost-intention. The proposed MCU design consists of an asynchronous interface, a multisensor controller, a register bank, a hardware-shared filter, a lossless compressor, an encryption encoder, an error correct coding (ECC) circuit, a universal asynchronous receiver/transmitter interface, a power management, and a QRS complex detector. A hardware-sharing technique was added to reduce the silicon area of a hardware-shared filter and provided functions in terms of high-pass, low-pass, and band-pass filters according to the uses of various body signals. The QRS complex detector was designed for calculating QRS information of the ECG signals. In addition, the QRS information is helpful to obtain the heart beats. The lossless compressor consists of an adaptive trending predictor and an extensible hybrid entropy encoder, which provides various methods to compress the different characteristics of body signals adaptively. Furthermore, an encryption encoder based on an asymmetric cryptography technique was designed to protect the private physical information during wireless transmission. The proposed MCU design in this paper contained 7.61k gate counts and consumed 1.33 mW when operating at 200 MHz by using a 90-nm CMOS process. Compared with previous designs, this paper has the benefits of increasing the average compression rate by over 12% in ECG signal, providing body signals analysis, and enhancing security of the WBSNs."
  },
  {
    "year": "2017",
    "abstract": "An application of a more cost-effective, simplified, and enhanced approach for the design and evaluation of Safety Instrumented Systems (SIS) called funnel risk graph method (FRGM) is presented in this paper. This approach makes compliance more practicable and standards more useful, resulting to an equal degree of functional safety as compared with the traditional approach. A real-life case study utilizing industrial SIS devices are presented to demonstrate the benefits of this approach. In contrast with other complex schemes commonly used for safety assessment, the proposed FRGM gives benefits such that it is straightforward in steps and resource-efficient while achieving the same safety function. While safety is aimed at protecting the systems from accidental failures to eliminate or minimize hazards, security is focused on protecting the systems from deliberate malicious attacks. They share the same goal-protecting the SIS from failing. Industry cybersecurity has become more critical these days and to address such concern, risk assessment for the security of SIS is proposed to be included in the design and evaluation, as part of the enhancement process."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an emergency-oriented procedure to recognize trajectory patterns by analyzing GPS data collected from intelligent sensor devices. An overall description, including design architecture and system modules, is presented. The primary issues are devoted to satisfying the requirements of key group identification and surveillance under normal and emergency circumstance. For the sake of panoramic understanding of human distribution and movement, semantic trajectory information is extracted from dynamic transportation data and static human distribution data. The sequential Monte Carlo method in conjunction with a state-transition model is employed to predict the updating real-time locations. The proposed algorithm selects particles from time-stamped sequential historical data sets. Simultaneously, a resampling strategy is developed to replace low-weight particles. A curve similarity measurement called Fréchet distance is employed to compare trajectories and city roads. Afterward, human daily location and significant locations are identified based on the clustering method. To evaluate the proposed procedure and methods, sequential trajectory data sets come from the GeoLife project along with human distribution logs from smartphone application EMAPP are utilized. Finally, we demonstrate the potential of dealing location information for promoting emergency management."
  },
  {
    "year": "2017",
    "abstract": "Content caching at network edge nodes, such as base stations (BSs) and user equipments (UEs), can significantly reduce the traffic load in future cellular networks. Considering the limited caching space, the contents cached at BSs should be selected carefully for improving caching efficiency. In this paper, we study the edge caching at BSs to minimize the transmission cost by considering traffic offloading via the device-to-device (D2D) communications. The traffic offloading reduces the traffic via cellular transmission and thus changes the utility achieved by content caching at BSs. We model the edge caching problem as a Markov decision process and propose a distributed cache replacement strategy based on Q-learning. The proposed strategy further needs the calculations of the following two key parameters: 1) To describe the effect of D2D offloading to the cellular traffic, we define the cellular serving ratio, which is calculated by the iterative maximum weighted independent sets problem for static networks and the stochastic geometry for high-dynamic networks; 2) The cache replacement rewards are calculated by analyzing the relationship between the requested and cached amounts of content data, which are obtained from the messages of the previous data request and transmissions, ignoring any extra information exchange between the BSs. Furthermore, the convergence of the proposed distributed cache replacement strategy is proved by the sequential stage game model. Simulation results verify the convergence of the proposed cache replacement strategy and show its performance gain compared with conventional strategies."
  },
  {
    "year": "2017",
    "abstract": "Ambient backscatter technology has attracted much attention recently, because it enables battery-free devices, such as tags or sensors, to communicate through wireless energy harvesting and radio backscattering. Existing studies about ambient backscatter assume that the tags have only two states: backscatter or non-backscatter. Actually, some references have shown that the tags can readily realize three states: positive and negative phase backscatter, and non-backscatter. In this paper, we propose a new coding scheme for these tags with three states to improve the throughput of the ambient backscatter communication system. We then design a maximum a posteriori (MAP) detector for the reader to extract binary information from ternary coded signals. We also analyze the detection performance in terms of closed-form bit error rate (BER) expressions. It is found that the proposed coding scheme can improve the throughput of an ambient backscatter system, and there exists an error floor for the BER curve. Finally, simulation results are provided to corroborate our theoretical studies."
  },
  {
    "year": "2017",
    "abstract": "As the promising communication architecture for future networks, the content-centric network (CCN) is still facing many challenges. In CCNs, it is difficult to discover temporary content replicas spreading in routers' caches based on the routing information provided by proactive routing protocols. This paper proposes an advanced perceptive forwarding strategy (APFS), which adaptively perceives closer temporary content replicas to respond the users' requests quickly. A data structure, called a chunk map (CM), is designed and is included into a data packet to indicate the availability of the content replicas in the cache of a closer router. The routers that have received the CM seem to perceive the closer content replicas so that they would intelligently forward the users' requests to the closer routers that cache the requested content replicas. Moreover, a new policy, called early start with punishment, is put forward to guarantee the adaptability of the CM probing and an improved cache replacement policy is employed to extend the validity duration of the CM. The simulation result shows that our APFS scheme has the noticeable performance in terms of the download delay and the average bandwidth."
  },
  {
    "year": "2017",
    "abstract": "The quality fluctuation of video is significant in human visual system, and thus, many rate control schemes are widely developed in the area of video communication. In recent years, researchers show more interests in region of interest (ROI)-based encoding, and it is widely applied in the latest video codecs, such as HEVC and VP9. This paper presents a new rate control scheme for ROI mode coding based on discrete fourier transform coefficient model and radial basis function neuron network. A new R-D model is proposed by classifying blocks into different depth, ROI groups, and so on. Then, rate and distortion are described based on the Laplacian distribution model using mathematical ways. A machine learning approach is induced to enhance the accuracy of the distortion estimation. By utilizing the new R-D model, a new rate control scheme is designed for ROI mode coding from the group of picture layer to coding unit layer. By comparisons with other rate control approaches, the proposed one has a better result in terms of visual quality, R-D performance, bitrate accuracy, and so on. Hence, it outperforms the conventional schemes especially for sequences with obvious ROI details."
  },
  {
    "year": "2017",
    "abstract": "The complex-valued neural networks are the class of networks that solve complex problems by using complex-valued variables. The gradient descent method is one of the popular algorithms to train complex-valued neural networks. Essentially, the established networks are integer-order models. Compared with classical integer-order models, the built models in terms of fractional calculus possess significant advantages on both memory storage and hereditary characteristics. As one of commonly used fractional-order derivatives, Caputo derivative is more applicable in practical problems due to its simple requirements on initial condition. In this paper, we adopt this specific fractional-order derivative to train split-complex neural networks. As a result, the monotonicity and weak convergence of the presented model are rigorously proved. In addition, numerical simulation has effectively verified its competitive performance and also illustrated the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "There are current limitations in the recording technologies for measuring EEG activity in clinical and experimental applications. Acquisition systems involving wet electrodes are time-consuming and uncomfortable for the user. Furthermore, dehydration of the gel affects the quality of the acquired data and reliability of long-term monitoring. As a result, dry electrodes may be used to facilitate the transition from neuroscience research or clinical practice to real-life applications. EEG signals can be easily obtained using dry electrodes on the forehead, which provides extensive information concerning various cognitive dysfunctions and disorders. This paper presents the usefulness of the forehead EEG with advanced sensing technology and signal processing algorithms to support people with healthcare needs, such as monitoring sleep, predicting headaches, and treating depression. The proposed system for evaluating sleep quality is capable of identifying five sleep stages to track nightly sleep patterns. Additionally, people with episodic migraines can be notified of an imminent migraine headache hours in advance through monitoring forehead EEG dynamics. The depression treatment screening system can predict the efficacy of rapid antidepressant agents. It is evident that frontal EEG activity is critically involved in sleep management, headache prevention, and depression treatment. The use of dry electrodes on the forehead allows for easy and rapid monitoring on an everyday basis. The advances in EEG recording and analysis ensure a promising future in support of personal healthcare solutions."
  },
  {
    "year": "2017",
    "abstract": "In cloud service over crowd-sensing data, the data owner (DO) publishes the sensing data through the cloud server, so that the user can obtain the information of interest on demand. But the cloud service providers (CSP) are often untrustworthy. The privacy and security concerns emerge over the authenticity of the query answer and the leakage of the DO identity. To solve these issues, many researchers study the query answer authentication scheme for cloud service system. The traditional technique is providing DO's signature for the published data. But the signature would always reveal DO's identity. To deal with this disadvantage, this paper proposes a cooperative query answer authentication scheme, based on the ring signature, the Merkle hash tree (MHT) and the non-repudiable service protocol. Through the cooperation among the entities in cloud service system, the proposed scheme could not only verify the query answer, but also protect the DO's identity. First, it picks up the internal nodes of MHT to sign, as well as the root node. Thus, the verification computation complexity could be significantly reduced from O(log2N) to O(log2N0.5) in the best case. Then, it improves an existing ring signature to sign the selected nodes. Furthermore, the proposed scheme employs the non-repudiation protocol during the transmission of query answer and verification object to protect trading behavior between the CSP and users. The security and performance analysis prove the security and feasibility of the proposed scheme. Extensive experimental results demonstrate its superiority of verification efficiency and communication overhead."
  },
  {
    "year": "2017",
    "abstract": "The explosive growth of mobile date traffic and ubiquitous mobile services cause an high energy consumption in mobile devices with limited energy supplies, which has become a bottleneck for deploying device-to-device (D2D) communication. Simultaneous wireless information and power transfer (SWIPT), which enables mobile devices to harvest energy from the radio frequency signals, has emerged as a promising solution to improve the energy efficiency (EE) performance. In this paper, we address joint power control and spectrum resource allocation problem in SWIPT-based energy-harvesting D2D underlay networks. First, we formulate joint optimization problem as a 2-D matching between D2D pairs and cellular user equipments (CUEs), and propose a preference establishment algorithm based on Dinkelbach method and Lagrange dual decomposition. Second, we propose an energy-efficient stable matching algorithm by exploring the Gale-Shapley algorithm, which is able to maximize the EE performance of D2D pairs and the amount of energy harvested by CUEs simultaneously. Third, we provide in-depth theoretical analysis of the proposed matching algorithm in terms of stability, optimality, and complexity. Simulation results demonstrate that the proposed algorithm can bring significant EE performance gains compared with some heuristic algorithms."
  },
  {
    "year": "2017",
    "abstract": "Scene text information extraction plays an important role in many computer vision applications. Most features in existing text extraction algorithms are only applicable to one text extraction stage (text detection or recognition), which significantly weakens the consistency in an end-to-end system, especially for the complex Chinese texts. To tackle this challenging problem, we propose a novel text structure feature extractor based on a text structure component detector (TSCD) layer and residual network for Chinese texts. Inspired by the three-layer Chinese text cognition model of a human, we combine the TSCD layer and the residual network to extract features suitable for both text extraction stages. The specialized modeling for Chinese characters in the TSCD layer simulates the key structure component cognition layer in the psychological model. And the residual mechanism in the residual network simulates the key bidirectional connection among the layers in the psychological model. Through the organic combination of the TSCD layer and the residual network, the extracted features are applicable to both text detection and recognition, as humans do. In evaluation, both text detection and recognition models based on our proposed text structure feature extractor achieve great improvements over baseline CNN models. And an end-to-end Chinese text information extraction system is experimentally designed and evaluated, showing the advantage of the proposed feature extractor as a unified feature extractor."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a new hotspot ranking-based indoor mapping and mobility analysis approach based on the sporadically collected crowdsourced Wi-Fi received signal strength (RSS) data. This approach aims to construct the indoor mapping, as well as achieve the mobility analysis of the users following their daily motion patterns in target environment. First, we perform the wavelet analysis with respect to each RSS sequence to mitigate the noise interference to some extent. Second, we develop a new multidimensional scaling approach to map each RSS data into a linear one in the 2-D signal space, which is followed by the density clustering approach to merge the linear ones into different clusters based on the spatial correlation property. Finally, we construct the indoor mapping from the signal into physical spaces by the concept of hotspot ranking order, as well as the transfer relations among different RSS clusters and different physical sub-areas. The experimental results demonstrate that the proposed approach can achieve the superior performance in terms of indoor mapping and mobility analysis in an unknown indoor environment."
  },
  {
    "year": "2017",
    "abstract": "Since trust among entities can change according to various conditions, it is necessary for ambient services to determine when and how the trust has to be updated. Therefore, our contribution in this paper is to present: 1) a new definition of trust that can be extended to various domains; 2) a novel method based on social events and patterns to trigger trust refreshment in ambient services; and 3) a web application framework (called SocioScope) for collecting and analyzing data from multiple data sources. Finally, the case study suggests that this proposal could be applied to trust-aware ambient and recommendation systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the simultaneous wireless information and power transfer (SWIPT) in a multiple-input multiple-output (MIMO) amplify-and-forward relay communication system, where the relay is an energy harvesting (EH) node and harvests the energy the signals transmitted from the source. The harvested energy is partially used to forward signals from the source to the destination, and the remaining energy is stored for other usages. The SWIPT in relay-assisted communication is interesting as long as the relay stores energy from the source and the destination receives successfully the data from the source. In this context, we propose to investigate the source and relay precoders that characterize the relationship between the achievable stored energy at the relay and the achievable source-to-destination rate, namely, the rate-stored energy (R-E) tradeoff region. First, we consider the ideal scheme, where there is the simultaneous operation of the EH and information decoding (ID) receivers at the relay. Then, we consider practical schemes, such as the power splitting and the time switching that separate the operation of EH and ID receivers over power domain or time domain, respectively. Moreover, we study the case of imperfect channel state information at the relay and the destination, and characterize its impact on the achievable R-E region. Through the simulation results, we show the effect of the position of the relay and the channel uncertainty on the achievable R-E regions of all the schemes when the used energy at the relay is constant or variable. We also show that, although it provides an outer bound on the achievable rate-energy region in one-hop MIMO systems, the ideal scheme provides only an upper bound on the maximum achievable end-to-end rate and not an outer bound on the R-E region."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a simultaneous cooperative spectrum sensing and energy harvesting model is proposed to improve the transmission performance of the multichannel cognitive radio. The frame structure is divided into sensing slot and transmission slot. In the sensing slot, the secondary user (SU) splits the subchannels into two subchannel sets, one for sensing the primary user (PU) by multichannel cooperative spectrum sensing and the other one for collecting the radio frequency energy of the PU signal and noise by multichannel energy harvesting. In the transmission slot, the harvested energy is supplied to compensate the sensing energy loss in order to guarantee the throughput. We have formulated the resource allocation of the proposed model as a class of optimization problems, which maximize aggregate throughput, harvested energy, and energy efficiency of the SU over all the subchannels through jointly optimizing subchannel set, sensing time, and transmission power, respectively. To achieve the sub-optimal solutions to the optimization problems, we have proposed the subchannel allocation algorithm and the joint optimization algorithm of sensing time and transmission power based on the Greedy algorithm and the alternating direction optimization. The stopping criteria of SU is described, when the PU is not present but the harvested energy is not enough. The simulation results are presented to demonstrate the validity and predominance of our proposed algorithms."
  },
  {
    "year": "2017",
    "abstract": "This paper focuses on the analysis of cultivated collagen samples at the terahertz (THz) band using double debye model parameter extraction. Based on measured electrical and optical parameters, we propose a model to describe such parameters extracted with a global optimisation method, namely, particle swarm optimisation. Comparing the measured data with ones in the open literature, it is evident that using only cultivated collagen is not sufficient to represent the performance of the epidermis layer of the skin tissue at the THz band of interest. The results show that the differences between the measured data and published ones are as high as 14 and 6 for the real and imaginary values of the dielectric constant, respectively. Our proposed double debye model agrees well with the measured data."
  },
  {
    "year": "2017",
    "abstract": "Mutation testing is a fault-based testing technique that helps generating effective test cases. Mutation testing is computationally expensive, because it requires executing hundreds and even thousands of mutants. In this situation, search-based approaches like genetic algorithm can help to automate test case generation to reduce the cost. In this paper, we present an improved genetic algorithm that can reduce computational cost of mutation testing. First, we present a novel state-based and control-oriented fitness function that efficiently uses object-oriented program features to evaluate a test case. We then empirically evaluate it using our implemented tool, eMuJava, and compare it with the standard fitness function. Results show that although our proposed fitness function provides detailed information about fitness of a test case but standard genetic algorithm is incapable of using that effectively to repair the test cases. Therefore, we propose a new two-way crossover and adaptable mutation methods that intelligently use the fitness information to generate fitter offspring. Finally, we compare the improved genetic algorithm with random testing, standard genetic algorithm, and EvoSuite. Experiment results prove that our proposed approach can find the optimal test cases in less number of attempts (reduces computational cost). Besides that it can detect software bugs from suspiciously equivalent mutants and these mutants eventually get killed (increases mutation score)."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) will be integrated into the future Internet as one of the components of the Internet of Things, and will become globally addressable by any entity connected to the Internet. Despite the great potential of this integration, it also brings new threats, such as the exposure of sensor nodes to attacks originating from the Internet. In this context, lightweight authentication and key agreement protocols must be in place to enable end-to-end secure communication. Recently, Amin et al. proposed a three-factor mutual authentication protocol for WSNs. However, we identified several flaws in their protocol. We found that their protocol suffers from smart card loss attack where the user identity and password can be guessed using offline brute force techniques. Moreover, the protocol suffers from known session-specific temporary information attack, which leads to the disclosure of session keys in other sessions. Furthermore, the protocol is vulnerable to tracking attack and fails to fulfill user untraceability. To address these deficiencies, we present a lightweight and secure user authentication protocol based on the Rabin cryptosystem, which has the characteristic of computational asymmetry. We conduct a formal verification of our proposed protocol using ProVerif in order to demonstrate that our scheme fulfills the required security properties. We also present a comprehensive heuristic security analysis to show that our protocol is secure against all the possible attacks and provides the desired security features. The results we obtained show that our new protocol is a secure and lightweight solution for authentication and key agreement for Internet-integrated WSNs."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an optimized belief propagation (OBP) based progressive edge-growth (PEG) method for constructing quasi-cyclic low density parity check (QC-LDPC) codes. In this proposed method, Tanner graphs are built by progressively appending the check nodes rather than the variable nodes. Moreover, this OBP-PEG method considers three new constraint conditions to select the QC-LDPC code sets constructed by the PEG method. Compared with the PEG-based QC-LDPC decoders, the proposed OBP-PEG decoders decrease the number of the input ports of check-node processer by up to 25%, accelerates the convergence speed by up to 11.7% in layered decoding process, and improves the success probability by up to ten times in constructing fast-convergence QC-LDPC codes."
  },
  {
    "year": "2017",
    "abstract": "The impedance at the each input terminal of paper presents a voltage combining Doherty power amplifier in a standard 180-nm CMOS process. This Doherty PA uses a series combining transformer (SCT) to combine the output power and realize the load modulation, which is different from the conventional current combining method. The series combining transformer is analyzed for impedance modulation behavior, and we have provided the design method. The proposed Doherty PA achieves a maximum output power of 27.6 dBm at 1.75 GHz with a peak power added efficiency (PAE) of 35.2% at 3.4 V supply voltage. The PAE at 6 dB back-off is still high, about 29.2%. The PA has 24.2 dBm output power with 30.2% PAE at −37 dBc ACLR (5 MHz offset) and 25.2 dBm output power with 32% PAE at −33 dBc ACLR (5 MHz offset) at 1.75 GHz under a wideband code division multiple access signal with 3.3-dB PAPR and 3.84-MHz BW."
  },
  {
    "year": "2017",
    "abstract": "Target tracking has wide-ranging applications in fields using wireless sensor networks. However, localization accuracy is adversely affected by the non-line-of-sight (NLOS) effect. Thus, we propose a three-step localization approach to target tracking to identify and mitigate the NLOS effect. A Bayesian sequential test is designed to identify whether the measurement data are affected by this effect. On the basis of the identified measurement condition, we smooth the measurement range and mitigate the NLOS effect using a modified Kalman filter (MKF). After adjusting the measurement noise covariance and prediction covariance by using an established measurement equation, we apply the MKF, which is a standard Kalman filter with updated parameters. After the distances between the target and the sensor nodes are estimated by the MKF, the final estimated target position can be obtained using a residual weighting algorithm. Experimental and simulation results show that the proposed approach is superior to other methods that do not identify the propagation condition, and it can effectively improve the localization accuracy."
  },
  {
    "year": "2017",
    "abstract": "Full-duplex (FD) systems have emerged as an essential enabling technology to further increase the data rate of wireless communication systems. The key idea of FD is to serve multiple users over the same bandwidth with a base station (BS) that can simultaneously transmit and receive the signals. The most challenging issue in designing an FD system is to address both the harmful effects of residual self-interference caused by the transmit-to-receive antennas at the BS as well as the co-channel interference from an uplink user (ULU) to a downlink user (DLU). An efficient solution to these problems is to assign the ULUs/DLUs in different groups/slots, with each user served in multiple groups. Hence, this paper studies the joint design of transmit beamformers, ULUs/DLUs group assignment, and time allocation for each group. The specific aim is to maximize the sum rate under the ULU/DLU minimum throughput constraints. The utility function of interest is a difficult nonconcave problem, and the involved constraints are also nonconvex, and so this is a computationally troublesome problem. To solve this optimization problem, we propose a new path-following algorithm for computational solutions to arrive at least the local optima. Each iteration involves only a simple convex quadratic program. We prove that the proposed algorithm iteratively improves the objective while guaranteeing convergence. Simulation results confirm the fast convergence of the proposed algorithm with substantial performance improvements over existing approaches."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an overhead-optimizing multi-device task scheduling strategy for ad-hoc-based mobile edge computing system is proposed. This task scheduling strategy takes the opportunity consumption, time delay, energy consumption, and monetary cost into account, aiming at minimizing the overhead of each mobile device. First, a system model for ad-hoc-based mobile edge computing is presented and the overhead of mobile device is analyzed. Second, the task scheduling problem is formulated as a distributed multi-device task scheduling game. Then, by constructing a potential function, the task scheduling game is proved to be a potential game, which possesses a property of finite improvement and always owns a Nash equilibrium. Next, an overhead-optimizing multi-device task scheduling algorithm is designed and the computational complexity is analyzed. Finally, simulations are conducted to evaluate the effectiveness of the proposed strategy. The results show that the proposed task scheduling strategy can effectively minimize the overhead of the mobile device and successfully complete the tasks."
  },
  {
    "year": "2017",
    "abstract": "Low-density parity check (LDPC) error correction decoders have become popular in diverse communications systems, owing to their strong error correction performance and their suitability to parallel hardware implementation. A great deal of research effort has been invested into the implementation of LDPC decoder designs on field-programmable gate array (FPGA) devices, in order to exploit their high processing speed, parallelism, and re-programmability. Meanwhile, a variety of application-specific integrated circuit implementations of multi-mode LDPC decoders exhibiting both inter-standard and intrastandard reconfiguration flexibility are available in the open literature. However, the high complexity of the adaptable routing and processing elements that are required by a flexible LDPC decoder has resulted in a lack of viable FPGA-based implementations. Hence in this paper, we propose a parameterisable FPGAbased LDPC decoder architecture, which supports run-time flexibility over any set of one or more quasicyclic LDPC codes. Additionally, we propose an off-line design flow, which may be used to automatically generate an optimized HDL description of our decoder, having support for a chosen selection of codes. Our implementation results show that the proposed architecture achieves a high level of design-time and run-time flexibility, whilst maintaining a reasonable processing throughput, hardware resource requirement, and error correction performance."
  },
  {
    "year": "2017",
    "abstract": "Radio Frequency (RF) energy harvesting holds a promising future for energizing low power mobile devices in next generation wireless networks. Harvesting from a dedicated RF energy source acquires much more energy than simply harvesting from ambient RF sources. In this paper, novel Self-healing of Users equipment by RF Energy transfer scheme is introduced between the network operator and battery starved users to heal and extend their battery life time by sending dedicated energy from different sources in order to be aggregated and harvested by starved users. This approach depends on the concept of Energy as a Service where the network operator delivers energy to battery starved users in the next generation networks. A mixed integer non-linear optimization problem is formulated and solved efficiently using three heuristic algorithms. Simulation results prove that sufficient amounts of energy can be delivered to starved users while minimizing their uplink power requirements and guaranteeing a minimum uplink data rate."
  },
  {
    "year": "2017",
    "abstract": "Fog computing-enhanced Internet of Things (IoT) has recently received considerable attention, as the fog devices deployed at the network edge can not only provide low latency, location awareness but also improve real-time and quality of services in IoT application scenarios. Privacy-preserving data aggregation is one of typical fog computing applications in IoT, and many privacy-preserving data aggregation schemes have been proposed in the past years. However, most of them only support data aggregation for homogeneous IoT devices, and cannot aggregate hybrid IoT devices' data into one in some real IoT applications. To address this challenge, in this paper, we present a lightweight privacy-preserving data aggregation scheme, called Lightweight Privacy-preserving Data Aggregation, for fog computing-enhanced IoT. The proposed LPDA is characterized by employing the homomorphic Paillier encryption, Chinese Remainder Theorem, and one-way hash chain techniques to not only aggregate hybrid IoT devices' data into one, but also early filter injected false data at the network edge. Detailed security analysis shows LPDA is really secure and privacy-enhanced with differential privacy techniques. In addition, extensive performance evaluations are conducted, and the results indicate LPDA is really lightweight in fog computing-enhanced IoT."
  },
  {
    "year": "2017",
    "abstract": "In wireless sensor networks, energy balancing and energy efficiency are the key requirements to prolong the network lifetime. In this paper, we investigate the problem of energy hole, in which sensor nodes located near the sink or in some other parts of the network die early due to unbalanced load distribution. Moreover, there is a dire need to utilize the energy resource efficiently. For this purpose, balanced energy consumption and hole alleviation, and energy-aware balanced energy-consuming and hole-alleviating algorithms are proposed. These algorithms balance the distribution of load along with efficient energy consumption. An optimal distance and energy-based transmission strategy with least expected error rate is adopted to forward the data packets of different sizes. Furthermore, the data distribution between high-energy consuming nodes and low-energy consuming nodes in each corona is analyzed. This distribution enables the proposed algorithms to outperform their counterparts in term of network lifetime, balanced energy consumption, and throughput on the cost of increased end-to-end delay."
  },
  {
    "year": "2017",
    "abstract": "Recently, Hao and Xia noted a connection between a class of binary locally repairable codes (LRCs) with multiple repair groups and binary low-density parity-check (LDPC) codes, and proposed a framework for constructing binary LRCs from LDPC codes as well as three specific constructions of binary LRCs that can achieve a distance bound. The connection between binary LRCs and LDPC codes, however, has not yet been fully disclosed and constructions of binary LRCs that can achieve the distance bound remain largely unknown. Accordingly, this paper comments on the connection and presents two infinite families of binary LRCs that can achieve the distance bound, based on circulant permutation matrices and affine permutation matrices. The proposed LRCs generalize the promising construction of high-rate codes proposed by Hao and Xia, and offer larger relative distances with the same or higher code rates when compared with other competitive codes."
  },
  {
    "year": "2017",
    "abstract": "Owing to many appealing properties, neural networks provide a natural basis for solving different kinds of problems. The performance of neural networks greatly depends on whether they can provide appealing solutions to the problems of the parameter learning (i.e., the connecting weights in each layer) and the structure learning (i.e., the network structure). These two kinds of learning can be performed simultaneously or separately. In this paper, we proposed the Jacobian matrix-based learning machine (JMLM) to provide an appealing solution to the aforementioned two kinds of learning. The network structure of a JMLM can be incrementally constructed and a Jacobian-matrix-based learning method is proposed to efficiently estimate the corresponding network parameters. Furthermore, we can provide physically meaningful explanations to help human analyzers to make decisions based on the parameters embedded in a trained JMLM. One 2-D artificial data set, one benchmark medical data set, and an intensive care unit survival prediction data set were used for demonstrating the performance of the proposed JMLM."
  },
  {
    "year": "2017",
    "abstract": "Telecare medical information system (TMIS) is highly desirable to users by allowing them to remotely access medical services or medical information and security, such as authentication and privacy preserving of users is challenging. Recently, some smart card-based password authentication (two-factor authentication) schemes have been proposed. In this paper, we use Chaudhry et al.'s scheme as a case study and demonstrate that a family of two-factor authentication schemes for the TMIS are not secure against offline dictionary attack and fail to revoke the stolen/lost smart card. Furthermore, an improved two-factor authentication scheme with anonymity has been proposed to remedy the weakness of these schemes. The security analysis of the proposed solution is formally given with the random oracle model and Burrows-Abadi-Needham logic."
  },
  {
    "year": "2017",
    "abstract": "Vehicle target tracking is a sub-field of increasing and increasing interest in the vehicular networking research area, in particular for its potential application in dense urban areas with low associated costs, e.g., by exploiting existing monitoring infrastructures and cooperative collaboration of regular vehicles. Inspired by the concept of trap coverage area, we have originally designed and implemented an original protocol for vehicle tracking in wide-scale urban scenarios, called TCAP. TCAP is capable of achieving the needed performance while exploiting a limited number of inexpensive sensors (e.g., public-authority cameras already installed at intersections for traffic monitoring), and opportunistic vehicle collaboration, with high scalability and low overhead if compared with state-of-the-art literature. In particular, the wide set of reported results show i) the suitability of our TCAP tracking in the challenging urban conditions of high density of vehicles, ii) the very weak dependency of TCAP performance from topology changes/constraints (e.g., street lengths and speed limits), iii) the TCAP capability of self-adapting to differentiated runtime conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the application of cooperative techniques for non-orthogonal multiple access (NOMA). More particularly, the fixed gain amplify-and-forward (AF) relaying with NOMA is investigated over Nakagami-m fading channels. Two scenarios are considered insightfully: 1) the first scenario is that the base station (BS) intends to communicate with multiple users through the assistance of AF relaying, where the direct links are existent between the BS and users and 2) the second scenario is that the AF relaying is inexistent between the BS and users. To characterize the performance of the considered scenarios, new closed-form expressions for both exact and asymptomatic outage probabilities are derived. Based on the analytical results, the diversity orders achieved by the users are obtained. For the first and second scenarios, the diversity order for the nth user are μ(n + 1) and μn, respectively. Simulation results unveil that NOMA is capable of outperforming orthogonal multiple access (OMA) in terms of outage probability and system throughput. It is also worth noting that NOMA can provide better fairness compared with conventional OMA. By comparing the two scenarios, cooperative NOMA scenario can provide better outage performance relative to the second scenario."
  },
  {
    "year": "2017",
    "abstract": "This paper examines the history of electrical engineering education, leveraging the concept of “expansive (dis)integration” to frame a number of key trends and challenges in the field. Our account is organized historically, starting with the origins and early development of electrical engineering education beginning in the late 1800s, and then tracing out the rise of new subfields and specialties during the inter-war and post-WWII periods. The development of computer engineering as a field is given special attention as a case study in disciplinary (dis)integration, while setting the stage for a discussion of broader trends associated with the rising influence of digital techniques and technologies across electrical engineering. The final sections of this paper report on some contemporary challenges and opportunities that may further transform the field in upcoming years and decades, with particular emphasis on issues of demographic diversity and perceptions of broader relevance and impact. The approach of this paper is largely historical, drawing on a wide variety of primary and secondary source materials. It is expected that this paper will be of interest to anyone who would like to know more about the historical development of electrical engineering education, including in relation to more contemporary currents in the field."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study crucial elements of a complex network, namely its nodes and connections, which play a key role in maintaining the network's structure and function under unexpected structural perturbations of nodes and edges removal. Specifically, we want to identify vital nodes and edges whose failure (either random or intentional) will break the most number of connected triples (or triangles) in the network. This problem is extremely important, because connected triples form the foundation of strong connections in many real-world systems, such as mutual relationships in social networks, reliable data transmission in communication networks, and stable routing strategies in mobile networks. Disconnected triples, analog to broken mutual connections, can greatly affect the network's structure and disrupt its normal function, which can further lead to the corruption of the entire system. The analysis of such crucial elements will shed light on key factors behind the resilience and robustness of many complex systems in practice. We formulate the analysis under multiple optimization problems and show their intractability. We next propose efficient approximation algorithms, namely, DAK-n and DAK-e, which guarantee an (1 - 1/e)-approximate ratio (compared with the overall optimal solutions) while having the same time complexity as the best triangle counting and listing algorithm on power-law networks. This advantage makes our algorithms scale extremely well even for very large networks. In an application perspective, we perform comprehensive experiments on real social traces with millions of nodes and billions of edges. Empirical results indicate that our approaches achieve comparably better solution quality while are up to 100× faster than the current state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Emotional health plays very vital role to improve people's quality of lives, especially for the elderly. Negative emotional states can lead to social or mental health problems. To cope with emotional health problems caused by negative emotions in daily life, we propose efficient facial expression recognition system to contribute in emotional healthcare system. Thus, facial expressions play a key role in our daily communications, and recent years have witnessed a great amount of research works for reliable facial expressions recognition (FER) systems. Therefore, facial expression evaluation or analysis from video information is very challenging and its accuracy depends on the extraction of robust features. In this paper, a unique feature extraction method is presented to extract distinguished features from the human face. For person independent expression recognition, depth video data is used as input to the system where in each frame, pixel intensities are distributed based on the distances to the camera. A novel robust feature extraction process is applied in this work which is named as local directional position pattern (LDPP). In LDPP, after extracting local directional strengths for each pixel such as applied in typical local directional pattern (LDP), top directional strength positions are considered in binary along with their strength sign bits. Considering top directional strength positions with strength signs in LDPP can differentiate edge pixels with bright as well as dark regions on their opposite sides by generating different patterns whereas typical LDP only considers directions representing the top strengths irrespective of their signs as well as position orders (i.e., directions with top strengths represent 1 and rest of them 0), which can generate the same patterns in this regard sometimes. Hence, LDP fails to distinguish edge pixels with opposite bright and dark regions in some cases which can be overcome by LDPP. Moreover, the LDPP capabilities are ..."
  },
  {
    "year": "2017",
    "abstract": "The faults of rolling element bearings can result in the deterioration of machine operating conditions; how to assess the working condition and identify the fault of the rolling element bearing has become a key issue for ensuring the safe operation of modern rotating machineries. This paper presents a novel hybrid approach that detects bearing faults and monitors the operating status of rolling element bearings in modern rotating machineries. Based on redundant second-generation wavelet packet transform and local characteristic-scale decomposition, this method is implemented to extract the fault features, the vibration signal is adaptively decomposed into a number of desired intrinsic scale components by two-step screening processes based on the energy ratio, and reduce random noises and eliminate the pseudofrequency components. The fault features are then used to implement the identification classification of faults using singular value decomposition and extreme learning machine. The approach is evaluated by simulation and practical bearing vibration signals under different conditions. The experiment results show that the proposed approach is feasible and effective for the fault diagnosis of rolling element bearing."
  },
  {
    "year": "2017",
    "abstract": "In conventional cellular networks, for base stations (BSs) that are deployed far away from each other, it is general to assume them to be mutually independent. Nevertheless, after long-term evolution of cellular networks in various generations, this assumption no longer holds. Instead, the BSs, which seem to be gradually deployed by operators in a service-oriented manner, have embedded many fundamentally distinctive features in their locations, coverage, and traffic loading. These features can be leveraged to analyze the intrinstic pattern in BSs and even human community. In this paper, according to large-scale measurement datasets, we build up a correlation model of BSs by utilizing one of the most important features, i.e., spatial traffic. Coupling with the theory of complex networks, we make further analysis on the structure and characteristics of this traffic load correlation model. Numerical results show that the degree distribution follows scale-free property. Also, the datasets unveil the characteristics of fractality and small-world. Furthermore, we apply collective influence algorithm to localize the influential base stations and demonstrate that some low-degree BSs may outrank BSs with larger degree."
  },
  {
    "year": "2017",
    "abstract": "This paper considers electromagnetic compatibility (EMC) aspects in the context of power line communication (PLC) systems. It offers a complete overview of both narrow band PLC and broad band PLC EMC norms. How to interpret and translate such norms and measurement procedures into typical constraints used by designers of communication systems is discussed. In particular, the constraints to the modulated signal spectrum are considered and the ability of pulse shaped OFDM (PS-OFDM), used in most of the PLC standards as IEEE P1901 and P1901.2, to fulfill them is analyzed. In addition, aiming to improve the spectrum management ability, a novel scheme named pulse shaped cyclic block filtered multitone modulation (PS-CB-FMT) is introduced and compared to PS-OFDM. It is shown that PS-CB-FMT offers better ability to fulfill the norms which translates in higher system capacity."
  },
  {
    "year": "2017",
    "abstract": "Sparsity is one of the key concepts that allows the signal recovery at a significantly lower subsample rate than required by the Nyquist-Shannon sampling theorem. By using a multistate transform, such as wavelets and shearlets system, the sparse representation of signals can be obtained. To further exploit the sparsity of the reconstructed signal, a generalized gradient regularizer is introduced to the proposed model. Motivated by the idea of iterative support detection (ISD), an optimization algorithm framework for image deblurring is given. The algorithm aims to solve a reweightedℓ0-minimization problem in split Bregman framework, and the weights used for the next iteration are decided by an ISD process. The advantage of this process is that it forms an iterative-feedback mechanism, which improves the effectiveness for solution searching. A series of experiments are presented to demonstrate the availability of the proposed framework. Experimental results show that this method yields significant improvement in peak signal-to-noise ratio when compared to other counterparts. However, the numerical experiments also show that more computing time is required due to the utilization of the redundant multiscale system."
  },
  {
    "year": "2017",
    "abstract": "In this paper, relative motion model and control strategy for autonomous fixed-wing unmanned aerial vehicle (UAV) carrier landing are addressed. First, a coupled six-degrees-of-freedom (6-DOF) non-linear relative motion model is established from 6-DOF UAV and carrier models. Second, because of the under-actuated characteristic of two vehicles, the 6-DOF relative motion model is simplified to a four-degree-of-freedom (4-DOF) model to facilitate the control design. Third, an adaptive sliding mode control law is proposed to track desired landing trajectory and maintain constant relative pitch and roll angles. Finally, simulation results demonstrate the effectiveness of the proposed control method."
  },
  {
    "year": "2017",
    "abstract": "To overcome the constraint of spectrum heterogeneity, i.e., different spatial locations may have different available spectrum resources, nodes in a multi-channel ad hoc network (MCAHN) should exchange necessary control information. To facilitate this exchange, this paper first develops a novel distributed mechanism for MCAHNs to randomly aggregate the topology and spectrum information (TSI) of all network nodes into a unique one, then proposes two heuristic algorithms for the randomly selected node to perform clustering by solving a constrained set covering problem (SCP), and finally establishes a Hamiltonian cycle over the resulting clusters to afford an ordered flow of inter-cluster control information. Numerical simulation shows that, compared with the existing mechanisms under heterogeneous spectrum availability, the proposed distributed mechanism of information aggregation is more efficient in both time and energy consumption, while the proposed SCP-based clustering algorithms yield a better tradeoff between the efficiency and robustness for cluster-based control information exchange. Moreover, compared with the existing mechanism of control information exchange, the proposed mechanism based on a cluster-based Hamiltonian cycle incurs less packet collisions as well as shorter time delay and is more suitable to provide the quality of service guarantee for various types of traffic."
  },
  {
    "year": "2017",
    "abstract": "This article claims, an investigation on compact ultrathin triple band polarization independent metamaterial absorber for microwave frequency applications. The proposed absorber unit cell consist of two resonators named as Structure-A and Structure-B. Both the resonators are printed on the upper surface of dual side copper coated FR-4 epoxy glass substrate of thickness 0.8 mm. The proposed absorber structure offers three distinct absorption peaks of 99.67%, 99.48%, and 99.42% with FWHM bandwidth of 170 MHz (4.11-4.28 GHz), 350 MHz (9.17-9.52 GHz), and 480 MHz (11.24-11.72 GHz) at 4.19 GHz, 9.34 GHz, and 11.48 GHz, respectively, under normal incidence. In addition to above, the four fold symmetry of proposed absorber structure make it polarization independent. Proposed absorber structure also offers more than 80% absorptivity at different angle of incidence (up to 60°) under transvers electric and transvers magnetic polarization states. The designed absorber unit cell has compactness of 0.11 λ0× 0.11 λ0with ultra-thin thickness of 0.0111 λ0, where λ0is the free space wavelength with respect to the lowest absorption peak of 4.19 GHz. Absorption mechanism of proposed unit cell has been discussed with the help of normalized input impedance, electric field distribution, and surface current density plots. In order to discuss the metamaterial property of proposed absorber unit cell dispersion diagram has been shown."
  },
  {
    "year": "2017",
    "abstract": "Multi-label learning plays a critical role in the areas of data mining, multimedia, and machine learning. Although many multi-label approaches have been proposed, few of them have considered to de-emphasize the effect of noisy features in the learning process. To address this issue, this paper designs a new method named representative multi-label learning algorithm. Instead of considering all features, the proposed algorithm focuses only on the representative ones, via incorporating an affinity propagation algorithm, kernel formulation, and a multi-label support vector machine into the learning framework. Specifically, it first adopts an affinity propagation algorithm to select a set of representative features and capture the relationships among features. Then, the algorithm constructs the representative kernel functions to measure the similarity between data instances. Finally, a multi-label support vector machine is applied to solve the learning problem. Based on the representative multi-label learning algorithm, we further design a representative multi-label learning ensemble framework to improve the accuracy, stableness, and robustness. Experimental results show that the proposed algorithm works well on most of the datasets and outperforms the compared multi-label learning approaches."
  },
  {
    "year": "2017",
    "abstract": "The proliferation of smartphones has significantly facilitated people's daily life, and diverse and powerful embedded sensors make smartphone a ubiquitous platform to acquire and analyze data, which may also provide great potential for efficient human activity recognition. This paper presents a systematic performance analysis of motion-sensor behavior for human activity recognition via smartphones. Sensory data sequences are collected via smartphones, when participants perform typical and daily human activities. A cycle detection algorithm is applied to segment the data sequence for obtaining the activity unit, which is then characterized by time-, frequency-, and wavelet-domain features. Then both personalized and generalized model using diverse classification algorithms are developed and implemented to perform activity recognition. Analyses are conducted using 27 681 sensory samples from 10 subjects, and the performance is measured in the form of F-score under various placement settings, and in terms of sensitivity to user space, stability to combination of motion sensors, and impact of data imbalance. Extensive results show that each individual has its own specific and discriminative movement patterns, and the F-score for personalized model and generalized model can reach 95.95% and 96.26%, respectively, which indicates our approach is accurate and efficient for practical implementation."
  },
  {
    "year": "2017",
    "abstract": "In energy harvesting communications, the transceivers have to adjust the data transmission to the energy scavenged during the course of communication. The performance of the transmission depends on the channel conditions, which vary randomly due to mobility and environmental changes. In this paper, we consider the problem of power allocation, considering the energy arrivals over time and the quality of channel state information (CSI) measured at the transmitter, in order to maximize the throughput. Differently from previous work, we focus on energy harvesting communications where the CSI at the transmitter is not perfect and may include estimation errors. In this paper, we introduce a Markov process that models the energy arrival process. Indeed, we solve the throughput maximization problem with respect to energy harvesting constraints. We show that the optimal online power policy can be found using dynamic programming. Furthermore, we study the asymptotic behavior of the communication system at low and high average recharge rate regime. Selected numerical results are provided to support our analysis."
  },
  {
    "year": "2017",
    "abstract": "The increasing complexity of the manufacturing industry demands computer numerical control (CNC) machining, a massively used process that is equipped with an intelligent feature. Not only does its control function revitalize competition in a sustainable manufacturing ecosystem but also advances the Industry 4.0 readiness. This paper develops an intelligent computer-aided process planning (i-CAPP) based on two widely accepted performance measures: manufacturability and efficiency. Machine tapping is a very popular CNC machining process making threaded holes, from which there is an investigation of two manufacturability scenarios. The first scenario deals with all holes with the same size that undergo the same operation (OP). The second one handles the groups of holes with different sizes machined by various OPs. Meanwhile, the study of efficiency focuses on point-to-point drilling, tapping, and chamfering. This research work verifies such indicators by proposing hybrid-two-stage optimization algorithms: 1) traveling salesman problem and 2) innovative Tabu Search. The i-CAPP verification of both indicators was confirmed in an application with a five-axis CNC tapping machine to realize the Industry 4.0 readiness. Extensions of the research in the pursuit of higher intelligent manufacturing platforms are discussed."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) is a network of all devices that can be accessed through the Internet. These devices can be remotely accessed and controlled using existing network infrastructure, thus allowing a direct integration of computing systems with the physical world. This also reduces human involvement along with improving accuracy and efficiency, resulting in economic benefit. The devices in IoT facilitate the day-to-day life of people. However, the IoT has an enormous threat to security and privacy due to its heterogeneous and dynamic nature. Authentication is one of the most challenging security requirements in the IoT environment, where a user (external party) can directly access information from the devices, provided the mutual authentication between user and devices happens. In this paper, we present a new signature-based authenticated key establishment scheme for the IoT environment. The proposed scheme is tested for security with the help of the widely used Burrows-Abadi-Needham logic, informal security analysis, and also the formal security verification using the broadly accepted automated validation of Internet security protocols and applications tool. The proposed scheme is also implemented using the widely accepted NS2 simulator, and the simulation results demonstrate the practicability of the scheme. Finally, the proposed scheme provides more functionality features, and its computational and communication costs are also comparable with other existing approaches."
  },
  {
    "year": "2017",
    "abstract": "Motivated by the success of student-centered language-learning tools and data-driven platforms commonly found in popular commercial and entertainment platforms, we present a new adaptive educational web platform for engineering students. The presented adaptive education platform (ADEPT) focuses on personalizing learning in large college classes by enabling proactive and continuous student engagement. In this paper, we present the principles, implementation strategies, and initial results obtained by working with an early version of ADEPT in a required sophomore-level circuits course at Purdue University. Initial results underline the potential of this web tool to identify the challenging concepts for students as well as prepare instructors to modify the way concepts are presented to the students. In addition, ADEPT helps to reveal the student engagement habits and studying patterns that may not be easily identifiable through other means, such as self-reporting."
  },
  {
    "year": "2017",
    "abstract": "During the lifecycle of a software system, software patches are committed to software repositories to fix discovered bugs or append new features. Unfortunately, the patches may bring new bugs or vulnerabilities, which could break the stability and security of the software system. A study shows that more than 15% of software patches are erroneous due to poor testing. In this paper, we present a novel approach for automatically determining whether a patch brings new vulnerabilities. Our approach combines symbolic execution with data flow analysis and static analysis, which allows a quick check of patch-related codes. We focus on typical memory-related vulnerabilities, including buffer overflows, memory leaks, uninitialized data, and dangling pointers. We have implemented our approach as a tool called KPSec, which we used to test a set of real-world software patches. Our experimental results show that our approach can effectively identify typical memory-related vulnerabilities introduced by the patches and improve the security of the updated software."
  },
  {
    "year": "2017",
    "abstract": "This paper presents predictive drying control design for a lab-scaled industrial pneumatic conveying dryer (PDC) involves with continuous/ batch processing of powder materials. The model predictive control (MPC) is an established method for drying control in various drying applications, such as fluidized bed dryers, rotary dryer, infrared dryer, timber dryers, baker's yeast dryers and so on. But the predictive control of PDCs have not been studied in the literature, however, these dryers are widely used in food, agriculture, and chemical industries, particularly suitable for batch processing of fine grained materials. The unavailability of any suitable control oriented first principle's model of these dryers make the predictive control design and implementation issues more challenging. Existing control methods for similar drying applications use outlet material moisture as a main control variable, online measurement, of which is difficult, costly, and unreliable due to the involvement of materials in granular/powder form. In the present contribution, an innovative control oriented model of the dryer is derived from first principle's encompassing a soft sensor-based online powder-moisture measurement procedure replacing the physical moisture sensors. The proposed physical sensor-less powder moisture control strategy stands on the traditional two-layer predictive control paradigm involving detection of an economically best operating point for batch dryer operation by optimizing the various process economic objectives followed by employing a suitable state space MPC (SSMPC) law for steering the process to operate at economically best operating point. The developed control strategy has been implemented and tested under practical settings and shown its effectiveness in improving the drying performance and product quality compared with an inbuilt auto-tuned proportional integral plus derivative controller of Honeywell make HC900 programmable logic controller."
  },
  {
    "year": "2017",
    "abstract": "The emerging ultra-dense small cell networks (UD-SCNs) will need to combat a variety of challenges. On the one hand, massive number of devices sharing the limited wireless resources renders centralized control mechanisms infeasible due to the excessive cost of information acquisition and computation. On the other hand, to reduce the energy consumption from fixed power grid and/or battery, network entities (e.g., small cell base stations and user devices) may need to rely on the energy harvested from the ambient environment (e.g., from environmental sources). However, opportunistic energy harvesting introduces uncertainty in the network operation. In this paper, we study the distributed user association problem for energy harvesting UD-SCNs. After reviewing the state-of-the-art research, we outline the major challenges that arise in the presence of energy harvesting due to the uncertainty (e.g., limited knowledge on energy harvesting process or channel profile) as well as limited computational capacities. Finally, we propose an approach based on the mean-field multi-armed bandit games to solve the uplink user association problem for energy harvesting devices in a UD-SCN in the presence of uncertainty."
  },
  {
    "year": "2017",
    "abstract": "The recently proposed principal component analysis network (PCANet) has performed well with respect to the classification of 2-D images. However, feature extraction may perform less well when dealing with multi-dimensional images, since the spatial relationships within the structures of the images are not fully utilized. In this paper, we develop a multilinear principal component analysis network (MPCANet), which is a tensor extension of PCANet, to extract the high-level semantic features from multi-dimensional images. The extracted features largely minimize the intraclass invariance of tensor objects by making efficient use of spatial relationships within multi-dimensional images. The proposed MPCANet outperforms traditional methods on a benchmark composed of three data sets, including the UCF sports action database, the UCF11 database, and a medical image database. It is shown that even a simple one-layer MPCANet may outperform a two-layer PCANet."
  },
  {
    "year": "2017",
    "abstract": "A t/s-diagnosable system, a generalization of t/t-diagnosable system, refers to such a system that all the faulty nodes of the system can be isolated within a set of size at most s in the presence of at most t faulty nodes. In this paper, the t/s-diagnosability of the hypercubes under the PMC model (the comparison model) is evaluated. First, several novel properties of hypercube are proposed, which are previously unknown in the literatures. Second, based on the above properties of hypercubes, we show that an n-dimensional (n ≥ 5) hypercube is (kn - ((k(k + 1))/2) + 1)/(kn - ((k(k + 1))/2) + k - 1)-diagnosable in terms of both the PMC and the comparison models, where 2 ≤ k ≤ n - 2. Furthermore, we introduce a fast diagnosis algorithm to isolate the faulty nodes in a subset of the system under the PMC model (the comparison model). And the time complexity of the algorithm is O(n2n) for an n-dimensional hypercube."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a miniature wearable device and a system for detecting and recording the movement and biometric information of a user during sport activities. The wearable device is designed to be worn on a wrist and can monitor skin temperature and pulse rate. Furthermore, it can monitor arm movement and detect gestures using inertial measurement unit. The device can be used for various professional and amateur sport applications and for health monitoring. Because of its small size and minimum weight, it is especially appropriate for swing-based sports like tennis or golf, where any additional weight on the arms would most likely disturb the player and have some influence on the player's performance. Basic signal processing is performed directly on the wearable device but for more complex signal analysis, the data can be uploaded via the Internet to a cloud service, where it can be processed by a dedicated application. The device is powered by a lightweight miniature LiPo battery and has about 6 h of autonomy at maximum performance."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a backscatter-assisted wireless powered communication network that includes a hybrid access point and multiple users. In conventional wireless powered communication networks with only harvest-then-transmit (HTT) mode, urgent data transmission is not possible since users need to first harvest sufficient energy before transmitting information. Backscatter communication depends on instantaneous excitation energy such that the dedicated time for harvesting energy first is not required. To improve the system performance, both HTT and backscatter modes are employed at the users in the proposed model. An optimization problem is formulated to maximize the sum-throughput by finding the optimal transmission policy, including the optimal users' working mode permutation and time allocation. Simulation results demonstrate the superiority of the proposed model."
  },
  {
    "year": "2017",
    "abstract": "Over the last few years, identity-based cryptosystem (IBC) has attracted widespread attention because it avoids the high overheads associated with public key certificate management. However, an unsolved but critical issue about IBC is how to revoke a misbehaving user. There are some revocable identity-based encryption schemes that have been proposed recently, but little work on the revocation problem of identity-based signature has been undertaken so far. One approach for revocation in identity-based settings is to update users' private keys periodically, which is usually done by the key generation center (KGC). But with this approach, the load on the KGC will increase quickly when the number of users increases. In this paper, we propose an efficient revocable identity-based signature (RIBS) scheme in which the revocation functionality is outsourced to a cloud revocation server (CRS). In our proposed approach, most of the computations needed during key-updates are offloaded to the CRS. We describe the new framework and the security model for the RIBS scheme with CRS and we prove that the proposed scheme is existentially unforgeable against adaptively chosen messages and identity attacks in the random oracle model. Furthermore, we monstrate that our scheme outperforms previous IBS schemes in terms of lower computation and communication costs."
  },
  {
    "year": "2017",
    "abstract": "Clinical practice calls for reliable diagnosis and optimized treatment. However, human errors in health care remain a severe issue even in industrialized countries. The application of clinical decision support systems (CDSS) casts light on this problem. However, given the great improvement in CDSS over the past several years, challenges to their wide-scale application are still present, including: 1) decision making of CDSS is complicated by the complexity of the data regarding human physiology and pathology, which could render the whole process more time-consuming by loading big data related to patients; and 2) information incompatibility among different health information systems (HIS) makes CDSS an information island, i.e., additional input work on patient information might be required, which would further increase the burden on clinicians. One popular strategy is the integration of CDSS in HIS to directly read electronic health records (EHRs) for analysis. However, gathering data from EHRs could constitute another problem, because EHR document standards are not unified. In addition, HIS could use different default clinical terminologies to define input data, which could cause additional misinterpretation. Several proposals have been published thus far to allow CDSS access to EHRs via the redefinition of data terminologies according to the standards used by the recipients of the data flow, but they mostly aim at specific versions of CDSS guidelines. This paper views these problems in a different way. Compared with conventional approaches, we suggest more fundamental changes; specifically, uniform and updatable clinical terminology and document syntax should be used by EHRs, HIS, and their integrated CDSS. Facilitated data exchange will increase the overall data loading efficacy, enabling CDSS to read more information for analysis at a given time. Furthermore, a proposed CDSS should be based on self-learning, which dynamically updates a knowledge model according t..."
  },
  {
    "year": "2017",
    "abstract": "As an effective nonlinear dynamic data analysis tool, kernel slow feature analysis (KSFA) has achieved great success in continuous process monitoring field during recent years. However, its application to batch process monitoring is unexploited, which is a more challenging task because of the complicated characteristics of batch process data. In this paper, we propose a novel batch process monitoring method based on the modified KSFA method, referred to as multiway global preserving kernel slow feature analysis (MGKSFA), to capture high nonlinearity and inherently time-varying dynamics of process data. In the proposed method, a two-step multiway data unfolding strategy is first utilized to convert the three-way batch process training data set into a two-way matrix. Then, the global structure preserving-based kernel slow feature analysis (GKSFA) is used to build the nonlinear statistical monitoring model, which not only explores the local dynamic data relationships but also considers the mining of global data structure information. Furthermore, a rule based on the cumulative slowness contribution is designed to determine the number of the retained slow features. Last, two monitoring statistics T2and SPE are built to detect the process faults. Two case studies, including one simple numerical nonlinear system and the benchmark fed-batch penicillin fermentation process, are used to demonstrate that the proposed MGKSFA method has the superior fault detection performance over the traditional batch process monitoring methods."
  },
  {
    "year": "2017",
    "abstract": "Recently, the sport of mountaineering is a popular leisure activity and many people may injure while mountaineering. In the year of 2014, Chen et al. suggested a cloud-based emergency response and SOS system for mountaineering travelers when they encounter dangers. Chen et al. claimed that their proposed system is secure against various known attacks and the executive performance of the system is reasonable when the protocol is implemented on the traveler's mobile device. However, in this paper, we discover that Chen et al.'s scheme is unable to protect the privacy of mountaineering travelers and the vulnerability allows a malicious attacker to spy on the electronic medical records of all mountaineering travelers by launching eavesdropping attacks. Moreover, Chen et al.'s scheme is vulnerable to off-line password guessing attack when the mobile device of the mountaineering traveler is lost or stolen by an attacker. In order to repair these shortcomings existing in Chen et al.'s scheme, we suggest an improved version of their scheme, which is provably secure in the random oracle model under the DDH and CDH problems."
  },
  {
    "year": "2017",
    "abstract": "A recommendation system provides personalized recommendations on products and services to users. In the traditional recommendation system, the user interest is regarded as constant over time, while in fact, the user interest changes over time. Hence, tracking the user interest drift becomes key in designing the dynamic recommendation system. However, it is a challenge to find an accurate and effective method that can predict the user interest drift. To solve the prediction problem of the user interest drift, this paper adopts clustering and time impact factor matrix to monitor the degree of user interest drift in the class and more accurately predict an item's rating. We add a time impact factor to the original baseline estimates and use the linear regression to predict the user interest drift. Our comparative experiments are conducted on three big data sets: MovieLens100K, MovieLens1M, and MovieLens10M. The experimental results show that our proposed approach can efficiently improve the prediction accuracy."
  },
  {
    "year": "2017",
    "abstract": "This paper investigated the problem of overall gas holdup and the oxygen mass transfer in the internal loop airlift reactor by numerical modeling and experimental validation. The population balance model (PBM) was introduced as the general model to characterize the bubble behaviors, i.e., bubble breakage and coalescence. Bubble coalescence, as a result of fluid turbulent eddy, bubble rise difference, and bubble wake entrainment, was considered in the PBM kernels. Meanwhile, bubble breakage, owing to eddy collision and large bubble instability, was included in the PBM kernels. A class method was applied to numerically solve the population balance equations. Based on the lab-scale internal loop airlift reactor, experiments and CFD simulations have been carried on simultaneously. The comparison between them demonstrated that CFD simulation results had good agreement between the experimental data and validated the effectiveness of the PBM model indirectly. Therefore, the PBM-CFD modeling provides an effective method for the problem of scale up. Finally, the flow regime transition of gas holdup difference and small bubble volume fraction are investigated in an internal loop airlift reactor."
  },
  {
    "year": "2017",
    "abstract": "Although many successful algorithms have been proposed for visual tracking, it is still a challenging task due to occlusion, scale variation, fast motion, and deformation. To handle these challenges, we propose a collaborative model and focus on three key factors: 1) an effective representation to consider appearance variations; 2) an effective application of the keypoints; and 3) an incorporation of contextual information. In this paper, we propose a novel algorithm that takes into account the three key factors based on complex cells and keypoints. The complex cells can effectively explore the contextual information at multiple scales. Meanwhile, a keypoint is an ideal local representation. Keypoints-based tracking method is used to make coarse tracking. A precise tracking-by-detection whose samples come from keypointsbased tracking is followed by considering the scale information. In addition, measurement of appearance variation is measured by matching the current inner cell with template's individualistically. In the basis of the measurement, an adaptive learning rate parameter is estimated for updating the object appearance model to avoid noises. Experimental results demonstrate that our tracker is able to handle appearance variations and recover from drifts. In conjunction with tracking acceleration modules, the proposed method performs in real time and outperforms favorably many state-of-the-art algorithms for object tracking."
  },
  {
    "year": "2017",
    "abstract": "In this paper, wireless power transfer (WPT) strategies to maximize information throughput are studied for cooperative relay systems, where the relay has to harvest energy from radio frequency signals in order to help the source transmit information to the destination. First, the performances of three basic WPT schemes, source WPT, destination WPT, and joint source and destination WPT, is analyzed. Then, for a given transmission duration, optimal transfer parameters to maximize system information throughput for these three WPT schemes are provided. With the distances from the source and destination to the relay, we propose an optimal WPT strategy and two suboptimal WPT strategies. Finally, simulation results verify the theoretical results and show that there is no one WPT scheme always achieving the best performance at various relay positions. Moreover, it is also presented that the proposed optimal WPT strategy outperforms both suboptimal strategies."
  },
  {
    "year": "2017",
    "abstract": "In wireless networks, network topology may change at any time. Therefore, topology control is one of the effective methods to get and keep the desired topology performance. The most existing topology control methods assume that nodes are altruistic. Although there are some game-based topology control schemes to stimulate cooperation between nodes, they only consider a single objective (e.g., energy consumption or network lifetime), which cannot be adaptive to the variation of demand on topology performance. To address these weaknesses, we present the notion of link lifetime and model the multi-objective weight sum of any link as the function with respect to transmission power, link delay and link lifetime. Then the proposed game-based localized multi-objective topology control ensures that the desired topology property exists in resulting topology, in which the presented Improved LOCALδ-Improvement Algorithm (LDIA) algorithm not only stimulates nodes' cooperation on topology control operation and ensures network's convergence to a steady state, but also has the better performance with respect to executing time and communication overhead than a classic algorithm, i.e., LDIA. Finally, the simulation results show that, by employing appropriate weight values, when compared with some typical schemes considering only energy efficiency, the proposed scheme is the most efficient in regard to average link delay and link lifetime. When compared with a typical scheme considering only network lifetime, the proposed scheme has advantage over average link lifetime, but it is slightly worse in terms of average link delay. Although the proposed scheme is less efficient in terms of average transmission power, where the shortage may be alleviated by adjusting weight values, it satisfies diversified demands for applications due to its flexibility."
  },
  {
    "year": "2017",
    "abstract": "Twitter sentiment analysis offers organizations ability to monitor public feeling towards the products and events related to them in real time. The first step of the sentiment analysis is the text pre-processing of Twitter data. Most existing researches about Twitter sentiment analysis are focused on the extraction of new sentiment features. However, to select the pre-processing method is ignored. This paper discussed the effects of text pre-processing method on sentiment classification performance in two types of classification tasks, and summed up the classification performances of six pre-processing methods using two feature models and four classifiers on five Twitter datasets. The experiments show that the accuracy and F1-measure of Twitter sentiment classification classifier are improved when using the pre-processing methods of expanding acronyms and replacing negation, but barely changes when removing URLs, removing numbers or stop words. The Naive Bayes and Random Forest classifiers are more sensitive than Logistic Regression and support vector machine classifiers when various pre-processing methods were applied."
  },
  {
    "year": "2017",
    "abstract": "A novel low profile broadband circularly polarized Fabry-Perot resonator antenna (CP-FPRA) with a linearly polarized feed is proposed. The goal of this antenna is to generate circular polarization with high gain level in broad bandwidth, while maintaining low profile and simple feed configuration. The proposed antenna consists of a primary radiator aligned along 45° with linear polarization, a partially reflective surface, and a nonstandard artificial magnetic conductor acting as a reflective ground plane. Its profile can be reduced to a quarter of a wavelength. Furthermore, an array antenna of 2×2 arrangement using CP-FPRA as element with a compact sequential rotation feeding scheme is also proposed and fabricated to enhance the gain and to improve the axial ratio (AR) bandwidth. The array was optimized to minimize grating lobes and reduce the sidelobe level, even though the element spacing was about two wavelengths. Reasonable agreement between the simulated and measured results is observed. The measured common bandwidth of |S11| ≤-10 dB, gain-drop ≤3 dB, and AR ≤3 dB is about 7.4%."
  },
  {
    "year": "2017",
    "abstract": "This paper considers secure transmission with the aid of a helper for finite alphabet signals in multiple-input-multiple-output multiple antenna eavesdropper networks, where the helper transmits a jamming signal along with the confidential message sent by the source node to confuse the eavesdropper. For the scenario in which the only statistical channel-state-information (CSI) of the eavesdropper links is available at the transmitter, the ergodic secrecy rate lacks closed-form expression, and the evaluation of the ergodic secrecy rate is computationally prohibitive. To address this problem, an accurate approximation of the ergodic secrecy rate is proposed to reduce the computational complexity. Utilizing this approximation of the ergodic secrecy rate, the joint optimization of precoding design and power allocation between the source and the helper is investigated to improve the ergodic secrecy rate. Furthermore, to achieve a tradeoff between computational complexity and performance, low-complexity schemes without iteration are proposed based on the analysis at extreme signal-to-noise ratio (SNR). In the low SNR regime, we prove that it is optimal to transmit confidential messages with full power, and the beamforming design is the first-order optimal precoder. At high SNR, we transform the problem of precoding design into a semi-definite programming problem, which can be efficiently solved by the interior-point method."
  },
  {
    "year": "2017",
    "abstract": "With the continuous rise in ingenious forgery, a wide range of digital audio authentication applications are emerging as a preventive and detective control in real-world circumstances, such as forged evidence, breach of copyright protection, and unauthorized data access. To investigate and verify, this paper presents a novel automatic authentication system that differentiates between the forged and original audio. The design philosophy of the proposed system is primarily based on three psychoacoustic principles of hearing, which are implemented to simulate the human sound perception system. Moreover, the proposed system is able to classify between the audio of different environments recorded with the same microphone. To authenticate the audio and environment classification, the computed features based on the psychoacoustic principles of hearing are dangled to the Gaussian mixture model to make automatic decisions. It is worth mentioning that the proposed system authenticates an unknown speaker irrespective of the audio content i.e., independent of narrator and text. To evaluate the performance of the proposed system, audios in multi-environments are forged in such a way that a human cannot recognize them. Subjective evaluation by three human evaluators is performed to verify the quality of the generated forged audio. The proposed system provides a classification accuracy of 99.2% ± 2.6. Furthermore, the obtained accuracy for the other scenarios, such as text-dependent and text-independent audio authentication, is 100% by using the proposed system."
  },
  {
    "year": "2017",
    "abstract": "Energy Internet represents a critical breakthrough that allows traditional energy to be transformed into intelligent energy. In this regard, the reliability apportionment technologies for modern products within Energy Internet deserve more attention because they can ensure the reliability optimization of different functional modules of systems. And because of the growingly serious energy crisis, environmental protection has become much more urgent, which requires industrial products to be more environmental friendly. However, traditional reliability apportionment methods can not do this. First, in design phase of product, most of them tend to ignore the environmental attributes, including carbon emissions and resource efficiency. Second, they fail to process the uncertainties of reliability apportionment, which is inevitable and important efficiently. Third, they pay insufficient attention to the correlations among product subsystems, which greatly influence the different product functions. To overcome these drawbacks, a reliability apportionment model based on the interval analysis and decision-making trial and evaluation laboratory is proposed. The validity of the proposed method is demonstrated by a case study."
  },
  {
    "year": "2017",
    "abstract": "Emotion-aware mobile applications have been increasing due to their smart features and user acceptability. To realize such an application, an emotion recognition system should be in real time and highly accurate. As a mobile device has limited processing power, the algorithm in the emotion recognition system should be implemented using less computation. In this paper, we propose an emotion recognition with high performance for mobile applications. In the proposed system, facial video is captured by an embedded camera of a smart phone. Some representative frames are extracted from the video, and a face detection module is applied to extract the face regions in the frames. The Bandlet transform is realized on the face regions, and the resultant subband is divided into non-overlapping blocks. Local binary patterns' histograms are calculated for each block, and then are concatenated over all the blocks. The Kruskal-Wallis feature selection is applied to select the most dominant bins of the concatenated histograms. The dominant bins are then fed into a Gaussian mixture model-based classifier to classify the emotion. Experimental results show that the proposed system achieves high recognition accuracy in a reasonable time."
  },
  {
    "year": "2017",
    "abstract": "Social media plays an increasingly important role in people's life. Microblogging is a form of social media which allows people to share and disseminate real-life events. Broadcasting events in microblogging networks can be an effective method of creating awareness, divulging important information, and so on. However, many existing approaches at dissecting the information content primarily discuss the event detection model and ignore the user interest which can be discovered during event evolution. This leads to difficulty in tracking the most important events as they evolve including identifying the influential spreaders. There is further complication given that the influential spreaders interests will also change during event evolution. The influential spreaders play a key role in event evolution and this has been largely ignored in traditional event detection methods. To this end, we propose a user-interest model-based event evolution model, named the hot event evolution model. This model not only considers the user interest distribution but also uses the short text data in the social network to model the posts and the recommend methods to discover the user interests. This can resolve the problem of data sparsity, as exemplified by many existing event detection methods, and improve the accuracy of event detection. A hot event automatic filtering algorithm is initially applied to remove the influence of general events, improving the quality and efficiency of mining the event. Then, an automatic topic clustering algorithm is applied to arrange the short texts into clusters with similar topics. An improved user-interest model is proposed to combine the short texts of each cluster into a long text document simplifying the determination of the overall topic in relation to the interest distribution of each user during the evolution of important events. Finally, a novel cosine measurebased event similarity detection method is used to assess correlation between events, t..."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, data is being generated, collected, and analyzed at an unprecedented scale, data integration is the problem of combining data from heterogeneous, autonomous data sources, and providing users with a unified view of integrated data. To design a data integration framework, we need to address challenges, such as schema mapping, data cleaning, record linkage, and data fusion. In this paper, we briefly introduce the traditional data integration approaches, and then, a novel graph-based data integration framework based on unified concept model (UCM) is proposed to address real-world refueling data integration problems. Within this framework, schema mapping was carried out and metadata from heterogeneous sources is integrated in a UCM. UCM has the benefits of being easy to update. It is also important for effective schema mapping and data transformation. By following the structure of UCM, data from different sources is automatically transformed into instance data and linked together by using semantic similarity computation metrics, finally the data is stored in graph database. Experiments are carried out based on heterogeneous data from refueling records, social networks of astroturfers, and vehicle trajectories. Experimental results and reference implementation demonstrations show good precision and recall of the proposed framework."
  },
  {
    "year": "2017",
    "abstract": "A wireless physical layer identification (WPLI) system aims at identifying or classifying authorized devices of different users based on the unique radio frequency fingerprints (RFFs) extracted from their radio frequency signals at physical layer. Most existing works mainly focus on demonstrating feasibility of system by presenting the classification performance of a fixed-user-number network. However, the real-world WPLI systems are expected to work in various scenarios with different scales of user numbers, dynamic changes in user numbers, and various choices of user combinations. Hence, an important question needs to be answered: what's the user number that a WPLI system can support, i.e. the user capacity, under the condition that the minimum system performance is guaranteed. In thispaper, we theoretically characterize the user capacity of WPLI. A theoretical approach is proposed based on ensemble mutual information between RFF and user identity. With this approach and one-time RFF training, the user capacity of WPLI can be characterized under various real-world constraints. Extensive experiments are conducted to validate the accuracy and tightness of the theoretically derived WPLI user capacity."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a mathematical model for vehicle-to-vehicle frontal crash is developed. The experimental data are taken from the National Highway Traffic Safety Administration. To model the crash scenario, the two vehicles are represented by two masses moving in opposite directions. The front structures of the vehicles are modeled by Kelvin elements, consisting of springs and dampers in parallel, and estimated as piecewise linear functions of displacements and velocities, respectively. To estimate and optimize the model parameters, a genetic algorithm approach is proposed. Finally, it is observed that the developed model can accurately reproduce the real kinematic results from the crash test."
  },
  {
    "year": "2017",
    "abstract": "This research was performed to investigate the ability of transcranial magnetic stimulation (TMS) to evoke the deeper areas of the brain with a minimal impact on non-target areas. To reach this goal, a novel core design in a semi-hexagonal shape with the arrow tips was utilized to collect a magnetic field in the selected target region. In addition, a new circuit topology was presented to generate stimulative pulses with optimal amplitude, frequency, and duration. For the first time in this research voxel resolution was proposed and exploited to evaluate the TMS system accuracy. To study the induced potential in different parts of the brain and its related resolution, a custom-made recording electrode and a micromanipulator were employed. They provided the linear movement in all Rostral/Caudal, Dorsal/Ventral, and Medial/Lateral orientations. The ARM cortex-M microcontroller managed the stimulation and recording sessions. After performing the finite element analysis, the researcher developed a prototype of the proposed system and tested it in vivo on the intact WAG/Raj rat. The results showed that spatial resolution could be significantly enhanced by employing the proposed TMS concept. The outcome of animal trials have raised some hopes to apply the knowledge of this article in the clinical contexts."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the coexistence between two key enabling technologies for fifth generation (5G) mobile networks, non-orthogonal multiple access (NOMA), and millimeter-wave (mmWave) communications. Particularly, the application of random beamforming to mmWave-NOMA systems is considered in order to avoid the requirement that the base station know all the users' channel state information. Stochastic geometry is used to characterize the performance of the proposed mmWave-NOMA transmission scheme by using key features of mmWave systems, i.e., that mmWave transmission is highly directional and potential blockages will thin the user distribution. Two random beamforming approaches that can further reduce the system overhead are also proposed, and their performance is studied analytically in terms of sum rates and outage probabilities. Simulation results are also provided to demonstrate the performance of the proposed schemes and verify the accuracy of the developed analytical results."
  },
  {
    "year": "2017",
    "abstract": "In Long-Term Evolution (LTE) and beyond systems, radio resource scheduling mechanism plays one of the main roles in system performance maximization. From this perspective, due to the conflicting quality requirements of different traffic types, providing a compromise among all performance targets for heterogeneous traffic is difficult. Moreover, the centralized scheduling mechanism for the ever growing number of users along with the massive variety of services, especially in overload states, is infeasible due to the extensive cost of information acquisition and computations. In this paper, we design resource scheduling policies for supporting the efficient delivery of heterogeneous traffic in overload states of a cell. To this end, we cast the class-based bearer-level resource distribution problem as a Proportional Fractional Knapsack model. The objective of the formulated problem is to meet Quality of Service (QoS) requirements and provide fairness for all standardized service classes. Since the solution of this problem is computationally expensive, due to the uncertainty and limited information on network and user operation, we develop a Gaussian-based analytical model and drive a formula for simplified computation of the weight of service bearers. Then, we propose Proportional Fractional Knapsack algorithm for guaranteeing effective utilization of resources for heterogeneous traffic. Finally, performance evaluation results are provided and demonstrate that the proposed scheduling approach can provide a significant level of fairness, in balance with the QoS and throughput performance targets, comparable with optimal ones."
  },
  {
    "year": "2017",
    "abstract": "We consider the capacity region of a K-user multiple-access channel (MAC) with energy harvesting transmitters. Each user stores and schedules the randomly arriving energy using an energy buffer. Users can also perform energy cooperation by transmitting energy to other users or receiving energy from them. We derive the capacity region of this channel and show that: 1) the capacity region coincides with that of a traditional K-user Gaussian MAC with energy cooperation, where the average power constraints equal to the battery recharging rates of the energy harvesting case and 2) each rate on the capacity region boundary can be achieved using the save-and-forward power control and a fixed energy cooperation policy."
  },
  {
    "year": "2017",
    "abstract": "Hadoop is the most popular implementation framework of the MapReduce programming model, and it has a number of performance-critical configuration parameters. However, manually setting these parameters to their optimal values not only needs in-depth knowledge on Hadoop as well as the job itself, but also requires a large amount of time and efforts. Automatic approaches have therefore been proposed. Their usage, however, is still quite limited due to the intolerably long searching time. In this paper, we introduce MapreducE Self-Tuning (MEST), a framework that accelerates the searching process for the optimal configuration of a given Hadoop application. We have devised a novel mechanism by integrating the model trees algorithm with the genetic algorithm. As such, MEST significantly reduces the searching time by removing unnecessary profiling, modeling, and searching steps, which are mandatory for existing approaches. Our experiments using five benchmarks, each with two input data sets (DS1 and 2× DS1 ) show that MEST improves the searching efficiency (SE) by factors of 1.37× and 2.18×$ on average respectively over the state-of-the-art approach."
  },
  {
    "year": "2017",
    "abstract": "Multiple transmit and receive antennas can be used to increase the number of independent streams between a transmitter-receiver pair, and/or to improve the interference resilience with the help of linear minimum mean squared error (MMSE) receivers. Typically, rank adaptation algorithms aim at balancing the tradeoff between increasing the spatial multiplexing gain through independent streams, and improving the interference resilience property. An interference aware inter-cell rank coordination framework for the future fifth generation wireless system is proposed in this paper. The proposal utilizes results from random matrix theory to estimate the mean signal-to-interference-plus-noise ratio at the MMSE receiver. In addition, a game-theoretic interference pricing measure is introduced as an inter-cell interference management mechanism to balance the spatial multiplexing versus interference resilience tradeoff. Centralized and distributed implementations of the proposed inter-cell rank coordination framework are presented, followed by exhaustive Monte Carlo simulation results demonstrating its performance. The obtained results indicate that the performance of the proposed method is up to 56% better than conventional non interference-aware schemes; and within 6% of the optimum performance obtained using a brute-force exhaustive search algorithm though it incurs much lower computational complexity."
  },
  {
    "year": "2017",
    "abstract": "Micro-blog services have become popular tools in the social networks. Online users discuss various topics in the micro-blog and some influential users can affect the opinions, attitudes, behaviors, or emotions of others. This paper proposes a user influence rank (UIRank) algorithm to identify the influential users through interaction information flow and interaction relationships among users in the micro-blog. The UIRank algorithm considers the contribution of user's tweet and the characteristics of information dissemination in the micro-blog networks and calculates user influence score iteratively by user follower graph. Experimental results show that the UIRank algorithm outperforms other existing related algorithms in the precision, recall, and F1-Measure value."
  },
  {
    "year": "2017",
    "abstract": "Publicly Verifiable Computation (PVC) enables computationally weak trusted sources to outsource several computations to some more powerful public untrusted clouds. On issuing a query, the public cloud replies the result of the function evaluation with a witness vouching for correctness of computation. This primitive requires high efficiency and public verifiability. However, existing PVC constructions all request trusted sources to know delegated function beforehand, and thus it fails to meet diverse requirements, especially outsourced target unknown need to be jointly computed among different entities in a privacy-preserving manner. To strengthen current PVC’s flexibility, we proposed a new primitive called Secure Collaborative PVC (SCPVC), where TTP is responsible only for initializing system parameter and publishing some information in its bulletin. After some rounds, the public cloud owns lots of functions outsourced in PVC ways. The private cloud works out an algebraic operation structureL, which involves some functions provided by public cloud and himself. Based onL, they jointly perform the protocol to generate the target function. At the end of the protocol, the public cloud obtains target function while not disclosing respective secrets. Due to the misbehavior of the public cloud, this mechanism allows the private cloud to check the integrity of target function and any client to verify the correctness of results. Our scheme without jointly computing is a typical existing PVC scheme. Therefore, our protocol is compatible with the prevailing publicly verifiable computation Scheme. Before investigatingSCPVC, we tailored two secure two-party polynomial computation protocols using 1-out-of-lOblivious Transfer protocol as the main building block toSCPVC. More preciously, polynomial multiplication protocol transforms two polynomials multiplication into another two addi..."
  },
  {
    "year": "2017",
    "abstract": "The increasing demand of mobile devices (MDs) for data services brings tremendous pressure to cellular networks. It has become a great challenge for traditional offloading techniques to balance the energy efficiency and quality of service. The concept of device-to-device (D2D) communication shows a huge potential in cellular offloading. In this paper, we investigate the scenario where MDs have the same demand for a common content and they cooperate to download the content by multihop relaying. We aim to minimize the total power consumption by grouping MDs in multihop D2D networks, while satisfying the minimum rate required by each MD. As the problem is NP-complete and the optimal solution cannot be found in polynomial time, we propose three greedy algorithms with different grouping strategies to trade off the performance and complexity. Simulation results demonstrate that the total power consumption can be saved significantly in the content delivery situation using cooperative D2D communication, and the proposed algorithms are suitable for static and dynamic networks with different advantages."
  },
  {
    "year": "2017",
    "abstract": "Notice of Violation of IEEE Publication Principles \"Group-Aware Delay-Constrained Video Transmission Over Multihomed Device-to-Device Networks\" by Junfei Huang and Zhaowen Lin, in IEEE Access, Volume 5, 2017, pp 2651-2664 After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE’s Publication Principles. This paper is a duplication of the original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission. \"Group-Aware Delay-Constrained Streaming in Wireless Device-to-Device Networks\" by Xiaoyi Zhang, Jiawei Liang, Jiyan Wu, and Lin Zhang, in the ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM). Submitted December 26, 2016  The technological advancements in wireless communication systems enable mobile users to leverage different radio interfaces (e.g., cellular and WiFi) for concurrent data transmission. However, the existing transmission schemes do not seriously consider the problem of real-time video multicast to a cluster of co-located multihomed mobile devices. Conventionally, each client fetches the video streaming to the best of its capability, and this results in competing resources that degrade user-perceived video quality. Several literatures investigated the problem of using cellular to obtain video contents from the remote server and sharing them through WiFi. However, the stringent delay constraint of real-time video is not addressed in these solutions. In this paper, a cooperative transmission scheme is proposed to tackle the problem. First, a mathematical framework dubbed (Group-Aware Delay-COnstraint) is developed to formulate the delay-constrained goodput maximization problem of real-time video transmission to a group of multihomed mobiles. Second, a dataflow distribution mechanism..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, filter bank-based multicarrier systems using a fast convolution approach are investigated. We show that exploiting offset quadrature amplitude modulation enables us to perform FFT/IFFT-based convolution without overlapped processing, and the circular distortion can be discarded as a part of orthogonal interference terms. This property has two advantages. First, it leads to spectral efficiency enhancement in the system by removing the prototype filter transients. Second, the complexity of the system is significantly reduced as the result of using efficient FFT algorithms for convolution. The new scheme is compared with the conventional waveforms in terms of out-of-band radiation, orthogonality, spectral efficiency, and complexity. The performance of the receiver and the equalization methods are investigated and compared with other waveforms through simulations. Moreover, based on the time variant nature of the filter response of the proposed scheme, a pilot-based channel estimation technique with controlled transmit power is developed and analyzed through lower-bound derivations. The proposed transceiver is shown to be a competitive solution for future wireless networks."
  },
  {
    "year": "2017",
    "abstract": "Since microaneurysms (MAs) can be seen as the earliest lesions in diabetic retinopathy, its detection plays a critical role in the diabetic retinopathy diagnosis. In recent years, many machine-learning methods have been developed for MA detection. Generally, MA candidates are first identified and then a set of features for these candidates are extracted. Finally, machine-learning methods are applied for candidate classification. In this paper, we present a novel unsupervised classification method based on sparse posterior cerebral artery (PCA) for MA detection. Since it does not have to consider a non-MA training set, the class imbalance problem can be avoided. Furthermore, effective features can be selected due to the characteristic of sparse PCA, which combines the elastic net penalty with the PCA. Meanwhile, a single T2statistic is introduced, and the control limit can be determined for distinguishing true MAs from spurious candidates automatically. Experiment results on the retinopathy online challenge competition database show the effectiveness of our proposed method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an event-based control strategy for mobile robots is proposed. The solution includes new features that minimize the effects of the noise on the system. Two methodologies have been developed to compensate the perturbations. To avoid the effects of such perturbations, a threshold calculator and a perturbation estimator are included in the system. The proposed system is compared with classical control systems based on discrete time. Different scenarios are analyzed in the experiments to check its performance. The stability and the improvements of the proposed control strategy are also analyzed in the experimental results."
  },
  {
    "year": "2017",
    "abstract": "Personalized recommendation and the processing of real-time data exemplify the processing of massive data which in the field of Internet-of-Things (IoT) received a great extent of attention in recent literature. The incompleteness of massive data in the IoT is widespread. Obtaining personalized information from the incomplete data set is still puzzled by searching efficient and accurate methods at present. Skyline query is a widely used data processing method, especially in the field of multi-objective decision analysis and data visualization. To eliminate the negative effects on massive data processing in IoT, a novel skyline preference query strategy based on massive and the incomplete data set is proposed in this paper. This strategy simply separates and divides massive and incomplete data set into two parts according to dimension importance and executes skyline query, respectively. The strategy mainly resolves the problem of extracting personalized information from massive and incomplete data set and improves the efficiency of skyline query on massive and incomplete data set. First, this paper presents a skyline preference query strategy based on strict clustering and implements it on dimensions that have higher importance. Second, a skyline preference query strategy based on loose clustering is implemented on dimensions that have lower importance. Finally, integrating local skyline query results, this paper calculates global skyline query results by using information entropy theory. The efficiency and effectiveness of Skyline Preference Query (SPQ) algorithm have been evaluated in terms of response time and result set size through the comparative experiments with ISkyline algorithm and sort-based incomplete data skyline algorithm. A large number of simulation results show that the efficiency of SPQ algorithm is higher than that of other common methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study a dual-rate system with fast-sampling at the input and propose a design to optimize the consecutive control signals. The objective of the optimization is to maximize the decay rate depending on the available resources to stabilize the control system faster. Stability conditions are enunciated in terms of linear matrix inequalities. The control solution is extended to time delays. A numerical example illustrates the benefits of the control proposal."
  },
  {
    "year": "2017",
    "abstract": "In the cognitive radio ad hoc networks (CRAHNs), the spectrum availability may change from time to time and hop by hop. Thereby, the performance analysis and optimization for CRAHNs become so intricate that pure divide-and-conquer strategies by layered principles strand. Focusing on the five-layer involved performance analysis of CRAHNs, we set up a cross-layer design framework mathematically and solve it through vertical decomposition approaches. After the convex relaxation, a partial Lagrangian formula, which captures network objective and constraints from the physical layer to application layer, is devised. Then, a cross-layer optimization scheme through a vertical decomposition method (COVD) is proposed, which leads to a novel cross-layer architecture. Through the dual decomposition and primal decomposition, the complex joint optimization problem is decoupled into three subproblems with control parameters flowing back and forth. Although COVD achieves the optimal solution for the joint optimization issue, it incurs high cost in terms of overhead and complexity. Furthermore, we propose a cross-layer optimization design by heuristic algorithm, which reduces the computation complexity by a step-bystep division approach. Finally, simulation results demonstrate the efficiency of the proposed schemes. Complexity analysis and violation of the current protocols are also provided."
  },
  {
    "year": "2017",
    "abstract": "Network management, planning, and optimization rely on accurate and complete traffic measurement. However, anomalies and missing data are inevitable in direct traffic measurement because of high measurement costs and unreliable network transport protocols. Existing traffic matrix estimation approaches concern only the outlier and ignore the structural anomaly, which often degrades the estimation accuracy drastically. To address this challenge, an anomaly-tolerant traffic matrix estimation approach called Simultaneously Estimate Traffic Matrix and Detect Anomaly (SETMADA) is presented. By utilizing the prior low-rank property and temporal characteristic of the traffic matrix, the traffic matrix estimation in the coexistence of the outlier and structural anomaly is formulated as a Prior Information Guided Matrix Completion (PigMaC) problem, where outlier and structural anomalies are modeled by the L1-norm and L2,1-norm, respectively. Furthermore, by employing the multi-blocks ADMM and stochastic proximal gradient descent, a scalable parallel optimization algorithm PigMaC-ADMM-S is proposed to solve the PigMaC problem. To our knowledge, SETMADA is the first approach that can simultaneously estimate the missing traffic matrix and explicitly sift outlier and structural anomalies. Simulation results demonstrate that SETMADA achieves better estimation performance compared with the state-of-the-art algorithms. In addition, SETMADA provides an accurate localization of outlier and structural anomaly, which is the prerequisite for malfunction diagnosis in the large-scale networks."
  },
  {
    "year": "2017",
    "abstract": "The cross-layering concept has enabled flexibility in sensor communication by decreasing the level of modularity through inter-layer information exchange. This has improved adaptability, reliability, and efficiency in the communication process. This is principally so, because the inter-layer information is utilized to enable the selection of nodes that are perceived to foster efficient communication. However, despite these numerous achievements, the cross-layering concept suffers immensely as a result of security attacks, which prey on nodes utilized for data forwarding. In this paper, we propose T-XLM, a trust-based cross-layering framework to provide minimal defense against security attacks. The framework introduces a fuzzy-based trust estimation mechanism, which is used to formulate imprecise empirical knowledge that is utilized for reputation building in the nodes to ensure secure forwarding and reliable delivery of data. We further proposed trust-based fuzzy implicit cross-layer protocol (TruFiX), a T-XLM inspired protocol which utilizes multiple parameters pulled through inter-layer information exchange to mitigate the effects of security threats in a network. Using extensive simulation experiments, TruFiX was compared with resource bound security solution (RBSS)-based protocols, which also achieved minimal security by altering their routing semantics. The conducted experiments evaluated the security performance of the protocols and the results showthat the proposed TruFiX significantly outperforms the RBSS-based protocols in terms of packet delivery."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a theoretical investigation of electromagnetic wave coupling and tunneling through chiral-chiral interfaces. The dispersion relation, conditions of the trapped modes, and evanescent wave coupling and tunneling in an optically active chiral slab and chiral ambient medium are derived. The transfer matrix method is developed to obtain the transmission and reflection coefficients across the chiral slab. The formation of discrete trapped modes and the continuous interval, where the discrete trapped modes are embedded, are determined by the chirality parameter of the chiral slab. The instantaneous field components, revealed via evanescent wave coupling and tunneling through the chiral slab interfaces, are also reported."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a novel Data-Flow architecture for MATLAB. This architecture provides thread-level pipelining of MATLAB functions as well as general concurrency support. The proposed approach yields a significant speedup of current MATLAB implementations that rely on streaming data or employ data-dependent operations. Following the development of increased CPU core counts, this proposed framework will provide additional benefit only as this trend continues. A performance analysis of the proposed framework is performed, and we are able to demonstrate high-level throughput gains of specific applications. Discussions on implementation guidelines, as well as limitations of the framework, are proposed in this paper. Through the use of this tool, we have demonstrated a 802.11a receiver employing Software-Defined Radio hardware running in real time. From the user's perspective, this tool requires interaction only from the MATLAB language, handling all threading and data transfer without user intervention."
  },
  {
    "year": "2017",
    "abstract": "FPGA-based accelerators have recently evolved as strong competitors to the traditional GPU-based accelerators in modern high-performance computing systems. They offer both high computational capabilities and considerably lower energy consumption. High-level synthesis (HLS) can be used to overcome the main hurdle in the mainstream usage of the FPGA-based accelerators, i.e., the complexity of their design flow. HLS enables the designers to program an FPGA directly by using high-level languages, e.g., C, C++, SystemC, and OpenCL. This paper presents an HLS-based FPGA implementation of several algorithms from a variety of application domains. A performance comparison in terms of execution time, energy, and power consumption with some high-end GPUs is performed as well. The algorithms have been modeled in OpenCL for both GPU and FPGA implementation. We conclude that FPGAs are much more energy-efficient than GPUs in all the test cases that we considered. Moreover, FPGAs can sometimes be faster than GPUs by using an FPGA-specific OpenCL programming style and utilizing a variety of appropriate HLS directives."
  },
  {
    "year": "2017",
    "abstract": "Software Defined Networks (SDN) is an emerging network architecture. It is shown that SDN can be deployed in a variety of small size networks, such as personal area networks and local area networks. Nevertheless, the deployment of SDN in large scale networks, such as wide area networks, raises a lot of concerns. In these scenarios, SDN relies on traditional hop-by-hop forwarding scheme which may lead to performance degradation due to heavy control traffic incurred and flow tables over-consumption. Source routing can be utilized to reduce control traffic and flow table consumption by installing only one flow table entry in the ingress switch and encoding complete routing path of a particular flow in the packet header. However, it will lead to severe bandwidth overhead which may also degrade network performance. In this paper, we propose an efficient forwarding scheme called Arbitrary Jump Source Routing (AJSR), which makes use of MPLS-based source routing. AJSR aims to achieve a trade-off between the control traffic overhead and the bandwidth overhead by dividing the complete routing path of a particular flow into arbitrary length sections and distributing these sections at different switches along the flow's routing path. To find the most suitable flow entry placement scheme, we formulate the flow entry placement problem as an optimization problem and present a dynamic programming solution with the objective of maximizing the overall cost saving. Through simulation experiments, we find that AJSR can effectively achieve a trade-off between the control traffic overhead and the bandwidth overhead."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the impact of asymmetric hardware distortion (HWD) on the performance of receive diversity systems using linear and Selection combining receivers. The asymmetric attribute of the proposed model motivates the employment of improper Gaussian signaling (IGS) scheme rather than the traditional proper Gaussian signaling (PGS) scheme. The achievable rate performance is analyzed for the ideal and non-ideal hardware scenarios using PGS and IGS transmission schemes for different combining receivers. In addition, the IGS statistical characteristics are optimized to maximize the achievable rate performance. Moreover, the outage probability performance of the receive diversity systems is analyzed yielding closed form expressions for both PGS- and IGS-based transmission schemes. HWD systems that employ IGS are proven to efficiently combat the self-interference caused by the HWD. Furthermore, the obtained analytic expressions are validated through Monte Carlo simulations. Eventually, non-ideal hardware transceivers degradation and IGS scheme acquired compensation are quantified through suitable numerical results."
  },
  {
    "year": "2017",
    "abstract": "MicroRNAs (miRNAs) play critical roles in many biological processes. Predicting the miRNA-disease associations will aid in deciphering the underlying pathogenesis of human polygenic diseases. However, existing in silico prediction methods typically utilize a single or limited data sources for disease-related miRNA prioritization and most of the methods are biased toward known miRNA-disease associations. Due to the insufficient number of experimentally validated interactions as well as no experimentally verified negative samples, obtaining remarkable performances is still challenging for these methods. In this paper, we present a semi-supervised method of Kronecker regularized least squares for predicting the potential or missing miRNA-disease associations (KRLSM). KRLSM integrates different omics data to assist various diseases or miRNAs with sparsely known associations to make predictions, and combines the disease space and miRNA space into a whole miRNA-disease space by Kronecker product. Finally, the semi-supervised classifier of regularized least squares is adopted to identify disease-related miRNAs. The experiment results demonstrate that the proposed method outperforms the other state-of-the-art approaches. In addition, case studies of several common diseases further indicate the effectiveness of KRLSM to identify potential miRNA-disease associations."
  },
  {
    "year": "2017",
    "abstract": "Managing resources in dynamic vehicular environments is a tough task, which is becoming more challenging with the increased number of access technologies today available in connected cars (e.g., IEEE 802.11, LTE), in the variety of applications provided on the road (e.g., safety, traffic efficiency, and infotainment), in the amount of driving awareness/coordination required (e.g., local, context, and cooperative awareness), and in the level of automation toward zero-accident driving (e.g., platooning and autonomous driving). The open programmability and logically centralized control features of the software-defined networking (SDN) paradigm offer an attractive means to manage communication and networking resources in the vehicular environment and promise improved performance. In this paper, we enumerate the potentials of software-defined vehicular networks, analyze the need to rethink the traditional SDN approach from theoretical and practical standpoints when applied in this application context, and present an emulation approach based on the proposed node car architecture in Mininet-WiFi to showcase the applicability and some expected benefits of SDN in a selected use case scenario."
  },
  {
    "year": "2017",
    "abstract": "This paper presents location-aware speakers for the immersive virtual reality environments as well as conventional surround sound systems. The surround sound system generally requires multiple speakers fixed in specific positions and connected to dedicated audio jack holes. In this paper, we propose wireless speakers that can aware their locations and dedicated sound channels without troublesome installations. The proposed speakers use the Internet of things devices by combining a Raspberry Pi and a beacon to each speaker, which enable smart and connected applications. Each speaker estimates distances to other speakers from received signal strength indication of beacons with bluetooth low energy signals. By analyzing the relative distances between speakers, we detect the speaker locations in various speaker setups. We experimented our method with three sound system formats in various sizes and analyzed the accuracy of the location detection."
  },
  {
    "year": "2017",
    "abstract": "To increase the reliability of aerospace electronics and reduce their overall power consumption, we investigated the possibility of incorporating active thermoelectric cooling (TEC) solutions. The harsh avionic environment demands sophisticated active control schemes that enable the achievement of high coefficient of performance. The positive effect of active PWM control has been validated both in simulation and on a working laboratory prototype that allowed us to clarify the pros and cons of the incorporation of TEC techniques in avionics applications. This paper has been performed under the framework of CLEAN SKY-THERMICOOL project."
  },
  {
    "year": "2017",
    "abstract": "Energy harvesting (EH) is a prominent method to extend the operation time of energy-limited wireless networks. By integrating EH into wireless communications, the same spectrum is able to be used by simultaneous wireless information and power transfer (SWIPT) without affecting the quality of service. In this paper, we propose a joint subcarrier and power allocation-based SWIPT scheme in orthogonal frequency division multiplexing (OFDM) systems. Specifically, the received OFDM subcarriers are partitioned into two groups. A fraction of the received subcarriers are allocated to form one group, which is used for information decoding (ID), and the remaining subcarriers form the other group, which is used for energy harvesting. Thus, no splitter is needed at the receiver. A joint subcarrier and power allocation problem is formulated to maximize the harvested energy, subject to the ID constraint. By using the dual decomposition method, an efficient algorithm is proposed to solve this joint resource allocation problem."
  },
  {
    "year": "2017",
    "abstract": "The advancements in multi-core central processing units have attracted new designs ranging from mechanisms of packing higher number of transistors into the small space, new techniques for communications (e.g., wireless network on chips), or new methodologies for cooling the chip. The latter two design aspects are the focus of this paper, where a microfluidic system is utilized for performing both functions. The miniaturization of microfluidic channels makes it attractive to embed them into the chips to transport fluids that can remove the heat from the processor cores. The extension of the cooling purpose of on-chip microfluidic channels is done by integrating communication feature. The communication process is achieved by transporting fluid through the channel and injecting information through air droplets. Protocols for microfluidic communications are applied, including physical layer functionalities and medium access protocols. The protocol design takes into considerations various properties of the microfludics. Based on the proposed system, the tradeoffs between the data rate and its impact on the amount of heat that can be removed from the processor are evaluated. This system provides new forms of condensed processor design of the future, in which integration of multiple functionalities of microfluidic channel system embedded into multi-core processors."
  },
  {
    "year": "2017",
    "abstract": "Smart cities take advantage of recent Information and Communication Technology (ICT) developments to provide added value to existing public services and improve quality of life for the citizens. The Internet of Things (IoT) paradigm makes the Internet more pervasive where objects equipped with computing, storage, and sensing capabilities are interconnected with communication technologies. Because of the widespread diffusion of IoT devices, applying the IoT paradigm to smart cities is an excellent solution to build sustainable ICT platforms. Having citizens involved in the process through mobile crowdsensing (MCS) techniques augments capabilities of these ICT platforms without additional costs. For proper operation, MCS systems require the contribution from a large number of participants. Simulations are therefore a candidate tool to assess the performance of MCS systems. In this paper, we illustrate the design of CrowdSenSim, a simulator for mobile crowdsensing. CrowdSenSim is designed specifically for realistic urban environments and smart cities services. We demonstrate the effectiveness of CrowdSenSim for the most popular MCS sensing paradigms (participatory and opportunistic), and we present its applicability using a smart public street lighting scenario."
  },
  {
    "year": "2017",
    "abstract": "The deployment of heterogeneous networks (HetNets) inevitably demands the design of interference management techniques to elevate the overall network performance. This paper presents a novel interference mitigation technique known as reverse frequency allocation (RFA), which provides an efficient resource allocation compared with the other state-of-the-art techniques. RFA reverses the transmission direction of interferers, thereby minimizing the cross-tier interference. Eventually, better coverage as well as increased data rates are achieved by providing complementary spectrum to the macro and pico users. In this paper, we present a tractable approach for modeling HetNets under the proposed RFA scheme. Specifically, we employ well known tools from stochastic geometry to derive closed-form expressions for the coverage probability and rate coverage in two-tier cellular network employing RFA and its variants. The modeling is performed using two approaches; first, where the base stations and users are modeled as independent Poisson point processes (PPPs) and second, the interference is approximated using the fluid model. It is shown that the results obtained from the PPP model are accurate for higher values of path loss exponents, while the results from fluid model are useful for smaller values of path loss exponents. The plausibility of model is validated through the Monte-Carlo simulations and the network performance is evaluated in terms of coverage probability, coverage rate, and outage capacity. The results demonstrate that 2-RFA yields outage capacity gains of 13% as compared with the soft fractional frequency reuse scheme, whereas, the performance gains can be further improved by 14% by employing the proposed variants of RFA."
  },
  {
    "year": "2017",
    "abstract": "Fog and dust are used to be considered as major performance degrading factors for free space optic (FSO) communication links. Despite the number of field measurements, performed in foggy environments during the last decades, most of the proposed channel attenuation models are deterministic, i.e., assumed the channel attenuation constant over time. Stochastic behavior of the channel is still understudied. In this paper, we investigate the probabilistic behavior of the FSO channel in fog and develop a new statistical model for the signal attenuation. Moreover, we derive a probability distribution function (PDF) for the channel state. Using this PDF, we study the FSO system performance considering various metrics including average signal-to-noise ratio, average bit error rate, channel capacity, and probability. of outage Closed form expressions are derived for the average SNR and outage probability. We found acceptable performance with moderate and light fog. However, under thick and dense fog, the system performance poorly deteriorates. Finally, we derived closed form expressions for the average attenuation-distance product and the link availability that will potentially be very helpful for network design and planning."
  },
  {
    "year": "2017",
    "abstract": "Multiple-input-multiple-output (MIMO) radar image processing presents problems difficult to address by modifying conventional monostatic radar methods as Fourier range migration. When the distance between the transmitter and receiver is comparable to the target size, the single phase center approximation is not accurate. Furthermore, if the antenna radiation pattern significantly deviates from a spherical wave, the symmetries assumed in most range migration techniques are violated. We present a rapid Fourier-based MIMO reconstruction called Fourier accelerated multistatic imaging (FAMI) suitable for massively parallel computation that accounts for frequency-dependent radiation patterns, does not require the single phase center approximation, and is able to dynamically adapt to different target support volume shapes. FAMI is especially suitable for frequency-diversity antenna systems that use spectrally modulated coded spatial radiation patterns."
  },
  {
    "year": "2017",
    "abstract": "As an important part of the Internet of Energy, a complex access environment, flexible access modes and a massive number of access terminals, dynamic, and distributed mass data in an active distribution network will bring new challenges to the security of data transmission. To address the emerging challenge of this active distribution network, first we propose a content filtering function mining algorithm based on simulated annealing and gene expression programming (CFFM-SAGEP). In CFFM-SAGEP, genetic operation based on simulated annealing and dynamic population generation based on an adaptive coefficient are applied to improve the convergence speed and precision, the recall and the Fβmeasure value of the content filtering. Finally, based on CFFM-SAGEP, we present a distributed mining for content filtering function based on simulated annealing and gene expression programming (DMCF-SAGEP) to improve efficiency of content filtering. In DMCF-SAGEP, a local function merging strategy based on the minimum residual sum of squares is designed to obtain a global content filtering model. The results using three data sets demonstrate that compared with traditional algorithms, the algorithms proposed demonstrate strong content filtering performance."
  },
  {
    "year": "2017",
    "abstract": "To cope with the ongoing changing demands of the internet, `in-network caching' has been presented as an application solution for two decades. With the advent of information-centric network (ICN) architecture, `in-network caching' becomes a network level solution. Some unique features of the ICNs, e.g., rapidly changing cache states, higher request arrival rates, smaller cache sizes, and other factors, impose diverse requirements on the content eviction policies. In particular, eviction policies should be fast and lightweight. In this paper, we propose cache replication and eviction schemes, conditional leave cope everywhere (CLCE) and least frequent recently used (LFRU), which are well suited for the ICN type of cache networks (CNs). The CLCE replication scheme reduces the redundant caching of contents; hence improves the cache space utilization. LFRU approximates the least frequently used scheme coupled with the least recently used scheme and is practically implementable for rapidly changing cache networks like ICNs."
  },
  {
    "year": "2017",
    "abstract": "The mobile industry's evolution from 4G to 5G will lead to a deep progress on mobile applications that are widely used in some new environments, such as vehicular social networks (VSNs). In VSNs, which are considered the first automobile social networks, vehicular communication can facilitate large-scale data sharing between drivers and their neighbours. However, malicious users of VSNs can also disseminate false information over the network. Traditional public key infrastructure (PKI) cannot recognize these malicious users, as they all have authorized identities. Thus, a trust management mechanism is introduced to secure vehicular social data. This paper demonstrates a high-level trust management model and its deployment scheme based on a vehicular cloud system. We propose a layered trust management mechanism that benefits from efficient use of physical resources (e.g., computing, storage, communication cost) and explore its deployment in a VSN scenario based on a three-layer cloud computing architecture. Moreover, performance modeling of the proposed trust management scheme is conducted through a novel formal compositional approach - Performance Evaluation Process Algebra (PEPA). PEPA has superior features in compositionality and parsimony, which means that it can efficiently model systems with layered architectures and complex behaviours. PEPA also supports various numerical analyses through calculating its underlying continuous time Markov chains (CTMCs) directly or solving a set of approximated ordinary differential equations (ODEs). According to analysis outcomes, we analyzed several key performance properties of the scheme and related capacity issues in deployment. The findings also reveal an efficient investigation approach for evaluating the performances of trust models."
  },
  {
    "year": "2017",
    "abstract": "Modern wireless communication systems typically employ multiple frequency bands for several standards. A new class of miniaturized ring filters with tuning capability is introduced for this purpose. The proposed filter structure is based on a single multi-mode resonator with variable section impedances in microstrip technology. The bandwidth of the filter can be significantly extended to cover the whole ultra wideband (UWB) frequency range with high adjustability. Moreover, a tunable bandnotch is introduced within the filter response, which can be arbitrarily placed according to the required application. Varactor and PIN diodes are also utilized to facilitate a high tuning capability throughout the different filter characteristics with respect to bandwidth, center frequency, and bandnotch frequency. Based on the symmetry of the filter, even-odd mode analysis is applied to investigate the different filter design characteristics. In addition, a comprehensive transmission line model is investigated within this paper which showed excellent agreements with full-wave simulations and measurements. The implemented UWB filter is investigated with respect to its frequency-domain characteristics and group delay response. The realized filter has a fractional bandwidth of more than 119% with a low group delay. All measured results are in a very good agreement with analysis and simulations. The overall filter dimensions, including housing, do not exceed 25 mm× 25 mm."
  },
  {
    "year": "2017",
    "abstract": "The attraction repulsion (AR) model has been a common mathematical framework to emulate the interactions among mobile agents and to design rigid flocking laws. A main drawback of the AR model is that environment effects are not taken into account in the model. This means that rigid flocking laws can not react to the change of environments. In this paper, we make an attempt to design flocking systems that are adaptive to the change of communication environments. The flocking system is modeled as a cyber-physical system, where the cyber layer and control layer are designed systematically. In the cyber layer, a new interaction model is proposed by considering communication parameters of the environment. In the control layer, distributed controllers are designed for mobile agents with switching topology using the proposed interaction model. It is shown that the proposed flocking law can react to change of communication environments and guarantee the optimal communication link between agents. The stability and convergence of the flocking system are analyzed with nonsmooth techniques. Numerical simulations are provided to illustrate the effectiveness of the design."
  },
  {
    "year": "2017",
    "abstract": "Phase holdup measurement of the two-phase flow is of significance in industrial process. Accurate and real-time measurement of phase holdup is a critical problem requiring urgent solutions. Conductance sensors determine the flowparameters by detecting the change of electrical parameters. Kalman filter is widely applied in state estimation, and oil-water two-phase flow holdup measurement is considered as a state estimation problem in this paper. By using upstream and downstream measuring fluctuation information, an adaptive Kalman estimation model based on discrete cross-correlation with adaptive state transition matrix, and a serial estimation model based on unscented Kalman filter carrying out linear and nonlinear estimations successively are proposed combining with specific flow state. The proposed methods have been validated by online experiments, and the average error of phase holdup estimate is 1.5%."
  },
  {
    "year": "2017",
    "abstract": "Cloud storage systems frequently have a large user base that requires huge cloud resources. Sometimes, cloud devices become overloaded because of an imbalance in input/output (I/O) or space demand. How can data with different popularity be distributed over heterogeneous devices? The key to resolving this problem is to balance the workload of multi-dimension resources. A consistent hash-aware cloud storage system constitutes a good solution for data placement. It can achieve only 1-D balance, usually the balance of the space resource. However, it is not straightforward to obtain a balance of space, I/O, and other resources simultaneously. Many users have experienced the overloading of devices in these systems. We focus mainly on this problem in this paper. In this paper, we discuss the factors that cause the overload of devices that occurs in the hash-aware cloud. Furthermore, we design some schemes with three algorithms to facilitate the assignment of hybrid data of different size and popularity to the heterogeneous cloud. The system can reduce the probability of an overload occurring. Most systems do not easily accommodate the movement of data. However, we argue that relocating part of the necessary data is helpful. This relocation can achieve a balance of resource usage and use fewer resources, without the need for replicas. Our system can provide a better quality of service, because the imbalance in the usage of resources is reduced. We performed an evaluation using extensive simulations driven by real-world traces. We demonstrate that our system can effectively reduce the overload probability of devices in cloud storage systems."
  },
  {
    "year": "2017",
    "abstract": "In wireless networks, the performance is degraded by the intensity of the interference received from concurrent transmissions. Considering a stochastic cache-enabled network where some users have caching ability to store the most popular packets, we propose a novel interference management scheme to eliminate the interference by exploiting the content diversity. First, cache-enabled users can exploit cached packets as side information to cancel the interference. Second, considering that different access points may transmit the same contents to different users simultaneously, they should be regarded as useful signals rather than interference. The performance improvement with these two content diversity schemes is theoretically analyzed in this paper. The probabilities for the interference cancellation case and the signal enhancement case are derived, respectively, followed by the investigation of the signal to interference plus noise ratio improvement with our proposed content diversity schemes. Based on this, the effective content capacity of the system is analyzed. In addition to the simulations to validate the accuracy of the theoretical analysis, the impacts of caching ability and the proposed interference management schemes on the effective content capacity are investigated."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we focus on the issue of energy efficiency (EE) optimization of amplify-and-forward-based energy harvesting two-way relaying systems. Utilizing the statistical channel state information, we first build a statistical EE model, which is applicable to practical environments under fast fading channels. Then, a power allocation problem is formulated to maximize the EE under the constraints of total power and sum rate. Particularly, we have taken the asymmetric traffic requirements into account in our design, considering that the two sources may have different data rates. With the help of nonlinear fractional programming and Karush-Kuhn-Tuchker conditions, closed-form solution is achieved, thus providing valuable guidelines into practical system designs. For wider applications, we have shown that our results can be extended to multi-relay multi-user scenarios. Simulation results highlight the effect of our analytical results."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider a wireless powered communication (WPC) network consisting of one hybrid access point (H-AP) and K wireless nodes. The H-AP broadcasts wireless energy to nodes in the downlink and receives information from K nodes abided by TDMA protocol in the uplink. The wireless nodes have energy harvesting capabilities and can harvest energy from H-AP and other nodes in different assigned time slots. We propose two new schemes for the WPC network that perform energy harvesting among peer nodes. In the first scheme, each wireless node harvests energy from peer nodes transmitting in the previous time slots, while each wireless node harvests energy from all nodes in the second scheme. The maximization of the sum achievable throughput and the minimization of the required harvested energy are studied. An effective heuristic optimization algorithm is proposed to solve them. The contribution of this work includes the proposal of two new peer harvesting schemes, the formulation of two relevant optimizations and their solutions using heuristic optimization algorithm, which has better technical adaptability for solving complicated objective functions. Simulation results demonstrate the effectiveness of the proposed schemes in WPC networks."
  },
  {
    "year": "2017",
    "abstract": "Designing lightweight security protocols for cloud-based Internet-of-Things (IoT) applications for battery-limited mobile devices, such as smart phones and laptops, is a topic of recent focus. Ciphertextpolicy attribute-based encryption (CP-ABE) is a viable solution, particularly for cloud deployment, as an encryptor can “write”the access policy so that only authorized users can decrypt and have access to the data. However, most existing CP-ABE schemes are based on the costly bilinear maps, and require long decryption keys, ciphertexts and incur significant computation costs in the encryption and decryption (e.g. costs is at least linear to the number of attributes involved in the access policy). These design drawbacks prevent the deployment of CP-ABE schemes on battery-limited mobile devices. In this paper, we propose a new RSA-based CP-ABE scheme with constant size secret keys and ciphertexts (CSKC) and has O(1) time-complexity for each decryption and encryption. Our scheme is then shown to be secure against a chosen-ciphertext adversary, as well as been an efficient solution with the expressive AND gate access structures (in comparison to other related existing schemes). Thus, the proposed scheme is suitable for deployment on battery-limited mobile devices."
  },
  {
    "year": "2017",
    "abstract": "Blind source extraction (BSE) aims to extract the source of interest (SOI) from the outputs of a mixing system, which is a challenging problem. A property existing in many signals is cyclostationarity and this property has been widely exploited in BSE. While various cyclostationarity-based BSE methods have been reported in the literature, they usually require the mixing system to be instantaneous. In this paper, we address BSE in the context that the mixing system is convolutional. Specifically, a new BSE method is developed to extract cyclostationary source signal from the outputs of a multiple-input-multiple-output finite-impulse-response mixing system. It is shown that if the SOI has a unique cyclostationary frequency, it can be recovered from the measured data. The effectiveness of the proposed BSE method is demonstrated by simulation results."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) have been widely adopted in many domains like military and environment monitoring.In general, sensors in WSNs aim to sense and collect various types of information from environments. Sensors usually can be divided into two types as static or mobile sensors, where mobile sensors can move to collect the information from static sensors. How to make the best use of sensor's energy and prolong network lifetime is a challenge, which has attracted the attention of researchers in recent years. In this paper, we schedule mobile sensors by applying techniques derived from ant colony optimization and genetic algorithm in order to balance the energy consumption of mobile sensors. The network where static sensors are deployed are divided into relatively small regions, then we use our technique to allocate these regions to each mobile sensor, while ensuring that energy consumption of each mobile sensor is close to each other. Experimental evaluation shows that our technique can effectively balance the load of each mobile sensor and thus prolong the networks lifetime."
  },
  {
    "year": "2017",
    "abstract": "Machine-type communications are emerging as a new paradigm for enabling a broad range of applications from the massive deployment of sensor devices to mission-critical services. To support massive machine-to-machine (M2M) communications with delay constraints in cellular networks, we design an efficient random access and data transmission system known as distributed queueing random access-multiple-input multiple-output (DQRA-MIMO) data transmission system. This system has the advantages of both efficient collision resolution of DQRA protocol and the efficient data transmission of MIMO technology. To obtain higher throughput under delay constraint and limited time-frequency resources, we match the ability of collision resolution with the capability of MIMO transmission by optimally configuring system parameters. The closed-form expression of throughput is derived, which is a function of the total user equipments' traffic arrival rate, average packet number of each arrival, number of base station antennas, and number of access request (AR) slots. An optimization problem is formulated to maximize the throughput to obtain the optimal number of AR slots given a certain delay constraint for M2M traffic. Numerical and simulation results reveal that, for a given requirement of average delay, the proposed optimized DQRA-MIMO system, which dynamically adjusts time-frequency resource division to maximize throughput, can provide a higher throughput than that of a baseline approach."
  },
  {
    "year": "2017",
    "abstract": "Harmonic emissions have been changed in distribution networks, with respect to frequency range and magnitude, due to the penetration of modern power electronics systems. Two new frequency ranges 2-9 and 9-150 kHz have been identified as new disturbing frequency ranges affecting distribution networks. This paper presents the effects of grid-connected three-phase systems with different front-end topologies: conventional, small dc-link capacitor, and electronic inductor. A power converter with a small dc-link capacitor can create a resonant frequency with the line impedance below and above 1 kHz depending on the grid configurations. The resonant effects depend on many factors, such as load power levels, filter types, and the number of parallel drives. These issues can affect the grid current harmonics and power quality of the distribution networks. Analyses and simulations have been carried out for three different topologies and the results have been verified by experimental test at system level. Current harmonic emissions have been considered for 0-2, 2-9, and 9-150 kHz frequency ranges."
  },
  {
    "year": "2017",
    "abstract": "This paper studies joint power allocation and subcarrier pairing strategies for an orthogonal frequency division multiplexing-based amplify and forward relay system. The optimization target function is symbol error rate (SER) in the context of an additive white generalized Gaussian noise (AWGGN), which encompasses numerous noise types. For instance, the familiar additive white Gaussian noise (AWGN) is just a special case of AWGGN. At a given data rate, the SER performance is optimized under total and individual power constraints, respectively. Simulation results demonstrate superior performance gap through our adaptive resource allocation approach over equal power allocation as well as fixed subcarrier pairing strategies. The impacts of practical issues on the SER performance, such as relay location and unequal power budgets at a source and a relay, are further discussed."
  },
  {
    "year": "2017",
    "abstract": "Large scale multiple-input-multiple output (LS-MIMO) systems are one of the most promising candidates for 5thgeneration wireless communication networks. Many researchers have claimed that LS-MIMO systems increase energy efficiency (EE) and bandwidth efficiency (BE) exponentially because of large number of antennas. Significant increase in transmission directivity also increases sum rate and data throughput but implementation of LS-MIMO is complex in terms of hardware. As the number of antenna elements increase, it becomes necessary that the manufacturing material of antenna must be very cheap and size of antenna element should be very compact. Large number of antenna elements and other hardware components induce different impairments in the system due to amplifier distortion, quantization noise, and phase noise. Since these impairments come as a gift with large scale antenna regime and they effect EE and BE of the system, it is necessary to investigate them for practical scenarios. In this paper, we consider a LS-MIMO single cell scenario with the inclusion of hardware impairments. We derive new expressions for MMSE estimator and achievable rates including effects of hardware impairments. We analyze hardware impairments on the basis of derived expressions. We perform simulations using derived sophisticated impairments model with realistic measurements."
  },
  {
    "year": "2017",
    "abstract": "To meet the rapid growing requirement of data services and offload the heavy base station load, device-to-device (D2D) communication is proposed as one of the key technologies for future cellular network, which can enable users to communicate directly and thus effectively improve the bearing capacity of the network. However, when D2D users transmit packets in the manner of cooperative communication, the cooperative users with non-cooperative behavior, such as the selfishness of user, may lead to a sharp decline in network performance. For this reason, in our paper, a trust-oriented partner selection mechanism (TPSM) is proposed to avoid choosing those users with non-cooperative behavior. In particular, the related psychological researches show that the psychology structure of users can be divided into three aspects: cognition, emotion, and behavior. Considering the psychology structure of users, we build multi-dimensional trust relationships between sending users and cooperative users by evaluating the cognition trust, emotion trust, and behavior trust. Furthermore, aiming at the multi-dimensional trust relationships between sending users and cooperative users, we classify the cooperative users into three categories, namely reliable users, observed users, and unreliable users, by combining the decision-theoretic rough sets based on Naive Bayes. Finally, based on different cooperative transmission scenarios, an optimal partner selection mechanism is proposed in this paper. The optimal partner can be chosen from the reliable cooperative users, according to the different scenarios and factors. The numerical results show that the proposed TPSM can effectively identify the selfish users and notably enhance the packet delivery rate."
  },
  {
    "year": "2017",
    "abstract": "Hardware/software partitioning is playing an important role in designing complex embedded systems. In this paper, by considering the parallelism between hardware and software, we propose a more practical hardware/software partitioning method which can be combined with task scheduling. In one aspect, in order to select a more suitable partitioning algorithm, the concept of blind optimization algorithm for hardware/software partitioning is presented, and the advantages of this kind of algorithms are illustrated by diagrams. We combined the Shuffled Frog Leaping Algorithm (SFLA) with Earliest Time First (ETF), a scheduling algorithm, and proposed a new hardware/software partitioning algorithm named SFLA-ETF. The solution quality and algorithm execution time of SFLA-ETF is better than other blind algorithms and it can also obtain better solutions than non-blind optimization algorithm."
  },
  {
    "year": "2017",
    "abstract": "Distance metric learning is the foundation of many learning algorithms, and it has been widely used in many real-world applications. The basic idea of most distance metric learning methods is to find a space that can optimally separate data points that belong to different categories. However, current methods are mostly based on the single space that only learns one Mahalanobis distance for each data set, which actually fails to perfectly separate different categories in most real-world applications. To improve the accuracy of binary classification, a hierarchical method is proposed in this paper to completely separate different categories by sequentially learning subspace distance metrics. In the proposed method, a base-space distance metric is learned based on a similarity constraint first. Then, for binary classification problems, we formulate the subspace learning problem as a particular Burg Matrix optimization problem that minimizes the Burg Matrix divergence with distance constraints. Moreover, a cyclic projection algorithm is presented to solve the subspace learning problems. The experiments on five UCI data sets using different performance indices demonstrate the improved performance of the proposed method when compared with the state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Mobile social networks (MSNs) are the networks of individuals with similar interests connected to each other through their mobile devices. Recently, MSNs are proliferating fast supported by emerging wireless technologies that allow to achieve more efficient communication and better networking performance across the key parameters, such as lower delay, higher data rate, and better coverage. At the same time, most of the MSN users do not fully recognize the importance of security on their handheld mobile devices. Due to this fact, multiple attacks aimed at capturing personal information and sensitive user data become a growing concern, fueled by the avalanche of new MSN applications and services. Therefore, the goal of this work is to understand whether the contemporary user equipment is susceptible to compromising its sensitive information to the attackers. As an example, various information security algorithms implemented in modern smartphones are thus tested to attempt the extraction of the said private data based on the traces registered with inexpensive contemporary audio cards. Our obtained results indicate that the sampling frequency, which constitutes the strongest limitation of the off-the-shelf side-channel attack equipment, only delivers low-informative traces. However, the success chances to recover sensitive data stored within a mobile device may increase significantly when utilizing more efficient analytical techniques as well as employing more complex attack equipment. Finally, we elaborate on the possible utilization of neural networks to improve the corresponding encrypted data extraction process, while the latter part of this paper outlines solutions and practical recommendations to protect from malicious side-channel attacks and keep the personal user information protected."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with an event-triggered hybrid control for the energy Internet based on a multi-agent system approach with which renewable energy resources can be fully utilized to meet load demand with high security and well dynamical quality. In the design of control, a multi-agent system framework is first constructed. Then, to describe fully the hybrid behaviors of all distributed energy resources and logical relationships between them, a differential hybrid Petri-net model is established, which is an original work. The most important contributions based on this model propose four types of event-triggered hybrid control strategies whereby the multi-agent system implements the hierarchical hybrid control to achieve multiple control objectives. Finally, the effectiveness of the proposed control is validated by means of simulation results."
  },
  {
    "year": "2017",
    "abstract": "The popularity of social media together with the advancement of mobile Internet applications enabling the uploading of data plays a dominant role in the entire Internet traffic. IP flow mobility (IFOM) is proposed as an effective means to enhance the system capacity by offloading data from the cellular network to WiFi or Femtocells or other complementary networks. Although IFOM has been extensively investigated during the past few years, most of these studies, however, are concerned with IFOM technical issues only; little work regarding the IFOM application has been done from the service providers’ perspective. Unlike previous research, in this paper, we address the economic issue involved with the IFOM technology. Specifically, competition among multiple service providers supporting or not supporting IFOM are explored, and a game model for the competition is developed. The Nash equilibrium for the game model is then analyzed. Based on the analysis, an algorithm for Nash equilibrium computation is proposed. Also, numerical experiments are conducted to determine the factors that affect the market share and profit of the service providers. We believe that this research paper will shed light on service providers for the promotion and application of IFOM technology."
  },
  {
    "year": "2017",
    "abstract": "In recent years, the wide-voltage-operating-range circuit has drawn great attention because of its ad-hoc performance and energy efficiency to meet the demands of various applications. The circuit can either obtain the best possible energy efficiency at low voltage or achieve high performance at nominal voltage. A big challenge is the severe Process, Voltage, and Temperature variations under the nanometer process. Thus, when working at the near-threshold region, it may result in timing failure and fails to achieve the possible high-energy efficiency. In this paper, an Adaptive Voltage Scaling (AVS) method based on in-suit timing monitor is proposed with a tunable detection window. It resolves the above problem by monitoring the paths' timing and adjusts the supply voltage adaptively. It is applied on a system-on-chip circuit consistig of a CPU, ESRAM, an AES cryptographic circuit, and peripherals. Fabricated using the SMIC 40nm CMOS process, it can work at 0.6 to 1.1 V with remarkable power savings. Simulation results show that in the super-threshold voltage region, the supply voltage can be reduced from 1.1 to 0.86 V, enabling a maximum of 50% power saving at the FF corner, -25°C as compared to conventional non-AVS design. In the near-threshold region, the supply voltage is reduced to 0.48 V, with a power saving up to 70% at the FF corner, 125°C as compared to a non-AVS design."
  },
  {
    "year": "2017",
    "abstract": "Machine-type communications (MTC) in 5G will be mostly realized using low-cost transceivers with a small, discrete set of possible configurations. This is in contrast to more capable devices with software defined radio capabilities that support configurations over a practically continuous domain. We find that existing theoretical work assuming continuous domains cannot be immediately applied to such constrained MTC devices. Therefore, we propose a methodology that guides researchers in the process of developing effective MTC wireless systems with devices that have restricted capabilities. By following the proposed methodology, existing theories can be experimentally evaluated and replicated. We show how this methodology can be applied for developing and evaluating efficient interference mitigation systems on a case study using devices that support only discrete transmit power levels. In this case study, we formulate an interference mitigation problem and a corresponding game-theoretic formalism that can support discrete output power levels. We validated some of the existing results obtained analytically and in simulation and we also found that: (1) in practice, devices have to be penalized stronger than in theory to determine them to select all the available transmit power levels; (2) in practice, for the discrete case of the power allocation algorithm, the convergence speed does not increase exponentially with the number of devices; and (3) the proposed power selection algorithm converges in two to four iterations. Similarly, as in the presented case study, the methodology can be used to adapt and test other resource management solutions in an operating environment with real-world restrictions."
  },
  {
    "year": "2017",
    "abstract": "Recent advances in renewable energy generation and the Internet of things (IoT) has urged energy management to enter the era of the Internet of energy (IoE). The IoE adopts a huge number of distributed energy-generating facilities, distributed energy storage facilities, and IoT technologies to implement energy sharing, promote utilization of electrical grids, and maintain safety of electrical grids. Rapid economic and social development makes energy shortage tend to be increasingly serious. Most cases of energy shortage occur during the peak energy load, and hence the previous works focused on shifting peak load to address energy shortage. However, few of these works took the IoE framework into account. Consequently, this work aims to consider the IoE framework to investigate the peak load shifting problem in which end-users in the energy market can adopt their respective energy storage facilities to charge and discharge energy to minimize the total operating costs. In such a problem setting, each end-user can not only be a demander, but also be a supplier in the energy market, so that operating costs are concerned; the energies from both conventional electrical grids and distributed renewable energy sources can be stored in energy storage facilities; real-time price of energy will be applied adequately to affect energy distribution of supply and demand. Simulation results of a case study show that the proposed model can obtain the optimal result and achieve peak load shifting."
  },
  {
    "year": "2017",
    "abstract": "With the increasing customer demand on fabric variety in fashion markets, fabric texture becomes much more diverse, which brings great challenges to accurate fabric defect detection. In this paper, a fabric inspection model, consisting of image preprocessing, image restoration, and thresholding operation, is developed to address the woven fabric defect detection problem in the apparel industry, especially for fabric with complex texture and tiny defects. The image preprocessing first improves the image contrast in order to make the details of defects more salient. Based on the learned sub-dictionaries, a non-locally centralized sparse representation model is adopted to estimate the non-defective version of the input images, so that the possible defects can be easily segmented from the residual images of the estimated images and the inputs by thresholding operation. The performance of the proposed defect detection model was evaluated through extensive experiments with various types of real fabric samples. The proposed detection model was proved to be effective and robust, and superior to some representative detection models in terms of the detection accuracy and false alarms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the capacity scaling laws of content-centric hybrid wireless networks, where users aim to retrieve content stored in the network rather than to maintain source-destination communication. A total of n nodes that have limited storage capacities are assumed to be independently and uniformly distributed in the square area. The storage at in each node is used to cache contents according to proposed caching schemes. A total of m-base stations are regularly placed and act as relays during the content retrieving process. Two different content access schemes are considered: homogeneous content access scheme, where each content is requested and cached with equal probability; and heterogenous content access scheme, where the cached probability of each content is different and the requested contents follow a Zipf content popularity distribution. We present the closed form capacity formulae for the two different content access schemes in order sense, respectively. We also discuss the impact of the number of nodes n, the number of base stations m, the storage capacities of nodes C, cached probability of content qj, and content popularity distribution pj on the capacity scaling. The capacity can be improved by increasing the storage capacities of nodes and adding base stations in the networks under homogeneous content access scheme. Under the heterogeneous content access scheme, increasing the cached probability of content and adding the base stations in the networks can effectively improve the capacity. We also present the capacity under different exponent of content popularity distribution. Finally, we compare our results with previous work, which appear as special cases of our work."
  },
  {
    "year": "2017",
    "abstract": "Under short messaging service (SMS) spam is understood the unsolicited or undesired messages received on mobile phones. These SMS spams constitute a veritable nuisance to the mobile subscribers. This marketing practice also worries service providers in view of the fact that it upsets their clients or even causes them lose subscribers. By way of mitigating this practice, researchers have proposed several solutions for the detection and filtering of SMS spams. In this paper, we present a review of the currently available methods, challenges, and future research directions on spam detection techniques, filtering, and mitigation of mobile SMS spams. The existing research literature is critically reviewed and analyzed. The most popular techniques for SMS spam detection, filtering, and mitigation are compared, including the used data sets, their findings, and limitations, and the future research directions are discussed. This review is designed to assist expert researchers to identify open areas that need further improvement."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a dynamic phasor-based model for three-level front-end VIENNA rectifiers. The proposed model comprehensively predicts the behavior of the ac- and dc-side variables of the rectifier on which the issue of neutral point (NP) voltage is studied. The nonzero NP current causes an imbalance of dc-link voltages and the occurrence of low-frequency ripples (LFRs). By employing the offset voltage injection method, a mathematical relationship is derived between the NP current and the dominant components of the injected offset voltage. A distribution parameter is introduced to optimize the dc-link voltages balance and LFRs reduction. A modified one-cycle control (OCC) combined with offset voltage injection is proposed, and the closed-loop voltage regulator is analyzed. The modified OCC scheme proposed in this paper is capable of balancing the dc-link voltages and eliminating the LFRs. It also provides good performance both in transient and steady states. The proposed approach is verified by simulations in MATLAB/Simulink and experimental results."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an optimization framework to maximize the lifetime of wireless sensor networks for structural health monitoring with and without energy harvesting. We develop a mathematical model and formulate the problem as a large-scale mixed integer non-linear programming problem. We also propose a solution based on the Branch-and-Bound algorithm augmented with reducing the search space. The proposed strategy builds up the optimal route from each source to the sink node by providing the best set of hops in each route and the optimal power allocation of each sensor node. To reduce the computational complexity, we propose heuristic routing algorithms. In this heuristic algorithm, the power levels are selected from the optimal predefined values, the problem is formulated by an integer non-linear programming, and the Branch-and-Bound reduced space algorithm is used to solve the problem. Moreover, we propose two sub-optimal algorithms to reduce the computation complexity. In the first algorithm, after selecting the optimal transmission power levels from a predefined value, a genetic algorithm is used to solve the integer non-linear problem. In the second sub-optimal algorithm, we solve the problem by decoupling the optimal power allocation scheme from the optimal route selection. Therefore, the problem is formulated by an integer non-linear programming, which is solved using the Branch-and-Bound space-reduced method with reduced binary variables (i.e., reduced complexity), and after the optimum route selection, the optimal power is allocated for each node. The numerical results reveal that the presented algorithm can prolong the network lifetime significantly compared with the existing schemes. Moreover, we mathematically formulate the adaptive energy harvesting period to increase the network lifetime with the possibility to approach infinity. Finally, the minimum harvesting period to have infinite lifetime is obtained."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate a tradeoff between the secrecy rate (SR) and energy efficiency (EE) in an underlay cognitive radio network that consists of a cognitive base station (CBS), a cognitive user (CU), a primary user (PU), and multiple eavesdroppers (EDs). By using a so-called secrecy EE (SEE), which is defined as the ratio of SR to the total power consumption of CBS, as the design criterion, we formulate an SEE maximization (SEEM) problem for the CBS-CU transmission under the constraints of the transmit power of CBS, the SR of CU, and the quality-of-service (QoS) requirement of PU. Since the formulated optimization problem with a fractional objective function is non-convex and mathematically intractable, we first convert the original fractional objective function into an equivalent subtractive form, and then develop a method of combining the penalty function and the difference of two-convex functions (D.C.) approach to obtain an approximate convex problem. Based on this, an optimal beamforming (OBF) scheme is finally proposed to obtain the optimal solution. Furthermore, to reduce the computational complexity, we design a zero-forcing-based beamforming (ZFBF) scheme to achieve a sub-optimal solution to the SEEM problem. Simulation results are given to illustrate the effectiveness and advantage of the proposed SEE oriented OBF and ZFBF schemes over conventional SR maximization and EE maximization schemes."
  },
  {
    "year": "2017",
    "abstract": "The inherent flexibility of hierarchical structure scheme with main-servo loop control structure is proposed to the problem of integrated chassis control system for the vehicle. It includes both main loop, which calculates and allocates the aim force using the optimal robust control algorithm and servo loop control systems, which track and achieve the target force using the onboard independent brake actuators. In fact, for the brake actuator, the aim friction is obtained by tracking the corresponding slip ratio of target force. For the coefficient of tire-road friction varying with different road surface, to get the nonlinear time-varying target slip ratio, the most famous quasi-static magic formula is proposed to estimate and predict real-time coefficient of different road surface and the constrained hybrid genetic algorithm (GA) is used to identify the key parameters of the magic formula on-line. Then, a self-tuning longitudinal slip ratio controller (LSC) based on the nonsingular and fast terminal sliding mode (NFTSM) control method is designed to improve the tracking accuracy and response speed of the actuators. At last, the proposed integrated chassis control strategies and the self-tuning control strategies are verified by computer simulations."
  },
  {
    "year": "2017",
    "abstract": "The education industry around the globe is undergoing major transformations. Organizations, such as Coursera are advancing new business models for education. A number of major industries have dropped degrees from the job requirements. While the economics of higher education institutions are under threat in a continuing gloomy global economy, digital and lifelong learners are increasingly demanding new teaching and learning paradigms from educational institutions. There is an urgent need to transform teaching and learning landscape in order to drive global economic growth. The use of distance eTeaching and eLearning (DTL) is on the rise among digital natives alongside our evolution toward smart societies. However, the DTL systems today lack the necessary sophistication due to several challenges including data analysis and management, learner-system interactivity, system cognition, resource planning, agility, and scalability. This paper proposes a personalised Ubiquitous eTeaching & eLearning (UTiLearn) framework that leverages Internet of Things, big data, supercomputing, and deep learning to provide enhanced development, management, and delivery of teaching and learning in smart society settings. A proof of concept UTiLearn system has been developed based on the framework. A detailed design, implementation, and evaluation of the UTiLearn system, including its five components, are provided using 11 widely used datasets."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we develop an effective classification framework to classify a hyperspectral image (HSI), which consists of two fundamental components: weighted generalized nearest neighbor (WGNN) and label refinement. First, we propose a novel WGNN method that extends the traditional NN method by introducing the domain knowledge of the HSI classification problem. The proposed WGNN method effectively models the spatial consistency among the neighboring pixels by using a point-to-set distance and a local weight assignment. In addition, we develop a novel label refinement method to enhance label consistency in the classification process, which is able to further improve the performance of the WGNN method. Finally, we evaluate the proposed methods by comparing them with other algorithms on several HSI classification data sets. Both qualitative and quantitative results demonstrate that the proposed methods perform favorably in comparison to the other algorithms."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the impacts that open-trench drains make on the accuracy of radio propagation prediction in an urban city environment. Compared with conventional prediction styles that assume the ground to be flat, in this paper, we have considered for the first time the real scenario in many Asian cities to make open-trench drains inclusive in radio propagation modeling. The aims of this paper are twofold. First, to scrutinize one narrow L-shaped structure, modeled after an open-trench drain, by means of comparing ray-tracing simulation results with the actual field measurement results at 2.4 and 5.8 GHz. Second, to compare one city model built without and with the inclusion of open-trench drains for running ray-tracing simulation in yielding radio propagation prediction results. The findings from this paper are especially beneficial to the improvement of mobile communications in extraordinary environments such as open-trench drains, caves, coal mines, underground passageway, and others. Besides, they provide a unique insight into how the presence of the open-trench drains may affect radio wave propagation in an urban city environment."
  },
  {
    "year": "2017",
    "abstract": "Providing cost-effective and high throughput WiFi access for vehicle drivers and passengers is a promising solution to support the increasing demand for in-vehicle Internet applications. Prior to accessing Internet services via an on-road WiFi access point (AP), a vehicle user has to wait for a certain duration, referred to as access delay, until the user is authenticated and assigned proper network layer parameters, such as an Internet protocol address. Investigation of the access delay in a vehicular environment is critical, since a large access delay can significantly reduce the duration that a vehicle actually benefits from Internet connectivity during its temporary existence within the coverage area of an on-road WiFi AP, especially with high vehicle moving speeds. In this paper, we propose an analytical model based on a Markov chain to study the dependency of the access delay on different factors, including the wireless channel conditions, the number of vehicles accessing the AP service, and the employed authentication mechanism, such as the WiFi protected access II (WPA2)-pre-shared key and the WPA2-802.1X modes. The accuracy of the analytical model is studied via computer simulations and experimental testing using commercial off-the-shelf WiFi products together with a channel emulator that emulates the wireless channel conditions in a vehicular environment. Simulation and experiment results highlight the accuracy of the proposed analytical model. Results in this paper provide useful guidelines for future selection/development of suitable WiFi network access schemes in a vehicular environment."
  },
  {
    "year": "2017",
    "abstract": "Tchebichef polynomials (TPs) and their moments are widely used in signal processing due to their remarkable performance in signal analysis, feature extraction, and compression capability. The common problem of the TP is that the coefficients computation is prone to numerical instabilities when the polynomial order becomes large. In this paper, a new algorithm is proposed to compute the TP coefficients (TPCs) for higher polynomial order by combining two existing recurrence algorithms: the three-term recurrence relations in the n-direction and x-direction. First, the TPCs are computed for x, n = 0, 1, ... , (N/2) - 1 using the recurrence in the x-direction. Second, the TPCs for x = 0, 1, ... , (N/2) - 1 and n = (N/2), (N/2) + 1, ... , N - 1 based on n and x directions are calculated. Finally, the symmetry condition is applied to calculate the rest of the coefficients for x = (N/2), (N/2) + 1, ... , N - 1. In addition to the ability of the proposed algorithm to reduce the numerical propagation errors, it also accelerates the computational speed of the TPCs. The performance of the proposed algorithm was compared to that of existing algorithms for the reconstruction of speech and image signals taken from different databases. The performance of the TPCs computed by the proposed algorithm was also compared with the performance of the discrete cosine transform coefficients for speech compression systems. Different types of speech quality measures were used for evaluation. According to the results of the comparative analysis, the proposed algorithm makes the computation of the TP superior to that of conventional recurrence algorithms when the polynomial order is large."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an enhanced linear inverted pendulum model (LIPM) and a gait planning algorithm are proposed. The LIPM is a widely used concept for gait reference generation, and it provides a simplified model for planning a center of mass trajectory when given a proper zero moment point trajectory. However, one of the assumptions of LIPM is that the legs of the robot are massless, so that the mass of the supporting leg can be neglected for simplification, and it conflicts with the mass distributions of human beings and most humanoid robots. Hence, this paper proposes a double-link LIPM (DLIPM) to eliminate the conflict about mass distribution. In addition, a gait planning algorithm is proposed for natural walking reference generation. In the simulation results, the proposed method is implemented based on a model of a teen-sized humanoid robot named David Junior. The simulation results validate the feasibility and practicability of the proposed method. Moreover, comparisons between conventional LIPM and DLIPM demonstrate the performance of the proposed DLIPM method. Eventually, the proposed method is implemented on David Junior for the weight-lifting event in the 2015 FIRA RoboWorld Cup, an event which David Junior won first place."
  },
  {
    "year": "2017",
    "abstract": "Coordinated scheduling is an efficient resource allocation technique employed to improve the throughput, utilization, and energy efficiency of radio networks. This work focuses on the coordinated scheduling problem for cloud radio access network (CRAN). In particular, we consider the downlink of a CRAN where a central cloud performs the scheduling and synchronization of transmitting frames across the base stations (BSs). For each BS, the transmit frame is composed of several time/frequency slots called resource blocks (RBs). We formulate an optimization problem for joint users to BS association and resource allocation with an objective to maximize the overall network utilization under practical network constraints. The formulated problem is combinatorial and an optimal solution of such a problem can be obtained by performing an exhaustive search over all possible users-to-BSs assignments that satisfy the network constraints. However, the size of search space increases exponentially with the number of users, BSs, and RBs, thus making this approach prohibitive for networks of practical size. This work proposes an interference-aware greedy heuristic algorithm for the constrained coordinated scheduling problem. The complexity analysis of the proposed heuristic is also presented and performance is compared with the optimal exhaustive search algorithm. Simulation results are presented for various network scenarios which demonstrate that the proposed solution achieves performance comparable to the optimal exhaustive search algorithm."
  },
  {
    "year": "2017",
    "abstract": "Due to the limited battery energy of mobile devices, the issue of energy-efficient resource allocation has drawn significant interest in the mobile cloud computing area. Simultaneous wireless information and power transfer (SWIPT) is an innovative way to provide electrical energy for mobile devices. Extensive research on the resource allocation problem is conducted in SWIPT systems. However, most previous works mainly focus on energy harvesting over a relatively narrow frequency range. Due to small amounts of energy harvested by the users, the practical implementations are usually limited to low power devices. In this paper, an energy-efficient uplink resource allocation problem is investigated in a cloud-based cellular network with ambient radio frequency (RF) energy harvesting. In order to obtain sufficient energy, a broadband rectenna is equipped at the user device to harvest ambient RF energy over six frequency bands at the same time. From the viewpoint of service arrival in the ambient transmitter, a new energy arrival model is presented. The joint problem of sub-carrier and power allocation is formulated as a mixed-integer nonlinear programming problem. The objective is to maximize the energy efficiency while satisfying the energy consumption constraint and the total data rate requirement. In order to reduce the computational complexity, a suboptimal solution to the optimization problem is derived by employing a quantum-behaved particle swarm optimization (QPSO) algorithm. Simulation results show that more energy can be harvested by the user devices compared with narrow band SWIFT systems, and the QPSO method achieves higher energy efficiency than a conventional particle swarm optimization approach."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the performance of large-scale cache-enabled device-to-device (D2D) networks with homogeneous Poisson point process distributed mobile helpers(MHs) and user equipments (UEs). The MHs are assumed to have caching capabilities and able to serve the random requests from the UEs within the collaboration distance of D2D transmission. To avoid collisions among the concurrent transmissions, a contention-based multimedia delivery protocol is proposed, under which a MH is allowed to transmit only if its back-off timer is the smallest among its associated contenders. By applying tools from stochastic geometry, the transmission probability of MHs is derived and analyzed. We then characterize the coverage probability of the randomly requested files and thereby the successful content delivery probability of the cache-enabled D2D network. Based on the obtained results of successful content delivery probability, the optimal probabilistic caching strategy of MHs is investigated. Particularly, under the proposed contention-based multimedia delivery protocol, it is recommended to simply cache the most popular file at each MH to maximize the successful content delivery probability of the cache-enabled D2D network. Simulations are provided to validate our analysis."
  },
  {
    "year": "2017",
    "abstract": "A heterogeneous ring domain communication topology with equal area in each ring is presented in this paper in an effort to solve the energy balance problem in original IPv6 routing protocol for low power and lossy networks (RPL). A new clustering algorithm and event-driven cluster head rotation mechanism are also proposed based on this topology. The clustering information announcement message and clustering acknowledgment message were designed according to RFC and original RPL message structure. An energy-efficient heterogeneous ring clustering (E2HRC) routing protocol for wireless sensor networks is then proposed and the corresponding routing algorithms and maintenance methods are established. Related messages are analyzed in detail. Experimental results show that in comparison against the original RPL, the E2HRC routing protocol more effectively balances wireless sensor network energy consumption, thus decreasing both node energy consumption and the number of control messages."
  },
  {
    "year": "2017",
    "abstract": "The aim of the radar systems is to collect information about their surroundings. In many scenarios besides static targets there are numerous moving objects with very different characteristics, such as extent, movement behavior or micro-Doppler spread. It would be most desirable to have algorithms that extract all information on static and moving object automatically, without a system operator. In this paper, we present measurements conducted with a commercially available high-resolution multi-channel linear frequency-modulated continuous-wave radar and algorithms that do not only produce radar images but a description of the scenario on a higher level. After conventional spectrum estimation and thresholding, we present a clustering stage that combines individual detections and generates representations of each target individually. This stage is followed by a Kalman filter based multi-target tracking block. The tracker allows us to follow each target and collect its properties over time. With this method of jointly estimating tracks and characteristics of each individual target in a scenario, inputs for classifiers can be generated. Which, in turn, will be able to generate information that could be used for driver assistance or alarm trigger systems."
  },
  {
    "year": "2017",
    "abstract": "Even after 16 years of existence, low energy adaptive clustering hierarchy (LEACH) protocol is still gaining the attention of the research community working in the area of wireless sensor network (WSN). This itself shows the importance of this protocol. Researchers have come up with various and diverse modifications of the LEACH protocol. Successors of LEACH protocol are now available from single hop to multi-hop scenarios. Extensive work has already been done related to LEACH and it is a good idea for a new research in the field of WSN to go through LEACH and its variants over the years. This paper surveys the variants of LEACH routing protocols proposed so far and discusses the enhancement and working of them. This survey classifies all the protocols in two sections, namely, single hop communication and multi-hop communication based on data transmission from the cluster head to the base station. A comparitive analysis using nine different parameters, such as energy efficiency, overhead, scalability complexity, and so on, has been provided in a chronological fashion. The article also discusses the strong and the weak points of each and every variants of LEACH. Finally the paper concludes with suggestions on future research domains in the area of WSN."
  },
  {
    "year": "2017",
    "abstract": "Mobile Ad Hoc Cloud (MAC) enables the use of a multitude of proximate resource-rich mobile devices to provide computational services in the vicinity. However, inattention to mobile device resources and operational heterogeneity-measuring parameters, such as CPU speed, number of cores, and workload, when allocating task in MAC, causes inefficient resource utilization that prolongs task execution time and consumes large amounts of energy. Task execution is remarkably degraded, because the longer execution time and high energy consumption impede the optimum use of MAC. This paper aims to minimize execution time and energy consumption by proposing heterogeneity-aware task allocation solutions for MAC-based compute-intensive tasks. Results of the proposed solutions reveal that incorporation of the heterogeneity-measuring parameters guarantees a shorter execution time and reduces the energy consumption of the compute-intensive tasks in MAC. A system model is developed to validate the proposed solutions' empirical results. In comparison with random-based task allocation, the proposed five solutions based on CPU speed, number of core, workload, CPU speed and workload, and CPU speed, core, and workload reduce execution time up to 56.72%, 53.12%, 56.97%, 61.23%, and 71.55%, respectively. In addition, these heterogeneity-aware task allocation solutions save energy up to 69.78%, 69.06%, 68.25%, 67.26%, and 57.33%, respectively. For this reason, the proposed solutions significantly improve tasks' execution performance, which can increase the optimum use of MAC."
  },
  {
    "year": "2017",
    "abstract": "We propose a practical, simple and hardware friendly, yet novel and efficient, angle of arrival (AoA) estimation system. Our intuitive, two-phases cross-correlation-based system requires a switched beam antenna array with a single radio frequency circuitry, which is used to collect an omni-directional reference signal using a single element of the antenna array in the first phase. Our system applies energy detection on the collected reference signal to decide on the presence or absence of a transmitted signal. In the second phase, the system steers the main beam to scan the angular region of interest. The collected signal from each beam angle is cross correlated with the omni-directional reference signal to determine the angle of arrival of the received signal. The combined practicality and high efficiency of our system is demonstrated through performance and complexity comparisons with one of the literature's best performing multiple signal classification (MUSIC) algorithm. Our proposed AoA estimation system has a negligible root mean square error at signal to noise ratio level greater than -16 dB, which is very comparable to MUSIC."
  },
  {
    "year": "2017",
    "abstract": "The concept of massive spatial modulation aided multiple-input multiple-output (SM-MIMO) systems, where the base station (BS) is equipped with a large number of antennas and simultaneously serves several multi-antenna users that employ SM for their uplink transmission, has recently attracted substantial research interest. In this paper, we investigate the uplink bandwidth efficiency (BE) of single-cell massive SM-MIMO systems, and derive a new BE lower bound when the BS employs maximum ratio combining for uplink user detection. The proposed BE bound takes into account the impact of spatial correlations at the transmitter, of imperfect channel estimation, and of non-uniform power allocation among each user's antennas (i.e., different antennas are allocated with different levels of transmit power). These bounds are shown to be tight even when a moderate number of antennas is used by the BS. Based on this bound, a gradient ascent method-based optimization is carried out to find the optimal power allocation among the transmit antennas (TAs) of each user, so that the uplink BE can be maximized. More specifically, the optimal power allocation is found to be typically dependent both on the TAs' spatial correlation and on the large-scale attenuation of each user. Aided by this new power allocation scheme, a substantial BE gain can be achieved over the conventional uniform power allocation schemes, which is substantiated by our simulation results."
  },
  {
    "year": "2017",
    "abstract": "Solitary pulmonary nodules (SPN) in digital radiography (DR) images often have unclear contours and infiltration, which make it a challenging task for traditional segmentation models to get satisfactory segmentation results. To overcome this challenge, this paper has proposed an adaptive SPN segmentation model for DR images based on random walks segmentation and sequential filter. First, the SPN image is decomposed to get the cartoon component, which is used to acquire a set of seeds. Second, the seeds selection tactic is employed to optimize the scope of walking pixels and reduce the number of seeds, which could reduce the computational cost. Finally, we incorporate the sequential filter and construct the new representation of the weight and the probability matrices. In this paper, by using a data set of 724 SPN cases, the proposed method was tested and compared with four different models, and five kinds of evaluation indicators were given to evaluate the effect of segmentation. Experimental results indicate that the proposed method performs well on the blurred edge, as it could get relatively accurate results."
  },
  {
    "year": "2017",
    "abstract": "To alleviate the burdens on the fronthaul and reduce the transmit latency, the device-to-device (D2D) communication is presented in cloud radio access networks (C-RANs). Considering dynamic traffic arrivals and time-varying channel conditions, the resource allocation in C-RANs with D2D is formulated into a stochastic optimization problem, which is aimed at maximizing the overall throughput, subject to network stability, interference, and fronthaul capacity constraints. Leveraging on the Lyapunov optimization technique, the stochastic optimization problem is transformed into a delay-aware optimization problem, which is a mixed-integer nonlinear programming problem and can be decomposed into three subproblems: mode selection, uplink beamforming design, and power control. An optimization solution that consists of a modified branch and bound method as well as a weighted minimum mean square error approach has been developed to obtain the close-to-optimal solution. Simulation results validate that D2D can improve throughput, decrease latency, and alleviate the burdens of the constrained fronthaul in C-RANs. Furthermore, an average throughput-delay tradeoff can be achieved by the proposed solution."
  },
  {
    "year": "2017",
    "abstract": "One of the fundamental tasks for spatial index trees constructed in wireless sensor networks is to determine the sensors, which can participate in the region query accurately and quickly. Most of the existing works focus on constructing the spatial index trees for single attribute sensors having the same sensing capability. The key principle underlying the design of these works is the exploitation of parent-child node relation in the network structure, such as the routing tree in which message broadcasting for the parent node selection will consume more energy. However, due to the existence of multi-attribute sensors having different sensing capabilities in skewness distribution, it is more practical to obtain an energy-efficient spatial index tree to query the multi-attribute sensors in a realistic skewness distribution. Specifically, in this paper, we propose a novel energy-efficient heuristic density-based clustering model to build such a multi-attribute spatial index tree. In addition, multiregion attribute aggregation queries are carried out in our proposed index tree, which mainly focus on the recombination of query regions and query attributes. Finally, through an extensive performance evaluation study, we show that the proposed algorithms outperform the existing state-of-the-art approaches significantly in terms of energy consumption, query time, and network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoTs) has emerged to motivate various intelligent applications based on the data collected by various “things.” Cloud computing plays an important role for big data processing by providing data computing and processing services. However, cloud service providers may invade data privacy and provide inaccurate data processing results to users, and thus cannot be fully trusted. On the other hand, limited by computation resources and capabilities, cloud users mostly cannot independently process big data and perform verification on the correctness of data processing. This raises a special challenge on cloud computing verification, especially when user data are stored at the cloud in an encrypted form and processed for satisfying the requests raised in different contexts. But the current literature still lacks serious studies on this research issue. In this paper, we propose a context-aware verifiable computing scheme based on full homomorphic encryption by deploying an auditing protocol to verify the correctness of the encrypted data processing result. We design four optional auditing protocols to satisfy different security requirements. Their performance is evaluated and compared through performance analysis, algorithm implementation, and system simulation. The results show the effectiveness and efficiency of our designs. The pros and cons of all protocols are also analyzed and discussed based on rigorous comparison."
  },
  {
    "year": "2017",
    "abstract": "For enterprise systems running on public clouds in which the servers are outside the control domain of the enterprise, access control that was traditionally executed by reference monitors deployed on the system servers can no longer be trusted. Hence, a self-contained security scheme is regarded as an effective way for protecting outsourced data. However, building such a scheme that can implement the access control policy of the enterprise has become an important challenge. In this paper, we propose a self-contained data protection mechanism called RBAC-CPABE by integrating role-based access control (RBAC), which is widely employed in enterprise systems, with the ciphertext-policy attribute-based encryption (CP-ABE). First, we present a data-centric RBAC (DC-RBAC) model that supports the specification of fine-grained access policy for each data object to enhance RBAC's access control capabilities. Then, we fuse DC-RBAC and CP-ABE by expressing DC-RBAC policies with the CP-ABE access tree and encrypt data using CP-ABE. Because CP-ABE enforces both access control and decryption, access authorization can be achieved by the data itself. A security analysis and experimental results indicate that RBAC-CPABE maintains the security and efficiency properties of the CP-ABE scheme on which it is based, but substantially improves the access control capability. Finally, we present an implemented framework for RBAC-CPABE to protect privacy and enforce access control for data stored in the cloud."
  },
  {
    "year": "2017",
    "abstract": "In recent years, online social networks have gained tremendous popularity because of the massive number of online users, the fast spread of information, and strong inter-personal influence. However, due to the high complexity of the user interaction and the real-time changing of the online social networks, it is still a big challenge to model the spreading process of the information delicately and, then, to predict the information diffusion precisely. In this paper, we exploit a hydrodynamic model to describe the spreading process of the information in online social networks. By using the proposed hydrodynamic information diffusion prediction model (hydro-IDP), we can describe the spreading process of the information on both temporal and spatial perspectives. It is also helpful in extracting the characteristics of information diffusion (e.g., the information popularity, the user influence, and the diffusivity of social platform). We also consider the superimposed effect of the information diffusion resulted from influential users in the model. The high accuracy of the model results has illustrated that our proposed Hydro-IDP model is competent to describe and predict the spreading process of information in online social networks."
  },
  {
    "year": "2017",
    "abstract": "Software defined networking (SDN) brings about innovation, simplicity in network management, and configuration in network computing. Traditional networks often lack the flexibility to bring into effect instant changes because of the rigidity of the network and also the over dependence on proprietary services. SDN decouples the control plane from the data plane, thus moving the control logic from the node to a central controller. A wireless sensor network (WSN) is a great platform for low-rate wireless personal area networks with little resources and short communication ranges. However, as the scale of WSN expands, it faces several challenges, such as network management and heterogeneous-node networks. The SDN approach to WSNs seeks to alleviate most of the challenges and ultimately foster efficiency and sustainability in WSNs. The fusion of these two models gives rise to a new paradigm: Software defined wireless sensor networks (SDWSN). The SDWSN model is also envisioned to play a critical role in the looming Internet of Things paradigm. This paper presents a comprehensive review of the SDWSN literature. Moreover, it delves into some of the challenges facing this paradigm, as well as the major SDWSN design requirements that need to be considered to address these challenges."
  },
  {
    "year": "2017",
    "abstract": "The increase in problem size and complexity of the global routing problems has made it harder for the global routers to produce good results. The global routers employ many different techniques to reach good solutions. However, the results on the recent benchmarks (ISPD 2008) reveal that existing global routers need more enhancements in their designs in-order to improve their solution quality. This work proposes a game theory based algorithm that can enhance the solutions of existing global routers. The proposed algorithm models the rip-up and re-route process as a sequential game in which nets act as players. The set of pure strategies of a net consists of different methods to rip-up and re-route its spanning tree. The nets use mixed strategies in which the probability of any pure strategy is based on the estimation of its likelihood to improve the solution. The performance of the proposed method has been evaluated by using it to enhance the solutions of two excellent global routers namely NCTU-GR 2.0 [1] & BFG-R [2]. The proposed method has been experimented using the ISPD 2008benchmarks and found to be successful in enhancing the total-overflow/wire-length of the existing global routers. On four hard-to-route problems, it has improved the total-overflow of three problems when used with NCTU-GR 2.0 and all four problems when used with BFG-R. It has improved the wire-lengths of all sixteen problems for both NCTU-GR 2.0 and BFG-R. The wire-length of NCTU-GR 2.0 was improved by a value ranging from 35-754 edges and that of BFG-R by a value ranging from 6462-15587 edges. While we demonstrated the potential of GT to enhance results of other heuristics, embedding the discussed technique can help produce better global routers as it will help better traversal of search space, and intelligent decision making."
  },
  {
    "year": "2017",
    "abstract": "Through Internet, a cloud computing system provides shared resources, data, and information to users or tenant users in an on-demand and pay-as-you-go styles. It delivers large-scale utility computing services to a wide range of consumers. To ensure that their provisioned service is acceptable, cloud providers must exploit techniques and mechanisms that meet the service-level-agreement (SLA) performance commitment to their clients. Thus, performance issues of cloud infrastructures have been receiving considerable attention by both researchers and practitioners as a prominent activity for improving service quality. This paper presents an analytical approach to percentile-based performance analysis of unreliable infrastructure-as-a-service clouds. The proposed analytical model is capable of calculating percentiles of the request response time under variable load intensities, fault frequencies, multiplexing abilities, and instantiation processing time. A case study based on a real-world cloud is carried out to prove the correctness of the proposed theoretical model. To achieve optimal performance-cost tradeoff, we formulate the performance model into an optimal capacity decision problem for cost minimization subjected to the constraints of request rejection and SLA violation rates. We show that the optimization problem can be numerically solved through a simulated-annealing method."
  },
  {
    "year": "2017",
    "abstract": "Due to the prevalence of smartphones and various wearable devices, the collection of rich personal data that can be used for human activity recognition, user modeling, and personalized services has become feasible. Because of its popularity and high accessibility, the smartphone has not only become an effective terminal in personal data collection, but also a gateway connecting wearable devices and gathering various types of personal data from these wearables. In most current applications, such wearables operate to collect data according to a fixed schedule, often preset manually by a user. The main problems in the data collection arising from such fixed scheduling are weak adaptiveness to wearables' state changes, a high level of redundancy in collected data, and possible mismatches in the dynamic precision requirements of data capture. Therefore, we propose a context-aware scheduler, that is able to dynamically adjust a data collection schedule based on contingent situations in the condition of wearables, system resource availability, and user behavior. This paper is focused on context data detection and data collection scheduling in a smartphone-based client-server system. The smartphone functions as not only a gateway gathering data from multiple wearables, but also a terminal for the performance of a context-aware scheduler. A context-aware engine is implemented to handle different contextual information. The data quality and system performance have been evaluated and verified in practical experimental tests."
  },
  {
    "year": "2017",
    "abstract": "Conventional 802.11 carrier sense multiple access/collision avoidance (CSMA/CA) networks perform channel contention and data transmission serially over a whole channel. This leads to low throughput efficiency. In this paper, we propose a novel design called CSMA/CQ (contention queuing) to address this problem. This design is developed from the decoupling idea of SDN (Software-defined networking). In CSMA/CQ, each node concurrently executes channel contention and data transmission over two separate subchannels, where a CQ is introduced to coordinate the concurrency. This design enables CSMA/CQ to inherit the merit of the conventional distributed random channel access and carry out a centralized control on data transmission, while achieving far higher throughput than conventional 802.11 networks. We then develop a theoretical model to optimize bandwidth allocation for the channel contention and the data transmission, and prove the existence and uniqueness of the optimal solution. Extensive simulations verify the efficiency of CSMA/CQ and the accuracy of our theoretical model. To the best of our knowledge, CSMA/CQ is the first protocol to make channel contention and data transmission be executed independently and concurrently for wireless LANs (WLANs). This paper provides novel ideas in designing software-defined wireless networks."
  },
  {
    "year": "2017",
    "abstract": "Faster-than-Nyquist (FTN) signaling can improve the bandwidth utilization. In this paper, we will provide a comprehensive survey on the topic. The history and the applications of FTN signaling are first introduced. Then, the basic principles and the system framework of FTN signaling are presented. Next, more details on transmitter and receiver optimization are discussed. Finally, the current research challenges on FTN signaling are identified and conclusions are provided."
  },
  {
    "year": "2017",
    "abstract": "In order to improve the quality of the power injected into a grid, this paper presents a model predictive control strategy for three-phase four-leg grid-tied inverters. For the convenience of optimization, the discrete-time model of the inverter in which duty ratios are modeled as continuous control variables is investigated. A current tracking error oriented cost function is employed as a criterion to optimize duty ratios of the inverters. In order to eliminate the effects of sampling delay, a model predictive control with delay compensation method (MPC-DC) is proposed. Because there is a large amount of calculations in implementing predictive control algorithm, a double-CPU, namely FPGA plus DSP controller, is employed to implement parallel calculation, so as to reduce the computation time. Simulation and experimental results demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "The heart is potentially a highly secured biometric modality. Although many templates have been proposed to be extracted from heart-signal for biometric authentication, they have yet to reach a single digit equal error rate (EER) of false matches and false non-matches when applied on large across-session data sets, where gallery and probe data are taken from different sessions. However, since different templates possess different strengths, the fusion of them has a great potential to improve the authentication performance. We propose an efficient template selection algorithm to select a suitable subset of templates from a given set to obtain a minimal EER. The fusion of the subset of templates selected by this algorithm from a set of seven state-of-the-art templates has obtained a significant 5% reduction of EER in authentication in our experiments on a large database of finger-based ECG signals captured in two different sessions."
  },
  {
    "year": "2017",
    "abstract": "To improve the energy conversion ability and well utilize renewable resources, J. Rifkin first put forward the concept of “Internet of energy IoE)”. Although a peer-to-peer energy sharing mechanism is achieved through bi-directional energy transportation, the approach to solving cooperative energy transportation and storage still needs improving. Traditionally, the redundant energy will be wasted if it cannot be consumed by power load. In fact, the redundant energy can be stored to supply power loads in the future. For this end, we investigate cooperative energy transportation and storage for IoEs in terms of problem analysis, algorithm design, and platform development. After demonstrating the feasibility condition and proving the NP-hard of our problem, we derive the optimal solution by the reduction from a classic knapsack problem. We also design novel heuristics followed by different energy storage strategies. In addition, based on software-defined networking (SDN), a complementary platform is developed to make an effective decision for cooperative energy transportation and storage using heuristics above. Both simulation and experimental results demonstrate the effectiveness of our solutions."
  },
  {
    "year": "2017",
    "abstract": "The wide area monitoring system (WAMS) is considered a pivotal component of future electric power grids. As a pilot WAMS that has been operated for more than a decade, the frequency monitoring network FNET/GridEye makes use of hundreds of global positioning system-synchronized phasor measurement sensors to capture the increasingly complicated grid behaviors across the interconnected power systems. In this paper, the FNET/GridEye system is overviewed and its operation experiences in electric power grid wide area monitoring are presented. Particularly, the implementation of a number of data analytics applications will be discussed in details. FNET/GridEye lays a firm foundation for the later WAMS operation in the electric power industry."
  },
  {
    "year": "2017",
    "abstract": "Recently, there are lots of visual tracking algorithms proposed to improve the performance of object tracking in video sequences with various real conditions, such as severe occlusion, complicated background, fast motion, and so on. In real visual tracking systems, there are various quality degradation occurring during video acquisition, transmission, and processing. However, most existing studies focus on improving the accuracy of visual tracking while ignoring the performance of tracking algorithms on video sequences with certain quality degradation. In this paper, we investigate the performance evaluation of existing visual tracking algorithms on video sequences with quality degradation. A quality-degraded video database for visual tracking (QDVD-VT), including the reference video sequences and their corresponding distorted versions, is constructed as the benchmarking for robustness analysis of visual tracking algorithms. Based on the constructed QDVD-VT, we propose a method for robustness measurement of visual tracking (RMVT) algorithms by accuracy rate and performance stability. The performance of ten existing visual tracking algorithms is evaluated by the proposed RMVT based on the built QDVD-VT. We provide the detailed analysis and discussion on the robustness analysis of different visual tracking algorithms on video sequences with quality degradation from different distortion types. To visualize the robustness of visual tracking algorithms well, we design a robustness pentagon to show the accuracy rate and performance stability of visual tracking algorithms. Our initial investigation shows that it is still challenging for effective object tracking for existing visual tracking algorithms on video sequences with quality degradation. There is much room for the performance improvement of existing tracking algorithms on video sequences with quality degradation in real applications."
  },
  {
    "year": "2017",
    "abstract": "To improve the sum-rate (SR) and the outage probability of the dual-hop relay system, a novel two-stage power allocation scheme with non-orthogonal multiple access is proposed. In this scheme, after the reception of the superposition coded symbol with a power allocation from the source, the relay decodes-and-forwards a new superposition coded symbol with another power allocation to the destination. By employing a simple linear combination, the destination jointly decodes the information symbols from the received signals from the source and the relay. Assuming Rayleigh fading channels, the ergodic SR and the outage performance of the system are investigated. In addition, a suboptimal power allocation strategy with closed form of the power allocation factors is also designed, which is close to the optimal one. Through numerical results, it is shown that the performance of the proposed scheme is significantly improved compared with the existing works."
  },
  {
    "year": "2017",
    "abstract": "Wireless energy transfer technologies have attracted increasing attention on empowering the wireless sensor nodes in recent years. In this paper, we consider a typical wireless rechargeable network, where a mobile charging vehicle is scheduled to charge a wireless sensor network with practical nodes' deployment restrictions that may result in low charging efficiency for sensor nodes by charging vehicle. In our model, we take the effects of charging distance and angle on charging efficiency into consideration. Intuitively, there is an inevitable tradeoff between the charging distance and the angle. First of all, the scheduling traveling path of charging vehicle in previous studies has been proved to be NP-hard. Even worse, the nonlinear property between the charging distance and angle makes the problem even harder. For these concerns, we aim at minimizing the recharging cycle time, which contains the traveling time and recharging time. To this end, we prove that the charging vehicle would travel along the shortest Hamiltonian cycle. And we show the optimal charging location for each wireless charging incident. Experimental results demonstrate that our proposed solution could improve the charging efficiency around two times compared with the baseline scheme without optimization for angle and distance."
  },
  {
    "year": "2017",
    "abstract": "Recently, the Internet of Things (IoT) is attracting significant attention from both academia and industry. To connect the huge amount of IoT devices effectively, software-defined networking (SDN) is considered as a promising way because of its centralized network management and programmable routing logic. However, due to the limited resources in both the data plane and the control plane, SDN is vulnerable to the new-flow attack, which can disable the SDN-based IoT by exhausting the switches or the controller. Therefore, in this paper, we propose a smart security mechanism (SSM) to defend against the new-flow attack. The SSM uses the standard southbound and northbound interfaces of SDN, and it includes a low-cost method that monitors the new-flow attack by reusing the asynchronous messages on the control link. The monitor method can differentiate the new-flow attack from the normal flow burst by checking the hit rate of the flow entries. Based on the monitoring result, the SSM uses a dynamic access control method to mitigate the new-flow attack by perceiving the behavior of the security middleware in the IoT. The dynamic access control method can intercept the attack flows at their access switch. Extensive simulations and testbed-based experiments are conducted and the corresponding results verify the feasibility of our claims."
  },
  {
    "year": "2017",
    "abstract": "Mobile edge computing is a new cloud computing paradigm, which makes use of small-sized edge clouds to provide real-time services to users. These mobile edge-clouds (MECs) are located in close proximity to users, thus enabling users to seamlessly access applications running on MECs. Due to the co-existence of the core (centralized) cloud, users, and one or multiple layers of MECs, an important problem is to decide where (on which computational entity) to place different components of an application. This problem, known as the application or workload placement problem, is notoriously hard, and therefore, heuristic algorithms without performance guarantees are generally employed in common practice, which may unknowingly suffer from poor performance as compared with the optimal solution. In this paper, we address the application placement problem and focus on developing algorithms with provable performance bounds. We model the user application as an application graph and the physical computing system as a physical graph, with resource demands/availabilities annotated on these graphs. We first consider the placement of a linear application graph and propose an algorithm for finding its optimal solution. Using this result, we then generalize the formulation and obtain online approximation algorithms with polynomial-logarithmic (poly-log) competitive ratio for tree application graph placement. We jointly consider node and link assignment, and incorporate multiple types of computational resources at nodes."
  },
  {
    "year": "2017",
    "abstract": "With the increasing volume and scale of prefabricated architecture in China, there is urgent and critical need for the seamless integration of prefabricated component supply chain, which covers project design, component production, logistics and transportation, construction, and maintenance. Due to the coordination problem between the links in the supply chain, the overall operating cost of the upstream and downstream enterprises becomes uncontrollable and the scale effect does not materialize. In this paper, based on RFID application and multi-agent simulation, an information tracking and supply mechanism for prefabricated supply chain are proposed. The research builds the information connections along the whole supply chain using RFID and creates the possibility of zero inventory of prefabricated components along the supply chain. Besides, in order to lower the impact of the demand fluctuation on the supply chain, the research proposes the industry alliance mechanism to satisfy the dynamic supply requirements. This paper, first, summarizes relevant studies on RFID, multi-agent, and industry alliance, and then proposes an RFID and multi-agent-based system architecture for prefabricated component supply chain for information tracking and coordination. It uses a case study involving underground precast tunnel segments to demonstrate the feasibility of the approach in addition to establishing an industry alliance to solve the problem of demand fluctuation."
  },
  {
    "year": "2017",
    "abstract": "In permanent magnet (PM) machine drives, the initial position is typically estimated based on the machine inductance variation and the flux saturation. The saliency-based method using the voltage signal injection has demonstrated the reliable position estimation for high salient PM machines at initial state. However considering the saliency-based drive on low salient machines, several implementation issues appear due to the low signal-to-noise ratio of position dependent signals. This paper addresses the implementation issues on saliency-based initial position estimation. It is shown that conventional saliency-based estimation methods might not be able to obtain the correct rotor position on low salient machines due to secondary saliency harmonics. A two-step estimation process is proposed to improve the initial position estimation accuracy on low salient PM machines. Two PM machines with different saliency ratios are tested for the experimental evaluation."
  },
  {
    "year": "2017",
    "abstract": "Three-factor mutually authenticated key agreement protocols for multi-server environments have gained momentum in recent times due to advancements in wireless technologies and associated constraints. Several authors have put forward various authentication protocols for multi-server environment during the past decade. Wang et al. recently proposed a biometric-based authentication with key agreement protocol for multi-server environment and claimed that their protocol is efficient and resistant to prominent security attacks. The careful investigation of this paper shows that Wang et al. protocol's users are sharing personal identifiable information with the application servers during the registration and authentication process. This nature of disclosing credentials leads to severe threats particularly insider attacks, user impersonation attacks, and server impersonation attacks. As a remedy of the aforementioned problems, this paper proposes a novel biometric-based mutually authenticated key agreement protocols for multi-server architecture based on elliptic curve cryptography. We prove that the proposed protocol achieves secure mutual authentication property using the broadly used Burrows-Abadi-Needham logic. The formal security of the proposed protocol is verified using the widely accepted automated validation of Internet security protocols and applications tool to show that our protocol can withstand active and passive attacks including the replay and man-in-the-middle attacks. The proposed protocol is robust and efficient compared with the existing related protocols."
  },
  {
    "year": "2017",
    "abstract": "Wireless nanosensor networks (WNSNs), which consist of numerous nanosensors, offer a number of unprecedented and promising applications in the biomedical, environmental, industrial, and military fields. However, a single nanosensor in WNSNs has very limited capability as a result of nanoscale components, especially the extremely small nanobatteries. Therefore, energy efficiency has become an essential issue for WNSNs. In this paper, by considering the scenarios of transmitting binary source symbols in WNSNs, an energy optimization coding (EOC) for communication in WNSNs is proposed, and the energy model by jointly accounting for the energy consumption of both a transmitter and a receiver is presented. Based on the optimal source-word length and the optimal code-word length by solving an energy optimization problem, an energy-efficient coding scheme and the corresponding coding algorithm are presented. Simulation results show that EOC performs better energy efficiency than the existing nanonetwork minimum energy coding while requiring a smaller source-word length. Moreover, the proposed coding algorithm is more suitable for the scenarios of transmitting long binary source symbols."
  },
  {
    "year": "2017",
    "abstract": "Hybrid multiple-input multiple-output (MIMO) systems have been thought as a promising technology in future 5G. Compared with conventional digital MIMO systems, such a structure is equipped with fewer RF chains, which would reduce the computational complexity and hardware cost, and meanwhile additional analog beamforming is introduced to maintain the performance. However, scarce RF chains make channel state information acquisition difficult for analog beamforming. In this paper, we consider a practical hybrid beamforming, which includes zero-forcing (ZF) precoding in digital beamforming, and beam selection for analog beamforming. First, the statistic information of users (e.g., angle and distance) is utilized to construct an approximate channel for each user. Second, users individually evaluate the codebook and feedback the results, by which base station (BS) makes optimization and selects the final beams for analog beamforming. Finally, BS performs the digital baseband ZF precoding with the equivalent channel. In the process, we give two limited feedback methods for users, and two corresponding beam selection methods for BS. These methods are evaluated in the Rayleigh fading channels and mmWave channels. Simulation results show that our hybrid beamforming could approach performance of conventional digital precoding, and more RF chains could provide better performance. Moreover, proposed methods only require once feedback and effectively reduce the delay, and two feedback methods achieve a good tradeoff between performance and feedback cost."
  },
  {
    "year": "2017",
    "abstract": "Wireless power transfer (WPT) has long been one of the main goals of Nikola Tesla, the forefather of electromagnetic applications. In this paper, we investigate radio-frequency beamforming in the radiative far field for WPT. First, an analytical model of the channel fading is presented, and a blind adaptive beamforming algorithm is adapted to the WPT context. The algorithm is computationally light, because we need not explicitly estimate the channel state information. Then, a testbed with a multiple-antenna software-defined radio configuration on the transmitting side and a programmable energy harvester on the receiving side is developed in order to validate the algorithm in this specific power application. From the results, it can be seen that the implementation of this version of beamforming indeed improves the harvested power. Specifically, at various distances from 50 cm to 1.5 m, the algorithm converges with two, three, and four antennas with an increasing gain as we increase the number of antennas. These encouraging results could have far-reaching consequences in providing wireless power to Internet of Things devices, our target application."
  },
  {
    "year": "2017",
    "abstract": "The next-generation cellular network is to provide a large variety of services for different kinds of terminals, from traditional voice and data services over mobile phones to small packet transmission over massive machine-type terminals. Although orthogonal-subcarrier-based waveforms are widely used nowadays in many practical systems, they can hardly meet the requirements in the coming 5G networks. Therefore, more flexible waveforms have been proposed to address the unprecedented challenges. In this paper, we will provide comprehensive analysis and comparison for typical waveforms. To offer an insightful analysis, we will not only introduce the basic principles of the waveforms, but also reveal the underlying characteristics. Moreover, a comprehensive comparison in terms of different performance metrics will also be presented in thispaper, which provides an overall understanding of the new waveforms."
  },
  {
    "year": "2017",
    "abstract": "Energy Internet, as a major trend in power system, can provide an open framework for integrating equipment of energy generation, transmission, storage, consumption, and so on, so that global energy can be managed and controlled efficiently by information and communication technologies. In this paper, we focus on the coordinated management of renewable and traditional energy, which is a typical issue on energy connections. We consider a conventional power system consisting of the utility company, the energy storage company, the microgrid, and electricity users. First, we formulate the energy management problem as a three-stage Stackelberg game, and every player in the electricity market aims to maximize its individual payoff while guaranteeing the system reliability and satisfying users' electricity demands. We employ the backward induction method to solve the three-stage non-cooperative game problem, and give the closed-form expressions of the optimal strategies for each stage. Next, we study the big data-based power generation forecasting techniques, and introduce a scheme of the wind power forecasting, which can assist the microgrid to make strategies. Furthermore, we prove the properties of the proposed energy management algorithm including the existence and uniqueness of Nash equilibrium and Stackelberg equilibrium. Simulation results show that accurate prediction results of wind power is conducive to better energy management."
  },
  {
    "year": "2017",
    "abstract": "Ultra-dense network (UDN) is considered as a promising technology in 5G wireless networks. In an UDN network, dynamic traffic patterns can lead to a high computational complexity and an excessive communications overhead with traditional resource allocation schemes. In this paper, a new resource allocation scheme presenting a low computational overhead and a low subband handoff rate in a dynamic ultra-dense heterogeneous network is presented. The scheme first defines a new interference estimation method that constructs network interference state map, based on which a radio resource allocation scheme is proposed. The resource allocation problem is a MAX-K cut problem and can be solved through a graph-theoretical approach. System level simulations reveal that the proposed scheme decreases the subband handoff rate by 30% with less than 3.2% network throughput degradation."
  },
  {
    "year": "2017",
    "abstract": "Recognizing 3-D objects in cluttered scenes is a challenging task. Common approaches find potential feature correspondences between a scene and candidate models by matching sampled local shape descriptors and select a few correspondences with the highest descriptor similarity to identify models that appear in the scene. However, real scans contain various nuisances, such as noise, occlusion, and featureless object regions. This makes selected correspondences have a certain portion of false positives, requiring adopting the time-consuming model verification many times to ensure accurate recognition. This paper proposes a 3-D object recognition approach with three key components. First, we construct a Signature of Geometric Centroids descriptor that is descriptive and robust, and apply it to find high-quality potential feature correspondences. Second, we measure geometric compatibility between a pair of potential correspondences based on isometry and three angle-preserving components. Third, we perform effective correspondence selection by using both descriptor similarity and compatibility with an auxiliary set of “less” potential correspondences. Experiments on publicly available data sets demonstrate the robustness and/or efficiency of the descriptor, selection approach, and recognition framework. Comparisons with the state-of-the-arts validate the superiority of our recognition approach, especially under challenging scenarios."
  },
  {
    "year": "2017",
    "abstract": "As a powerful nonparametric Bayesian model, the infinite mixture model has been successfully used in machine learning and computer vision. The success of the infinite mixture model owes to the capability clustering and density estimation. In this paper, we propose a nonparametric Bayesian model for single-image super-resolution. Specifically, we combine the Dirichlet process and Gaussian process regression for estimating the distribution of the training patches and modeling the relationship between the low-resolution and high-resolution patches: 1) the proposed method groups the training patches by utilizing the clustering property of Dirichlet process; 2) the proposed method relates the low-resolution and high-resolution patches by predicting the property of Gaussian process; and 3) the mentioned two points are not independent but jointly learned. Hence, the proposed method can make full use of the nonparametric Bayesian model. First, the Dirichlet process mixture model is used to obtain more accurate clusters for training patches. Second, Gaussian process regression is established on each cluster, and this directly reduces the computational complexity. Finally, the two procedures are learned simultaneously to gain the suitable clusters with the ability of prediction. The parameters can be inferred simply via the Gibbs sampling technique. Thorough super-resolution experiments on various images demonstrate that the proposed method is superior to some state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "A low-profile and wide-beamwidth dual-polarized distributed microstrip antenna is presented in this paper. Four isolated micro patches are proposed as the radiation components and are excited by a compact differential-fed network. The micro patches in two diagonals determine the operating frequency bands of the two polarizations, respectively. By increasing the distances between the micro patches, the beamwidth in E plane can be broadened. Shorting poles between the patches and the ground plane are used to achieve good impedance matching. Compact dual-polarized differential-fed networks are also studied and compared with achieve the best antenna performance. To validate the proposed method, a wide-beamwith dual-polarized distributed microstrip antenna, whose dual polarizations operate at 2 and 2.2 GHz, respectively, is manufactured and measured. The external dimensions of the antenna is 70mmx10 mm (0.49λ x 0.07λ). The experimental results agree well with the simulated ones. The 3dB beamwidths in E planes reach 116° and 115°, and the gains are 5.15 and 5.5 dB for two polarizations, respectively. Meanwhile, the cross polarizations are less than -26.2 and -27.8 dB. In addition, the impedance bandwidths of 9.2% and 9.9% for VSWR≤2 are achieved, and the port isolation is greater than 25.4 dB in the bands."
  },
  {
    "year": "2017",
    "abstract": "Accurate prediction of traffic conditions on orthogonal frequency division multiple access passive optical networks is important because of its vital role in network resource management and efficient bandwidth allocation. Given the dynamic and stochastic nature of network traffic, our proposed algorithm conducts a probabilistic approach by using the hidden Markov model (HMM). The HMM defines traffic states with two parameters: the mean and contrast of the bandwidth request observations. Simulation results demonstrate the performance comparison between with and without the prediction method in terms of throughput and end-to-end delay. As a result, the throughput improves 15% and the saturation offered load of the delay for the prediction and non-prediction is 0.8 and 0.7, respectively."
  },
  {
    "year": "2017",
    "abstract": "Non-verbal sounds (NVS) constitute an appealing communicative channel for transmitting a message during a dialog. They provide two main benefits, such as they are not linked to any particular language, and they can express a message in a short time. NVS have been successfully used in robotics, cell phones, and science fiction films. However, there is a lack of deep studies on how to model NVS. For instance, most of the systems for NVS expression are ad hoc solutions that focus on the communication of the most prominent emotion. Only a small number of papers have proposed a more general model or dealt directly with the expression of pure communicative acts, such as affirmation, denial, or greeting. In this paper we propose a system, referred to as the sonic expression system (SES), that is able to generate NVS on the fly by adapting the sound to the context of the interaction. The system is designed to be used by social robots while conducting human-robot interactions. It is based on a model that includes several acoustic features from the amplitude, frequency, and time spaces. In order to evaluate the capabilities of the system, nine categories of communicative acts were created. By means of an online questionnaire, 51 participants classified the utterances according to their meaning, such as agreement, hesitation, denial, hush, question, summon, encouragement, greetings, and laughing. The results showed how very different NVS generated by our SES can be used for communicating."
  },
  {
    "year": "2017",
    "abstract": "With various information sources (e.g., from IoT sensors to social media), it is difficult to provide users with trustworthy services in ambient environment. The aim of this paper is i) to design trust ontology for representing semantics of the ambient services and ii ) to compute trust measures among users by using a personalized trust ontology. In particular, given a large amount of data collected from ambient sensors, efficient trust computation and reasoning are required for the stability and reliability. Thereby, we propose trust ontology-based framework for deriving personalized ontologies for individual users according to their preference, perspective, and purpose. To evaluate the proposed model, we have figured out a method how the degree of trust is estimated based on the trust ontology. Furthermore, we have proved that the proposed method is reliable with a case study on a social media (Twitter) for a particular domain (restaurant)."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates a full duplex wireless-powered two way communication networks, where two hybrid access points (HAPs) and a number of amplify and forward relays both operate in full duplex scenario. We use time switching (TS) and static power splitting (SPS) schemes with two way full duplex wireless-powered networks as a benchmark. Then, the new time division duplexing static power splitting (TDD SPS) and the full duplex static power splitting (FDSPS) schemes as well as a simple relay selection strategy are proposed to improve the system performance. For TS, SPS, and FDSPS, the best relay harvests energy using the received RF signal from HAPs and uses harvested energy to transmit signal to each HAP at the same frequency and time, therefore only partial self-interference (SI) cancellation needs to be considered in the FDSPS case. For the proposed TDD SPS, the best relay harvests the energy from the HAP and its self-interference. Then, we derive closed-form expressions for the throughput and outage probability for delay limited transmissions over Rayleigh fading channels. Simulation results are presented to evaluate the effectiveness of the proposed scheme with different system key parameters, such as time allocation, power splitting ratio, and residual SI."
  },
  {
    "year": "2017",
    "abstract": "Narrowband Internet of Things (NB-IoT) is a new narrow-band radio technology introduced in the Third Generation Partnership Project release 13 to the 5th generation evolution for providing low-power wide-area IoT. In NB-IoT systems, repeating transmission data or control signals has been considered as a promising approach for enhancing coverage. Considering the new feature of repetition, link adaptation for NB-IoT systems needs to be performed in 2-D, i.e., the modulation and coding scheme (MCS) and the repetition number. Therefore, existing link adaptation schemes without consideration of the repetition number are no longer applicable. In this paper, a novel uplink link adaptation scheme with the repetition number determination is proposed, which is composed of the inner loop link adaptation and the outer loop link adaptation, to guarantee transmission reliability and improve throughput of NB-IoT systems. In particular, the inner loop link adaptation is designed to cope with block error ratio variation by periodically adjusting the repetition number. The outer loop link adaptation coordinates the MCS level selection and the repetition number determination. Besides, key technologies of uplink scheduling, such as power control and transmission gap, are analyzed, and a simple single-tone scheduling scheme is proposed. Link-level simulations are performed to validate the performance of the proposed uplink link adaptation scheme. The results show that our proposed uplink link adaptation scheme for NB-IoT systems outperforms the repetition-dominated method and the straightforward method, particularly for good channel conditions and larger packet sizes. Specifically, it can save more than 14% of the active time and resource consumption compared with the repetition-dominated method and save more than 46% of the active time and resource consumption compared with the straightforward method."
  },
  {
    "year": "2017",
    "abstract": "Internet of Energy is considered as a promising approach to solve the problems of energy crisis and carbon emission. It needs to collect user's real-time data for optimizing the energy utilization. However, such data may disclose user's privacy information. Previous works usually adopt specific obfuscation value to mask user's data and counteract the deviation through data aggregation; these works can preserve the data privacy effectively, but most of them consider less about the data-utility (precision). In this paper, we propose a utility-privacy tradeoff scheme based on random data obfuscation in Internet of Energy. In the proposed scheme, we adopt random data-obfuscation to mask the real-time data and realize the fault-tolerance during data aggregation, and the random obfuscation value obeys the Laplace distribution. We use the signal-to-noise ratio to quantify the level of utility; we measure the level of privacy through information entropy. Based on these two Indicators, we balance the utility-privacy tradeoff by calculating the optimal parameters of the Laplace distribution. The analysis shows that our scheme can meet the security requirement, and it also has better performance than that of other popular methods."
  },
  {
    "year": "2017",
    "abstract": "Image dehazing is a technique to enhance the images acquired in poor weather conditions, such as fog and haze. Existing image dehazing methods are mainly based on dark channel prior. Since the dark channel is not reasonable for sky regions, a sky segmentation and region wised medium transmission based image dehazing method is proposed in this paper. Firstly, sky regions are segmented by quad-tree splitting based feature pixels detection. Then, a medium transmission estimation method for sky regions is proposed based on color characteristic observation of sky regions. The medium transmission is then filtered by an edge preserving guided filter. Finally, based on the estimated medium transmission, the hazed images are restored. Experimental results demonstrate that the performance of the proposed method is better than that of existing methods. The restored image is more natural, especially in the sky regions."
  },
  {
    "year": "2017",
    "abstract": "The uncertainties of the predicted load demand and N-K contingencies are very significant aspects to composite generation and transmission expansion planning (CGTEP). In this paper, multi-contingency constrained CGTEP with load uncertainty was analyzed from stringent mathematical view and formulated as a tri-level optimization model. To effectively solve the tri-level optimization, the entire problem is formulated as two problems using Benders' decomposition: master problem with expansion planning and the sub-problem with the worst case load shedding. The sub-problem is a bi-level optimization problem which can be solved mathematically using strong duality theory and linearization method. CGTEP with the tri-level optimization can endure the disturbances of interval load and N-K contingencies. A benchmark test system is simulated to validate the effectiveness of the proposed approach. Furthermore, for Bender's decomposition with many sub-problems of worst load shedding, the numerically comparable results of a special case demonstrate that all sub-problems of composite contingencies must be validated at each iteration even if certain contingency meets the standard of load shedding at the previous iteration."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, remote collaborative learning tools for computer science education mostly emphasize providing learning resources and realizing virtual collaborative learning environment for students. Many people in this field tend to have their mind fixed on the process improvement of such a collaboration as a whole, while few notice that individuals may have different roles and impacts on this type of teamwork. There usually is a “supervisor” on the team, who offers support to all members in the collaborative learning environment. However, such support may not always be as accessible as students demand it to be. Therefore, this paper describes a cloud-based tool to support software engineering practice courses in collaboration with remote tutors. This system utilizes a cloud storage platform to provide sharing of multimedia study materials and a better management of project developing cycles. A remote collaborative component called the Virtual Debug Laboratory is designed to improve and share students' debugging experience in the same team. The most innovative feature of this system is that it amplifies the role of tutoring in remote collaborative learning environments so that tutors can, in real time, assist students in debugging during actual project developing and demonstrate step by step to the students the process of debugging. The results of the analyzed data regarding the use of this system indicate that the system can potentially enhance students' abilities in project developing and debugging in software engineering practice courses. It is our hope that these preliminary data can provide a future reference for the software education community."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel heating, ventilation, and air-conditioning system that can achieve significant energy savings. A smart register that can reduce overall energy costs by up to 30%, compared to conventional devices, is demonstrated. A high abstraction model based on a computational fluid dynamics (CFD) simulation is developed to predict the diffused airflow from the register. The model is validated to within a 10% error, and is found to be 1000 times more efficient than the detailed CFD simulations. Finally, a prototype of the electroactive smart air-conditioning vent register is implemented, and adjustments of the register's tunnels are implemented."
  },
  {
    "year": "2017",
    "abstract": "FPGAs offer high performance coupled with energy efficiency, making them extremely attractive computational resources within a cloud ecosystem. However, to achieve this integration and make them easy to program, we first need to enable users with varying expertise to easily develop cloud applications that leverage FPGAs. With the growing size of FPGAs, allocating them monolithically to users can be wasteful due to potentially low device utilization. Hence, we also need to be able to dynamically share FPGAs among multiple users. To address these concerns, we propose a methodology and a runtime system that together simplify the FPGA application development process by providing: 1) a clean abstraction with high-level APIs for easy application development; 2) a simple execution model that supports both hardware and software execution; and 3) a shared memory-model which is convenient to use for the programmers. Akin to an operating system on a computer, our lightweight runtime system enables the simultaneous execution of multiple applications by virtualizing computational resources, i.e., FPGA resources and on-board memory, and offers protection facilities to isolate applications from each other. In this paper, we illustrate how these features can be developed in a lightweight manner and quantitatively evaluate the performance overhead they introduce on a small set of applications running on our proof of concept prototype. Our results demonstrate that these features only introduce marginal performance overheads. More importantly, by sharing resources for simultaneous execution of multiple user applications, our platform improves FPGA utilization and delivers higher aggregate throughput compared to accessing the device in a time-shared manner."
  },
  {
    "year": "2017",
    "abstract": "Ubiquity of mobile devices with rich sensory capabilities has given rise to the mobile crowd-sensing (MCS) concept, in which a central authority (the platform) and its participants (mobile users) work collaboratively to acquire sensory data over a wide geographic area. Recent research in MCS highlights the following facts: 1) a utility metric can be defined for both the platform and the users, quantifying the value received by either side; 2) incentivizing the users to participate is a non-trivial challenge; 3) correctness and truthfulness of the acquired data must be verified, because the users might provide incorrect or inaccurate data, whether due to malicious intent or malfunctioning devices; and 4) an intricate relationship exists among platform utility, user utility, user reputation, and data trustworthiness, suggesting a co-quantification of these inter-related metrics. In this paper, we study two existing approaches that quantify crowd-sensed data trustworthiness, based on statistical and vote-based user reputation scores. We introduce a new metric - collaborative reputation scores - to expand this definition. Our simulation results show that collaborative reputation scores can provide an effective alternative to the previously proposed metrics and are able to extend crowd sensing to applications that are driven by a centralized as well as decentralized control."
  },
  {
    "year": "2017",
    "abstract": "Blurring is one of the most common distortions in digital images. In the past decade, extensive image deblurring algorithms have been proposed to restore a latent clean image from its blurred version. However, very little work has been dedicated to the quality assessment of deblurred images, which may hinder further development of more advanced deblurring techniques. Motivated by this, this paper presents a no-reference quality metric for defocus deblured images based on Natural Scene Statistics (NSS). Two categories of NSS features are extracted in both the spatial and frequency domains to account for both the global and local aspects of distortions in deblurred images. Specifically, the spatial domain NSS features are used to characterize the global naturalness, and the frequency domain NSS features are used to portray the local structural distortions. All features are combined to train a support vector regression model for quality prediction of defocus deblurred images. The performance of the proposed metric is evaluated in a subjectively rated defocus deblurred image database. The experimental results demonstrate the advantages of the proposed metric over the relevant state-of-the-arts. As an application, the proposed metric is further used for benchmarking deblurring algorithms and very encouraging results are achieved."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider collaborative power systems education through the FEEDER consortium. To increase students’ access to power engineering educational content, the consortium of seven universities was formed. A framework is presented to characterize different collaborative education activities among the universities. Three of these approaches of collaborative educational activities are presented and discussed. These include 1) cross-institutional blended courses (“MS-MD”); 2) cross-institutional distance courses (“SS-MD”); and 3) single-site special experiential courses and concentrated on-site programs available to students across consortium institutions (“MS-SD”). This paper presents the advantages and disadvantages of each approach."
  },
  {
    "year": "2017",
    "abstract": "Applying rotated and cyclic Q delayed (RCQD) modulation on the transmitter side improves the performance of the receiver in case of fading channel conditions along with erasures. However, the complexity of demapping in the receiver increases significantly to achieve this elevated performance. Many low complexity demapping solutions are available but few are actually implemented in hardware. Recently, new constellation rotation angles and associated simplified demapping technique with better performance for fading channel conditions along with erasure scenarios has been proposed. In this paper, we propose a novel demapper architecture model that exploits these latest simplifications. Moreover, a joint demapper implementation is proposed, which can demap the symbols from different constellations using full or simplified demapping algorithm to achieve best throughput in terms of LLR/sec. Compared to state-of-the-art implementations of RCQD demappers, significant hardware reductions are demonstrated encouraging the use of RCQD modulation in future wireless communication applications."
  },
  {
    "year": "2017",
    "abstract": "The two-layer network structure has been widely adopted in wireless sensor networks (WSNs) for managing sensor nodes. In such a structure, the low layer nodes communicate with their cluster head, followed by the cluster-head nodes communicating with the base station operating in either a one-hop or a multi-hop manner. The main focus of node-clustering algorithms is minimizing energy consumption due to strictly limited resources in WSNs. Also, WSNs are data intensive networks with the capability of providing users with accurate data. Unfortunately, data missing is common in WSNs. In this paper, we propose a novel joint design of sensor nodes clustering and data recovery, where the WSNs is organized in a two-layer manner with our developed clustering algorithm, and then, the missing data are recovered based on this two-layer structure. Furthermore, in the proposed clustering algorithm, we take both the energy-efficiency and data forecasting accuracy into consideration and investigate the tradeoff between them. This is based on the key observation that the high energy-efficiency of the network can be achieved by reducing the distances among the nodes in a cluster, while the accuracy of the forecasting results can be improved by increasing the correlation of the data stream among the nodes in a cluster. Simulation results demonstrate that our joint design outperforms the existing algorithms in terms of energy consumption and forecasting accuracy."
  },
  {
    "year": "2017",
    "abstract": "Due to limited energy resources, energy balancing becomes an appealing requirement/ challenge in Underwater Wireless Sensor Networks (UWSNs). In this paper, we present a Balanced Load Distribution (BLOAD) scheme to avoid energy holes created due to unbalanced energy consumption in UWSNs. Our proposed scheme prolongs the stability period and lifetime of the UWSNs. In BLOAD scheme, data (generated plus received) of underwater sensor nodes is divided into fractions. The transmission range of each sensor node is logically adjusted for evenly distributing the data fractions among the next hop neighbor nodes. Another distinct feature of BLOAD scheme is that each sensor node in the network sends a fraction of data directly to the sink by adjusting its transmission range and continuously reports data to the sink till its death even if an energy hole is created in its next hop region. We implement the BLOAD scheme, by varying the fractions of data using adjustable transmission ranges in homogeneous and heterogeneous simulation environments. Simulation results show that the BLOAD scheme outperforms the selected existing schemes in terms of stability period and network lifetime."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel decentralized robust H∞fixed-order dynamic output feedback (DOF) controller design approach for discrete-time nonlinear large-scale systems via Takagi-Sugeno fuzzy-affine models. By a state-input augmentation method and piecewise quadratic Lyapunov functions, some sufficient conditions for decentralized fixed-order piecewise affine DOF controller synthesis are given. It is shown that by some convexification techniques, the controller gains can be obtained by solving a set of linear matrix inequalities. Two simulation examples are carried out to verify the effectiveness of the proposed design method."
  },
  {
    "year": "2017",
    "abstract": "With the evolution of mobile phone sensing and wireless networking technologies, mobile crowd sensing (MCS) has become a promising paradigm for large-scale sensing applications. MCS is a type of multi-participant sensing that has been widely used by many sensing applications because of its inherent capabilities, e.g., high mobility, scalability, and cost effectiveness. This paper reviews the existing works of MCS and clarifies the operability of MCS in sensing applications. With wide use and operability of MCS, MCS's industrial applications are investigated based on the clarifications of: 1) the evolution of industrial sensing and 2) the benefits MCS can provide to current industrial sensing. As a feasible industrial sensing paradigm, MCS opens up a new field that provides a flexible, scalable, and cost-effective solution for addressing sensing problems in industrial spaces."
  },
  {
    "year": "2017",
    "abstract": "The problem of malicious activities in online social networks, such as Sybil attacks and malevolent use of fake identities, can severely affect the social activities in which users engage while online. For example, this problem can affect content publishing, creation of friendships, messaging, profile browsing, and commenting. Moreover, fake identities are often created to disseminate spam, use the private information of other users, commit fraud, and so on. A malicious person can generate numerous fake accounts for these purposes to reach a large number of trustworthy users. Thus, these types of malicious accounts must be detected and deactivated as quickly as possible. However, this objective is challenging, because a fake account can exhibit trustworthy behaviors and have a type of name that will prevent it from being detected by the security system. In this paper, we provide a comprehensive survey of literature from 2006 to 2016 on Sybil attacks in online social networks and use of social networks as a tool to analyze and prevent these attack types. We first review existing Sybil attack definitions, including those in the context of online social networks. We then discuss a new taxonomy of Sybil attack defense schemes and methodologies. Finally, we compare the literature and identify areas for further research in Sybil attacks in online social networks."
  },
  {
    "year": "2017",
    "abstract": "We consider the two-cell two-hop multiple-input-multiple-output interference channel with half-duplex relays, where each source group having M single antenna users communicates with the corresponding destination with M antennas via two relays, each having M antennas. For such a channel, by exploiting three time slots, the previously known achievable degrees of freedom (DoF) is 2M/3 regardless of whether the half-duplex relays have global channel state information (CSI) for the first hop. In this paper, we show that using n ≥ 3 time slots, the achievable DoF is (n - 1)M/n, which is higher than the previous result of 2M/3 DoF for the case of n ≥ 4. The achievability is shown by a new relaying protocol, which combines the alternate transmission strategy with an interference cancellation technique. A major implication of the derived result is that a normalized DoF of one can be achieved asymptotically without requiring global CSI at the source and relay nodes."
  },
  {
    "year": "2017",
    "abstract": "Random Forests are powerful classification and regression tools that are commonly applied in machine learning and image processing. In the majority of random classification forests algorithms, the Gini index and the information gain ratio are commonly used for node splitting. However, these two kinds of node-split methods may pay less attention to the intrinsic structure of the attribute variables and fail to find attributes with strong discriminate ability as a group yet weak as individuals. In this paper, we propose an innovative method for splitting the tree nodes based on the cooperative game theory, from which some attributes with good discriminate ability as a group can be learned. This new random forests algorithm is called Cooperative Profit Random Forests (CPRF). Experimental comparisons with several other existing random classification forests algorithms are carried out on several real-world data sets, including remote sensing images. The results show that CPRF outperforms other existing Random Forests algorithms in most cases. In particular, CPRF achieves promising results in ocean front recognition."
  },
  {
    "year": "2017",
    "abstract": "Intelligent travel guide systems have grown increasingly popular in recent years. They also benefit a lot from the development of social media, resulting in a large amount of attractions uploaded by users. To tackle this, attractions should be real time classified by user-generated photos automatically to gain better user experience. However, in practice, the given label of photos and text ratings may be incomplete or missing. Moreover, recently, domain adaptation has been applied to deal with few labeled data. Thus, in this paper, we propose a novel framework for automatically attraction classification in leveraging web-harvesting data from search engine and the photos of attractions uploaded by users. Specifically, we assume that top-k web-harvesting images from search engines have correct labels. The classification problem is formulated as a regularized domain adaptation approach. Experiments conducted on the collected real-world data set demonstrated that the promising performance is gained over state-of-the art classification methods."
  },
  {
    "year": "2017",
    "abstract": "As a result of the significant increase of overlapped coverage areas among base stations (BSs), interference coordination in heterogeneous cellular networks (HetCNets) becomes necessary, since interference would degrade network performance and even cause dropped calls. In addition, various types of BSs coexist in HetCNets, and BSs with low power (such as Pico BSs and Femto BSs) are deployed more arbitrarily than those in macrocell BSs (MBSs) so that the traditional anti-interference technologies are not enough in HetCNets. To reduce the interference between MBSs and low-power BSs within the coverage, a novel distributed resource allocation algorithm is proposed. First, an interference graph is established, by which the corresponding orthogonal resources can be assigned to different BSs, and the users can be classified into center and edge users, respectively. After that, users select appropriate resource blocks according to an improved proportional fair algorithm, and BSs distribute transmission power to different resource blocks to enhance network throughput further. Simulation results demonstrate the effectiveness of our proposed scheme in resource allocation and utilization."
  },
  {
    "year": "2017",
    "abstract": "State convergence is a novel scheme to control a teleoperation system in a bilateral mode. Starting from modeling an nthorder teleoperation system on state space, the scheme offers a simple and elegant procedure, which requires 3n+1 design conditions to be solved in order to synchronize the master and slave systems, and to achieve the desired dynamic behavior of the teleoperation system. However, in its current form, the scheme cannot be applied in situations where more than one master and/or slave systems are involved to perform a certain task. To overcome this limitation, we first present an alpha-modified version of the standard state convergence architecture for a single-master/single-slave teleoperation system. This alpha-modified architecture is then used to develop extended state convergence architecture for a multi-master/multi-slave teleoperation system. The resulting extended state convergence architecture requires solving a set of n(k+l)+(n+1)kl design equations to determine the control gains for synchronizing k-master and l-slave systems in a desired dynamic way. MATLAB simulations considering a one-degree-of-freedom dual-master/tri-slave teleoperation system are presented to show the efficacy of the proposed extended state convergence architecture for multilateral teleoperation systems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a large-scale machine-to-machine (M2M) network architecture that incorporates energy harvesting and social-aware relays. The relay is powered by harvesting radio frequency energy and adopts the simultaneous wireless information and power transfer strategy. For the social aspect, a relay is conversant with only some of the communities and will only assist the data transfer of conversant sources. Moreover, for the energy harvesting and social-aware relay that assists the cooperative transmission protocol, we propose two different relay selection strategies, that is, social-aware random relay selection and social-aware best relay selection. The outage probability and network throughput of the proposed protocols are derived in a closed form using the stochastic geometry model, where the multiple M2M transmitter-receiver pairs and relays form independent homogeneous Poisson point processes, respectively. By comparing with the situation without social awareness, we find that social awareness can improve performance in some situations. The theoretical analysis is validated by extensive simulations."
  },
  {
    "year": "2017",
    "abstract": "Planning of optimal/shortest path is required for proper operation of unmanned ground vehicles (UGVs). Although most of the existing approaches provide proper path planning strategy, they cannot guarantee reduction of consumed energy by UGVs, which is provided via onboard battery with constraint power. Hence, in this paper, a new ant-based path planning approach that considers UGV energy consumption in its planning strategy is proposed. This method is called Green Ant (G-Ant) and integrates an ant-based algorithm with a power/energy consumption prediction model to reach its main goal, which is providing a collision-free shortest path with low power consumption. G-Ant is evaluated and validated via simulation tools. Its performance is compared with ant colony optimization, genetic algorithm, and particle swarm optimization approaches. Various scenarios were simulated to evaluate G-Ant performance in terms of UGV travel time, travel length, computational time by taking into account different numbers of iterations, different numbers of obstacle, and different population sizes. The obtained results show that the G-Ant outperforms the existing methods in terms of travel length and number of iteration."
  },
  {
    "year": "2017",
    "abstract": "Cache-aided small-cell network is becoming an effective method to improve the transmission rate and reduce the backhaul load. Due to the limited capacity of backhaul, less power should be allocated to users whose requested contents do not exist in the local caches to maximize the performance of caching. In this paper, power allocation is considered to improve the performance of cache-aided small-cell networks with limited backhaul, where interference alignment is used to manage interferences among users. Specifically, three power allocation algorithms are proposed. First, we come up with a power allocation algorithm to maximize the sum transmission rate of the network, considering the limitation of backhaul. Second, to have more users meet their rate requirements, a power allocation algorithm to minimize the average outage probability is also proposed. Third, to further improve the users' experience, a power allocation algorithm that maximizes the average satisfaction of all users is also designed. Simulation results are provided to show the effectiveness of the three proposed power allocation algorithms for cache-aided small-cell networks with limited backhaul."
  },
  {
    "year": "2017",
    "abstract": "This paper jointly investigates the downlink/uplink of wireless powered networks (WPNs), which are exposed to the effect of the cascaded near-far problem, i.e., the asymmetric overall degradation of the users' performance, due to different path-loss values. More specifically, assuming that the users are able to harvest energy both from interference and desired signals, higher path loss reduces the downlink rate of the far user, while it also negatively affects its uplink rate, since less energy can be harvested during downlink. Furthermore, if the far user is located at the cell edge, its performance is more severely impaired by interference, despite the potential gain due to energy harvesting from interference signals. To this end, we fairly maximize the downlink/uplink users' rates, by utilizing corresponding priority weights. Two communication protocols are taken into account for the downlink, namely, time division multiple access and non-orthogonal multiple access (NOMA), while NOMA with time sharing is considered for the uplink. The formulated multidimensional non-convex optimization problems are transformed into the equivalent convex ones and can be solved with low complexity. Simulations results illustrate that: 1) a relatively high downlink rate can be achieved, while the required energy is simultaneously harvested by the users for the uplink and 2) dowlink NOMA is a more appropriate option with respect to the network topology, especially when a high downlink rate is desired."
  },
  {
    "year": "2017",
    "abstract": "Cyber-physical system (CPS) is a new trend in the Internet-of-Things related research works, where physical systems act as the sensors to collect real-world information and communicate them to the computation modules (i.e. cyber layer), which further analyze and notify the findings to the corresponding physical systems through a feedback loop. Contemporary researchers recommend integrating cloud technologies in the CPS cyber layer to ensure the scalability of storage, computation, and cross domain communication capabilities. Though there exist a few descriptive models of the cloud-based CPS architecture, it is important to analytically describe the key CPS properties: computation, control, and communication. In this paper, we present a digital twin architecture reference model for the cloud-based CPS, C2PS, where we analytically describe the key properties of the C2PS. The model helps in identifying various degrees of basic and hybrid computation-interaction modes in this paradigm. We have designed C2PS smart interaction controller using a Bayesian belief network, so that the system dynamically considers current contexts. The composition of fuzzy rule base with the Bayes network further enables the system with reconfiguration capability. We also describe analytically, how C2PS subsystem communications can generate even more complex system-of-systems. Later, we present a telematics-based prototype driving assistance application for the vehicular domain of C2PS, VCPS, to demonstrate the efficacy of the architecture reference model."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a comprehensive study of the effectiveness of the classical grid and coordinate models (CMs) in producing the optimal wind farm layout is conducted based on theoretical analyses and computational experiments. The wind farm layout planning with the grid model (GM) and CM is formulated as a combinatorial and a continuous optimization problem separately. Theoretical analyses prove that it is more complicated to solve CM than GM if the solution space of two models is searched exhaustively. In computational studies, the impact of advanced heuristic search methods on generating optimal wind farm layouts with GM and CM is analyzed. First, two models are solved with the multi-swarm optimization (MSO) algorithm, and CM, in general, produces better layouts, because swarm intelligence is inherently continuous and the flexibility of CM. To further evaluate the importance of selecting an appropriate heuristic search algorithm, the random key genetic algorithm (RKGA) is introduced to compare with MSO in solving GM. Results show that GM produces much better wind farm layouts with RKGA, which is inherently combinatorial. Computational results demonstrate that it is important to match the inherent suitability of heuristic search algorithms with the type of the layout planning models in the wind farm layout optimization."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the problem of H∞stabilization for nonuniform sampling fuzzy systems. To achieve better performance, a parallel distributed compensation scheme is proposed to design a nonlinear controller. By taking the deviation bounds of asynchronous normalized membership functions into account, the H∞stability criterion is first obtained, which is dependent on the deviation bounds of asynchronous normalized membership functions. To reduce the computational complexity, a method for eliminating slack variables and a structured vertex separator for reducing the number of linear matrix inequalities are provided, and then an H∞stabilization criterion with less complexity and less conservatism is obtained. Finally, an illustrative example is given to show the effectiveness of the proposed method and the significant improvement on the existing results."
  },
  {
    "year": "2017",
    "abstract": "The time to frequency protocol is the first frequency-domain contention protocol in wireless LANs, and has attracted a great deal of attention, since it can improve channel efficiency significantly. However, this protocol mainly provides a uniform service by letting each user conduct channel contention over the same frequency-domain range. In this paper, we first propose a novel weighted frequency-domain contention (WFC) scheme for service differentiation. In WFC, different frequency-domain ranges are assigned to different users to achieve weighted channel access opportunity, and a signature-assisted method is employed to completely exclude collisions. We then develop a theoretical framework to study the performance of WFC. With this framework, we can evaluate system throughput, optimize system parameter settings, and achieve proportional fairness. Extensive simulations verify that our theoretical model is very accurate."
  },
  {
    "year": "2017",
    "abstract": "Reconstruction of highly accelerated dynamic magnetic resonance imaging (MRI) is of crucial importance for the medical diagnosis. The application of general robust principal component analysis (RPCA) to MRI can increase imaging speed and efficiency. However, conventional RPCA makes use of nuclear norm as convex surrogate of the rank function, whose drawbacks have been mentioned in plenty of literature. Recently, nonconvex surrogates of the rank function in RPCA have been widely investigated and proved to be tighter rank approximation than nuclear norm by the massive experimental results. Motivated by this, we propose a nonconvex alternating direction method based on nonconvex rank approximation to reconstruct dynamic MRI data from undersampledk−tspace data. We solve the associated nonconvex model by the alternating direction method and difference of convex programming. The convergence analysis provided guarantees the effectiveness of our algorithm. Experimental results on cardiac perfusion and cardiac cine MRI data demonstrate that our method outperforms the state-of-the-art MRI reconstruction methods in both image clarity and computation efficiency."
  },
  {
    "year": "2017",
    "abstract": "A diffusion general mixed-norm (DGMN) algorithm for distributed estimation over network (DEoN) is proposed. The standard diffusion adaptive filtering algorithm with a single error norm exhibits slow convergence speed and poor misadjustments under specific environments. To overcome this drawback, the DGMN is developed by using a convex mixture of p and textit q norms as the cost function to improve the convergence rate and substantially reduce the steady-state coefficient errors. Especially, it can be used to solve the DEoN under Gaussian and non-Gaussian noise environments, including measurement noises with long-tail and short-tail distributions, and impulsive noises with α-stable distributions. In addition, the analysis of the mean and mean square convergence is performed. Simulation results show the advantages of the proposed algorithm with mixing error norms for DEoN."
  },
  {
    "year": "2017",
    "abstract": "This paper analyzes the effects of realistic relay transceiver on the outage probability and throughput of a two-way relay cognitive network that is equipped with an energy-harvesting relay. In this paper, we configure the network with two wireless power transfer policies and two bidirectional relaying protocols. Furthermore, the differences in receiver structure of relay node that can be time switching or power splitting structure are also considered to develop closed-form expressions of outage and throughput of the network providing that the delay of transmission is limited. Numerical results are presented to corroborate our analysis for all considered network configurations. This paper facilitates us not only to quantify the degradation of outage probability and throughput due to the impairments of realistic transceiver but also to provide an insight into practical effects of specified configuration of power transfer policy, relaying protocol, and receiver structure on outage and throughput. For instance, the system with multiple access broadcast protocol and the power splitting-based receiver architecture achieves ceiling throughout higher than that of the transmission rate of source nodes. On the contrary, a combination of dual-source energy transfer policy and the time division broadcast protocol is contributed the highest level of limiting factor in terms of transceiver hardware impairments on the network throughput."
  },
  {
    "year": "2017",
    "abstract": "In this paper, measurements in a laboratory characterizing the 15-GHz band propagation channels are introduced. Both an omnidirectional antenna (ODA) and a 10° half-power-beamwidth (HPBW) pyramidal horn antenna are deployed at the transmitter (Tx) in different measurements. The receiver (Rx) is equipped with a 10° HPBW horn antenna. A direction-scanning sounding method is applied by rotating the Rx horn antenna in steps of 5° to collect channel impulse responses (CIRs) in the angular domains. Clusters are extracted based on power concentration from the 3-D power spectrum in delay, azimuth, and zenith arrival angles. Each cluster represents the contribution of specular paths with similar delay, azimuth, and zenith arrival angles, and of the diffuse-scattering components spreading around these paths. The mapping of the propagation paths reconstructed from the extracted clusters to the physical interacting objects in the environment is found to be reasonable. Differences on channel characteristics are compared for both a horn antenna and an ODA at the Tx. Finally, a stochastic cluster model is provided based on five measurements in the laboratory for the case where the ODA is used at the Tx."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the simple Internet of Things enabler (SITE), a smart home solution that allows users to specify and centrally control Internet of Things smart objects. Unlike most existing systems, SITE supports End-User Development. Hence, it defines a simple language for the specification of control rules for smart objects. It also provides a user interface to graphically illustrate the data received from smart objects. To assess the usability of SITE, we conduct an empirical study involving 20 participants belonging to two user groups: users with technical training (IT users) and users without technical training (non-IT users). We demonstrate that both user groups can satisfactorily build smart objects and define control rules in a smart home environment using SITE."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, mobile devices have been considered as a new platform for information services, and have been widely used in many fields. In mobile application services, the processing and representation of data is a key issue which has a great impact on the service quality. Knowledge map is regarded as an effective method and has been widely utilized in mobile devices. However, traditional knowledge maps employed in mobile devices are subject to a lack of cognition characteristics, which results in corresponding information services' being unable to match the users' cognition level, thus affecting the quality of services. In this paper, we propose a hierarchical cognitive academic map (HCAM) for the specific academic domain application background. HCAM can meet the needs of three basic levels of Bloom's cognition taxonomy model by distinguishing the academic attributes of nodes and relations between nodes. First, academic concepts are the basic units in HCAM and are classified into research object concepts and method/technique concepts, which meet the human's remembering cognition levels. Second, HCAM provides the implementation and collaboration relation between concepts, which satisfies the human's applying and understanding cognition levels. Third, technique/method concepts are organized in the form of hierarchical structure from the top down of which concepts' specificity for the domain get higher and higher. In addition, Bayesian rose tree clustering is adopted in the construction of this hierarchical structure and acquiring the cognition depth for each concept. Furthermore, experiments on information retrieval field and data mining field are performed to demonstrate the effectiveness and cognition characteristics of HCAM."
  },
  {
    "year": "2017",
    "abstract": "Mean control charts are effective tools for detecting mean shifts of an interesting quality variable in both manufacturing processes and service processes. Much of the data in service industries come from processes exhibiting non-normal or unknown distributions. The commonly used Shewhart mean control charts, which depend heavily on the normality assumption, are not appropriately used here. This paper thus proposes an asymmetric EWMA mean chart with a double sampling scheme (DS EWMA-AM chart) for monitoring mean shifts of a process with variables data. Furthermore, we explore the sampling properties of the new mean monitoring statistics, and investigate the out-of-control detection performance of the proposed DS EWMA-AM chart using average run lengths. The detection performance of the DS EWMA-AM chart and that of the single sampling EWMA mean (SS EWMA-AM) chart are then compared, with the former showing superior out-of-control detection performance versus the latter. We also compare the out-of-control mean detection performance of the proposed chart with those of non-parametric mean control charts, like the likelihood ratio-based distribution-free NLE, CWE, SS EWMA-AM, the SL, the SU, and the VSS and double sampling and variable sampling intervalX¯¯¯¯control charts by considering cases in which the critical quality characteristic presents normal, double exponential, uniform, chi-square, and exponential distributions, respectively. Comparison results show that the proposed control chart always outperforms the existing mean control charts. We hence recommend employing the DS EWMA-AM chart. A numerical example of a service system for a bank branch in Taiwan is used to illustrate the application of the proposed mean control chart. Finally, we give a discussion for future study."
  },
  {
    "year": "2017",
    "abstract": "Ever-increasing demands for portable and flexible communications have led to rapid growth in networking between unmanned aerial vehicles often referred to as flying ad-hoc networks (FANETs). Existing mobile ad hoc routing protocols are not suitable for FANETs due to high-speed mobility, environmental conditions, and terrain structures. In order to overcome such obstacles, we propose a combined omnidirectional and directional transmission scheme, together with dynamic angle adjustment. Our proposed scheme features hybrid use of unicasting and geocasting routing using location and trajectory information. The prediction of intermediate node location using 3-D estimation and directional transmission toward the predicted location, enabling a longer transmission range, allows keeping track of a changing topology, which ensures the robustness of our protocol. In addition, the reduction in path re-establishment and service disruption time to increase the path lifetime and successful packet transmissions ensures the reliability of our proposed strategy. Simulation results verify that our proposed scheme could significantly increase the performance of flying ad hoc networks."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose the architecture of the ARM-based server system and physically build the ARM-based server cluster board (SCB). Based on a real implementation, the efficiency of the microserver is evaluated to verify the benefits of the proposed scheme. In experiments, every SCB is equipped with four server-grade ARM quad-core processors for enterprise-class applications. The major difference between our work and other studies is that this paper tests the performance of the server-grade processors, whereas previous works use the cluster system formed by the embedded processors. The experiment results show that the SCB-based systems perform with lower power-consumption than the x86 systems. Since various types of cluster systems can be built with the SCB through either the PCI Express (PCIe) interface or gigabit Ethernet interface, the proposed design of the ARM server board and the systems can, therefore, be extensively applied. This physical implementation and measurement show that the proposed architecture can work well. The proposed energy-saving (i.e., green) server designs with low-power processors are suitable for relative applications in the coming era of Industry 4.0 and the Internet of Things."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes an innovative economic and engineering coupled framework to encourage typical flexible loads or load aggregators, such as parking lots with high penetration of electric vehicles, to participate directly in the real-time retail electricity market based on an integrated eVoucher program. The integrated eVoucher program entails demand side management, either in the positive or negative direction, following a popular customer-centric design principle. It provides the extra economic benefit to end-users and reduces the risk associated with the wholesale electricity market for electric distribution companies (EDCs), meanwhile improving the potential resilience of the distribution networks with consideration for frequency deviations. When implemented, the eVoucher program allows typical flexible loads, such as electric vehicle parking lots, to adjust their demand and consumption behavior according to financial incentives from an EDC. A distribution system operator (DSO) works as a third party to hasten negotiations between such parking lots and EDCs, as well as the price clearing process. Eventually, both electricity retailers and power system operators will benefit from the active participation of the flexible loads and energy customers."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the reduced-order observer-based consensus problem of multi-agent system with time delay and event trigger strategy. First, a multi-step algorithm is presented to construct a reduced-order observer for each agent. Then, a novel push-based event-triggered control strategy, which based on the reduced-order observer and the relative outputs of neighboring agents is proposed. Under this control strategy, a sufficient condition for the consensus of multi-agent systems is obtained by using the integral inequality technique and matrix theory. Moreover, the estimation value of the output time delay is also obtained and the Zeno-behavior of triggering time sequences is excluded. Finally, two simulations about the multi-agent system are provided to illustrate the correctness of theoretical results."
  },
  {
    "year": "2017",
    "abstract": "In recent years, selective catalytic reduction (SCR) system has been used in modern ship or vehicle diesel engines to reduce emissions. SCR technique is a key enabler for NOx reduction, which is critical for the performance and fuel economy of both ship and vehicle diesel engines, since a more advanced timing of the diesel injection is used. The ammonia (NH3) is generated from reaction mechanism of SCR system by using the liquid urea as the reluctant. Therefore, a precise urea dosing system is crucial, and its flow control is very challenging as the traditional approach is still in the open-loop fashion or little urea requirement quantity. To address this challenge, a new urea dosing sub-system of SCR is proposed, which realizes flow feedback with a flow sensor and different control method. The proposed system is novel as it embeds all the control elements in the flow rate regulation, which successfully solves the precise control of the urea dosing system with nonlinear dynamics. In this paper, we first present the working principle of the new urea dosing system. Then, the mechanical system design is shown and the system dynamic model is built. To this end, the proposed system control mechanism is fabricated and validated in a testing fixture. The new urea dosing system performance is finally presented through a series of simulation and experimental results."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, the rapidly developed Internet of Things requires the ability handling information efficiently to deal with the intelligent applications. Wireless sensor networks (WSNs), which act as an important interface between physical environment and Internet of Things, have been applied in numerous applications. As a kind of important application of WSNs, the continuous objects boundary detection is popular in industry. However, the long-term maintenance for the traditional WSNs, which are used to monitor the leakage of continuous objects, is expensive. Thus, we use sparse WSNs to address this issue. But, the inaccuracy of the sparse network is a big problem while the information of continuous objects is used to arrange retreat path for people. To access this problem, we propose our mechanism, which used hybrid network to compromise the accuracy and cost of maintenance. The sensing holes will be detected by using Voronoi diagram, before the network starts to work. After the static sensor nodes get the value of the toxic air, the mechanism can calculate the high variation location, which give weights to the sensing holes, in the static sensor networks. Thus, the sensing holes, which selected by both spatial and data variation factors will be list in a target nodes list for the mobile sensor node. Finally, the optimal path considering both distance and priority for the mobile sensor will be plan out. Experimental evaluation shows that there is an optimal amount of the static nodes decided by the sensing radius and the size of area. And it reduces the energy consumption by the static networks."
  },
  {
    "year": "2017",
    "abstract": "At the present time, only large multinational pharmaceutical companies have the financial ability to research new drugs. Thus, reducing the research and development costs of new drugs is an important subject. Through the in-depth mining of existing drug data, this paper aims to classify unknown drugs and provide assistance for drug screening during the development process. This will reduce the costs of original drug research and promote the transformation of China’s pharmaceutical industry. In this paper, we first collected a drug data set using a Web crawler. Based on this data set, we derived a formula for calculating the similarity between drugs and identified the parameters of the similarity calculation formula from a subset of the data. We used the k-nearest neighbor classifier to categorize the drug data based on the similarity of medicines. The results show that the proposed drug classification model can achieve 77.7% accuracy, which is far better than the classification performance of a decision tree and a random forest with only one decision tree, similar to that of a random forest with 10 decision trees, and worse than that of a random forest with 500 decision trees. Although the classification method proposed in this paper is reasonable and the experimental results are in line with expectations, the proposed technique could be improved to manage problems, such as overfitting. Because this classification method is based on chemical similarity and depends entirely on the available training data (which are limited), such fitting problems are inevitable. To solve this problem, more data are needed and the existing sampling method should be improved. One possible approach is to combine this algorithm with ensemble learning techniques to avoid the phenomenon of overfitting."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a formation collision forecast and coordination algorithm (FCFCA) is proposed to avoid collisions in the configuration control of missile autonomous formation (MAF). First, the conditions are derived to forecast collisions of the MAF. Second, the transition target configuration is designed to coordinate collisions. Third, by minimizing the formation group cost, we obtain the optimal transition vector, which can avoid collisions and guarantee the efficiency, safety, and stability of the MAF. Finally, simulation and experiment results are presented to verify the effectiveness of the FCFCA."
  },
  {
    "year": "2017",
    "abstract": "The fog radio access network (F-RAN) is a promising paradigm to provide high spectral efficiency and energy efficiency. Characterizing users to select an appropriate communication mode in F-RANs is critical for performance optimization. With evolutionary game theory, a dynamic mode selection is proposed for F-RANs, in which the competition among the groups of potential users' space is formulated as a dynamic evolutionary game, and the game is solved by an evolutionary equilibrium. Stochastic geometry tool is used to derive the proposals' payoff expressions for both fog access point and device-to-device users by considering node location, cache sizes, as well as the delay cost. The analytical results for the proposed game model and the corresponding solution are evaluated, which show that the evolutionary game-based access mode selection algorithm has a better payoff than the max rate-based algorithm."
  },
  {
    "year": "2017",
    "abstract": "With the popularity of mobile devices and the quick growth of the mobile Web, users can now browse news wherever they want; so, their news preferences are usually related to their geographical contexts. Consequently, many research efforts have been put on location-aware news recommendation, which recommends to users news happening nearest to them. Nevertheless, in a real-world context, users' news preferences are not only related to their locations, but also strongly related to their personal interests. Therefore, in this paper, we propose a hybrid method called location-aware personalized news recommendation with explicit semantic analysis (LP-ESA), which recommends news using both the users' personal interests and their geographical contexts. However, the Wikipedia-based topic space in LP-ESA suffers from the problems of high dimensionality, sparsity, and redundancy, which greatly degrade the performance of LP-ESA. To address these problems, we further propose a novel method called LP-DSA to exploit recommendation-oriented deep neural networks to extract dense, abstract, low dimensional, and effective feature representations for users, news, and locations. Experimental results show that LP-ESA and LP-DSA both significantly outperform the state-of-the-art baselines. In addition, LP-DSA offers more effective (19.8%-179.6% better) online news recommendation with much lower time cost (25 times quicker) than LP-ESA."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the effects of phase noise difference in receiving signals are introduced to discriminate targets. Oscillators and signal sources have their own phase noise levels and specific patterns. This property can be used for discriminating a real target from the airborne digital radio frequency memory (DRFM) in continuous wave tracking radar sensor networks with linear frequency modulation. A simulated signal made through complex circuits by DRFM has higher phase noise with different patterns. To investigate the phase noise level of oscillators, a system is provided to measure the phase noise. Then, the probability of detection (PD) and the probability of false alarm (Pfa) can be achieved by defining an appropriate threshold to evaluate the performance of discriminating between real targets and DRFM targets. The phase noise powers are measured through the same sets of circuits and coherent time periods in various radar sensor systems. To control the amplitude fluctuation of the received signal, the normalization of signal phase power is defined in phase noise bandwidths. The likelihood ratio test is used for target discrimination by a threshold level to achieve the minimum Pfaof target discrimination. The proposed method has a simple structure without any additional complexities, and is easily compatible with common radar systems. Two real DRFM systems are used to evaluate the performance of the proposed method in both the L-band and X-band frequencies. The presented results are investigated in different ranges, Doppler frequencies, signal-to-noise ratios, and signal-to-jammer ratios. The experimental results prove the capability of proposed method in radar sensor networks."
  },
  {
    "year": "2017",
    "abstract": "Due to distributed nature, dynamic topology and resources constraints of tiny sensing nodes in wireless sensor networks (WSNs), the quality of service (QoS) support is a challenging issue. However, satisfying the stringent QoS requirements is an open problem. QoS aware protocols for WSNs have gained recently considerable attention of the researchers. In this paper, we focus on the QoS satisfaction in WSNs, basics of QoS support in WSNs, and more importantly challenge, requirements of QoS at each layer. Furthermore, we review the QoS protocols and categorize the QoS aware protocols and elaborate their pros and cons. We also discuss the QoS parameters with respect to each protocol performance parameters. A survey and comprehensive discussion on the QoS aware protocols of WSNs are presented, including their strengths and limitations. Finally, we also survey some computational intelligence (CI) techniques and find the basic requirements of such techniques. Moreover, we study these CI techniques in the light of QoS management and tabulate the level of each CI technique for QoS management. The paper is concluded with open research issues."
  },
  {
    "year": "2017",
    "abstract": "Recently, much effort has been directed toward reducing the energy consumption of hydraulic systems against the backdrop of energy shortages and environmental problems. This paper is focused on the development of an energy-saving hydraulic system based on common pressure rail (CPR), which has the potential benefit of being widely applicable to construction machinery. First, the principle of CPR is introduced. Then, the main components, including hydraulic transformers and storage elements, are reviewed, followed by an analysis of the development and research efforts focused on the CPR from a system perspective, which includes energy saving application and control performance investigation. Finally, the challenges and the direction of future development are discussed."
  },
  {
    "year": "2017",
    "abstract": "In order to mimic the capability of human listeners identifying speech in noisy environments, this paper proposes a phoneme classification technique using simulated neural responses from a physiologically based computational model of the auditory periphery instead of using features directly from the acoustic signal. The 2-D neurograms were constructed from the simulated responses of the auditory-nerve fibers to speech phonemes. The features of the neurograms were extracted using the Radon transform and used to train the classification system using a deep neural network classifier. Classification performance was evaluated in quiet and under noisy conditions for different types of phonemes extracted from the TIMIT database. Based on simulation results, the proposed method outperformed most of the traditional acoustic-property-based phoneme classification methods for both in quiet and under noisy conditions. The proposed method could easily be extended to develop an automatic speech recognition system."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks (WSNs) have been widely used in industrial systems. Industrial systems demand a high degree of reliability and real-time requirements in communications. In many industrial WSNs applications, flows with different levels of criticality coexist in the system. When errors or exceptions occur, high-criticality flows must be guaranteed reliably and in real time. However, only a few works focus on mixed-criticality industrial systems. Concerning this issue, in this paper, we study mixed-criticality industrial systems and propose a supply/demand bound function analysis approach based on earliest deadline first scheduling. In addition, our method considers both source routing and graph routing. At the beginning, when the system is in low-criticality mode, source routing considers the schedulability of each flow. When errors or exceptions occur, the system switches to high-criticality mode, and network routing turns to graph routing to guarantee that important flows can be scheduled. By estimating the demand bound for mixed-criticality systems, we can determine the schedulability of industrial systems. Experiments indicate the effectiveness and efficacy of our approach."
  },
  {
    "year": "2017",
    "abstract": "The inflexible management and operation of today’s wireless access networks cannot meet the increasingly growing specific requirements, such as high mobility and throughput, service differentiation, and high-level programmability. In this paper, we put forward a novel multipath-transmission supported software-defined wireless network architecture (MP-SDWN), with the aim of achieving seamless handover, throughput enhancement, and flow-level wireless transmission control as well as programmable interfaces. In particular, this research addresses the following issues: 1) for high mobility and throughput, multi-connection virtual access point is proposed to enable multiple transmission paths simultaneously over a set of access points for users and 2) wireless flow transmission rules and programmable interfaces are implemented into mac80211 subsystem to enable service differentiation and flow-level wireless transmission control. Moreover, the efficiency and flexibility of MP-SDWN are demonstrated in the performance evaluations conducted on a 802.11 based-testbed, and the experimental results show that compared to regular WiFi, our proposed MP-SDWN architecture achieves seamless handover and multifold throughput improvement, and supports flow-level wireless transmission control for different applications."
  },
  {
    "year": "2017",
    "abstract": "Presently, educational institutions compile and store huge volumes of data, such as student enrolment and attendance records, as well as their examination results. Mining such data yields stimulating information that serves its handlers well. Rapid growth in educational data points to the fact that distilling massive amounts of data requires a more sophisticated set of algorithms. This issue led to the emergence of the field of educational data mining (EDM). Traditional data mining algorithms cannot be directly applied to educational problems, as they may have a specific objective and function. This implies that a preprocessing algorithm has to be enforced first and only then some specific data mining methods can be applied to the problems. One such preprocessing algorithm in EDM is clustering. Many studies on EDM have focused on the application of various data mining algorithms to educational attributes. Therefore, this paper provides over three decades long (1983-2016) systematic literature review on clustering algorithm and its applicability and usability in the context of EDM. Future insights are outlined based on the literature reviewed, and avenues for further research are identified."
  },
  {
    "year": "2017",
    "abstract": "With the fast development of high-speed railway (HSR), how to provide high-quality and cost-effective wireless services for HSR users has attracted increasing attention in recent years. A key issue is to design an efficient resource management scheme for wireless service delivery between the train and the ground. In this paper, we first provide an overview of the existing resource management schemes and some unsolved challenges are identified. To address these challenges, a cross-layer optimization framework is developed for facilitating the design and optimization of dynamic resource management. Then, the resource management problem is formulated as a stochastic optimization problem, which jointly considers the quality-of-service requirements and dynamic characteristics of HSR wireless communications. The stochastic network optimization theory is applied to transform the intractable stochastic optimization problem into a tractable deterministic optimization problem, which can be further decomposed into two separate subproblems: admission control and resource allocation. A fully distributed admission control scheme is proposed for the admission control subproblem, and a cooperative distributed resource allocation scheme is developed for the mixed-integer resource allocation subproblem with guaranteed global optimality. Finally, a distributed dynamic resource management algorithm is proposed to solve the original stochastic optimization problem with high reliability and robustness against central node failure. The performance of the proposed algorithm is analyzed theoretically and further validated by numerical simulations under realistic conditions for HSR wireless communications."
  },
  {
    "year": "2017",
    "abstract": "In the context of signal processing, the comparison of time histories is required for different purposes, especially for the model validation of vehicle safety. Most of the existing metrics focus on the mathematical value only. Therefore, they suffer the measuring errors, disturbance, and uncertainties and can hardly achieve a stable result with a clear physical interpretation. This paper proposes a novel scheme of time histories comparison to be used in vehicle safety analysis. More specifically, each signal for comparison is decomposed into a trend signal and several intrinsic mode functions (IMFs) by ensemble empirical mode decomposition. The trend signals reflect the general variation and are free from the influence of high-frequency disturbances. With the help of dynamic time warping, the errors of time and magnitude between trends are calculated. The IMFs, which contain high-frequency information, are compared on frequency, magnitude, and local features. To illustrate the full scope and effectiveness of the proposed scheme, this paper provides three vehicle crash cases."
  },
  {
    "year": "2017",
    "abstract": "With more consumers using online opinion reviews to inform their service decision making, opinion reviews have an economical impact on the bottom line of businesses. Unsurprisingly, opportunistic individuals or groups have attempted to abuse or manipulate online opinion reviews (e.g., spam reviews) to make profits and so on, and that detecting deceptive and fake opinion reviews is a topic of ongoing research interest. In this paper, we explain how semi-supervised learning methods can be used to detect spam reviews, prior to demonstrating its utility using a data set of hotel reviews."
  },
  {
    "year": "2017",
    "abstract": "This paper tackles the problem of the estimation of simplified human limb kinematics for home health care. Angular kinematics are widely used for gait analysis, for rehabilitation, and more generally for activity recognition. Residential monitoring requires particular sensor constraints to enable long-term user compliance. The proposed strategy is based on measurements from two low-power accelerometers placed only on the forearm, which makes it an ill-posed problem. The system is considered in a Bayesian framework, with a linear-Gaussian transition model with hard boundaries and a nonlinear-Gaussian observation model. The state vector and the associated covariance are estimated by a post-regularized particle filter (constrained-extended-RPF or C-ERPF), with an importance function whose moments are computed via an extended Kalman filter (EKF) linearization. Several sensor configurations are compared in terms of estimation performance, as well as power consumption and user acceptance. The proposed constrained-EKF (CERPF) is compared to other methods (EKF, constrained-EKF, and ERPF without transition constraints) on the basis of simulations and experimental measurements with motion capture reference. The proposed C-ERPF method coupled with two accelerometers on the wrist provides promising results with 19% error in average on both angles, compared with the motion capture reference, 10% on velocities and 7% on accelerations. This comparison highlights that arm kinematics can be estimated from only two accelerometers on the wrist. Such a system is a crucial step toward enabling machine monitoring of users health and activity on a daily basis."
  },
  {
    "year": "2017",
    "abstract": "Any large water treatment/production utility that employs autonomous plant as part of its processes will utilize supervisory control and data acquisition systems. These systems will generally be isolated from each other and will exist solely to serve the site they control and visualize. More often, they are delivered and developed organically through cost driven maintenance regimes that prioritize on process risk rather than asset lifecycles. In some cases, this has led to variations in installed software and hardware applications, not only across a business enterprise, but also down to a site level. This is usually based on favored products at the time of supply, and in turn requires a broader range of engineering skills to maintain and update. The previous adoption of a “fit and forget”model has also led to large areas of unsupported computer assets within an organization that further introduces “data risk.”As regulatory bodies start to impose stricter compliance measures on the water industry, so to the suppliers become more reliant upon their process data. This paper presents how a water utility has employed a modular approach and has set to standardize its SCADA assets across all business sectors. It reviews the hardware the systems are installed on, the software applications used to deliver the integration, and discusses how the software devices have been modeled and tagged in search of a common information model. All in line with their respective field assets. It also discusses some of the human factors surrounding the replacement of control systems."
  },
  {
    "year": "2017",
    "abstract": "Mindful of several recent developments in the area of wireless optical data transfer over long and short distances, we present a novel technique to transmit data using an optical carrier. With this technique, the irradiance distribution of a Gaussian optical beam is controlled by passing it through an electronically controlled tunable lens (ECTL). The focal length of the ECTL is controlled by varying the root mean squared voltage of its input electrical drive signal, which alters the irradiance distribution of the Gaussian beam at any fixed plane located after the ECTL. These changes in the irradiance distribution can be interpreted as irradiance modulation with an applied input electrical signal. Variations in the input voltage signal to the ECTL result in variations in the photo-current produced inside a photo-detector of a finite active area. This paper aims to use this unique and simple method for free-space data transfer, and understand the limitations imposed by the currently available commercial ECTL technologies. With rapidly improving ECTL switching speeds and their already widespread use in mobile devices, this method promises an excellent alternative to existing point-to-point wireless data transfer schemes with minimum alterations to the existing hardware architecture of portable mobile devices."
  },
  {
    "year": "2017",
    "abstract": "Energy conservation is considered to be one of the key design challenges within resource constrained wireless sensor networks that leads the researchers to investigate energy efficient protocols with some application specific challenges. Dynamic clustering is generally considered as one of the energy conservation techniques; but unbalanced distribution of cluster heads, highly variable number of sensor nodes in the clusters and high number of sensor nodes involved in event reporting tend to drain out the network energy quickly resulting premature decrease in network lifetime. In this paper, a dynamic and cooperative clustering and neighborhood formation scheme is proposed that is expected to evenly distribute energy demand from the cluster heads and optimize the number of sensor nodes involved in event reporting. Assuming multiple sensors will form a cluster, while responding to an event to report to the fusion center. However, all the sensor nodes are assuming to report the sensing parameters to a cluster-head; which are to be summarized and then report it to fusion center. The transmission of the same event data from multiple sensors within the cluster at different distances with single or multiple antennas to the cluster-head with similar antenna characteristics can be realized as multiple-input multiple-output (MIMO) channel set up as found in the literature. Such realization among clusters of MIMO channel and existence of a feedback channel between the clusters and fusion center is the key of the proposed framework. The dynamic behavior has been adopted within the framework with a proposed index derived from the received measure of the channel quality, which has been attained through the feedback channel from the fusion center. The dynamic property of the proposed framework makes it robust against time-varying behavior of the propagation environment. The proposed framework is independent of the nature of the sensing application, providing with universal behavio..."
  },
  {
    "year": "2017",
    "abstract": "Online social networks (OSNs) gradually integrate financial capabilities by enabling the usage of real and virtual currency. They serve as new platforms to host a variety of business activities, such as online promotion events, where users can possibly get virtual currency as rewards by participating in such events. Both OSNs and business partners are significantly concerned when attackers instrument a set of accounts to collect virtual currency from these events, which make these events ineffective and result in significant financial loss. It becomes of great importance to proactively detecting these malicious accounts before the online promotion activities and subsequently decreases their priority to be rewarded. In this paper, we propose a novel system, namely ProGuard, to accomplish this objective by systematically integrating features that characterize accounts from three perspectives including their general behaviors, their recharging patterns, and the usage of their currency. We have performed extensive experiments based on data collected from the Tencent QQ, a global leading OSN with built-in financial management activities. Experimental results have demonstrated that our system can accomplish a high detection rate of 96.67% at a very low false positive rate of 0.3%."
  },
  {
    "year": "2017",
    "abstract": "The measurement of human miRNA functional similarity is an important research for studying miRNA-related therapeutic strategy. Pair wise-based approaches using disease-miRNA associations have recently become a popular tool for inferring miRNA functional similarity. However, the miRNA functional similarity is vitally influenced by calculation of the disease semantic similarity in those methods. Moreover, integrating information content with hierarchical structure can improve calculation of the miRNA functional similarity. Therefore, we propose a group-wise method for inferring the miRNA functional similarity, named GMFS. First, the information content is computed by using disease MeSH descriptors to describe the specific of disease. Second, the acquirement of disease feature is based on the hierarchical structure as well as the information content of disease. Finally, the miRNA functional similarity is measured by using both miRNA-disease associations and the disease feature. To validate the effectiveness of the GMFS, we compare our method with several existing methods in terms of the average similarity of intra-family, inter-family, intra-cluster, and inter-cluster groups. Thep-values achieved by non-parametric test further indicate that the GMFS could have reliable miRNA similarity. Besides, the correlation between other biological information of the miRNA and the miRNA functional similarity is analyzed. The influence of the varying parameter is shown. We also demonstrate that the constructed network based on the miRNA functional similarity is a scale-free and small-world network. The superior performance on uncovering lymphoma-related miRNAs explains the ability of the GMFS inferring the miRNA functional similarity."
  },
  {
    "year": "2017",
    "abstract": "Trustworthiness is an important indicator for service selection and recommendation in the cloud environment. However, predicting the trust rate of a cloud service based on its multifaceted quality of services (QoSs) is not an easy task due to the complicated and non-linear relations between service's QoS values and the final trust rate of the service. According to the existing studies, the adoption of intelligent technique is a rational way to attack this problem. Neural network (NN) has been validated as an effective way to predict the trust rate of the service. However, the parameter setting of NN, which plays an important role in its prediction performance, has not been properly addressed yet. In the paper, particle swarm optimization (PSO) is introduced to enhance NN by optimizing its initial settings. In the proposed hybrid prediction algorithm named PSO-NN, PSO is used to search the appropriate parameters for NN so as to realize accurate trust prediction of cloud services. In order to investigate the effectiveness of PSO-NN, extensive experiments are performed based on public QoS data set, as well as in-depth comparison analysis. The results show that our proposed approach has better performance than basic classification methods in most cases, and significantly outperforms the basic NN in the terms of prediction precision. In addition, PSO-NN demonstrates better stability than the basic NN."
  },
  {
    "year": "2017",
    "abstract": "Cloud radio access network (C-RAN) is considered to be a promising architecture for the future network due to its competitive advantage in both spectral efficiency and energy efficiency (EE). However, the tremendous increase in the mobile data traffic lead resource allocation in C-RANs to be less flexible and efficient. To solve this problem, an energy efficient resource allocation scheme for uplink C-RAN is investigated, and its software-based architecture, which provides the proposed framework in a software-defined network fashion is designed. The proposed framework analyzes the information from the data plane, and completes the resource allocation process in the control plane. In the control plane, a relay region selection algorithm is designed to reduce the computational complexity after the user classification module. Then an optimal power allocation, relay selection and network selection scheme with total power constraint, quality of service requirements, and radio resource constraints are proposed to maximize EE. Based on the dual decomposition method and the Dinkelbach method, optimal power allocation, relay selection, and network selection can be obtained from the reformulated convex problem. Numerical results demonstrate the effectiveness of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "For the control request of specialty vehicles, this paper combines a phase plane analysis with the variable universe fuzzy control technique. Moreover, we develop a new systemic design strategy for the adaptive fuzzy logic controller. With the phase plane analysis, the complete rule base that consists of few key rules can be objectively established, which avoids the irrationality introduced into the process via the subjectivity of the designer of the fuzzy controllers. Furthermore, with the variable universe, the design requirements of the membership functions can be relaxed. Meanwhile, the accuracy of the performance of the fuzzy logic controller can be enhanced despite the limited number of fuzzy rules in the rule base. Based on the Lyapunov stability theory, the stability of the close-loop system can be guaranteed. Simulation results of a double inverted pendulum demonstrate the feasibility of the design strategy for the adaptive fuzzy logic controller, which simplifies the design of the fuzzy logic controller and ensures control. The application of this design strategy can significantly lighten the burden for fuzzy logic controller designers and shorten the development period of the fuzzy logic controller."
  },
  {
    "year": "2017",
    "abstract": "Complex computing based on multi-heterogeneous parameters can utilize the Lebesgue measure to measure their linear and non-linear relations in infinite dimensional Hilbert space, which can characterize those different dimensional characteristics in a set of autonomous learning base. The temporal-spatial micro-scale mildew indices can be fitted by using four heterogeneous parameters, including temperature, humidity, wind force, and water vapor pressure. This paper proposes a fitting process of heterogeneous parameter curves, which is based on a common reference coordinate base. The multi-scale functional fitting tree is constructed by R*-tree and the Lebesgue similarity measure algorithm. When the similarity of two tree nodes representative of similar environmental sub-space exceeds a given threshold, these nodes can be combined into a parent node, which represents the environmental characteristic of combined bigger-space and its mildew curve is the fitted result of all the son-node mildew curves. The curve similarity measurement based on the Lebesgue multi-dimensional matrix and the functional curve generating process of multi-heterogeneous data curves are proposed in the micro-space mildew index fitting example. The boundary finding of fitting curves can be realized by envelop curve algorithm. Based on two years environmental measurement parameters of ancient dwellings, the mildew index comparison of indoor and outdoor can be obtained. The experimental results show that the multi-heterogeneous curve fitting algorithm is effective and the mildew indices of indoor and outdoor have cyclical differences."
  },
  {
    "year": "2017",
    "abstract": "Ciphertext-policy attribute-based encryption (CP-ABE) is widely used in many cyber physical systems and the Internet of Things for guaranteeing information security. In order to improve the performance and efficiency of CP-ABE, this paper makes a change to the access structure of describing access polices in CP-ABE, and presents a new CP-ABE system based on the ordered binary decision diagram (OBDD). The new system makes full use of both the powerful description ability and the high calculating efficiency of OBDD. First, in the access structure, the new system allows multiple occurrences of the same attribute in a strategy, supports both positive attribute and negative attribute in the description of access polices, and can describe free-form access polices by using Boolean operations. Second, in the key generation stage, the size of secret keys generated by the new system is constant and not affected by the number of attributes; furthermore, time complexity of the key generation algorithm is O(1). Third, in the encryption stage, both the time complexity of the encryption algorithm and the size of generated ciphertext are determined by the number of valid paths contained in the OBDD instead of the number of attributes occurring in access polices. Finally, in the decryption stage, the new system supports fast decryption and the time complexity of the decryption algorithm is only O(1). As a result, compared with existing CP-ABE schemes, the new system has better performance and efficiency. It is proved that the new CP-ABE system can also resist collision attack and chosen-plaintext attack under the decisional bilinear Diffie Hellman assumption."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a random frequency diverse array-based directional modulation with artificial noise (RFDA-DM-AN) scheme is proposed to enhance physical layer security of wireless communications. Specifically, we first design the RFDA-DM-AN scheme by randomly allocating frequencies to transmit antennas, thereby achieving 2-D (i.e., angle and range) secure transmissions, and outperforming the state-of-the-art 1-D (i.e., angle) phase array (PA)-based DM scheme. Then we derive the closed-form expression of a lower bound on the ergodic secrecy capacity (ESC) of our RFDA-DM-AN scheme. Based on the theoretical lower bound derived, we further optimize the transmission power allocation between the useful signal and artificial noise (AN) in order to improve the ESC. Simulation results show that: (1) our RFDA-DM-AN scheme achieves a higher secrecy capacity than that of the PA-based DM scheme; (2) the lower bound derived is shown to approach the ESC as the number of transmit antennas N increases and precisely matches the ESC when N is sufficiently large; and (3) the proposed optimum power allocation achieves the highest ESC of all power allocations schemes in the RFDA-DM-AN."
  },
  {
    "year": "2017",
    "abstract": "Multi-input multi-output (MIMO) holds great potential in the high-speed transmission of visible light communication (VLC). However, as for the current MIMO-VLC techniques, the error performance is improved by wasting spatial resources, which just drops the core advantage within an MIMO structure. Moreover, they cannot change over the channel, which greatly limits their application range. In this paper, a general design criterion of the channel-adaptive space-collaborative constellation (CASCC) is established for MIMO-VLC systems. Specifically, we not only consider the channel into our criterion, but also build relations among the light-emitting diodes to exploit the spatial resources instead of wasting. Under the criterion, a regular CASCC is particularly designed for2×2MIMO-VLC in terms of the basic four-point constellation and the high-order constellation. Correspondingly, a fast maximum likelihood (ML) detection algorithm for CASCC is proposed. Simulation results show that our proposed CASCC obtains better error performance and wider application range compared with the conventional MIMO-VLC schemes. Moreover, the fast ML algorithm reduces the computational complexity without any performance loss."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a frequency reconfigurable antenna system with a directional selectivity is presented. The reconfiguration of the antenna's radiation characteristics is wirelessly controlled through a mobile phone and a microcontroller. The antenna system is a multi-element radiator composed of four monopoles on top of a hexagonal ground plane, in addition to four rectangular microstrip two-elements antenna arrays. The monopoles and the microstrip arrays are designed to contribute to the communication requirements of the complete system. The position, orientation, and topology of the various antennas are optimized to achieve the required frequency reconfigurability in addition to the variable selective directivity performance. The whole system is fabricated and integrated in a single compact unit controlled by a microcontroller, four servo motors, and a Bluetooth module. The antenna system is tested and the measured results confirm the validity of the proposed design."
  },
  {
    "year": "2017",
    "abstract": "A human localization system using multi-source heterogeneous data in indoor environments is proposed in this paper. The system can be easily constructed with already deployed Wi-Fi and camera infrastructures and is able to make use of received signal strength samples, surveillance images, and room map information to achieve a comparable performance. In a corridor scenario, we optimize propagation model (PM) parameters with crowdsourcing data from only several locations and establish a data table of optimized parameters for trilateration localization. These crowdsourcing data are also used to correct trilateration localization results, through which localization performance can be greatly improved. In a room scenario, we locate a human object with a panoramic camera and room map. We first detect the human object on the observed image and search a pixel location that represents the object's location best. Then, the pixel location on the image is mapped to the room map using an artificial neural network. By this method, localization accuracy of sub-meter level can be obtained. We perform the proposed system in our experimental environment, and the experimental results show that our localization system not only requires no extensive time and labor cost, but also outperforms fingerprinting and PM localization systems."
  },
  {
    "year": "2017",
    "abstract": "Since indoor visible light communication (VLC) modulates the information into the light beams emitted from light-emitting diodes, the channel gain is often modeled as the Lambertian model. For different spatial locations of transmitters and receivers, the channel gain for VLC directly changes with several related geometrical parameters. The distinct geometrical feature makes the ergodic capacity of indoor VLC different from that of radio-frequency communication. However, the issue has not been studied currently. In this paper, we propose the lower bounds on the point-to-point capacity, which have simple expressions with respect to the geometrical parameters. Then, by analyzing indoor human mobility, two typical distributions of the geometrical parameters are considered. Correspondingly, we derive the lower bounds on the ergodic capacity, which are related to the variables of the geometrical feature and the distribution model. Furthermore, simulation results show that our lower bounds on the ergodic capacity are effective to reveal the geometrical feature of indoor VLC systems. Moreover, our proposed lower bounds are tight to the numerical upper bounds at high optical signal-to-noise rates, which are the main application zones of indoor VLC systems."
  },
  {
    "year": "2017",
    "abstract": "In multi-autonomous underwater vehicle (multi-AUV) systems, the convergence rate is characterized by the pace of consistency of the key state information for each member. The topology with leader-follower architecture is designed as a combination of an undirected graph between followers and a digraph between leaders and followers. An overview of influences on convergence rate of the second-order consensus algorithm is elaborated in three aspects, along with the main contributions in this paper. Specifically, the explicit expression of the maximum convergence rate is established based on the root locus method, and then, the effects of control parameters on the convergence rate are analyzed. Moreover, the influences of network topologies on the convergence rate are investigated from the view of adjusting the existing connectivity, changing the weights on links, and utilizing hierarchical structure. The combination of consensus and filtering algorithm is also an approach to enhance the capacity of multi-AUV systems. In order to eliminate the accumulated errors in the process of dead reckoning, a collaborative navigation model is presented, and then, a localization approach based on consensus-unscented particle filter algorithm is proposed. Simulations results are provided to verify location performance under the assumption of Gaussian white noise in the systems. In addition, the influences of the topologies on positioning accuracy are explored."
  },
  {
    "year": "2017",
    "abstract": "In this paper, based on outdoor microcellular channel measurements at 32 GHz for 5G radio systems, a comprehensive channel modeling, simulation, and validation are performed. The directional-scan-sounding measurements using a horn antenna rotated with an angular step at the receiver are carried out, which constitutes a virtual array to form a single-input multiple-output radio channel. The directional- and omni-directional path-loss models are developed by using close-in and floating-intercept methods. Non-parametric and parametric methods are applied to extract large-scale channel parameters (LSPs). The non-parametric method is based on the definition of a channel parameter, whereas the parametric method is derived by the space-alternating generalized expectation-maximization (SAGE) algorithm, which can de-embed an antenna pattern. It is found that the LSPs in the angular domain are significantly different by using the two methods; however, the LSPs in the delay domain almost stay the same. By comparing the LSPs with the parameter table at 32 GHz with 3GPP standard, it is found that 3GPP LSPs should be corrected at the International Telecommunications Union-assigned millimeter wave (mmWave) frequencies for 5G. In this paper, the channel simulation is implemented by using the quasi-deterministic radio channel generator (QuaDRiGa) platform recommended by 3GPP. By comparing the LSPs with the simulated and measured results, it is found that QuaDRiGa is a good platform at the mmWave band, even if it is originally developed for channel simulation below 6 GHz. The results of this paper are important and useful in the simulations and design of future 5G radio systems at 32 GHz."
  },
  {
    "year": "2017",
    "abstract": "Device to device (D2D) communication brings numerous benefits for future heterogeneous cellular networks. However, an energy-efficient design of such D2D communications is a critical challenge due to the cochannel deployment and limited power of users. In this paper, we present an energy-efficient self-organized cross-layer optimization scheme, which aims to maximize the D2D communication energy-efficiency without jeopardizing the quality of service (QoS) requirements of other tiers. Specifically, we model the cross-layer optimization, which includes resource block (RB) and power allocation using a noncooperative game. In the proposed scheme, each D2D transmitter user, which is a player in the game, operates in a self-organizing manner and selects the RBs and the power levels for enhancing its energy efficiency while maintaining the QoS requirements of other heterogeneous parties. Concerning the computationally intense nature of the global optimization problem, we decompose the problem into two subproblems: the RB allocation and the power allocation, and solve them iteratively in a game-theoretic manner. Simulation results demonstrate superior energy efficiency performance of the proposed scheme over conventional schemes. In addition, it is also shown via simulation that the performance of the proposed scheme degrades if the channel state information is not precisely available."
  },
  {
    "year": "2017",
    "abstract": "Persistently high traffic loads and heterogeneous quality of service (QoS) requirements arising from machine-to-machine communication in wireless 5G systems require effective random access prioritization. 5G systems will likely evolve from mature wireless technologies, e.g., long term evolution (LTE). LTE conducts random access through preamble contention based on slotted Aloha principles. Prior studies have mainly examined random access prioritization for addressing temporary traffic bursts through manipulating the access contention procedure on a given set of preambles, such as adapting the number of permitted transmission attempts and back off windows. We conduct a detailed study of random access prioritization through separating (splitting) the random access preambles into non-overlapping priority classes. Based on the obtained insights, we develop the Load-Adaptive Throughput-MAximizing Preamble Allocation (LATMAPA). LATMAPA automatically adjusts the preamble allocation to the priority classes according to the random access load and a priority tuning parameter. Extensive analytical and simulation evaluations indicate that LATMAPA provides effective QoS differentiation across a wide range of random access loads, which are expected in 5G systems."
  },
  {
    "year": "2017",
    "abstract": "This paper aims to minimize the tracking error of a laser auto-focus system that in developing treatment, due to uncertainty setting and modeling of its control system. The error is derived from the imperfect response to the standardized object reference. Optimizing procedure is obtained via multi-variable parameters by using a UniNeuro-hybrid uniform design genetic algorithm (HUDGA). In general, the parameter setting of a servo-controller is determined by some complex analysis or the trial-and-error of an expert person; when the controlled model is distinctly undefined, the process requires considerable time. The UniNeuro-HUDGA requires only 40 experiments to be conducted in the uniform design (UD) of building the metamodel via a neural network (UniNeuro), which is used as the fitness function in the optimization procedure by combining a genetic algorithm with UD. UD is then embedded in the HUDGA for initializing and enriching the solution set, whereas chromosomes used in crossover and mutations generated by UD chromosomes are individually conveyed using a selection procedure combined with the Euclidean distance; then, the optimized setting has investigated by the equipment. This paper concludes that the proposed algorithm optimizes the adjustable parameters of a servo-controller and outperforms the trial-and-error of an expert person."
  },
  {
    "year": "2017",
    "abstract": "Approximate message passing (AMP) is a low-cost iterative signal recovery algorithm for linear system models. When the system transform matrix has independent identically distributed (IID) Gaussian entries, the performance of AMP can be asymptotically characterized by a simple scalar recursion called state evolution (SE). However, SE may become unreliable for other matrix ensembles, especially for ill-conditioned ones. This imposes limits on the applications of AMP. In this paper, we propose an orthogonal AMP (OAMP) algorithm based on de-correlated linear estimation (LE) and divergence-free non-linear estimation (NLE). The Onsager term in standard AMP vanishes as a result of the divergence-free constraint on NLE. We develop an SE procedure for OAMP and show numerically that the SE for OAMP is accurate for general unitarily-invariant matrices, including IID Gaussian matrices and partial orthogonal matrices. We further derive optimized options for OAMP and show that the corresponding SE fixed point coincides with the optimal performance obtained via the replica method. Our numerical results demonstrate that OAMP can be advantageous over AMP, especially for ill-conditioned matrices."
  },
  {
    "year": "2017",
    "abstract": "To achieve the maximum network energy efficiency (EE) and guarantee the fairness of EE among cognitive users (CUs), respectively, in the massive multiple-input multiple-output cognitive radio network, we investigate two power optimization problems: network EE optimization problem (NEP) and fair EE optimization problem (FEP) under a practical power consumption model. Because of the fractional nature of EE and the interference, both NEP and FEP are non-convex and NP-hard. To tackle these issues, we propose two energy-efficient power control algorithms, in which we decompose NEP/FEP into two steps, and solve them with an alternating iterative optimization scheme. Specifically, in the first step, for an initial transmit power, the maximum network EE/fair EE is achieved by the bisection method based on fractional programming; then, with the achieved EE, in the second step, the adapted optimal transmit power can be obtained by an efficient iterative algorithm based on sequential convex programming. These two steps are performed alternately until the stop conditions are reached. Numerical results confirm the fast convergence of these proposed algorithms and demonstrate their effectiveness with high network EE and well fairness of EE among CUs. Furthermore, it is illustrated that, under a practical power consumption model, more cognitive base station antennas would cause some loss of network EE but bring some improvements on the network spectral efficiency (SE), whereas higher circuit power consumption would reduce the network EE but only slightly affect the network SE."
  },
  {
    "year": "2017",
    "abstract": "This paper proposed an extension of bipedal spring-mass model with variable slack length and stiffness. Since conventional bipedal spring-mass model has problems to accomplish stepping and low speed walking, we solve it by adjusting slack length of spring leg. Moreover, to produce heel-strike and toe-strike running, the stiffness of spring is changed to get running gaits with different frequencies. In order to imitate the human foot rolling behavior, we synchronize motion of center of pressure with that of center of mass. Based on the proposed methods, simulations of a human size robot achieve walking, heel-strike, and toe-strike running. Walking at a speed of 1 m/s can generate the double-humped ground reaction force. Heel-strike and toe-strike running gaits at a speed of 4.5 m/s are accomplished. The frequencies of two running gaits are consistent with those in human motion capture data. Joints angular positions of walking and heel-strike running are similar to those of human data. Therefore, the proposed model turns out to be effective in generating human-like walking and running behaviors."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a multiple frequency bands-switching scheme for wideband channel sounding, which is able to extend the overall sounding bandwidth without changing operation bandwidth of the hardware. It is especially suitable for low mobility and high data-rate scenarios (e.g., indoor hot spot) in the fifth generation mobile communication systems. With this scheme, a channel sounder is developed on a software-defined radio platform that employs an orthogonal frequency division multiplexing signal at 5.6 GHz. In each sounding cycle, ten concatenated frequency bands (20 MHz bandwidth) are covered to acquire an equivalent measurement over a 200-MHz bandwidth, corresponding to 5-ns time delay resolution. The key challenges and solutions for hardware system calibration, including amplitude and phase compensation on different frequency bands, are detailed to ensure the accuracy of measurement results. Next, the spurious free dynamic range of channel impulse response is modeled and verified for this sounding scheme. Finally, to explore the massive multiple-input-multiple-output channel characteristics in indoor scenarios, a virtual large antenna array is built based on the wideband sounder."
  },
  {
    "year": "2017",
    "abstract": "Conventional machine stator open-phase fault detection methods rely on the detection of current harmonics from the sensing of phase currents. Because the magnitudes of current harmonics are proportional to the machine load condition, it is a challenge for the phase fault detection at the light load condition when fault-induced current harmonics are too small to detect. This paper proposes an improved stator phase fault detection for permanent magnet (PM) machines based on the use of neutral point (NP) in Y-connected windings. It is shown that the first-order voltage harmonic is resultant once the open-phase fault occurs. Comparing with prior detection methods based on the current measurement, the fault detection using NP voltage is insensitive to the load condition, because the proposed fault signal is induced by the voltage unbalance as a result of the open phase. In addition, considering the fault tolerant control, a single-phase drive is developed by connecting the machine NP to one of the inverter legs. The machine can drive at the most efficient condition using standard three-leg inverters under phase fault. A 50-W PM machine with the accessible NP is used to evaluate the proposed open-phase fault detection and tolerant control method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a measurement campaign for massive multiple-input multiple-output (MIMO) channel characterization in both line-of-sight (LoS) and non-LoS outdoor environments is introduced. The measurements are conducted at the center frequency of 15 GHz with a bandwidth of 4 GHz. A virtual 40 × 40 planar antenna array formed by stepping a vertically-polarized bi-conical omni-directional antenna (ODA) along regularly-spaced grids is used in the receiver (Rx). The transmitter is equipped with a single ODA. To investigate channel variations over the Rx array, this 1600-element Rx array is split into multiple 7 × 7 sub-arrays, and a maximum-likelihood parameter estimation algorithm implemented using the space-alternating generalized expectation-maximization principle is applied to extracting multipath components (MPCs) from sub-array outputs. The spatial variability of K-factor, composite channel spreads in delay, azimuth, and elevation of arrival are investigated. Based on the estimated MPCs' parameters, multipath clusters are identified and associated across the array to find the so-called spatial-stationary (SS) clusters. From several hundreds of SS-clusters extracted, we establish a stochastic model for their life distances in horizontal and vertical directions, two-dimensional (2-D) life region, and variations of cluster spreads. These findings are important for massive MIMO channel modeling in the cases, where 2-D largescale arrays are considered."
  },
  {
    "year": "2017",
    "abstract": "A compact shorted patch antenna with quasi-isotropic radiation pattern is proposed in this paper. The antenna consists of a radiating patch, a small ground plane that has the same dimensions with the top patch, and a metallic sidewall which connects the former two. A coaxial probe is used to feed the antenna and excite its fundamental TEM mode, whose magnetic field generates surface electric current on the shorted sidewall and electric field generates surface magnetic current on the open-ended aperture. Due to the inherent properties of the electric and magnetic fields, the corresponding currents are found not only perpendicular but also quadrature with each other, and, therefore, the patch antenna can provide a quasi-isotropic radiation pattern without involving complex feeding circuit. To verify the theory, a prototype operating at 2.4-GHz WLAN band was designed, fabricated, and measured. Reasonable agreement between the calculated, simulated, and measured results is obtained. It has been shown that the difference between the maximum and minimum radiation power densities is ~2 dB over the entire spherical radiating surface, and the difference can be further reduced to ~0.9 dB by using a lower profile."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an Interactive Multiple Model filter design is proposed to improve signal shadowing detection performance on land-mobile channels during rain fading for a downlink operating at Ka-band through a geostationary satellite. A robust solution for on-line determination of the filter measurement error covariance is provided. Analyses are performed for a combination of channels under different atmospheric conditions, clear sky and rain, and different scenarios, suburban and rural. Using International telecommunications union-based synthesized attenuation time-series, the proposed filter achieved a reduction in the incorrect detection duration of 32% for the scenario with a mobile terminal experiencing rain, and by 60% for the scenario with a fixed terminal experiencing rain."
  },
  {
    "year": "2017",
    "abstract": "The diffusion of mobile devices equipped with sensing, computation, and communication capabilities is opening unprecedented possibilities for high-resolution, spatio-temporal mapping of several phenomena. This novel data generation, collection, and processing paradigm, termed crowdsensing, lays upon complex, distributed cyberphysical systems. Collective data gathering from heterogeneous, spatially distributed devices inherently raises the question of how to manage different quality levels of contributed data. In order to extract meaningful information, it is, therefore, desirable to the introduction of effective methods for evaluating the quality of data. In this paper, we propose an approach aimed at systematic accuracy estimation of quantities provided by end-user devices of a crowd-based sensing system. This is obtained thanks to the combination of statistical bootstrap with uncertainty propagation techniques, leading to a consistent and technically sound methodology. Uncertainty propagation provides a formal framework for combining uncertainties, resulting from different quantities influencing a given measurement activity. Statistical bootstrap enables the characterization of the sampling distribution of a given statistics without any prior assumption on the type of statistical distributions behind the data generation process. The proposed approach is evaluated on synthetic benchmarks and on a real world case study. Cross-validation experiments show that confidence intervals computed by means of the presented technique show a maximum 1.5% variation with respect to interval widths computed by means of controlled standard Monte Carlo methods, under a wide range of operating conditions. In general, experimental results confirm the suitability and validity of the introduced methodology."
  },
  {
    "year": "2017",
    "abstract": "A low profile omnidirectional patch antenna with filtering response is investigated in this paper. The triangular patch antenna is axially fed by a probe at its center, exciting both its TM10and TM11modes. Comparing with the traditional circular patch, the triangular patch can not only minimize the patch size but also can generate a radiation null at the upper band edge. A ring slot and a series of shorting vias are introduced into the patch to merge the two modes, enhancing the bandwidth of the passband. The combination of the two elements simultaneously generates a radiation null at the lower band edge. Consequently, a compact filtering patch antenna with quasi-elliptic bandpass response is obtained without involving specific filtering circuits. The prototype with profile of $0.03 λ0has a 10-dB impedance bandwidth of 8.9% (4.3-4.7 GHz), an average gain of 6.0 dBi within passband, an out-of-band suppression level of more than 30 dB within lower stopband (0-3.6 GHz), and more than 20 dB within upper stopband (5.1-6.3 GHz)."
  },
  {
    "year": "2017",
    "abstract": "Pervasive social networking (PSN) is a fundamental infrastructure in social networking that has played an important role in not only the Internet but also mobile domains. A practical and accurate evaluation system is required to ensure the further development of PSN. Secure and efficient communication is also an essential issue in PSN to increase its adoption in daily life. In this paper, we discuss the establishment of a hierarchical evaluation system to support secure and trustworthy PSN with multiple and variable nodes. The proposed hierarchical evaluation system is essentially based on a special symmetric balanced incomplete block design: the (7, 3, 1)-design and the tree structure. Together, they constitute a multilevel system that supports both our hierarchical trust level (HTL) evaluation system and key agreement scheme. The former solves the problem of trust evaluation in PSN, and the latter guarantees the secure communication of trusted nodes. Note that both security and performance analyses show that the proposed HTL evaluation system can support extensive adoption of efficient and secure PSN."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address the problem of green and secure communications under adverse conditions, i.e., no instantaneous eavesdropper channel state information (CSI) and imperfect instantaneous legitimate CSI. The benefits of a massive multiple-input multiple-output relay are exploited to significantly improve the secrecy energy efficiency (bit per Joule), which is defined as the ratio of secrecy outage capacity and total power consumption. The focus of this paper is on joint power allocation at the source and the relay to maximize the secrecy energy efficiency. Accordingly, two energy-efficient power allocation schemes are proposed under joint and distributed source and relay power constraints. We show that the two schemes asymptotically approach the same saturated energy efficiency. Finally, simulation results validate the advantage of the proposed energy-efficient schemes compared with several baseline schemes."
  },
  {
    "year": "2017",
    "abstract": "To mitigate spectrum scarcity, the cognitive radio (CR) paradigm has been invoked for improving the overall exploitation of the licensed spectrum by identifying and filling the free spectrum holes without degrading the transmission of primary users (PUs). Hence, we conceive a CR communication scheme, which enables a cognitive user (CU) to sense the activity of the PUs over a primary radio (PR) channel, which is exploited to transmit data using the modified Go-Back-N hybrid automatic repeat request (GBN-HARQ) protocol, when PR channel is free from the PUs. This arrangement is termed as the cognitive GBN-HARQ (CGBN-HARQ), whereby the activity of the PUs on the PR channel is modeled as a two-state Markov chain having “ ON” and “ OFF” states. However, the CU may wrongly detect the “ ON”/“ OFF” activity of the PUs in the channel, hence resulting in false-alarm or misdetection. Therefore, the two-state Markov chain is extended to four states by explicitly considering all the wrong sensing decisions. In this paper, we analytically modeled the CGBN-HARQ scheme with the aid of a discrete time markov chain (DTMC). Explicitly, an algorithm is developed for deriving all the legitimate states and for eliminating the illegitimate states, which assists us in reducing both the dimensionality of the state transition matrix and the associated computational complexity. Furthermore, based on DTMC modeling, we derive closed-form expressions for evaluating the throughput, the average packet delay, and the end-to-end packet delay of CGBN-HARQ in realistic imperfect sensing environment. The results are also validated by our simulations. Our performance results demonstrate that both the achievable throughput and the delay are significantly affected by the activity of the PUs as well as by the reliability of the PR channel and by the number of packets transmitted per time-slot (TS). To attain the maximum throughput and/or the minimum transmission delay, the number of packets transmitted with..."
  },
  {
    "year": "2017",
    "abstract": "In recent years, vehicular ad hoc networks (VANETs) have received significant interests from both academia and industry because of the ubiquitous communication capabilities they provide. VANETs are expected to support a wide range of applications that may influence our daily life, ranging from road safety applications to entertainment ones. A key to the development of protocols and algorithms for intervehicle communication and services lies in the knowledge of the structural properties of the VANET communication graph. Nonetheless, previous researches represented the VANET communication graph as a set of snapshots and tracked the evolution of some metrics on snapshots at certain time intervals. They neglected to take into account the temporal property of VANETs, which in many real scenarios plays a pivotal role. In this paper, we mainly explore the temporal structural characteristics of VANETs. A time-extended model is first presented to capture the temporal property of VANETs. Based on the model, some key metrics are defined to describe the structural characteristics of VANETs in various aspects. We then employ a real and large-scale urban taxi GPS dataset to provide a comprehensive study of the temporal structural characteristics involved with time-ordered paths, reachability, and connectivity of VANETs. These results are helpful in designing better protocols and algorithms to achieve reliable and low-latency communications."
  },
  {
    "year": "2017",
    "abstract": "An injection-locked frequency divider topology for wide locking-range and high-order division is presented. Based on the theoretical analysis of the locking-range and injection locking characteristic, we propose locking-range enhancement techniques and high-order dividing topology. Fabricated in a 0.18-μm BiCMOS process, three test circuits are designed with only a standard CMOS, aiming at input frequency ranges of 7.8, 11.1, and 11.7 GHz. The 7.8-GHz divide-by-2 ILFD consumes 2.9 mW with a locking range of 692 MHz operated from a 1.5 V supply. The optimized dual injection method improves the locking range by a factor of 10. The 11.1-GHz divide-by-3 ILFD employs an even-harmonic phase tuning technique and the proposed technique improves the locking range by 25%. The core of the 11.1-GHz ILFD consumes 6.15 mW from a 1.8 V supply. For the 11.7-GHz divide-by-3 ILFD, a self-injection technique is proposed that utilizes harmonic conversion and self-injection to improve phase-noise, locking-range, and input sensitivity simultaneously. By employing harmonic tuning and self-injection, odd-order division is enabled with 47.8% enhancement in the locking-range and 15.7-dBc/Hz reduction in phase noise."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate an application of two different beamforming techniques and propose a novel downlink power minimization scheme for a two-tier heterogeneous network (HetNet) model. In this context, we employ the time reversal (TR) technique to a femtocell base station, whereby we assume that a macrocell base station uses a zero-forcing-based algorithm, and the communication channels are subject to frequency selective fading. Additionally, the HetNet backhaul connection is unable to support a sufficient throughput for signaling an information exchange between two tiers. Given the considered HetNet model, a downlink power minimization scheme is proposed, and closed-form expressions concerning the optimal solution are provided by taking this constraint into account. Furthermore, considering imperfect channel estimation at TR-employed femtocell, a worst-case robust power minimization problem is formulated. By devising TR worst-case analysis, this robust problem is transformed into an equivalent formulation that is tractable to solve. The results presented in our paper, show that the TR technique outperforms the zero-forcing one from the perspective of beamforming methods for femtocell working environments. Finally, we validate the proposed power loading strategy for both cases of perfect and imperfect channel estimations."
  },
  {
    "year": "2017",
    "abstract": "This paper aims to study the issue of robust synchronous control of multi-motor. A scheme of synchronous motion based on the artificial potential field is proposed. In this scheme, a model of artificial potential field is constructed and by employing the methods for the flocking control and the sliding mode variable structure, the synchronous control is designed for the multi-motor system. Moreover, by using the Lyapunov method and the graph theory, the stability conditions of the controlled system and further the necessary conditions of multi-motor synchronous control are obtained. It shows that, under such designed control scheme, the robustness with respect to the variations of parameters and the synchronous performance of a multi-motor system can be improved. Finally, the simulation and experimental results illustrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "In addition to being environment friendly, vehicle-to-grid (V2G) systems can help the plug-in electric vehicle (PEV) users in reducing their energy costs and can also help stabilizing energy demand in the power grid. In V2G systems, since the PEV users need to obtain system information (e.g., locations of charging/discharging stations, current load, and supply of the power grid) to achieve the best charging and discharging performance, data communication plays a crucial role. However, since the PEV users are highly mobile, information from V2G systems is not always available for many reasons, e.g., wireless link failures and cyber attacks. Therefore, in this paper, we introduce a novel concept using cyber insurance to “transfer” cyber risks, e.g., unavailable information, of a PEV user to a third party, e.g., a cyber-insurance company. Under the insurance coverage, even without information about V2G systems, a PEV user is always guaranteed the best price for charging/discharging. In particular, we formulate the optimal energy cost problem for the PEV user by adopting a Markov decision process framework. We then propose a learning algorithm to help the PEV user make optimal decisions, e.g., to charge or discharge and to buy or not to buy insurance, in an online fashion. Through simulations, we show that cyber insurance is an efficient solution not only in dealing with cyber risks, but also in maximizing revenue for the PEV user."
  },
  {
    "year": "2017",
    "abstract": "Recent work has demonstrated that self-propagating worms are a real threat to sensor networks. Since worms can enable an adversary to quickly compromise an entire sensor network, they must be detected and stopped as quickly as possible. To meet this need, we propose a worm propagation detection scheme for sensor networks. The proposed scheme applies a sequential analysis to detect worm propagation by leveraging the intuition that a worm's communication pattern is different from benign traffic. In particular, a worm in a sensor network requires a long sequence of packets propagating hop-by-hop to each new infected node in turn. We thus have detectors that observe communication patterns in the network, a worm spreading hop-by-hop will quickly create chains of connections that would not be seen in normal traffic. Once detector nodes identify the worm propagation pattern, they initiate remote software attestations to detect infected nodes. Through analysis and simulation, we demonstrate that the proposed scheme effectively and efficiently detects worm propagation. In particular, it blocks worm propagation while restricting the fraction of infected nodes to at most 13.5% with an overhead of at most 0.63 remote attestations per node per time slot."
  },
  {
    "year": "2017",
    "abstract": "Model management systems become increasingly critical in model-driven engineering. One of the main tasks of these systems is to record the operations performed on model elements. While most systems support the record of primitive model change operations, complex composite model change operations are neglected, which may result in the lack of understandability. In this paper, we propose an approach to capture model transformation from primitive operations to composite ones. First, based on the low-level operation, we define some general high-level operations with hierarchical structures. Then, a matching algorithm is designed to compare primitive operations with the hierarchical structures from the bottom up. If matching successfully, the primitive operations would be lifted to a composited operation. The algorithm is iterative and ensures that all operations are lifted. The evaluation results on real-world cases show that both precision and recall of composite operation detection are improved when compared with the EMF Modeling Operations (EMO) and Complex Change Detection Engine (CCDE) algorithms."
  },
  {
    "year": "2017",
    "abstract": "The soft set theory is a mathematical tool that deals with uncertainty, imprecise, and vagueness in decision systems. It has been widely used to identify irrelevant parameters and make reduction set of parameters for decision making in order to bring out the optimal choices of the decision systems. Many normal parameter reduction algorithms exist to handle parameter reduction and maintain consistency of decision choices. However, they require much time to repeatedly run the algorithm to reduce unnecessary parameters using either parameter important degree or oriented parameter sum. In this paper, we propose an alternative algorithm for parameter reduction and decision making based on soft set theory. We show that the proposed algorithm can reduce the computational complexity and run time compared with baseline algorithms. To evaluate the proposed algorithm, we perform thorough experiments on a binary-valued data set. The experimental result shows that the proposed algorithm is feasible and has relatively reduced the computational complexity and running time. In addition, the algorithm is relatively easy to understand compared with the state of the art of normal parameter reduction algorithm. The proposed algorithm is able to avoid the use of parameter important degree, decision partition, and finding the multiple of the universe within the sets."
  },
  {
    "year": "2017",
    "abstract": "The transmission frequency of power grids, i.e., electric network frequency (ENF), has become a common criterion to authenticate audio recordings during the past decade, drawing much attention from both the academic researchers and law enforcement agencies world widely. The properties of ENF enable forensic applications such as audio evidence timestamp verification and tampering detection. In this paper, based on a general review of existing works, we discuss several important practical problems and facts that have drawn less research attention or have not been formally studied, including ENF detection problems, limitations of the ENF-based tampering detection systems, and the difficulties in the ENF analysis. During ENF detection, the challenges come from not only the noise and the interference, but also the fact that audio recordings without captured ENF can still have signal components in the frequency band of interest (false positive). In ENF-based tampering detection systems, the weakness of commonly used assumptions and the limitations of several existing solutions are discussed. In addition, we reveal that in the most intensively studied ENF-based audio evidence timestamp verification, many works aiming at improving ENF estimation could only produce marginal performance improvement, while the main problems due to noise and interference remain open. All these analysis and discussions are related by a proposed big picture of ENF-based audio authentication systems. After that, we also investigate the strategies to design more reliable audio authentication systems based on the ENF, which consists of a series of research and investigation works."
  },
  {
    "year": "2017",
    "abstract": "With the evolution of the research on network moving target defense (MTD), the selection of optimal strategy has become one of the key problems in current research. Directed to the problem of the improper defensive strategy selection caused by inaccurately characterizing the attack and defense game in MTD, optimal strategy selection for MTD based on Markov game (MG) is proposed to balance the hopping defensive revenue and network service quality. On the one hand, traditional matrix game structure often fails to describe MTD confrontation accurately. To deal with this inaccuracy, MTD based on MG is constructed. Markov decision process is used to characterize the transition among network multi-states. Dynamic game is used to characterize the multi-phases of attack and defense in MTD circumstances. Besides, it converts all the attack and defense actions into the changes in attack surface or the ones in exploration surface, thus improving the universality of the proposed model. On the other hand, traditional models care little about defense cost in the process of optimal strategy selection. After comprehensively analyzing the impact of defense cost and defense benefit on the strategy selection, an optimal strategy selection algorithm is designed to prevent the deviation of the selected strategies from actual network conditions, thus ensuring the correctness of optimal strategy selection. Finally, the simulation and the deduction of the proposed approach are given in case study so as to demonstrate the feasibility and effectiveness of the proposed strategy optimal selection approach."
  },
  {
    "year": "2017",
    "abstract": "In order to explore the coupling inter-relationship between two closely placed memristors (MRs), a new circuit for emulating MRs is proposed. The coupling behavior between closely placed MRs is achieved by making use of the inductive coupling properties of two inductors. The most attractive advantages of this emulator are the unique capability that it offers for wireless coupling and high-frequency operation up to dozens of kilohertz. The theoretical discussion for the dynamic operation performance of this coupled MRs emulator is presented and then validated by simulation and experimental results considering different parameter configurations. The value of memductance for one MR can be altered by the MR on the other side. Meanwhile, no energy could be transferred between two MRs. Good agreement between theoretical and experimental analysis confirms that the proposed emulator could be utilized for discovering potential applications of coupled MRs."
  },
  {
    "year": "2017",
    "abstract": "Underwater images are degraded due to scatters and absorption, resulting in low contrast and color distortion. In this paper, a novel self-similarity-based method for descattering and super resolution (SR) of underwater images is proposed. The traditional approach of preprocessing the image using a descattering algorithm, followed by application of an SR method, has the limitation that most of the high-frequency information is lost during descattering. Consequently, we propose a novel high turbidity underwater image SR algorithm. We first obtain a high resolution (HR) image of scattered and descattered images by using a self-similarity-based SR algorithm. Next, we apply a convex fusion rule for recovering the final HR image. The super-resolved images have a reasonable noise level after descattering and demonstrate visually more pleasing results than conventional approaches. Furthermore, numerical metrics demonstrate that the proposed algorithm shows a consistent improvement and that edges are significantly enhanced."
  },
  {
    "year": "2017",
    "abstract": "Total laryngectomy is a common treatment for patients with advanced laryngeal and hypopharyngeal cancer, but it is also a result from the loss of the natural voice and directly affects the basic communication functions in daily life. Reconstructing the basic communication function is an important issue for these patients after total laryngectomy surgery. Recently, the image processing technique for lip-reading recognition has been widely developed and applied in various kinds of applications. It is also one of the possibly alternative approaches to reconstructing the basic communication function for these patients after total laryngectomy surgery. Although many human lip-reading recognition methods have been developed to detect lip contour precisely, detecting pronouncing lip contour effectively is still a difficult challenge. In this paper, a novel lip-reading recognition algorithm was proposed to recognize English vowels from the lip contour when speaking. Here, several criteria for detecting the mouth region of interest (ROI) were designed to reduce the error rate of detecting the mouth ROI and lip contour. Moreover, several lip parameters, including the width, height, contour points, area, and the ratio (width/height) of lips, were used to recognize the lip contour and English vowels when speaking. The advantages of the proposed method are that it could detect the mouth ROI automatically, reduce the influence of individual differences, such as the individual lip shape or makeup effect, and it also could perform a good performance without pretraining. Finally, the performance of lip-reading recognition under different backgrounds and individual differences was also tested, and the accuracy of the proposed algorithm on lip-reading recognition was over 80%."
  },
  {
    "year": "2017",
    "abstract": "Long short-term memory (LSTM) has been widely used in different applications, such as natural language processing, speech recognition, and computer vision over recurrent neural network (RNN) or recursive neural network (RvNN)-a tree-structured RNN. In addition, the LSTM-RvNN has been used to represent compositional semantics through the connections of hidden vectors over child units. However, the linear connections in the existing LSTM networks are incapable of capturing complex semantic representations of natural language texts. For example, complex structures in natural language texts usually denote intricate relationships between words, such as negated sentiment or sentiment strengths. In this paper, quadratic connections of the LSTM model is proposed in terms of RvNNs (abbreviated as qLSTM-RvNN) in order to attack the problem of representing compositional semantics. The proposed qLSTM-RvNN model is evaluated in the benchmark data sets containing semantic compositionality, i.e., sentiment analysis on Stanford Sentiment Treebank and semantic relatedness on sentences involving compositional knowledge data set. Empirical results show that it outperforms the state-of-the-art RNN, RvNN, and LSTM networks in two semantic compositionality tasks by increasing the classification accuracies and sentence correlation while significantly decreasing computational complexities."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a hybrid gate-level leakage model for the use with the Monte Carlo (MC) analysis approach, which combines a lookup table (LUT) model with a first-order exponential-polynomial model (first-order model, herein). For the process parameters having strong nonlinear relationships with the logarithm of leakage current, the proposed model uses the LUT approach for the sake of modeling accuracy. For the other process parameters, it uses the first-order model for increased efficiency. During the library characterization for each type of logic gates, the proposed approach determines the process parameters for which it will use the LUT model. And, it determines the number of LUT data points, which can maximize analysis efficiency with acceptable accuracy, based on the user-defined threshold. The proposed model was implemented for gate-level MC leakage analysis using three graphic processing units. In experiments, the proposed approach exhibited the average errors of ¡5% in both mean and standard deviation with reference to SPICE-level MC leakage analysis. In comparison, MC analysis with the first-order model exhibited more than 90% errors. In CPU times, the proposed hybrid approach took only two to five times longer runtimes. In comparison with the full LUT model, the proposed hybrid model was up to one hundred times faster while increasing the average errors by only 3%. Finally, the proposed approach completed a leakage analysis of an OpenSparc T2 core of 4.5 million gates with a runtime of ."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the problem of scheduling shiftable loads, over multiple users, in smart electrical grids. We approach the problem, which is becoming increasingly pertinent in our present energy-thirsty society, using a novel distributed game-theoretic framework. In our specific instantiation, we consider the scenario when the power system has a local-area Smart Grid subnet comprising of a single power source and multiple customers. The objective of the exercise is to tacitly control the total power consumption of the customers' shiftable loads, so to approach the rigid power budget determined by the power source, but to simultaneously not exceed this threshold. As opposed to the “traditional”paradigm that utilizes a central controller to achieve the load scheduling, we seek to achieve this by pursuing a distributed approach that allows the users1 to make individual decisions by invoking negotiations with other customers. The decisions are essentially of the sort, where the individual users can choose whether they want to be supplied or not. From a modeling perspective, the distributed scheduling problem is formulated as a game, and in particular, a so-called “Potential”game. This game has at least one pure strategy Nash equilibrium (NE), and we demonstrate that the NE point is a global optimal point. The solution that we propose, which utilizes the theory of learning automata (LA), permits the total supplied loads to approach the power budget of the subnet once the algorithm has converged to the NE point. The scheduling is achieved by attaching a LA to each customer. The paper discusses the applicability of three different LA schemes, and in particular, the recently-introduced Bayesian learning automata. Numerical results, obtained from testing the schemes on numerous simulated data sets, demonstrate the speed and the accuracy of proposed algorithms in terms of their convergence to the game's NE point."
  },
  {
    "year": "2017",
    "abstract": "In orthogonal frequency-division multiple access (OFDMA) networks, the use of universal frequency reuse improves overall cell capacity at the cost of very high levels of inter-cell interference particularly affecting the users located in the cell-edge regions. In order to provide a better quality of experience to cell-edge users while still achieving high spectral efficiencies, conventional fractional frequency reuse (FFR) schemes split the cells into inner and outer regions (or layers) and allocate disjoint frequency resources to each of these regions by applying higher frequency reuse factors to the outer regions. Recently, multi-layer FFR-aided OFDMA-based designs, splitting the cell into inner, middle, and outer layers, have been proposed with the aim of further improving the throughput fairness among users. This paper presents an analytical framework allowing the performance evaluation and optimization of multi-layer FFR-aided OFDMA-based networks. Tractable mathematical expressions of the average spectral efficiency are derived and used to pose optimization problems allowing network designers to achieve the optimal trade-off between spectral efficiency and fairness. Analytical and simulation results clearly show that, irrespective of the channel-aware scheduler in use, multi-layer FFR-schemes can outperform the conventional two-layer FFR architectures."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel wideband circularly polarized (CP) slot antenna and its array are presented. The antenna element consists of a C-shaped slot and a 50-Ωmicrostrip-fed port to achieve left-hand circular polarization. Both the impedance bandwidth (IBW) and the 3-dB axial ratio bandwidth (ARBW) are greatly broadened by off-center microstrip-fed sword-shaped structure. A2×2array prototype based on the proposed CP element is also designed. Sequential rotation microstrip-feeding structure is used to excite four antennas and to realize good symmetric unidirectional radiation. To verify this design, both the CP antenna element and2×2array are fabricated and measured. The measured results of the antenna element exhibit an IBW of 132% (0.85–4.15GHz) and an ARBW of95.7%(1.20−3.40GHz). The measured ARBW and IBW of the2×2antenna array are about 108.3% (1.10–3.70GHz) and100%(1.15−3.45GHz), respectively. And the measured peak gain of the antenna array reaches 13.4 dBic. The proposed antenna is very suitable for CP applications in L/S bands."
  },
  {
    "year": "2017",
    "abstract": "The lack of sufficient spectral resources in many alternative positioning, navigation, and timing (APNT) systems for aviation has led to the problem of mutual interferences. Building APNT system with the cognitive radio and frequency-hopping (FH) techniques can resolve above problem, however, the main challenge is to achieve a long and high-precision range with high-speed FH signals. In this paper, we propose a novel ranging method called time–frequency matrix ranging (TFMR), which is based on the FH signals. Using the TFMR method, we built a jam-resistant APNT system to meet the accuracy and coverage requirements of aviation. We employed a dual-tone signal for the TFMR to estimate the pseudoranges between the ground stations and the aircrafts. One major challenge we faced was that what was good for ranging accuracy was bad for coverage. For example, increasing the dual-tone interval can improve the ranging accuracy; however, this led to a decrease in the unambiguous measurement range (UMR). To overcome this challenge, we employed different dual-tone intervals in different hops of the frequency-hopping signal. Finally, we formed a time–frequency matrix, so that a high UMR could be guaranteed without any harmful consequences on the ranging accuracy in the middle to high levels of the signal-to-noise ratio. The Cramér–Rao lower bound of TFMR is derived as the benchmark of the method. Using extensive simulations, we investigated the ranging performance of the TFMR method. The simulation results showed that the proposed TFMR could satisfy the APNT requirements of the Federal Aviation Administration."
  },
  {
    "year": "2017",
    "abstract": "Quality is the most important factor for software development as it mainly defines customer satisfaction that is directly related to the success of a software project. The software process model is used to ensure software quality, represent a variety of task settings, manage project duration, improve the process and range to execute the process understanding, and to appropriate implicit conjecture for all task settings. Several software processes models exist in software albeit with limited scope. Given this viewpoint, this paper presents a new software development life cycle model, “AZ-Model,” for software development by introducing new activities during software development life cycle. It overcomes the limitations of traditional models and significantly impacts the production of a quality product in a time-box. This paper also presents a comprehensive comparative study and statistical analyses to examine the significance of AZ–Model for software development."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel adaptive-gain sliding mode observer (SMO) is designed for sensorless control of permanent magnet linear synchronous motors (PMLSMs). By the proposed adaptive-gain algorithm, the gain can dynamically adapt to a changing operation condition of the PMLSMs and reach an appropriate value in finite time. Stability of the SMO is proved by using Lyapunov stability theory. Compared with the traditional SMO, the adaptive-gain SMO can improve the control precision, especially when the operation condition is not invariant. Simulation results are given to show the advantages of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Vehicular mesh networks could be an important new way to provide Internet access in urban areas using dedicated short range communications (DSRC). In some circumstances, DSRC technology is more cost-effective than expanding the capacity of cellular networks. We determine what those circumstances are by combining our simulation model with data collected from an actual vehicular network that is operating in Portugal. We use the model to estimate how much Internet traffic can be offloaded to vehicular networks that would otherwise be carried by cellular networks, under a variety of conditions. We use offloaded traffic to estimate the benefits of cost savings of reduced cellular infrastructure due to offload, and the cost of the DSRC vehicular network to carry that traffic. Then, we determine when benefit exceeds cost. We find that the benefits from the Internet traffic alone are not enough to justify a universal mandate to deploy DSRC in all vehicles, i.e., the benefits of Internet access alone are less than total costs. However, the majority of DSRC-related costs must be incurred anyway if safety is to be enhanced. Thus, soon after a mandate to put DSRC in new vehicles becomes effective, the benefits of Internet access through vehicular networks in densely populated areas would be significantly greater than the remaining costs, which are the costs of roadside infrastructure that can serve as a gateway to the Internet. Moreover, the benefit of Internet access would exceed DSRC infrastructure cost in regions with lower and lower population densities over time."
  },
  {
    "year": "2017",
    "abstract": "To reduce energy consumption and balance the resource load of physical machines (PMs) in cloud data centers, we present a game-based consolidation method of virtual machines (VMs) with energy and load (applied load) constraints. First, we test every measured value of the resource load using a t-test to filter outliers. Based on these values, the future resource load is forecast using gray theory. Second, all online PMs are grouped by the number of VMs on them and their future load values. Based on the groupings, a pre-processing algorithm for selecting destination PMs is proposed to determine a set of destination PMs for a VM awaiting migration. Finally, we select the final destination PM for the VM using game-based methods aimed at optimizing overall energy consumption. The experimental results show that our method can reduce energy consumption as well as balance loads without unnecessarily increasing the number of VM migrations."
  },
  {
    "year": "2017",
    "abstract": "We propose a sampling-based framework for privacy-preserving approximate data search in the context of big data. The framework is designed to bridge multi-target query needs from users and the data platform, including required query accuracy, timeliness, and query privacy constraints. A novel privacy metric, (ε, δ)-approximation, is presented to uniformly measure accuracy, efficiency and privacy breach risk. Based on this, we employ bootstrapping to efficiently produce approximate results that meet the preset query requirements. Moreover, we propose a quick response mechanism to deal with homogeneous queries, and discuss the reusage of results when appending data. Theoretical analyses and experimental results demonstrate that the framework is capable of effectively fulfilling multi-target query requirements with high efficiency and accuracy."
  },
  {
    "year": "2017",
    "abstract": "Haptic feedback is essential for achieving virtual and augmented reality (VR/AR) systems with high fidelity and realism. Haptic-enabled VR/AR systems offer a proficient environment in which to enhance the skills of medical practitioners. While pneumatic actuation is traditionally used in heavy automation industries, haptics researchers have utilized pneumatic techniques to produce various haptic effects, i.e., stiffness feedback and contour control, and these techniques have shown promising results in the medical domain. In this paper, we focus on the use of pneumatic-actuated haptic systems in VR/AR-based medical simulators. We begin with the taxonomy of the physical-virtual continuum and discuss the role of pneumatics in medical haptic systems. Furthermore, we propose the conceptual design architecture of a pneumatic haptic system. In addition, the systematic state-of-the-art role of pneumatic haptics in medical systems is presented for different categories. In this paper, we provide a systematic review and discuss the study of pneumatics to provide guidelines for the design and development of pneumatic haptic medical systems."
  },
  {
    "year": "2017",
    "abstract": "This paper considers both local and global synchronizations of fractional-order nonlinearlycoupled complex networks with time delay and unknown external disturbances. Here, neither delayed or nondelayed configuration matrices are necessarily irreducible or symmetric. Combined with the fractional order compare theorem and fractional order stability theory, some novel sufficient conditions are obtained that guarantee the realization of local and global asymptotic synchronization via adaptive control and pinning control. The network model and conclusion in this paper are more practical and general than those in the existing literature. The experimental results show the feasibility of our theoretical analysis."
  },
  {
    "year": "2017",
    "abstract": "The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions."
  },
  {
    "year": "2017",
    "abstract": "Mobile edge computing (MEC) can augment the computation capabilities of mobile terminals (MTs) through offloading the computational tasks from the MTs to the MEC-enabled base station (MEC-BS) covering them. However, the load of MEC-BS will rise as the increase of the scale of tasks. Existing schemes try to alleviate the load of MEC-BS through refusing, postponing, or queuing the offloading requests of the MTs; thus, the users’ QoS will largely deteriorate due to service interruption and prolonged waiting and execution time. In this paper, we investigate the cooperations of multiple MEC-BSs and propose a novel scheme to enhance the computation offloading service of an MEC-BS through further offloading the extra tasks to other MEC-BSs connected to it. An optimization algorithm is proposed to efficiently solve the optimization problem which maximizes the total benefits of time and energy consumptions gained by all the MTs covered by the MEC-BS. A balance factor is used to flexibly adjust the bias of optimization between minimizations of time and energy consumption. Extensive simulations are carried out in eight different scenarios, and the results demonstrate that our scheme can largely enhance the system performance, and it outperforms the reference scheme in all scenarios."
  },
  {
    "year": "2017",
    "abstract": "Coverage estimation is one of the fundamental issues of camera sensor networks (CSNs), and is also an important metric used to evaluate the monitoring quality of field of interest (FoI). In comparison with conventional omnidirectional sensor networks, coverage estimation in CSNs is more challenging due to the sensing region of camera sensor that is a sector-disk region. Moreover, the heterogeneous deployment of CSNs makes the coverage estimation problem even more complex. Currently, most of the literatures assume that a great number of camera sensors are directly deployed in the FoI. This paper assumes that all heterogeneous camera sensors are stochastically deployed outside the FoI. For such heterogeneous CSNs, we derived a k-coverage probabilistic expression to estimate the minimum number of camera sensors required for a desired level of k-coverage. To evaluate the performance of the proposed k-coverage estimation expression, several simulation experiments are conducted to validate the theoretical results."
  },
  {
    "year": "2017",
    "abstract": "In the era of big data, traditional industrial mobile wireless networks cannot effectively handle the new requirements of mobile wireless big data networks arising from the spatio-temporal changes of a nodes traffic load. From the perspective of load balancing and energy efficiency, industrial big data (IBD) brings new transmission challenges to industrial wireless mobile networks (IWMNs). Previous research works have not considered dynamic changes related to the traffic and mobility of IWMNs. In this paper, using an IBD technique, we propose a novel second-deployment and sleep-scheduling strategy (SDSS) for balancing load and increasing energy efficiency, while taking the dynamic nature of the network into consideration. SDSS can be divided into two stages. In the first stage, changes in the traffic of every network grid and its maximum traffic load at different times are calculated using big data analysis techniques. In the second stage, a second-deployment method for the cluster head nodes (CHNs), based on each grids maximum traffic load, is adopted. To save energy, based on their position and traffic states, a sleep-wake scheduling is presented for the CHNs. Simulations results verify the effectiveness of this methodology to save energy and obtain a traffic balance, which is more efficient than obtained through traditional methods."
  },
  {
    "year": "2017",
    "abstract": "Data hiding is a useful technology to protect secret data through the Internet. Exploiting modification direction (EMD)-based data hiding uses a group of n cover-pixels to embed secret data. It achieves good image quality and high security level of resisting RS detection. However, the embedding capacity of EMD decreases fast when n increases. In 2013, a Generalized EMD (GEMD) was proposed to improve the embedding capacity of EMD, which is always more than 1 bpp (bits per pixel), and keeps the good stego-image quality. In this paper, we propose an enhanced GEMD by dividing a group of n coverpixels into multiple groups. By this method, the embedding capacity can be further improved from GEMD. Our scheme maintains the good image quality and can resist the RS detection as well."
  },
  {
    "year": "2017",
    "abstract": "To alleviate the problem of scarce spectrum resources and meet the ever-increasing of mobile broadband data traffic demands, Licensed Assisted Access (LAA)-Long Term Evolution (LTE), operating in the unlicensed spectrum, is a promising solution. Considering that the unlicensed spectrum is shared by a few incumbent systems, such as IEEE 802.11 (i.e., WiFi), one main target is to guarantee the friendly and harmonious coexistence of LTE with other wireless systems in the unlicensed spectrum. Both listen-before-talk (LBT) and duty cycle methods are regarded as effective ways to solve the coexistence problem in academia and industry so far. Although there are a large number of theoretical researches on LTE in unlicensed spectrum (LTE-U), field trail results are still lacking. In this paper, an experimental testing platform is deployed to model the realistic environment. This paper focuses on three aspects. First, a typical indoor field trial scenario in 5.8 GHz unlicensed bands is deployed, and the performance of LTE-U and WiFi, including coverage and capacity, is evaluated. Specifically, a methodology to determine the proper clear channel assessment energy detection (CCA-ED) threshold for LTE-U is proposed to implement the friendly coexistence between LTE-U and WiFi systems. Second, supplementary downlink (SDL) and Cell ON/OFF mechanisms are investigated to verify the fair coexistence between LAA and WiFi in the unlicensed spectrum. Third, the Enhanced Cell ON/OFF scheme, which introduces Clear to Send (CTS)-to-Self (CTS2S) message, is discussed and evaluated. Based on the built testbed, we obtain threefold conclusions. First of all, introducing LTE into unlicensed spectrums can greatly improve the spectrum efficiency and optimize wireless resources. Furthermore, test results and analyses show that a proper CCA-ED threshold is necessary for coexisting friendly and fairly among different systems, and experiments are also provided to validate the feasibility of the sugges..."
  },
  {
    "year": "2017",
    "abstract": "Predicting user response is one of the core machine learning tasks in recommender systems (RS). The matrix factorization (MF)-based model has been proved to be a useful tool to improve the performance of recommendation. Many existing matrix factorization-based models mainly rely on adding some side information into basic MF to enable the model to fully express the data. However, most of the side information is measured based on the statistics or empirical formula. Also, the latent features of side information cannot be deeply mined. In this paper, we focus on mining the influence of field information (useful side information) to improve the performance of prediction. Based on the MF framework, we propose a field-aware matrix factorization (FMF) model. In FMF, the interactions between user/item and field can be captured and learned in the latent vector spaces. We propose efficient implementations to train FMF. Then, we comprehensively analyze FMF and compare this model with the state-of-the-art models. The analysis of experiments on two large data sets demonstrates that our method is very useful in RS."
  },
  {
    "year": "2017",
    "abstract": "Controlling integration failure is one of the major challenges in global software development (GSD) that remains hidden during the development phase and surfaces during the system integration. The integration failures occur as a result of incompatibilities and integration complexities that subsequently lead to delays, extra cost, affect the overall quality, and can even throw the entire GSD project into chaos. A very good understanding of integration failures may help to overcome the integration challenges. The objective of this paper is to explore comprehensively the integration failure factors. This paper thoroughly reviews the available literature. Moreover, the authors have conducted an industrial survey to more closely explore the integration failure factors. This paper largely contributes by devising a detailed taxonomy of 40 integration failure factors. The classification allows to better understand the relationships between the various factors and helps in creating a holistic solution to deal with integration problems in the context of GSD."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad-hoc networks (VANETs) have been developed to provide safety-related and commercial service applications on the road. The IEEE 1609.4 is a standard (legacy) designed to support multi-channels in VANETs, namely control channel (CCH) and service channels (SCHs) with fixed alternating CCH and SCH intervals. The CCH is dedicated to broadcast safety and control applications while SCHs are used to transfer service data applications. However, due to the nature of contention-based channel access scheme and the transmission of multiple applications over the CCH during a fixed interval, safety applications performance is degraded during CCH congestion in high network density scenarios. In this paper, we propose an adaptive multi-channel assignment and coordination (AMAC) scheme for the IEEE 802.11p/1609.4 in VANETs which exploits channel access scheduling and channel switching in a novel way. AMAC scheme includes an adaptive execution of the peer-to-peer negotiation phase between service providers and users for SCH resource reservations, and collision-aware packet transmission mechanisms. These two mechanisms alleviate collisions and increase packet delivery ratio (PDR) of safety applications on the CCH. Thereby, the AMAC scheme ensures an efficient and reliable quality of service (QoS) for different traffic flows and improves the time diversity among vehicles based on the traffic conditions. For performance analysis, analytical models are developed based on 1-D and 2-D Markov chain models taking into account an error-prone channels. The probabilities of successful transmission and collisions have been derived to compute PDR, and delay for safety packets in legacy standard and AMAC scheme. Analytical and simulation results indicate that the AMAC scheme reduces the collisions and increases the PDR for safety applications over the CCH compared with the legacy standard. In addition, AMAC scheme outperforms the legacy standard in terms of system throughput of service ..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a new structure-recovery cryptanalysis against 16-round Skipjack-like structure in which all the inner transformations are unknown. Our attack is divided into three phases. In the first phase, we use yoyo game to recover the outermost round functions. In the second phase, we use integral attack to achieve the round functions in round 2/3/4/13/14/15. A series of equations based on integral distinguishers is established to recover these inner transformations. However, effective integral distinguishers cannot be constructed for shorter rounds. For this reason, we propose a guess and determine attack to recover the residue round functions in the third phase. For n-bit Skipjack-like cipher, our attack can be executed within time complexity O(22.81×n/4) and data complexity O(2n/2), and thus can lead to a practical attack against 16-round Skipjack cipher."
  },
  {
    "year": "2017",
    "abstract": "Recommender Systems present a high-level of sparsity in their ratings matrices. The collaborative filtering sparse data makes it difficult to: 1) compare elements using memory-based solutions; 2) obtain precise models using model-based solutions; 3) get accurate predictions; and 4) properly cluster elements. We propose the use of a Bayesian non-negative matrix factorization (BNMF) method to improve the current clustering results in the collaborative filtering area. We also provide an original pre-clustering algorithm adapted to the proposed probabilistic method. Results obtained using several open data sets show: 1) a conclusive clustering quality improvement when BNMF is used, compared with the classical matrix factorization or to the improved KMeans results; 2) a higher predictions accuracy using matrix factorizationbased methods than using improved KMeans; and 3) better BNMF execution times compared with those of the classic matrix factorization, and an additional improvement when using the proposed pre-clustering algorithm."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a supervised feature learning method to learn discriminative and compact descriptors for drusen segmentation from retinal images. This method combines generalized low rank approximation of matrices with supervised manifold regularization to learn new features from image patches sampled from retinal images. The learned features are closely related to drusen and potentially free from information that is redundant in distinguishing drusen from background. The learned feature representations are then vectorized and used to train a support vector machine (SVM) classifier. Finally, the obtained SVM classifier is employed to classify the pixels in the test images as drusen or non-drusen. The performance of the proposed method is validated on the STARE and DRIVE databases, where it achieves an average sensitivity/specificity/accuracy of 90.03%/97.06%/96.92% and of 87.41%/94.93%/94.81%, respectively. We also experimentally compare the proposed method with the several representative state-of-the-art drusen segmentation techniques and find that it generates superior accuracy."
  },
  {
    "year": "2017",
    "abstract": "Currently, HTTP adaptive streaming (HAS) is the state-of-the-art technology for mobile video streaming. The rate adaptation of HAS has been designed to make a trade-off between two contrasting requirements, i.e., enhancing the quality of a video, and reducing the probability of video freezes, by adaptively switching between different video bitrates during a video playback session. This process becomes more challenging when moving onto an long term evolution (LTE) cellular network due to the unstable nature of the wireless channel. In this paper, we propose the bandwidth variation pattern-differentiated rate adaptation (BVPDRA) algorithm for LTE cellular networks. Unlike prior works, BVPDRA does not strike a balance between the stableness and responsiveness of bitrate switching in the case of bandwidth capacity variations. BVPDRA differentiates between bandwidth variation patterns of the LTE cellular network as either constant bandwidth fluctuations or instantaneous bandwidth hopping. Accordingly, BVPDRA operates with a dual character: for the constant bandwidth fluctuations, BVPDRA performs smoothed bandwidth prediction and conservative rate switching to minimize video quality version oscillations; for the instantaneous bandwidth hopping, BVPDRA performs positive bandwidth prediction and aggressive rate switching to maximize the bandwidth utilization and minimize the risk of playback stalling. We empirically evaluate the performance of BVPDRA on an LTE cellular network testbed. The results demonstrate that BVPDRA achieves a higher average bitrate, and lower rebuffering ratio with a reduced bitrate switching frequency."
  },
  {
    "year": "2017",
    "abstract": "The connectivity of a large-scale heterogeneous Internet of Vehicles (IoV) is an important challenge for the environment of urban road scenes, which feature crossroads, buildings, and communication devices. The uneven density and wide distribution of vehicles in the city, the building barriers, and the interference of other communication technology will make the connectivity weaker. To the best of our knowledge, there is no formal method to model and analyze connectivity by considering the environment of urban road scenes. This paper presents such a theoretical method to investigate four connectivity properties- i.e., possibility, data forwarding time, link forwarding capability, and packet error rate-and deduce a connectivity model. Using experiments, we prove that the proposed model can ensure that the connectivity is effective and reliable in an urban road scene, and it can be used to accurately evaluate the network connectivity of a highly dynamic IoV."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present the dynamic modeling and controller design of a tendon-driven system that is antagonistically driven by elastic tendons. In the dynamic modeling, the tendons are approximated as linear axial springs, neglecting their masses. An overall equation for motion is established by following the Euler-Lagrange formalism of dynamics, combined with rigid-body rotation and vibration. The controller is designed using the singular perturbation approach, which leads to a composite controller (i.e., consisting of a fast sub-controller and a slow sub-controller). An appropriate internal force is superposed to the control action to ensure the tendons to be in tension for all configurations. Experimental results are provided to demonstrate the validity and effectiveness of the proposed controller for the antagonistic tendon-driven system."
  },
  {
    "year": "2017",
    "abstract": "Nine-switch inverters were designed by sharing three-switches to realize dual-outputs, which are normally realized by two three phase inverters with 12 power semiconductors. Therefore, its modulation strategy is very complex and hard to implement. For this reason, a simplified modulations strategy for the nine-switch inverter is proposed. Based on the switched system model, m-modes controllability of the nine-switch inverter is first proposed to design a simplified space vector pulse width modulation (SVPWM) strategy. Compared with the conventional SVPWM strategies, the newly proposed switching scheme cannot only reduce half of the operating modes but also reduce the switching frequencies. It is significant since it can simplify the control, increase power efficiency and reduce economy cost. Finally, a prototype is designed to verify the proposed modulation strategy."
  },
  {
    "year": "2017",
    "abstract": "Urdu language is used by approximately 200 million people for spoken and written communications. The bulk of unstructured Urdu textual data is available in the world. We can employ data mining techniques to extract useful information from such a large, potentially informative base data. There are many text processing systems available to process unstructured textual data. However, these systems are mostly language specific with the large proportion of systems applicable to English text. This is primarily due to language-dependent preprocessing systems, mainly the stemming requirement. Stemming is a vital preprocessing step in the text mining process and its primary aim is to reduce grammatical words form, e.g., parts of speech, gender, tense, and so on, to their root form. In the proposed work, we have developed a rule-based comprehensive stemming method for Urdu text. This proposed Urdu stemmer has the ability to generate the stem of Urdu words as well as loan words that belong to borrowed languages, such as Arabic, Persian, and Turkish, by removing prefix, infix, and suffix from the words. In the proposed stemming technique, we introduced six novel Urdu infix words classes and a minimum word length rule to generate the stem of Urdu text. In order to cope with the challenge of Urdu infix stemming, we have developed infix stripping rules for introduced infix words classes and generic stemming rules for prefix and suffix stemming. We also present a probabilistic classification approach to classify Urdu short text. Different experiments are performed to demonstrate the effectiveness and efficacy of the proposed approach. Comparison with existing state-of-the art approaches is also made. Stemming accuracy results demonstrate the adoptability of the proposed stemming approach for a variety text processing applications."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the lag exponential synchronization for a class of neural networks with distributed delays and discrete delays (mixed delays) is studied via adaptive semiperiodically intermittent control. Using the adaptive control theory, the Lyapunov stability theory combined with the method of intermittent control, the simple but robust adaptive semiperiodically intermittent controller and impulse controller are designed. Via the proposed control methods, the response system can lag synchronize with the drive system, and the less conservative results are obtained. Using the adaptive control approach and giving a rigorous proof for the synchronization scheme, the proposed controllers are obviously little costly and more useful in practice than before. In the original references, the control width should be larger than the time delay and the time delay should be smaller than the noncontrol width. While, in this paper, these strict assumptions can be removed. Moreover, the control time and the control rate may not be constants. This leads to a larger application scope for our method. Last, numerical simulations are exploited to show the effectiveness of the results."
  },
  {
    "year": "2017",
    "abstract": "Millimeter wave (mm-Wave) communications are emerging to meet the increasing demand for high transmission data rate in high user density areas. Meanwhile, the mm-Wave base station (BS) needs to employ a large number of antenna elements to increase the gain as well as serve a huge number of users. However, a vast number of antenna elements causes dimensionality problem in channel correlation matrix (rotation matrix). Therefore, we propose a novel codebook construction design based on CUR-decomposition technique to reduce the dimensionality problem. In this paper, the original correlation matrix is decomposed to the product of three low dimension matrices (C, U, and R). The new rotated codebook is then constructed by the new rotation matrix. Moreover, we evaluate the new decomposition matrix with the original matrix in terms of compression ratio and mismatch error. We also provide the achievable sum rate capacities for singular value decomposition, zero forcing, and a matched filter techniques to compare with the proposed method. Furthermore, the system capacity enhancement related to the number of antenna elements and the required feedback bits are analyzed. Simulation results show that the proposed method achieves much better system performance since the dimensionality problem is solved. The proposed method can be applied in the fifth generation massive antenna multi-user system with over a hundred antenna elements."
  },
  {
    "year": "2017",
    "abstract": "Data mashup is a Web technology that combines information from multiple sources into a single Web application. Mashup applications support new services, such as environmental monitoring. The different organizations utilize data mashup services to merge data sets from the different Internet of Multimedia Things (IoMT) context-based services in order to leverage the performance of their data analytics. However, mashup, different data sets from multiple sources, is a privacy hazard as it might reveal citizens specific behaviors in different regions. In this paper, we present our efforts to build a cognitive-based middleware for private data mashup (CMPM) to serve a centralized environmental monitoring service. The proposed middleware is equipped with concealment mechanisms to preserve the privacy of the merged data sets from multiple IoMT networks involved in the mashup application. In addition, we presented an IoT-enabled data mashup service, where the multimedia data are collected from the various IoMT platforms, and then fed into an environmental deep learning service in order to detect interesting patterns in hazardous areas. The viable features within each region were extracted using a multiresolution wavelet transform, and then fed into a discriminative classifier to extract various patterns. We also provide a scenario for IoMT-enabled data mashup service and experimentation results."
  },
  {
    "year": "2017",
    "abstract": "Anew design of a segmented helical antenna (SHA), which can switch its sense of polarization by rotating around its center axis is presented. Two implementation methods, one based on origami folding and the other one based on skeleton scaffolding are developed. Example bifilar SHA designs are presented for the UHF frequency band. The performance of the antennas is studied and validated through simulations and measurements. Specifically, the reflection coefficient, axial ratio, realized gain, and radiation pattern beamwidth of the proposed SHAs are investigated and compared with the ones of a conventional bifilar helical antenna. The proposed SHA has two stable states of operation, one with right-hand circular polarization and the other one with left-hand circular polarization. The sense of the polarization of this antenna can be controlled and switched using mechanical rotation. Therefore, this antenna exhibits reconfigurable polarization performance."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we first provide some properties of truth tables of bent functions. Furthermore, a upper bound of truth table's runs length of a bent function is presented. Based on these results, we propose a new algorithm for enumerating bent functions. At last, we find that our algorithm requires lower storage complexity and is easier to implement with parallel/distributed computing infrastructures by comparing with some known searching algorithms."
  },
  {
    "year": "2017",
    "abstract": "A new overlapped multiplexing principle is revealed that points out the overlapping between consecutive and adjacent data symbols is never an interference but a beneficial coding constraint relation. The heavier the overlapping the higher the coding gain. The destroy facts coming from outside the system is the only interference. Under such a principle an improved channel capacity is obtained, which points out the channel capacity is linear to SNR rather than logarithm to SNR of the channel."
  },
  {
    "year": "2017",
    "abstract": "A hybrid power train system, which uses an electric machine to balance fluctuations of a load, is a practicable method to improve the efficiency of hydraulic excavators. To realize fast charge and discharge, ultra-capacitors are applied to a hybrid hydraulic excavator (HHE), which will cause the direct current (dc) supply voltage to change in a wide range. When the voltage of the ultra-capacitor varies, the output torque of the electric machine will be affected. In this paper, an interior permanent magnet synchronous machine (IPMSM) is employed in the HHE. When the dc supply voltage is low, the output torque of the IPMSM will drop and cannot balance fluctuations of the load adequately. To improve the control performance of the IPMSM output torque, a novel high-performance control strategy based on a vector control is proposed for the IPMSM to reduce the influence from the dc voltage. The mutual influence between the torque of the IPMSM and the dc voltage is analyzed. The novel high-performance control strategy for the IPMSM is introduced. To verify the effectiveness of the novel control strategy for the IPMSM, simulations and experiments are carried out. The results show that the proposed control strategy can improve the control performance of the IPMSM."
  },
  {
    "year": "2017",
    "abstract": "Due to the impact of an open deployment environment, severe restrictions in power with poor hardware equipment, and a lack of centralized administration in management, wireless sensor networks (WSNs) are extremely vulnerable to malicious attacks aimed at routing and other aspects. To face this problem, we propose a novel trust-aware routing protocol for WSNs which incorporates multiattributes (TRPM) of sensor nodes in terms of communication, data, energy, and recommendation. The proposed trust model relies on an improved sliding time window considering attack frequency to facilitate the discovery of malicious behaviors of attackers. Combined with effective routing detection and maintenance protocol, the performance of our solution is tested through a wide set of simulation experiments. Extensive results reveal that an average packet transfer rate of TRPM is increased by about 19% and time consumption on the routing update is shortened by about 11% in case 20% of all sensor nodes are malicious compared with other existing trust-based routing protocols."
  },
  {
    "year": "2017",
    "abstract": "Smart Internet of Things has greatly improved the quality of human life with increasingly intelligent sensor networks. Efficient and accurate human motion time series segmentation is the key issue in human motion analysis and understanding. To realize human motion sequence segmentation, a comprehensive human motion description and an intelligent segmentation algorithm are required. Hence, this paper proposes a sensor network-based human motion sequence segmentation framework. With the facilitation of sensor network and sensor network-based feature fusion method, human motions can be comprehensively described. Based on the comprehensive description of motion data, a new motion change variation-based segmentation method is proposed to realize human motion sequence segmentation. Moreover, to satisfy the time efficiency demand in the applications of large scale sensor networks, a hashing algorithm is introduced to compress the original captured sensor data, which can effectively represent the human motions with short binary codes and facilitate the motion change measurement. Experiments on real-world human motion data sets validate the effectiveness of our proposed sensor network-based human motion sequence segmentation framework compared with other state-of-the-art human motion segmentation methods."
  },
  {
    "year": "2017",
    "abstract": "In order to achieve perfect trajectory-tracking performance over the entire time interval at a higher convergence speed, this paper proposes a suboptimal learning control scheme for a class of nonlinearly parametric time-delay systems under alignment condition. The controller is designed by integrating the robust learning control with the suboptimal control, in which, the control Lyapunov function and Sontag formula are employed in generating a suboptimal controller for the nominal system, while robust learning control mechanism is applied to deal with nonlinearly parametric time-delay uncertainties. As the iteration number increases, the system state can follow its reference signal over the full time interval. The proposed method extends some existing results. Numerical simulations demonstrate that our suboptimal iterative learning control scheme improves the convergence performance in comparison with traditional solutions."
  },
  {
    "year": "2017",
    "abstract": "Meeting application requirements under a tight power budget is of a primary importance to enable connected health internet of things applications. This paper considers using sparse representation and well-defined inequality indexes drawn from the theory of inequality to distinguish ventricular ectopic beats (VEBs) from non-VEBs. Our approach involves designing a separate dictionary for each arrhythmia class using a set of labeled training QRS complexes. Sparse representation, based on the designed dictionaries of each new test QRS complex is then calculated. Following this, its class is predicted using the winner-takes-all principle by selecting the class with the highest inequality index. The experiments showed promising results ranging between 80% and 100% for the detection of VEBs considering the patient-specific approach, 80% using cross validation and 70% on unseen data using independent sets for training and testing, respectively. An efficient hardware implementation of the alternating direction method of multipliers algorithm is also presented. The results show that the proposed hardware implementation can classify a QRS complex in 69.3 ms that use only 0.934 W energy."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a new local discriminative feature learning method for finger vein recognition. Unlike most previous finger vein recognition methods, which use hand-crafted descriptors such as local binary pattern, local line binary pattern, and Gabor features, this paper aims to learn a feature mapping to enhance the discriminative ability of local features. To achieve this goal, we first extract multi-directional pixel difference vectors (MDPDVs) for each pixel in a training finger vein image by computing the difference between each pixel and its straight-line neighboring pixels. Second, we learn a feature mapping to project these MDPDVs into low-dimensional binary codes in a supervised manner, where: 1) the loss between the original real-valued codes and learned binary vectors is minimized; 2) the between-class variation of the local binary features is maximized; and 3) the within-class variation of the local binary features is minimized. Last, we represent each finger vein image as a histogram feature by clustering and pooling these binary codes. Experiments on SDUMLA-FV and PolyU databases verify the superior performance of the proposed method over other existing finger vein recognition methods."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a cascaded regional spatiotemporal feature-routing networks for video object detection. Region proposal networks in faster region-based convolutional neural network (CNN) generate spatial proposals, whereas neglecting the temporal property of the videos. We incorporate the correlation filter tracking on the convolutional feature maps to explore an efficient and effective spatiotemporal region proposal generation method. To gradually refine the bounding boxes of proposals, three region classification and regression networks are cascaded. Feature maps from different layers in CNNs extract hierarchical information of the input, so we propose a router function which selects feature maps according to the scale of proposals. In addition, object co-occurrence inference is exploited to suppress conflicting false positives, which leads to a semantically coherent interpretation on the video. Extensive experiments on the Pascal VOC 2007 dataset and the ImageNet VID dataset show that the proposed method achieves the state-of-the-art performance for detecting unconstrained objects in cluttered scenes."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an original study with the aim of improving users' performance in completing large questionnaires through adaptability in web forms. Such adaptability is based on the application of machine-learning procedures and an A/B testing approach. To detect the user preferences, behavior, and the optimal version of the forms for all kinds of users, researchers built predictive models using machine-learning algorithms (trained with data from more than 3000 users who participated previously in the questionnaires), extracting the most relevant factors that describe the models, and clustering the users based on their similar characteristics and these factors. Based on these groups and their performance in the system, the researchers generated heuristic rules between the different versions of the web forms to guide users to the most adequate version (modifying the user interface and user experience) for them. To validate the approach and confirm the improvements, the authors tested these redirection rules on a group of more than 1000 users. The results with this cohort of users were better than those achieved without redirection rules at the initial stage. Besides these promising results, the paper proposes a future study that would enhance the process (or automate it) as well as push its application to other fields."
  },
  {
    "year": "2017",
    "abstract": "Task switching is a common method to investigate executive functions such as working memory and attention. This paper investigates the effect of acute stress on brain activity using task switching. Surprisingly few studies have been conducted in this area. There is behavioral and physiological evidence to indicate that acute stress makes the participants more tense which results in a better performance. In this current study, under stressful conditions, the participants gave quick responses with high accuracy. However, unexpected results were found in relation to salivary cortisol. Furthermore, the electroencephalogram results showed that acute stress was pronounced at the frontal and parietal midline cortex, especially on the theta, alpha, and gamma bands. One possible explanation for these results may be that the participants changed their strategy in relation to executive functions during stressful conditions by paying more attention which resulted in a higher working memory capacity which enhanced performance during the task switching."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an optimization model for determining the optimal time-varying numbers of cashiers and pharmacists in a large hospital. The objective of this model is to minimize the weighted sum of the waiting cost incurred by patients and the operating costs incurred by the hospital. A point-wise fluid-based approximation approach is adopted to construct a dynamic queuing network that takes into account time-varying (or non-stationary) arrivals of patients and describes time-varying queue lengths. The dynamic queuing network is then encapsulated in the optimization model that determines the optimal time-varying numbers of cashiers and pharmacists. A test problem instance is designed based on a large hospital in the city of Taipei, and the MINOS solver of GAMS is applied to solve the problem instance. Sensitivity analyses are also conducted to examine the impacts of customer arrival rates and service rates on the waiting cost and operational cost. Numerical results show that the optimization model can provide an optimal allocation of manpower that significantly reduces both waiting and operating costs."
  },
  {
    "year": "2017",
    "abstract": "A new compact microstrip tunable bandpass filter with continuous control of center frequency and bandwidth is proposed in the paper. The proposed design is based on short parallel-coupled lines, which are tuned by properly loading varactors. The structure exhibits a pair of transmission poles and one-side passband edge transmission zero that can be flexibly adjusted for required positions. A thorough theoretical analysis is derived to estimate the performance of the proposed filter and verify the initial values of design parameters. To verify the design concept, a prototype is fabricated and measured. The fabricated circuit has an extreme compact size (smaller than 0.03λg× 0.1λg). The simulated and measured results agree well with the derived theory, and indicate wide tunable center frequencies (0.56-1.15 GHz) and 1-dB bandwidth (65-180 MHz)."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a receiver energy efficient congestion control algorithm based on multipath transmission control protocol (MPTCP) to enable the battery powered mobile devices receive more data than MPTCP with the same energy consumption. First, based on the receiver energy consumption model of wireless interface, a constrained optimization problem to maximize energy efficiency is formed. With genetic algorithm, a rate distribution vector is obtained as a near-optimal solution. Second, we adjust the congestion windows based on the acquired vector to schedule packets over each path directly. Jointly considering energy efficiency, round trip time and path loss rate, a novel congestion control algorithm is proposed to adjust the increment of congestion window when an acknowledgement is received in the congestion avoidance phase. The energy efficiency term is obtained by extending the energy efficient rate distribution vector into the window-based congestion control algorithm via fluid model. The simulation results demonstrate that the proposed algorithm shifts part of traffic from the higher energy consumption paths to the lower ones. It improves throughput greatly and achieves higher energy efficiency, almost twice the size of MPTCP."
  },
  {
    "year": "2017",
    "abstract": "To optimize input current distortion, output voltage fluctuation, and other problems caused by a three-phase to single-phase matrix converter (3-1 MC) under unbalanced input voltage, the harmonic characteristic of the 3-1 MC input current is analyzed. A control strategy based on virtual dc current is proposed using input positive-sequence voltage as current reference vector, which avoids the dividing error of input sector by the positive-sequence voltage as reference vector. Through dynamic modulation ratio and stable output voltage, a pseudo-dc current is synthesized after the output phase current and decoupling phase current are modulated. A closed-loop control system is designed using the virtual dc current and deduced 3-1 MC mathematical model. Finally, the control strategy is validated by simulations and experiments and the control target of the input current harmonic and output voltage stability is achieved. The effectiveness and practicability of the control strategy are confirmed."
  },
  {
    "year": "2017",
    "abstract": "A differential probe-fed liquid crystal (LC)-based frequency tunable circular-ring patch antenna is presented. Besides, cavity model is extended to analyze the LC-based antenna for the differential operation. According to the cavity model, the permittivity and loss tangent of the LC are extracted from the measured differential reflection coefficients. Acceptable agreements among the measurement, simulation, and calculation for differential impedances, reflection coefficients, and radiation patterns are obtained and also validate the extraction method and model. More importantly, the extended cavity model can provide a deep physical insight into the LC-based antenna."
  },
  {
    "year": "2017",
    "abstract": "Attention-based deep learning model as a human-centered smart technology has become the state-of-the-art method in addressing relation extraction, while implementing natural language processing. How to effectively improve the computational performance of that model has always been a research focus in both academic and industrial communities. Generally, the structures of model would greatly affect the final results of relation extraction. In this article, a deep learning model with a novel structure is proposed. In our model, after incorporating the highway network into a bidirectional gated recurrent unit, the attention mechanism is additionally utilized in an effort to assign weights of key issues in the network structure. Here, the introduction of highway network could enable the proposed model to capture much more semantic information. Experiments on a popular benchmark data set are conducted, and the results demonstrate that the proposed model outperforms some existing relation extraction methods. Furthermore, the performance of our method is also tested in the analysis of geological data, where the relation extraction in Chinese geological field is addressed and a satisfactory display result is achieved."
  },
  {
    "year": "2017",
    "abstract": "It is essential to enhance the speed and accuracy of the localization process to gain the robustness and instantaneous properties and to adapt from the practical environment of a confidence band. In this paper, we proposed a new received signal strength indicator-based method to construct a realtime confidence band, which was composed by multiple confidence region sets in a multivariate normal distribution, associated to a target's trajectory for location-based services. Based on the concept of weighted positioning circular algorithm, we designed a new objective function to take into consideration the signal disruptions of the surrounding environments. The characteristics of the state of motion for the moving target were then inferred from the status of each confidence region. In order to speed up the localization process to obtain the real-time estimate of the confidence band via our objective function, we proposed in this paper a swarm intelligence-based localization optimization algorithm, which was modified from the standard framework of a novel swarm intelligence-based evolutionary algorithm."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we provide two types of pattern matrices for the diffusion layer P, both can be used as classification criteria for the substitution-permutation network (SPN) structures: if the pattern matrices of distinct SPN structures are equal, then these structures may have the same impossible differential (ID)/zero correlation linear hull (ZC) and the same differential/linear active S-boxes. We introduce some interesting properties of the pattern matrices. Applying our results, we arrive at several interesting facts. First, all the SPN structures with MDS-type diffusion layers fall into the same class and have the same ID/ZC/minimum number of active S-boxes. Second, we provide several interesting properties of pattern matrices and build the links between the P-layer and that after several popular operations. Finally, we investigate the properties of pattern matrices for bit shuffles, the pattern matrices keep the same if and only if the n-partition characteristics of them are equal. Our results are helpful in the designing of block ciphers."
  },
  {
    "year": "2017",
    "abstract": "Accurately predicting future service traffic would be of great help for load balancing and resource allocation, which plays a key role in guaranteeing the quality of service (QoS) in cloud computing. With the rapid development of data center, the large-scale network traffic prediction requires more suitable methods to deal with the complex properties (e.g., high-dimension, long-range dependence, non-linearity, and so on). However, due to the limitations of traditional methods (e.g., strong theoretical assumptions and simple implementation), few research works could predict the large-scale network traffic efficiently and accurately. More importantly, most of the studies took only the temporal features but without the services’ communications into consideration, which may weaken the QoS of applications in the data center. To this end, we applied the gated recurrent unit (GRU) model and the interactive temporal recurrent convolution network (ITRCN) to single-service traffic prediction and interactive network traffic prediction, respectively. Especially, ITRCN takes the communications between services as a whole and directly predicts the interactive traffic in large-scale network. Within the ITRCN model, the convolution neural network (CNN) part learns network traffic as images to capture the network-wide services’ correlations, and the GRU part learns the temporal features to help the interactive network traffic prediction. We conducted comprehensive experiments based on the Yahoo! data sets, and the results show that the proposed novel method outperforms the conventional GRU and CNN method by an improvement of 14.3% and 13.0% in root mean square error, respectively."
  },
  {
    "year": "2017",
    "abstract": "Differential evolution (DE) is confirmed as a simple yet efficacious methodology to solve practical optimization problems. In this paper, we develop a new rotating crossover operator (RCO), to improve the optimization performance by utilizing multiangle searching strategy-based RCO. The proposed crossover scheme, different from conventional crossover operators, can generate trial vectors in control of the self-adaptive crossover parameter and rotation control vectors, which obey Lévy distribution. More specifically, trial vectors are generated diversely within circle regions around donor vectors and target vectors, by multiplying the rotation control vectors and difference of donor and target vectors. Rotation angles and radii are adjusted along with angles and moduli of the rotation control vectors. The proposed RCO operator can be easily applied to crossover strategies of other DE variants with minor changes. In order to verify the efficiency and generality of the algorithm, the proposed RCO scheme is respectively applied to the conventional DE variants and a state-of-the-art algorithm JADE, denoted as JADE-RCO. Further comparison experiments of JADE-RCO and other five efficient DE variants are conducted to confirm the superiority of the improved algorithm JADE-RCO. Series of experiments on a set of test functions in CEC 2013 demonstrate that the DE-RCO shows excellent performance in convergence rate and optimization ability comparing with classic and advanced evolutionary algorithms and it improves the performance of the original algorithms by 57%-96%."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes the design of a reconfigurable circularly polarized textile antenna. The circular polarization feature in the proposed antenna is generated by the edge truncation of a rectangular patch and the incorporation of a slotted ground plane, whilst the frequency reconfigurability feature is realized by slot size modification via the use of three embedded RF p-i-n diode switches. Consequently, the antenna operation can be switched between six frequencies (1.57, 1.67, 1.68, 2.43, 2.50, and 2.55 GHz) depending on the seven switch configurations. The proposed antenna is validated experimentally to be operable within the WBAN, WLAN, and GPS range in a compact and wearable format, with gains of up to 4.8 dBi."
  },
  {
    "year": "2017",
    "abstract": "Bitcoin is promoted as decentralized cryptocurrency by using pseudonym to achieve anonymity. Unfortunately, numerous seminal works have demonstrated that Bitcoin only offers weak anonymity in practice. Indeed, the practical technologies of clustering and flow analysis are much effective for tracing Bitcoin transaction and thereby revealing the owner involved. Otherwise said, user's privacy in Bitcoin has been sadly degenerated to be linkable. In this paper, we propose a completely decentralized scheme that can provide full anonymity in Bitcoin. The idea behind the output is to exploit a secure escrow address, which is consensual by all the involved users. The escrow address is generated from the trick of cryptographically secure distributed key generation and can then be used for mixing transactions in Bitcoin. Our protocol is secure against malicious adversaries. The users can jointly perform the protocol and successfully accomplish the transaction without the help of any (trusted) third party and no extra fees. Besides, our proposal is completely compatible with the current Bitcoin architecture."
  },
  {
    "year": "2017",
    "abstract": "A novel vibration sensor based on a bio-inspired nonlinear structure with quasi-zero stiffness characteristic is developed for the real-time measurement of absolute vibration motion. With this bio-inspired vibration sensor, the problems of error accumulation and real-time performance induced by traditional measurement method using accelerometer can be effectively eliminated. In order to construct a comparatively exact model of the bio-inspired vibration sensor, an adaptive compensation method is applied to the estimation of the structure parameter. Through taking full advantage of the bio-inspired vibration sensor in real-time measurement of absolute vibration motion, a model-based fault detection algorithm is proposed to cope with the real-time detection problem of weak fault with fast time-varying characteristic which cannot be exactly identified by existing frequency-based and wavelet-based fault detection methods. Theoretical analysis and experimental results demonstrate that the fault detection algorithm based on this bio-inspired vibration sensor is effective and efficient, compared with the existing ones and thus has a great potential in many real practical applications."
  },
  {
    "year": "2017",
    "abstract": "The intercell interference in massive multiple-input-multiple-output uplink consists of both correlated and uncorrelated components, where the former is due to pilot contamination and the latter is usually neglected in most of the existing literature. In this paper, we show that the uncorrelated intercell interference is actually not negligible for reasonably many antennas at the base station. Hence, a novel and general uplink performance analysis framework is established to take the uncorrelated interference into account. Specifically, we investigate the tradeoff between pilot overhead and uplink signal-to-interference-plus-noise ratio (SINR) in four uplink transmission schemes. Without cell coordination, the conventional uplink scheme and the soft pilot reuse scheme are evaluated. Compared with the former one, the soft pilot reuse scheme has higher mitigation efficiency on correlated intercell interference. However, the uncorrelated intercell interference cannot be mitigated without cell coordination. With cell coordination, we first evaluate the scheme that the pilot information can be shared via backhaul. Hence, both the correlated and uncorrelated interference can be canceled effectively. We also propose and analyze a novel pilot extension scheme in the cell coordination scenario, which could address different preferences of both cell-edge and cell-center users. In all the above four schemes, the asymptotic expressions of uplink SINR for arbitrary user are first obtained. Based on them, we derive the distribution of uplink SINR by considering the randomness of interfering users’ locations. It is shown that the analytical results match the numerical simulation tightly. Besides, both analytical and numerical results demonstrate the performance gain of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Many state-of-the-art citation recommendation methods have been proposed for finding a list of reference papers for a given manuscript, among which the graph-based method has gained particular attention, due to its flexibility for incorporating various information that embodies user's preferences. To achieve a more synthetic, accurate, and personalized recommendation result than the previous graph-based methods, this paper proposes a new graph-based recommendation framework that exploiting diversified link information in a bibliographic network and the concise query information that embodies the specific requirement of user comprehensively. The proposed framework not only performs mutual reinforcement rules on all available multiple types of relations in a multi-layered graph but also incorporates the query information into the multi-layered mutual reinforcement schema to construct a multi-layered mutually reinforced query-focused (MMRQ) citation recommendation approach. Extensive experiments have been conducted on a subset of anthology network data set. Experimental results of Recall measures, normalized discounted cumulative gain measures, and case study all demonstrate that our MMRQ method obtains a superior citation recommendation."
  },
  {
    "year": "2017",
    "abstract": "The suspension system is an important component of any vehicle as it transmits the force and torque between the wheel and the frame, satisfying the requirements of ride comfort and handling stability. To solve the problem of active suspension control, a seven-degree-of-freedom active suspension system model with electrohydraulic actuators is established. Through the approximate expansion in the rolling time domain, a robust model predictive controller (RMPC) for the active suspension system is designed and the RMPC of the active suspension is deduced by defining the RMPC performance evaluation function. A fractional PID controller is used to control the active suspension hydraulic actuators. The accuracy and efficiency of the controller are verified with prototype vehicle simulations and road experiments. Results show that the performance of the active suspension system is better than that of traditional suspension systems. The ride comfort and handling stability are considerably improved by the reductions of vertical acceleration, pitch angle, and roll angle accelerations."
  },
  {
    "year": "2017",
    "abstract": "Scene recognition is a significant and challenging problem in the field of computer vision. One of the principal bottlenecks in applying machine learning techniques to scene recognition tasks is the requirement of a large number of labeled training data. However, labeling massive training data manually (especially labeling images and videos) is very expensive in terms of human time and effort. In this paper, we present a novel multicriteria-based active discriminative dictionary learning (M-ADDL) algorithm to reduce the human annotation effort and create a robust scene recognition model. The M-ADDL algorithm possesses three advantages. First, M-ADDL introduces an active learning strategy into the discriminative dictionary learning model so that the performance of discriminative dictionary learning can be improved when the number of labeled samples is small. Second, different from most existing active learning methods that measure either the informativeness or representativeness of unlabeled samples to select useful samples for expanding the training dataset, M-ADDL employs both informativeness and representativeness to query useful unlabeled samples and utilizes the manifold-preserving ability of unlabeled samples as an additional sample selection criterion. Finally, a more effective representativeness criterion is presented based on the reconstruction coefficients of the samples. The experimental results of four standard scene recognition databases demonstrate the feasibility and validity of the proposed M-ADDL algorithm."
  },
  {
    "year": "2017",
    "abstract": "In this paper, an ultra-low power (ULP) 8T static random access memory (SRAM) is proposed. The proposed SRAM shows better results as compared with conventional SRAMs in terms of leakage power, write static noise margin, write-ability, read margin, and ION/IOFF. It is observed that the leakage power is reduced to 82× (times) and 75× as compared with the conventional 6T SRAM and read decoupled (RD)-8T SRAM, respectively, at 300 mV VDD. In addition, write static noise margin (WSNM), write trip point (WTP), read dynamic noise margin, and ION/IOFFratio are also improved by 7.1%, 43%, 7.4%, and 74× than conventional 6T SRAM, respectively, at 0.3 V VDD. Moreover, the WSNM, WTP, and ION/IOFFvalues are improved by 6.67%, 7.14%, and 68× as compared with RD-8T SRAM, respectively, at 0.3 V VDD. Furthermore, a fast, reliable, less memory usage object tracking algorithm and implementation of its memory block using ULP 8T SRAM are proposed. A quadtree-based approach is employed to diminish the bounding box and to reduce the computations for fast and low power object tracking. This, in turn, minimizes the complexity of the algorithm and reduces the memory requirement for tracking. The proposed object detection and tracking method are based on macroblock resizing, which demonstrates an accuracy rate of 96.5%. In addition, the average total power consumption for object detection and tracking which includes writing, read and hold power is 1.63× and 1.45× lesser than C6T and RD8T SRAM at 0.3 V VDD."
  },
  {
    "year": "2017",
    "abstract": "In practical massive multiple-input-multiple-output (MIMO) system, limited transmitted antennas installed at the base station (BS) cannot guarantee the ideal orthogonality and the theoretical channel rate cannot thus be achieved. In this paper, we consider the approximation of channel rate for the configuration of large but finite number of antennas at BS in a massive MIMO system. A perturbation matrix is introduced to model the non-ideal orthogonality. And then, Taylor expansion of determinant is utilized to derive the closed form of the achievable channel rate. The convergence of the Taylor expansion is theoretically proved and simulated. Numerical results show that our calculation of channel rate can get a better approximation compared with the practical rate, especially in the case of high expansion order and large number of antennas."
  },
  {
    "year": "2017",
    "abstract": "High-voltage direct-current (HVDC) power transmission is becoming increasingly important due to steadily rising need for bulk power delivery and interconnected power transmission and distribution systems. DC grids are vulnerable to dc faults, which lead to a rapid rise in dc fault currents. The dc faults must be cleared within the timeframe of milliseconds to avoid the collapse of the HVDC system. In the event of primary protection (PP) failure, back-up protection (BP) must be applied to clear the fault. In this paper, a novel algorithm based on a Naïve Bayes classifier is proposed to determine threshold levels and operational time frames for primary and back-up protection in multi-terminal voltage source converter-based HVDC. Local voltage and currents are measured to detect and identify the kind of fault. A four-terminal HVDC transmission system is developed in PSCAD/EMTDC and is subjected to line-line faults at different locations and time, to assess the designed protection schemes. Results show that a relaying algorithm effectively detects the fault and expedite the primary protection operation. On malfunctioning of PP, BP is accelerated in a short delay of 0.2 ms. Furthermore, the relaying algorithm provides faster protection compared with techniques available in the literature. The resulting reduced fault clearance time truncates the maximum fault current and, inevitably, leads to reduced power ratings required for dc grid equipment."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a design method for high-isolation n-way power combiners based on 2n + 1 port mode networks. The scattering matrix of a 2n + 1 port mode network is obtained by rigorously deriving the voltage and current relations. Following the proposed method, a compact four-way coaxial power combiner based on a nine-port mode network is designed and fabricated. Measurements show that from 7.8 to 10.3 GHz, the return losses of the input and output ports are better than -18 and -21 dB, respectively, the isolation levels between the input ports are higher than 21 dB, the insertion loss for power combination is less than 0.2 dB, and the amplitude and phase imbalances of the power combiner are less than approximately 0.15 dB and 2°, respectively. The simulated results agree well with the measured results. Moreover, the combiner has compact cross-sectional dimensions of 1.2λ × 1.2λ. It is clear that the designed four-way power combiner is superior in terms of its compact cross-sectional dimensions, high degree of isolation, low return loss, low insertion loss, and output amplitude and phase imbalance, which make it well suited for solid-state power combination. In addition, the power combiner is easy to fabricate and assemble. The proposed method shows great potential for realizing multi-way power combination with high isolation, low return loss, and compact cross-sectional dimensions."
  },
  {
    "year": "2017",
    "abstract": "Non-orthogonal multiple access (NOMA) is a promising multiple access technique, proposed in literature for the fifth generation (5G) mobile networks. The NOMA system model consists of the conventional orthogonal frequency division multiplexing (OFDM), as a pulse shaping technique in conjunction with a variable power domain for various users, allocated in proportion to each user's channel gain. OFDM technique based on wavelet filter banks, namely wavelet OFDM (WOFDM) has been utilized in digital communication to improve the system robustness to noise and adjacent channel interference, and is therefore anticipated to be adopted for the NOMA technique. WOFDM in NOMA (WNOMA) outperforms OFDM-based conventional NOMA (CNOMA) with reference to interference mitigation, bandwidth efficiency, spectral confinement, and multi-user capacity. Most of the fourth generation (4G) networks are based on OFDM and its variants. Therefore, in this paper, keeping in view the interoperability with the 4G networks and the latency requirements in 5G, a dual physical layer based on conventional OFDM and WOFDM as pulse shaping methods, is proposed for the NOMA transceiver. Performance of WNOMA and CNOMA is analyzed for bit error rate in the presence of channel impairments including additive noise and IQ imbalance and multiuser capacity is also computed. Comparison of various parameters indicates the advantage of adopting WNOMA over its conventional counterpart for relatively poor channel conditions."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the performance analysis of wireless energy harvesting (EH) cluster-based multi-hop networks, where all communication nodes harvest energy from the radiated signals transmitted by multiple power beacons (PBs) to support the information transmission. To this end, we propose three relay selection schemes. The first scheme tries to select the relay harvesting the largest energy to forward information. The second scheme chooses the relay, providing the best data channel gain from the transmitter to forward information. In the third scheme, two relays in two consecutive clusters will be selected based on the maximum EH link and maximum data link. The destination node is equipped with multiple antennas and applies the maximal ratio combining technique to combine its received signal. The system performances in terms of outage probability of three schemes are evaluated in Nakagami-m fading environments and verified by Monte Carlo simulations."
  },
  {
    "year": "2017",
    "abstract": "A decentralized proportional-integral-differential (PID) control structure has been always the first option for magnetic levitation systems due to its model-free nature as well as the simplicity. It is very challenging to tune PID parameters for each suspension point to ensure that the closed-loop system is less sensitive to uncertainties/disturbances. Even though, by a large number of experiments, a reasonably good PID control parameter set can be obtained to levitate a single suspension point for a given set point, these parameters are very sensitive when the set point changes or the decentralized PID controller is applied to the half bogie where coupling exists, strong oscillations will be observed and retuning of parameters is needed. This paper utilizes the extremum seeking (ES) method to tune PID parameters on-line to improve the steady-state performance of the system with few oscillations. A “sampled-data”structure is used to obtain a moving window approximation of the steady-state behavior, leading to a discrete-time ES tuning for the decentralized PID parameters. By using projection method, the tuning parameters are constrained in a compact set, in which the stability can be guaranteed and the optimal performance can be achieved. Experiments have shown the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Social media has drawn scientists’ attention due to their potential values for health and marketing, among other activities. To effectively exploit such huge online resources by using incomplete user profiles, which are very common on social media sites and can be caused by user privacy settings, it is meaningful to explore user profile identification methods. In this paper, we focus on gender identification using reposting behaviors on social networks. Whereas most existing works rely on pure statistical methods, we propose a scheme that is underpinned by homophily and four intuitive methods based on it by combining knowledge of statistics and sociology. For our data set, which was obtained from Sina Weibo and contained 1039 test samples and 528k user profiles, our methods perform with 86.7% accuracy. We explore the sensitivity of our methods on the scale of the data set and find surprisingly competitive results surpassing the binary classification baseline. Finally, we further suggest possible extensions to our methods."
  },
  {
    "year": "2017",
    "abstract": "Automated software defect prediction is an important and fundamental activity in the domain of software development. However, modern software systems are inherently large and complex with numerous correlated metrics that capture different aspects of the software components. This large number of correlated metrics makes building a software defect prediction model very complex. Thus, identifying and selecting a subset of metrics that enhance the software defect prediction method's performance are an important but challenging problem that has received little attention in the literature. The main objective of this paper is to identify significant software metrics, to build and evaluate an automated software defect prediction model. We propose two novel hybrid software defect prediction models to identify the significant attributes (metrics) using a combination of wrapper and filter techniques. The novelty of our approach is that it embeds the metric selection and training processes of software defect prediction as a single process while reducing the measurement overhead significantly. Different wrapper approaches were combined, including SVM and ANN, with a maximum relevance filter approach to find the significant metrics. A filter score was injected into the wrapper selection process in the proposed approaches to direct the search process efficiently to identify significant metrics. Experimental results with real defect-prone software data sets show that the proposed hybrid approaches achieve significantly compact metrics (i.e., selecting the most significant metrics) with high prediction accuracy compared with conventional wrapper or filter approaches. The performance of the proposed framework has also been verified using a statistical multivariate quality control process using multivariate exponentially weighted moving average. The proposed framework demonstrates that the hybrid heuristic can guide the metric selection process in a computationally efficient way by in..."
  },
  {
    "year": "2017",
    "abstract": "This research proposes a graphical solution to arterial road dynamics simulation. An arterial road consists of channelized and upstream sections. Traffic flow is mixed in the upstream section (U-section) and operates without lateral interaction in the channelized section (C-section). Under oversaturated conditions, C-section spillover occurrence governs the traffic flow dynamics of the entire road. In order to capture the arterial road traffic flow dynamics, the proposed method takes advantage of the following components: 1) a decomposition mechanism that uniforms the analysis of each lane; 2) a red-green pair-based vehicle queue tracking component that describes traffic dynamics both temporally and spatially; and 3) a well-defined converted cumulative curve that is capable of generating a queue solution directly. The graphical method permits arbitrary traffic flow and signal settings input and can easily be automated, as demonstrated in the example."
  },
  {
    "year": "2017",
    "abstract": "Energy management system (EMS) is responsible for the optimal operation of microgrids. EMS adjusts its operational schedule for near future by using the available information. Market price signals are generally used for the operation of microgrids, which are obtained by using estimation/ forecasting methods. However, it is difficult to precisely predict the market prices due to the involvement of various complex factors like weather, policy, demand, errors in forecasting methods, and fuel cost. Therefore, in this paper, the uncertainties associated with the real-time market price signals (buying and selling) are realized via a robust optimization method. In addition to market price signals, uncertainties associated with renewable power sources and forecasted load values are also considered. Initially, a deterministic model is formulated for an ac/dc hybrid microgrid. Then a min-max robust counterpart is formulated by considering the worstcase uncertainties. Finally, an equivalent mixed integer problem is formulated by using linear duality and other optimality conditions. The developed model can provide feasible solutions for all the scenarios if the uncertainties fluctuate within the specified bounds. The effect of market price uncertainties on internal power transfer and external power trading, operation cost, the state-of-charge of energy storage elements, and unit commitment of dispatchable generators is analyzed. Taguchi's orthogonal array (OA) method is used to find the worst-case scenario within the specified uncertainty bounds. Then, Monte Carlo method is used to generate various scenarios within the uncertainty bounds to evaluate the robustness of the selected scenario via Taguchi's OA method. Finally, a violation index is formulated to evaluate the robustness of the proposed approach against the deterministic model. Simulations results have validated the robustness of the proposed optimization strategy."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a dependent modeling method for reliability estimation of metal structures under constant amplitude loading and random shocks considering the nonlinear damage accumulation mechanism. It is well known that a large monotonic plastic zone ahead of a crack tip caused by a spike overload will retard subsequent fatigue crack growth. However, most existing degradation-and-shock dependent models cannot account for this retardation phenomenon. Moreover, the increase in damage caused by shock is usually assumed to be independent of fatigue degradation. In this investigation, both fatigue degradation and applied random shock damage are considered to have a coupled effect on the crack propagation process. The nonlinear damage superposition approach is utilized herein to model the interaction between fatigue loading and random shocks. Fatigue degradation is considered as a stochastic process influenced by the uncertainties in material properties, and the applied shocks are regarded as random incidents. Next, the piecewise deterministic Markov process is employed to describe the coupling relationship between this stochastic degradation and the random shock process. In the proposed algorithm, Paris' equation is utilized to describe fatigue degradation, and the Willenborg model is employed to describe retardation caused by random shock loads. A simulation is performed to validate the proposed method, and the proposed method is compared with the traditional method."
  },
  {
    "year": "2017",
    "abstract": "Intrusion detection has been an important countermeasure to secure computing infrastructures from malicious attacks. To improve detection performance and reduce bias towards frequent attacks, this paper proposes a two-step hybrid method based on binary classification and k-NN technique. Step 1 employs several binary classifiers and one aggregation module to effectively detect the exact classes of network connections. After step 1, the connections whose classes are uncertain are sent to step 2 to further determine their classes by the k-NN algorithm. Step 2 is based on the outcomes of step 1 and yields a beneficial supplement to step 1. By combining the two steps, the proposed method achieves reliable results on the NSL-KDD data set. The effectiveness of the proposed method is evaluated in comparison with five supervised learning techniques. Experimental results demonstrate that the proposed method outperforms baselines with respect to various evaluation criteria. In particular, for U2R and R2L attacks, the F1-scores of the proposed method are much higher than those of baselines. Furthermore, comparisons with some recent hybrid approaches are also listed. The results illustrate that the proposed method is competitive."
  },
  {
    "year": "2017",
    "abstract": "The evolution of traditional energy networks toward smart grids increases security vulnerabilities in the power system infrastructure. State estimation plays an essential role in the efficient and reliable operation of power systems, so its security is a major concern. Coordinated cyber-attacks, including false data injection (FDI) attack, can manipulate smart meters to present serious threats to grid operations. In this paper, a robust state estimation algorithm against FDI attack is presented. As a solution to mitigate such an attack, a new analytical technique is proposed based on the Markov chain theory and Euclidean distance metric. Using historical data of a set of trusted buses, a Markov chain model of the system normal operation is formulated. The estimated states are analyzed by calculating the Euclidean distance from the Markov model. States, which match the lower probability, are considered as attacked states. It is shown that the proposed method is able to detect malicious attack, which is undetectable by traditional bad data detection (BDD) methods. The proposed robust dynamic state estimation algorithm is built on a Kalman filter, and implemented on the massively parallel architecture of graphic processing unit using fine-grained parallel programming techniques. Numerical simulations demonstrate the efficiency and accuracy of the proposed mechanism."
  },
  {
    "year": "2017",
    "abstract": "With the fast development of many event-based social networks (EBSNs), event recommendation, which is to recommend a list of upcoming events to a user according to his preference, has attracted a lot of attentions in both academia and industry. In this paper, we propose a successive event recommendation based on graph entropy (SERGE) to deal with the new event cold start problem by exploiting diverse relations as well as asynchronous feedbacks in EBSNs. The SERGE creates recommendation lists at discrete times during each publication period. At the beginning, it constructs a primary graph (PG) based on the entities and their relations in an EBSN and computes the user-event similarity scores by applying a random walk with restart (RWR) algorithm on PG. At each recommendation time, it then constructs a feedback graph (FG) based on the up-to-date user feedbacks on event reservations and applies the RWR again on FG to compute new user-event similarity scores. We then propose to weight the two sets of similarity scores with the graph entropies of both PG and FG and create the final recommendation lists accordingly. We have crawled two datasets from a real EBSN for two cities, Beijing and Shanghai in China. Experimental results validate the effectiveness and superiority of the proposed SERGE scheme over the peer schemes."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the dual hesitant bipolar fuzzy multiple attribute decision making problems in which there exists a prioritization relationship over attributes. Then, motivated by the idea of Hamacher operations and prioritized aggregation operators, we have developed some Hamacher prioritized aggregation operators for aggregating dual hesitant bipolar fuzzy information: dual hesitant bipolar fuzzy Hamacher prioritized average operator, dual hesitant bipolar fuzzy Hamacher prioritized geometric operator, dual hesitant bipolar fuzzy Hamacher prioritized weighted average operator, dual hesitant bipolar fuzzy Hamacher prioritized weighted geometric operator. Then, we have utilized these operators to develop some approaches to solve the dual hesitant bipolar fuzzy multiple attribute decision making problems. Finally, a real-world example is then analyzed to illustrate the relevance and effectiveness of the proposed methodology."
  },
  {
    "year": "2017",
    "abstract": "With the release of the 5 GHz unlicensed spectrum has emerged licensed-assisted access, in which long-term evolution (LTE) operators compete with Wi-Fi users for a share of the unlicensed spectrum so as to augment their licensed spectrum. Subsequently, there has been the need to develop a LTE channel access mechanism that enables harmonious coexistence between Wi-Fi and LTE. Load-based listen-before-talk (LB-LBT) has been adopted as this LTE channel access mechanism by the 3rd Generation Partnership Project (3GPP). Theoretical modelling of LB-LBT schemes has focused on throughput and fair channel-time sharing between Wi-Fi and LTE technologies. We explore a LB-LBT scheme that belongs to LBT category 4, as recommended by the 3GPP, and develop a model for the distribution of the medium access control (MAC) delays experienced by the Wi-Fi packets and LTE frames. The model, validated by simulations, reveals design insights that can be used to dynamically adjust the LB-LBT parameters not only to achieve channel-time fairness, but also to guarantee MAC-delay bounds, with specified probability."
  },
  {
    "year": "2017",
    "abstract": "Effective fault diagnosis for mission-critical and safety-critical systems has been an essential and mandatory technique to reduce failure rate and prevent unscheduled shutdown. In this paper, to realize fault diagnosis for a closed-loop single-ended primary inductance converter, a novel optimization deep belief network (DBN) is presented. First, wavelet packet decomposition is adopted to extract the energy values from the voltage signals of four circuit nodes, as the fault feature vectors. Then, a four-layer DBN architecture including input and output layers is developed. Meanwhile, the number of neurons in the two hidden layers is selected by the crow search algorithm (CSA) with training samples. Not only the hard faults such as open-circuit faults and short-circuit faults but also the soft faults such as the component degradation of power MOSFET, inductor, diode, and capacitor are considered in this study. Finally, these fault modes are isolated by CSA-DBN. Compared with the back-propagation neural network and support vector machine fault diagnosis methods, both simulation and experimental results show that the proposed method has a higher classification accuracy that proves its effectiveness and superiority to the other methods."
  },
  {
    "year": "2017",
    "abstract": "Radio frequency identification has become a vital technique for enabling intelligent supply chain management. Throughout the life cycle of the supply chain, one-for-one checking is necessary at all the handover points where physical shipped inventory is checked against with the receiver's order to discover discrepancies because of missing or misplaced objects. Such operation is so universal that the improvement over its efficiency can significantly benefit the whole supply chain. Yet, there are a few challenging issues, namely, inconsistent tags, high-volume data, and high network latency. In this paper, we first carefully analyze the characteristics of EPCglobal Network. We then design two discrepant tag identification protocols with different optimization goals including minimum communication data and minimum communication round. Also, we perform thorough analysis by comparing our proposals with state-of-the-art methods and extensive experiments to validate the effectiveness and efficiency of our methods."
  },
  {
    "year": "2017",
    "abstract": "The future adaptability of reflectarray antenna requires a thorough investigation of its main conventional features for expected improvements. Its existing design featuring at microwave and millimeterwave frequencies can be considered as a basic platform for further studies. In this paper, a thorough review of reflectarrays on some selected areas is presented. Its design implementations involving gain and efficiency improvement are discussed in details. Various design approaches have been critically analyzed at the unit cell and full reflectarray levels for a plausible enhancement in the featured parameters with 5G compatibility."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a language-independent ontology (LION) construction method that uses tagged images in an image folksonomy. Existing multilingual frameworks that construct an ontology deal with concepts translated on the basis of parallel corpora, which are not always available; however, the proposed method enables LION construction without parallel corpora by using visual features extracted from tagged images as the alternative. In the proposed method, visual similarities in tagged images are leveraged to aggregate synonymous concepts across languages. The aggregated concepts take on intrinsic semantics of themselves, while they also hold distinct characteristics in different languages. Then relationships between concepts are extracted on the basis of visual and textual features. The proposed method constructs a LION whose nodes and edges correspond to the aggregated concepts and relationships between them, respectively. The LION enables successful image retrieval across languages since each of the aggregated concepts can be referred to in different languages. Consequently, the proposed method removes the language barriers by providing an easy way to access a broader range of tagged images for users in the folksonomy, regardless of the language they use."
  },
  {
    "year": "2017",
    "abstract": "Resource failures frequently occur in a smart manufacturing information system (SMIS), which exerts significant impacts on the robustness of the system. From a complex network perspective, this paper develops a fresh methodology for analyzing the robustness of an SMIS suffering from resource failures. First, this methodology divides an SMIS into cyber and physical layers, dissects the resources within these layers and the relationships among these resources. Based on complex network thinking, the methodology then builds a network model incorporating different failure modes and link patterns. Finally, extensive simulations are performed using the case of an appliance manufacturer and one of its suppliers. The results show that an SMIS, along with its cyber layer, exhibits the property of being robust-yet-fragile, and that an assortative link pattern is the optimal link pattern to guarantee robustness for the SMIS under targeted failures."
  },
  {
    "year": "2017",
    "abstract": "Several recent contributions have envisioned the possibility of increasing currently exploitable maximum channel capacity of a free-space link, both at optical and radio frequencies, by using vortex waves, i.e., carrying orbital angular momentum (OAM). Our objective is to disprove these claims by showing that they are in contradiction with very fundamental properties of Maxwellian fields. We demonstrate that the degrees of freedom (DoFs) of the field cannot be increased by the helical phase structure of electromagnetic vortex waves beyond what can be done without invoking this property. We also show that the often-advocated over-quadratic power decay of OAM beams with distance does not play any fundamental role in the determination of the channel DoF."
  },
  {
    "year": "2017",
    "abstract": "Many natural and manmade dynamical systems that are modeled as large nonlinear multioscillator systems like power systems are hard to analyze. For such systems, we propose a nonlinear modal decoupling (NMD) approach inversely constructing as many decoupled nonlinear oscillators as the system's oscillation modes so that individual decoupled oscillators can be easily analyzed to infer dynamics and stability of the original system. The NMD follows a similar idea to the normal form except that we eliminate inter-modal terms but allow intra-modal terms of desired nonlinearities in decoupled systems, so decoupled systems can flexibly be shaped into desired forms of nonlinear oscillators. The NMD is then applied to power systems toward two types of nonlinear oscillators, i.e. the single-machine-infinite-bus (SMIB) systems and a proposed non-SMIB oscillator. Numerical studies on a 3-machine 9-bus system and New England 10-machine 39-bus system show that: 1) decoupled oscillators keep a majority of the original system's modal nonlinearities and the NMD can provide a bigger validity region than the normal form and 2) decoupled nonSMIB oscillators may keep more authentic dynamics of the original system than decoupled SMIB systems."
  },
  {
    "year": "2017",
    "abstract": "In many applications of wireless sensor networks (WSNs), node location is required to locate the monitored event once occurs. Mobility-assisted localization has emerged as an efficient technique for node localization. It works on optimizing a path planning of a location-aware mobile node, called mobile anchor (MA). The task of the MA is to traverse the area of interest (network) in a way that minimizes the localization error while maximizing the number of successful localized nodes. For simplicity, many path planning models assume that the MA has a sufficient source of energy and time, and the network area is obstacle-free. However, in many real-life applications such assumptions are rare. When the network area includes many obstacles, which need to be avoided, and the MA itself has a limited movement distance that cannot be exceeded, a dynamic movement approach is needed. In this paper, we propose two novel dynamic movement techniques that offer obstacle-avoidance path planning for mobility-assisted localization in WSNs. The movement planning is designed in a real-time using two swarm intelligence based algorithms, namely grey wolf optimizer and whale optimization algorithm. Both of our proposed models, grey wolf optimizer-based path planning and whale optimization algorithm-based path planning, provide superior outcomes in comparison to other existing works in several metrics including both localization ratio and localization error rate."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a methodology for building a consensus among the stakeholders based on the level of importance of each evaluation criterion to choose the best final design, approach, or solution for a project. The proposed methodology adopts an improved vague set minimum-cost consensus model (MCCM) and a modified Delphi method. This paper discusses several shortcomings of the traditional MCCM and the Delphi method. It argues that humans' resistance to change based on a numerical rating scale follows a natural logarithm pattern instead of a linear or quadratic pattern as claimed in other studies. Hence, the traditional MCCM needs to be revised accordingly. In addition, an experiment was concluded to compare the proposed consensus-building methodology with the traditional Delphi method. The experiment showed that the proposed methodology is better than the traditional Delphi method regarding using fewer rounds to reach a consensus. At last, this paper applies the proposed methodology to the field of road junction design selection."
  },
  {
    "year": "2017",
    "abstract": "How can we discover and estimate major events in complex social networks? Event detection and evaluation in social networks provide an effective solution, which has become the critical basis for many real applications, such as crisis management and decision making. However, the existing methods ignore the difference of the evolution fluctuations of nodes. In order to further improve the accuracy of event detection, this paper proposes an event detection method for social networks based on node evolution fluctuations (NodeED). It contains a node similarity index algorithm (SimJudge) and a microevolution fluctuation detection algorithm (MicroFluc). The main work is as follows: 1) based on particle swarm optimization algorithm, SimJudge is proposed to apply the values of different similarity indexes to quantify the evolution fluctuations of nodes, and the optimal similarity index is determined for each node and 2) microFluc is proposed to integrate the evolution fluctuations of different nodes and quantify the impacts of events in the evolutions of social networks. The results of comparisons with state-of-the-art methods using extensive experiments show that NodeED improves the event detection accuracy and has more advantages to detect events in social networks than other state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Interference is believed to be the most significant bottleneck for the next-generation wireless networks to achieve high throughout. Interference alignment (IA), as a novel interference management scheme to break through the traditional interference cancelation, not only makes the complete mitigation of interference possible but also achieves a theoretical breakthrough in promoting the wireless network capacity region. In this paper, by combining the space and time, we proposed a linear space-time (LST) IA algorithm based on the extension of the channel in time dimension for K-user multi-input multi-output interference channel. The proposed LST-IA scheme effectively reduces the number of antennas required for eliminating interference completely in systems, and the closed-form solution of precoding matrices and detector matrices is obtained as well. Compared with the classical IA algorithms, the simulation results demonstrate that the proposed scheme shows distinguished advantages in terms of sum-rate and bit error rate in the strong interference communication scenarios."
  },
  {
    "year": "2017",
    "abstract": "Determining the variable transmission structure is the key step in designing a distributed monitoring scheme for multiunit processes. This paper proposes randomized algorithm (RA) integrated with evolutionary optimization-based data-driven distributed local fault detection scheme to achieve efficient monitoring of multiunit chemical processes. First, the RA is employed to generate faulty validation data. Second, evolutionary optimization-based variable transmission structure determination is performed to achieve the minimal non-detection rate by selecting transferred variables. Then, a principal component analysis (PCA) or kernel PCA monitoring model is established for each operation unit to identify the status of the unit. Last, a comprehensive index is developed to identify the status of the entire process. The established local monitors consider the relationship with other units but avoid introducing redundant information, thereby exhibiting superior monitoring performance. Case studies on two numerical examples, including a linear and a nonlinear case and the Tennessee Eastman benchmark process, are provided. Comparative results of traditional local or global monitoring methods verify the efficiency of the proposed monitoring scheme."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel approach for the joint tracking and identification (JTI) problem. JTI involves interdependent tracking and identification, and thus solving them jointly is preferable. The recently proposed joint decision and estimation (JDE) framework provides a good solution for such problems involving coupled decision and estimation. To solve the JTI problem, this paper proposes a compact conditional JDE (CCJDE) method within the JDE framework. First, we propose a new CCJDE risk, which unifies the traditional decision and estimation risks in a concise form. Based on this, we present the optimal joint solution with analytical form. Second, inspired by the interacted parameters in CCJDE, we propose a new CCJDE scheme with time-varying parameters, which further utilizes the interdependence between decision and estimation. Third, we apply CCJDE to practical JTI problems. An applicable multiple model CCJDE algorithm is proposed for JTI. For performance evaluation, we propose a new joint performance metric (JPM), which unifies the tracking error and the identification error. Finally, two illustrative examples verify the superiority of the proposed CCJDE method. CCJDE outperforms the traditional two-step strategies in JPM. For multisensor data JTI, however, CCJDE can further utilize all information from heterogeneous sensor data. Besides, the effectiveness of the proposed JPM and the time-varying parameters in CCJDE are also demonstrated."
  },
  {
    "year": "2017",
    "abstract": "The replacement of conventional electricity generators by wind turbines and solar photovoltaic panels results in reduced system inertia, which jeopardizes the electric power system frequency. Frequency variation is critical as it may cause equipment damage and blackouts. Frequency regulation (FR) plays a crucial role in sustaining the stability of electric power grids by minimizing the instantaneous mismatches between electric power generation and load demand. Regulation service (RS) providers dynamically inject/absorb electric power to/from the grid, in response to regulation signals provided by independent system operators (ISOs), in order to keep the frequency within the permissible limits. The regulation signals are highly transient and hence require quick responding resources in order to provide FR effectively. This paper proposes innovative design and operation frameworks for state-of-the-art battery-energy storage system (BESS) and ultracapacitor (UC)-based hybrid energy storage system (HESS) employed for FR in electricity market. The proposed system design framework is based upon the initial investment cost, replacement cost, maintenance cost, and financial penalty imposed by ISO on RS provider for not supplying the required RS. The proposed system operation framework allocates power to both BESS and UC based upon their maximum power ratings while fulfilling their constraints at the same time. The frequent partial charge-discharge transitions, which are detrimental for BESS, are reduced by using two battery banks instead of one large battery bank. The charging and discharging of two battery banks are controlled innovatively to reduce the transitions between the partial charge-discharge transitions. Moreover, a comparison based upon cost per unit between two cases, that is: 1) HESS employed for FR and 2) BESS employed for FR, is presented, which shows that the HESS is more economical."
  },
  {
    "year": "2017",
    "abstract": "Currently, vehicle incidence remains high, but the related research is mainly focused on single-vehicle collision warning, which is unable to notice the following multiple endangered vehicles in emergency. The main technical challenge of chain collision warning is accurate and seamless ranging or positioning of the neighboring multiple vehicles. Because of the non-line of sight (NLOS) environments, the traditional ultrasonic or laser method does not work. At the same time, the accuracy of global navigation satellite system (GNSS) is over 10 m, such as global positioning system (GPS) or BeiDou satellite positioning system (BDS), which is not efficient for the cooperative collision avoidance (CCA) system. Moreover, GNSS fails to operate in NLOS tunnels or downtown areas where blockage of satellite signals is frequent. Thus, in this paper, a seamless and high accuracy positioning method based-on three kind of multi-source information fusion is proposed, i.e., the high accuracy local positioning information is provided by IEEE 802.11p protocol, the dual-mode wide area differential positioning information provided by the fusion of BDS and GPS, the positioning information of dead reckoning provided by the fusion of on-board diagnostic (OBD) and micro-electro-mechanical system-inertial navigation system. In vehicle positioning system, the accurate time of arrival (TOA) estimation is very important, so in this paper, a two steps method for TOA estimation using the IEEE 802.11p short preamble is proposed. Simulations show that in both the international telecommunication union vehicular multipath channel and the additive white Gaussian noise channel, the proposed method provides better accuracy and is less time complex than some well-known methods. The estimated TOA fused with the GNSS and OBD information can be used for seamless and high accuracy positioning in the CCA system to avoid traffic accident."
  },
  {
    "year": "2017",
    "abstract": "Driven by the increasing demand of intensive computing services and the resource limitation of mobile devices at the edge of mobile networks, mobile edge computing (MEC) is concerned with being an emerging paradigm towards the 5G communications. A main issue of MEC is the coordination of communication, computation, and storage. In this paper, we propose a novel MEC framework with a user virtualization scheme in the software-defined network virtualization cellular network, in which radio resources are virtualized along with computation and storage resources to cooperatively finish MEC services. Besides, we introduce the user virtualization assisted by the full-duplex communication which can extend the radio resource of wireless networks and provide the potential to increase system performance. Moreover, enabled by user virtualization, users can offload the edge computation tasks directly to the MEC server implemented at infrastructure providers or via the virtualized mobile device attributed to different mobile virtual network operators (MVNOs). Under this MEC framework, we formulate the virtual resource allocation as ajoint optimization problem. A distributed resource allocation algorithm based on an alternating direction method of multipliers is proposed which can reduce computational complexity and signaling overhead. We evaluate the proposed algorithm through extensive simulations, and the results show that the total utility of MVNOs can be improved significantly which benefited from user virtualization."
  },
  {
    "year": "2017",
    "abstract": "Research demonstrates that individualized instruction is superior to the traditional one-size-fits-all teaching approach. The use of 3D virtual environments for educational purposes is becoming attractive because of their rich presentation, user friendly interaction techniques, and adaptive capabilities. However, defining the adaptive aspect of 3D virtual learning environments (3D-VLEs) is a challenging task. In this paper, we quantitatively measure learning skill of a student through a fuzzy logic-based approach and use it as adaptation criterion for changing the contents of 3D-VLEs. The system displays customize teaching materials for different students, which results in improved learning. The experimental results show that the proposed approach is effective and can be efficiently used to enhance the learning capabilities of students in 3D-VLEs."
  },
  {
    "year": "2017",
    "abstract": "This paper shares experiences and lessons learned from designing and developing the bespoke Internet of Things (IoT) sensing platforms of a sensor platform for healthcare in a residential environment (SPHERE). These IoT platforms, which include a wrist-worn wearable sensor, a room-level environmental sensor, and a dual-radio gateway, constitute integral parts of the SPHERE system that is currently getting deployed in up to 100 houses of volunteers for up to 12 months. This paper is focused on sharing several years’ worth of insight and experiences from making IoT sensing platforms for large-scale academic deployments, providing information that can accelerate the development and deployment of prototypes and enable timely research in the space of IoT."
  },
  {
    "year": "2017",
    "abstract": "The known methods used for strapdown inertial navigation system (SINS)/celestial navigation system (CNS) integration are classified based on two categories of measurement in this paper. One category is called the\"attitude observation method,\" in which the measurement is derived by the difference between the optimal attitude information of the star sensor and the SINS. The other category is called the \"star vector observation method,\" in which the measurement is derived by the difference between the original star vector information of the star sensor. The attitude angle observation equation of the first category is generally obtained by using the relationship between the attitude angle errors and the Phi-angle (or tilt errors), and the attitude matrix observation equation is obtained by using the relationship between the attitude matrix and the Psi-angle (or platform errors). However, the interrelationship between these two observation equations has not been developed in previous studies. A simpler attitude angle observation method based on the Psi-angle instead of the Phi-angle is proposed to reveal the interrelationship between these two methods. This proposed method is basically the principle behind the SINS/CNS integration and depicts the physical meaning clearly. In addition, the internal relationships of the second category and the interrelationship of these two categories are also analyzed to show their equivalence to each other. Numerical simulations verify the correctness of the analysis. Experimental studies indicate that the integration accuracy of the two categories is also exactly equivalent."
  },
  {
    "year": "2017",
    "abstract": "Searchable Encryption (SE) has been extensively examined by both academic and industry researchers. While many academic SE schemes show provable security, they usually expose some query information (e.g., search and access patterns) to achieve high efficiency. However, several inference attacks have exploited such leakage, e.g., a query recovery attack can convert opaque query trapdoors to their corresponding keywords based on some prior knowledge. On the other hand, many proposed SE schemes require significant modification of existing applications, which makes them less practical, weak in usability, and difficult to deploy. In this paper, we introduce a secure and practical searchable symmetric encryption scheme with provable security strength for cloud applications, called IDCrypt, which improves the search efficiency, and enhances the security strength of SE using symmetric cryptography. We further point out the main challenges in securely searching on multiple indexes and sharing encrypted data between multiple users. To address the above issues, we propose a token-adjustment search scheme to preserve the search functionality among multi-indexes, and a key sharing scheme which combines identity-based encryption and public-key encryption. Our experimental results show that the overhead of the key sharing scheme is fairly low."
  },
  {
    "year": "2017",
    "abstract": "Massive MIMO is commonly described as a large number of base station (BS) antennas serving a smaller number of single-antenna users. However, adding a second antenna to the user handset opens the possibility to exploit multiplexing techniques and obtain higher throughput. This paper is based on a measurement campaign comprising a BS with 64 elements reconfigurable into three shapes: 1) a very large array with 6-m aperture; 2) a large array with 2m aperture; and 3) a compact two dimensional array with 25 cm by 28 cm sides. We study the throughput in single-user and multi-user scenarios using both non-linear optimal and linear precoders. The experimental results show that the throughput increases when adding a second antenna, but the increase is lower than in Gaussian channels due to the intra-user correlation. However, increasing the number of BS antennas, massive MIMO achieves more benefits from the second antenna. A large number of users in the system and the inter-user correlation reduce the benefits of a second antenna in the user handset."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the procedure for evaluating the electromagnetic field induced by the wake of an undersea-moving slender body. The slender body is considered equivalent to a pair of Havelock point sources that can generate wake flow fields. The electric current generated in the seawater is calculated by means of the moving conductive seawater that cuts the earth's magnetic field. The electromagnetic fields in the air and in the seawater are then determined by solving the Maxwell equations with appropriate boundary conditions. The induced electromagnetic fields include two parts: One is the attenuating oscillation that can be ascribed to the free surface Kelvin wake, and the other is the bipolar pulse that can be ascribed to the localized volume wake. Near the sea surface, the magnitude of the former is typically a few hundred picotesla, while that of the latter could be greater by ten times."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad hoc networks (VANETs) have increased in popularity in recent years and play an extremely important role in the intelligent transportation field. However, the demands of larger communication networks and the integrated message verification process for ensuring security incur more communication and computation overheads, and directly affect the efficiency of existing VANET schemes. To address this issue, this paper proposes a novel and practical conditional privacy-preserving authentication scheme, which uses the registration list instead of the revocation list to reduce the communication overhead. Specifically, our scheme can prevent malicious vehicles from disrupting the security features of VANETs. Moreover, we do not use the bilinear pairing operation, which is the most complicated operation in modern cryptography, thus significantly reducing the computation overhead and communication overhead. Security and performance analyses demonstrate that our proposed scheme is more secure and efficient than current schemes, and that the proposed scheme is more suitable for VANET deployments."
  },
  {
    "year": "2017",
    "abstract": "Power system faults are significant problems in power transmission and distribution. Methods based on relay protection actions and electrical component actions have been put forward in recent years. However, they have deficiencies dealing with power system fault. In this paper, a method for data-based line trip fault prediction in power systems using long short-term memory (LSTM) networks and support vector machine (SVM) is proposed. The temporal features of multisourced data are captured with LSTM networks, which perform well in extracting the features of time series for a long-time span. The strong learning and mining ability of LSTM networks is suitable for a large quantity of time series in power transmission and distribution. SVM, with a strong generalization ability and robustness, is introduced for classification to get the final prediction results. Considering the overfitting problem in fault prediction, layer of dropout and batch normalization are added into the network. The complete network architecture is shown in this paper in detail. The parameters are adjusted to fit the specific situation of the actual power system. The data for experiments are obtained from the Wanjiang substation in the China Southern Power Grid. The real experiments prove the proposed method's improvements compared with current data mining methods. Concrete analyses of results are elaborated in this paper. A discussion of practical applications is presented to demonstrate the feasibility in real scenarios."
  },
  {
    "year": "2017",
    "abstract": "In this paper, characteristic mode analysis (CMA) is originally applied to investigate complex spoof localized surface plasmon (LSP) resonators, including a traditional toroid spoof-LSP resonator, and three Fabry-Perot type spoof-LSP resonators with different boundary conditions: open, shorted, and reactive. Compared with three traditional analytical methods of spoof LSP: dispersion curve approximation, near-field measurement (NFM), and extinction cross-sectional simulation (ECSS), CMA has three main advantages: to provide an insight of intrinsic resonances independent of excitations, to provide eigencurrents distribution, and to track each resonant mode at the full frequency band even when many resonant modes coexist at a very narrow band. Resonant frequencies calculated by CMA match well with that obtained by NFM and ECSS, indicating the correctness of CMA method. Based on CMA, bandwidths and eigencurrents of different resonant modes are also presented. It is foreseeable that CMA could be further utilized in spoof-LSP designs for various applications."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel access protocol based on the distributed queue (DQ) mechanism to effectively tackle the massive access issue in the cellular-based machine-to-machine (M2M) communications. To fully take the advantage of the DQ mechanism, we newly propose a method to avoid the DQ's inherent over-division problem by letting the base station first roughly probes the number of colliding devices in a random access opportunity. Based on the probing result, the base station then randomly divides these devices into a determined number of groups and “pushes”these groups to the end of a logical access queue. In addition, we develop an analytic model to accurately estimate the average access delay of the proposed protocol in the massive scenarios. Computer simulations are also performed to validate the correctness of the analytic model as well as the effectiveness of the proposed protocol in comparison with the LTE standard and conventional DQ access schemes."
  },
  {
    "year": "2017",
    "abstract": "With the development of mobile devices, mobile crowdsourcing has become the research hotspot in mobile crowd sensing networks (MCSS). How to protect the location privacy of mobile user in location-based services is a key problem in MCSS. However, with the increase of privacy-preserving level, the service quality will be influenced and decrease. In order to prevent mobile user's location privacy from being leaked, this paper proposes a location privacy-preserving mechanism CKD through combining k-anonymity and differential privacy-preserving. In addition, the tradeoff between privacy protection and service quality is solved based on Stackelberg game. Through comparison experiments, the proposed location privacy-preserving CKD is verified. In addition, the tradeoff between privacy protection and service quality can be solved by our location privacy-preserving."
  },
  {
    "year": "2017",
    "abstract": "The grid-connected inverter with virtual synchronous generator (VSG) control technology can improve the friendliness of a distributed power supply to the power grid. However, its low-voltage ridethrough (LVRT) capability is insufficient, which results in difficulties in limiting the current and provide reactive power support. A new LVRT control strategy based on the smooth switching is proposed in this paper. In this strategy, the voltage source mode of VSG is transformed into current source mode to limit the output current and provide reactive power support through the proportional resonance current control algorithm under grid fault. Furthermore, the feedback tracking synchronization strategy of the phase angle is employed to realize the smooth switching between two modes. When the grid fault recovers, it can directly switch back to grid-connected operation mode through a delay module without an additional algorithm. The simulation results verify the correctness and feasibility of the proposed control strategy."
  },
  {
    "year": "2017",
    "abstract": "The inclusion of distributed renewable energy sources, new goals of efficiency and reliability, and the technological advancement of the power grid has led to a significant increase in the complexity of distribution systems. Although multiple devices can be controlled to achieve these objectives during smart grid operation, many proposed algorithms are based on ideal scenarios where the complex distribution system is assumed to be fully observable or measurable. As this condition obstructs many advanced applications, it is necessary to implement novel alternatives that provide support and validation in the field. In this paper, we show that embedded simulation is capable of providing accurate results of the system real-time condition. The designed platform exploits the technological development of mobile devices, a specific purpose solver, and concurrent processing to embed the power systems simulation into small, flexible, and affordable devices. Simulation results demonstrate the accuracy and timeliness of the proposed realtime simulation based on the IEEE 37 bus test feeder emulation and other large-scale scenarios such as the IEEE 8500 node test feeder. We anticipate that this simulation approach will be useful for applications covering advanced protection relaying, volt-var control, topological reconfiguration, distributed generation management, storage control, and cyber security assessment among others."
  },
  {
    "year": "2017",
    "abstract": "Recent research has shown that both radio and visible light waves can be used to enable communications in highly dynamic vehicular environments. However, the roles of these two technologies and how they interact with each other in future vehicular communication systems remain unclear. Understanding the propagation characteristics is an essential step in investigating the benefits and shortcomings of each technology. To this end, we discuss salient properties of radio and visible light propagation channels, including radiation pattern, path loss modeling, noise and interference, and channel time variation. Comparison of these properties provides an important insight that the two communication channels can complement each other's capabilities in terms of coverage and reliability, thus better satisfying the diverse requirements of future cooperative intelligent transportation systems."
  },
  {
    "year": "2017",
    "abstract": "Chromosomal structural changes known as copy number alterations-aberrations (CNAs) result in gains or losses in copies of deoxyribonucleic acid sections, which are typically associated with different types of cancer. An intensive noise inherent to modern technologies of CNAs probing often causes inconsistency between the estimates provided by different methods. Therefore, testing estimates by the confidence masks is recommended to guarantee an existence of genomic changes within certain regions. In known masks, jitter in the CNA's breakpoints is expected to be distributed with the skew Laplace law, which is sufficiently accurate when the segmental signal-to-noise ratio (SNR) exceeds unity. In this paper, we extend the confidence masks to low and very low SNRs often observed in subtle chromosomal changes. The modified masks employ several proposed approximations of the segmental noise variance as a function of the departure step from the candidate breakpoint. Because approximations are accurate in jitter computation only for specified SNR regions, we suggest using hybrid masks to achieve the maximum available accuracy. Confidence masks are tested experimentally by genome CNA profile data obtained using the single nucleotide polymorphism array."
  },
  {
    "year": "2017",
    "abstract": "Correlated color temperature (CCT) is an important feature of the LED luminaire. However, its influence on visual discomfort remains vague due to the lack of a comprehensive study based on ocular physiological parameters and psychological assessment. In this paper, the investigation was carried out by the measurement of ocular parameters and the collection of subjective score. Three physiological parameters were used including higher order aberrations, modulation transfer function, and the ratio of accommodative convergence to accommodation ratio. It is shown that CCT has significance influence on human eye, and the proper CCT for the ocular health of moderate myopia people is near 5000 K. In addition, the results imply that the perception of discomfort is caused by psychological perception rather than ocular fatigue."
  },
  {
    "year": "2017",
    "abstract": "Unlike adaptive interfaces which use sensors to adapt themselves, adaptable interfaces need the intervention of end users to adapt their different aspects according to user requirements. These requirements are commonly expressed according to the context of use. This latter was defined by the triplet <;platform, environment, user> where the platform refers to the physical device and the device software, the environment refers to the physical environment in which the application is used and the user element refers to the user preferences and user profile. In this paper, we define a dynamic software product line (DSPL) approach for the development of a family of context-adaptable user interfaces. The DSPL paradigm exploits the knowledge acquired in software product line engineering to develop systems that can be context-aware, or runtime adaptable. Our approach satisfies a set of contributions which will be validated by implementing and evaluating them according to an illustrative case study."
  },
  {
    "year": "2017",
    "abstract": "Soft robotics is a research field growing rapidly with primary focuses on the prototype design, development of soft robots and their applications. Due to their highly deformable features, it is difficult to model and control such robots in a very precise way compared with the conventional rigid structured robots. Hence, the calibration and parameter identification problems of an underactuated robotic hand with soft fingers are important, but have not been investigated intensively. In this paper, we present a comparative study on the calibration of a soft robotic hand. The calibration problem is framed as an AX = YB problem with the partially known matrix A. The identifiability of the parameters is analyzed, and calibration methods based on nonlinear optimization (i.e., Levenberg-Marquardt method and interior-point method) and evolutionary computation (i.e., differential evolution) are presented. Extensive simulation tests are performed to examine the parameter identification using the three methods in a comparative way. The experiments are conducted on the real soft robotic-hand setup. The fitting, interpolating, and extrapolating errors are presented as well."
  },
  {
    "year": "2017",
    "abstract": "The hybrid electric ground vehicle (HEGV), driven by in-wheel motors (IWMs), is a good solution for prolonging vehicle driving range and improving dynamics performance. This paper presents a hierarchical optimization control strategy for a four-axle HEGV driven by IWMs to improve handling stability. In the proposed hierarchical control strategy, the upper layer controller controls the vehicle motion states to track the desired ones, in which the controlled force and moment are considered as resultant of the longitudinal tire force, and is determined by using the nonlinear sliding mode control method. In the lower layer controller, the control allocation method is adopted to assign torque to all actuators, including the IWMs and brakes, to generate the controlled force and moment determined by the upper layer controller. Considering the motor torque capability, tire workload rate, and road adhesion, we establish an objective function with constraints, which is solved by using the optimization algorithm. The software simulation and the hardware-in-loop test results show that the proposed control strategy exhibits excellent performance in terms of vehicle handling stability, compared with the commonly used control strategies, and has the capability of real-time implementation."
  },
  {
    "year": "2017",
    "abstract": "This paper introduces the structural characteristics of a 6-D force sensor based on an E-type membrane, analyzes the calibration results of each bridge, and determines the coupling relationship between bridges of a sensor. In the case that a sensor has no fault in its bridges, a decoupling matrix is calculated by identifying a linear decoupling model. In the case that the fault happens, a linear neural network method is used to discard the faulty bridge to calculate the reduced-dimensional decoupling matrix, and the BP neural network nonlinear method is used to compensate the faulty bridge signal for fault-tolerant decoupling. Simulation results indicate that the reliability of the sensor under the fault condition has been significantly improved."
  },
  {
    "year": "2017",
    "abstract": "MedFDTD, a new parallel and open-source cross-platform framework for bioelectromagnetics research, has been developed by solving Maxwell's equations using the finite-difference time-domain method. This framework implements the complex-frequency-shifted perfectly matched layer, supports the import of antenna and bioelectromagnetic models through media with non-dispersive/dispersive properties, and can calculate the antenna output power and specific absorption rate of biological tissues, thereby making it favorable for bioelectromagnetics studies. In addition, MedFDTD can be implemented on multiple CPUs or a variety of chip-based GPUs to accelerate all parallel computing tasks."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a nonlinear excitation controller is designed for multimachine power systems in order to enhance the transient stability under different operating conditions. The two-axis models of synchronous generators in multimachine power systems along with the dynamics of the IEEE Type-II excitation systems are considered to design the proposed controller. The partial feedback linearization scheme is used to simplify the multimachine power system as it allows decoupling a multimachine power system based on the excitation control inputs of synchronous generators. A receding horizon-based continuoustime model predictive control scheme is used for partially linearized power systems to obtain linear control inputs. Finally, the nonlinear control laws, which also include receding horizon-based control inputs, are implemented on the IEEE 10-machine, 39-bus New England power system. The superiority of the proposed scheme is evaluated by providing comparisons with a similar existing nonlinear excitation controller, where the control input for the feedback linearized model is obtained using the linear quadratic regulator (LQR) approach. The simulation results demonstrate that the proposed scheme performs better as compared to the LQR-based partial feedback linearizing excitation controller in terms of enhancing the stability margin."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a symmetrical Doherty power amplifier (DPA) based on class-J mode for efficiency enhancement in a broad bandwidth. With a second harmonic suppression integrated into the output matching network of carrier power amplifier (PA) and peaking PA, respectively, the complex interaction of varying second harmonic impedances caused by dynamic load modulation can be eliminated and the second harmonic impedance remains the same reactance at both the output back-off (OBO) region and the saturated power. To meet the requirement of second harmonic termination, the DPA works in conventional class-J mode at the saturated power and a modified class-J continuum is proposed to expand the impedance design space at 8 dB OBO with good efficiency performance. A gallium nitride DPA is designed and fabricated to validate the method over a frequency band of 3.3-3.75 GHz. Under a 10%-duty-cycle pulse excitation, experimental results show the DPA delivers 48-48.8 dBm output power with a drain efficiency (DE) of 58%-71%. At 8 dB OBO, a measured DE of 44%-55% is achieved with a gain of 11.8-13.5 dB. When driven by a 2-carrier 40-MHz long-term evolution signal with a peak-to-average power ratio of 8 dB, the DPA exhibits an adjacent channel leakage ratio of -30 dBc at an average output power of 40.7 dBm at 3.45 GHz."
  },
  {
    "year": "2017",
    "abstract": "Monocomponent image decomposition plays an important role in image analysis and related areas, such as image denoising, object detection, and texture segmentation. Existing image decomposition methods can extract monocomponents but their performances are insufficiently accurate because of interference and redundancy component problems caused by inaccurate spectrum segmentation. In this paper, an empirical monocomponent image decomposition (EMID) is proposed for fully recoverable monocomponents. The EMID method empirically decomposes an image into monocomponents based on energy concentration in Fourier support. This method is composed of two main processes: 1) energy concentrationbased segmentation and 2) empirical image filter bank construction. In the former process, the base of a mountain-shaped energy concentration that can perfectly represent the monocomponent spectrum boundary is detected and identified. This process provides a more accurate spectrum segmentation which helps prevent the serious problems from interference and redundancy components. In the latter process, an empirical image filter bank is constructed in accordance with the actual monocomponent boundaries by means of ellipse and Gaussian functions and used to decompose an image into monocomponent images with fewer ringing artifacts. The experimental results show that the proposed EMID method achieves a better decomposition than the state-of-the-art methods in terms of the quality of monocomponent images that are evaluated by peak signal-to-noise ratio and structural similarity index. Furthermore, in a real world dataset, the EMID method is able to clearly detect text regions, thus significantly improving the efficiency of Thai text character localization in natural scene images."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the objective is to classify biomedical signals from their compressive measurements. The problem arises when compressed sensing (CS) is used for energy efficient acquisition and transmission of such signals for wireless body area network. After reconstruction, the signal is analyzed via certain machine learning techniques. This paper proposes to carry out joint reconstruction and analysis in a single framework; the reconstruction ability is obtained inherently from our formulation. We put forth a new technique called semi-supervised deep blind CS that combines the analytic power of deep learning with the reconstruction ability of CS. Experimental results on EEG classification show that the proposed technique excels over the state-of-the-art paradigm of CS reconstruction followed by deep learning classification."
  },
  {
    "year": "2017",
    "abstract": "Two integrated, highly efficient RF-to-dc rectifier circuits are presented. The rectifier circuits are based on improved Dickson charge pump models and are fabricated using 65-nm CMOS GlobalFoundries process. The designs utilize diode-connected metal-oxide-semiconductor field-effect transistors instead of the conventional Schottky diodes to provide a fully integrated circuits. A detailed analytical model that supports the improved circuit model is given. The measurement results of both rectifier circuits show good agreement with the simulation results. The fabricated rectifiers' start to operate at -17.5-dBm input power. The tested frequency of operation of the rectifier circuits is 953 MHz (GSM900 band), however, other frequency bands such as 2.4 GHz (Bluetooth/WLAN) could be covered with proper impedance matching. The measured peak power conversion efficiency (PCE) of the implemented rectifiers are 84.37% and 56.16% at input power levels of -12.5 and -15 dBm, respectively. To the best of our knowledge, this is the highest achieved PCE for the class of rectifiers at such low input power level in the literature. High sensitivity and excellent PCE of the presented rectifiers are ideal for utilization in wireless sensor network, Internet of Things, energy harvesting, and biomedical applications."
  },
  {
    "year": "2017",
    "abstract": "This paper studies adaptive transmission in an underwater acoustic (UWA) point-to-point communication system that operates on an epoch-by-epoch basis for a long term. A fixed amount of information bits periodically arrive at the transmitter data queue, and wait for transmission via a number of packets within each epoch. To trade off energy consumption with transmission latency, the transmitter decides the transmission action at the beginning of each epoch, including to transmit or not, and the transmission power and the modulation-and-coding parameters, based on the data queue status and the predicted channel conditions in the current and future epochs. To describe both the fast fading and the large-scale shadowing of UWA channels, the channel within each epoch is characterized by a compound Nakagamilognormal distribution, and the evolution of the distribution parameters is modeled as an unknown Markov process. Given that the channel can only be observed during active transmissions, we formulate the adaptive transmission problem as a partially observable Markov decision process, and develop an online algorithm in a model-based reinforcement learning framework. The algorithm recursively estimates the channel model parameters, tracks the channel dynamics, and computes the optimal transmission action that minimizes a long-term system cost. Emulated results based on channel measurements from two-field experiments demonstrate that the proposed algorithm achieves decent performance relative to a benchmark method that assumes perfect and non-causal channel knowledge."
  },
  {
    "year": "2017",
    "abstract": "In order to implement 3-D displays with focus cues, several technologies, including multi-layer displays, have been introduced and studied. In multi-layer displays, a volumetric 3-D scene is represented by 2-D layer images via optimization process. Although this methodology has been thoroughly explored and discussed in optical aspect, the optimization method has not been fully analyzed. In this paper, we deal with pupil movement that may prevent efficient synthesis of layer images. We propose a novel optimization method called foveated retinal optimization, which considers the foveated visual acuity of human. Exploiting the characteristic of human vision, our method has tolerance for pupil movement without gaze tracking while maintaining image definition and accurate focus cues. We demonstrate and verify our method in terms of contrast, visual metric, and experimental results. In experiment, we implement a see-through near-eye display that consists of two display modules, a light guide, and a holographic lens. The holographic lens enables us to design a more compact prototype as performing the roles of an image combiner and floating lens, simultaneously. Our system achieves38∘×19∘field of view, continuous focus cues, low aberration, small form factor, and clear see-through property."
  },
  {
    "year": "2017",
    "abstract": "Sleep is a fundamental and vital physiological function. Getting enough quality sleep is necessary to a person’s mental health, physiological well-being, quality of life, and safety. Sleep-disordered breathing, specifically obstructive sleep apnea can result in serious health issues, including hypertension and stroke. The current approaches for diagnosing sleep disorders are burdensome, intrusive, and can affect the patient’s sleep quality. As a result, there is a crucial need for less cumbersome systems to diagnose sleep-related problems. In this paper, we evaluated the capacity of the microbend fiber optic sensor to monitor heart rate and respiration in a nonintrusive manner. In addition, we tested the capacity of the sensor in discriminating between shallow breathing and no breathing. The proposed sensor was compared with the three-channel portable monitoring device (ApneaLink) in a clinical setting during a drug-induced sleep endoscopy. Across all ten patients recruited for our study, the system achieved satisfactory results in the mean heart rate and the mean respiratory rate with an error of 0.55 ± 0.59 beats/minute and 0.38 ± 0.32 breaths/minute, respectively. Besides, the Pearson correlation coefficient between the proposed sensor and the reference device was 0.96 and 0.78 for heart rate and respiration, respectively. On the contrary, the proposed sensor provided a very low sensitivity (24.24 ± 12.81%) and a relatively high specificity (85.88 ± 6.01%) for sleep apnea detection. It is expected that this preliminary research will pave the way toward unobtrusive detection of vital signs in real time."
  },
  {
    "year": "2017",
    "abstract": "Automatic recording and analysis of bird calls is becoming an important way to understand changes in bird populations and assess environmental health. An issue currently proving problematic with the automatic analysis of bird recordings is interference from noise that can mask vocalizations of interest. As such, noise reduction can greatly increase the accuracy of automatic analyses and reduce processing work for subsequent steps in bioacoustics analyses. However, only limited work has been done in the context of bird recordings. Most semiautomatic methods either manually apply sound enhancement methods available in audio processing systems such as SoX and Audacity or apply preliminary filters such as lowand highpass filters. These methods are insufficient both in terms of how generically they can be applied and their integration with automatic systems that need to process large amounts of data. Some other work applied more sophisticated denoising methods or combinations of different methods such as minimum mean square error short-time spectral amplitude estimator (MMSE STSA) and spectral subtraction for other species such as anurans. However, their effectiveness is not tested on bird recordings. In this paper, we analyze the applicability of the MMSE STSA algorithm to remove noise from environmental recordings containing bird sounds, particularly focusing on its quality and processing time. The experimental evaluation using real data clearly shows that MMSE STSA can reduce noise with similar effectiveness [using objective metrics such as predicted signal quality (SIG)] to a previously recommended wavelet-transform-based denoising technique while executing between approximately 5-300 times faster depending on the audio files tested."
  },
  {
    "year": "2017",
    "abstract": "In information-centric networking, accurately predicting content popularity can improve the performance of caching. Therefore, based on software defined network (SDN), this paper proposes Deep-Learning-based Content Popularity Prediction (DLCPP) to achieve the popularity prediction. DLCPP adopts the switch's computing resources and links in the SDN to build a distributed and reconfigurable deep learning network. For DLCPP, we initially determine the metrics that can reflect changes in content popularity. Second, each network node collects the spatial-temporal joint distribution data of these metrics. Then, the data are used as input to stacked auto-encoders (SAE) in DLCPP to extract the spatiotemporal features of popularity. Finally, we transform the popularity prediction into a multi-classification problem through discretizing the content popularity into multiple classifications. The Softmax classifier is used to achieve the content popularity prediction. Some challenges for DLCPP are also addressed, such as determining the structure of SAE, realizing the neuron function on an SDN switch, and deploying DLCPP on an OpenFlow-based SDN. At the same time, we propose a lightweight caching scheme that integrates cache placement and cache replacement-caching based on popularity prediction and cache capacity (CPC). Abundant experiments demonstrate good performance of DLCPP, and it achieves close to 2.1%~15% and 5.2%~40% accuracy improvements over neural networks and auto regressive, respectively. Benefitting from DLCPP's better prediction accuracy, CPC can yield a steady improvement of caching performance over other dominant cache management frameworks."
  },
  {
    "year": "2017",
    "abstract": "Respiratory motion causes difficulty in locating tumours in the thorax and upper abdomen for image-guided radiotherapy. Precisely predicting the respiratory-induced organ motion is still a challenging problem at present. In this paper, to predict the motion of lungs in a respiratory cycle, we propose a novel method comprising Bayesian registration and trajectory modelling based on cine four-dimensional computer tomography (4DCT) images. Specifically, we take the CT image captured at the end-inhale phase as the source image and those captured at other phases as the moving images. We then align the source image to each moving-phase image to generate the displacement fields using the Bayesian registration method. The lung-motion trajectory is then modelled based on a continuous time-related displacement field by linking the displacement fields at discrete phases. The results indicate that any point in the lungs at any given time is accurately predicted using the proposed method, which provides an alternative method of estimating the lung and tumour motions for radiation therapy."
  },
  {
    "year": "2017",
    "abstract": "Feature extraction is vital for face recognition. In this paper, we focus on the general feature extraction framework for robust face recognition. We collect about 300 papers regarding face feature extraction. While some works apply handcrafted features, other works employ statistical learning methods. We believe that a general framework for face feature extraction consists of four major components: filtering, encoding, spatial pooling, and holistic representation. We analyze each component in detail. Each component could be applied in a task with multiple levels. Then, we provide a brief review of deep learning networks, which can be seen as a hierarchical extension of the framework above. Finally, we provide a detailed performance comparison of various features on LFW and FERET face database."
  },
  {
    "year": "2017",
    "abstract": "In many real-world applications, labeled instances are generally limited and expensively collected, while the most instances are unlabeled and the amount is often sufficient. Therefore, semi-supervised learning (SSL) has attracted much attention, since it is an effective tool to discover the unlabeled instances. However, how to safely make use of the unlabeled instances is an emerging and interesting problem in SSL. Hence, we propose DuAL Learning-based sAfe Semi-supervised learning (DALLAS), which employs dual learning to estimate the safety or risk of the unlabeled instances. To realize the safe exploitation of the unlabeled instances, our basic idea is to use supervised learning (SL) to analyze the risk of the unlabeled instances. First, DALLAS utilizes a primal model obtained by dual learning to classify each unlabeled instance and then uses a dual model to reconstruct the unlabeled instances according to the obtained classification results. The risk can be measured by analyzing the reconstruction error and predictions of the original and reconstructed unlabeled instances. If the error is small and the predictions are equal, the unlabeled instance may be safe. Otherwise, the instance may be risky and its output should be approach to be that obtained by SL. Finally, we embed a risk-based regularization term into SSL. Hence, the outputs of our algorithm are a tradeoff between those of SL and SSL. In particular, we utilize respectively regularized least squares (RLS) and Laplacian RLS for SL and SSL. To verify the effectiveness of the proposed safe mechanism in DALLAS, we carry out a series of experiments on several data sets by the comparison with the state-of-the-art supervised, semi-supervised, and safe semi-supervised learning methods and the results demonstrate that DALLAS can effectively reduce the risk of the unlabeled instances."
  },
  {
    "year": "2017",
    "abstract": "Communication systems are witnessing an outstanding revolution that has a clear impact on all aspects of life. The world technology is drifting towards high frequency and data rate solutions to accommodate the future expansion in applications such as 5G communications. The 5G technology will offer advanced features in the mm-Wave frequency band which requires intelligent subsystems such as beam switching. Therefore, the microwave components, especially couplers, still need a significant improvement to follow the rapid variations in future technologies. One of the most recent and promising guiding technologies for mm-Wave applications is the printed ridge gap waveguide (PRGW). In this paper, a design of 3-dB planar quadrature hybrid coupler based on PRGW is presented. The proposed design has superior characteristics such as compactness, low loss, and low dispersion device. The prototype of the proposed coupler is fabricated and tested, where the measured and simulated results show an excellent agreement."
  },
  {
    "year": "2017",
    "abstract": "We study the linear precoder design problem in downlink multiuser MIMO (MU-MIMO). We first analyze the leakage-based precoder design under a full multiplexing constraint, which maximizes the signal-to-leakage-and-noise ratio (SLNR) for each individual user. We prove that the SLNR-optimal multistream precoder always maximizes the SLNR via essentially concentrating all the available transmit power on a single data stream, regardless of the rank constraint. We then propose a novel design criterion, called signal-over-leakage capacity (SLC), which corresponds to the achievable rate difference between a virtual signal-only link and a virtual interference-only link, for each individual user. We completely solve the SLC maximization problem and provide a closed-form optimal solution, which distributes the transmit power among multiple data streams, and thus better utilizes the available spatial degrees of freedom in an MU-MIMO system. Numerical experimental results are provided to corroborate the analysis."
  },
  {
    "year": "2017",
    "abstract": "The Gerschgorin circle theorem was recently applied to build two detectors for the purpose of spectrum sensing in cognitive radio applications, the so-called Gerschgorin radius-based and the Gerschgorin disk-based detectors. However, the corresponding test statistics do not exhibit the constant false alarm rate (CFAR) property and are not robust against dynamical noise, the situation in which nonuniform noise levels fluctuate over time. In this paper, a novel and simple detector for cooperative or multi-antenna spectrum sensing is proposed. The test statistic is the ratio between the sum of the Gerschgorin radii and the sum of the Gerschgorin centers relative to the covariance matrix of the signal received from one or more transmitters. It is named Gerschgorin radii and centers ratio (GRCR) detector. The GRCR exhibits the CFAR property and is robust against nonuniform and dynamical noise and received signal powers, yet being able to detect time-uncorrelated or time-correlated transmitted signals over additive Gaussian noise and fading channels."
  },
  {
    "year": "2017",
    "abstract": "Trajectory mining is an interesting data mining problem. Traditionally, it is either assumed that the time-ordered location data recorded as trajectories are either deterministic or that the uncertainty, e.g., due to equipment or technological limitations, is removed by incorporating some pre-processing routines. Thus, the trajectories are processed as deterministic paths of mobile object location data. However, it is important to understand that the transformation from uncertain to deterministic trajectory data may result in the loss of information about the level of confidence in the recorded events. Probabilistic databases offer ways to model uncertainties using possible world semantics. In this paper, we consider uncertain sensor data and transform this to probabilistic trajectory data using pre-processing routines. Next, we model this data as tuple level uncertain data and propose dynamic programming-based algorithms to mine interesting trajectories. A comprehensive empirical study is performed to evaluate the effectiveness of the approach. The results show that the trajectories could be modeled and worked as probabilistic data and that the results could be computed efficiently using dynamic programming."
  },
  {
    "year": "2017",
    "abstract": "Burst-interference suppression is quite challenging and of great importance to wireless communications, but is rarely investigated in the current literature. In this paper, a novel approach based on space-time processing is proposed for the burst-interference suppression. First, part of the conventional centralized training sequence is scattered and evenly embedded into the transmitted data sequence. In this way, the unexpected burst interference has a much higher possibility to contaminate the training sequence, as compared with the conventional centralized one. Next, we can exploit the burst-interference information contained in the received scattered pilot to adaptively compute the optimal space-time weighting coefficients (STWC) under the weighted minimum mean square error criterion. The STWC are then used to perform the space-time filtering on the received data sequence to suppress interference as well as recover the transmitted data symbols. Simulation results show that our proposed method can effectively mitigate the influence of burst interference."
  },
  {
    "year": "2017",
    "abstract": "Due to the current structure of digital factory, it is necessary to build the smart factory to upgrade the manufacturing industry. Smart factory adopts the combination of physical technology and cyber technology and deeply integrates previously independent discrete systems making the involved technologies more complex and precise than they are now. In this paper, a hierarchical architecture of the smart factory was proposed first, and then the key technologies were analyzed from the aspects of the physical resource layer, the network layer, and the data application layer. In addition, we discussed the major issues and potential solutions to key emerging technologies, such as Internet of Things (IoT), big data, and cloud computing, which are embedded in the manufacturing process. Finally, a candy packing line was used to verify the key technologies of smart factory, which showed that the overall equipment effectiveness of the equipment is significantly improved."
  },
  {
    "year": "2017",
    "abstract": "For moving targets localization, incorporating frequency-difference-of-arrival (FDOA) measurements in the commonly used time-difference-of-arrival (TDOA) positioning systems will improve performance. Such an approach still has unresolved technical challenges. The commonly used maximum likelihood estimator (MLE) is nonconvex and highly nonlinear, and the parameters to be estimated are mutually coupled in the positioning process. The goal of this paper is to develop an effective iterative method that resolves these challenges for moving target localization using TDOA and FDOA. Specifically, a semidefinite programming (SDP) method is proposed to transform the MLE problem into a convex optimization problem. To improve the performance further, we develop an iterative method that uses the position and velocity estimates obtained using the SDP method as the initial values. This iterative method includes two steps: update of the velocity by using a weighted least squares method and update of the position by using SDP. The major advantage of the proposed scheme is that it significantly outperforms existing methods at moderate to high noise levels, which is validated via extensive numerical results."
  },
  {
    "year": "2017",
    "abstract": "With the integration of renewable energy resources and variable loads into power grid, power oscillations caused by persistent external fluctuating forces are becoming more prevalent. Termed as “forced oscillations (FO)”, such phenomena could happen even when the grid is with good damping characteristics. Therefore, conventional mitigation methods based on improving damping are rendered less effective. By leveraging the new control capability offered by static synchronous compensator with energy storage (E-STATCOM), a novel approach to mitigate FOs is proposed in this paper. A control strategy based on resonant controllers is adopted to modulate active and reactive power supplied by E-STATCOM. It is theoretically shown that FOs propagating from the disturbed area to other areas can be effectively eliminated by this method. Besides, we derived the analytical relationship among the location, the capacity of E-STATCOM and the suppression performance. Case studies demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose a hybrid modeling method for analyzing the electromagnetic compatibility characteristics of printed circuit boards (PCBs). The method uses an equivalent magnetic dipole array deduced from near-field scanning results obtained at a certain height over the PCB surface under test and the finite-difference time domain (FDTD) algorithm. The array of dipoles can simulate the PCB electromagnetic emissions, including the ground plane effect at a particular high frequency; the equivalent dipole array can then be imported into the FDTD calculation space for calculating the electromagnetic fields generated by the dipole array. In our experiment, we obtained the tangential magnetic field distribution of the PCB surface using near-field scanning, from where the tangential magnetic field component, orientation, and the magnitude and phase of the dipoles could be deduced. We used the proposed method to model two different modules on a highly integrated circuit. The results of the proposed method and those obtained by near-field scanning are nearly the same, which demonstrates the effectiveness and accuracy of the proposed method. We therefore conclude that the proposed modeling approach presents a new technique for studying the electromagnetic interference of PCBs."
  },
  {
    "year": "2017",
    "abstract": "Time-domain passivity control (TDPC) is a widely used reliable approach to ensure the stability of the teleoperation systems. Although TDPC almost guarantees the stability of the system, there can be a possibility of instability as TDPC inherits the zero division problem in its conventional control laws. Low value force or velocity signals can lead to zero division in control laws and can be a reason of control failure. A multilateral teleoperation system is much more complex as compared to a bilateral teleoperation system. A multilateral teleoperation system comprises of multiple humans and multiple master and slave robots which results in increased transmission of signals over a communication network. So, it is substantially invaluable for multilateral teleoperation system to have a control scheme which ensures a safe and stable operation. This paper, an extension of our previous work, presents a novel design of TDPC laws for multilateral teleoperation, which not only maintains the passivity of the system for stability but also avoids zero division, thus guaranteeing a stable operation. A new architecture of communication channel is introduced to assign different weights to the masters and slaves depending upon the task requirements. The control strategy proposed in this paper is valid for different numbers of masters and slaves. Simulation and experimental results are presented to demonstrate the efficacy of the control design."
  },
  {
    "year": "2017",
    "abstract": "This paper explores a novel idea for power equipment monitoring and finds that random matrix theory is suitable for modeling the massive data sets in this situation. Big data analytics are mined from those data. We extract the statistical correlation between key states and those parameters. In particular, the (empirical) eigenvalue spectrum distribution and the (theoretical) single ring law are derived from large-dimensional random matrices whose entries are modeled as time series. The radii of the single ring law are used as statistical analytics to characterize the measured data. The evaluation of key state and anomaly detection are accomplished through the comparison of those statistical analytics."
  },
  {
    "year": "2017",
    "abstract": "3-D object recognition is a challenging task for many applications including autonomous robot navigation and scene understanding. Accurate recognition relies on the selection/learning of discriminative features that are in turn used to uniquely characterize the objects. This paper proposes a novel evolutionary feature learning (EFL) technique for 3-D object recognition. The proposed novel automatic feature learning approach can operate directly on 3-D raw data, alleviating the need for data pre-processing, human expertise and/or defining a large set of parameters. EFL offers smart search strategy to learn the best features in a huge feature space to achieve superior recognition performance. The proposed technique has been extensively evaluated for the task of 3-D object recognition on four popular data sets including Washington RGB-D (low resolution 3-D Video), CIN 2D3D, Willow 2D3D and ETH-80 object data set. Reported experimental results and evaluation against existing state-of-the-art methods (e.g., unsupervised dictionary learning and deep networks) show that the proposed EFL consistently achieves superior performance on all these data sets."
  },
  {
    "year": "2017",
    "abstract": "A compact, high performance, and novel-shaped ultra-wideband (UWB) multiple-input multiple-output (MIMO) antenna with low mutual coupling is presented in this paper. The proposed antenna consists of two radiating elements with shared ground plane having an area of 50 x 30 mm2. F-shaped stubs are introduced in the shared ground plane of the proposed antenna to produce high isolation between the MIMO antenna elements. The designed MIMO antenna has very low mutual coupling of (S21<; -20 dB), low envelop correlation coefficient (ECC <; 0.04), high diversity gain (DG > 7.4 dB), high multiplexing efficiency (ηMux> -3.5), and high peak gain over the entire UWB frequencies. The antenna performance is studied in terms of S-Parameters, radiation properties, peak gain, diversity gain, envelop correlation coefficient, and multiplexing efficiency. A good agreement between the simulated and measured results is observed."
  },
  {
    "year": "2017",
    "abstract": "A modern production plant may consist of several parallel-running batch processes, and the monitoring of such processes is imperative. This paper proposes a multiset canonical correlation analysis (MCCA)-based joint-individual monitoring scheme for parallel-running batch processes, which considers the individual feature of each batch process and the joint features shared by all batch processes. First, fourway batch process data are unfolded into two-way time-slice data. Second, MCCA is performed at each time instant to extract joint features throughout all running batch processes. Then, for each batch process, the measurements are projected onto a joint feature subspace and its orthogonal complement subspace that contains the individual features of the batch process. Finally, monitoring statistics are constructed to examine the joint and individual features. The proposed monitoring scheme is applied on a numerical example and the simulated parallel-running batch-fed penicillin fermentation processes. Monitoring results show the efficiency of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Online product reviews sentiment classification plays an important role on service recommendation, yet most of current researches on it only focus on single-modal information ignoring the complementary information, that results in unsatisfied accuracy of sentiment classification. This paper proposes a cross-modal hypergraph model to capture textual information and sentimental information simultaneously for sentiment classification of reviews. Furthermore, a mixture model by coupling the latent Dirichlet allocation topic model with the proposed cross-modal hypergraph is designed to mitigate the ambiguity of some specific words, which may express opposite polarity in different contexts. Experiments are carried out on four-domain data sets (books, DVD, electronics, and kitchen) to evaluate the proposed approaches by comparison with lexicon-based method, Naïve Bayes, maximum entropy, and support vector machine. Results demonstrate that our schemes outperform the baseline methods in sentiment classification accuracy."
  },
  {
    "year": "2017",
    "abstract": "Symbol boundary alignment, with respect to waveform selection, has an important impact on the numerology design for fifth-generation mobile applications. The current symbol boundary alignment, along with orthogonal frequency division multiplexing (OFDM) waveform, strongly suffers from intercarrier interference (ICI) especially in unmanned aerial vehicles (UAV) communications. This happens when the mobility causes Doppler effect which results in loss of orthogonality in OFDM. The available solutions for overcoming the ICI problem suffer from high complexity, low spectral efficiency, and incompatibility with the current radio access technologies. This paper presents a novel symbol boundary alignment, called Low ICI Symbol (LICIS) boundary alignment numerology, to avoid the disadvantages of the available solutions. LICIS utilizes large subcarrier-spacing to reduce the ICI power (e.g., around 5-dB ICI power reduction with subcarrier spacing of 30 kHz in high-speed UAV communications). Moreover, LICIS is based on the same reference clock as local thermal equilibrium (LTE) which guarantees its compatibility with the current LTE numerology. In addition, this approach places only one guard-interval at the end of a sequence of OFDM symbols and creates a subslot. This leads to less overhead and preserves the spectral efficiency. Furthermore, a pre-fast Fourier transform (FFT) multipath channel equalizer is considered for removing the intersymbol interference between the OFDM symbols occurring within the subslot. Only one additional FFT and IFFT operations are required for the equalizer which creates an acceptable complexity increment compared to the complexity of other available solutions. Numerical and analytical evaluations show the superior performance of the proposed technique in terms of reliability and spectral efficiency"
  },
  {
    "year": "2017",
    "abstract": "Cognitive radio and non-orthogonal multiple access are promising for alleviating the severe spectral scarcity problem encountered by the next generation wireless communication systems. In this paper, in order to improve energy efficiency and spectral efficiency, a non-orthogonal multiple access cognitive radio network with simultaneous wireless information and power transfer is studied under a practical non-linear energy harvesting model. A multi-objective resource optimization problem is formulated for maximizing the harvesting power of each energy harvesting receiver. This problem is non-convex and challenging to solve. A weighted Tchebycheff method is applied to solve the formulated problem. It is shown that the performance achieved under the non-linear energy harvesting model is better than that obtained under the linear energy harvesting model."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel approach to broaden the 3-dB gain bandwidth of Fabry-Perot cavity (FPC) antennas by utilizing a shaped ground plane. The shaped ground plane is flat in the middle to accommodate the source antenna, and then angled up in the shape of trapezoids. Compared with an FPC antenna with a traditional flat ground plane, the 3-dB gain bandwidth of the one with a shaped ground plane is improved from 11% to 20.2% with the maximum realized gain and the 10-dB impedance bandwidth almost unchanged. To validate the feasibility of the proposed approach, an FPC antenna prototype has been designed, fabricated, and measured. It consists of a U-slot rectangular microstrip patch antenna as the source, a Rogers RT6006 superstrate as the partially reflective surface, and the proposed shaped ground plane. Measured results on input reflection coefficients and radiation patterns agree well with simulated ones. Therefore, this new approach can be an effective way to enhance the gain bandwidth without increasing the cavity profile or using multi-layer superstrate structures."
  },
  {
    "year": "2017",
    "abstract": "The beam pattern of the virtual node antenna array (VNAA) in wireless sensor networks has a high maximum sidelobe level (SLL), thereby causing communication interference because of the uncontrollable node positions. A sidelobe and energy optimization array node selection (SEOANS) algorithm is proposed for optimally selecting the sensor nodes to form a VNAA that optimizes the beam pattern of VNAA and reduces the average energy consumption of nodes. SEOANS uses a calculation method to determine the optimal number of array nodes, proposes a node location selection optimization method based on concentric circular ring array and a novel swarm intelligence optimization algorithm called cuckoo search chicken swarm optimization (CSCSO) to optimize the excitation current of each array node. CSCSO uses chaos theory, introduces the inertia weight Lévy flight, and adopts the grade mechanism in chicken swarm optimization to improve the performance of the cuckoo search algorithm. In addition, the scheduling and fault tolerance mechanisms are designed and implemented in SEOANS. Simulation results show that the node position selection optimization method and the excitation current optimization based on CSCSO can effectively reduce the maximum SLL. Furthermore, compared with traditional clustering routing algorithms, SEOANS has advantages in the communication delay and average energy consumption of nodes, thus effectively improving network lifetime."
  },
  {
    "year": "2017",
    "abstract": "Blockchain technology has been known as the underlying technology of cryptocurrencies, but nowadays it is further considered as a functional technology for improving existing technologies and creating new applications previously never practical. In this paper, we are focused on utilizing blockchain technology to introduce a new ID as a service (IDaaS) for digital identity management. The proposed blockchain-based ID as a service (BIDaaS) is explained with one practical example that shows how the proposed BIDaaS works as an identity and authentication management infrastructure for mobile users of a mobile telecommunication company."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel nonlinear control approach for a medium density fiberboard continuous hot pressing hydraulic system. Uncertainties, disturbances, and input saturation are explicitly taken into account. The proposed controller incorporates a smooth function by using a hyperbolic tangent function to substitute for the saturation nonlinearity in the system. Moreover, a novel backstepping-like slab thickness tracking controller is developed for a third-order cascade system within two steps. Taking advantages of radial basis function neural network (RBFNN) technique, a RBFNN-based reconstruction law is introduced to approximate the composite term consisting unknown function, disturbances, and saturation error. Lyapunov stability analysis shows that the designed control algorithm guarantees the asymptotic stability of the system with great robustness. Numerical simulation results are also exhibited to authenticate and validate the benefits of the proposed control scheme."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the energy-efficient resource allocation in two-tier massive multiple-input multiple-output (mMIMO) heterogeneous networks with wireless backhaul. Millimeter wave frequency is adopted at the mMIMO macro base station (MBS), and the cellular frequency is considered at small cell BS with orthogonal frequency-division multiple access. To lower the hardware cost and energy consumption at the MBS, two hybrid analog/digital precoding schemes are proposed according to the connectivity, i.e., fully connected and subarray structures. In order to design the small cell cluster-based power and subchannel allocation, we aim to maximize the energy efficiency of the system with limited wireless backhaul and users' quality of service constraints. The formulated problem is non-convex mixed integer nonlinear fraction programming, which is non-trivial to solve directly. By exploiting fractional programming, we propose a two-loop iterative resource allocation algorithm to solve the nonconvex problem. Specifically, integer relaxation and a Dinkelback method are considered to transform the outer loop problem into a difference of convex programming (DCP). Following this, the first-order Taylor approximation is considered to linearize this inner loop DCP problem into a convex optimization framework. Lagrange dual problem is considered to obtain the closed-form power allocation. Furthermore, we prove the convergence of the proposed iterative algorithm. Numerical results are provided to validate our proposed schemes."
  },
  {
    "year": "2017",
    "abstract": "The stochastic and intermittent nature of renewable energy resources (RERs) poses great challenges to the energy scheduling of microgrids. The hybrid energy storage system (HESS), such as a combination of the battery (BA) and ultracapacitor, is considered as an effective way to cope with such challenges. In this paper, a hierarchical energy scheduling framework is proposed for the microgrid with HESSs to optimize the operation under the uncertainty of RERs and loads. The framework consists of two stages of scheduling: hour-ahead scheduling and real-time scheduling. In hour-ahead scheduling, a deterministic optimization model is formulated to minimize the operation cost of microgrids, and to guarantee the operation safety. Subsequently, a decomposition-based method is presented to solve the proposed model. In real-time scheduling, a control strategy of HESSs is developed to accommodate the imbalanced power mainly due to the uncertainty of RERs and loads, while extending the lifetime of BAs. The methodology is tested on a seven-bus microgrid system. Simulation results validate the effectiveness of the formulated model and the developed strategy."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, online product reviews play a crucial role in the purchase decision of consumers. A high proportion of positive reviews will bring substantial sales growth, while negative reviews will cause sales loss. Driven by the immense financial profits, many spammers try to promote their products or demote their competitors' products by posting fake and biased online reviews. By registering a number of accounts or releasing tasks in crowdsourcing platforms, many individual spammers could be organized as spammer groups to manipulate the product reviews together and can be more damaging. Existing works on spammer group detection extract spammer group candidates from review data and identify the real spammer groups using unsupervised spamicity ranking methods. Actually, according to the previous research, labeling a small number of spammer groups is easier than one assumes, however, few methods try to make good use of these important labeled data. In this paper, we propose a partially supervised learning model (PSGD) to detect spammer groups. By labeling some spammer groups as positive instances, PSGD applies positive unlabeled learning (PU-Learning) to study a classifier as spammer group detector from positive instances (labeled spammer groups) and unlabeled instances (unlabeled groups). Specifically, we extract reliable negative set in terms of the positive instances and the distinctive features. By combining the positive instances, extracted negative instances and unlabeled instances, we convert the PU-Learning problem into the well-known semisupervised learning problem, and then use a Naive Bayesian model and an EM algorithm to train a classifier for spammer group detection. Experiments on real-life Amazon.cn data set show that the proposed PSGD is effective and outperforms the state-of-the-art spammer group detection methods."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we proposed an upper-limb post-stroke rehabilitation system integrating a motion tracking device (MTD), a portable electroencephalogram (EEG) device for an attentional feedback, and interactive virtual reality (VR) game with the goal to assist patients in upper-limb rehabilitation. Fifteen post-stroke patients were recruited and randomly assigned to a control group (A) or one of two experimental groups (B and C). Group B played the game using a MTD and group C played it using a MTD and brain- computer-interface-based attention-monitoring EEG device. In group C, patients' attention was measured in real time using the EEG while the patients performed tasks; visual and auditory stimuli were emitted when their attention lowered. The primary outcome was a change in score on the upper extremity section of the Fugl-Meyer assessment, which was used to evaluate the severity of motor impairment and indicate any improvement of motor function. Improvement in motor function, associated with game performance, was found in group C. Based on their performance quality during 12 training sessions, the higher performance of group C patients in the VR game was significantly correlated with attention level and motor performance. Higher attention level is associated with higher game performance after 12 training sessions, and our MTD-EEG-VR training system may facilitate the improvement of motor function and assist patients in upper-limb rehabilitation. Our MTD-EEG-VR game with the attentional EEG-feedback device is a potential intervention for improving motor function in patients with stroke."
  },
  {
    "year": "2017",
    "abstract": "With the rapid innovations in the design of transceiver for full duplex (FD) communications, the benefits of FD for single-hop wireless communications have been widely shown. But in a multi-hop wireless network, the benefits of FD with power control still need to disclose. The goal of this paper is to investigate the energy efficiency (EE) performance of FD scheduling in a multi-hop wireless network. In this paper, we explore FD on EE in multi-hop networks under optimal scheduling through strict mathematical model, formulation and proof. First, an EE model under FD scheduling with power control in multi-hop wireless networks is constructed. Then, through exploiting the reformulation linearization technique to reformulate and piece-wise linearization method to approximate, the nonlinear optimization problem for EE under FD is transformed into a linear one and solved with performance guarantee. Finally, simulation results validate the proposed optimization method to achieve the optimal EE under FD with power control compared to half duplex with power control and FD without power control."
  },
  {
    "year": "2017",
    "abstract": "Pulmonary valve diseases in children and adults include different degrees of stenosis, regurgitation, or congenital defects. Valve repair or replacement surgery is used to treat valvular dysfunction and to improve regurgitations flow for pulmonary valve pathologies. Handmade trileaflet valve designs with different ranges of diameters have been used for pulmonary valved conduit reconstruction among children or adult patients with available conditions. In this paper, we propose a multiple regression model as a cascadecorrelation-network-based estimator to determine optimal trileaflet parameters, including width, length, and upper/lower curved structures, for trileaflet valve reconstruction. The diameter of the main pulmonary artery is determined via computed tomography pulmonary angiography, and a trileaflet valve template is rapidly sketched. The actual valve is constructed using an expanded polytetrafluoroethylene material. Using an experimental pulmonary circulation loop system, design parameters and valve efficacy can be validated by the Taguchi method through calculation of signal-to-noise ratios. Experimental results indicate that in contrast to commercial valve stents, the handmade trileaflet valve exhibits good performance and is a valuable option in treatment of severe pulmonary regurgitation."
  },
  {
    "year": "2017",
    "abstract": "Localization of linear frequency modulation (LFM) source based on combination of time- frequency analysis and a spatial spectrum estimation technique has received extensive research. However, this scheme is always confined to far-field sources and suffers from high computational cost. In this paper, by performing the fractional Fourier transform to multiple incoherent LFM signals, a fast and closed-form algorithm based on phase difference is proposed for 3-D source localization under a uniform circular array. First, the phase relationship among sensors' maximum outputs in fractional Fourier domain is exploited to construct indefinite equations, and then the least square method is employed to estimate the source's azimuth angle, elevation angle, and range simultaneously. Finally, comparing with current approaches, the satisfactory performance of our proposed algorithm is demonstrated, and the effectiveness for dealing with mixed far-field and near-field sources is also confirmed."
  },
  {
    "year": "2017",
    "abstract": "Network is an abstract expression of subjects and the relationships among them in the realworld system. Research on community detection can help people understand complex systems and identify network functionality. In this paper, we present a novel approach to community detection that utilizes a nonnegative matrix factorization (NMF) model to divide overlapping community from networks. The study is based on the different physical meanings of the pair of matrices W and H to optimize the constraint condition. Many community detection algorithms based on NMF require the number of known communities as a prior condition, which limits the field of application of the algorithms. This paper handled the problem by feature matrix preprocessing and ranking optimization, so that the proposed algorithm can divide the network structure with unknown community number. Experiments demonstrated that the proposed algorithm can effectively divide the community structure, and identify network overlay communities and overlapping nodes."
  },
  {
    "year": "2017",
    "abstract": "Virtualization enabled by container-based technologies is a recently emerging concept in the integration of Internet of Things (IoT) and cloud computing. Due of their lightweight nature, container-based virtualization tools improve manageability of cloud-based IoT solutions by making it possible to update application software on the fly. Although different studies have demonstrated the feasibility of efficiently running container-based virtualization on low-power IoT nodes, the implication of doing so on battery-powered nodes has been overlooked. In this paper, we investigate how much energy overhead is generated by Docker-based virtualization on battery powered camera sensor nodes. In our scenario, camera nodes are most of the time in “power off”state to save energy. They are switched on for streaming video only when activity is detected by motion sensor nodes. By means of empirical measurement and subsequent analysis, we found that starting and closing of containers in the Docker platform adds-up roughly 13 percent power consumption overhead during the boot-up and shutdown of the camera nodes. Furthermore, the fixed overhead occurring from boot-up and shutdown procedures become negligible with longer video stream sessions."
  },
  {
    "year": "2017",
    "abstract": "A randomized fingerprint model is proposed, which can effectively reduce the false positive rate by generating a unique fingerprint for each URL. The model is also used to improve the Wu and Manber (WM) algorithm, which is a multi-string matching algorithm; as a result, a randomized fingerprint WM (RFP-WM) algorithm is proposed. Furthermore, a Graphics Processing Unit (GPU)-based parallel randomized fingerprint algorithm (GRFP-WM) is implemented. Experimental results indicate that, for a massive pattern set containing more than a million URLs, the efficiency of the RFP-WM algorithm is 20% higher than that of the WM algorithm. The WM algorithm’s efficiency is approximately 7% higher than that of the Aho and Corasick (AC) algorithm, which is also a multi-string matching algorithm. The efficiency and speedup of the GRFP-WM algorithm are higher than those of the GPU-based WM and the GPU-based AC algorithms. These results indicate that the randomized fingerprint model can effectively reduce the collision rate and improve the efficiency of the algorithm."
  },
  {
    "year": "2017",
    "abstract": "Mobile edge computing (MEC) that affords service to the vicinity of mobile devices (MDs) has become a key technology for future network. Offloading big data to the MEC server for preprocessing is an attractive approach of MDs. In this paper, we investigate data offloading from MDs to MEC servers, and a coalitional game-based pricing scheme is proposed. We apply coalitions to arrange data offloading of MDs as well as depict the offloading relationship between MDs and MEC servers. Furthermore, pricing is utilized as the stimuli for the offloading. In the proposed scheme, a scheduled MD in a coalition chooses an MEC server within the same coalition for offloading, and pays the selected MEC server for the MEC service. By analyzing the formulated coalitional non-transferable utility game, theoretical properties are derived and sufficient conditions for the core existence are given. Finally, the utility performances of the proposed scheme are demonstrated by numerical results."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an effective yet simple video representation for RGB-D-based action recognition. It proposes to represent a depth map sequence into three pairs of structured dynamic images (DIs) at body, part, and joint levels, respectively, through hierarchical bidirectional rank pooling. Different from previous works that applied one convolutional neural network (ConvNet) for each part/joint separately, one pair of structured DIs is constructed from depth maps at each granularity level and serves as the input of a ConvNet. The structured DI not only preserves the spatial-temporal information but also enhances the structure information across both body parts/joints and different temporal scales. In additionally, it requires low computational cost and memory to construct. This new representation, referred to as Spatially and Temporally Structured Dynamic Depth Images, aggregates from global to fine-grained levels motion and structure information in a depth sequence, and enables us to fine-tune the existing ConvNet models trained on image data for classification of depth sequences, without a need for training the models afresh. The proposed representation is evaluated on six benchmark data sets, namely, MSRAction3D, G3D, MSRDailyActivity3D, SYSU 3D HOI, UTD-MHAD, and M2I data sets and achieves the state-of-the-art results on all six data sets."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a novel location-based multi-group multicast framework, which is termed non-orthogonal multiple access (NOMA)-assisted multi-region geocast. This novel spectrum sharing framework exploits the NOMA technology to realize the simultaneous delivery of different messages to different user groups characterized by different geographical locations. The essence of the proposed framework is that the geographical information of user groups unites NOMA and multi-group multicast to enhance the spectral efficiency (SE) and the energy efficiency (EE) of wireless transmissions. Specifically, we investigate the downlink beamforming design of the proposed framework in multiple-input single-output settings. The decoding strategy for NOMA is designed and guaranteed by users' geographical information and required quality of service. The majorization and minimization algorithm is exploited to solve the non-convex and intractable problems therein. Comprehensive numerical experiments are further provided to show that NOMA holds tremendous promise but also limitations in terms of SE and EE, compared with spatial division multiple access and orthogonal multiple access."
  },
  {
    "year": "2017",
    "abstract": "Iris recognition refers to the automated process of recognizing individuals based on their iris patterns. The seemingly stochastic nature of the iris stroma makes it a distinctive cue for biometric recognition. The textural nuances of an individual's iris pattern can be effectively extracted and encoded by projecting them onto Gabor wavelets and transforming the ensuing phasor response into a binary code - a technique pioneered by Daugman. This textural descriptor has been observed to be a robust feature descriptor with very low false match rates and low computational complexity. However, recent advancements in deep learning and computer vision indicate that generic descriptors extracted using convolutional neural networks (CNNs) are able to represent complex image characteristics. Given the superior performance of CNNs on the ImageNet large scale visual recognition challenge and a large number of other computer vision tasks, in this paper, we explore the performance of state-of-the-art pre-trained CNNs on iris recognition. We show that the off-the-shelf CNN features, while originally trained for classifying generic objects, are also extremely good at representing iris images, effectively extracting discriminative visual features and achieving promising recognition results on two iris datasets: ND-CrossSensor-2013 and CASIA-IrisThousand. We also discuss the challenges and future research directions in leveraging deep learning methods for the problem of iris recognition."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a systematic synthesis approach is proposed for achieving negative group delay responses using lossy coupling matrix. It is mathematically proved that, for a passive and reciprocal network, loss is the necessary condition to realize a negative group delay. Also, the optimum strategy is to place zeros and poles of the transfer function on the left complex plane. A closed-form relation between the group delay and magnitude is then derived based on this strategy, and followed by a complete synthesis approach using coupling matrix. Two numerical and one experimental examples are finally given to illustrate the proposed synthesis method."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the problem of trajectory tracking control of a surface vessel subject to parametric uncertainties, external disturbances, and thruster faults. A novel robust fault-tolerant tracking controller is developed by incorporating the radial basis function neural network and an adaptive control technique into the sliding mode control. It is shown that the designed controller is not only robust against environmental disturbances induced by waves and ocean currents, but also able to ensure that the surface vessel tracks the desired trajectory, without resorting to any knowledge of inertia parameters and despite the presence of thruster faults. In particular, exploiting a novel time-varying sliding mode manifold, the tracking errors are proved to converge to zero within a finite time, whose value can be pre-assigned by the designers according to the mission requirements. Numerical examples are carried out to testify the effectiveness of the proposed control algorithm."
  },
  {
    "year": "2017",
    "abstract": "Recently, telemedicine solutions have become a new trend in remote medical treatment. Many diseases are originated from abnormal variation of biological processes, especially in nucleosome positioning. Thus, effective prediction of nucleosome positioning becomes a hotspot in the research of telemedicine. In this paper, a novel method is provided to compare varies of sequences firstly. This method, which is called fractal entropy increment of diversity (FEID), is based on information entropy and increment of diversity. Then, a novel nucleosome positioning method is provided by using FEID into the data set of diversiform DNA sequences of human, worm, fly, and yeast. Moreover, experimental results show that FEID is an effective nucleosome positioning method by compared with other methods on several benchmark data sets. Finally, the most important nucleotide sequence in nucleosome positioning is provided based on calculated contribution rates of nucleotide sequences."
  },
  {
    "year": "2017",
    "abstract": "The design of good host overload/underload detection and virtual machine (VM) placement algorithms plays a vital role in assuring the smoothness of VM live migration. The presence of the dynamic environment that leads to a changing load on the VMs motivates us to propose a Markov prediction model to forecast the future load state of the host. We propose a host load detection algorithm to find the future overutilized/underutilized hosts state to avoid immediate VMs migration. Moreover, we propose a VM placement algorithm to determine the set of candidates hosts to receive the migrated VMs in a way to reduce their VM migrations in near future. We evaluate our proposed algorithms through CloudSim simulation on different types of PlanetLab real and random workloads. The experimental results show that our proposed algorithms have a significant reduction in terms of service-level agreement violation, the number of VM migrations, and other metrics than the other competitive algorithms."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider multipair two-way massive multiple-input and multiple-output (MIMO) communication system, in which multiple pairs of source nodes exchange messages with the help of one shared amplify-and-forward relay provisioned with large number of antennas. Unlike the perfect channel state information (CSI) assumption, the practical minimum mean-squared error-based channel estimation is considered. And the asymptotic signal to interference plus noise ratio (SINR) analysis of four power-scaling scenarios is presented to show that, even with the imperfect CSI, the interpair interference can still be eliminated, the small-scale fading as well as the noise at source nodes and the relay can be averaged out in the regime of very large number of antenna. It is unveiled that the impact of the channel estimation error will present in the effective large-scale fading coefficient, which explicates the degradation by the imperfect CSI estimate and consumes the results with perfect CSI as special cases. On the basis of the asymptotic SINR analysis results, the optimal power allocation problem is formulated to derive the energy efficient relaying scheme for the maximum ratio combining-maximum ratio transmission precoding scheme. Finally, numerical results are presented to validate that the energy efficient design can effectively reduce the power consumption while maintaining a reasonable sum rate in the multipair two-way massive MIMO relaying system, even in the presence of CSI error."
  },
  {
    "year": "2017",
    "abstract": "To effectively mitigate interference and improve the performance, we propose a grouping-based two-stage distributed interference alignment (GTDIA) scheme for a two-layered heterogeneous network (HetNet) in multi-user multiple-input-multiple-output (MIMO) Gaussian downlink transmission scenario. In this paper, we first extend the grouping-based interference alignment (GIA) scheme, which is suitable in single-layer multi-cell scenario to a two-layered HetNet. Then, in order to improve the system performance and reduce the computational complexity, we propose a new interference alignment (IA) scheme (i.e., GTDIA) by grouping pico users (PUEs) to align inter-layer interference (inter-layer IF) and design the receive beamforming matrices of PUEs. Since the macro users (MUEs) are located randomly under the coverage of macro base station, the inter-layer IF is between some pico base stations and MUEs. Specifically, two-stage (i.e., a composite of two cascade matrices) transmit beamforming matrices of base stations are designed to cancel both of the inter-layer and intra-layer interference among MUEs. Furthermore, because of the reciprocity of time-division duplex system, a distributed algorithm is used when designing the second stage transmit beamforming matrices. Analysis and simulation results demonstrate that the proposed scheme outperforms the extended GIA and other conventional IA schemes."
  },
  {
    "year": "2017",
    "abstract": "This paper studies the secure transmission issue for simultaneous wireless information and power transfer in a multiuser multiple-input-multiple-output system with multiple external eavesdroppers, where the transmitter broadcasts independent confidential messages to different legitimate receivers. Each receiver can be seen as an internal eavesdropper intended by other receivers. Our objective is to achieve the robust beamforming design under imperfect channel state information, in which the total transmission power is minimized with constraints on the achievable secrecy rate and the energy harvesting. Since the problem is nonconvex, we propose a two-level optimization scheme. For the inner problem, we investigate two conservative relaxation approaches, large-deviation inequality and Bernstein-type inequality (BTI), to reformulate the outage secrecy rate constraints into some convex ones, yielding a convex optimization by semidefinite programming (SDP) relaxation. For the outer problem, it is a K-variable optimization problem, which can be solved via the novel line-dimensional-like search method. Moreover, we characterize the rank profile of SDP relaxed solution for these two approaches. Specifically, the optimal solution is proved to be rank-one. Numerical results are provided to verify the performance of the proposed algorithms, where the LDI-based scheme outperforms the BTI-based scheme in terms of energy efficiency."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose robust waveform techniques for multistatic cognitive radars in a signal-dependent clutter environment. In cognitive radar design, certain second order statistics such as the covariance matrix of the clutter, are assumed to be known. However, exact knowledge of the clutter parameters is difficult to obtain in practical scenarios. Hence, we consider the case of waveform design in the presence of uncertainty on the knowledge of the clutter environment and propose both worst-case and probabilistic robust waveform design techniques. Initially, we tested our multistatic, signal-dependent model against existing worst-case and probabilistic methods. These methods appeared to be over conservative and generic for the considered scenario. We therefore derived a new approach where we assume uncertainty directly on the radar cross-section and Doppler parameters of the clutters. Accordingly, we propose a clutter-specific stochastic optimization that, by using Taylor series approximations, is able to determine robust waveforms with specific signal to interference and noise ratio outage constraints."
  },
  {
    "year": "2017",
    "abstract": "With the number of nonhuman devices expected to significantly overtake human users of long-term evolution networks, it is no surprise that First Responders in mission critical (MC) operations will need to interact with an increasing number of unmanned devices, “bots”or drones. In this paper, we propose the MC “bot”concept as an entity capable of gathering environmental/situational information and triggering certain automated actions without the need of human intervention. We prove that in certain circumstances these bots can help quickly resolve emergency situations and complement traditional centralized coordination from dispatch control rooms. We explain how such “bots”relate to and expand the 3GPP MC Communications architecture framework, considering different architectural approaches and complexity levels. Importantly, because First Responders must remain focused, hands free, and context aware most of the time, we cover specifically the case where man-machine interaction is based on voice communication without having to use hands or look at a screen. It is hence of particular interest to convert “bot”interactions into audio information exchanged over push-to-talk communication services, be it through the cellular network or leveraging the 3GPP device-to-device capability. This paper is complemented with theoretical use cases as well as description and multimedia material of a prototype implementation of a concept emulator."
  },
  {
    "year": "2017",
    "abstract": "Base station sleeping (BSS) can result in significant reduction in energy consumption of cellular networks during low traffic conditions. We show that the coverage loss due to BSS can be compensated via coordinated multi-point (CoMP) -based transmission in a cluster of base stations. For a BSS with CoMP-based system, we propose various BSS patterns to achieve suitable trade-offs between energy savings and throughput. We formulate the CoMP resource allocation and α-Fair user scheduling as a joint optimization problem. We derive the optimal time fraction and user scheduling for this problem and use it to formulate a simplified BSS with CoMP optimization problem. A heuristic that solves this problem is presented. Through extensive simulations, we show that suitable trade-offs among energy, coverage, and rate can be achieved by appropriately selecting the BSS pattern, CoMP cluster, and rate threshold."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a multi-objective, multi-level model is proposed for active distribution system expansion planning with high-penetration renewable energy sources (RESs) and energy storage systems (ESSs). To optimize the planning of RESs, ESSs, and distribution networks cooperatively, a three-level optimization method is adopted based on the leader–follower strategy of hierarchic optimizations. In this model, the upper level and the middle-level serve to model the planning problems from different perspectives of multi-stakeholders; the lower level serves to model the operation aspect of ESSs. The multi-level model enables us to integrate operation optimization into a planning model and achieve the collaborative optimization of them in different time-scales. The multi-scenario tools and K-means clustering are adopted to deal with the uncertainties and capture the time-variable nature of RESs and load demand. In order to balance the multiple objectives of costs reduction, reliability improvement, and RES penetration promotion, a modified Pareto-based particle swarm optimization is employed to solve the proposed optimization problem. Finally, results obtained by case studies are presented and discussed, where the availability and the effectiveness of the proposed planning model are verified."
  },
  {
    "year": "2017",
    "abstract": "We conceive and investigate the family of classical topological error correction codes (TECCs), which have the bits of a codeword arranged in a lattice structure. We then present the classical-to-quantum isomorphism to pave the way for constructing their quantum dual pairs, namely, the quantum TECCs (QTECCs). Finally, we characterize the performance of QTECCs in the face of the quantum depolarizing channel in terms of both the quantum-bit error rate (QBER) and fidelity. Specifically, from our simulation results, the threshold probability of the QBER curves for the color codes, rotated-surface codes, surface codes, and toric codes are given by1.8×10−2,1.3×10−2,6.3×10−2, and6.8×10−2, respectively. Furthermore, we also demonstrate that we can achieve the benefit of fidelity improvement at the minimum fidelity of 0.94, 0.97, and 0.99 by employing the 1/7-rate color code, the 1/9-rate rotated-surface code, and 1/13-rate surface code, respectively."
  },
  {
    "year": "2017",
    "abstract": "In recent years, role-based access control (RBAC) has become the de facto access control model due to its good applicability and high flexibility. Since the organizations need to update the access control policies to meet the changes in employees, departments, business processes, and so on. The RBAC system has to define new roles and becomes more and more bloated because it's difficult to modify the role-permission assignment with no or minimal impact to other users and roles. Hence, there is a great need to reconfigure the RBAC system over time to reduce its structural complexity and keep as close as possible to the original. Several RBAC reconfiguration approaches have been proposed aiming at generating roles similar to the deployed ones, but they neglect the differences in deployed roles that some of them are useless for the system and generate more roles than needed, which in turn increases the system structure complexity. In this paper, we first propose three indicators to evaluate the quality of deployed roles and define the problem of hierarchy RBAC reconfiguration with minimal weight structure complexity and perturbation. Then, the hierarchy RBAC reconfiguration approach and its algorithm process are proposed to address the problem. To conclude, we demonstrate the effectiveness and stability of our approach through experiments."
  },
  {
    "year": "2017",
    "abstract": "A tri-polarized 12-antenna array working in the 3.5-GHz band (3.4-3.6 GHz) for future 5G (the fifth generation mobile communication) multiple-input multiple-output (MIMO) operations in the smartphone is presented. In order to reduce the mutual couplings and simplify the design process, orthogonal polarization technique is utilized. By combining a quarter mode substrate integrated wave-guide antenna and two open-end slots, a compact 3-antenna tri-polarization block operating in the 3.5-GHz band is achieved within a small volume of 17 × 17 × 6 mm3. Thanks to the orthogonal polarization features, the three antennas within the block are able to have good impedance matchings and low mutual couplings between antennas. By integrating four such tri-polarization blocks, a 12-antenna MIMO array is then designed for smartphone applications. It is also due to the tri-polarization feature, the proposed array could attain acceptable isolations and low correlations between antennas with only two additional decoupling structures. The proposed array is fabricated and tested, good antenna performances, such as return loss better than 10 dB, isolation higher than 12.5 dB, and antenna efficiencies higher than 50%, are obtained. The channel capacity of the 12-antenna array is calculated to be about 57 bps/Hz in a 12 × 12 MIMO system with 20-dB signal-to-noise ratio, which indicates the proposed array using tri-polarization technique is a good choice for future 5G terminals."
  },
  {
    "year": "2017",
    "abstract": "The problem of resource provisioning and content placement in cloud-based content delivery networks is studied, and a two-stage resource provisioning and cloud assignment is proposed based on dynamic large and small-scale fluctuations of user demand rates as well as considering a constrained minimum lease time for resources. In the first stage, we perform resource provisioning while costs of resources, quality of service (QoS) violation, and cloud-based root server redirection are included in the optimization, and constraints of QoS and limited resource of cloud sites are taken into account. In the second stage, cloud site assignment is conducted where for fixed allocated resources, QoS violation and cloud-based root server redirection costs are minimized or reduced using three different proposed schemes. We further show that reassignment of cloud sites during rising demand rates within a lease time period improves revenue, while reassignment is not very effective for falling demand rates."
  },
  {
    "year": "2017",
    "abstract": "Voltage rise beyond statuary limits in low voltage (LV) ac networks due to high photovoltaic (PV) penetration and its mitigation using multiple techniques was assessed. Investigations using a real rural domestic overhead LV network were done through load flow simulations. A three-phase four wire medium length LV network with a fixed tap transformer and PV inverters operating at unity power factor was able to host PV between 79%-98% of transformer ratings for five different PV configurations. For the case studied at this penetration level three, limiting factors (voltage, thermal loading limits of lines, and transformer) come together. Three techniques were utilized to control the voltage across the LV network. On load tap changer (OLTC) control was found more robust than reactive power control (RPC). Hybrid control (OLTC and RPC) was found beneficial only for extra high PV penetration scenarios. Replacement of a few critical line spans and the existing transformer with higher capacity conductors and an OLTC equipped transformer (higher size) enabled the network to host an additional 50%-90% PV. The unequal distribution of single-phase PV systems among three phases has negative effects on penetration. Consideration of PV integration while planning new LV networks and retrofitting of OLTCs with existing transformers, could make the LV system more PV friendly. The RPC option, though less effective than OLTC due to increased current, can be beneficial at medium penetrations where OLTC may become a costly solution."
  },
  {
    "year": "2017",
    "abstract": "Perceptual stereo image quality assessment (SIQA) aims to design computational models to measure the stereo image quality in accordance with human opinions. In this paper, a novel reduced-reference (RR) SIQA is proposed by characterizing the statistical and perceptual properties of the stereo image in both the spatial and gradient domains. To be specific, in the spatial domain, we extract the parameters of the generalized Gaussian distribution fits of luminance wavelet coefficients to form the underlying features. In the gradient domain, the modified gradient magnitudes maps are generated by jointly considering human visual system's contrast sensitivity and neighborhood gradient information to weight the gradient magnitudes in a locally adaptive manner. Afterward, perceptual features are extracted based on the entropy of discrete wavelet transform coefficients of modified gradient magnitudes. Furthermore, we consolidate the left and right features into a single set of features per stereo image pair. Finally, the qualities of both the spatial and gradient domains are combined to obtain the overall quality of stereo image. Extensive experiments performed on popular data sets demonstrate that the proposed RR-SIQA method achieves highly competitive performance as compared with the state-of-the-art RR-SIQA models as well as full-reference ones for both symmetric and asymmetric distortions."
  },
  {
    "year": "2017",
    "abstract": "It is a significant challenge for telecommunication network operators to immediately restore communication services in the disaster area. To quickly recover telecommunication services in the affected area, this paper proposes a wired and wireless network cooperation system. When the wired communication for leaf nodes of optical tree networks is disrupted, surviving leaf nodes relay packets to and from these nodes via wireless bypass routes. The advantages of the proposed method are promptness and high-throughput, which is achieved with single-hop wireless bypass routes backhauled by wired networks. The optimal routes for wireless links are calculated to maximize the expected throughput by solving a binary integer programming problem. The proposed system is cost effective, because it can be deployed with minimum additional functions for leaf nodes of optical networks. To overcome the limitation of the proposed approach that the distribution of leaf nodes is determined by the demand distribution, additional recovery nodes can be deployed to improve the expected throughput. The numerical simulations including a medium access control level simulation conducting carrier sense multiple access with collision avoidance behavior showed that the proposed method can achieve a higher throughput than an existing bypass routing method, irrespective of the topology of the wired networks."
  },
  {
    "year": "2017",
    "abstract": "Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading."
  },
  {
    "year": "2017",
    "abstract": "To achieve more precise positioning of the electronic throttle plate, a nonlinear backstepping tracking control strategy is presented in this paper. In contrast to the existing control schemes for electronic throttles, the input saturation and unknown external disturbances are explicitly considered in the tracking control design. The difficulties in controlling an electronic throttle include the strong nonlinearity of the spring and friction as well as the unknown external disturbance. In particular, the valve plate angle is adjusted by the control input voltage of the driving motor, and the input voltage is limited to a certain range. Therefore, input saturation problems exist in the control system for an electronic throttle. To overcome the abovementioned difficulties, an auxiliary design system is presented to handle the input saturation, and its state is applied in the proposed control design. A sliding-mode control term is also utilized in the tracking controller to counteract the unknown external disturbance. The proof and analysis show that the satisfactory tracking performance of the valve plate angle can be achieved by using the designed control scheme for the electronic throttle system in the presence of input saturation and unknown external disturbances. Simulation studies and results are provided to illustrate the desired performance of the proposed nonlinear tracking controller."
  },
  {
    "year": "2017",
    "abstract": "Influence maximization is to extract a small gathering of influential people from a network in order to obtain the largest influence spread. As a key issue in viral marketing, this problem has been extensively studied in the literature. However, despite a great deal of work that has been done, the traditional influence maximization model cannot fully capture the characteristics of real-world networks, since it usually assumes that the cost of activating each individual among the seed set is the same and ignores the cost differences of activating them. In fact, if a company plans to market its products or ideas, it always provides the reward for each disseminator of the seed group according to his or her degree of influence spread. All companies expect to obtain the maximum influence with minimum cost, or acceptable cost, for them. Motivated by this observation, we propose a new model, called influence maximization-cost minimization (IM-CM), which can capture the characteristics of real-world networks better. To solve this new model, we propose a multiobjective discrete particle swarm optimization algorithm for IM-CM. The algorithm can take both individual cost and individual influence into consideration. Besides, the results of this algorithm can also provide a variety of choices for decision makers to choose on the basis of their budgets. Finally, experiments on three real-world networks demonstrate that our algorithm has excellent effectiveness and efficiency."
  },
  {
    "year": "2017",
    "abstract": "The distributed coordination function (DCF) is the core of the IEEE 802.11 standard and is applied routinely to contention-based vehicular networks. Many existing backoff algorithms based on DCF are applied to develop the performance of wireless networks and most of them work in saturated traffic load conditions, which are unlikely to be valid in practical wireless network. The study of the backoff algorithm under unsaturated traffic load conditions is still an open issue. In this paper, a dynamic adaptive success-collision (DASC) backoff algorithm is proposed to improve the performance of contentionbased vehicular network. As we know that the probability of collision reflects system performance, and the probability of collision is restricted by the variation of contention window (CW) size and it depends on the traffic loads. A threshold is defined to judge the low or high traffic loads. In addition, the DASC backoff algorithm takes proactive measures to optimize throughput and delay through decreasing CW after “S”times consecutive successful transmissions and increasing CW after “C”times consecutive collisions. The simulation results indicate that the proposed DASC backoff algorithm provides better performance in terms of throughput and delay than dynamic control backoff time algorithm, exponential linear backoff algorithm, and binary exponential backoff algorithm."
  },
  {
    "year": "2017",
    "abstract": "Prefixes, in forms of cyclic-prefixes or zero-padding, have often been viewed as indispensable in underwater acoustic single-carrier transmissions to avoid inter-block interference (IBI) and to formulate circular convolution. However, the prefix introduces overhead and reduces spectral efficiency. This is especially true in fast time-varying channel conditions. Here, we propose a prefix-free scheme to facilitate frequency-domain equalization (FDE) in an underwater acoustic communication system, based on the time-reversal processing. In the proposed scheme, three main procedures, block partitioning, IBI cancellation, and prefix reconstruction, precede the FDE operation. The block partitioning at the receiver provides flexibility to support channel equalization in different channel fluctuation rates. The utilized prefix reconstruction scheme requires a strong first arrival to minimize the noise enhancement. Our solution is to use the time-reversal processing, because the resultant equivalent impulse response, also known as the q-function, has a stable and compact peak. To further enhance receiver performance, we incorporate two strategies. One is overlapping partitioning. The other is iterative prefix reconstruction. The proposed schemes have been tested using the field measurements obtained from the Gulf of Mexico in August 2016. Communications over four ranges at the carrier frequency of 85 kHz with a symbol rate of 17 kHz have been demonstrated. The overlapping partitioning and iterative prefix reconstruction strategies have been shown to generate improvements in the receiver performance."
  },
  {
    "year": "2017",
    "abstract": "Facial expression recognition (FER) is a significant task for the machines to understand the emotional changes in human beings. However, accurate hand-crafted features that are highly related to changes in expression are difficult to extract because of the influences of individual difference and variations in emotional intensity. Therefore, features that can accurately describe the changes in facial expressions are urgently required. Method: A weighted mixture deep neural network (WMDNN) is proposed to automatically extract the features that are effective for FER tasks. Several pre-processing approaches, such as face detection, rotation rectification, and data augmentation, are implemented to restrict the regions for FER. Two channels of facial images, including facial grayscale images and their corresponding local binary pattern (LBP) facial images, are processed by WMDNN. Expression-related features of facial grayscale images are extracted by fine-tuning a partial VGG16 network, the parameters of which are initialized using VGG16 model trained on ImageNet database. Features of LBP facial images are extracted by a shallow convolutional neural network (CNN) built based on DeepID. The outputs of both channels are fused in a weighted manner. The result of final recognition is calculated using softmax classification. Results: Experimental results indicate that the proposed algorithm can recognize six basic facial expressions (happiness, sadness, anger, disgust, fear, and surprise) with high accuracy. The average recognition accuracies for benchmarking data sets “CK+,”“JAFFE,”and “Oulu-CASIA”are 0.970, 0.922, and 0.923, respectively. Conclusions: The proposed FER method outperforms the state-of-the-art FER methods based on the hand-crafted features or deep networks using one channel. Compared with the deep networks that use multiple channels, our proposed network can achieve comparable performance with easier procedures. Fine-tuning is effective to FER tasks with a well..."
  },
  {
    "year": "2017",
    "abstract": "Image processing and analysis is useful to monitor the activated sludge (AS) wastewater treatment plants based on the morphology of microbial aggregates (flocs) and filamentous bacteria. Phasecontrast microscopy is used to observe filamentous bacteria in the AS samples at lower objective magnification with improved visibility of details. However, segmentation of the phase-contrast images faces inherent difficulties caused by the artifacts associated with the microscopy, such as halos and shade-off. This paper is comprised mainly of three tasks: robust segmentation of phase-contrast images for filamentous bacteria, identification of novel image analysis parameters for morphology of the bacteria, and the use of the proposed parameters to model sludge volume index (SVI). SVI is the most important physical measurement employed to monitor the operation of an AS plant. In this paper, a robust phase-congruency-based method, augmented by top-hat and bottom-hat filtering, is proposed for segmentation of filamentous bacteria. Different metrics, such as accuracy, recall, variation of information, F-measure, and Rand index are used for the segmentation assessment. We propose an exact procedure to determine the total length of branched and unbranched filamentous bacteria. Moreover, a novel rotation invariant feature is proposed to determine the extent of the curvature of a filament. Finally, we investigated regression models for SVI of multiple AS wastewater treatment plants, based on the proposed image analysis parameters of the filaments. The modeling of SVI proves the significance of the proposed image analysis parameters for monitoring AS plants."
  },
  {
    "year": "2017",
    "abstract": "We present a novel methodology to procedurally restore facade texture from images, where severe occlusions and lighting variations occur, making the textures difficult to reconstruct effectively. A refinement strategy is designed, which includes an iterative weighted-average algorithm, to restore and update the high-quality consensus texture of the targeted building. Our approach combines component-based structure analysis and rule-based texture recovery techniques that are suitable for removing the occluded areas from a given building facade. We demonstrate our framework on several real-world buildings with varying amounts of occlusion, and show that our approach can be used to generate 3-D buildings with far more aesthetic quality than the previous approaches."
  },
  {
    "year": "2017",
    "abstract": "Transfer learning and ensemble learning are the new trends for solving the problem that training data and test data have different distributions. In this paper, we design an ensemble transfer learning framework to improve the classification accuracy when the training data are insufficient. First, a weightedresampling method for transfer learning is proposed, which is named TrResampling. In each iteration, the data with heavy weights in the source domain are resampled, and the TrAdaBoost algorithm is used to adjust the weights of the source data and target data. Second, three classic machine learning algorithms, namely, naive Bayes, decision tree, and SVM, are used as the base learners of TrResampling, where the base learner with the best performance is chosen for transfer learning. To illustrate the performance of TrResampling, the TrAdaBoost and decision tree are used for evaluation and comparison on 15 UCI data sets, TrAdaBoost, ARTL, and SVM are used for evaluation and comparison on five text data sets. According to the experimental results, our proposed TrResampling is superior to the state-of-the-art learning methods on UCI data sets and text data sets. In addition, TrResampling, bagging-based transfer learning algorithm, and MultiBoosting-based transfer learning algorithm (TrMultiBoosting) are assembled in the framework, and we compare the three ensemble transfer learning algorithms with TrAdaBoost to illustrate the framework's effective transfer ability."
  },
  {
    "year": "2017",
    "abstract": "Mobile cyber-physical systems (CPS) that take the advantages and extend the application domains of CPS have become increasingly popular in recent years. For example, mobile CPS could be a kind of foundational techniques to support the development of vehicular networking systems, thereby improving security and privacy of users in the dynamic environments of vehicular networks. In this paper, we first distinguish mobile CPS from traditional CPS. Then, we introduce their three emerging application areas, i.e., vehicular networking systems, healthcare systems, and mobile education. After that, we discuss four main research challenges of mobile CPS regarding security, energy consumption, mobile dynamic environment, and system stability. Also, we consider the corresponding techniques, which may address these challenges, and analyze the inter-relations among them. Finally, we outline the possible research directions and applications of mobile CPS in the future."
  },
  {
    "year": "2017",
    "abstract": "Sequential patterns are important, because they can be exploited to improve the prediction accuracy of our classifiers. Sequential data, such as time series/video frames, and event data are becoming more and more ubiquitous in a wide spectrum of application scenarios especially in the background of large data and deep learning. However, large data sets used in training modern machine-learning models, such as deep neural networks, are often affected by label noise. Existing noisy learning approaches mainly focus on building an additional network to clean the noise or find a robust loss function. Few works tackle this problem by exploiting sample correlations. In this paper, we propose BundleNet, a framework of sequential structure (named bundle-module, see Fig. 1) for deep neural networks to handle the label noise. The bundle module naturally takes into account sample correlations by constructing bundles of samples class-by-class, and treats them as independent inputs. Moreover, we prove that the bundle-module performs a form of regularization, which is similar to dropout as regularization during training. The regularization effect endows the BundleNet with strong robustness to the label noise. Extensive experiments on public data sets prove that the proposed approach is effective and promising."
  },
  {
    "year": "2017",
    "abstract": "An electrostatic discharge (ESD) event can cause a medical device to fail and pose a threat to patients'safety. This paper presents the data mining analysis of ESD failures in medical devices, over the last ten years, using the U.S. FDA's manufacturer and user facility device experience database. The most frequent failure modes and activities resulting in ESD events were identified and correlated with key environmental factors. Recommendations are then presented to medical device manufacturers and hospitals."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an energy-efficient multi-hop routing protocol for wireless sensor networks (WSNs). The nature of sensor nodes with limited batteries and inefficient protocols are the key limiting factors of the sensor network lifetime. We aim to provide for a green routing protocol that can be implemented in a wireless sensor network. Our proposed protocol's most significant achievement is the reduction of the excessive overhead typically seen in most of the routing protocols by employing fixed clustering and reducing the number of cluster head changes. The performance analysis indicates that overhead reduction significantly improves the lifetime as energy consumption in the sensor nodes can be reduced through an energy-efficient protocol. In addition, the implementation of the relay nodes allows the transmission of collected cluster data through inter cluster transmissions. As a result, the scalability of a wireless sensor network can be increased. The usage of relay nodes also has a positive impact on the energy dissipation in the network."
  },
  {
    "year": "2017",
    "abstract": "Dempster-Shafer evidence theory is efficient to deal with uncertain information. One assumption of evidence theory is that the source of information should be independent when combined by Dempster's rule for evidence combination. However, the assumption does not coincide with the reality. A lot of works are done to solve the problem about the independence. The existing method based on the statistical parameter Pearson correlation coefficient discount is one of the feasible methods. However, the Pearson correlation coefficient is only used to characterize the linear correlation between the attributes of the normal distribution. In this paper, a new method is proposed, the Pearson correlation coefficient and Shearman correlation coefficient to generate the discounting factor. Taking the parametric statistic and nonparametric statistic into consideration, the proposed method is more efficient. The experiments on wine data set are illustrated to show the efficiency of our proposed method."
  },
  {
    "year": "2017",
    "abstract": "Current Internet packet delivery only relies on packet’s destination IP address and forwarding devices neglect the validation of packet’s IP source address, it makes attackers can leverage this flaw to launch attacks with forged IP source address so as to meet their vicious purposes and avoid to be tracked. In order to mitigate this threat and enhance Internet accountability, many solutions have been proposed either from the intra-domain or the inter-domain aspects. However, most of them faced with some issues hard to cope with, e.g., low filtering rates, high deployment cost. And most importantly, few of them can cover both intra-domain and inter-domain areas at the same time. With the central control and edge response pattern, the novel network architecture of software defined networking (SDN) possess whole network intelligence and distribute control rules directly to edged SDN switches, which brings a good opportunity to solve the IP spoofing problem. By taking advantage of SDN, in this paper, we propose an SDN-based integrated IP source address validation architecture (ISAVA) which can cover both intra- and inter-domain areas and effectively lower SDN devices deployment cost, while achieve desirable control granularities in the meantime. Specifically, within autonomous system (AS), ISAVA relies on an SDN incremental deployment scheme which can achieve IP prefix (subnet)-level validation granularity with minimum SDN devices deployment. While among ASes, ISAVA sets up border server and establishes a vouch mechanism between allied ASes for signing outbound packets so as to achieve AS-level validation granularity. Finally, conducted experiments confirm that ISAVA intra-domain scheme can get beyond 90% filtering rates with only 10% deployment in average, while the inter-domain scheme can get high filtering rates with low system cost and less storage usage."
  },
  {
    "year": "2017",
    "abstract": "For an active distribution system (ADS) that integrates high levels of distributed generators (DGs), the control dimension of such a wide and dynamic set of resources would become overwhelming. This study proposes a novel pinning group consensus (PGC)-based distributed coordination control to simplify ADS control by using the virtual clusters building block concept. A given ADS is rethought as coupled small virtual clusters, including virtual microgrid clusters and virtual power plant clusters; accordingly, the ADS can be coordinated by controlling a small number of selected pinning agents instead of a huge number of DGs. The predefining of the PGC values for these pinning agents, which comprehensively considers both clusters features and DG capacities, is the most distinguishing work for the proposed control scheme and can lead to effective global coordination in a distributed manner. Simulation cases under normal/disturbed/emergency conditions verify the effectiveness and advantages of the proposed scheme."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing is considered as one of the key drivers for the next generation of mobile networks (e.g. 5G). This is combined with the dramatic expansion in mobile networks, involving millions (or even billions) of subscribers with a greater number of current and future mobile applications (e.g. IoT). Cloud Radio Access Network (C-RAN) architecture has been proposed as a novel concept to gain the benefits of cloud computing as an efficient computing resource, to meet the requirements of future cellular networks. However, the computational complexity of obtaining the channel state information in the full-centralized C-RAN increases as the size of the network is scaled up, as a result of enlargement in channel information matrices. To tackle this problem of complexity and latency, MapReduce framework and fast matrix algorithms are proposed. This paper presents two levels of complexity reduction in the process of estimating the channel information in cellular networks. The results illustrate that complexity can be minimized from O(N3) to O((N/k)3), where N is the total number of RRHs and k is the number of RRHs per group, by dividing the processing of RRHs into parallel groups and harnessing the MapReduce parallel algorithm in order to process them. The second approach reduces the computation complexity from O((N/k)3) to O((N/k)2.807) using the algorithms of fast matrix inversion. The reduction in complexity and latency leads to a significant improvement in both the estimation time and in the scalability of C-RAN networks."
  },
  {
    "year": "2017",
    "abstract": "Ensuring ubiquitous mission-critical public safety communications (PSC) to all the first responders in the public safety network is crucial at an emergency site. Recently, the use of unmanned aerial vehicles (UAVs) has received extensive interest for PSC to fill the coverage holes and establish reliable connectivity. The UAVs can be deployed as unmanned aerial base stations (UABSs) as part of a heterogeneous network (HetNet) PSC infrastructure. In this paper, we design a PSC LTE-Advanced HetNet for different path loss models and deployment mechanism for UABSs. We enhance the system-wide spectral efficiency (SE) of this PSC HetNet by apply cell range expansion (CRE) to UABSs and mitigating the inter-cell interference arising in the HetNet by applying 3GPP Release-10 enhanced inter-cell interference coordination (eICIC) and 3GPP Release-11 further-enhanced inter-cell interference coordination (FeICIC). Through Monte Carlo simulations, we compare the system-wide fifth percentile SE when UABSs are deployed on a hexagonal grid and when their locations are optimized using a genetic algorithm, while also jointly optimizing the CRE and the inter-cell interference coordination parameters. Our results show that at optimized UABS locations, reduced power subframes defined in 3GPP Release-11 can provide considerably better fifth percentile SE than the 3GPP Release-10 with almost blank subframes (eICIC)."
  },
  {
    "year": "2017",
    "abstract": "Device-free localization (DFL), which can detect and locate a person by measuring the changes in received signals, is one of the primary techniques in wireless sensor networks. Recently, research on fingerprint-based localization in changing environments has been receiving increasing attention. However, when the environment changes due to furniture or other objects are moved, there is still much room for localization accuracy improvement in fingerprint-based DFL. In this paper, we propose a novel DFL algorithm for changing environments: this algorithm features an enhanced channel-selection method and adopts the logistic regression classifier to improve the localization accuracy. The proposed frequency channel-selection method selects two correlated channels with higher Pearson correlation coefficient both in the training and testing procedures, which would be more robust to the environmental change. Meanwhile, the logistic regression classifier could counteract the negative influence on the localization accuracy, without the need for rebuilding the database in fingerprint-based DFL. Experimental results demonstrate that the logistic regression classifier has the lowest error rate among three related methods (k-nearest neighbours classifier, linear discriminant analysis classifier, and random forests classifier). In addition, the localization accuracy has been further improved by the proposed DFL algorithm than by the other state-of-the-art fingerprint-based methods."
  },
  {
    "year": "2017",
    "abstract": "By enabling very high bandwidth for radio communications, the millimeter-wave (mmWave), which can easily be integrated with massive-multiple-input-multiple-output (massive-MIMO) due to small antenna size, has been attracting growing attention as a candidate for the fifth-generation (5G) and 5G-beyond wireless communications networks. On the other hand, the communication over the orthogonal states/modes of orbital angular momentum (OAM) is a subset of the solutions offered by massive-MIMO communications. Traditional massive-MIMO-based mmWave communications did not concern the potential spectrum-efficiency-gain (SE-gain) offered by the orthogonal states of OAM. However, the highly expected maximum SE-gain for OAM and massive-MIMO communications is the product of SE-gains offered by OAM and multiplexing-MIMO. In this paper, we propose the OAM-embedded-MIMO (OEM) communication framework to obtain the multiplicative SE-gain for joint OAM and massive-MIMO-based mmWave wireless communications. We design the parabolic antenna for each uniform circular array antenna to converge OAM signals. Then, we develop the mode-decomposition and multiplexing-detection scheme to obtain the transmit signal on each OAM-mode of each transmit antenna. Also, we develop the OEM-water-filling power allocation policy to achieve the maximum multiplicative SE-gain for OEM communications. The extensive simulations obtained validate and evaluate our developed a parabolic antenna-based converging method, a mode-decomposition and multiplexing-detection scheme, and an OEM-water-filling policy, showing that our proposed OEM mmWave communications can significantly increase the SE as compared with the traditional massive-MIMO-based mmWave communications."
  },
  {
    "year": "2017",
    "abstract": "Theoretical expression of radar detection probability is the foundation of radar detection performance analysis. In this paper, we derive the mathematical expression of the noncoherent radar detection probability for correlated gamma fluctuating targets in K-distributed clutter. We demonstrate the correctness of the derivation by Monte Carlo simulations."
  },
  {
    "year": "2017",
    "abstract": "Intrusion detection techniques are widely used to guarantee the security of people’s possessions. With the rapid development of wireless communication, device-free passive human detection based on wireless techniques may have more opportunities in intrusion detection. WiFi has been widely deployed in both public and private areas, which can be used as generalized sensors to detect human motion beyond communication. As a result, there have been several researches on WLAN-based motion detection. However, the detection accuracy of previous approaches declines significantly when people’s moving speed becomes very slow. In this paper, we explore a novel method which has a relative stable detection performance under different moving speeds. We extract a novel feature representing the fluctuation of the whole channel from channel state information at the physical layer of 802.11n wireless networks, and utilize a probability technique to detect human motion. A hidden Markov model is leveraged as the classifier to make human detection a probability problem. We implement the system using off-the-shelf WiFi devices and evaluate it in two scenarios. As indicated in the evaluation results, our approach is an appropriate method for intrusion detection."
  },
  {
    "year": "2017",
    "abstract": "In the traditional graph embedding framework, the graph is usually built by k-NN or r-ball. Since it is difficult to manually set the parameters k and r in the high-dimensional space, sparse representation-based methods are usually introduced to automatically build the graphs. In recent years, nuclear norm-based matrix regression (NMR) has been proposed for face recognition using the low rank structural information (i.e., the image matrix-based error model). Inspired by NMR, we give a NMR-based projections (NMRP) method for feature extraction and recognition. The experiments on FERET and extended Yale B face databases show that NMR can be used to build the graph while NMRP is an effective feature extraction method."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses the estimation of large-dimensional covariance matrices under both normal and nonnormal distributions. The shrinkage estimators are constructed by convexly combining the sample covariance matrix and a structured target matrix. The optimal oracle shrinkage intensity is obtained analytically for any prespecified target in a class of matrices which includes various structured matrices such as banding, thresholding, diagonal, and block diagonal matrices. After deriving the unbiased and consistent estimates of some quantities in the oracle intensity involving unknown population covariance matrix, two classes of available optimal intensities are proposed under normality and nonnormality, respectively, by plug-in technique. For the target matrix with unknown parameter such as bandwidth in banded target, an analytic estimate of unknown parameter is provided. Both the numerical simulations and applications to signal processing and discriminant analysis show the comparable performance of the proposed estimators for large-dimensional data."
  },
  {
    "year": "2017",
    "abstract": "Projection-based tabletop sharing (PBTS) systems allow a local user to share a pointing gesture or a handwritten note on a tabletop document with a remote user who places the same document on a tabletop by projecting the upper limb image of the local user onto the remote document and tabletop. A vertical display is used to share an image of the upper body, including the face of the remote user. However, in previous systems, the spatial layouts of the shared documents must be identical on both tabletops, and the projected upper limb is not extended from the upper body image of the remote user. This paper proposes a PBTS system to address such geometric consistency issues to improve remote collaboration. First, we propose to maintain the geometric consistency of a pointing gesture and handwritten note between each pair of the shared documents rather than between the entire tabletops. This allows users to freely change the document layouts on both tabletops. Second, we propose to overlay the upper limb image such that it is extended from the vertical display, where the upper body image is shown. This is achieved by rotating the upper limb image around the fingertip that performs the pointing gestures or around the tip of the pen used to write notes. We constructed a prototype to determine if the proposed system resolves the geometric consistency issues. Then, we evaluated how accurately a user can convey a pointing position to a distant partner when the document layouts differ between the remote tabletops. Finally, we evaluated how the user experience, particularly the social presence, is improved by the proposed geometrically consistent upper limb direction."
  },
  {
    "year": "2017",
    "abstract": "To accommodate the increasing penetration level of distributed generators (DGs) in the electrical energy power system, appropriate reactive power control of DGs, which can lead to the voltage profile improvement and power loss minimization, should be addressed. This paper proposed a consensus-based distributed algorithm for the reactive power control of DGs in the power system to optimize the multiobjective function, which includes power loss, voltage deviation, and cost of the reactive power generation of DGs. The formulated problem is proved to be convex. The proposed algorithm is tested on 6- and 34-bus systems to validate its effectiveness and scalability. The proposed algorithm is also compared with the centralized technique particle swarm optimization (PSO), which demonstrates the effectiveness of the proposed distributed algorithm."
  },
  {
    "year": "2017",
    "abstract": "Numerous applications, such as material handling, manufacturing, security, and automated transportation systems, use mobile robots. Autonomous navigation remains one of the primary challenges of the mobile robot industry; many new control algorithms have been recently developed that aim to overcome this challenge. These algorithms are primarily related by their adoption of new strategies for avoiding obstacles and minimizing the travel time to a target along an optimal path. In this paper, we introduce four different navigation systems for an autonomous mobile robot (PowerBot) and compare them. The four systems are based on a fuzzy logic controller (FLC). The FLC of one system is tuned by an inexperienced human (naive), while the three other FLCs are optimized through a genetic algorithm (GA), particle swarm optimization (PSO), and a human expert. We hope the comparison answers the question of which is the best controller. In other words, “who can win?,”the naive, the GA, the PSO, or the expert, in fine tuning the membership functions of the navigation and obstacle avoidance behavior of the mobile robot? To answer this question, we used four different techniques for optimization (the naive FLC, GA, PSO, and FLC-expert) and used many criteria for comparison, whereas other research papers have dealt with two techniques at a time."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a massive multiple-input multiple-output (MIMO) channel measurement campaign with 256-element virtual rectangular array at the base station was conducted. The typical hotspot scenario, subway station, is considered, and the measurements were conducted at 6 GHz with a bandwidth of 100 MHz. A hybrid clustering approach is proposed to characterize the cluster evolution over the large-scale array. In the hybrid approach, we apply the space-alternating generalized expectation maximization algorithm to estimate the multipath components (MPCs), and use the multipath component distance-based tracking algorithm and the KPowerMeans algorithm for MPCs tracking and clustering. A cluster partition algorithm is further proposed to adjudge the clusters association over the array, and output the final clustering results. Under such a scheme, cluster-based model parameters are provided with detailed analysis. The extracted parameters include overall angle distribution, global angular spread, inter-cluster parameters, and intra-cluster parameters. The obtained model parameters can be fed into the new channel simulator for massive MIMO. This is useful for the design and application of the practical massive MIMO system in the future."
  },
  {
    "year": "2017",
    "abstract": "The RAKE receivers are widely used in code division multiple access communication systems to achieve anti-multipath fading. However, a traditional RAKE receiver requires pilot data stream inserted into the sequence, which occupies channel resources and limits its applications. In this paper, a new adaptive RAKE receiver based on Bayesian theory is reported that only uses received signals to estimate its channel parameters. Observed data are used to obtain the information of the channel impulse response. Next, the prior information is used. In the iterative process, a priori information is accumulated to improve the receiver performance. Thus, the mean and covariance of the channel impulse response that is modeled as a complex and uncertain Gaussian random vector are recursively estimated using Bayesian theory. Finally, the RAKE weights are obtained using the mean and covariance. As shown in the simulation results, the bit error rate (BER) decreases as the number of fingers increases. The performance of the new RAKE receiver has been greatly improved compared with the all-RAKE receiver with maximal ratio combining, RAKE receiver with singular value decomposition, and RAKE receiver with fast approximated power iteration. Under medium to high SNR conditions (i.e., ≥-5 dB), the BER performance of the new RAKE receiver provides at least 3 × 10-4less than that of the other receiver tested."
  },
  {
    "year": "2017",
    "abstract": "Low-rank matrix completion with phase constraints have been applied to the single-channel magnetic resonance imaging (MRI) reconstruction. In this paper, the reconstruction of sparse parallel imaging with smooth phase in each coil is formulated as the completion of a low-rank data matrix, which is modeled by the k-space neighborhoods and symmetric property of samples. The proposed algorithm is compared with a calibrationless parallel MRI reconstruction method based on both simulation data and real data. The experiment results show the proposed method has better performance in terms of MRI imaging enhancement, scanning time reduction, and denoising capability."
  },
  {
    "year": "2017",
    "abstract": "The federal communications commission (FCC) took the unprecedented step to approve the usage of TV white spaces, i.e., locally vacant TV channels, in 2012. This TV spectrum will present new opportunities for wireless access technologies and applications, e.g. femtocell networks. The utilization of TV white spaces in femtocell networks also comes with some technical challenges. One of the most fundamental is that how much capacity and energy efficiency can be achieved in TV white spaces network. Prior works only focused on capacity consideration for cellular network in outdoor scenario leaving important femtocell network in indoor scenario largely open for investigation. In this paper, we explore the capacity and energy efficiency for femtocell network by developing a TV white spaces reuse and power allocation scheme. The problem is formulated into an optimization problem with the objective to maximize the energy efficiency achieved by a femtocell network, while keeping the interference to the primary receiver and macro receiver at an acceptable level. We demonstrate the existence of a unique globally optimal transmit power vector for all the femtocells, and propose a gradient absent algorithm to obtain it. Simulation results show that the femtocell can have a considerable capacity and energy efficiency improvement by using the TV channels."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new linear array configuration based on the concept of two-level nested array is proposed. Specifically, the proposed array configuration consists of two uniform linear arrays (ULAs) plus a separate sensor with appropriate spacing apart. Compared with the original two-level nested array, the degrees of freedom of our proposed array configuration can be increased by 2L - 6 for an array with L physical sensors. Moreover, the virtual array aperture can be enlarged by nearly (L2/2 - L - 2)d1, where d1is the inter-element spacing of the first ULA. Owing to these advantages, our proposed array configuration has enhanced resolution and achieves better performance in parameter estimation, such as direction-ofarrival (DOA) estimation. Numerical simulations of DOA estimation exhibit the effectiveness and superiority of this array configuration."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the attitude tracking control problem of hypersonic reentry vehicles is addressed by synthesizing a neural network (NN) using the backstepping control technique. The control-oriented model is formulated with mismatched and matched lumped uncertainties, which reflect the multiple aerodynamic uncertainties, external disturbances, and actuator saturation. Based on the universal approximation property of the radial basis function NN, an adaptive NN disturbance observer is developed to estimate the lumped disturbances online using only the tracking error state as its input vector. The “explosion of terms”problem in backstepping is avoided using a tracking differentiator. To address the input constraints, a sigmoid function is introduced to approximate the saturation and guarantee that the control input is bounded. In particular, a novel auxiliary system, driven by the tracking error and the input error between the unconstrained input and the constrained input, which was processed using the sigmoid function, is further designed to reduce the saturation effects and satisfy the stability requirement. Via modification of the adaptive laws, the tracking errors are guaranteed to be uniformly ultimately bounded based on Lyapunov theory. Moreover, several simulations are investigated to show the effectiveness of the proposed control scheme."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a novel nonlinear decoupling control scheme for a permanent magnet in-wheel motor (PMIWM), in which both the radial basis function neural network inverse (RBFNNI) and the state feedback robust pole placement (RPP) are employed. First, a theoretical analysis shows the existence of the inverse system of the PMIWM to be modeled mathematically. An inverse system is introduced into the original system of the PMIWM. Then, by cascading the RBFNNI system on the left side of the original PMIWM system, a new decoupling pseudo-linear system is established. Moreover, the RPP theory is employed to design an extra controller which further improves the disturbance rejection and robustness of the whole system. The effectiveness of the proposed control approach is verified by the real-time hardware-in-the-loop experiments under various operations."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the integration of a haptic vest with a multimodal virtual environment, consisting of video, audio, and haptic feedback, with the main objective of determining how users, who interact with the virtual environment, benefit from tactile and thermal stimuli provided by the haptic vest. Some experiments are performed using a game application of a train station after an explosion. The participants of this experiment have to move inside the environment, while receiving several stimuli to check if any improvement in presence or realism in that environment is reflected on the vest. This is done by comparing the experimental results with those similar scenarios, obtained without haptic feedback. These experiments are carried out by three groups of participants who are classified on the basis of their experience in haptics and virtual reality devices. Some differences among the groups have been found, which can be related to the levels of realism and synchronization of all the elements in the multimodal environment that fulfill the expectations and maximum satisfaction level. According to the participants in the experiment, two different levels of requirements are to be defined by the system to comply with the expectations of professional and conventional users."
  },
  {
    "year": "2017",
    "abstract": "If the construction and maintenance of Wi-Fi radio maps (WRMs) were fully automated, the implementation of a global-scale Wi-Fi indoor positioning system would be possible. This paper proposes a WRMs calibration system that automates the initial construction and maintenance of radio maps using crowdsourced fingerprints collected from numerous smartphones without location information. The system incorporates an unsupervised learning algorithm into an incremental and adaptive calibration process. The unsupervised learning algorithm constructs an initial radio map, using fingerprints collected from unknown locations, by finding a hidden structure among them. Once a positioning service is available based on the initial radio map, the radio map continues to adapt to signal changes in the environment through the incremental and adaptive calibration process using the fingerprints that are continuously collected from the service users. Experiments carried out in an office building have shown that the proposed system could successfully construct and maintain a precise radio map without requiring any location information. In a long-term experiment that lasted for five months, the proposed system was able to not just maintain but also improve the quality of the radio map. These results indicate that Wi-Fi indoor positioning systems can be automatically constructed and maintained in continuously changing Wi-Fi environments without manual calibration efforts."
  },
  {
    "year": "2017",
    "abstract": "Belief reliability is a new reliability metric based on the uncertainty theory, which aims to measure system performance incorporating the influences from design margin, aleatory uncertainty, and epistemic uncertainty. A key point in belief reliability is to determine the belief reliability distribution based on the actual conditions, which, however, could be difficult when available information is limited. This paper proposes an optimal model to determine the belief reliability distribution based on the maximum entropy principle when kth moments of what can be obtained. An estimation method using linear interpolation and a genetic algorithm is subsequently applied to the optimal model. When only the expected value and the variance are available, the optimal results are in accordance with the maximum entropy principle. It could be observed in the sensitivity analysis that the accuracy of the optimal results is a decreasing function of the width of variances and an increasing function of the number of interpolation points. Therefore, researchers could adapt to different widths of variances and requirements of accuracy by adjusting the number of interpolation points. It could be concluded that this new method to acquire belief reliability distribution is important in the application of belief reliability."
  },
  {
    "year": "2017",
    "abstract": "Induction motors (IM) used for various industrial applications operate with lagging power factor. Electrical distribution agency insists high power factor operation and it gives incentives on operating a system closer to unity. This paper presents a novel reactive power compensation using IM driven by nine switch ac-dc-ac converter for a high power factor operation at the point of common coupling (PCC). The nine switch converter (NSC) with leading power factor operation delivers reactive power to the PCC. Thus, reactive power required for another load at PCC is compensated. Modified sinusoidal pulse width modulation is developed for NSC to operate the active front end rectifier and an inverter simultaneously to feed three-phase IM. A closed loop proportional integral control technique is developed to achieve desired VAR compensation. As per the required VAR compensation, front end rectifier voltage is modified. This is achieved by phase shifting of front end rectifier modulation reference by an angle δ with respect to utility phase voltage. The PCC phase voltage is continuously sensed to track instantaneous phase angle θ using synchronous reference frame phase lock loop. The analysis of VAR compensator is presented in the d-q reference frame. The proposed system is simulated in MATLAB for VAR compensation at PCC with 5.4 hp induction motor drive to test the performance of VAR control loop. To validate the feasibility of the proposed system an experimental prototype is developed with 1 hp induction motor drive. Gate pulses are generated using digital signal controller dsPIC33EP256MU810. The simulation and experimental results proved the feasibility of the proposed VAR compensation system."
  },
  {
    "year": "2017",
    "abstract": "The IEEE 802.22 standard targets rural and sparsely populated regions exploiting television white space (TVWS) technology. In these regions, there are fewer mobile users per density and end-user traffic is light. Hence, there is a need to adopt traffic aware algorithm leveraging on the end-user nonuniform traffic attributes and in essence, promote spectrum efficiency in the TVWS spectrum-management regime. This paper investigates a mechanism to encourage spectrum sharing during low end-user traffic regime motivated by financial inducement. Since incumbent coexistence has been achieved using market models, it is tractable to apply market-assisted spectrum sharing models to address self-coexistence issues in TVWS networks. The purpose of this paper is to use the market model to promote self-coexistence in TVWS networks in the uplink self-frequency reuse. Toward this goal, this paper proposes discounted spectrum price game-based resource allocation in a competitive environment (D-GRACE). Specifically, D-GRACE is a transmit power reduction strategy motivated by financial incentives during light TVWS end-user traffic. When compared with an existing non-market-inspired TVWS self-coexistence resource allocation algorithm under the same scenario, D-GRACE exhibited superior power savings of about 20% and converged after five iterations."
  },
  {
    "year": "2017",
    "abstract": "Explosion phenomena today are considered a significant concern that needs to be detected and analyzed with a prompt response. We develop a multiclass categorization system for explosion phenomena using color images. Consequently, we describe four patterns of explosion phenomena, including pyroclastic density currents, lava fountains, lava and tephra fallout, and nuclear explosions, against three patterns of non-explosion phenomena, including wildfires, fireworks, and sky clouds. The classification task was handled through extracting different types of features, including texture features, amplitude features, frequency features, and histogram features. Then, these features were fed into several multiclass classification methods. In addition, we present a new data set for volcanic and nuclear explosions that includes 10654 samples. Evaluation results show the one-against-one multiclass support vector machine with degree 3 polynomial kernel outperforms other classification methods. It produces the highest classification rate of 90.85% to categorize 5327 images of the data set. A reasonable execution time of approximately 117 ms was accomplished to classify one input test image."
  },
  {
    "year": "2017",
    "abstract": "Advances in multimedia technologies have led to the emergence of smart home applications. In fact, mobile multimedia technologies provide the infrastructure to adopt smart solutions and track inhabitants' activities. In-home activity recognition significantly enhances the performance of healthcaremonitoring and emergency-control applications for elderly and people with special needs. Developing and validating data models for such applications requires training sets that reflect a ground truth in the form of labeled or annotated data. With the accelerated development of Internet-of-Things applications, automated annotation processes have emerged understanding resident behavior in terms of activities. This paper presents a methodology for automatic data annotation by profiling sensing nodes. Our proposed methodology models activities based on spatially recognized actions, with every activity expected to have a direct relationship with a specific set of locations. Furthermore, the proposed technique validates the assignment of labels based on the temporal relations among consecutive actions. We performed experiments to evaluate our proposed methodology on CASAS data sets, which indicated that the proposed methodology achieved better performance, to a statistically significant extent, than the state-of-the-art methodologies presented in the literature."
  },
  {
    "year": "2017",
    "abstract": "The conventional approach to designing controllers for the phase-shifted full-bridge (PSFB) converter is to design a linear compensator based on the small-signal model, which cannot provide the converter with strong robustness against parametric disturbances and consistent transient responses over a wide range of operating conditions. This paper proposed a fixed frequency pulse-width-modulation (PWM)-based integrated sliding mode (ISM) controller for the PSFB converter. By analyzing the phase-shifted modulation of the full bridge, the dynamic state-space model of the PSFB is established based on the simplified circuit model. On this basis, the sliding motion in state space, the existence condition for steady-state operation, and the indirect PWM control function are discussed. Meanwhile, a switch control is introduced to the control function, and a robustness condition for parametric disturbances is analyzed. The designed PWM ISM controller is applied to a 1-kW PSFB converter prototype. Experimental results verify the effectiveness of the proposed controller by comparison with the hysteresis-modulation-based sliding mode controller and the increment PID controller."
  },
  {
    "year": "2017",
    "abstract": "It is widely acknowledged that the forthcoming 5G architecture will be highly heterogeneous and deployed with high degree of density. These changes over the current 4G bring many challenges on how to achieve an efficient operation from the network management perspective. In this paper, we introduce revolutionary vision of the future 5G wireless networks, in which operating the wireless networks is no longer limited by hardware or even software. Specifically, by the idea of virtualizing the wireless networks, which has recently gained increasing attention, we introduce the everything-as-a-service (XaaS) taxonomy to light the way towards designing the service-oriented wireless networks. The concepts and challenges along with the research opportunities for realizing XaaS in wireless networks are overviewed and discussed."
  },
  {
    "year": "2017",
    "abstract": "The Kalman filter (KF) is the most common state estimation method for gas turbine health monitoring, and it runs in the centralized architecture. However, health estimation cannot be achieved by the KF-based method as sensor fault occurs, and malfunction of the central monitoring unit will unavoidably result to the termination of the diagnosis task. For these purposes, this paper develops a novel hybrid federated KF approach from the previous achievements. The hybrid KF consists of a bank of local filters and one master filter, and the federated filtering structure and asynchronous fusion mechanism are designed. Both the linearized KF and extended KF are employed as the local filters based on the linear correlation of thermodynamic parameters. The local state estimates and covariance are yielded in parallel, and then integrated in a master filter to produce global state estimate. The proposed methodology is evaluated and compared with the general federated KFs in terms of estimation accuracy, computational efforts, and robustness to sensor fault in the application of gas turbine health monitoring. The result shows that the hybrid KF is the best balance off the involved performance, and confirms our viewpoints in this paper."
  },
  {
    "year": "2017",
    "abstract": "Computing hardware has become an attractive attack surface due to the globalization of semi-conductor design and supply chain, and the wide integration of third-party intellectual property cores. Recently, gate-level information flow tracking (GLIFT) has been proposed to monitor the flow of information in secure hardware design by associating data objects with sensitivity labels and tracking the flow of labeled data. GLIFT can be used to model and verify security-related properties, such as confidentiality and integrity. However, existing work in this realm only considers binary labels. These are inadequate for understanding simultaneous information flow behaviors and the root source information flows. In this paper, we propose a precise multi-bit GLIFT method to perform simultaneous multi-bit flow tracking for understanding exactly which bits are affecting a data object at the same time. The proposed method provides more detailed insights into simultaneous information flow behaviors and thus allows proof of quantitative information flow data properties. We compare the complexity and verification performance for different information flow models using primitive gates, IWLS benchmarks, several cryptographic cores, and trustHUB benchmarks. Experimental results have demonstrated that our method can reason about multi-bit information flow behaviors and identify potential security flaws."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a detail-preserving image denoising method via cluster-wise progressive principal component analysis (PCA) thresholding based on the Marchenko-Pastur (MP) law in random matrix theory. According to random matrix theory, an efficient and stable noise-level estimation method is also presented. Specifically, a global Gaussian noise level is estimated by interpreting the relationship between noise and eigenvalues of PCA for noisy patch matrices via the MP law in conjunction with the observation that vectors extracted from a noise-free image often lie in a low-dimensional subspace. Before noise removal, an adaptive clustering method is developed to automatically determine a suitable number of clusters segregating patches with different features (edges and textures). To denoise each cluster matrix, progressive PCA thresholding is performed. First, a hard thresholding of singular values in the singular value decomposition domain based on the MP law is applied to find a low-rank approximation to the cluster matrix. Second, the remaining noises of the low-rank matrix are further removed in the PCA transform domain using a special soft thresholding, i.e., the linear minimum mean-square-error technique with locally estimated parameters. The experiments show that the proposed method not only achieves state-of-the-art denoising performance in terms of quantitative indices, but also preserves visually important image details best."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an agent-based modeling framework for affordance-based driving behaviors during the exit maneuver of driver agents in human-integrated transportation problems. We start our discussion from one novel modeling framework based on the concept of affordance called the affordancebased finite state automata (AFSA) model, which incorporates the human perception of resource availability and action capability. Then, the agent-based simulation illustrates the validity of the AFSA framework for the highway-lane-driver system. Next, the comparative study between real driving data and agent-based simulation outputs is provided using the transition diagram. Finally, we perform a statistical analysis and a correlation study to analyze affordance-based driving behavior of driver agents. The simulation results show that the AFSA model well represents the perception-based human actions and drivers' characteristics, which are essential for the design viewpoint of control framework of human driver modeling. This paper is also expected to benefit a designed control for autonomous/self-driving car in the future."
  },
  {
    "year": "2017",
    "abstract": "The densification of small cells in heterogeneous networks (HetNets) causes huge energy consumption and severe network interference. To fully exploit the potential of new network architecture, the cell selection (CS) in such HetNets should couple with reducing power consumption and network interference. To this end, we jointly perform cell activation and selection (CAS) to maximize the network energy efficiency (EE) under users' long-term rate constraints. The formulated problem is in a mixed-integer fractional form and hard to tackle. We need to transform it into a parametric subtractive form, by which we reach its solution through a three-layer iterative algorithm. The first layer searches an EE parameter using a bisection method; the second layer alternately optimizes CAS indices; the third layer solves CS and cell activation (CA) problems using dual decomposition and fixed point iteration, respectively. At last, we give some complexity and convergence analyses for the designed algorithm, and investigate the impacts of different network parameters on system performance. The simulation results show that the CA introduced in CS is a good option to reduce energy consumption and network interference."
  },
  {
    "year": "2017",
    "abstract": "The bank account location (BAL) problem is an NP-hard discrete optimization problem. A few experimental studies have shown that evolutionary algorithms are efficient methods for the BAL problem. However, from theoretical point of view, we know little about the performance of evolutionary algorithms (EAs) on the BAL problem. In this paper, we contribute to theoretical understanding of EAs on the BAL problem. The worst-case bounds on a simple evolutionary algorithm called (1 + 1) EA and a global simple multiobjective evolutionary algorithm called GSEMO for the BAL problem is presented. We reveal that the (1 + 1) EA can find a (k/(2k - 1)) approximation solution for the BAL problem. We also find that GSEMO can obtain an approximate solution on the BAL problem with value not less than (1-(1/e))OPT in expected polynomial runtime O(n2log n + nk2), where OPT is the optimal fitness function value, n is the number of banks that can open accounts, and k is the maximum number of accounts that can be maintained. Meanwhile, we demonstrate that the (1+1) EA and GSEMO are superior to some local search algorithms with interchange neighborhood on an instance, and we also show that GSEMO can efficiently optimize another instance while the (1 + 1) EA may be inefficient."
  },
  {
    "year": "2017",
    "abstract": "Takagi-Sugeno (T-S) fuzzy coronary artery system. We use the T-S fuzzy model to represent the coronary artery system, because the coronary artery system has complicated nonlinear characteristic in reality. Based on the new model, a fuzzy parametric adaptive output feedback controller is designed to achieve the H∞synchronization of coronary artery system with input nonlinearity and parameter perturbations. Some simulation results are given to illustrate the effectiveness of our control strategy."
  },
  {
    "year": "2017",
    "abstract": "It has been envisaged that in future 5G networks user devices will become an integral part by participating in the transmission of mobile content traffic typically through device-to-device (D2D) technologies. In this context, we promote the concept of mobility as a service, where content-aware mobile network edge is equipped with necessary knowledge on device mobility in order to distribute popular mobile content items to interested clients via a small number of helper devices. Toward this end, we present a device-level information centric networking architecture that is able to perform intelligent content distribution operations according to necessary context information on mobile user mobility and content characteristics. Based on such a platform, we further introduce device-level online content caching and offline helper selection algorithms in order to optimize the overall system efficiency. In particular, this paper sheds distinct light on the importance of user mobility data analytics based on which helper selection can lead to overall system optimality. Based on representative user mobility models, we conducted realistic simulation experiments and modeling which have proven the efficiency in terms of both network traffic offloading gains and user-oriented performance improvements. In addition, we show how the framework can be flexibly configured to meet specific delay tolerance constraints according to specific context policies."
  },
  {
    "year": "2017",
    "abstract": "A first-order-filter-based time delay feedback (TDF) controller is proposed to stabilize the buck converter when operating with non-linear phenomena, such as bifurcation and chaos. Compared with the existing second-order filter method, the proposed controller needs only two parameters. This is similar to the ideal TDF controller and it makes the design of the controller simpler. The discrete model of the converter is used to compute one of the two parameters, which is known as the feedback gain. The frequency domain comparison of the proposed controller and the ideal TDF controller shows that the proposed controller is almost non-invasive, because it does not change the dc component of the converter and only changes slightly the harmonic at the switching frequency. The proposed controller has another structure called the extended controller, which needs three parameters. By increasing the third parameter, the feedback gain needs a larger value to stabilize the converter. The benefit of the proposed controller lies in the fact that it does not need the digital circuit that was thought to be necessary for the TDF control of the converter. Simulated and experimental waveforms verify the computation results. The added feedback signal is small enough when the switch turns on."
  },
  {
    "year": "2017",
    "abstract": "The fear of needles and pain prevents some patients from seeking intravitreal treatment, which drives our group to develop a needleless device for performing intravitreal injections. A prototype for an electro-magnetically actuated needleless injector, based on Halbach arrays, is described and characterized in a laboratory setting. The implication of the prototype for needleless ocular drug delivery is investigated. This investigation is intended to improve drug delivery of glaucoma medication with a safe needleless approach. We detail the design aspects of the injector and characterized the device with custom-made phantoms. It was observed that, despite delivering the drug bolus to the center, the viscous vitreous phantom indicated vorticities similar to counter rotating vortex pairs, which could cause damage to the retina. The observed peak velocity during the phantom experiments was 6.1 mm/sec at the retinal layer, indicating that the delivery bolus can impart shear forces to the retina via the vitreous."
  },
  {
    "year": "2017",
    "abstract": "Battery technology is the bottleneck of the electric vehicles (EVs). It is important, both in theory and practical application, to do research on the modeling and state estimation of batteries, which is essential to optimizing energy management, extending the life cycle, reducing cost, and safeguarding the safe application of batteries in EVs. However, the batteries, with strong time-variables and nonlinear characteristics, are further influenced by such random factors such as driving loads, operational conditions, in the application of EVs. The real-time, accurate estimation of their state is challenging. The classification of the estimation methodologies for estimating state-of-charge (SoC) of battery focusing with the estimation method/algorithm, advantages, drawbacks, and estimation error are systematically and separately discussed. Especially for the battery packs existing of the inevitable inconsistency in cell capacity, resistance and voltage, the advanced characterizing monomer selection, and bias correction-based method has been described and discussed. The review also presents the key feedback factors that are indispensable for accurate estimation of battery SoC, it will be helpful for ensuring the SoC estimation accuracy. It will be very helpful for choosing an appropriate method to develop a reliable and safe battery management system and energy management strategy of the EVs. Finally, the paper also highlights a number of key factors and challenges, and presents the possible recommendations for the development of next generation of smart SoC estimation and battery management systems for electric vehicles and battery energy storage system."
  },
  {
    "year": "2017",
    "abstract": "Recent surge in cyber physical systems (CPSs) which integrate cyber and physical worlds, increases security risks at both the surfaces. The wireless sensor communication network is one of the major components of the critical infrastructure in all networked systems including networked control systems and CPSs. As these systems support range of time and data sensitive applications, varying from health care to emergency services, to transport, and to environmental monitoring services, core sensor network component faces potential threats due to varying attacks, including wormhole attack that can cause damage to the control system in terms of data leakage, data dropping, and delayed delivery. It is also difficult to detect, as it requires neither nodes in the network to be compromised nor adversaries to acquire valid network identity to instigate such attacks. Many existing solutions in the literature to detect wormholes are based on node's static location information, synchronization of clocks, use of additional hardware, such as antennas and GPS, and neighborhood and traffic information, which may lead to large energy consumption. In this paper, a scalable and distributed scheme which uses sequential probability ratio test is proposed, to avoid single point failures and to handle high mobility, with no additional resource requirements. It is observed that wormholes are detected using few packets and detection is faster with increasing mobility. The system is highly customizable as system parameters can be chosen to balance the speed and accuracy of detection. System overheads in terms of communication, computation, and storage aspects are analyzed and presented."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the design of a multi-master-single-slave nonlinear tele-robotic system working in the presence of time varying delays. The structure of the proposed tele-robotic system is derived from the extended state convergence architecture and the control objective is defined as the position regulation of the slave manipulator. The desired reference value for the slave manipulator is set by the master systems according to their authority levels. To ensure that the tele-robotic system remains stable in the presence of time varying delays and the control objective is also achieved, Lyapunov-based stability analysis is carried out which results in certain guidelines to be followed for the selection of the control gains. In order to check the validity of the proposed scheme, MATLAB simulations are performed on a two degrees-of-freedom nonlinear tele-robotic system containing three master and single slave manipulators. Simulation results suggest that the proposed scheme is viable and can be deployed to control a class of multilateral nonlinear tele-robotic systems."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with generalized discrete Fourier transform-spread-orthogonal frequency division multiplexing (G-DFT-s-OFDM) waveforms, which replace the cyclic prefix of traditional OFDM/DFT-s-OFDM with an internal guard period. Such waveforms feature significant benefits in terms of flexibility, spectral containment, and low peak-to-average power ratio. Aspects related to reference sequence design and mapping for channel estimation are thoroughly addressed, and a new estimator for the specific zero-tail DFT-s-OFDM case is proposed. Furthermore, we address the opportunity of exploiting the internal guard period at each symbol for frequent channel state information updates, thus enabling the possibility of tracking rapidly varying propagation conditions."
  },
  {
    "year": "2017",
    "abstract": "Distribution systems are inevitably vulnerable to natural disasters, which causes multiple damages within or outside the system. The disruption of supply demands microgrid formation, where the objective is to maximize the restoration of critical loads. The complete restoration requires repair of damaged regions which brings the need for an efficient crew selection, repair time estimation, and crew dispatch. Ranking of load points and location are important considerations for strategic placement of distributed generation units. Prioritization of damaged regions is required for efficient crew dispatch. These ranking depends on multiple criteria based on subjective opinions of the experts. However, the existing methods fail to take account of the same. This paper presents fuzzy approaches which fill the gap present in the existing methods by explaining the theoretical solutions to ranking of load points, locations, crew selection, estimation of repair times, and prioritization of the damaged regions."
  },
  {
    "year": "2017",
    "abstract": "The smart factory of Industry 4.0 has been regarded as a solution for handling the increasing production complexity caused by growing global economy and demand for customized products. Besides, it will make the interactions between humans, machines, and products become a highly competitive area for market capitalization in the near feature. Nowadays, cloud computing with the high performance of computing and self-service access plays an important role in realizing smart factor. To minimize the overall cost of company in a heterogeneous cloud environment, including multiple public clouds, while ensuring a proper level of quality-of-service, task placement across multiple public clouds is a critical problem, where task deadlines and long-haul data transmission costs between smart factory and different clouds must be considered. We formulate this task placement problem as an integer linear program (ILP) to minimize company cost under the task deadline constraint. With extensive simulations, we evaluate the performance of our proposed ILP model in heterogeneous public clouds with finite and infinite resources."
  },
  {
    "year": "2017",
    "abstract": "Complexity is one of the factors, inducing high cost, operational issues, and increased lead time for product realization and continues to pose challenges to manufacturing systems. One solution to reduce the negative impacts of complexity is its assessment, which can help designers to compare and rationalize various designs that meet the functional requirements. In this paper, a systemic approach is proposed to assess complexity of a product’s assembly. The approach is based on Hückel’s molecular orbital theory and defines complexity as a combination of both the complexity of product entities and their topological connections. In this model, the complexity of product entities (i.e., components and liaisons) is defined as the degree to which the entity comprises structural characteristics that lead to challenges during handling or fitting operations. The characterization of entity complexities is carried out based on the widely used DFA principles. Moreover, the proposed approach is tested on two case studies from electronics industry for its validity. The results showed that the approach can be used at initial design stages to improve both the quality and assemblability of products by reducing their complexity and accompanying risks."
  },
  {
    "year": "2017",
    "abstract": "As the main supplier of the workforce to the industry, higher education is increasingly criticized for not being abreast with the digital revolution and being disconnected from the industry. Competency-based education was developed to address this issue and bridge the gap between what the university is producing and the requirements of the industry. Hence, tools need to be developed that assists in the analysis process. This paper focuses on proposing a system that models the competencies required by occupations in the industry and higher education curricula and assists in matching profiles from the two domains. The different concepts in the domain are modeled as a semantic web ontology, and an inference engine performs the profile matching. In addition to the profile matching, the system calculates a score for the matching degree using the analytic hierarchy process (AHP) method."
  },
  {
    "year": "2017",
    "abstract": "A tone-mapped image (TMI) converted from its high-dynamic-range image (HDRI) tends to appear overexposed in its brightest regions or underexposed in its darkest regions, resulting in inevitable loss of details and impaired naturalness and aesthetics. To address this issue, this paper proposes a novel blind TMI quality assessment (BTMIQA) method for HDRIs used in different dynamic range displays. The brightest and darkest regions of the TMI are first defined and segmented, and their local detail features are used in combination with the global detail feature of the TMI to evaluate the detail distortion. The natural scene statistics features of the luminance and yellow channels of the TMI are then used to evaluate the luminance naturalness and chrominance naturalness, respectively. Subsequently, to predict the aesthetics of the TMI, a series of colorfulness features are extracted and concatenated in a final feature vector, which is used to evaluate the TMI quality by random forest regression. Experiments are performed on the TMI database and ESPL-LIVE high-dynamic-range database, and the results show the effectiveness of the proposed method. Compared with the existing TMI quality assessment methods, the proposed BTMIQA method is more consistent with human visual perception."
  },
  {
    "year": "2017",
    "abstract": "Most information technology (IT) equipment found in a data center is air-cooled as electrical component produces heat, which must be removed to prevent the temperature of the IT equipment from rising to an unacceptable level. The energy consumption for the data center cooling system is positively related to the air temperature outside the data center. The difference of data center internal temperature and the outside air temperature varies from each data center location. If we reschedule the workload of Internet cloud services to the least temperature difference, the cooling energy consumption will be the biggest savings. The cooling energy-consumption model and query characteristics of cloud services provide the methodology to formulate the energy consumption and workload rescheduling. However, the cloud service must meet the tail latency constraint after the rescheduling. We solve this problem by estimating the high-percentile tail latency and scheduling the cloud service to where can meet the tail latency constraint. At last, a proactive weather-aware geo-scheduling algorithm, called EC3, is proposed to distribute end-users’ loads among data centers so as to reduce the cooling energy consumption. The trace-driven experiments on real clouds and data center workload traces show the effectiveness of our design for reducing data center cooling consumption."
  },
  {
    "year": "2017",
    "abstract": "Orthogonal frequency division multiplexing (OFDM) signals are characteristically independent and identically distributed Gaussian random variables that follow Rayleigh distribution. The signals also exhibit high peak-to-average power ratio (PAPR) problem due to the infinitesimal amplitude component distributed above the mean of the Rayleigh distribution plot. Since the amplitudes are nonlinearly and nonmonotonically increasing, applying roots to the amplitude distribution is shown in this paper to change the probability density function (PDF) and thus reduces the PAPR. We exemplify these by imposing this constraint on standardμ-law companding (MC) technique in reducing PAPR of OFDM signals, which is known to expand the amplitudes of low power signals only without impacting the higher amplitude signals. This limits the PAPR reduction performance of the MC scheme. Since companding involves simultaneously compressing/expanding high/low amplitude OFDM signals, respectively, in this paper, we refer to the new method as a root-based MC (RMC) scheme that simultaneously expands and compresses OFDM signal amplitudes unlike MC. In addition, we express a second transform independent of the MC model. The results of the two proposed schemes outperform four other widely used companding techniques [MC, log-based modified (LMC), hyperbolic arc-sine companding (HASC) and exponential companding (EC)]. Besides these, we precode the OFDM signals using discrete Hartley transform (DHT) in order to further reduce the PAPR limits achieved by RMC by distorting the phase. While preserving the BER, DHT-precoded RMC outperforms all the four other companding schemes (MC, EC, HASC, LMC) in terms of PAPR."
  },
  {
    "year": "2017",
    "abstract": "The discovery of truth is a critical step toward effective information and knowledge utilization, especially in Web services, social media networks, and sensor networks. Typically, a set of sources with varying reliability claim observations about a set of objects and the goal is to jointly discover the true fact for each object and the trustworthy degree of each source. In this paper, we propose a latent Dirichlet truth (LDT) discovery model to approach this problem. It defines a random field over all the possible configurations of the trustworthy degrees of sources and facts, and the most probable configuration is inferred by a maximum a posteriori criterion over the observed claims. We note that a typical source is usually made of mixed trustworthy and untrustworthy components, since it can make true or false claims on different objects. While most of the existing algorithms do not attempt separate the untrustworthy component from the trustworthy one in each source, the proposed model explicitly identifies untrustworthy component in each source. This makes the LDT model more capable of separating the trustworthy and untrustworthy components, and in turn improves the accuracy of truth discovery. Experiments on real data sets show competitive results compared with existing algorithms."
  },
  {
    "year": "2017",
    "abstract": "The Hausdorff distance (HD) between two point sets is widely used in similarity measures, but the high computational cost of HD algorithms restrict their practical use. In this paper, we analyze the time complexity to compute an accurate Hausdorff distance and find that reducing the iterations of the inner loop significantly contributes in reducing the average time cost. Based on the observation that the nearest neighbor (NN) of the breakpoint in the current inner loop suggests a higher probability to break the next inner loop, we present a novel and efficient approach for computing the accurate Hausdorff distance based on a diffusion search. The current breakpoint is recorded as the diffusion center of the next inner loop so that the efficiency of the HD computation can be significantly improved without scanning every point. According to the type of 3-D model (sparse and dense point sets), a novel HD computation framework consisting of two specific diffusion search methods is proposed. First, a Z-order-based HD algorithm (ZHD) for a sparse point sets is proposed. Second, to avoid the low efficiency of a diffusion search when computing the Hausdorff distance between dense point sets with the ZHD algorithm, an octree-based HD algorithm (OHD) is proposed. Evaluation results demonstrate that the ZHD algorithm and the OHD algorithm can greatly reduce the time complexity of HD computations for sparse and dense point sets, respectively. In addition, we conduct several comparative experiments against the most famous HD computation methods. Experimental results show that the proposed approach achieves performance as good as the most efficient available algorithm and exhibits better performance in dealing with spatial data that is highly overlapping."
  },
  {
    "year": "2017",
    "abstract": "Wastewater treatment process (WWTP) has long been a challenging industrial issue due to its built-in uncertainties and discontinuous measurement of system states. To solve this problem, in this paper, a data-based predictive control (DPC) strategy, based on the available sensing measurements, is proposed to control the dissolved oxygen (DO) concentration in WWTP. First, a self-organizing fuzzy neural network, which can adjust both the structure and parameters simultaneously, is developed to identify the real-time states of WWTP. Second, an improved nonlinear predictive control method is designed to reduce the online computation complexity by transforming the constrained conditions into an unconstrained nonlinear programming problem. Then, an adaptive second-order Levenberg-Marquardt algorithm is developed to derive the control law of DPC. Third, the theoretical analysis on the stability is also given to confirm the prerequisite of any successful application of DPC. Finally, the proposed DPC strategy is applied to the Benchmark Simulation Model No. 1. Experimental results demonstrate that the control performance of the proposed DPC is better than some existing methods."
  },
  {
    "year": "2017",
    "abstract": "With the growing demand for high safety in industrial system, fault diagnosis has attracted more and more attention. Currently, belief rule base (BRB) has shown an excellent performance in modeling complex system, where the expert knowledge is used effectively. Existing BRB models are assumed that the inputs of the attributes are independent and the attribute correlation is not taken into account. However, in some engineering system, there is an obvious correlation among these attributes. The correlated attributes may produce redundant information which limits the abilities of attributes to express the accurate information of system. In this paper, a new BRB model with considering attribute correlation (BRB-c) is proposed. Moreover, a decoupling matrix is introduced to eliminate the redundant information from the attributes. The initial parameters of the decoupling matrix are given according to the expert knowledge. And then, when the inputs of the attributes are available, the parameters in the decoupling matrix are trained by an optimization model. The projection covariance matrix adaption evolution strategy is chosen as an optimization algorithm. A practical case study about fault diagnosis of oil pipeline is conducted and the results show that the BRB-c model can diagnose the leak size and leak time of oil pipeline accurately, which can demonstrate that the proposed model can be widely applied in engineering for fault diagnosis."
  },
  {
    "year": "2017",
    "abstract": "The hydraulically driven fatigue testing machine is studied to simulate the vibration in the fatigue experiments for the insulators. First, hydraulic scheme and control principle are introduced. A special composite cylinder is designed, which is controlled by a servo valve and a proportional relief valve to generate static and dynamic tensional force. Then, models of electro-hydraulic subsystems are analyzed. For the actual needs of the dynamic tensional force system, a high-fidelity force source is of great significance. Considering parameter uncertainty and a high bandwidth of the servo valve pressure dynamics, there is a need to improve the bandwidth of the flow type servo valve as far as possible. Taking into account the limitations of general approaches, this paper proposes load velocity feedback to solve the challenging control issues, which mainly solves the problem of response bandwidth. Finally, a new system controller is designed, and some experiments are developed to verify the feasibility of system principle and the effectiveness of control algorithm. The hydraulically driven fatigue testing machine based on the discussed electro-hydraulic technology has been developed, with satisfactory technical specifications."
  },
  {
    "year": "2017",
    "abstract": "A novel antenna design for wideband operation is presented, consisting of a system of two coupled miniaturized eighth-mode resonant radiating cavities with a low-complexity feeding network. The design methodology relies on the virtual magnetic boundaries along the symmetry planes of a rectangular waveguide resonator, for size reduction, and the frequency bifurcation of two tightly coupled resonators, for bandwidth enhancement. After discussing its operating principle, a prototype targeting wearable applications is designed, manufactured, and validated. Multiband operation is achieved with simultaneous coverage of the 2.4-GHz ISM band and the LTE-7 upand downlink-bands. Measurements in free-space and on-body scenarios validate the antenna's performance. A bandwidth of 414 MHz (16.2%) is measured, as well as a maximal gain of 4.7 dBi. The directive patch-like radiation pattern and the ground plane topology lead to high body-antenna isolation and good on-body performance. Impedance bandwidth and radiation pattern remain stable when the antenna is worn by a person and bent around a cylinder to mimic deformation."
  },
  {
    "year": "2017",
    "abstract": "Internet users consider content information to be useful, but the current Internet approach treats location information as more important as so ties the former to the latter. A Content-Centric Network (CCN) allows the user to obtain content without regard to its location. CCN caches the contents information at its intermediate nodes. The content is searched along the shortest path between the user and the node that has the original content. If any cache node is located on the shortest path, the content can be obtained from the nearest cache node, so far fewer hops are needed compared to the network without any cache node. However, this efficiency is not achieved if no cache node is located on the shortest path. One proposal sets cache nodes that broadcast their contents to surrounding nodes; the user is able to obtain the content from the cache node, rather than the node that has the original content, if the cache node is closer to the user. The location of the cache node affects the number of hops. We formulate an optimization problem that determines the locations of cache nodes to minimize the hop count as an integer linear programming (ILP) problem. Since large ILPs cannot be solved in practical time, we introduce a betweenness centrality (BC) approach that determines the location of cache nodes by computing the BC value of each node and ranks the nodes in descending BC order. The BC value denotes the ratio of the number of shortest paths between source-receiver pairs passing through the node to the total number of shortest paths between source-receiver pairs. Simulations show that the BC approach offers drastically reduced computation time, while the average number of hops is just 5.8% higher than that determined with the ILP approach."
  },
  {
    "year": "2017",
    "abstract": "Time synchronization is becoming a general requirement for wireless sensor networks to wake up sensor nodes and achieve successful communications among the nodes. It is, however, challenging for multi-hop sensor networks to synchronize all the distributed nodes autonomously with minimum power consumption. This paper proposes a low power time synchronization protocol called density table-based synchronization (DTSync). It selects a minimal sequence of synchronization steps by estimating the density of the neighboring nodes and mapping these nodes in a density table. The proposed protocol attempts to minimize the power consumption by reducing the number of messages exchanged among the nodes. We evaluate the proposed protocol using software simulation and then real wireless networks with sensor hardware. Compared with a prior method, such as hierarchy reference broadcast synchronization (HRTS), DTSync achieves substantially fewer synchronization messages and thus lower power consumption. In addition, DTSync is guaranteed to synchronize all nodes in any multi-hop networks, whereas the previous methods are not guaranteed to synchronize all nodes. Simulation experiments demonstrate that DTSync reduces the number of synchronization messages by more than 40 times compared with HRTS for a large network of 1500 node."
  },
  {
    "year": "2017",
    "abstract": "A tool to estimate the ray-tracing component of the surveyed depth uncertainty was created and made publicly available through Web services and a Web geographic information system. The estimation is based on a spatial variability analysis at the time of validity of two popular, global-scope sources of oceanographic environmental data. The tool has potential applications in all the phases of ocean mapping, from survey planning to data collection and processing."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a comprehensive comparative study for the tracking control of a class of underactuated nonlinear uncertain systems. A given nonlinear model of the underactuated system is, at first stage, transformed into an input output form and the driving applied control input of the transformed system is then designed via four sliding mode control strategies, i.e., conventional first order sliding mode control, second order sliding mode, fast terminal sliding mode, and integral sliding mode. At second stage, a ball and beam system is considered and the aforementioned four control design strategies are experimentally implemented. A comprehensive comparative study of the simulation and experimental results is then conducted which take into account the tracking performance, i.e., settling time, overshoots, robustness enhancement, chattering reduction, sliding mode convergences, and control efforts."
  },
  {
    "year": "2017",
    "abstract": "The development of an anomaly-based intrusion detection system (IDS) is a primary research direction in the field of intrusion detection. An IDS learns normal and anomalous behavior by analyzing network traffic and can detect unknown and new attacks. However, the performance of an IDS is highly dependent on feature design, and designing a feature set that can accurately characterize network traffic is still an ongoing research issue. Anomaly-based IDSs also have the problem of a high false alarm rate (FAR), which seriously restricts their practical applications. In this paper, we propose a novel IDS called the hierarchical spatial-temporal features-based intrusion detection system (HAST-IDS), which first learns the low-level spatial features of network traffic using deep convolutional neural networks (CNNs) and then learns high-level temporal features using long short-term memory networks. The entire process of feature learning is completed by the deep neural networks automatically; no feature engineering techniques are required. The automatically learned traffic features effectively reduce the FAR. The standard DARPA1998 and ISCX2012 data sets are used to evaluate the performance of the proposed system. The experimental results show that the HAST-IDS outperforms other published approaches in terms of accuracy, detection rate, and FAR, which successfully demonstrates its effectiveness in both feature learning and FAR reduction."
  },
  {
    "year": "2017",
    "abstract": "Vehicle detection and counting in aerial images have become an interesting research focus since the last decade. It is important for a wide range of applications, such as urban planning and traffic management. However, this task is a challenging one due to the small size of the vehicles, their different types and orientations, and similarity in their visual appearance, and some other objects, such as air conditioning units on buildings, trash bins, and road marks. Many methods have been introduced in the literature for solving this problem. These methods are either based on shallow learning or deep learning approaches. However, these methods suffer from relatively low precision and recall rate. This paper introduces an automated vehicle detection and counting system in aerial images. The proposed system utilizes convolution neural network to regress a vehicle spatial density map across the aerial image. It has been evaluated on two publicly available data sets, namely, Munich and Overhead Imagery Research Data Set. The experimental results show that our proposed system is efficient and effective, and produces higher precision and recall rate than the comparative methods."
  },
  {
    "year": "2017",
    "abstract": "Considering the reliability of the cloud computing system, this paper aims to predict the security state with multiple large-scale attributes in cloud computing system. A double-layer method for predicting the security state of cloud computing system based on the belief rule-base model is proposed, where the evidential reasoning (ER) algorithm is employed to fuse the multiple system indicators of actual cloud system and make a reasonable assessment to describe the cloud security state. This method can utilize quantitative and qualitative information simultaneously. By using the ER algorithm to integrate multiple indicators whose attributes contain much uncertain information, the security state of the cloud computing system can be predicted accurately. Moreover, due to the initial parameters of the proposed models are given by experts that might cause imprecise results, the constraint CMA-ES algorithm is employed as the optimization tool to obtain the optimal parameters. A practical study about the cloud security-state prediction is verified to indicate the potential applications about the proposed prediction model in a cloud computing platform."
  },
  {
    "year": "2017",
    "abstract": "Green computing is a growing trend in computing, pursuing the goal of helping software developers to be more aware and produce energy-efficient software. This is especially relevant for battery-powered mobile applications, where a minimal energy consumption is desired to both mitigate the greenhouse effect and extend the battery lifetime. In this paper, we analyze the energy consumption and execution time of cryptographic primitives in Android devices. Our ultimate goal is to help Android application developers, especially those who are not experts in security, to choose the most energy-efficient cryptographic algorithms considering different security providers and security transformations. Information to make a tradeoff between energy and time consumption is also provided, being especially useful when the differences in energy consumption of different alternatives are not so significant. We have conducted our experiments with an energy profiling tool based on the PowerTutor application, which has been adapted to automate the energy profiling. Our results show that this type of power consumption studies is necessary, because selecting the most energy-efficient configuration depends on many factors, and some of the choices are not obvious to developers."
  },
  {
    "year": "2017",
    "abstract": "In this work, a mm-Wave vertically-polarized electric dipole array solution for 5G wireless devices is presented. The dipole is fabricated using vias in a standard PCB process to fit at the phone or tablet edges featuring wideband operation with broad half-power beamwidth in the elevation plane (HPBWELEV), high gain and high front-to-back radiation ratio (F/B). For enhanced gain, parasitic-vias are added in front of the dipole as directors. To improve HPBW without sacrificing gain, the directors are implemented as V-shaped bisection parasitic-vias. A via-fence surrounds the dipole structure to suppress back radiation and enhance F/B. The dipole is connected to a parallel-strip line (PS) which is interfaced to the main SIW feed through a novel SIW-to-PS transition. Thorough investigation, optimization, and parametric study are provided for each design parameter of the proposed structure. A single dipole, 2 x 1, and 4 x 1 arrays were designed and fabricated showing close agreement between the simulated and measured results. The single-dipole operates over 7.23-GHz bandwidth with stable radiation performance. The 4x1 array achieves HPBWELEVof 133.1°, F/B of 36.6-dB, cross-polarization less than -39.6-dB and 12.61-dBi gain with 95.8% radiation efficiency. The low cost, compactness, and good performance of the proposed dipole make it a competing candidate for the future 5G mobile devices transceivers."
  },
  {
    "year": "2017",
    "abstract": "Spatial data clustering has played an important role in the knowledge discovery in spatial databases. However, due to the increasing volume and diversity of data, conventional spatial clustering methods are inefficient even on moderately large data sets, and usually fail to discover clusters with diverse shapes and densities. To address these challenges, we propose a two-phase clustering method named KMDD (clustering by combining K-means with density and distance-based method) to fast find clusters with diverse shapes and densities in spatial databases. In the first phase, KMDD uses a partition-based algorithm (K-means) to cluster the data set into several relatively small spherical or ball-shaped subclusters. After that, each subcluster is given a local density; to merge subclusters, KMDD utilizes the idea that genuine cluster cores are characterized by a higher density than their neighbor subclusters and by a relatively large distance from subclusters with higher densities. Extensive experiments on both synthetic and real-world data sets demonstrate that the proposed algorithm has a near-linear time complexity with respect to the data set size and dimension, and has the capability to find clusters with diverse shapes and densities."
  },
  {
    "year": "2017",
    "abstract": "This paper implements and compares a symmetric hybridized cascaded multilevel inverter and an asymmetric multilevel inverter utilizing a switched capacitor unit for 17 level inverters. The symmetric hybridized multilevel inverter topology consists of a modified H-bridge inverter, which results in an increase in the output voltage to five level from the three level by using a bi-directional switch at the midpoint of a dual-input dc source. In the proposed asymmetric multilevel inverter, dc sources are replaced with the switched capacitor unit, which in turn boosts the output voltage and produces twice the voltage levels at the loads. The proposed topology with the staircase modulation technique has been verified using MATLAB-SIMULINK, and the results are experimentally executed with prototype models, which are interfaced with dSPACE RTI 1104. The results of the proposed topologies are experimentally obtained for steady state, and the performance of the same is tested under different resistive and inductive load disturbance conditions. The results substantiate that these multilevel inverter topologies are better stabilized during load disturbance conditions with low total harmonic distortion, a lesser number of switches, and increased output voltage levels, and these topologies well suit for renewable energy applications."
  },
  {
    "year": "2017",
    "abstract": "As an emerging voice of the customer (VOC) containing feedback, such as opinions and expectations about products, social media data have the potential use for product improvement and new product development. However, most prior studies have focused on determining customer concerns, while neglecting to incorporate them into a systematic approach to identify product opportunities. In response, this paper suggests an approach to identify product opportunities from customer reviews in social media. This approach employs topic modeling to identify the product topics discussed by customers from largescale review posts related to a given product. A keygraph is then constructed based on the co-occurrences among the topics contained in each post. The chance discovery theory is then applied to generate new product opportunities from the chance nodes obtained from the keygraph. Our approach contributes to the systematic ideation process for product opportunity analysis based on large-scale and real-time VOC."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a new topology of switched reluctance motor (SRM) drives for plug-in hybrid electric vehicles. Six operating modes can be achieved as a result. Three of those modes are applied for driving and the others for charging. During the driving mode, the topology can be converted to a fourlevel one. During the charging mode, two battery packs are charged in parallel with the boost circuit by the external ac source or generators. The main contributions of the proposed topology are as follows. First, a four-level converter is formed by adopting different ways of connection (series or parallel) of the two battery packs (or the two capacitors), which can accelerate the excitation and demagnetization procedures of SRMs. Moreover, the topology contributes to decreasing the switching losses and extending the constant torque region to improve the drive performance as well. Second, the state of charge of the two battery packs (or the voltages of two capacitors) can keep balance on their own by parallel operation of the two battery packs. Furthermore, a detailed comparison between two drive modes of the proposed topology and asymmetric half bridge inverters is undertaken with simulation and experimental studies, the results of which demonstrate the validity of the proposed topology."
  },
  {
    "year": "2017",
    "abstract": "With respect to other routing paradigms, source routing has received comparatively less attention in the underwater acoustic networking domain. The most likely causes of this lack of momentum are the high overhead caused by route discovery and maintenance in typical implementations of the source routing paradigm (e.g., dynamic source routing) in terrestrial radio networks. In this paper, we revert this view and argue that source routing can in fact be a reliable and convenient routing paradigm in underwater networks, when properly implemented and tailored to the peculiarities of underwater acoustic channels. Our scheme, named SUN, successfully recasts the source routing approach by introducing a number of new features, which improve the routing performance especially in the presence of unstable network links and mobile nodes. SUN is scenario-independent by design: this means that it can work in any connected topology, and does not need any side information (such as the node location and depth, or the channel state) in order to operate correctly. We evaluate the performance of SUN by means of simulations using the DESERT Underwater framework. Our results show that SUN correctly manages routing in both static and mobile networks, and that in some scenarios it even achieves better performance than a competing flooding-based approach. We also test the performance of SUN in a thorough experimental campaign involving six nodes and carried out in a lake near Berlin. From these results, we conclude that SUN, and the source routing paradigm in general, are in fact feasible options for general-purpose routing in underwater acoustic networks."
  },
  {
    "year": "2017",
    "abstract": "We propose a novel frame rate up-conversion algorithm, which adaptively selects multiple motion estimation (ME) schemes to generate absent frames according to the space-time saliency. We first use a space-time saliency classifier to determine which frames are most important to a human observer. Based on the varying saliency over time, we adopt high-cost ME scheme on high-salient frame but low-cost ME scheme on low-salient frame. Automatic switch of multiple ME schemes takes human visual attention into consideration, so that unnecessary computations cannot be invested into the frames of no interest. Experimental results show that our algorithm provides a better visual interpolation quality, while removing some redundant computations."
  },
  {
    "year": "2017",
    "abstract": "The problem of controller design is investigated to achieve the mean-square asymptotic synchronization of discrete-time neural networks with time-varying delay and restricted disturbances. The unreliable communication links between the neural networks, which are modeled as stochastic dropouts satisfying the Bernoulli distributions, are taken into account. By applying the Lyapunov function, a synchronization controller design method is proposed in the form of linear matrix inequalities. The design method is also extended to neural networks including modeling uncertainties. Two numerical examples are given to illustrate the effectiveness of the proposed methods."
  },
  {
    "year": "2017",
    "abstract": "The accuracy of user location information is inversely proportional to the user's privacy preserving degree k, and is proportional to quality of query service. In order to balance the conflict between privacy preserving security and query quality caused by the accuracy of location information, a clustering algorithm aiming at eliminating outliers based on the k-anonymity location privacy preserving model is proposed, which is used to realize the establishment of anonymous group in the anonymous model. The distribution of user in the anonymous group is optimized. The idea of replacing the user location query by the center of the anonymous group is proposed. The number of repeated queries is reduced, and the quality of query service is improved on the premise of ensuring security through the experimental analysis and comparison with other schemes."
  },
  {
    "year": "2017",
    "abstract": "The sequence comparison of large-scale string-typed data is fundamental in computer science and other computational disciplines. Its development has been promoted into an emerging outsourcing service by the almost unlimited powerful computing and storage capabilities from public clouds. The privacy preservation and effective utility of the outsourced sensitive information are key requirements now facing this service. All of the secure two-party computation protocols in existing solutions, however, cannot be free from the assumption of non-colluding servers under multi-server models, and thus fail to defend against some attacks from cloud service providers. For this reason, we present encrypted sequence comparison (E-SC), the first security system that works by executing encrypted sequence comparison under a single-server model. Two character sequences are encrypted by end users before outsourcing, while the encrypted character sequences are compared directly by a single cloud server to return their similarity results. To accomplish this goal, novel computable encryption algorithms are designed in this paper. Then, a collusion-resistant outsourcing is achieved using non-interactive padding, partition, and expansion mechanisms. Results of simulation experiments demonstrate that the client-side overhead is quadratic in the input number of salt values, along with an optimal server-side performance. Also, the overall runtime of our E-SC system is positively correlated with its security level, which is more practical in realistic applications."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel secure data transmission scheme using chaotic compressed sensing, which has inherent encryption property without additional cost, is proposed based on a T-way Bernoulli shift chaotic system. In the proposed scheme, the Bernoulli chaotic sensing matrix (BCsM) is generated by the Bernoulli shift chaotic sequence. We prove that the BCsM meets the restricted isometry property with overwhelming probability, which guarantees good sensing performance. Compared with the state-of-the-art sensing matrices, such as the Gaussian sensing matrix, the BCsM has low complexity and is easily implemented in hardware. Meanwhile, we investigate the recovery performance, robustness, and security of the proposed scheme and show that the proposed scheme can ensure efficient secure data transmission against additive noise and malicious attacks. The proposed scheme is perfectly effective for large-scale, long-term data transmission with high energy efficiency and strong security."
  },
  {
    "year": "2017",
    "abstract": "The world is experiencing a new industrial revolution characterized by intelligent manufacturing. Cyber-physical production systems (CPPSs) have become a research focus due to their proposed use as a solution to the development of flexible and reactive systems. The application of current centralized scheduling methods is difficult because of the enhanced precision control mode of a CPPS. Therefore, this paper focuses on distributed optimal scheduling based on multi-agent systems. First, the goals and constraints of the system are set, a two-layer decision model and the required indicators are designed to ensure the overall optimization effect, and the roles and functions of different agents are then set. Second, the dynamic decision cycle and the multistage negotiation mechanism based on the contract net protocol are studied to ensure the quality of negotiation. A rescheduling algorithm is designed to guarantee adaptability in the case of disturbance in the system. Finally, the applicability and superiority of the strategies are demonstrated via experiments and case studies."
  },
  {
    "year": "2017",
    "abstract": "The scarcity of bandwidth due to the explosive growth of mobile devices in 5G makes the offloading messaging workload to Wi-Fi devices that use opportunistic connections, a very promising solution. Communications in mobile opportunistic networks take place upon the establishment of ephemeral contacts among mobile nodes using direct communication. In this paper, we propose an analytical model based on population processes to evaluate data dissemination considering several parameters, such as user density, contact rate, and the number of fixed nodes. From this model, we obtain closed-form expressions for determining the diffusion time, the network coverage, and the waiting time. Newer 5G wireless technologies, such as WiGig, can offer multi-gigabit speeds, low latency, and security-protected connectivity between nearby devices. We therefore focus our work on the impact of high-speed and short-range wireless communications technologies for data dissemination in mobile opportunistic networks. Moreover, we test whether the coexistence with a fixed infrastructure can improve content dissemination, and thus justify its additional cost. Our results show that, when user density is high, the diffusion is mainly performed through the opportunistic contacts between mobile nodes, and that the diffusion coverage is close to 100%. Moreover, the diffusion is fast enough to dynamically update the information among all the participating members, so users do not need to get closer to fixed spots for receiving updated information."
  },
  {
    "year": "2017",
    "abstract": "The ability to access individual layers of a part as they are being printed has allowed additive manufacturing (AM) researchers to experiment with the in situ placement of components, thereby creating multi-process parts with additional functionality, such as customized printed electronics. As AM has evolved to become an established method for creating end-use parts, this interest in multi-process printing has increased. Although progress has been made in developing multi-process hardware, which can combine AM with other technologies, holistic design software, capable of readily integrating these processes, is developing at a slower rate. In this paper, an integrated software solution capable of supporting multi-process 3D printing from design through manufacture is described, featuring the integration of electronic components and circuits interconnected by copper wires. This solution features automated generation of the cavities that accommodate electronic components as well as toolpath generation for a multi-process 3D printer capable of automated wire embedding. As a case study of the developed technology, a hexagonal 3D printed body, which included a microcontroller, four LEDs, a USB connector, two resistors, and a Zener diode, all interconnected by embedded copper wires, was fabricated within a short cycle time: 5.75 h from design to fabricated part. Short cycle times allow multiple design iterations to be realized and printed within the same day."
  },
  {
    "year": "2017",
    "abstract": "Numerous radar polarimetry theories and polarimetric synthetic aperture radar (PolSAR) processing methods have been developed. However, the vast majority of SAR images are not fully polarimetric (full-pol). This paper proposes “radar image colorization”to reconstruct a full-pol image from a nonfull-pol image, so that existing PolSAR methods, such as model-based decomposition and unsupervised classification, can be directly applied to the reconstructed full-pol SAR images. It proposes to train a specially designed deep neural network to convert a single polarization gray-scale SAR image to full-pol. It consists of two components: a feature extractor network to extract hierarchical multi-scale spatial features of the grayscale SAR image, followed by a feature translator network to map spatial feature to polarimetric feature with which the polarimetric covariance matrix of each pixel can be reconstructed. Both qualitative and quantitative experiments with real full-pol data are conducted to show the efficacy of the proposed method. The reconstructed full-pol SAR image agrees well with the true full-pol image, not only in the sense of visual similarity but also in the sense of real PolSAR applications, such as target decomposition and terrain classification."
  },
  {
    "year": "2017",
    "abstract": "A fuzzy model predictive control scheme based upon adaptive neural network disturbance observer is proposed for the longitudinal dynamics of a constrained hypersonic vehicle (HV) in the presence of diverse disturbances. First, an equivalent disturbed fuzzy dynamic model with the varying parameters is constructed to approximate the nonlinear dynamics, where the inevitable lumped disturbances, including the fuzzy modeling error, extraneous disturbances, and model uncertainties caused by aerodynamic uncertainties, need to be suppressed. Subsequently, according to the parameter-dependent Lyapunov function, the proposed scheme taking the varying parameters into account is developed to explicitly handle the constraints of fuel equivalence ratio, elevator deflection, and angle of attack. Furthermore, based on the strong nonlinear approximation ability of neural network (NN), an adaptive neural network disturbance observer with the adaptive laws of NN's weight matrixes is established to estimate lumped disturbances, and then an additional compensator formulated by integrating the estimations of lumped disturbances and the corresponding compensation gain matrix is appended to the proposed method for suppressing the lumped disturbances directly. Finally, the comparative simulation results for tracking the reference commands of velocity and altitude demonstrate that the proposed method provides a satisfactory tracking performance even when HV is in the presence of lumped disturbances and constraints."
  },
  {
    "year": "2017",
    "abstract": "The line junction detection is a fundamental step in many computer vision applications, especially in biomedical image analysis. Most of the existing studies determine the junction position after delineating curvilinear structure, thus the detection accuracy relies heavily on the previous steps for curvilinear extraction, such as image segmentation and skeletonization. In this paper, we treat the detection of line junctions as an independent task without prior knowledge of curvilinear structures. We present the mathematical definition and properties of line junctions, and propose a new method called Junction Recognition (JUNR). It first maps the raw images into score matrices (or called score images) by the measurements based on line junction properties, then detects and screens blobs from the score images for identifying the regions covering junction points. Finally, it refines the locations of line junctions as well as their branch properties. A distinct advantage of JUNR is that it can be directly applied to raw images without knowing curvilinear structure beforehand. Besides, since JUNR is a rule-based method, it requires no training data and avoids the labor-intensive labeling work. We conducted experiments on two typical kinds of biomedical images, including both simulated and real images with curvilinear structures. Both qualitative and quantitative results demonstrate its good performance for junction detection and characterization."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a price-based approach for offloading macro users to small-cells in a two-tier heterogeneous network (HetNet). We have constructively exploited the small-cell density in a HetNet to harness offloading opportunities for macro users (MUs), the goal of which is to solve two problems simultaneously. It aims to shun the MUs, who have a lower received data rate due to the interference perceived from the small-cell tier. The scheme also fends off congestion in a macrocell, by offloading macro users to the small-cell tier. We have proposed a novel threshold pricing scheme, which a macrocell adopts, with a view to influencing low data rate MUs to join a small-cell network. Small-cell networks also charge a price, which includes an access price and an interference compensation price, proportional to the number of MUs who choose the small-cells instead of the macrocellular network. We assume that the small-cells adopt existing cell range expansion techniques to accommodate MUs. We formulate an evolutionary game to model and analyze the behavioral dynamics of the large number of MUs under the proposed pricing strategies of both networks. Replicator dynamics is used to find the evolutionary equilibrium of the evolutionary game. Sequentially, we provide the proof of the existence, uniqueness and stability of the evolutionary equilibrium through extensive analysis. Numerical results are provided to demonstrate that the proposed pricing strategies are able to shape the network dynamics by fine-tuning the rate-threshold and price. The ability to control the macrocell population share by itself with an application of the proposed pricing scheme remains the prime contribution of this paper."
  },
  {
    "year": "2017",
    "abstract": "One of the major open problems in computer vision is feature detection in visually impaired images. In this paper, we describe a potential solution using phase stretch transform, a new computational approach for image analysis, edge detection and resolution enhancement that is inspired by the physics of the photonic time stretch technique. We mathematically derive the intrinsic nonlinear transfer function and demonstrate how it leads to: 1) superior performance at low contrast levels and 2) a reconfigurable operator for hyper-dimensional classification. We prove that the phase stretch transform equalizes the input image brightness across a range of intensities resulting in high dynamic range in visually impaired images. We also show further improvement in the dynamic range by combining our method with the conventional techniques. Finally, our results propose a new paradigm for the computation of mathematical derivatives via group delay dispersion operations."
  },
  {
    "year": "2017",
    "abstract": "A centralized infrastructure system carries out existing data analytics and decision-making processes from our current highly virtualized platform of wireless networks and the Internet of Things (IoT) applications. There is a high possibility that these existing methods will encounter more challenges and issues in relation to network dynamics, resulting in a high overhead in the network response time, leading to latency and traffic. In order to avoid these problems in the network and achieve an optimum level of resource utilization, a new paradigm called edge computing (EC) is proposed to pave the way for the evolution of new age applications and services. With the integration of EC, the processing capabilities are pushed to the edge of network devices such as smart phones, sensor nodes, wearables, and on-board units, where data analytics and knowledge generation are performed which removes the necessity for a centralized system. Many IoT applications, such as smart cities, the smart grid, smart traffic lights, and smart vehicles, are rapidly upgrading their applications with EC, significantly improving response time as well as conserving network resources. Irrespective of the fact that EC shifts the workload from a centralized cloud to the edge, the analogy between EC and the cloud pertaining to factors such as resource management and computation optimization are still open to research studies. Hence, this paper aims to validate the efficiency and resourcefulness of EC. We extensively survey the edge systems and present a comparative study of cloud computing systems. After analyzing the different network properties in the system, the results show that EC systems perform better than cloud computing systems. Finally, the research challenges in implementing an EC system and future research directions are discussed."
  },
  {
    "year": "2017",
    "abstract": "Phthalates are common plasticizers found in many everyday products, including adhesives, plastics, flooring, cosmetics, and electronics. Phthalates are generally incorporated into materials to enhance their flexibility and durability. However, most phthalates used in electronics are low-molecular-weight orthophthalates that have been shown to have serious health effects, and as a result, ortho-phthalates are becoming regulated. This paper presents the chemistry of ortho-phthalates, their usage in the electronics industry, and potential alternatives to phthalate plasticizers, including bio-based substitutes and thermoplastic elastomers."
  },
  {
    "year": "2017",
    "abstract": "Infrared image segmentation is a useful and challenging research subject due to its inherent limitations, such as complicated noises, vague edges, and low contrast in infrared images. Active contour models have a wide range of applications for infrared image segmentation. A gradient vector flow (GVF) model and other external force field models have been proposed to improve the noise robustness and weak edge protection to a certain extent. To further address these issues, this paper presents a novel edge-preserving active contour model using guided filter and harmonic surface function for infrared image segmentation. Guided filter is applied to obtain the edge map, reducing the noise interference effectively and collecting more detailed information of the infrared images such as the edges. Then, a harmonic surface function is added into the smoothness term to make the proposed model possess both the abilities of fast convergence and weak edge protection. Besides, we incorporate the information of external force field into the proposed model to preserve the weak boundaries. Compared with adaptive diffusion flow, the proposed method has increased 4% and 2% in precision and F1 measure, respectively."
  },
  {
    "year": "2017",
    "abstract": "With the exponential rise in the number of devices, the Internet of Things (IoT) is geared toward edge-centric computing to offer high bandwidth, low latency, and improved connectivity. In contrast, legacy cloud-centric platforms offer deteriorated bandwidth and connectivity that affect the quality of service. Edge-centric Internet of Things-based technologies, such as fog and mist computing, offer distributed and decentralized solutions to resolve the drawbacks of cloud-centric models. However, to foster distributed edge-centric models, a decentralized consensus system is necessary to incentivize all participants to share their edge resources. This paper is motivated by the shortage of comprehensive reviews on decentralized consensus systems for edge-centric Internet of Things that elucidates myriad of consensus facets, such as data structure, scalable consensus ledgers, and transaction models. Decentralized consensus systems adopt either blockchain or blockchainless directed acyclic graph technologies, which serve as immutable public ledgers for transactions. This paper scrutinizes the pros and cons of state-of-the-art decentralized consensus systems. With an extensive literature review and categorization based on existing decentralized consensus systems, we propose a thematic taxonomy. The pivotal features and characteristics associated with existing decentralized consensus systems are analyzed via a comprehensive qualitative investigation. The commonalities and variances among these systems are analyzed using key criteria derived from the presented literature. Finally, several open research issues on decentralized consensus for edge-centric IoT are presented, which should be highlighted regarding centralization risk and deficiencies in blockchain/blockchainless solutions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a mobile terminal phased array at 28 GHz with different scan angles is compared with a switch diversity antenna array at 28 GHz in the case of antenna beams pointing at the user's body. In the switch diversity antenna array, there is only one element out of eight operating each time. The paper is carried out in data mode with a standing user, which includes both body blockage and user hand effects. The metrics of coverage efficiency, antenna shadowing power ratio, and isotropic antenna shadowing power ratio are utilized in the investigation. It is found that the scan angle of a phased array higher than 90° is not necessary for this scenario, because the user body will contribute to the total radiation at large angles by scattering the radiated energy around the body. For the linear phased antenna arrays on the edge of the mobile device ground plane, it can be concluded that in order to achieve the highest coverage efficiency and lowest user shadowing it is more beneficial to use a phased array instead of a switch diversity array. However, if the losses of the phase shifters and the feeding network from the phased array are higher than 5 dB, the switch array can be used, which will also decrease the complexity of a system."
  },
  {
    "year": "2017",
    "abstract": "Data privacy protection is crucial to cloud computing since privacy leakage may prevent users from using cloud services. To ensure data privacy, we propose PriGuarder, a novel privacy-aware access control method. This method spans the three stages of a cloud service, i.e., user registration, data creation, and data access. At each stage, users can choose two modes to interact with the cloud service provider, i.e., direct or indirect. With the indirect mode, an attribute fuzzy grouping scheme is introduced to ensure user identity privacy and attribute privacy in all the three stages. Furthermore, exploiting data encryption and timestamp techniques, new access control protocols are proposed to regulate interactions between users and the cloud service provider. We illustrate the use of our method in the context of Amazon S3. Theoretical analysis and comprehensive simulation experiments have been conducted, which demonstrate the efficacy of PriGuarder."
  },
  {
    "year": "2017",
    "abstract": "There is increasing interest in deploying swarms of underwater vehicles for marine surveys. One of the main challenges when designing these systems is coming up with an appropriate way to localize each vehicle in relation to one another. This paper considers the self-localization of a deforming swarm of subsurface floating vehicles using impulsive sources of opportunity, such as the sounds of snapping shrimp that are present in warm coastal waters. Impulsive sound sources provide high intensity, broadband signals that facilitate accurate arrival time detections across each vehicle. This makes them useful references for a self-localization solution. However, the similarity between different signals presents a significant correspondence problem, which must be solved to provide accurate estimates of the changing geometry of the swarm. A geometric solution to this correspondence problem is shown and an optimization procedure is proposed to track the geometry of a swarm as it changes. The method is verified using a swarm of 17 self-ballasting subsurface floats that independently drifted with currents off of the coast of San Diego, California. The changing geometry of the floats was estimated using both an acoustic localization system and the proposed approach. The two estimates show good agreement, validating our method. We believe that this new localization strategy is useful for high endurance, low power, and multi-vehicle surveys."
  },
  {
    "year": "2017",
    "abstract": "Nearest neighbor search is a fundamental problem in various domains, such as computer vision, data mining, and machine learning. With the explosive growth of data on the Internet, many new data structures using spatial partitions and recursive hyperplane decomposition (e.g., k-d trees) are proposed to speed up the nearest neighbor search. However, these data structures are facing big data challenges. To meet these challenges, binary hashing-based approximate nearest neighbor search methods attract substantial attention due to their fast query speed and drastically reduced storage. Since the most notably locality sensitive hashing was proposed, a large number of binary hashing methods have emerged. In this paper, we first illustrate the development of binary hashing research by proposing an overall and clear classification of them. Then we conduct extensive experiments to compare the performance of these methods on five famous and public data sets. Finally, we present our view on this topic."
  },
  {
    "year": "2017",
    "abstract": "With the rapid increase of vehicular Internet of things applications, it is urgent to design a mobile edge computing architecture, which is possible to distribute and process a large amount of contents with vehicles on the road. From a communication perspective, the current cellular technology faces challenges due to the limited bandwidth in a dense vehicle environment. In this paper, we propose a multi-access edge computing framework and the corresponding communication protocol which integrates licensed Sub-6 GHz band, IEEE 802.11p, and millimeter wave (mmWave) communications for the content distribution and processing in vehicular networks. The proposed protocol uses a cluster-based approach, where a fuzzy logic-based algorithm is employed to select efficient gateway nodes which bridge the licensed Sub-6 GHz communication and the mmWave communication in order to maximize the overall network throughput. IEEE 802.11p vehicle-to-vehicle communication is used to share information among vehicles in order to achieve efficient clustering. We conduct extensive simulations to evaluate the performance of the proposed protocol under various network conditions. Simulation results show that the proposed protocol can achieve significant improvements in various scenarios compared with the existing approaches."
  },
  {
    "year": "2017",
    "abstract": "Limited range of emerging delivery vehicles, specifically unmanned aerial systems, creates gaps in last mile retail distribution networks and excludes significant numbers of potential customers. Implementing a two-stage distribution process is one approach that eliminates this deficit. However, dispatchers must load the vehicles hauling orders in the initial stage of the process and assign orders for delivery to transfer points in a way that ensures timely arrival while utilizing only the minimum required resources. This paper investigates the capacitated transfer point covering problem which has, until now, been unstudied. The research proposes a mathematical programming model to provide an optimal solution. The model is then applied to a realistic delivery situation using a distribution case study on the eastern coast of the U.S. and solved using a commercial optimization software. The results are analyzed, insights provided, and areas are identified for future research."
  },
  {
    "year": "2017",
    "abstract": "In smart cities, there are always unpredicted emergencies, which must be handled to maintain the regular order. Then a smart system is needed to detect threats and deal with them. In this paper, we propose a system structure composed of a central agent and three layers: unmanned aerial vehicle (UAV) layer, multirobot layer and sensor network layer. The UAVs act as moving sensors and conveyors in the air. They provide the overall rough monitoring data from the air and transport robots to the emergency occurring places. The robots on the ground are responsible for obtaining detailed monitoring data and dealing with the emergencies. The sensor networks keep monitoring the environment and assist robots and UAVs in the range to complete their tasks. The central agent can adjust the system according to the specific task requirements. We provide a general system design and review main required technologies, highlighting the challenges and some possible solutions. The future researching directions are presented to guide the system design."
  },
  {
    "year": "2017",
    "abstract": "Recently, femtocells are expected to be densely deployed to meet the booming demands for wireless data traffic, which inevitably causes serious co-layer interference due to the unplanned deployment. Hence, how to efficiently combat interference while furthest guaranteeing the quality of service (QoS) becomes an open question. To address this issue, in this paper, we present a joint admission control and a resource allocation strategy for an orthogonal frequency-division multiple access-based femtocell network. Particularly, we consider the scenario, where users are classified into two types, of which high priority ones have priority to access the network and enjoy high-resolution video streams. To perfectly eliminate the colayer interference with limited spectrum while maximizing the number of users whose QoS requirements can be guaranteed, we formulate an integer nonlinear programming problem, followed by a graph-based algorithm with polynomial computational complexity to solve it. The basic principle behind the proposed algorithm is to first chordalize the given conflict graph, and then perform admission control with priority differentiation-based admission control sub-algorithm, followed by the final resource block assignment with maximum effect rank allocation sub-algorithm. Furthermore, we illustrate how our proposal could be implemented in the long-term evolution system. Finally, through extensive simulations, we show that our proposal outperforms other two schemes in terms of guaranteeing QoS requirements."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a method based on the active shape model (ASM) to segment the prostate in magnetic resonance (MR) images. Due to the great variability in appearance among different boundaries of the prostate and among subjects, the traditional ASM is weak in MR image prostate segmentation. To address these limitations, we investigated a novel ASM-based method by incorporating deep feature learning into our previous liver segmentation framework. First, an adaptive feature learning probability boosting tree (AFL-PBT) based on both simple handcrafted features and deep learned features was developed for prostate pre-segmentation and for further shape model initialization. The proposed AFL-PBT classifier also provided a boundary searching band, which made the ASM less sensitive to model initialization. Then, the convolutional neutral network (CNN) deep learning method was used to train a boundary model, which separated voxels into three types: near, inside, and outside the boundary. A three-level ASM based on the CNN boundary model was employed for the final segmentation refinement. On MICCAI PROMISE12 test data sets, the proposed method yielded a mean Dice score of 84% with a standard deviation of 4%. The experimental results demonstrated that the proposed method outperformed other ASM-based prostate MRI segmentation methods and achieved a level of accuracy comparable to that of state-of-the-art methods."
  },
  {
    "year": "2017",
    "abstract": "Content caching at the base stations (BSs) is a promising strategy that can provide improved quality-of-service (QoS) provisioning for content-centric services, and at the same time reduce instantaneous backhaul payload. This paper focuses on the applications of the caching mechanism in the downlink of coordinated multipoint (CoMP) transmission, where the collaborating BSs cooperatively serve the user equipments (UEs). A cache-aided transmission scheme for downlink CoMP with limited local cache resources at the BSs is proposed to improve QoS provisioning in terms of outage performance. In order to cache files more efficiently while guaranteeing the QoS, the contents are divided into two sets, a popular set and a less popular set, according to their popularity profile following the Zipf model. The popular files are cached at all the BSs, while the less popular files are cached only at part of the BSs in a cache cluster subject to the strategy design. Furthermore, based on the popularity of the requested files, UEs are categorized into two groups and the notion of request competition between the two groups is introduced. The corresponding request competition model and admission probabilities for transmission requests are analyzed. Based on the request competition model, the best cache placement strategy for the popular and less popular sets that minimizes the average outage probability is derived. Numerical results show that the proposed cache-aided CoMP scheme outperforms the baseline traditional caching strategies in terms of the average transmission outage."
  },
  {
    "year": "2017",
    "abstract": "Active learning for networked data that focuses on predicting the labels of other nodes accurately by knowing the labels of a small subset of nodes is attracting more and more researchers because it is very useful especially in cases, where labeled data are expensive to obtain. However, most existing research either only apply to networks with assortative community structure or focus on node attribute data with links or are designed for working in single mode that will work at a higher learning and query cost than batch active learning in general. In view of this, in this paper, we propose a batch mode active learning method which uses information-theoretic techniques and random walk to select which nodes to label. The proposed method requires only network topology as its input, does not need to know the number of blocks in advance, and makes no initial assumptions about how the blocks connect. We test our method on two different types of networks: assortative structure and diassortative structure, and then compare our method with a single mode active learning method that is similar to our method except for working in single mode and several simple batch mode active learning methods using information-theoretic techniques and simple heuristics, such as employing degree or betweenness centrality. The experimental results show that the proposed method in this paper significantly outperforms them."
  },
  {
    "year": "2017",
    "abstract": "The robot manipulator system is a complicated system with multiple-input and multiple-output, high nonlinearity, strong coupling, and uncertainties, such as parameter disturbances, external interference, and unmodeled dynamics. A robust adaptive Takagi-Sugeuo-Kang fuzzy cerebellar model articulation controller (RATFC) is proposed and applied to a robot manipulator to achieve high-precision position and speed control. A Takagi-Sugeuo-Kang fuzzy cerebellar model articulation controller is adopted, and the parameters are regulated by the derived adaptable rules according to a Lyapunov function. The robust compensation controller mitigates approximation-based errors. Finally, simulation results show that the proposed RATFC can achieve improved tracking performance compared with other neural network controllers."
  },
  {
    "year": "2017",
    "abstract": "Due to the impressive performance and computational efficiency of correlation filter (CF)based object tracking methods, CF trackers have gained lots of popularity in recent years. However, target drift and tracking failure caused by background clutter and target appearance change (resulting from scale variation and deformation and so on) are still challenging tasks. To overcome these challenges, we propose a new tracking method within the CF framework in this paper. First, we learn a large margin CF by exploiting discriminative background patches. Contrary to conventional CF trackers that aim to maximize target response, we model a tracker that maximizes the margin between the target and surrounding background by exploiting background information effectively. To remedy the deficiency in handling target scale variation of CF-based trackers, we propose to train a CF by multi-level scale supervision, which aims to make CF sensitive to the target scale variation. Then, we integrate the two individual modules into one framework to simplify our tracking model. The proposed method can effectively prevent tracking module degradation introduced by target appearance changes. Extensive experiments conducted on public available data sets OTB-50/100 demonstrate that the proposed tracking method is robust to the background clutter and discriminative to the target scale variation. Both qualitative and quantitative results show the excellent performance against some state-of-the-art trackers."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose an efficient approach that computes the dynamic time warping (DTW) distance in time-series similarity search. The DTW distance is known to offer the high accuracy in similarity search, but it has difficulty in supporting the large database due to its high computational complexity. Recently, FastDTW and FTW have been proposed for efficient computation of DTW distances, but they have still performance limitations. In this paper, we propose a hybrid approach, called HybridFTW, which combines the advantages of both FastDTW and FTW. First, HybridFTW takes the advantage of FastDTW that provides fast computation through the limitation of allowable ranges. We call these allowable ranges dynamic (warping) bands, which reduce the computation spaces on the fly, and we reanalyze previous FastDTW and FTW in the viewpoint of static and dynamic bands. Second, HybridFTW also takes the advantage of FTW that exploits the early abandon effect by using the segment-based tight lower bound. To maximize the synergy of combining two methods, we obtain the dynamic band of FastDTW during the process of computing the lower bound in FTW. Using HybridFTW, we next propose range search and k-NN search algorithms and prove their correctness through formal theorems. Experimental results on real and synthetic data sets show that HybridFTW improves the search performance by up to 38 times over FastDTW and by up to 12 times over FTW."
  },
  {
    "year": "2017",
    "abstract": "Large-scale data centers play a vital role in supporting the ever growing demand for computation and storage. These data centers often employ commodity hardware switches with shallow buffers arranged in a multi-rooted tree topology. Many-to-one traffic communication pattern is often observed in a data center whereby many servers simultaneously send requested data to an aggregation server. This may result in excessive congestion on the bottleneck switch, overwhelming the shallow switch buffer and resulting in large number of packet drops. Legacy transmission control protocol (TCP) treats a packet drop as an indication of severe congestion in the path and forces the sender to drastically reduce its sending rate. This leads to the phenomena of TCP incast resulting in severe throughput collapse deteriorating the performance of the data center. Many solutions have been proposed in literature that addresses the TCP incast issue by either tweaking TCP parameters or proposing a modified/custom version of TCP to be used in data centers. Recently, software-defined networking (SDN) has gained the attention of researchers due to the ease of centralized control and programmability of the network. The centralized nature of SDN presents an opportunity to address the TCP incast issue in data center networks in an efficient manner. This paper provides a snapshot of research efforts that leverage the capabilities of SDN to mitigate the effect of congestion in data centers. We provide a taxonomy of the existing solutions, discuss complementary concepts and highlight their relative strengths along with their shortcomings."
  },
  {
    "year": "2017",
    "abstract": "Fractional order characteristics (FOCs) have been shown to be useful in the predict degradation trend of rotating machinery. In this paper, a novel prognostics methodology based on improved R/S statistic and fractional Brownian motion (FBM) for rolling bearing degradation process is proposed. Due to the fact that bearing health indicators, such as equivalent vibration intensity (EVI), often exhibit non-stationary and non-Gaussian traits, the FOC methodology normally involves the estimation of a parameter Hurst H; the improved R/S statistic technique with auto-covariance estimator was introduced to address the issue that the calculation of the Hurst exponent by classical R/S methods is sensitive to heteroskedasticity and short-range dependence. Furthermore, a slow degrading process of a rolling bearing can be predicted by a common FOC model, but the actual sharp transition points (STPs) of the degradation are often very difficult to track. The main purpose of a rolling bearing degradation prediction is to prognosticate and track the STP's trend when the failure occurs between the normal phase and the incipient degradation phase. A method that combined FBM and Brownian motion is presented when the forecasted points contaminated with STPs, in which the predicting operator, driven by a new stochastic differential equation and its computationally efficient algorithm, are explored. The experimental results show that the proposed approach can better predict the EVI degradation trend than traditional FOC and other time series models."
  },
  {
    "year": "2017",
    "abstract": "This paper presents new challenges for the real-time scheduling of distributed reconfigurable embedded systems powered by a renewable energy. Reconfigurable computing systems have to deal with unpredictable events from the environment, such as activation of new tasks and hardware or software failures, by adapting the task allocation and scheduling in order to maintain the system feasibility and performance. The proposed approach is based on an intelligent multiagent distributed architecture composed of: 1) a global agent “coordinator” associated with the whole distributed system and 2) four local agents, such as supervisor, scheduler, battery manager, and reconfiguration manager, belong to each subsystem. The efficiency and completeness of the reconfiguration adaptative strategy is proved as all possible reconfiguration forms are considered to guarantee a feasible system with a graceful quality of service. Two communication protocols, such as an intra-subsystem communication protocol and an inter-subsystem communication protocol, are proposed to ensure the effectiveness of the proposed reconfiguration strategy. Extensive simulations show the effectiveness of the proposed intelligent multiagent distributed architecture in terms of the number of exchanged messages, deadline success ratio, and the energy consumption."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) is a promising technology which tends to revolutionize and connect the global world via heterogeneous smart devices through seamless connectivity. The current demand for machine-type communications (MTC) has resulted in a variety of communication technologies with diverse service requirements to achieve the modern IoT vision. More recent cellular standards like long-term evolution (LTE) have been introduced for mobile devices but are not well suited for low-power and low data rate devices such as the IoT devices. To address this, there is a number of emerging IoT standards. Fifth generation (5G) mobile network, in particular, aims to address the limitations of previous cellular standards and be a potential key enabler for future IoT. In this paper, the state-of-the-art of the IoT application requirements along with their associated communication technologies are surveyed. In addition, the third generation partnership project cellular-based low-power wide area solutions to support and enable the new service requirements for Massive to Critical IoT use cases are discussed in detail, including extended coverage global system for mobile communications for the Internet of Things, enhanced machine-type communications, and narrowband-Internet of Things. Furthermore, 5G new radio enhancements for new service requirements and enabling technologies for the IoT are introduced. This paper presents a comprehensive review related to emerging and enabling technologies with main focus on 5G mobile networks that is envisaged to support the exponential traffic growth for enabling the IoT. The challenges and open research directions pertinent to the deployment of massive to critical IoT applications are also presented in coming up with an efficient context-aware congestion control mechanism."
  },
  {
    "year": "2017",
    "abstract": "The telecare medical information systems (TMISs) provide the convenience to the patients/users to be served at home. Along with such ease, it is essential to preserve the privacy and to provide the security to the patients/users in TMIS. Often, authentication protocols are adopted to guarantee privacy and secure interaction between the patients/users and remote server. Recently, Chaudhry et al. pointed out that Islam et al.'s scheme based on smart card is prone to user impersonation and server impersonation attacks. Chaudhry et al. later presented an enhanced scheme based on elliptic curve cryptography to remedy the weaknesses of Islam et al.'s scheme. Unfortunately, we find some important limitations in both schemes. We remark that their scheme is prone to off-line password guessing attack, user/server impersonation attack, and man-in-middle attack. To overcome these limitations, we present an improved authentication scheme keeping apart the threats encountered in the design of Chaudhry et al.'s scheme. Moreover, the presented scheme can also resist all known attacks. We prove the security of the proposed scheme with the help of widespread Burrows-Abadi-Needham logic. A brief comparison with the previous works provides that the presented protocol is more efficient and more secure than other related schemes."
  },
  {
    "year": "2017",
    "abstract": "Network function virtualization (NFV) has become an emerging issue in both academia and industry. By outsourcing network functions from dedicated hardware to virtualization platform, NFV promises to significantly improve the scalability and flexibility of network management and orchestration. One of the main challenges for NFV deployment is to realize coordinated service function chaining on NFV-based infrastructures. This challenge is referred to as the coordinated NFV resource allocation (coordinated NFV-RA) problem which is proved to be NP-hard. In order to response timely to the service variation, many heuristic or meta-heuristic algorithms are proposed to reduce the computing complexity. However, it is very difficult to evaluate the approach degree between obtained sub-optimal solutions and the optima, since finding the optimal solution is a non-trivial task. In this paper, a novel modeling approach called homogeneous link mapping is proposed to find the optimal solutions of a typical threestage coordinated NFV-RA model with CPLEX. Then we further establish a service function chain (SFC) deployment database with optimal solutions and the results in the database can be used as a criterion to evaluate other SFC algorithms. In order to imitate different practical networks, the SFC deployments are conducted on three type network topologies. And we also analyze the SFC deploying performance on different topologies. At Last, we make the optimal modeling approach open source, and upload the database on http: //www.opensource5g.org/database."
  },
  {
    "year": "2017",
    "abstract": "The Turing pattern formation is modeled by reaction-diffusion (RD) type partial differential equations, and it plays a crucial role in ecological studies. Big data analytics and suitable frameworks to manage and predict structures and configurations are mandatory. The processing and resolution procedures of mathematical models relies upon numerical schemes, and concurrently upon the related automated algorithms. Starting from a RD model for vegetation patterns, we propose a semi-automatic algorithm based on a smart numerical criterion for observing ecological reliable results. Numerical experiments are carried out in the case of spot's formations."
  },
  {
    "year": "2017",
    "abstract": "Different operation phases in batch processes cover distinguishing behaviors, so establishing statistical models for each identical phase become an effective way for batch monitoring. In this paper, a new adaptive phase partition and online fault detection method is proposed, which can track the phase's transition by time sequence and has less reliance on parameters' selection. The discussion and analysis of this proposed method follows. In this proposed method, the information contained in every sample time will be evaluated, and the change tendency of feature is demonstrated on a batch prospect. Then, two control bounds are designed for the feature tendency, the stable, and the transitional phases that have a different feature level and play certainly roles in process operation, will be identified automatically. For online monitoring, the new fault detection strategy is composed of modeling the PCA and PLS statistical methods for each identified phase, three statistics are established to ensure the data-decomposing reliable. The proposed method is applied to the industrial penicillin fermentation process, and the experimental result shows better performance in phase partition and fault detection."
  },
  {
    "year": "2017",
    "abstract": "Network-on-chip (NoC) is an emerging alternative to address the communication problem in embedded system-on-chip designs. One of the key and major issues is the optimized mapping of the embedded applications on the underlined NoC platform. In this paper, we propose the bandwidth-constrained multi-objective segmented brute-force mapping (SBMAP) algorithm, which minimizes the communication energy consumption and reduces the computational complexity of the NoC designs. The algorithm generates efficient mapping of the embedded applications on the processing elements of the NoC system by segregating the application into multiple segments. It utilizes the property of modular systematic search, which produces high-performance results with optimized simulation time. We compared the SBMAP algorithm with the state-of-the-art mapping techniques, such as branch and bound (BB), near-optimal mapping (NMAP), and random mapping algorithms for mapping real-world application workloads. The experimental results validated the efficiency of the proposed algorithm against its competitors for most of the performance parameters of the NoC designs. The improvement in energy consumption of the SBMAP algorithm is up to 53% for 2-D mesh and 62% for torus topology as compared with the NMAP, BB, and random algorithms for video object plane decoder, picture in picture, Wi-Fi receiver, and multimedia system real-time application benchmarks."
  },
  {
    "year": "2017",
    "abstract": "In order to meet different data rate and timeliness requirements of different services in aeronautical network communications based on frequency and time-hopping mechanism, a hybrid media access control protocol based on pre-allocation of transmission time slots and immediate access is proposed. It is based on network capacity simulation analysis of burst service frames, channel immediately access capability is reserved for high-priority service frames, and time slot pre-allocation strategies and network access permissions are designed for middle- and low-priority service frames. Time sensitive demand of high-priority service frames is guaranteed, and transmission of middle- and low-priority service frames to the greatest extent is ensured at the same time. The simulation results verify the effectiveness of the protocol."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we present a comprehensive channel modeling and characterization study for underwater visible light communications. Our study is based on the advanced ray tracing, which allows for an accurate description of the interaction of rays emitted from the lighting source within an underwater environment. Contrary to existing works, which are mainly limited to simplified underwater scenarios, i.e., empty sea, we take into account the presence of human and man-made objects to investigate the effects of shadowing and blockage. The reflection characteristics of the sea surface and sea bottom as well as the water characteristics, i.e., extinction coefficient and scattering phase function of particles, are precisely considered. As case studies, we consider various underwater scenarios with different transmitter/receiver specifications (i.e., viewing angle, aperture size) and different depths from the sea surface. For each environment, we obtain channel impulse responses and present a characterization study where channel parameters, such as channel DC gain, path loss, and delay spread, are obtained."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes two major novelties. First, we provide a mathematical framework for hardware resource efficient IP core-based image compression and decompression (CODEC). The framework includes CODEC functions that are capable of determining the pixel intensities of a compressed gray scale image using significantly lesser hardware resources. Digital pixel values of the original image are fed as an input to the functions of proposed IP framework and compressed digital pixel values of compressed image generated. Similarly, digital pixel values of the compressed image are fed into other functions of the proposed framework for image decompression. Second, the second novelty is using the derived IP functions to propose designs of reusable IP cores for complete Haar wavelet transformation (HWT)-based lossy image CODEC. Testing of images from various data sets (NASA, medical applications, and so on) in terms of hardware resources, image quality, and compression efficiency have indicated that the proposed IP core framework was successful in achieving hardware efficient CODEC compared with JPEG and conventional HWT CODECs."
  },
  {
    "year": "2017",
    "abstract": "In remote medical diagnosis, the percentage of poor-quality fundus images is very high, which requires automated quality assessment of fundus images in the acquisition stage to reduce the retransmission cost. In this paper, we propose a fundus image quality classifier via the analysis of illumination, naturalness, and structure, which use three effective secondary indices (or 5-D feature set) and different classification methods to determine the recommendation indexes of fundus images for further diagnosis. We construct a fundus image database including `accept' and `reject' classes based on the definition of illumination, naturalness, and structure. The model can achieve a sensitivity of 94.69%, specificity of 92.29%, and accuracy of 93.60% for the classifying of the fundus images."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a modeling method based on MATLAB/Simulink for a temperature-dependent SiC MOSFET in the entire working region was proposed. Using a supplementary test circuit, the output characteristics of a device in the saturated region were extracted. Based on these characteristics, the model covered the output characteristics of the device in the whole working region. From the output curves, three main parameters essential for modeling were derived. Based on the Si lateral double-diffused MOSFET model, a temperature-dependent static model of SCT20N120 was established by adding a temperaturedependent compensation voltage source to simulate the temperature characteristics of the threshold voltage and a temperature-dependent compensation current source to compensate for the drain current error in the linear region due to the differences in structure and material between Si and SiC. In addition, based on the gate equivalent circuit, the dynamic model of the target device was established. The temperature-dependent static simulation results could simulate the actual measured values well. Furthermore, based on the comparison between the dynamic simulation results involving the device's turn-on and turn-off process losses and the actual transient state losses derived from a double-pulse test under the conditions of Vds= 300 V, Id= 15 A, Rg_exton= 18 Ω, and Rg_extoff= 12 Ω at 200 °C, the maximum error was 6.7%."
  },
  {
    "year": "2017",
    "abstract": "Text reuse occurs when one borrows the text (either verbatim or paraphrased) from an earlier written text. A large and increasing amount of digital text is easily and readily available, making it simpler to reuse but difficult to detect. As a result, automatic detection of text reuse has attracted the attention of the research community due to the wide variety of applications associated with it. To develop and evaluate automatic methods for text reuse detection, standard evaluation resources are required. In this paper, we propose one such resource for a significantly under-resourced language-Urdu, which is widely used in day to day communication and has a large digital footprint particularly in the Indian subcontinent. Our proposed Urdu short text reuse corpus contains 2684 short Urdu text pairs, manually labeled as verbatim (496), paraphrased (1329), and independently written (859). In addition, we describe an evaluation of the corpus using various state-of-the-art text reuse detection methods with binary and multi-classification settings and a set of four classifiers. Output results show that character n-gram overlap using J48 classifier outperform other methods for the Urdu short text reuse detection task."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) now permeates our daily lives, providing important measurement and collection tools to inform our every decision. Millions of sensors and devices are continuously producing data and exchanging important messages via complex networks supporting machine-to-machine communications and monitoring and controlling critical smart-world infrastructures. As a strategy to mitigate the escalation in resource congestion, edge computing has emerged as a new paradigm to solve IoT and localized computing needs. Compared with the well-known cloud computing, edge computing will migrate data computation or storage to the network “edge”, near the end users. Thus, a number of computation nodes distributed across the network can offload the computational stress away from the centralized data center, and can significantly reduce the latency in message exchange. In addition, the distributed structure can balance network traffic and avoid the traffic peaks in IoT networks, reducing the transmission latency between edge/cloudlet servers and end users, as well as reducing response times for real-time IoT applications in comparison with traditional cloud services. Furthermore, by transferring computation and communication overhead from nodes with limited battery supply to nodes with significant power resources, the system can extend the lifetime of the individual nodes. In this paper, we conduct a comprehensive survey, analyzing how edge computing improves the performance of IoT networks. We categorize edge computing into different groups based on architecture, and study their performance by comparing network latency, bandwidth occupation, energy consumption, and overhead. In addition, we consider security issues in edge computing, evaluating the availability, integrity, and the confidentiality of security strategies of each group, and propose a framework for security evaluation of IoT networks with edge computing. Finally, we compare the performance of various IoT..."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the problem on stochastic exponential robust stability for a class of complex-valued interval neural networks with Markova jumping parameters and mixed delays, including both time-varying delays and continuously distributed delays. By applying the M-matrix theory and coupling with the vector Lyapunov function method, some sufficient conditions are derived to guarantee the existence, uniqueness, and stochastic exponential robust stability of the equilibrium point of the addressed system. The obtained results not only are easy to judge the dynamical behavior of the addressed system, but also are with lower level conservatism in comparison with some existing results. Finally, two numerical examples with simulation results are given to illustrate the effectiveness of the proposed results."
  },
  {
    "year": "2017",
    "abstract": "Ad-hoc networks have long been studied as an ideal technology to provide communications in emergency operations when network infrastructures are not available. Nevertheless, this area has not yet delivered enough mature technologies or working prototypes. We suspect that, among other issues, this is due to a lack of understanding of this application domain that forces researchers to make too many assumptions. One of those concerns is the mobility of network nodes. This paper describes, analyzes, and simulates the mobility traces of a fire department during 30 wildfires. The analysis shows interesting insights into the communication range and the type of network in these scenarios. For instance, multi-hop routes are unlikely, so the network behaves like a delay-tolerant network. In addition, the simulation results present a clear image of the network performance under different circumstances that can be used to design applications. We found that the network capacity is low due to the sparse network connectivity. Moreover, the buffer size has a much bigger impact on data delivery than the delay-tolerant routing protocol selected. We think that these are valuable insights and that the traces constitute an important asset for the research community."
  },
  {
    "year": "2017",
    "abstract": "The emergence of mobile edge computing enables many new mobile applications to run with relatively low costs by offloading the modules to nearby edge clouds. The edge cloud always and has limited resources and serves multiple users in the proximity. As a result, it is important to partition the computations between the mobile devices and the edge cloud, and meanwhile allocate the resources for multiple users with the aim of maximizing the average performance of the users. Existing optimization methods are usually costly in time especially when the number of users is large. In this paper, we propose a parallel method for achieving high efficiency as well as good performance in multi-user mobile edge computation partitioning. Our proposed method divides the users into small groups, and performs the genetic algorithm for the groups in parallel to find the in-group optimal solutions. By iteratively allocating the resources among the groups, the method converges to a near-optimal solution in global. Through extensive simulations, we show that our parallel method significantly reduces the execution time while guaranteeing competitive performance in average throughput compared with the benchmark algorithm."
  },
  {
    "year": "2017",
    "abstract": "In order to improve the accuracy of bearings fault diagnosis, one of the most crucial components of rotating machinery, a novel features extraction procedure incorporating an improved features dimensionality reduction method is proposed. In the first step, using the empirical mode decomposition method, the original statistical characteristics were calculated from intrinsic mode functions of the vibration signal. Due to information redundancy of the original statistical characteristics, this paper presents a novel features extraction method that combines K-means method and standard deviation to select the most sensitive characteristics. Furthermore, a modified features dimensionality reduction method is proposed, to realize the low-dimensional representations for high-dimensional feature space. Finally, the performance of the fault diagnosis model is evaluated by vibration signals with 12 bearing fault conditions, which are provided by Bearing Data Center of Case Western Reserve University. Experiment results show that the proposed fault diagnosis model can serve as an effective and adaptive bearing fault diagnosis system."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the analytical design techniques of several reflection-type group delay (GD) circuits (types-I-III) with arbitrarily prescribed wideband flat GD responses using λ/4-coupled lines. The type-I GD circuit consists of the λ/4 transmission lines and an open-circuited coupled line with a short-circuited load, whereas type-II consists of a short-circuited coupled line with an open-circuited load. For a compact circuit size, the type-III circuit is realized by a parallel combination of the open-circuited and short-circuited coupled lines. To obtain the arbitrarily prescribed response of wideband flat GD, closed-form analytical design equations are provided. An analytical analysis shows that the wideband flat GD response can be obtained by controlling the appropriate evenand odd-mode impedances of the coupled lines. For an experimental validation of the proposed structures, prototypes of the three GD circuits were designed and fabricated at the center frequency of 2.5 GHz. To realize a higher GD response over a wideband bandwidth, a number of reflection-type GD circuit units are cascaded and measured. The measurement results agree soundly with the simulation and theoretical prediction results."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a new approach for multiple access in the fifth generation (5G) of cellular networks called power domain sparse code multiple access (PSMA) is proposed. In PSMA, we adopt both the power domain and the code domain to transmit multiple users' signals over a subcarrier simultaneously. In such a model, the same sparse code multiple-access (SCMA) codebook can be used by multiple users, where, for these users, the power domain non-orthogonal multiple access (PD-NOMA) technique is used to send signals non-orthogonally. Although the signal of different SCMA codebooks can be detected orthogonally, the same codebook used by multiple users produces interference over these users. With PSMA, a codebook can be reused in the coverage area of each base station more than one time, which can improve the spectral efficiency. We investigate the signal model as well as the receiver and transmitter of the PSMA method. In the receiver side, we propose a message passing algorithm-based successive interference cancellation detector to detect the signal of each user. To evaluate the performance of PSMA, we consider a heterogeneous cellular network. In this case, our design objective is to maximize the system sum rate of the network subject to some system level and QoS constraints such as transmit power constraints. We formulate the proposed resource allocation problem as an optimization problem and solve it by successive convex approximation techniques. Moreover, we compare PSMA with SCMA and PD-NOMA from the performance and computational complexity perspective. Finally, the effectiveness of the proposed approach is investigated using numerical results. We show that by a reasonable increase in complexity, PSMA can improve the spectral efficiency about 50% compared with SCMA and PD-NOMA."
  },
  {
    "year": "2017",
    "abstract": "How and why cooperation is able to prevail in social dilemma situations is an intensely investigated subject with much relevance for the well-being of human societies. Many mechanisms that promote cooperation have been identified within the theoretical framework of evolutionary game theory. Here, we advance the subject by relaxing the simplified assumption that each player in the population has the same number of interaction neighbors. This assumption indeed contradicts actual conditions, and it is, thus, important to understand what consequences this has for the evolution of cooperation. We therefore take into consideration that replacement and interaction neighbors can differ, and moreover, that each player can randomly select the number of interaction neighbors. The results of Monte Carlo simulations reveal that the introduction of neighborhood diversity elevates the level of cooperation in various types of social dilemmas, including the prisoner's dilemma and the snowdrift game. We also show that the same mechanism of cooperation promotion remains valid in evolutionary multigames. Taken together, our results strongly support the assertion that diversity, in general, is a strong facilitator of cooperation even under the most testing conditions and they provide a rationale for engineering better social systems."
  },
  {
    "year": "2017",
    "abstract": "Space-time network coding (STNC) is a time-division multiple access (TDMA)-based scheme that combines network coding and space-time coding by allowing relay nodes to combine the information received from different source nodes during the transmission phase and to forward the combined signal to a destination node in the relaying phase. However, STNC schemes require all the relay nodes to overhear the signals transmitted from all the source nodes in the network. They also require a large number of timeslots to achieve full diversity in a multipoint-to-multipoint transmission. Both conditions are particularly challenging for large cellular networks where, assuming a downlink transmission, base stations (BSs) and users only overhear a subset of all the BSs. In this paper, we exploit basic knowledge of the network topology in order to reduce the number of time-slots by allowing simultaneous transmissions from those BSs that do not overhear each other. Our results show that these topology-aware schemes are able to increase the spectral efficiency per time-slot and bit error rate with unequal transmit power and channel conditions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the performance of three transmit antenna selection (TAS) schemes for an energy harvesting decode-and-forward relay cooperative network. In the network, the energy-limited relay first harvests the energy from the received signal with the power-splitting scheme, and then utilizes the harvested energy to forward the received signal to the destination. Specifically, exact analytical expressions for the outage probability of the considered network with three TAS schemes are derived for evaluating the impact of key parameters on the outage performance. In order to deeply extract insights, we further present tractable asymptotic outage probabilities for three TAS schemes to characterize the diversity order and coding gain in high signal-to-noise ratio regimes, respectively. In addition, we also analyze the impact of feedback delays on the performance of the optimal TAS scheme, which is quantified by the reduction of diversity order and coding gain. Numerical results sustained by Monte Carlo simulations demonstrate that: 1) the second suboptimal TAS schemes achieve a comparable performance as the optimal TAS scheme with the reduced implementation cost; 2) the relay location has a great impact on the outage performance and the optimal power-splitting ratio; and 3) the feedback delay plays a critical role in determining the diversity order achieved by the considered system."
  },
  {
    "year": "2017",
    "abstract": "Today there is considerable interest for making use of the latest technological advancements for several healthcare applications. However, there are several challenges for making use of different technologies for healthcare applications. In particular, there is a need to ensure that the healthcare related services receive priority during events, such as legitimate failures of devices, congestion, and attacks in the networks. In this paper, we discuss some of the requirements for making use of technology for healthcare applications and propose techniques for secure monitoring of patients with wandering behavior in a hospital or elderly care environment. One of the aims of our work is to use technology for secure monitoring of patients with wandering behavior to keep them away from danger, or detect if the behavior of the patient violates the policies of the hospital, or even violates privacy policies of other patients. Our approach makes use of software defined networking (SDN), Wireless LAN (WLAN), and wearable devices for the patients. Our approach incurs low cost since WLAN is widely deployed. However, there are some challenges for making use of WLAN for monitoring dementia patients, since it is primarily used for accessing the Internet and its open nature is vulnerable to different types of security attacks. Hence we make use of SDN to solve some of these challenges and provide priority for the monitoring services. We have developed a security application for an SDN controller that can be used to enforce fine granular policies for communication between the hosts, real time location tracking of the patients, and deal with attacks on the hospital networks. The policy-based security enforcement helps to differentiate healthcare related traffic from other traffic and provide priority to the healthcare traffic. The real time location tracking detects wandering by patients and if necessary can raise alarms to the staff. The attack detection component makes use of attac..."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel opportunistic spectrum access protocol, namely the primary receiver assisted interference avoidance (PRA-IA) protocol, is proposed and analyzed in cognitive radio (CR) networks to simultaneously exploit the underutilized positions of the primary network and avoid transmission collisions among secondary transmitters (STs). Particularly, the proposed PRA-IA protocol is comprised of two processing phases, i.e., the qualification phase and the contention phase. The qualification phase is designed to preselect the set of STs (denoted by eligible STs) which are in the “spatial holes”of the active primary receivers to guarantee the primary transmissions. The contention phase, on the other hand, aims to improve the performance of secondary transmissions by further resolving the potential collisions among the eligible STs based on the randomly generated backoff timer. With mathematical tools from stochastic geometry, the transmission probability of active STs, the coverage probability, and thereby the spatial throughput of the CR network under the PRA-IA protocol are characterized and analyzed. Furthermore, simulations are provided to verify the accuracy of the derived analytical results and demonstrate the impacts of key network parameters on network performance. From the numerical results, it is shown that the proposed PRA-IA protocol is superior to the PRA protocol on the spatial throughput tradeoff of the primary and secondary networks."
  },
  {
    "year": "2017",
    "abstract": "In the cloud computing environment, the source-level energy consumption (EC) estimation is employed to approximately measure the EC of a cloud computing task before it is executed. The EC estimation on tasks is critical to task scheduling and source-code improvement in the aspect of EC optimization. The existing studies treat a task as a program, and EC of the task as the simple summation of each statement's EC. However, EC of two tasks consisting of the same statements with different structures is unequal; therefore, the code structure should be highlighted in source-level EC estimation. In this paper, an abstract energy consumption (AEC) model, which is static and runtime-independent, is proposed. For the model, the two quantitative measurements, “cross-degree”and “reuse-degree,”are proposed as the code structure features, and the relationship between EC and the measurements is formulated. Although AEC is not a precise EC measurement, it can properly represent the EC of a task, compare with other tasks, and verify the optimization effect. Experimental results show that the ratios between the EC and AEC with 50 test cases are stable; the standard deviation is 0.0002; and the mean value is 0.005. The regularities of EC and code structures, represented as “cross-degree”and “reuse-degree,”are also validated. Though AEC, it is easier to schedule the cloud computing tasks properly and further reduce the consumed energy."
  },
  {
    "year": "2017",
    "abstract": "Brain storm optimization (BSO) is a young and promising population-based swarm intelligence algorithm inspired by the human process of brainstorming. The BSO algorithm has been successfully applied to both science and engineering issues. However, thus far, most BSO algorithms are prone to fall into local optima when solving complicated optimization problems. In addition, these algorithms adopt complicated clustering strategies, such as K-means clustering, resulting in large computational burdens. This paper proposes a simple BSO algorithm with a periodic quantum learning strategy (SBSO-PQLS), which includes three new strategies developed to improve the defects described above. First, we develop a simple individual clustering strategy that sorts individuals according to their fitness values and then allocates all individuals into different clusters. This reduces computational burdens and resists premature convergence. Second, we present a simple individual updating strategy by simplifying the individual combinations and improving the step size function to enrich the diversity of newly generated individuals and reduce redundancy in the pattern for generating individuals. Third, a quantum-behaved individual updating with periodic learning (QBIU-PL) strategy is developed by introducing a quantum-behaved mechanism into SBSO-PQLS. QBIU-PL provides new momentum, enabling individuals to escape local optima. With the support of these three strategies, SBSO-PQLS effectively improves its global search capability and computational burdens. SBSO-PQLS is compared with seven other BSO variants, particle swarm optimization, and differential evolution on CEC2013 benchmark functions. The results show that SBSO-PQLS achieves a better global search performance than do the other nine algorithms."
  },
  {
    "year": "2017",
    "abstract": "Wideband spectrum sensing is an important aspect of cognitive radio systems. In current models of wide spectrum sensing, a discrete frequency denotes a continuous frequency band. This type of model is divorced from practice and cannot reflect the reality of spectrum occupation. In this paper, we propose a novel wideband spectrum sensing scheme in terms of a modulated wideband converter (MWC) and sparse Bayesian learning (SBL). By exploiting the MWC, a practical wideband signal denoted by a block-sparse model is sampled to acquire the compressed measurements. We then employ SBL to directly extract the relevant information from the compressed measurements for estimating the support set. The estimated support set is chosen as the test statistic to facilitate spectrum sensing and analyze the detection performance. For applications in actual situations of support sets, different matching criteria are presented according to the requirements imposed by wideband spectrum sensing. Finally, we analyze the detection performance when a frequency band's location is given as well as when it is randomly generated by conducting simulations. These simulations show that the proposed method outperforms the MWC-based orthogonal matching pursuit method, and the best performance can be achieved under matching criterion 3."
  },
  {
    "year": "2017",
    "abstract": "It is a great challenge to find an optimal one-wafer cyclic schedule for a single-arm multicluster tool that is widely adopted in semiconductor fabrication. Aiming to tackle this significant problem, an optimal scheduling strategy is determined first for each individual tool under the condition that the bottleneck individual tool is transport-bound. Then, by developing a Petri net model with robot waiting being explicitly described to reveal the properties of the entire system, this paper shows that to schedule such a tool optimally is to allocate the robot waiting time properly. Then, this paper presents the necessary and sufficient conditions for the existence of an optimal one-wafer cyclic schedule. Thereafter, an efficient algorithm is developed to check the given conditions and find such a schedule efficiently if existing. Finally, two industrial examples are used to verify that the proposed method is applicable and effective."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study an underlay cognitive energy harvesting decode-and-forward (DF) relaying communications system with multiple secondary users (SUs) and a primary destination. By utilizing power splitting receiver, the relay is capable of harvesting radio frequency energy from SU and retransmitting data with harvested energy. Both direct and relaying links are taken into consideration in selecting the best SU, and furthermore exploited for data transmission by employing selection combining receiver at the secondary destination. To evaluate the system performance, analytical outage probabilities for both selection and fixed DF relaying protocols have been provided under Rayleigh fading channel. Moreover, we further derive their asymptotic expressions of outage probability. With the given asymptotic expressions, we confirm that the system diversity approaches to N +1 for selection DF relaying and reaches N for fixed DF relaying. Numerical and simulation results are demonstrated to verify our proposed analysis."
  },
  {
    "year": "2017",
    "abstract": "This paper presents the realization of a lossy asymmetrical bandstop filter prototype on a microstrip planar structure using multiple Triplet sections. The realization of a single Triplet section on a microstrip structure is proposed and discussed. To prove the realizability, a third-order Generalized Chebyshev filtering function is used to obtain the asymmetrical response by placing zeros asymmetrically on the real frequency axis. With the multi-stage predistortion reflection mode technique, the lossy bandstop filter is synthesized as a network consisting of multiple Triplet sections of finite low Q resonators. The prototype is designed and fabricated on a microstrip, Rogers RT/Duroid 5880 substrate. There is very good agreement between simulated and measured results."
  },
  {
    "year": "2017",
    "abstract": "It is well-known that the deformation of transformer winding can produce detectable changes to the frequency response spectrum compared with a referenced past measurement. To interpret such changes for diagnostic purposes, main causes of the trace deviation need to be recognized precisely. In addition, it is useful that the interpretation of transformer frequency response is classified in a way that IoT-based techniques can be developed in the near future to analyze the transformer mechanical integrity. This paper has specifically concentrated on the inductance and capacitance variation due to the axial and radial disk deformation of transformer winding. Analytical analyses on selfand mutual-inductance variations are discussed and capacitance variation is studied in detail for symmetrical and asymmetrical transformer disk deformations. A numerical example is provided to establish the analytical approach and compare inductance and capacitance variation. The analytical approach is finally examined through the experimental study of disk deformation in a 66 kV transformer winding."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a quantum lightning search algorithm (QLSA) -based optimization technique for controlling speed of the induction motor (IM) drive. The developed QLSA is implemented in fuzzy logic controller to generate suitable input and output fuzzy membership function for IM drive speed controller. The main objective of this paper is to develop QLSA-based fuzzy (QLSAF) speed controller to minimise the mean absolute error in order to improve the performance of the IM drive with changes in speed and mechanical load. The QLSAF-based speed controller is implemented in simulation model in the MATLAB/Simulink environment and the prototype is fabricated and experimentally tested in a fully integrated DSP for controlling the IM drive system. The experimental results of the developed QLSAF speed controller are compared with the simulation results under different performance conditions. Several experimental results show that there are good agreement of the controller parameters, SVPWM signals, and different types of speed responses and stator currents with the simulation results, which are verified and validated the performance of the proposed QLSAF speed controller. Also, the proposed QLSAF speed controller outperforms other studies with settling time in simulation and in experimental implementation, which validates the controller performance as well."
  },
  {
    "year": "2017",
    "abstract": "An adaptive array design is proposed for hybrid beamforming in millimeter-wave (mmWave) communications in the context of cloud radio access networks (C-RAN). More explicitly, the adaptive design focuses on the physical layer aspect of C-RAN. The adaptation is performed at two levels, depending on whether the channel is of line-of-sight (LOS) or non-line-of-sight (NLOS) nature. First, the antenna array architecture can be adapted between a fully connected and a sub-array-connected architecture. Then, the employment of a digital precoder in the baseband is decided based on both the channel conditions and the architecture employed. We show that the proposed adaptive design performs better than the fully connected and sub-array-connected constituent designs, when the channel varies between LOS and NLOS scenarios. Then, we extend our proposed adaptive design to mmWave communications in the context of C-RAN, where we propose an adaptive virtual cell formation algorithm, where a user can be connected to one or two remote radio heads, depending on the channel conditions."
  },
  {
    "year": "2017",
    "abstract": "In the normalized cut (Ncut) process, it is crucial to construct an appropriate affinity matrix. The affinity matrix is generally limited to pairwise similarity relations. However, in practice, it is necessary to use high-order affinities in several computer vision applications such as motion segmentation. In this paper, by using high-order singular value decomposition techniques, we derive a high-order affinity model directly from the Ncut relaxation formula, called high-order normalized cut (HNcut). However, in practice, it cannot directly utilize the high-order affinity matrix because of the computational resources required. To address this issue, we adopt and improve various techniques to make the proposed method more practical such as sampling strategy. Finally, we analyze the upper error bound of our algorithm based on matrix perturbation theory. To demonstrate the performance of our HNcut, we compare it with some existing algorithms for the motion segmentation and face clustering problems."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address the problem of confidentiality of keyframes, which are extracted from diagnostic hysteroscopy data using video summarization. We propose an image color coding method aimed at increasing the security of keyframes extracted from diagnostic hysteroscopy videos. In this regard, we use a 2-D logistic map to generate the cryptographic keys sequences, which relies on mixing and cascading the orbits of the chaotic map in order to generate the stream keys for the encryption algorithm. The encrypted images produced by our proposed algorithm exhibit randomness behavior, providing a high-level of security for the keyframes against various attacks. The experimental results and security analysis from different perspectives verify the superior security and high efficiency of our proposed encryption scheme compared to other state-of-the-art image encryption algorithms. Furthermore, the proposed method can be combined with mobile-cloud environments and can be generalized to ensure the security of cloud contents as well as important data during transmission."
  },
  {
    "year": "2017",
    "abstract": "The advanced features of 5G mobile wireless network systems yield new security requirements and challenges. This paper presents a comprehensive study on the security of 5G wireless network systems compared with the traditional cellular networks. The paper starts with a review on 5G wireless networks particularities as well as on the new requirements and motivations of 5G wireless security. The potential attacks and security services are summarized with the consideration of new service requirements and new use cases in 5G wireless networks. The recent development and the existing schemes for the 5G wireless security are presented based on the corresponding security services, including authentication, availability, data confidentiality, key management, and privacy. This paper further discusses the new security features involving different technologies applied to 5G, such as heterogeneous networks, device-to-device communications, massive multiple-input multiple-output, software-defined networks, and Internet of Things. Motivated by these security research and development activities, we propose a new 5G wireless security architecture, based on which the analysis of identity management and flexible authentication is provided. As a case study, we explore a handover procedure as well as a signaling load scheme to show the advantages of the proposed security architecture. The challenges and future directions of 5G wireless security are finally summarized."
  },
  {
    "year": "2017",
    "abstract": "This paper deals with the authentication of the user of a connected object. We propose a flexible and nonintrusive method based on the use of two categories of everyday connected objects (i.e., smart watch and remote control). Data were collected during participants' interactions with a smart TV. The discrete cosine transform algorithm was used to extract the most informative features. Based on these features, four classification algorithms (deep neural network, support vector machine, Naïve Bayes classifier, and C45) were applied to the data in order to detect the user's identity. The classification was performed based on the recognition of four types of human activities (sitting, standing, walking, and lying down) through building four databases. Following this, a second classification was made for each data set activity type in order to identify the users. The results show that it is possible to discriminate between users according to their activities. The accuracy of recognition reached 91% for some participants within a certain activity configuration."
  },
  {
    "year": "2017",
    "abstract": "In future intelligent transportation systems, a large amount of content needs to be efficiently and securely exchanged between vehicles and roadside units via vehicular networks to improve the driving and traveling experience. To solve the challenges caused by poor-quality wireless links and the mobility of vehicles, vehicular content-centric networking (VCCN) emerges as a promising paradigm, which has a better content distribution efficiency, mobility, and security via named data and in-networking caching compared with an IP-based network. However, providing a high-quality experience for content distribution in VCCN is challenging due to the dynamic network topologies, varying wireless channel conditions, and vehicle user privacy. In this paper, we propose a novel crowdsourced VCCN framework for secure and efficient content distribution. This framework enables the nearby vehicles to crowdsource their caching resources and radio links for cooperative content distribution. We formulate the problem as the maximization of all users' payoff and propose an online scheduling method to solve this solution. Furthermore, we adopt identity-based proxy reencryption and named function networking to secure the process of content distribution. The simulation results show that our proposals improve the performance of VCCN in terms of average requester utility compared with original CCN forwarding strategies."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a PMU-based state estimation (SE) algorithm that uses a pseudo-dynamic network modeling approach. The pseudo-dynamic network model combines different equations with static network equations. Then it applies the weighted least squares algorithm to solve an over-determined least squares estimation problem. The proposed method can improve SE accuracy during both steady state and transient conditions without increasing the computational burden. In addition, the proposed modeling approach is applied to networks containing both a STATCOM and a voltage source converter-HVdc to demonstrate how to develop and apply a pseudo-dynamic SE model. Case studies aim to illustrate and verify the performance of the proposed method under steady state and transient conditions."
  },
  {
    "year": "2017",
    "abstract": "The expansion of the smart devices, the growing popularity of the social networks, and the wide spread of the corporate services impose huge amounts of heterogeneous data to be generated and stored in separate silos on a daily basis. Parts of this data are private and highly sensitive as they reflect owner's behavior, obligations, habits, and preferences. On the other hand, the emerging crowd services challenge the owners to expose these data in return to the convenience they offer. Therefore, it is imperative not only to protect the interaction with sensitive data, but also to selectively open it in an unharmful manner for the owner's personal integrity. One of the main enablers of the crowd services is the emerging linked data, which is all about opening heterogeneous knowledge from separate data silos. Its growing popularity encourages the data owners to publish their personal data in linked data format. The fusion of sensor, social, and corporate data opens new security challenges, which extend the standard security considerations toward more flexible and context aware authorization platforms. In this paper, we propose a linked data authorization (LDA) platform atop a policy language flexible enough to cover all newly emerged requirements, including context awareness. The proposed policy language extends the widely accepted W3C's SPARQL query language and leverages its expressiveness to protect every part of the data. The novelty of our LDA platform is its unique capability of design time policy validation through stand-alone testing, conflict detection, and overall protection coverage extraction."
  },
  {
    "year": "2017",
    "abstract": "Industrial production has evolved significantly over the last decade. For this reason, it is necessary to obtain mathematical and computational tools that enable power systems engineers to make decisions that reduce harmonic distortions in accordance with international standards. This paper presents a total harmonic distortion (THD) assessment based on full knowledge discovery in databases (KDD) using power quality (PQ) standards and computational intelligence tools. The materials and methods of THD assessment consist of load and layout analysis; choice and installation of PQ analyzers; and the application of the full KDD process, including collection, selection, cleaning, integration, transformation and reduction, mining, interpretation, and evaluation of the data. This research methodology was used in an electrical and electronic industry; the results obtained have characteristics that can be used as a reference for other types of analyses. The results indicate that these methods can be applied to several industrial applications such as: 1) the description of the complete KDD process for THD assessment of the point of common coupling; 2) simultaneous collection using five PQ analyzers at several points in the electrical network; and (3) the use of a decision tree classifier."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a series of models were established, and based on the Google Flu Trends (GFT) data and Centers for Disease Control (CDC) data. The models include the GFT regression model (model 1), the weighted GFT regression model (model 2), the GFT + CDC regression model (model 3), the CDC regression model (model 4), and the weighted CDC regression model (model 5). All models were utilized to predict and assess influenza activity across ten regions of the United States. The least squares and backpropagation neural network based on the genetic algorithm are used to fit the model parameters, and the error and historical sample fitting accuracy of each model are compared. The results show that models 4 and 5 are superior to other models. To optimize the prediction model, the seasonal characteristics of influenza incidence were investigated, and flu-prediction models for the high-flu season and low-flu season were established. The experimental results show that the prediction model of seasonal influenza is superior to the non-seasonal model. The influenza-like illness values predicted by the seasonal flu model are consistent with information provided by the CDC, suggesting that the results accurately reflect influenza epidemic characteristics and can thus be readily applied for the prevention and control of influenza."
  },
  {
    "year": "2017",
    "abstract": "Public key encryption supporting equality test (referred to as PKE-ET) provides the capability of testing the equivalence between two messages encrypted under different public keys. Ciphertext-policy attribute-based encryption (CP-ABE) is a promising primitive to achieve versatile and secure data sharing in the cloud computing by providing flexible one-to-many encryption. In this paper, we first initialize the concept of CP-ABE with equality test (CP-ABE-ET) by combining the notions of PKE-ET and CP-ABE. Using ABE-ET primitive, the receiver can delegate a cloud server to perform an equivalence test between two messages, which are encrypted under different access policies. During the delegated equivalence test, the cloud server is unable to obtain any knowledge of the message encrypted under either access policy. We propose a concrete CP-ABE-ET scheme using bilinear pairing and Vi`ete's formulas, and give the security proof of the proposed scheme formally in the standard model. Moreover, the theoretic analysis and experimental simulation reveal that the proposed scheme is efficient and practical."
  },
  {
    "year": "2017",
    "abstract": "Prognostics and health management is an emerging discipline to scientifically manage the health condition of engineering systems and their critical components. It mainly consists of three main aspects: construction of health indicators, remaining useful life prediction, and health management. Construction of health indicators aims to evaluate the system's current health condition and its critical components. Given the observations of a health indicator, prediction of the remaining useful life is used to infer the time when an engineering systems or a critical component will no longer perform its intended function. Health management involves planning the optimal maintenance schedule according to the system's current and future health condition, its critical components and the replacement costs. Construction of health indicators is the key to predicting the remaining useful life. Bearings and gears are the most common mechanical components in rotating machines, and their health conditions are of great concern in practice. Because it is difficult to measure and quantify the health conditions of bearings and gears in many cases, numerous vibration-based methods have been proposed to construct bearing and gear health indicators. This paper presents a thorough review of vibration-based bearing and gear health indicators constructed from mechanical signal processing, modeling, and machine learning. This review paper will be helpful for designing further advanced bearing and gear health indicators and provides a basis for predicting the remaining useful life of bearings and gears. Most of the bearing and gear health indicators reviewed in this paper are highly relevant to simulated and experimental run-to-failure data rather than artificially seeded bearing and gear fault data. Finally, some problems in the literature are highlighted and areas for future study are identified."
  },
  {
    "year": "2017",
    "abstract": "In the system of face recognition, the tradition method of data dimension reduction method is used to rearrange the face image vectors, resulting in the structural characteristics of the data itself lost and the recognition accuracy not high. In this paper, we develop a data dimension reduction method based on tensor-multilinear discriminant subspace projection. The algorithm directly describes the face with tensor and projects the tensor data into the vector discriminant subspace through a new projection mode tensor to vector projection (TVP). This method finds a set of orthogonal projection vector sets to maximize the dispersion between the data classes and minimize the intra-class dispersion in the discriminant subspace. Then, the high-dimensional tensor data is mapped to low-level vector data by TVP. These vector features after dimension reduction will be the most representative feature data in the whole face data under the appropriate constraint condition. Finally, these feature data are classified by the K-nearest neighbor classifier. Experiments on classical face database Olivetti Research Laboratory and face recognition technology verify the effectiveness of this method."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we report the mechanistic insights into thermal and humidity induced degradation of silicone employed in high power LEDs. High power blue and white light emitting diodes (LEDs) are used for experimentation. The silicone encapsulant of both the blue and white LEDs are degraded due to hydrolysis, likewise for the molding part of the blue LED. However, the molding part of the white LED is degraded via thermal oxidation. We find that lumen degradation is rapid for white LEDs, whereas material degradation is unexpectedly rapid for blue LEDs. The reasons for such differences in the degradation of the packaging materials are explained. We also found that the degradation of LEDs under high temperature alone is different from that under high temperature and humid condition, such as those used in the outdoor applications."
  },
  {
    "year": "2017",
    "abstract": "Machine learning techniques have the potential to revolutionize medical diagnosis. Single Nucleotide Polymorphisms (SNPs) are one of the most important sources of human genome variability; thus, they have been implicated in several human diseases. To separate the affected samples from the normal ones, various techniques have been applied on SNPs. Achieving high classification accuracy in such a high-dimensional space is crucial for successful diagnosis and treatment. In this work, we propose an accurate hybrid feature selection method for detecting the most informative SNPs and selecting an optimal SNP subset. The proposed method is based on the fusion of a filter and a wrapper method, i.e., the Conditional Mutual Information Maximization (CMIM) method and the support vector machinerecursive feature elimination, respectively. The performance of the proposed method was evaluated against four state-of-the-art feature selection methods, minimum redundancy maximum relevancy, fast correlationbased feature selection, CMIM, and ReliefF, using four classifiers, support vector machine, naive Bayes, linear discriminant analysis, and k nearest neighbors on five different SNP data sets obtained from the National Center for Biotechnology Information gene expression omnibus genomics data repository. The experimental results demonstrate the efficiency of the adopted feature selection approach outperforming all of the compared feature selection algorithms and achieving up to 96% classification accuracy for the used data set. In general, from these results we conclude that SNPs of the whole genome can be efficiently employed to distinguish affected individuals with complex diseases from the healthy ones."
  },
  {
    "year": "2017",
    "abstract": "Accurate detection of rivers plays a significant role in water conservancy construction and ecological protection, where airborne synthetic aperture radar (SAR) data have already become one of the main sources. However, extracting river information from radar data efficiently and accurately still remains an open problem. The existing methods for detecting rivers are typically based on rivers’ edges, which are easily mixed with those of artificial buildings or farmland. In addition, pixel-based image processing approaches cannot meet the requirement of real-time processing. Inspired by the feature integration and target recognition capabilities of biological vision systems, in this paper, we present a hierarchical method for automated detection of river networks in the high-resolution SAR data using biologically visual saliency modeling. For effective saliency detection, the original image is first over-segmented into a set of primitive superpixels. A visual feature set is designed to extract a regional feature histogram, which is then quantized based on the optimal parameters learned from the labeled SAR images. Afterward, three saliency measurements based on the specificity of the rivers in the SAR images are proposed to generate a single layer saliency map, i.e., local region contrast, boundary connectivity, and edge density. Finally, by exploiting belief propagation, we propose a multi-layer saliency fusion approach to derive a high-quality saliency map. Extensive experimental results on three airborne SAR image data sets with the ground truth demonstrate that the proposed saliency model consistently outperforms the existing saliency target detection models."
  },
  {
    "year": "2017",
    "abstract": "In several papers, analytical calculations of the mean value of the end-to-end delay in highway vehicular ad-hoc networks (VANETs) have been presented. Unfortunately, none of these papers presented calculations of the probability distribution of this delay, which is necessary to give probabilistically guaranteed upper bounds on the end-to-end delay in such VANETs. In a previous paper, we introduced the first analytical framework for the calculation of the probability distribution, and not only the mean, of the end-to-end delay in multi-lane one-way highway VANETs. This made it possible to provide guarantees of transmission in a given time frame with known confidence. In this paper, that previous work is extended to two-way multi-lane highways by taking into consideration vehicles travelling in both directions. The probability distribution of the end-to-end delay is calculated herein and its dependence on system parameters, such as speed distributions in the two directions, communication range, and vehicle densities, are analyzed. Computer simulations are used to verify the analytical model. The good agreement between simulation results and the analytical calculations demonstrates the correctness and accuracy of the proposed analytical model."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the joint design of transmit beamforming over physical layer and file dissemination strategy at base stations (BSs) over transport layer in the cache-enabled cloud radio access networks. Our objective is to minimize the total user file download delay while satisfying each BS's power constraint and file dissemination proportion constraints. This problem is very challenging because of the highly coupled optimization variables in the objective function. To address the untractable non-convex problem, the original problem is decomposed into two subproblems. The first subproblem is a non-convex fractional program problem, and by transforming it into a second-order cone program, an iterative algorithm based on an inner approximation method is proposed to achieve the optimal beamforming vectors. For the other subproblem, we propose a sparse optimization algorithm and prove that there exists a closed-form solution in terms of l0-norm. Then, the original non-convex problem is addressed in an iterative manner by employing the two proposed sub-algorithms. Numerical results demonstrate that the proposed cross-layer optimization algorithms can efficiently reduce the total user download delay."
  },
  {
    "year": "2017",
    "abstract": "Among the various scaffold design methods, function-based modeling is of great interest due to its accurate controllability for designing pore architectures. Parameters, such as the pore size, pore shape, porosity, and channel interconnectivity, should be designed according to actual skeleton characteristics. To this, an effective modeling method of trabecular bone is proposed, combining triply periodic minimal surface (TPMS) and fractal geometry. First, the surface morphology of real trabecular bone is obtained based on the binary processing of computed tomography images. Then, the fractal pore-making element using TPMS is built and constructed into a complex porous structure. Finally, the customized scaffold model is manufactured with an additive manufacturing method."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, the growing global economy and demand for customized products are bringing the manufacturing industry from a sellers' market toward a buyers' market. In this context, the smart manufacturing enabled by Industry 4.0 is changing the whole production cycle of companies specialized on different kinds of products. On one hand, the advent of cloud computing and social media makes the customers' experience more and more inclusive, whereas on the other hand cyber-physical system technologies help industries to change in real time the cycle of production according to customers' needs. In this context, “retention”marketing strategies aimed not only at the acquisition of new customers but also at the profitability of existing ones allow industries to apply specific production strategies so as to maximize their revenues. This is possible by means of the analysis of various kinds of information coming from customers, products, purchases, and so on. In this paper, we focus on customer loyalty programs. In particular, we propose cloud-based software as a service architecture that store and analyses big data related to purchases and products' ranks in order to provide customers a list of recommended products. Experiments focus on a prototype of human to machine workflow for the pre-selection of customers deployed on both private and hybrid cloud scenarios."
  },
  {
    "year": "2017",
    "abstract": "The characteristics of a hydraulic directional control method for the displacement controlled system are studied. The directional control is realized by the pilot-operated check valve. The reversing operation of the pilot-operated check valve system is investigated with simulation and experiment. The relationship between the valve spool motion and the circuit pressure has been analyzed during the directional control. The pressure reversing points during the directional control can be used to determine the operation state of the pilot-operated check valve system. The results indicate that the valve spool motion can be confirmed by the pressure reversing points. The response becomes faster with a smaller diameter control piston. A smaller hydraulic chamber volume is also an effective method to improve the dynamic response. Higher circuit pressures decrease the dynamic response. The results can be applied for the optimized design of the hydraulic directional control method with the pilot-operated check valve."
  },
  {
    "year": "2017",
    "abstract": "Resource allocation in secure communication is of primary importance due to the fact that the next-generation wireless network (5G) aims to achieve high spectral efficiency and a high level of security. Different from previous studies, we study the resource allocation for secure transmission in K-tier dynamic heterogeneous cellular networks jointly considering the randomness of base stations (BSs) in spatial dimension and user equipment (UE) arrival and departure processes in temporal dimension. First, we develop a 3-D stochastic model by jointly taking into account the randomness of BSs in two spatial dimensions and UE arrival and departure processes in one temporal dimension. Second, we analyze the connection outage probability and secrecy outage probability of the typical UE. Their expressions admit quite simple closed-forms in some plausible special cases. Based on the outage analysis, the reliability and security performances of the network are evaluated, respectively. Third, we investigate the network-wide secrecy throughput in virtue of the outage analysis. Furthermore, we derive the optimal resource allocation factors of different tiers to maximize the secrecy throughput. Since the objective function of the maximization problem is not in closed form and non-convex, the concave upper and lower bounds are deduced and utilized, which leads to near-optimal solutions of the resource allocation factors of different tiers. It is demonstrated that apart from the spatial intensity and transmission power of each BS, UE arrival and departure processes are also key elements influencing the resource allocation factors of different tiers. Finally, numerical results show the usefulness and correctness of our theoretical conclusions."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a passivity and fault alarm-based hybrid controller is designed for a Markovian jump delayed system with actuator failures. First, a passive condition is given, and a type of hybrid controller that combines with robust and fault-tolerant controllers is presented to ensure that both the normal system and the fault system are robustly stochastically passive. Next, a fault alarm signal is proposed by choosing the alarm threshold, and this signal is used to invoke the fault-tolerant controller. Finally, a numerical example is provided to show the effectiveness of the method."
  },
  {
    "year": "2017",
    "abstract": "Recurrent neural network (RNN) and long short-term memory (LSTM) have achieved great success in processing sequential multimedia data and yielded the state-of-the-art results in speech recognition, digital signal processing, video processing, and text data analysis. In this paper, we propose a novel action recognition method by processing the video data using convolutional neural network (CNN) and deep bidirectional LSTM (DB-LSTM) network. First, deep features are extracted from every sixth frame of the videos, which helps reduce the redundancy and complexity. Next, the sequential information among frame features is learnt using DB-LSTM network, where multiple layers are stacked together in both forward pass and backward pass of DB-LSTM to increase its depth. The proposed method is capable of learning long term sequences and can process lengthy videos by analyzing features for a certain time interval. Experimental results show significant improvements in action recognition using the proposed method on three benchmark data sets including UCF-101, YouTube 11 Actions, and HMDB51 compared with the state-of-the-art action recognition methods."
  },
  {
    "year": "2017",
    "abstract": "Cognitive radio (CR) enables unlicensed users to sense for and access underutilized licensed channels (or white spaces) owned by the licensed users in an opportunistic manner. Clustering segregates nodes in a network into logical groups called clusters. In CR networks (CRNs), larger cluster size improves network scalability thereby contributing to reduced routing overhead; however, it reduces cluster stability as the number of available common channels in a cluster reduces resulting in increased number of re-clusterings and clustering overhead. This paper presents our proposed first-of-its-kind cluster size adjustment scheme based on an artificial intelligence approach called reinforcement learning. The proposed scheme adapts the cluster size with the amount of white spaces as time goes by in order to improve network scalability and cluster stability in CRNs. Due to the lack of progress in the investigation of cluster size adjustment schemes in the literature, this paper also analyzes their attributes, and then presents such schemes investigated in various kinds of distributed wireless networks. Simulation results show that our proposed scheme improves network scalability by creating larger clusters, and improves cluster stability by reducing the number of re-clusterings (i.e., the number of cluster splits) and clustering overhead, while reducing interference between licensed and unlicensed users in CRNs."
  },
  {
    "year": "2017",
    "abstract": "A liquid-metal RF shunt switch is presented that combines a dielectric spacer over the RF path with electrolyte-filled capillary troughs to facilitate low-power electrical actuation. The switch demonstrates between 20and 30-dB isolation in the dc to 5-GHz range, and greater than 10-dB isolation from 5 to 11 GHz. This switch has between 0.2and 1.2-dB insertion loss from dc to 5 GHz."
  },
  {
    "year": "2017",
    "abstract": "Fully convolutional neural networks (FCNs) have been shown to achieve the state-of-the-art performance on the task of classifying time series sequences. We propose the augmentation of fully convolutional networks with long short term memory recurrent neural network (LSTM RNN) sub-modules for time series classification. Our proposed models significantly enhance the performance of fully convolutional networks with a nominal increase in model size and require minimal preprocessing of the data set. The proposed long short term memory fully convolutional network (LSTM-FCN) achieves the state-of-the-art performance compared with others. We also explore the usage of attention mechanism to improve time series classification with the attention long short term memory fully convolutional network (ALSTM-FCN). The attention mechanism allows one to visualize the decision process of the LSTM cell. Furthermore, we propose refinement as a method to enhance the performance of trained models. An overall analysis of the performance of our model is provided and compared with other techniques."
  },
  {
    "year": "2017",
    "abstract": "When using the PSO (particle swarm optimization) optimization adaptive stochastic-resonance method, the initial value and value range of the optimization parameters are defined inappropriately, divergence problems may easily emerge in the calculation process, and optimization may stop prematurely. To solve this problem, this research has analyzed the parameters that influence system stability using the scale-transformation stochastic-resonance solution procedure, and the value range leading to algorithm stability was obtained. On this basis, a stable mutation operator has been proposed, which is used in mutation operations on particles outside the stable condition. To ameliorate the poor local search ability and low convergence speed of the PSO algorithm in the later iteration stage, an inertial weight degression strategy based on a particle distance index has been developed. Based on these two research results, a PSO optimization scale-transformation stochastic-resonance algorithm with mutation operator has been proposed. The proposed algorithm has been used to detect numerically simulated signals and rotor test-table data. The results show that when the stable mutation operator acts on the SR optimization parameters, divergence is effectively avoided, and the stability of the iterative algorithm is improved accordingly. By adding the inertial weight degression strategy to the PSO algorithm, iteration speed could be improved at the same time."
  },
  {
    "year": "2017",
    "abstract": "In recent years, intelligent railway operation and maintenance using cloud technology have received wide consideration for the provision of public transport services. Under the cloud environment, information security is critical to ensure the integrity of data through protection from unauthorized manipulation and the confidentiality through protection against the leakage of sensitive information. This paper proposes a lightweight authenticated encryption scheme with associated data based on a novel discrete chaotic S-box coupled map lattice (SCML), which avoids the dynamic degradation of the digital chaotic system and low efficiency of the chaos-based cryptosystem. Based on the chaotic SCML, an authenticated encryption scheme that protects the confidentiality and integrity in one pass is presented in detail. The security analysis and performance simulations in software and hardware show that the proposed scheme is efficient and provides adequate security through authentication and encryption. Such a scheme could be used for applications in a railway cloud service that requires moderate security and low-cost implementations."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the outage probability of a multiuser multiple-input multipleoutput (MU-MIMO) system in the heterogeneous network (HetNet) in the presence of unpredictable interference (UI) from coexisting ad hoc systems. In order to achieve multiuser diversity gain, the MU-MIMO system requires feedback carrying the signal-to-interference-plus-noise ratio (SINR) from all active users to the base station. However, the coexisting ad hoc systems in HetNet can unpredictably initiate their data transmission during the SINR feedback duration. This unpredictable behavior by the coexisting ad hoc systems causes a mismatch between the measured SINR and the instantaneous SINR. In order to investigate the performance of the MU-MIMO system in HetNets, we first categorize the interferences into predictable interference and UI. Based on this categorization, we analyze the outage probability of an MU-MIMO system using a max-SINR scheduler. The theoretical analyses show that the MU-MIMO system cannot achieve the maximum diversity gain, since the UI from the coexisting systems causes beam selection mismatch. Additionally, we show that reducing the interval between the measurement and data transmission prevents performance degradation by reducing the effect of the unpredictable behavior of the coexisting ad hoc systems."
  },
  {
    "year": "2017",
    "abstract": "The recent advent of electric vehicles (EVs) marks the beginning of a new positive era in the transportation sector. Although the environmental benefits of EVs are well-known today, planning and managing EV charging infrastructure are activities that are still not well-understood. In this paper, we are investigating how the so-called EV-enabled parking lot, a parking lot that is equipped with a certain number of chargers, can define an appropriate parking policy in such a way that satisfies two challenges: EV owners' needs for recharging as well as the parking lot operator's goal of profit maximization. Concretely, we present three parking policies that are able to simultaneously deal with both EVs and internal combustion engine vehicles. Detailed sensitivity analysis, based on real-world data and simulations, evaluates the proposed parking policies in a case study concerning parking lots in Melbourne, Australia. This paper produces results that are highly prescriptive in nature because they inform a decision maker under which circumstances a certain parking policy operates optimally. Most notably, we find that the dynamic parking policy, which takes the advantage of advanced information technology (IT) and charging infrastructure by dynamically changing the role of parking spots with chargers, often outperforms the other two parking policies, because it maximizes the profit and minimizes the chance of cars being rejected by the parking lot. We also discuss how making a few parking spots EV-exclusive might be a good policy when the number of available chargers is small and/or the required IT infrastructure is not in place for using the dynamic policy. We conclude this paper proposing a technology roadmap for transforming parking lots into smart EV-enabled parking lots based on the three studied parking policies."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we newly model computation offloading competition when multiple clients compete with each other so as to reduce energy cost and improve computational performance. We consider two types of destination of offloading request, such as a cloudlet and a remote cloud. Here, the cloudlet consists of locally connected mobile terminals with low-latency and high bandwidth but suffering from task overload due to its limited computational capacity. On the other hand, the remote cloud has a high and stable capacity but the high latency. To facilitate the competition model, on the destination sides, we have designed an energy-oriented task scheduling scheme, which aims to maximize the welfare of clients in terms of energy efficiency. Under this proposed job scheduling, as a joint consideration of the destination and client sides, competition behavior among multiple clients for optimal computation offloading is modeled and analyzed as a non-cooperative game by considering a trade-off between different types of destinations. Based on this game-theoretical analysis, we propose a novel energy-oriented weight assignment scheme in the mobile terminal side to maximize mobile terminal energy efficiency. Finally, we show that the proposed scheme converges well to a unique equilibrium and it maximizes the payoff of all participating clients."
  },
  {
    "year": "2017",
    "abstract": "This paper characterizes rate-one (i.e., full rate) full-spatial-diversity-achieving communication schemes based on the channel state information (CSI) availability and antenna configurations, i.e., CSI at a transmitter (CSIT) or CSI at a receiver (CSIR) and the numbers of transmit and receive antennas M and N (denoted by M × N), respectively. The maximum ratio combining (MRC), maximum ratio transmission (MRT), and space-time block code (STBC) schemes are rate-one full-spatial-diversity-achieving method facilitated for communication systems with: 1) 1 × N and CSIR; 2) M × 1 and CSIT; and 3) M × 1 and CSIR, respectively. A novel space-time line code (STLC) is then introduced for a 1 × 2 system with CSIT, and it is extended to an M × 2 STLC. The proposed STLC uses CSI for encoding at the transmitter and enables the receiver to decode the STLC symbols without CSI. Also, the STLC encoding matrices with various code rates and decoding (combining) schemes are designed for the M × 3 and M × 4 STLC systems: A code rate of 3/4, 1/2, and 3/7 for the M × 3 systems and a code rate of 3/4, 4/7, and 1/2 for the M × 4 systems. For each STLC scheme, a full-diversity achieving STLC decoding method is designed. Based on analyses and numerical results, we verify that the proposed STLC scheme achieves a full diversity order, i.e., MN, and is robust against CSI uncertainty. It is also shown that the array processing gain is inversely proportional to the code rate. To verify the merit of STLC, we introduce a joint operation with STBC and STLC schemes, called an STBLC system. The STBLC system achieves full-spatial-diversity gain in both uplink and downlink communications. The new STLC achieving full-spatial diversity is scalable for various code rates and expected to be applied to various wireless communication systems along with MRC, MRT, and STBC."
  },
  {
    "year": "2017",
    "abstract": "Fingerprint indexing is studied widely with the real-valued features, but few works focus on the binary feature descriptors, which are more appropriate to retrieve fingerprints efficiently in the largescale fingerprint database. In this paper, the binary fingerprint descriptor (BFD), which is an effective and discriminative binary feature representation for fingerprint indexing, is proposed based on minutia cylinder code (MCC). Specifically, we first analyze MCC to find that it has characteristics of the high dimensionality, redundancy, and quantization loss. Accordingly, we propose an optimization model to learn a feature-transformation matrix, resulting in dimensionality reduction and diminishing quantization loss. Meanwhile, we also incorporate the balance, independence, and similarity-preservation properties in this learning process. Eventually, a multi-index hashing-based fingerprint indexing scheme further accelerate the exact search in Hamming space. The experiments on numerous public databases show that the BFD is discriminative and compact and that the proposed approach is outstanding for fingerprint indexing."
  },
  {
    "year": "2017",
    "abstract": "Fog and mobile-edge computing (FMEC) is a sustainable and innovative mobile networking framework that enables the offloading of cloud services and resources at the edge of mobile cellular networks to provide high bandwidth and ultra-low latency. Nonetheless, how to handle several dynamically varying security services with the mobile user's requirements efficiently is a critical problem that hinders the development of FMEC. To address this problem, we sought to introduce an approach to selecting an appropriate security service as per the mobile user requirements in FMEC. The problem of appropriate security service selection with hesitant fuzzy information is a multi-criteria decision making problem. In this paper, we introduce a soft hesitant fuzzy rough set (SHFRS) to solve multi-criteria decision making problems. SHFRS is introduced as an innovative extension of the hesitant fuzzy rough set theory by fusing it with the hesitant fuzzy soft set. We describe the inverse hesitant fuzzy soft set that defines the inverse hesitant fuzzy relation to determine the SHFRS upper and lower approximation operators of any hesitant fuzzy subset in the given set of parameters. We also present different special cases of SHFRS upper and lower approximation operators and discuss some fundamental theorems based on approximation operators. In addition, we propose a novel solution to multi-criteria decision making problems based on SHFRS. Finally, we assess the proposed solution by applying it to a real-time multi-criteria decision making problem of appropriate security service selection for FMEC in the existence of multi-observer hesitant fuzzy information."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things gateways with multi-radio facilities in wireless networks can simultaneously communicate using multiple available channels. This feature enhances the carrying capacity of wireless links and thus increases the overall network throughput. However, designing an efficient resource allocation strategy is a complex task due to the decisive behavior of interference. There is only a limited number of available channels; therefore, the resource allocation requires careful planning to mitigate the effect of interference. This research proposes a backtracking search-based resource allocation scheme that maps resource allocation to the constraint satisfaction problem. Some of the resource allocation constraints are applied as soft constraints which are relaxed to find a feasible solution, provided the perfect allocation of limited resources is not possible. The proposed approach has been benchmarked through simulations and the results prove the effectiveness of the proposed approach especially in dense multi-hop network deployments."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a comprehensive survey of the literature on self-interference management schemes required to achieve a single frequency full duplex (FD) communication in wireless communication networks. A single frequency FD system often referred to as in-band FD system has emerged as an interesting solution for the next generation mobile networks, where the scarcity of available radio spectrum is an important issue. Although studies on the mitigation of self-interference have been documented in the literature, this is the first holistic attempt at presenting not just the various techniques available for handling self-interference that arises when an FD device is enabled, as a survey, but it also discusses other system impairments that significantly affect the self-interference management of the system, and not only in terrestrial systems, but also on satellite communication systems. The survey provides a taxonomy of selfinterference management schemes and shows by means of comparisons the strengths and limitations of various self-interference management schemes. It also quantifies the amount of self-interference cancellation required for different access schemes from the first generation to the candidate fifth generation of mobile cellular systems. Importantly, the survey summarizes the lessons learnt, identifies and presents open research questions and key research areas for the future. This paper is intended to be a guide and take off point for further work on self-interference management in order to achieve FD transmission in mobile networks, including heterogeneous cellular networks, which is undeniably the network of the future wireless systems."
  },
  {
    "year": "2017",
    "abstract": "The understanding on the response of aluminum alloy to direct lightning currents is needed for lightning protection. Four typical lightning current components, which are the first return stroke current, subsequent return stroke current, continuing current in the stroke intervals, and long continuing current, are simulated to investigate their damage effects on Al alloy 3003 material by laboratory experiments. The damage morphology on alloy's surface and the microstructure in cross section are observed with high-resolution scanning electron microscope. Elemental composition changes of alloy material are measured by an X-ray energy dispersive spectrometer. Indentation hardness tests are conducted to measure the changes in alloy's micro-hardness. Then, the damage characteristics and mechanisms of the alloy are analyzed by comparing the experimental results under different current parameters of lightning components. The results show that, in response to the first return stroke current component, a thin oxide layer and cracks are formed on the alloy's surface. The cracks are initiated by the broken of the oxide layer. Under the continuing current component in the stroke intervals, the dendritic crystals appear and grow in the direction of temperature decrease inside the material. In response to the long continuing current component, uneven solidification induced cracks are formed. The over-burn phenomenon also occurs and lots of hydrogen evolution porosities appear. As a response to the subsequent return stroke current, the damage pattern on alloy's surface is dominated by pits, and the thickness of the damaged layer is typically 15 μm."
  },
  {
    "year": "2017",
    "abstract": "Hyperspectral image (HSI) is usually corrupted by various types of noise, including Gaussian noise, impulse noise, stripes, deadlines, and so on. Recently, sparse and low-rank matrix decomposition (SLRMD) has demonstrated to be an effective tool in HSI denoising. However, the matrix-based SLRMD technique cannot fully take the advantage of spatial and spectral information in a 3-D HSI data. In this paper, a novel group sparse and low-rank tensor decomposition (GSLRTD) method is proposed to remove different kinds of noise in HSI, while still well preserving spectral and spatial characteristics. Since a clean 3-D HSI data can be regarded as a 3-D tensor, the proposed GSLRTD method formulates a HSI recovery problem into a sparse and low-rank tensor decomposition framework. Specifically, the HSI is first divided into a set of overlapping 3-D tensor cubes, which are then clustered into groups by K-means algorithm. Then, each group contains similar tensor cubes, which can be constructed as a new tensor by unfolding these similar tensors into a set of matrices and stacking them. Finally, the SLRTD model is introduced to generate noisefree estimation for each group tensor. By aggregating all reconstructed group tensors, we can reconstruct a denoised HSI. Experiments on both simulated and real HSI data sets demonstrate the effectiveness of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Saliency detection aims to find the most conspicuous regions in an image, which highly catches the users’ attention. High-quality saliency map plays an important role in boosting many other computer vision tasks, such as object detection and segmentation. To assess a saliency map’s quality, the only way is to utilize a full reference metric, i.e., compute it with the ground-truth reference map. However, in the real-world applications, the ground-truth reference map for the saliency region is unavailable, which brings urgent demands for developing no reference saliency quality metric. In this paper, we propose a deep saliency quality assessment network (DSQAN) to predict the saliency quality scores directly from saliency maps. Furthermore, a joint metric is developed to better depict the quality of a saliency map. The proposed joint metric can not only lead better quality prediction accuracy, but also bring out more robust results. As a direct application of the proposed DSQAN, the predicted saliency quality scores are first utilized to choose the optimal saliency map from a set of saliency map candidates. The experimental results on the MSRA10K data set demonstrate that our proposed method could precisely predict the saliency quality. Particularly, when the DSQAN is applied to recommend optimal saliency map to feed an object segmentation algorithm from multiple candidates, its segmentation accuracy significantly outperforms the results outputted from the best saliency detection algorithms."
  },
  {
    "year": "2017",
    "abstract": "Uncertainty analyses have been considered critical analysis methods for identifying the risks in reliability evaluations. However, with multi-phase, multi-state, and repairable features, this method cannot effectively and precisely display the reliability evaluation results with uncertainty for dynamic and complex systems. In this paper, uncertainty analysis has been conducted in the evaluation of safety-related risk analysis for a nuclear power plant (NPP). A GO-FLOW and dynamic Bayesian network (DBN) combination approach for the reliability evaluation with uncertainty is proposed in this paper. Based on the unified rules, the various operators can be mapped into the DBN even with the multi-phase, multi-state, and repairable characteristics. As the framework of the DBN, utilizing sensitivity analysis, this approach can provide information on those inputs that are contributing the most to the uncertainty. Next, the DBN algorithm and the Monte Carlo simulation are used to quantify the uncertainty in terms of appropriate estimates for the analysis results. Finally, the auxiliary power supply system of the pressurized water reactor in the NPP is analyzed as an example to illustrate the approach. The results of this paper show that uncertainty analysis makes the reliability evaluation more accurate compared with the results without the uncertainty analysis. Moreover, the GO-FLOW methodology can be applied easily for uncertainty analysis with its modified functions and algorithms."
  },
  {
    "year": "2017",
    "abstract": "Smart spaces represent a powerful tool for deploying the new pervasive sensitive services based on Internet of Things products and developed in current information society close to users. Researchers have focused their efforts on new techniques to improve systems and products in this area but neglecting the human factors related to psychological aspects of the user and their psycho-social relationship with the deployment space where they live. This research proposes to take into account these cognitive features in early stages of the design of smart spaces by defining a set of interaction patterns. By using this set of interaction patterns it is possible to influence over the confidence that users can develop during the use of IoT products and services based on them. An evaluative verification has been carried out to assess how this design engineering approach provides a real impact on the generation of confidence in the users of this kind of technology."
  },
  {
    "year": "2017",
    "abstract": "A transportation (automotive service) facility location problem is important in urban infrastructure planning and construction. To handle it, researchers have proposed a number of stochastic/random models for locating an automotive service enterprise. However, most of them fail to describe all kinds of uncertainty, e.g., data imprecision. By considering regional constraints, this work proposes a new random fuzzy cost-profit equilibrium model by using uncertainty data and management methods. It presents a hybrid algorithm integrating stochastic fuzzy simulation and particle swarm optimization to solve the location problem of an automobile service enterprise. In addition, since risk factors can impact a decision, this work conducts a risk performance analysis when locating an automotive service enterprise. A practical example is given to illustrate the proposed model and algorithm."
  },
  {
    "year": "2017",
    "abstract": "With the availability of high-throughput satellite services at affordable cost, terrestrial network providers make use of satellite links to extend their coverage to areas, where land-based communication infrastructures are prohibitively costly to implement. Due to the ever-increasing demand for bandwidth resulted from the rapid development of data-intensive services in recent years, one of the fundamental challenges for satellite communications is to continuously improve utilization efficiency of the scarce satellite spectrum. Cognitive satellite communications address the problem by providing mechanisms for terrestrial and satellite users to dynamically access idle bands of licensed satellite networks, hence enabling spectrum sharing between two satellite systems or between satellite and terrestrial systems. In this paper, we investigate a distributed technique of spectrum sharing for cognitive satellite networks. In order to cater for situations with incomplete decision information, the proposed scheme is based on the Bayesian equilibrium theory. We first develop a spectrum allocation scheme by studying the action strategy of terrestrial cognitive terminals in a distributed competition. A feasible spectrum allocation scheme that caters for cases of incomplete user information is then developed as an extension of the basic scheme by formulating the problem as a Cournot game model. By identifying the unique equilibrium in this model, optimal spectrum allocation for cognitive satellite networks can be achieved. Essential discussions and proofs for the rationality of this method and uniqueness of the equilibrium are provided. Numerical results are given to justify the claimed advantages."
  },
  {
    "year": "2017",
    "abstract": "In recent years, ship motion control has been used in unmanned merchant ships. It is a key issue in the sailing performance and navigation cost of unmanned vessels. The merchant ship trajectory and attitude are always generated from the response mechanism for ship motion, which uses one rudder and one propeller as the actuator. Therefore, it is a typical underactuated ship. However, there is not a specialized control test platform for unmanned merchant ships, in particular container ships. A precise merchant ship motion control platform is crucial; its computing power and motion attitude monitoring are difficult to solve by shipborne computers. To solve this problem, a new free-running ship motion control platform is proposed, which realizes ship attitude monitoring and various motion control experiments. The proposed platform is novel as it embeds ship motion parameters and control parameters in the ship motion model, which successfully solves the precise control of the ship motion control experiment with linear or nonlinear dynamics. In this paper, the design scheme of the ship motion control platform is first presented. Then, the operating principle of the platform is shown, and the adaptive model of the ship plane motion is selected. A series of freerunning model experiments and simulations is conducted to test performance of the new platform. To this end, the proposed platform can meet the requirements."
  },
  {
    "year": "2017",
    "abstract": "The environmental problem is a major practical problem that China and the world are faced with. It is a trend for the future power grid to be dominated by the increasing penetration of renewable energy. However, the high penetration power system may face many new problems, including reduced inertia of the power system, the stability of the frequency stability, and the weak grid characteristics of the output system may limit the delivery capacity of renewable energy base. The motor-generator pair (MGP) system can deal with these problems efficiently, but the current MGP system control method is still flawed. In this paper, the mathematical model of the MGP system is analyzed. The characteristics of the source-grid difference control method is analyzed by simulation and experiment. In the experiment, the shortcoming of existing control method that the control system is sensitive to the power grid frequency change is found. The optimized control method based on power feedback is proposed. The feasibility of the power feedback control method is proved by the experimental and simulation. The result shows that the source-grid phase difference method based on power feedback can make the MGP system follow the power reference value to transmit active power stably and reduce the frequency sensitivity of the MGP system."
  },
  {
    "year": "2017",
    "abstract": "Recent development and technology advancement in wireless communication systems to accommodate higher data rate poses a great challenge for wideband operation. This is due to the employment of modulation scheme, such as OFDM, which is subject to high peak to average ratio. Hence communication systems, such as LTE have to operate in multiple operating bands at the moment in order to transmit the OFDM signals linearly with high gain. The power amplifier serves as the bottle neck for high gain linear operation over wide bandwidth. This paper addresses this issue and further presents a novel integrated feedback and analog pre-distortion linearization technique as a solution to achieve wideband flat gain and linear output power while preserving the power amplifier's power added efficiency (PAE). A maximally flat gain is achieved through the dual parallel feedback technique. The analog pre-distorter on the other hand introduces an optimum third order nonlinear signal components cancellation mechanism over wide frequency range. A prototype of 700 MHz to 2.5 GHz power amplifier is implemented in 0.25 μm PHEMT. It achieves an input and output return loss of less than -10 dB followed by flat power gain of 20 dB across the operating band, while sustaining an unconditional stability performance up to 20 GHz. With 1-dB compression point output power (P1dB) of 24.0 dBm, the PA delivers an OIP3 of more than 40 dBm with peak PAE of 66%. The fully integrated circuit consumes an area of 0.8 mm2. The proposed circuit serves to be a good solution to be integrated as a part of the wideband transmitter system for picocell application."
  },
  {
    "year": "2017",
    "abstract": "With the development of recurrent neural networks (RNN), various natural language generation (NLG) tasks have boomed in the past few years, such as response generation in conversation and poetry generation. However, automatic generation of news comments is anew, challenging and not well-studied task in NLG. Different from other NLG tasks, this task requires the contextual relevance between comments and news. In addition, we need to generate diversified comments, because different people usually have different opinions on the same news in the real world. In this paper, we propose a gated attention neural network model (GANN) to generate news comments. To address the problem of contextual relevance, we introduce the gated attention mechanism to use news context self-adaptively and selectively. To ensure the diversity of comments, we use random sample and relevance control to generate comments with different topics and degrees of relevance. Moreover, we apply generative adversarial nets to improve GANN. Automatic evaluation with perplexity score reveals that GANN outperforms the existing comment generation methods. Human evaluation proves that the generated news comments are close to human comments."
  },
  {
    "year": "2017",
    "abstract": "Batteries are essential for efficiently utilizing the energy from the photovoltaic (PV) modules. However, integration of batteries with PV plants at large scale needs more attention in terms of size, location, and times for the charging and discharging of the batteries. This paper addresses these aspects. It presents a mixed integer optimization using genetic algorithm for determining the optimum size and placement of battery-sourced distributed PV generation (B-SDPVG) in distribution networks. The total energy loss index is formulated as the main objective function and simultaneously, the bus voltage deviations and penetrations of the B-SDPVG are calculated. The yields from the PV plants are estimated using 15 years of weather data modeled with the aid of beta probability density function. Furthermore, a novel charge-discharge control model is developed for determining the choice of the charging and discharging of batteries at each hour. By considering different time varying voltage-dependent load models, the proposed algorithm is applied on the IEEE 33 bus and the IEEE 69 bus test distribution networks. The numerical results of two distribution networks with time-varying loads show the advantages of the proposed methodology. It was revealed that integration of battery storage and intelligent scheduling for charging and discharging of batteries produced much better results and improved the quality of distribution networks. The supply of power from the B-SDPVG during the peak load hours and at night was made possible for each load model. The proposed charge-discharge control model for scheduling the charging and discharging of the batteries was found dynamic. Results of this paper can be of potential importance in planning for the integration of battery storage in distribution networks."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the reachable set estimation problem for a class of memristor-based neural networks with time-varying delays and bounded disturbances. By constructing a Lyapunov- Krasovskii functional, a sufficient condition for the solvability of the addressed problem is established based on linear matrix inequality. This condition ensuring the existence of an ellipsoid that contains all the states under initial conditions. A stability criterion of memristor-based neural networks with timevarying delays is also given. Two numerical examples are provided to show the effectiveness of the proposed methods."
  },
  {
    "year": "2017",
    "abstract": "The model of a stochastic production/inventory system that is subject to deterioration failures is developed and examined in this paper. Customer interarrival times are assumed to be random and backorders are allowed. The system experiences a number of deterioration stages before it ultimately fails and is rendered inoperable. Repair and maintenance activities restore the system to its initial and previous deterioration state, respectively. The duration of both repair and maintenance is assumed to be stochastic. We address the problem of minimizing the expected sum of two conflicting objective functions: the average inventory level and the average number of backorders. The solution to this problem consists of finding the optimal tradeoff between maintaining a high service level and carrying as low inventory as possible. The primary goal of this research is to obtain optimal or near-optimal joint production/maintenance control policies, by means of a novel reinforcement learning-based approach. Furthermore, we examine parametric production and maintenance policies that are often used in practical situations, namely, Kanban, (s, S), threshold-type condition based maintenance and periodic maintenance. The proposed approach is compared with the parametric policies in an extensive series of simulation experiments and it is found to clearly outperform them in all cases. Based on the numerical results obtained by the experiments, the behavior of the parametric policies as well as the structure of the control policies derived by the Reinforcement Learning-based approach is investigated."
  },
  {
    "year": "2017",
    "abstract": "Image classification has been an incredibly active research topic in recent years with widespread applications. Researchers have put forward many remarkable techniques and semi-supervised learning (SSL) is one among them. However, due to not taking the relationship of samples among different classes in consideration, previous approaches cannot often get a clear decision boundary. In this paper, we propose an improved classification model on the basis of SSL. First, we adopt a deformable partbased model to capture a stable global structure and salient objects, and then, we find a better decision boundary by our classification algorithm-based on an improved ensemble projection (IEP). Our IEP exploits the weighted average method. To evaluate the effectiveness of our approach, we do experiments not only with the LandUse-21 (L-21) data set, but also with an architecture style data set. Experimental results show that our approach is capable of achieving the state-of-the-art performance on the two data sets. For each class in L-21 data set, when 50 images are randomly chosen as training images, the multi-class average precision increases to 97.63%. Besides, for the architecture style data set, we achieve the best result with about 80% accuracy and have about a 10% improvement over the previous best work. Although there are a small number of labeled data used to train, we get the satisfactory performance."
  },
  {
    "year": "2017",
    "abstract": "This paper first investigates an M-by-2 massive multiple-input multiple-output (MIMO) system that transmits a single stream is investigated. For this system, we propose a space-time line code (STLC), which is a transmitting and combining (at a receiver) scheme that achieves full spatial diversity. For the STLC, two consecutive (time) information symbols are weighted as per channel gains (space), combined at each transmit antenna, and transmitted through the M transmit antennas for two consecutive symbol times. With two receive antennas, the STLC receiver simply combines the signals received in the two symbol times and achieves a diversity order of 2M (full diversity). We show that the proposed STLC asymptotically achieves the maximum (optimal) received signal-to-noise ratio as M increases with significantly reduced computational complexity compared with the optimal scheme. Because the proposed STLC receiver requires no or partial channel state information, it avoids the issue of massive MIMO channel estimation. Furthermore, the rigorous performance evaluation under spatially correlated and uncertain channel conditions reveals that the proposed STLC achieves comparable or better performance than the existing schemes, and the results verify that the proposed STLC scheme is a potential candidate for M-by-2 massive MIMO systems. Next, the transmit antenna allocation algorithms are devised for a multiuser STLC system. Each user achieves full diversity order from the corresponding MIMO channels after the antenna allocation. The signal-tointerference-plus-noise ratio (SINR) of each user is analyzed considering the multiuser interference and channel uncertainty, and its lower bound is derived. Using the SINR lower bound, greedy algorithms that allocate the transmit antennas are devised. Rigorous simulation demonstrates that multiuser STLC with the proposed antenna allocation is robust against channel uncertainty and can improve the average SINR, improving the quality of exp..."
  },
  {
    "year": "2017",
    "abstract": "The means through which governments deliver services and the way they operate may be considerably enhanced through cloud computing. It can help to address e-government implementation challenges and revolutionize e-government systems in terms of cost savings and the professional use of resources. The aim of this paper is to analyze the importance and performance of the factors that influence the fitness of cloud computing fore-government implementation. This paper integrates the task technology fit model with the diffusion of innovation theory to address this issue. Yemeni public institutions were identified as sources for data collection and 292 information technology employees participated as sample respondents for a structured questionnaire. Security, compatibility, relative advantage, and tasks were the variables found to affect the fitness of cloud computing for e-government activities. However, no impact was seen from the standpoints of trialability and complexity of the technology. In terms of assessing the fitness of cloud computing for e-government services, a greater understanding among policy formulators was sought through the importance-performance matrix analysis (IPMA). The results of IPMA can help identifying areas for strategic focus to assess cloud computing as an alternative technology to implement e-government services."
  },
  {
    "year": "2017",
    "abstract": "This paper presents an energy-efficient wireless transmission scheme for battery-less vehicle tire pressure monitoring system (TPMS). Our proposed transmission scheme includes a wake-up communication link with 125-kHz carrier frequency and a data communication link with 433-MHz carrier frequency. Considering the TPMS application requirements and the special nature of the vehicle environment, we derive the relevant circuit parameters. In order to verify the reliability of the wireless communication system under the derived circuit parameters, we design an in-tire data transmitter and wake-up receiver. The 125-kHz wake-up receiver adopts dual-channel to improve the communication reliability and logarithmic amplifiers to achieve ASK demodulation and dynamic range compression. The receiver is implemented in 0.35-μm high voltage (HV) BCD process. Experiment results show that typical power consumption of the receiver is no more than 5 μA under 3.3 V supply voltage; the maximum data rate is 35 kb/s with 0.5 mVpp sensitivity. On the other hand, the data transmitter is implemented in 0.18-μm MMRF process. Experiment results show that the typical power consumption is 7.3 mA under 1.8 V supply voltage, and the emission power is -10 dBm@433.92 MHz with a phase noise of -103 dBc/Hz@300 kHz. System level experiments demonstrate that the proposed wireless transmission scheme fulfills the vehicle TPMS requirements. The data transmitter and wake-up receiver can communicate with the commercial data receiver and wake-up transmitter in the range of 20 m, which meets the requirements of most vehicles."
  },
  {
    "year": "2017",
    "abstract": "Fault location techniques play an essential role in system recovery and repair. Therefore, numerous methods have been presented for fault location in power transmission and distribution networks. The contribution of this paper is to extend the state-of-art impedance-based fault location methods to support four-wire power distribution. To make this possible an algorithm is developed. The method is obtained using the principles of circuit theory and overcomes the challenges which prevent the use of most fault location methods for distribution networks in practice. This paper presents the detailed equations which are used in the algorithm and how they are obtained. The satisfactory performance of the algorithm is confirmed with numerical examples using MATLAB software."
  },
  {
    "year": "2017",
    "abstract": "In hardware/software (HW/SW) co-design, hardware/software partitioning is an essential step in that it determines which components to be implemented in hardware and which ones in software. Most of HW/SW partitioning problems are NP hard. For large-size problems, heuristic methods have to be utilized. This paper presents a parallel genetic algorithm with dispersion correction for HW/SW partitioning on CPU-GPU. First, an enhanced genetic algorithm with dispersion correction is presented. The underconstraint individuals are marched to feasible region step by step. In this way, the intensification can be enhanced as well as the constraint problem can be handled. Second, the individuals performing costs computation and dispersion correction are run in parallel. For a given problem size, the overall run-time can be reduced while the diversity of genetic algorithm can be kept. Third, especially when a number of under-constraint individuals should be corrected in an irregular way, the computation process is complicated and the computation overhead is large. Therefore, we present a novel parallel strategy by leveraging the parallel power of a multi-core CPU and that of a many-core GPU. The proposed strategy computes the costs of each individual in parallel on GPU and corrects the under-constraint individuals in parallel on the multi-core CPU. In this way, a highly efficient parallel computing can be achieved in which dozens of irregular correction computing steps are mapped to the multi-core CPU and thousands of regular cost computing steps are mapped to the many-core GPU. Fourth, at each iteration of the hybrid parallel strategy, the solution vectors of individuals are transferred to the GPU and their costs are transferred back to the CPU. In order to further improve the efficiency of proposed algorithm, we propose an asynchronous transfer pattern (stream concurrency pattern) for CPU-GPU, in which the transfer process and computation process are overlapped and eventually th..."
  },
  {
    "year": "2017",
    "abstract": "Application programming interface (API)-related questions are increasingly posted and discussed by developers in popular question and answer forums, such as Stack Overflow. However, their extremely long resolution time seriously delays the working schedules of developers. Despite researchers have investigated how to automatically resolve API-related questions by recommending correct APIs for them, there is still much room for additional improvement. In this paper, we propose a novel approach of recommending APIs for API-related questions based on API specifications and historical resolved questions (RASH). Given a new API-related question, RASH recommends APIs for it guided by two central observations. First, the more lexically similar the functional description in an API's specification is to the new question, the more likely that the API can resolve the new question. Second, the APIs that have resolved more historical similar questions can also help to resolve the new question. To verify the effectiveness of RASH, we construct and publish a corpus containing 1234 API-related questions with their correct APIs from Stack Overflow, and conduct extensive experiments over it. The experimental results show that RASH is relatively stable and robust to a different quality of questions. In addition, RASH hits nearly 70% correct APIs and outperforms the state-of-the-art approach by 15.64% when recommending 15 APIs for each question."
  },
  {
    "year": "2017",
    "abstract": "For removing noises and recovering intrinsic structure from corrupted image data, a classic modeling approach is based on sparsity assumption. In traditionally, the sparsity is measured by L1-norm. However, L1-norm often leads to bias estimation and the solution is not as accurate as desired. To address this problem, this paper presents a new but effective data recovery model based on the L1-2metric, enabling the robust recovery of corrupted data. The L1-2metric is a non-convex approximation to L0-norm and defined by the difference of L1- and L2-norms. The significant characteristic of our model is measuring both recovery data and error by the L1-2metric. Our model allows for efficient optimization by two steps. Extensive experimental results show significant improvement compared with state-of-the-art algorithms."
  },
  {
    "year": "2017",
    "abstract": "Event-triggered control is a control strategy, which possesses advantages in applications where communication resources are scarce. In this paper, we study event-triggered control for switched delay systems. The proposed triggering condition is satisfied only if an error signal exceeds a dynamic threshold. Sampler updates and transfers the information of states and switching signal to controller when the event is triggered, under which asynchronous switching cannot be avoided. We therefore consider asynchronous switching control for switched delay systems also. The switching signal is assumed satisfying an average dwell time condition, under which globally exponential stability of the closed-loop system can be guaranteed. Finally, a simulation example is given to show the developed result."
  },
  {
    "year": "2017",
    "abstract": "Bitcoin has recently attracted considerable attention in the fields of economics, cryptography, and computer science due to its inherent nature of combining encryption technology and monetary units. This paper reveals the effect of Bayesian neural networks (BNNs) by analyzing the time series of Bitcoin process. We also select the most relevant features from Blockchain information that is deeply involved in Bitcoin's supply and demand and use them to train models to improve the predictive performance of the latest Bitcoin pricing process. We conduct the empirical study that compares the Bayesian neural network with other linear and non-linear benchmark models on modeling and predicting the Bitcoin process. Our empirical studies show that BNN performs well in predicting Bitcoin price time series and explaining the high volatility of the recent Bitcoin price."
  },
  {
    "year": "2017",
    "abstract": "We present a comprehensive review for wireless power transfer (WPT)-aided full-duplex (FD) relay systems. Two critical challenges in implementing WPT-aided FD relay systems are presented, that is, pseudo FD realization and high power consumption. Existing time-splitting or power-splitting structure based-WPT-aided FD relay systems can only realize FD operation in one of the time slots or only forward part of the received signal to the destination, belonging to pseudo FD realization. Besides, self-interference is treated as noise and self-interference cancellation (SIC) operation incurs high power consumption at the FD relay node. To this end, a promising solution is outlined to address the two challenges, which realizes consecutive FD realization at all times and forwards all the desired signal to the destination for decoding. Also, active SIC, that is, analog/digital cancellation, is not required by the proposed solution, which effectively reduces the circuit complexity and releases high power consumption at the FD relay node. Specific classifications and performance metrics of WPT-aided FD relay systems are summarized. Some future research is also envisaged for WPT-aided FD systems."
  },
  {
    "year": "2017",
    "abstract": "The crowdedness of current cellular bands and the demand for higher transmission speed prompt the use of the millimeter-wave spectrum for the next-generation mobile communication. In the millimeter-wave frequencies, the dosimetric quantity for human exposure to electromagnetic fields changes from the specific absorption rate to incident power density. In this paper, we used 28-GHz beam-steering patch arrays, a dipole antenna, and plane waves to investigate the temperature elevation in a multi-layer model of human head and its correlation with power density metrics. The power density averaged over one square-centimeter in free space and the peak temperature elevation in tissue at 28 GHz have good correlation. The peak temperature elevation indicated by the power density averaged one square-centimeter also agrees well with the peak temperature elevation induced by the plane waves. The results show that the averaging area of a few square-centimeters may be a good candidate for the spatial-average power density. The findings provide valuable input to the ongoing revision and updating of relevant safety standards and guidelines."
  },
  {
    "year": "2017",
    "abstract": "Wireless community networks (WCNs) are emerging as an alternative to provide wireless offloading before the deployment of 5G network. However, it is not clear about its development prospects, e.g., how to understand the WCN technology affects the adoption of users, and the competition in a communication market coexisting different wireless technologies, i.e., LTE in unlicensed spectrum. To this end, we envision three distinct development stages of WCN: evolution, regulation, and competition. Specially, we first study the evolution of self-organizing WCN in which the WCN services expands as WCN participants increases. We propose a dynamic model and show the existence of unique equilibrium point at which the fraction of subscribers does not change. Next, we turn to investigate the impact of regulation on a commercial WCN by introducing an operator. The users in commercial WCN can be divided into two parts: insiders and outsiders, according to whether contributing connectivity into the community. We discuss the economic interactions with regard to insiders, outsiders, and the operator, and derive the equilibrium adoption of various users and the optimal price of the WCN operator. We then investigate a competitive duopoly market that coexists a WCN provider (WCNP) and an LTE-U provider (LP). We model the economic relationships among the users, WCNP and LP as a tripartite game, in which the two providers choose their market shares independently. We derive a sufficient condition that guarantees the existence of equilibrium in the market competition game."
  },
  {
    "year": "2017",
    "abstract": "This paper investigates the application of underwater acoustic sensor networks for large scale monitoring of the ocean environment. The low propagation speed of acoustic signals presents a fundamental challenge in coordinating the access to the shared communication medium in such networks. In this paper, we propose two medium access control (MAC) protocols, namely, Transmit Delay Allocation MAC (TDA-MAC) and Accelerated TDA-MAC, that are capable of providing time division multiple access (TDMA) to sensor nodes without the need for centralized clock synchronization. A comprehensive simulation study of a network deployed on the sea bed shows that the proposed protocols are capable of closely matching the throughput and packet delay performance of ideal synchronized TDMA. The TDA-MAC protocols also significantly outperform T-Lohi, a classical contention-based MAC protocol for underwater acoustic networks, in terms of network throughput and, in many cases, end-to-end packet delay. Furthermore, the assumption of no clock synchronization among different devices in the network is a major advantage of TDA-MAC over other TDMA-based MAC protocols in the literature. Therefore, it is a feasible networking solution for real-world underwater sensor network deployments."
  },
  {
    "year": "2017",
    "abstract": "Limited-angle computed tomography (CT) reconstruction problem is an ill-posed inverse problem. Currently, regularized CT reconstructions are usually considered by incorporating the total variation (TV) norm of an image into data fidelity term. However, the reconstructed images may be degraded using the TV-based minimization method with limited-angle artifacts. In recent years, the theory of wavelet tight frame has been well developed and has some advantages in preserving the sharp features as well as smoothness. To further improve the quality of reconstructed images, we propose an image reconstruction method incorporating TV with wavelet tight frame for limited-angle CT problem, which objective function includes ℓ1and ℓ0regularization terms and solved by a TV-based simultaneous algebraic reconstruction technique and an alternating direction method of multipliers. Compared with some TV-based reconstruction methods, the experimental results show that our method can further improve the quality of reconstructed images and suppress the limited-angle artifacts as well as preserve the low-contrast objects."
  },
  {
    "year": "2017",
    "abstract": "Traditional multi-task multi-view (MTMV) models work under the single-objective learning framework and cannot incorporate too many regularization terms, which are primarily attributed to the utilization of the conventional numerical optimization methods. To this end, a cooperative multi-objective MTMV (CMO-MTMV) learning method is proposed in this paper. In CMO-MTMV, the MTMV problem is formulated as a multi-objective optimization problem. Compared with the existing single-objective MTMV learning methods, the proposed CMO-MTMV method integrates more relations, including task-task, view-view, instance-instance, and feature-feature relations as multiple objectives. An effective cooperative multi-objective quantum-behaved particle swarm optimization (CMOQPSO) algorithm is further developed to solve the multi-objective optimization problem. The integration of a multi-swarm scheme and a local communication strategy in CMOQPSO renders this algorithm efficient. The experimental results verify the superiority of the proposed CMO-MTMV method compared with the several state-of-the-art machine-learning methods."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing is the next generation computing model, which has a significant position in the field of scientific and business computing. By predicting cloud service's QoS in next period, it is helpful for end users to choose the most suitable cloud service that meets their needs. The underlying hardware/software resources of cloud architecture may have a certain influence on cloud service QoS. However, existing cloud service QoS prediction approaches do not take this influence into account. As these effects are real during the process of cloud service QoS prediction, ignoring the impact of these effects may create a big gap between the prediction results and the actual results. Therefore, in this paper interactive information is first used to describe the correlation between the hardware/software resources and the QoS attributes of the cloud service. Then, a Bayesian network model is established to predict cloud QoS. Bayesian network prediction reasoning algorithm is used to predict and reason about the future QoS values. A set of dedicated experiments is conducted to validate that our approach can accurately predict QoS of cloud service and the accuracy rate is better than state-of-the-art approaches."
  },
  {
    "year": "2017",
    "abstract": "Proper tuning of hyper-parameters is essential to the successful application of SVM-classifiers. Several methods have been used for this problem: grid search, random search, estimation of distribution Algorithms (EDAs), bio-inspired metaheuristics, among others. The objective of this paper is to determine the optimal method among those that recently reported good results: Bat algorithm, Firefly algorithm, Fruit-fly optimization algorithm, particle Swarm optimization, Univariate Marginal Distribution Algorithm (UMDA), and Boltzmann-UMDA. The criteria for optimality include measures of effectiveness, generalization, efficiency, and complexity. Experimental results on 15 medical diagnosis problems reveal that EDAs are the optimal strategy under such criteria. Finally, a novel performance index to guide the optimization process, that improves the generalization of the solutions while maintaining their effectiveness, is presented."
  },
  {
    "year": "2017",
    "abstract": "Security of medical media is important for patient safety and confidentiality. This paper proposes a framework for the chaos-based quantum encryption of healthcare images. In the framework, healthcare staff in one location send cipher images to the cloud. The healthcare staff in another location receives the images from the cloud. By decrypting the content of the images, the healthcare staff can assist users in a secure manner. This paper also proposes a novel approach for the efficient quantum image encryption of healthcare media. The proposed algorithm utilizes gray code and a chaotic map. The quantum image is scrambled by quantum gray code. Then, the scrambled quantum image is encrypted using a quantum XOR operation based on a key generator controlled by the logistic-sine map. The circuits of the proposed encryption/decryption algorithm are devised based on an NEQR quantum image representation. Numerical and simulation analyses show that the proposed quantum image encryption approach is robust, realizable, and has high efficiency compared with its classical counterpart."
  },
  {
    "year": "2017",
    "abstract": "The quality of coating and the resulting rate of corrosion of the underlying metal substrate can be measured by a variety of corrosion measurements (Tafel, electrochemical impedance spectroscopy) by using standard laboratory electrochemical cells. However, there is always a need of low cost, portable, and non-destructive electrochemical cells, which can be used on-site field for condition monitoring of large structures for example bridges and large infrastructures, complex operating systems as aircrafts, precision machines, petrochemical processes, automotive, and locomotives. This research has developed state of the art cells fabricated by using a special magnetic aluminum compound (AlnXn), which is highly electrically conductive and corrosion resistive. The research has commissioned for deploying this novel sensing technology for micro-defects detection, corrosion rate measurement, and condition assessment of the defected coatings. Tafel measurement facilitated by these non-destructive cells is used to detect micro-defects and corrosion rate measurement while electrochemical impedance spectroscopy measurement is facilitated to measure the coating condition. This technology has been successfully tested and commissioned on automotive, hazardous compartments with polymeric coatings and bridges to assess their coating condition in terms of their structural integrity. Post design testing involved the installation of these cells, running diagnostics, data acquisition, and macrographs to predict structural defects and the resulting corrosion rate. This technology enables the design process to incorporate operational conditions and fully realize more durable and reliable solutions to be applied to high-value large structures and complex interacting systems. Current developments in corrosion condition monitoring especially cost effective and non-destructive techniques to assess structural integrity beneath nonconductive and polymeric coating were long awaited. This reporte..."
  },
  {
    "year": "2017",
    "abstract": "Dynamic taxi sharing is an effective approach to reducing travel cost and conserving energy resources. Existing taxi sharing frameworks fail to consider personal preferences of passengers on taxisharing and unable to group them with compatible preferences for generating the optimal sharing schedule. In this paper, we propose a novel taxi-sharing framework called R-Sharing to provide a personalized rendezvous-sharing service. It enables passengers to set their preferences on four essential sharing experience, i.e., walking distance, waiting time, travel fare, and extra travel time. Given a sharing request, R-Sharing searches the optimal set of nearby companions with compatible personal preferences and similar destination directions, recommends a rendezvous point for them to meet, and plans the shortest sharing route, such that these passengers' probability of accepting the sharing schedule is maximized. Specifically, a companion candidate searching algorithm is proposed for searching nearby potential candidates to sharing a taxi for the request. To select the optimal subset of candidates and generate their optimal sharing schedule, we propose an exact taxi-sharing scheduling algorithm, in which, the rendezvous point is set by considering passengers' personal preference on walking distance and road network factors, and the shortest sharing route is planned by dynamic programming. Further, a heuristic sharing scheduling algorithm is developed to improve the efficiency. Extensive experiments are conducted using a one-month taxi trajectory data set collected in Nanjing, China. Experimental results show that R-Sharing is not only effective in terms of achieving better sharing ratio and reduced total travel distance, but also provides superior sharing experiences."
  },
  {
    "year": "2017",
    "abstract": "Network infrastructure sharing has been recently introduced as a promising solution toward energy reduction in cellular networks. In this paper, a framework for the potential power saving inherent in the network sharing approach is provided in multi-operator mobile networks. The overall downlink transmitted power consumption is derived in closed form expression as a function of relative inter-base stations (BSs) distance of cooperative operators. In addition, the optimal inter-BSs distance is deduced to obtain minimum power consumption in multi-operator networks. The proposed model is evaluated and compared with nonroaming scenario in order to provide an apparent vision for saving in power in mobile network operators networks. The proposed model provides a framework to guide the operators whether to roam the user equipment or not."
  },
  {
    "year": "2017",
    "abstract": "This paper analyzes a flexible job shop scheduling problem with operators and is motivated by a real-life case study of the aeronautical industry, where each process can be performed on alternative machines (shared by multiple products) and requires not only machines but also some operators to execute the process. One goal of this scheduling is to minimize the number of operators and airframes that are needed in the assembly line. Minimizing the number of airframes in the assembly line, which is particularly important due to the cost of each airframe, is generally ignored in production planning models that are used in prior studies. Moreover, the output of the program refers to a set of schedules that includes different combinations of number of operators and intermediate stock, to enable a better decision making. A mixed integer linear programming model is presented to solve this problem. Experimentation was conducted using real-life examples from the aeronautical industry. The solutions that are presented in this paper outperformed current industrial methods in both quality and calculation time. To the best of our knowledge, this variant has not been addressed in prior studies either in scheduling or in aeronautics contexts. However, minimizing the number of operators and intermediate stock could have significant implications for numerous labor intensive industries, contributing to enhanced and more agile decision making processes."
  },
  {
    "year": "2017",
    "abstract": "This paper presents a wideband circularly polarized (CP) antenna based on two Vivaldi antenna elements. The two elements are orthogonally placed for compact consideration, and are driven by a specially designed wideband feeding network that splits the input signal into two-way signals with equal magnitude and orthogonal phase. In order to avoid crossing of the feeding lines of two Vivaldi elements, a small shift between them is introduced. This, however, will result in the undesired phase difference of two Vivaldi elements inevitably. To compensate the phase difference and ensure a wide axial ratio bandwidth, the feeding network is specially designed. Besides, to make full use of the antenna space, the feeding network is placed on the surface of two Vivaldi elements. For demonstration purpose, a prototype is fabricated. The measured results show a -10 dB impedance bandwidth of 101.3% (2.35 to 7.18 GHz) and 3 dB axial-ratio bandwidth of 118.4% (2.05 to 8 GHz), and the maximum realized gain is 7.5 dBic. Meanwhile, stable radiation patterns are achieved with the cross-polarization lower than -20 dB across the wide operating bandwidth at boresight direction."
  },
  {
    "year": "2017",
    "abstract": "Personal privacy is facing severe threats as social networks are sharing user data with advertisers, application developers, and data mining researchers. Although these data are anonymized by removing personal information, such as user identity, nickname, or address information, personal information still could not be protected effectively. In order to arouse the attention of people from academia and industry for privacy protection, we propose a random forest method to de-anonymize social networks. First, we convert the social network de-anonymization problem into a binary classification problem between node pairs. In order to partition large sparse social networks, we use the spectral partition method to partition large graphs into a number of small subgraphs. Then, we use the features of the network structure to train the random forest classifier. As a result, candidate node pairs from anonymous network and auxiliary network can be classified as matched pair by the random forest classifier. Furthermore, we improve the efficiency of our solution through parallelizing proposed method. The experiments conducted on the real data sets show that our solution's area under the curve is 19% higher than baseline methods on average. Besides that we test the robustness of the proposed algorithm by adding some noisy data, and the result demonstrates that our solution has good robustness."
  },
  {
    "year": "2017",
    "abstract": "In the complex marine environment, a large-scale wireless sensor network (WSN) is often deployed to resolve the sparsity issue of the signal and to enforce an accurate reconstruction of the signal by upgrading the transmission efficiency. To best implement, such a WSN, we develop a holistic method by considering both raw signal processing and signal reconstruction factors: a node re-ordering scheme based on compression sensing and an improved sparse adaptive tracking algorithm. First, the sensor nodes are reordered at the sink node to improve the sparsity of the compression sensing algorithm in the discrete cosine transformation or Fourier transform domain. After that, we adopt the matching test to estimate sparse degree Kis. At last, we develop a sparse degree adaptive matching tracking framework step-by-step to calculate the approximation of sparsity, and ultimately converge to a precise reconstruction of the signal. In this paper, we employ MATLAB to simulate the algorithm and conduct comprehensive tests. The experimental results show that the proposed method can effectively reduce the sparsity of the signal and deliver an accurate reconstruction of the signal especially in the case of unknown sparsity."
  },
  {
    "year": "2017",
    "abstract": "The latest 6TiSCH standard enables highly reliable industrial monitoring and control applications through deterministic wireless communications and efficient allocation of radio resources among wireless nodes. However, much of these benefits are tied to the ability of the scheduler in orchestrating communication over individual links in an efficient and a non-conflicting manner. The state-of-the-art 6TiSCH scheduling algorithms only tackle the scheduling problem at the MAC layer with an assumption of having an optimal routing layer. Moreover, to the best of our knowledge, no solution so far has taken contentspecific scheduling into account. This paper proposes CONCISE, which is a content-centric cross-layer scheduling solution. CONCISE creates content-independent routing topologies and schedulers, resulting in an overlaid routing structure and multiple content-based schedules. Further, CONCISE addresses in-network processing and data aggregation with the objective of reducing network traffic. Performance evaluation demonstrates that CONCISE can effectively reduce inner layer network traffic by up to 65%. As a result, it can provide up to 50% delay reduction and achieve significantly higher packet delivery ratio, compared with existing scheduling solutions. Initial proof of concept is implemented and evaluated in Contiki OS."
  },
  {
    "year": "2017",
    "abstract": "The dry electrodes that the automotive manufacturers use to measure electrocardiogram (ECG) signals for driver status monitoring have three technical problems: a lack of attachment flexibility, low ECG signal detection stability, and the potential to harm or irritate the driver. In addition, the complicated signal-conditioning circuits employed by automotive manufacturers to improve the SNR, increase the ECG signal detection stability, and to ensure a wider dynamic range of the electrodes increase the cost and complexity of driver ECG measuring systems. In this paper, we propose a driver ECG measuring system that resolves these three technical issues using a steering wheel covered with a conductive fabric-based dry electrode material, which is manufactured by an electroplating method. In addition, we employ a conductive fabric-shaping procedure in the development of the fabric-based dry electrode to improve the attachment flexibility and to reduce the cost and complexity of the required signal-conditioning circuit. We verify the ECG signal-measuring performance of the proposed system by comparing it with ECG signal measurement results from a clinical ECG monitoring system. In addition, despite applying a simpler signal conditional circuit than those used in conventional ECG measuring systems, we verify that the proposed system achieves higher SNR and ECG signal detection stability than conventional ECG measuring systems through various field tests in actual driving environments."
  },
  {
    "year": "2017",
    "abstract": "MiRNAs are a kind of non-coding RNA molecules found in plants, animals, and various viruses. They have been proved to play an important role in multiple biological as well as physiological processes. Specifically, a growing number of studies have shown that miRNAs have close relationships with many diseases, and thus the exploration of the relationships between miRNAs and diseases is of great significance in disease research. Although traditional experimental methods can obtain the associations between miRNAs and diseases, the amount of data obtained is far from enough for us to fully understand the associations between them. Besides, traditional experiments are generally time-consuming and expensive. Therefore, it is necessary to propose efficient computational methods to predict miRNA-disease associations. In this paper, we develop a novel computational method based on KATZ model to predict MiRNA-Disease Associations (KATZMDA) by integrating multiple data sources. To evaluate the performance of KATZMDA, four classical methods are used to compare with our methods (WBSMDA, HGIMDA, RKNNMDA, MCMDA). The experimental results demonstrate that our method can be used as an effective tool to identify disease-related miRNAs. In addition, case studies of three common diseases further verify the utility of our method."
  },
  {
    "year": "2017",
    "abstract": "The co-existence of the microwave and millimeter-wave technologies becomes the inexorable trend of the future wireless communication systems. The corresponding components within the system are required to cover these two frequency bands simultaneously. But the existing dual-/multiband components cannot satisfy this requirement. For the first time, a new class of components are proposed to provide simultaneous power splitting functions at microwave and millimeter-wave frequency bands. To achieve such a large frequency ratio, an effective feeding approach should be proposed to properly route the signal between the input/output ports and the two elements which operate at microwave and millimeter-wave frequency bands respectively. For universality, the popular microstrip line and substrate integrated waveguide (SIW) structures are utilized for the implementation of microwave and millimeter-wave elements, respectively. An aperture coupling mechanism which can suppress the high order mode of the microstrip structure and excite the TE10 mode of the SIW structure at the same time is proposed. A simple transmission model is utilized to explain the working principle along with the theoretical analysis. Based on this novel feeding approach, fourdual-/tri-band components which can achieve a large frequency ratio up to 33.3 were designed, fabricated, and measured. Besides the flexibility in operating frequency, the proposed structure can provide arbitrary coupling coefficients (3-10 dB) and even different functionalities at the two frequency bands, which had not been reported in the literature."
  },
  {
    "year": "2017",
    "abstract": "Near-threshold computing brings several times of magnitude improvement in energy efficiency of digital circuits. However, it also introduces several times of deteriorated delay variations caused by process, voltage, and temperature (PVT) variations. In situ timing monitoring-based adaptive techniques can mitigate excessive timing margins caused by PVT variations, but current frequency and/or voltage tuning methods cause large performance loss. In this paper, we propose a low overhead timing error prediction monitor and a super-fast clock stretching circuit to solve this problem. They are both optimized for near threshold voltage of 0.5 V. When there are timing margins, the frequency will be increased. Until when the timing is intense due to variations, timing monitors will generate a predicted alarm signal. Accordingly, the system clock will be stretched immediately to avoid real timing errors. Applied on a 40-nm CMOS Bitcoin Miner chip, simulation results show that the whole system operating at near-threshold voltage can increase the frequency to up to 2.1× compared with the original non-monitored circuit. Our method can increase the energy efficiency to mitigate near-threshold variations effectively."
  },
  {
    "year": "2017",
    "abstract": "Advanced public safety communication (PSC) services call for fast, reliable and low-latency communication technologies, capable of supporting diverse communication modes (aerial, unmanned, vehicular, and peer-to-peer), fast channel dynamics, and ad hoc or mesh structures. For this reason, PSC has been identified as one of the key potential uses cases for the next generation of communication systems, the so-called 5G. In this scenario, the millimeter wave (mmWave) bands and other frequencies above 6 GHz are particularly interesting, since they are largely untapped and offer vastly more spectrum than current cellular allocations in the highly congested bands below 6 GHz, thus enabling orders of magnitude greater data rates and reduced latency. For example, new PSC networks in the mmWave bands could support high-definition video, virtual reality, and other broadband data to large numbers of first responders. Surveillance drones or ambulances could also be provided high-speed connectivity along with machine-type communication for remotely controlled robotic devices entering dangerous areas. However, the way towards this ambitious goal is hindered by a number of open research challenges. In this paper, after a brief introduction to PSC services and requirements, we illustrate the potential of the frequencies above 6 GHz for PSC and discuss the open problems that need to be solved in order to pave this way. Finally, we describe the main components of a test platform for mmWave systems that is functional to the study of such complex scenarios and that we plan to develop as an invaluable tool for realizing mmWave PSC networks."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we propose the negative ε dragging technique for robust classification of noisy and contaminated data. Different from the naïve ε dragging technique, the negative ε dragging technique argues that robust results can be obtained by properly reducing the class margin of conventional least squares regression when performing classification on noisy data. The underlying rationale of the negative ε dragging technique assumes that setting a relative small class margin for the training procedure of least squares regression leads to desirable generalization capability, which, therefore, considerably contributes to boosting the classification performance for the data corrupted with noise. The experimental results indicate that our technique obtains better classification accuracy."
  },
  {
    "year": "2017",
    "abstract": "Fall events are important health issues in elderly living environments such as homes. Hence, a confident and real-time video surveillance device that pays attention could better their everyday lives. We proposed an optical flow feedback convolutional neural network according to the video stream in a home environment. Our proposed model uses rule-based filters before an input convolutional layer and the recorded optical flow for supervising the optical flow of variation. Detecting human posture is a key factor, while fall events are like a falling posture. By sequencing frames of action, it is possible to recognize a fall. Our system can clearly detect the normal lying posture and lying after falling. Our proposed method can efficiently detect action motion and recognize the action posture. We compared the performance with other standard benchmark data sets and deployed our model to simulate a real-home situation, and the correct ratio achieved 82.7% and 98% separately."
  },
  {
    "year": "2017",
    "abstract": "The underrepresentation of women in engineering remains a problem till this day, where women made up 4% of its registered professional engineers in South Africa in 2014. The experience of women engineers in industry and women students in engineering courses can play a significant role in their decision to remain in engineering or pursue a different career path. The investigation of gender dynamics in small groups of engineering students, specifically focusing on the participation and role allocation of women students, can shed light on the experiences of women students in the engineering education environment. This paper shows that, although women engineering students are still in the minority in engineering courses, many are active participators in groups and fulfill leadership roles in those groups."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate disaster-recovery communications utilizing two-cell cooperative D2D communications. Specifically, one cell is in a healthy area, while the other is in a disaster area. A user equipment (UE) in the healthy area aims to assist a UE in the disaster area to recover wireless information transfer via an energy harvesting relay. In the healthy area, the cellular base station (BS) shares the spectrum with the UE, however, both of them may belong to different service providers. Thus, the UE pays an amount of price as incentive to the BS as part of two processes: energy trading and interference pricing. We formulate these two processes as two Stackelberg games, where their equilibrium is derived as closed-form solutions. The results help providing a sustainable framework for disaster recovery when the involving parties juggle between energy trading, interference compromise, and payment incentives in establishing communications during the recovery process."
  },
  {
    "year": "2017",
    "abstract": "The emergence of smarter and broader people-oriented IoT applications and services requires interoperability at both data and knowledge levels. However, although some semantic IoT architectures have been proposed, achieving a high degree of interoperability requires dealing with a sea of non-integrated data, scattered across vertical silos. Also, these architectures do not fit into the machine-to-machine requirements, as data annotation has no knowledge on object interactions behind arriving data. This paper presents a vision of how to overcome these issues. More specifically, the semantic profiling of objects, through CoRE related standards, is envisaged as the key for data integration, allowing more powerful data annotation, validation, and reasoning. These are the key blocks for the development of intelligent applications."
  },
  {
    "year": "2017",
    "abstract": "In view of the varying characteristics of material properties, environmental conditions, and loading effects randomly with long time, the random and temporal characters of different variables should take into account when the structural reliability analysis methods are adopted to estimate the reliability of ship structures. Therefore, a time-variant reliability analysis method combined the out-crossing approach and the first-order reliability method is proposed. In this paper, the research is conducted on the time-variant feature of ship structures under the corrosive action according to the environmental testing data. Furthermore, the limit state function is derived based on the time-variant feature analysis results in which the strength and stress of ship structures are both regarded as variables with respect to time. Then, the time-dependent reliability model of ship structures is established based on this combined method, and the solving process of parameters in this model is illustrated. Finally, a case of a ship grillage structure under marine environment is given to prove that the proposed method has a good application in evaluating the reliability of ship structures. The comparison analysis using different methods is also conducted to study the accuracy and efficiency of this method."
  },
  {
    "year": "2017",
    "abstract": "Dynamic reconfiguration techniques can greatly improve the flexibility and reliability of manufacturing systems. However, different from static reconfigurable systems, system behavior during dynamic reconfiguration processes is quite complex due to possible concurrence of system structure changes and events inside unaltered components. This increases the difficulty in designing and developing dynamic reconfigurable systems. The current paper deals with the analysis and control of dynamic reconfiguration process of manufacturing systems from the perspective of discrete event systems. To this end, the authors improve the reconfigurable timed net condition/event systems formalism by assigning reconfiguration functions with extra permeating time, action ranges, and concurrent decision functions. As a consequence, nondeterministic behavior of a dynamic reconfigurable system during dynamic reconfigurations can be specified, while the system correctness, coherence, and safety during reconfigurations can be guaranteed. A reconfigurable manufacturing plant is used as a running example to illustrate the contribution of this paper."
  },
  {
    "year": "2017",
    "abstract": "A novel visual and infrared sensor data-based system to assist visually impaired users in detecting obstacles in their path while independently navigating indoors is presented. The system has been developed for the recently introduced Google Project Tango Tablet Development Kit equipped with a powerful graphics processor and several sensors which allow it to track its motion and orientation in 3-D space in real-time. It exploits the inbuilt functionalities of the Unity engine in the Tango SDK to create a 3-D reconstruction of the surrounding environment, then associates a Unity collider component with the user and utilizes it to determine his interaction with the reconstructed mesh in order to detect obstacles. The user is warned about any detected obstacles via audio alerts. An extensive empirical evaluation of the obstacle detection component has yielded favorable results, thus, confirming the potential of this system for future development work."
  },
  {
    "year": "2017",
    "abstract": "Visualization and simulation models used for the evaluation and selection of security countermeasures need accurate data to compute the impact of cyber events (e.g., malicious and benign actions). The information required to build appropriate impact models depends directly on the nature of the system. The information dealt by water supply systems, for instance, is particularly different from the information obtained by energy, telecommunication, transportation, or finance systems. It is, therefore, important to properly classify the data of security events according to the nature of the system. This paper proposes an event data taxonomy based on the system's criticality, the geographical location of the target, the time at which the information is obtained by the attacker, and the nature of the data. A use case on the impact assessment of events originated in a critical infrastructure is presented to show the applicability of the proposed taxonomy."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes the base station ordering localization technique (BoLT) for emergency call localization in cellular networks. Exploiting the foreseen ultra-densification of the next-generation (5G and beyond) cellular networks, we utilize higher order Voronoi tessellations to provide ubiquitous localization services that are in compliance to the public safety standards in cellular networks. The proposed localization algorithm runs at the base stations (BSs) and requires minimal operation from agents (i.e., mobile users). Particularly, BoLT requires each agent to feedback a neighbor cell list that contains the order of neighboring BSs based on the received signal power in the pilots sent from these BSs. Moreover, this paper utilizes stochastic geometry to develop a tractable mathematical model to assess the performance of BoLT in a general network setting. The goal of this paper is to answer the following two fundamental questions: 1) how many BSs should be ordered and reported by the agent to achieve a desirable localization accuracy? and 2) what is the localization error probability given that the pilot signals are subject to shadowing? Assuming that the BSs are deployed according to a Poisson point process, we answer these two questions via characterizing the tradeoff between the area of location region and the localization error probability in terms of the number of BSs ordered by the agent. The results show that reporting the order of six neighboring BSs is sufficient to localize the agent within 10% of the cell area. Increasing the number of reported BSs to ten confines the location region to 1% of the cell area. This would translate to the range of a few meters to decimeters in the foreseen ultra-dense 5G networks."
  },
  {
    "year": "2017",
    "abstract": "Speckle noise is inevitable in the process of acquiring of digital holograms. In this paper, a new approach is proposed to suppress the speckle noise in the digital hologram. The method is composed of two steps: 1) to enhance the noisy digital holograms by Gamma correction, and 2) to process the reconstructed images by filtering. It is demonstrated that the presented method can effectively reduce speckle noise in the digital hologram."
  },
  {
    "year": "2017",
    "abstract": "The fourth industrial revolution involves the advanced topics, such as industrial Internet of Things, cyber-physical system and smart manufacturing that address increasing demands for mass customized manufacturing. The agent-based manufacturing is a highly distributed control paradigm that can cope with these challenges well. This paper gives an overview of agent-based architectures for manufacturing systems. Besides, a cloud-assisted self-organized architecture is presented by comprising smart agents and cloud to communicate and negotiate through networks. Ontological representations of knowledge base are constructed to provide the information basis for decision-making of agents, which enables dynamic reconfiguration among agents in a collaborative way to achieve agility and flexibility. Furthermore, the agents' interaction behavior is modeled to structure the agents hierarchically to reduce the complexity, because the interactions among agents in distributed system are difficult to understand and predict. The experimental results show that the presented architecture can be easily deployed to build smart manufacturing system and can improve the adaptiveness and robustness of the manufacturing system when dealing with mixed multi-product tasks."
  },
  {
    "year": "2017",
    "abstract": "This paper describes the research made toward improving medical case retrieval for Alzheimer's Disease (AD). Our approach considers using Magnetic Resonance Images as an input for the search. To improve the retrieval process, we used longitudinal information extracted from the different sets of scans acquired at different time points and automatically extracted descriptors to represent input images. All experiments were performed with and without quality control (QC) to determine the influence of the errors caused by the automated processing to the results relevance. For the experiments, a total of 267 subjects from the AD Neuroimaging Initiative database with available scans at baseline, the 6-month, 12-month, and 24-month follow-ups were selected. The obtained results showed that the selection of the time points for extraction of the longitudinal information influences the retrieval performance. Results also showed that not all automatically generated descriptors lead to improvement of the results. Longitudinal volume changes provide the most relevant representation. Adding QC phase in the experiments leads to improvements in all examined scenarios. The results showed that the most frequent automatically selected features are common semantic markers for AD."
  },
  {
    "year": "2017",
    "abstract": "A 12-port antenna array operating in the long term evolution (LTE) band 42 (3400-3600 MHz), LTE band 43 (3600-3800 MHz), and LTE band 46 (5150-5925 MHz) for 5G massive multiple-input multiple-output (MIMO) applications in mobile handsets is presented. The proposed MIMO antenna is composed of three different antenna element types, namely, inverted π-shaped antenna, longer inverted L-shaped open slot antenna, and shorter inverted L-shaped open slot antenna. In total, eight antenna elements are used for the 8×8 MIMO in LTE bands 42/43, and six antenna elements are designed for the 6×6 MIMO in LTE band 46. The proposed antenna was simulated, and a prototype was fabricated and tested. The measured results show that the LTE bands 42/43/46 are satisfied with reflection coefficient better than -6 dB, isolation lower than -12 dB, and total efficiencies of higher than 40%. In addition to that, the proposed antenna array has also shown good MIMO performances with an envelope correlation coefficient lower than 0.15, and ergodic channel capacities higher than 34 and 26.5 b/s/Hz in the LTE bands 42/43 and LTE band 46, respectively. The hand phantom effects are also investigated, and the results show that the proposed antenna array can still exhibit good radiation and MIMO performances when operating under data mode and read mode conditions."
  },
  {
    "year": "2017",
    "abstract": "Many target detectors commonly utilize a single a priori target spectral signature as an input. However, the detection results are greatly affected by the quality of the a priori target spectral signature because the spectral variability phenomenon is universal and anisotropic in hyperspectral image data. This paper proposes a sparse representation-based method to generate an optimized target spectrum from limited target training samples, which is able to alleviate the impact of spectral variability on hyperspectral target detection. When lacking comprehensive knowledge about the target object of interest, an optimized representative target spectrum should be expected to be reconstructed by the hyperspectral data themselves in a sparse representation manner following the characteristics of the data structure and then be generated by a set of selected candidate pixels that contain the target signal with a varying status. With the optimized a priori target signature, the experimental results of the detection of different characteristics of objects with three different types of hyperspectral images confirm the effectiveness, robustness, and generality performance of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "In visual tracking, a mature scale estimation method can greatly improve tracking performance and provide accurate target information for model training. However, many visual tracking approaches ignore the scale estimation problem or adopt a heuristic and exhaustive scale-estimation strategy. In this paper, we propose a novel correlation-filter based visual tracking approach that reveals the missing link between scale estimation and the detection response. In contrast to many multi-scale visual trackers, which generate samples at different scales using some pre-designed criteria and then select the sample with the maximal classifier response, in this paper, we deduce a scale estimation equation based on detection responses; thus, the scale of the target object can be estimated mathematically. To obtain a more stable estimated object scale, a constraint function that considers the prior knowledge of visual tracking is proposed. Moreover, a hybrid sample learning scheme is formulated to select pertinent training samples with higher learning weights to train the appearance model. Our tracker operates under a framework of correlation filters to achieve a high tracking speed. We demonstrate the efficiency and robustness of our proposed tracking algorithm by comparing it with 14 other state-of-the-art trackers on all the video sequences in the object tracking benchmark (OTB) 2013 dataset."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a two-layer model for islanded microgrids with communication constraints is proposed, where a key component of the model is a top layer communication network composed of agents over the bottom layer microgrid. Agents on the communication network collect present states of distributed generators to which they connect and exchange information with neighbors according to the asynchronous communication protocol. Furthermore, a systematic method is presented to derive a set of control laws for agents from a given communication network. However, communication constraints, such as packet losses, may occur on the communication network. Therefore, a power estimation term is employed and added into the control laws in order to alleviate the negative impact on the performance. Furthermore, two theorems are proved, which ensure the power balance in the system and the proportional outputs of distributed generators, while the proposition gives the convergence of the control laws with the power estimation term. Finally, simulations are carried out and the results show that the fluctuations of the frequency and voltage are small and meet the requirements, when fluctuations of load demand and environmental conditions are considered. Moreover, the proportional outputs of distributed generators still can be achieved, even if the probability of packet losses is high."
  },
  {
    "year": "2017",
    "abstract": "In underdetermined blind source separation (UBSS) of vibration signals, the estimation of the mixing matrix is often affected by noise and by the type of the used clustering algorithm. A novel UBSS method for the analysis of vibration signals, aiming to address the problem of the inaccurate estimation of the mixing matrix owing to noise and choice of the clustering method, is proposed here. The proposed algorithm is based on the modified k-means clustering algorithm and the Laplace potential function. First, the largest distance between data points is used to initialize the cluster centroid locations, and then the mean distance between clustering centroids average distance range of data points is used for updating the locations of cluster centroids. Next, the Laplace potential function that uses a global similarity criterion is applied to fine-tune the cluster centroid locations. Normalized mean squared error and deviation angle measures were used to assess the accuracy of the estimation of the mixing matrix. Bearing vibration data from Case Western Reserve University and our experimental platform were used to analyze the performance of the developed algorithm. Results of this analysis suggest that this proposed method can estimate the mixing matrix more effectively, compared with existing methods."
  },
  {
    "year": "2017",
    "abstract": "This paper provides a comprehensive survey of content placement (CP) algorithms for cloud-based content delivery networks (CCDNs). CP algorithms are essential for content delivery for their major role in selecting content to be stored in the geographically distributed surrogate servers in the cloud to meet end-user demands with quality of service (QoS). Evidently, the key objectives of CP, i.e., cost and QoS, are competing. Cost is determined by the underlying cost model of the CCDN infrastructure while the delivered QoS is determined by where the content is placed in the CCDN. Therefore, we provide an overview of the content and the CCDN infrastructure. The overview of the content includes content characteristics and the influence of Online Social Networking on CP. The overview of the CCDN infrastructure includes elasticity and cost model, which affect CP. Our goal is to provide a holistic perspective of the aspects that impact CP algorithms and their efficiency. From the influential factors, we derive a set of design criteria for CP algorithms in CCDNs. We discuss the state-of-the-art CP algorithms for CCDNs and evaluate them against the well-motivated design criteria. We also delineate practical implications and uncover future research challenges."
  },
  {
    "year": "2017",
    "abstract": "Accurate recognition of distribution line fault types can provide directional guidance for line operation and maintenance personnel. Based on the analysis of time-frequency features of fault waveform, a recognized method of distribution line fault type was proposed in this paper. Through modeling and theoretical analysis of waveforms of different fault types, characteristic parameters, which could characterize waveforms of different fault types from three aspects, time domain, frequency domain, and electric arc, were put forward. Calculation formula for extracting characteristic parameters according to fault waveform data was proposed, recognition logic was established by taking multi-parameter fusion as a basis, and then,automatic recognition of distribution line fault types caused by different factors was realized through detection and classification of characteristic parameters of input waveform data. Finally, 136 groups of field fault waveform data provided by the Electric Power Research Institute were used to do closed-loop control and verification of the algorithm, and results indicated that recognition success rate reached 90%, which verified the feasibility of using time-frequency characteristics of fault waveform to realize recognition of distribution line fault types."
  },
  {
    "year": "2017",
    "abstract": "Wireless energy transfer technologies have played an important role in the development of Internet of Things. Most of the previous studies focus on scheduling mobile chargers efficiently for rechargeable sensor nodes. In this paper, we investigate the deployment problem for wireless charging stations (WCSs) in urban areas with respect to the users detouring cost when they move to the candidate WCSs. With pre-known user's trajectories and given number of WCSs, we deploy the WCSs to maximize the number of recharged users with guaranteed probability. We convert our deployment problem into an NP-hard weighted maximum coverage problem, and prove the objective function is a maximum submodular set function. To this end, a simple but efficient greedy algorithm with approximation factor of (1 - 1/ε) is proposed for the threshold detouring mode. In addition, an improved algorithm with an approximation factor of (1 - 1/√e) is presented for the linear/nonlinear detouring mode. Finally, we evaluate the performance of our algorithms by comparing them with two typical heuristic algorithms (flow-centric and random-based), and the impacts of different detouring thresholds on our algorithms by synthetic traces. Moreover, real trace-driven evaluations validate that our algorithm improves the coverage quality by 75% when compared to the two aforementioned algorithms."
  },
  {
    "year": "2017",
    "abstract": "In index modulation schemes, information bits are conveyed through indexing of transmission entities, such as antennas, subcarriers, times slots, precoders, subarrays, and radio frequency (RF) mirrors. Index modulation schemes are attractive for their advantages, such as good performance, high rates, and hardware simplicity. This paper focuses on index modulation schemes in which multiple transmission entities, namely, antennas, time slots, and RF mirrors, are indexed simultaneously. Recognizing that such multidimensional index modulation schemes encourage sparsity in their transmit signal vectors, we propose efficient signal detection schemes that use compressive sensing based reconstruction algorithms. Results show that, for a given rate, improved performance is achieved when the number of indexed transmission entities is increased. We also explore indexing opportunities in load modulation (LM), which is a modulation scheme that offers power efficiency and reduced RF hardware complexity advantages in multiantenna systems. Results show that indexing time and RF mirrors in load modulated multiantenna systems can achieve improved performance. A stagewise algorithm based on message passing suited for the detection of indexed LM signals is also proposed."
  },
  {
    "year": "2017",
    "abstract": "With the development of intelligent transportation systems, the estimation of traffic flow in urban areas has attracted a great attention of researchers. The timely and accurate travel information of urban residents could assist users in planning their travel strategies and improve the operational efficiency of intelligent transportation systems. Currently, the origin-destination (OD) flows of urban residents are formulated as an OD matrix, which is used to denote the travel patterns of urban residents. In this paper, a simple and effective model, called NMF-AR, is proposed for predicting the OD matrices through combining the nonnegative matrix factorization (NMF) algorithm and the Autoregressive (AR) model. The basic characteristics of travel flows are first revealed based on the NMF algorithm. Then, the nonlinear time series coefficient matrix, extracted from the NMF algorithm, is estimated based on the AR model. Finally, we predict OD matrices based on the estimated coefficient matrix and the basis matrix of NMF. Extensive experiments have been implemented, in collected real data about taxi GPS information in Beijing, for comparing our proposed algorithm with some known methods, such as different kinds of K-nearest neighbor algorithms, neural network algorithms and classification algorithms. The results show that our proposed NMF-AR algorithm have a more effective capability in predicting OD matrices than other models."
  },
  {
    "year": "2017",
    "abstract": "To improve the segmentation performance of thresholding methods, a novel strategy of integrating the spatial information between pixel’s is proposed in this paper. The proposed strategy utilizes pixel’s gray level and its local entropy within a neighborhood to construct a novel 2-D histogram, called gray level-local entropy (GLLE) histogram. The local entropy can effectively reflect the homogeneity of a pixel’s gray level in a neighborhood. Based on the GLLE histogram, an ideal thresholding vector is obtained by maximizing the total Tsallis entropy of background and objects. The proposed method is validated through segmenting several real images. Experimental results show that the proposed method outperforms many existing thresholding methods."
  },
  {
    "year": "2017",
    "abstract": "The quasi-elliptic multi-mode bandpass cavity filters and duplexer with slot mixed-coupling structure are proposed in this paper. A single metal cavity embedded with a rectangular- shaped slot-cut metal plate is utilized to constitute a multi-mode bandpass filter with a few features including wide passband, low profile and controllable transmission zeros (TZs). In this paper, the slot-cut metal plane serves as the multi-mode resonators. In detail, the slot on the metal plane functions as the circuit element to move the higher order modes within the reasonable frequency-band, while serving as a mixed-coupling structure to generate out-of-band transmission zeros. To demonstrate the multiple-mode capability in filter design, the dual-mode, triple-mode, and quadruple-mode filters are developed by appropriately allocating a few TZs in the upper stopbands using the proposed slot mixed-coupling approach, namely, Type-I filters. Next, a quadruple-mode cavity filter with both lower and higher TZs is designed, namely, Type-II filter, which is further applied for the exploration of a duplexer. Finally, the filter and duplexer prototypes are fabricated and measured. The measurement results are found in good agreement with the simulated ones."
  },
  {
    "year": "2017",
    "abstract": "Inter cell interference (ICI) is a major challenge that degrades the performance of mobile systems, particularly for cell-edge users. This problem arises significantly in the next-generation system, as the trend of deployment is with high densification, which yields an ultra-dense network (UDN). One of the challenges in UDN is the dramatic increase of ICI from surrounding cells. A common technique to minimize ICI is interference coordination techniques. In this context, the most efficient ICI coordination is fractional frequency reuse (FFR). This paper investigates the FFR in UDN millimeter wave network at 26-GHz band. The focus is on dense network with short inter site distance, and higher order sectorisation (HOS). The metrics used in frequency reuse is the signal to interference plus noise ratio rather than the distance, as the line of sight in millimeter wave can be easily blocked by obstacles even if they are in close proximity to the serving base station. This paper shows that FFR can improve the network performance in terms of per user cell-edge data throughput and average cell throughput, and maintain the peak data throughput at a certain threshold. Furthermore, HOS has a potential gain over default sectored cells when the interference is carefully coordinated. The results show optimal values for bandwidth split per each scenario in FFR scheme to give the best tradeoff between inner and outer zone users performance."
  },
  {
    "year": "2017",
    "abstract": "Activity recognition is important for taking care of patients and old men especially in e-Health. The activity recognition system without carrying any wearable devices is widely used in our daily life. Current methods employing uneconomical equipment or even dedicated devices lead to cost-inefficiency for large-scale deployments. This paper introduces R&P, a device-free activity recognition system only using cheap radio frequency identification devices (RFID) tags. Based on the analysis of RFID signals, we extract received signal strength fingerprints and phase fingerprints for each activity and synthesize these two kinds of fingerprints to accurately recognize activities. Moreover, we also modify the dynamic time warping (DTW) algorithm and propose T-DTW method to improve the recognition efficiency. We use commercial passive RFID hardware and verify R&Pin three different environments with different targets and six activities. The results demonstrate that our solution can recognize activities with an average accuracy of 87.9%."
  },
  {
    "year": "2017",
    "abstract": "Synthetic transmit aperture (STA) ultrasound imaging that obtain bi-directional focusing can create a high-resolution image. Delay-and-sum (DAS) approach is performed in both transmit and receive modes, which leads to low contrast and high sidelobe. Adaptive weighting technology is effective in improving image quality. This paper proposes a new adaptive weighting factor namely signal eigenvalue factor (SEF) for STA imaging. SEF performs eigenvalue decomposition on transmitting aperture, and then it uses the larger eigenvalues as the weighting factor to carry out the adaptive imaging. For comparison, conventional coherence factor (CF) method is also presented. Simulation and experimental results show that SEF method can get higher resolution than CF and DAS. In addition, the contrast radio and contrast-to-noise radio can be enhanced, especially for massive cyst."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address a number of weaknesses of the windowed decoding of spatially coupled low-density parity-check (SC LDPC) codes and propose three modifications that simultaneously improve its performance, complexity, and latency. An effective termination method of the windowed decoding and the reuse of edge messages of previous target symbols provide a good performance-latency tradeoff when compared with the conventional windowed decoder. Also, we propose a scheme that lowers the error floor, in which the amplified edge messages of the previous window are used in the present window. The proposed windowed decoding, consisting of the three schemes, provides a significant performance gain with smaller latency. The validity of the new windowed decoding is verified by the evaluation with codes from different SC LDPC ensembles."
  },
  {
    "year": "2017",
    "abstract": "Internet-of-Things (IoT) can allow healthcare professionals to remotely monitor patients by analyzing the sensors outputs with big data analytics. Sleeping conditions are one of the most influential factors on health. However, the literature lacks of the appropriate simulation tools to widely support the research on the recognition of sleeping postures. This paper proposes an agent-based simulation framework to simulate sleeper movements on a simulated smart bed with load sensors. This framework allows one to define sleeping posture recognition algorithms and compare their outcomes with the poses adopted by the sleeper. This novel presented ABS-BedIoT simulator allows users to graphically explore the results with starplots, evolution charts, and final visual representations of the states of the bed sensors. This simulator can also generate logs text files with big data for applying offline big data techniques on them. The source code of ABS-BedIoT and some examples of logs are freely available from a public research repository. The current approach is illustrated with an algorithm that properly recognized the simulated sleeping postures with an average accuracy of 98%. This accuracy is higher than the one reported by an existing alternative work in this area."
  },
  {
    "year": "2017",
    "abstract": "With the advent of machine-to-machine and vehicular-to-everything communication systems, next-generation train control systems known as communication-based train control (CBTC) systems are also gathering increased interests both from academia and industry. Unlike the traditional train control systems based on track circuits, CBTC systems are expected to provide greater transportation capacity while ensuring safety by exploiting wireless communications between trains and wayside access points. However, due to the nature of wireless channels, packet transmission delays between APs and trains can greatly affect the train control performance. Most previous works have adopted an adaptive modulation and coding (AMC) method that minimizes the average delay to improve the control performance taking care of transmission errors due to channel fading. However, medium access control (MAC) layer contention due to multiple competing trains, which can entail significant degradations of the delay and control performance, has not been considered. Therefore, we propose an optimized link layer AMC method for CBTC systems using wireless local area network that encompasses the impacts of fading channels as well as of MAC layer contention. With much reduced required information, the proposed scheme enables to select the transmission mode that minimizes this average delay in each control period. The simulation results show that the proposed method greatly outperforms the conventional schemes over a wide range of parameters and settings."
  },
  {
    "year": "2017",
    "abstract": "Along with the blowout of new applications and the integration of the heterogeneous networks platforms in the future Internet of everything, the self-management of virtual radio access network is of significant importance. The urgent problem needed to be solved for the self-management in virtual radio access network is the match of application and virtual service (tailored service of virtual functions for the application). In this paper, an identification decision tree learning model (IDTLM) based on transfer learning has been proposed. First, we do research on the redundant problem of the traditional packet decision trees and reduce the dimensionality of features by a proximal gradient descent method and clustering the features by Lagrange's multiplier, so as to improve the online matching speed between applications and virtual service. And then, in consideration of the independent and non-identical distribution among online and trained data, and the possible change of virtualized network platform, a method of transfer learning is proposed to improve the quality of generalization for IDTLM. Finally, online test is done for IDTLM, and the result shows that the accuracy rate of trained applications can reach 99% and the accuracy rate can reach 96% if untrained applications are included. Meanwhile, theoretical analysis has been carried out for the transfer of IDTLM. The analysis shows that IDTLM system is of high recognizing speed and low false positive rate and it could adapt to the transfer of different scenarios."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we introduce an image enhancing approach for transforming dark images into lightened scenes, and we evaluate such method in different perceptual color spaces, in order to find the best-suited for this particular task. Specifically, we use a classical color transfer method where we obtain first-order statistics from a target image and transfer them to a dark input, modifying its hue and brightness. Two aspects are particular to this paper, the application of color transfer on dark imagery and in the search for the best color space for the application. In this regard, the tests performed show an accurate transference of colors when using perceptual color spaces, being RLAB the best color space for the procedure. Our results show that the methodology presented in this paper can be a good alternative to low-light or night vision processing techniques. Besides, the proposed method has a low computational complexity, property that is important for real time applications or for low-resource systems. This method can be used as a preprocessing step in order to improve the recognition and interpretation of dark imagery in a wide range of applications."
  },
  {
    "year": "2017",
    "abstract": "An explosive growth of cyber-physical-social systems has been witnessed owing to the wide use of various mobile devices recently. A large volume of heterogeneous data has been collected from cyber-physical-social systems in the past few years. Each object in the heterogeneous dataset is typically multi-modal, posing a remarkable challenge on heterogeneous data clustering. In this paper, we propose a high-order k-means algorithm based on the dropout deep learning model for clustering heterogeneous objects in cyber-physical-social systems. We first build three dropout stacked auto-encoders, each with three hidden layers to learn the features for the different modalities of each object. Furthermore, we establish a feature tensor for each object by using the vector outer product to fuse the learned features. At last, we devise a tensor k-means algorithm to cluster the heterogeneous objects based on the tensor distance. We evaluate the proposed high-order k-means algorithm on two representative heterogeneous data sets and results imply that the proposed high-order k-means algorithm can achieve more accurate clustering results than other heterogeneous data clustering methods."
  },
  {
    "year": "2017",
    "abstract": "Software failure probability quantification is an important aspect of digital system reliability assessment. Several quantification methods currently available in the software reliability field have characteristics unsuitable for application to safety-critical software. In this paper, a software test framework in consideration of input trajectory is developed, and a software failure probability quantification method is also suggested. The test input cases consist of the states and present inputs, where input trajectory is represented by the state. To obtain the input domain, which represents realistic plant behavior, digital system characteristics and plant dynamics are considered. This allows software failure probability to be estimated by using the result of each representative test case, thus reducing testing efforts. The proposed framework was applied to a nuclear power plant reactor protection system as an example to show its effectiveness. The method provides a practical and relatively simple way to test software and estimate software failure probability."
  },
  {
    "year": "2017",
    "abstract": "In aviation communication system, VHF data-link message is used to transmit flight status, airport control instructions as well as the other sensitive information. Radio-transmitted information can be intercepted or tampered with, leading to the disclosure of private data, illegal control, and hijacking. This paper analyzed three attack routes of monitoring, entity camouflage, and man-in-the-middle attack. Man-in-the-middle attack was also able to work in next generation aviation communication networks. Two viable experiments were designed to test data-link message attacks including information leakage and the entity camouflage attack. These experiments may also be used as penetration tests of secure of aviation communication system."
  },
  {
    "year": "2017",
    "abstract": "Trust establishment in vehicular ad hoc networks (VANETs) is a challenging task due essentially to the high speed of vehicles, the long distances, and the network topology dynamics. Furthermore, applications context evolves quickly at the same time that the lifetime validity of data messages is short. In this paper, we set up a new distributed trust computing framework tailored to VANETs characteristics and aiming to solve the aforementioned challenges. The proposed framework is based on the investigation of the direct experience between neighboring vehicles without using any recommendation system. We also propose a tier-based messages dissemination technique in order to efficiently detect eavesdropped messages and fake events. Each vehicle checks the authenticity of the received data messages and maintains a trust value for each of its neighbors. We analytically model the trust metrics evolution of malicious vehicles. Extensive simulations are conducted to show the validity of the proposed model and evaluate the efficiency of the proposed trust computing framework."
  },
  {
    "year": "2017",
    "abstract": "Noise reduction is a fundamental operation in image quality enhancement. In recent years, a large body of techniques at the crossroads of statistics and functional analysis have been developed to minimize the blurring artifact introduced in the denoising process. Recent studies focus on edge-aware filters due to their tendency to preserve image structures. In this paper, we adopt a psychological model of similarity based on Shepard's generalization law and introduce a new signal-dependent window selection technique. Such a focus is warranted, because blurring is essentially a cognitive act related to the human perception of physical stimuli (pixels). The proposed windowing technique can be used to implement a wide range of edge-aware spatial denoising filters, thereby transforming them into nonlocal filters. We employ simulations using both synthetic and real image samples to evaluate the performance of the proposed method by quantifying the enhancement in the signal strength, noise suppression, and structural preservation measured in terms of the peak signal-to-noise ratio (PSNR), mean square error (MSE), and structural similarity (SSIM) index, respectively. In our experiments, we observe that incorporating the proposed windowing technique in the design of mean, median, and nonlocal means filters substantially reduces the MSE while simultaneously increasing the PSNR and the SSIM."
  },
  {
    "year": "2017",
    "abstract": "Point-of-interest (POI) recommendation has attracted many interests recently because of its significant potential for helping users to explore new places and helping location-based service (LBS) providers to carry out precision marketing. Compared with the user-item rating matrix in conventional recommender systems, the user-location check-in matrix in POI recommendation is usually much more sparse, which makes the notorious cold start problem more prominent in POI recommendation. Trust-oriented recommendation is an effective way to deal with this problem but it requires that the recommender has access to user check-in and trust data. In practice, however, these data are usually owned by different businesses who are not willing to share their data with the recommender mainly due to privacy and legal concerns. In this paper, we propose a privacy-preserving framework to boost data owners willingness to share their data with untrustworthy businesses. More specifically, we utilize partially homomorphic encryption to design two protocols for privacy-preserving trust-oriented POI recommendation. By offline encryption and parallel computing, these protocols can efficiently protect the private data of every party involved in the recommendation. We prove that the proposed protocols are secure against semi-honest adversaries. Experiments on both synthetic data and real data show that our protocols can achieve privacy-preserving with acceptable computation and communication cost."
  },
  {
    "year": "2017",
    "abstract": "Here, the exponential synchronization about mean square problem of two complex dynamical networks with stochastic perturbations is investigated. A novel drive-response complex network model is formulated which is linear coupling with both time-varying delay and non-delay, meanwhile, this model also includes stochastic perturbations of vector-form. Based on the Lyapunov steady theory, stochastic differential equations, and matrix theory, several effective synchronous conditions are obtained to ensure exponential synchronization in mean square of the proposed complex dynamical networks by periodically intermittent pinning. Finally, several numerical simulations are performed to verify the theoretical results and the control methodology."
  },
  {
    "year": "2017",
    "abstract": "e-Healthcare promises to be the next big wave in healthcare. It offers all the advantages and benefits imaginable by both the patient and the user. However, current e-Healthcare systems are not yet fully developed and mature, and thus lack the degree of confidentiality, integrity, privacy, and user trust necessary to be widely implemented. Two primary aspects of any operational healthcare enterprise are the quality of healthcare services and patient trust over the healthcare enterprise. Trust is intertwined with issues like confidentiality, integrity, accountability, authenticity, identity, and data management, to name a few. Privacy remains one of the biggest obstacles to ensuring the success of e-Healthcare solutions in winning patient trust as it indirectly covers most security concerns. Addressing privacy concerns requires addressing security issues like access control, authentication, non-repudiation, and accountability, without which end-to-end privacy cannot be ensured. Achieving privacy from the point of data collection in wireless sensor networks, to incorporating the Internet of Things, to communication links, and to data storage and access, is a huge undertaking and requires extensive work. Privacy requirements are further compounded by the fact that the data handled in an enterprise are of an extremely personal and private nature, and its mismanagement, either intentionally or unintentionally, could seriously hurt both the patient and future prospects of an e-Healthcare enterprise. Research carried out in order to address privacy concerns is not homogenous in nature. It focuses on the failure of certain parts of the e-Healthcare enterprise to fully address all aspects of privacy. In the middle of this ongoing research and implementation, a gradual shift has occurred, moving e-Healthcare enterprise controls away from an organizational level toward the level of patients. This is intended to give patients more control and authority over decision making rega..."
  },
  {
    "year": "2017",
    "abstract": "Device-to-device (D2D) communication is a promising concept for improving user experiences and resource utilization in cellular networks. This type of communication enables two or more mobile devices in proximity to establish local links, coordinated by a base station, to perform direct data exchange. The benefits of D2D communication include ubiquitous computing and communication, enhanced energy efficiency, creation of new services, and so on. However, how to establish the trust relationship between two devices is a base problem that should be solved. In this paper, we propose a situational awareness trust evolution model for mobile devices involved in D2D communication. Compared with available trust evaluation schemes, we consider the comprehensive situation that a mobile device may encounter. We use what a device wants and what it can obtain to depict the situation of the device when given a concrete interaction (transaction). We give the method to get quantitative description of such information, and then the coefficients of the new proposed trust evolution function can be determined. To demonstrate the efficiency of our method, we conduct some experiments to show the properties of our method, and the results show that our trust evolution scheme is consistent with the intuition about trust in real life. Furthermore, we compare our scheme with two state-of-the-art dynamic trust evaluation schemes in different usage scenarios of mobile devices. The results show that our scheme can perform well in all scenarios, whereas the other two schemes can perform well only in some of the tested scenarios."
  },
  {
    "year": "2017",
    "abstract": "The Internet of Things (IoT) leads to intelligent services by collecting information from tiny sensor devices. In recent years, storage-less sensing devices have been used to implement IoT services. They depend on delivered software from a network server to operate service functions, and IoT services are based on collected user information. Therefore, it is important to maintain trusted connections during software delivery or data transmission. If a network connection is untrustworthy, stable data transmission cannot be achieved. Untrustworthy data connections cause many problems in IoT services. Therefore, this paper proposes a software update method in trusted connection of IoT networking. The proposed method employs a low-power wide area network (LPWAN) as a long-range IoT networking technology and uses a mobile edge cloud to improve computing efficiency in an access network that consists of IoT devices with insufficient resources. In the proposed method, the mobile edge cloud is integrated into a gateway and processes sensing data and remote software updates of LPWAN. IoT devices can receive software functions from the mobile edge cloud. The proposed method analyzes statistical information about connections in an access network and determines the LPWAN trusted connections. Then, software updates can be performed over the trusted connection. Using trusted connections leads to an increased packet delivery rate and reduced transmission energy consumption. The proposed method is compared with currently available systems through computer simulation and the proposed method’s efficiency is validated."
  },
  {
    "year": "2017",
    "abstract": "To provide high quality of network service, the response time reliability (RTR), the probability that the response time of a service is within the maximum allowable time determined by users, attracts researchers from both academic and industry. For those networked systems that can adjust their configuration adaptively, such as cloud computing systems, ad hoc networks, and network function virtualization systems, it is essential to predict the RTR of the system, and use the prediction result as a constraint to optimize the system configuration, e.g., tradeoff between reliability and energy efficiency. In general, the RTR changes along with the workload of the system. Due to the complex communication process, it is not easy to derive the analytical model between workload and RTR, and the maximum response time that users can tolerate also changes with the system workload according to users' experience. This paper proposes a variable thresholdbased RTR real-time prediction framework based on data-driven approaches to forecast the RTR for networked systems. In this framework, the response time threshold varies with the workload, reflecting both users' acceptable and perceived response time, and a real-time updating model between workload and RTR is built for RTR prediction based on the latest monitored dada. Finally, a communication network is taken as the example to validate the effectiveness of the proposed method from different perspectives. The experimental results illustrate that this continually updating model can obtain more accurate RTR prediction."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a locally adaptive kernel regression with adaptive-scale kernels for deformable image registration with outliers (i.e., missing correspondences and large local deformations). The adaptive kernel regression locally constructs dense deformation fields from the weighted contributions of each pixel's surrounding discrete displacement fields in a moving anisotropic kernel by exploiting the contextual deformations of the corresponding saliency structures in the two images. Specifically, we first propose an effective superpixel-based structure scale estimator to estimate the boundary-aware structure scale of each reference structure. We further propose an edge-aware mismatch scale measuring the mismatch degree of the edge structures to be matched in the images. By combining the boundary-aware structure scale with the edge-aware mismatch scale of the underlying saliency structures to be matched, we define edge-aware adaptive-scale kernels for the locally adaptive kernel regression to efficiently construct deformations for deformable registration with outliers. The experiments show that the proposed method achieves not only state-of-the-art matching accuracy for normal corresponding structures but also the best matching efficiency for outlier structures in deformable image registration."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a blind channel estimator based on expectation maximization algorithm and historical information-based basis expansion model for uplink wireless communication systems on high speed railways. The information of basis matrices is obtained from the uplink data of the past trains at the base station (BS). With the known basis matrices at the BS, our suggested estimator can estimate the basis coefficients and recover the channel parameters without requiring training symbols. The modified Cramer-Rao bound is derived for the estimated basis coefficients and the computational complexity of the proposed estimator is analyzed. Numerical results are then provided to corroborate our studies. It is shown that the proposed estimator outperforms existing data-aided estimators, including least square and linear minimum mean square error."
  },
  {
    "year": "2017",
    "abstract": "Since the end of the 1990s, the world has witnessed a tremendous growth in the area of information and communication technology (ICT), starting with grid computing, cloud computing (CC), and fog computing to recently introduced edge computing. Although, these technologies are still in very good shape, they do heavily rely on connectivity, i.e., Internet. To address this challenge, this paper proposes a novel dew-cloud architecture that brings the power of CC together with the dew computing (DC). Originally, the dew-cloud architecture is an extension of the existing client-server architecture, where two servers are placed at both ends of the communication link. With the help of a dew server, a user has more control and flexibility to access his/her personal data in the absence of an Internet connection. Primarily, the data are stored at the dew server as a local copy upon which instantiation of the Internet is synchronized with the master copy at the cloud side. Users can browse, read, write, or append data on the local dew site, which is a local Web form of an actual website. With the incorporation of the dew domain naming system and dew domain name redirection, mapping between different local dew sites has become possible. Novel services, such as infrastructure-as-a-dew, software-as-a-dew service, and software-as-a-dew product, are, hereby, introduced along with the DC. This paper presents the following as key contributions: 1) a precise and concrete definition of DC; 2) detailed and comprehensive discussions of its concept and working principle; 3) application potentials; and 4) technical challenges. The motto of this paper is to conceptualize the fact of empowerment of the ICT-user base with almost an Internet-free surfing experience in coming days."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we describe the long-term evolution of societies of secondary users in dynamic spectrum access networks. Such an understanding is important to help us anticipate future trends in the organization of large-scale distributed networked deployments. Such deployments are expected to arise in support of a wide variety of applications, including vehicular networks and the Internet of Things. Two new biologically-inspired spectrum access strategies are presented here, and compared with a random access baseline strategy. The proposed strategies embody a range of plausible assumptions concerning the sensing capabilities and social characteristics of individual secondary users. Considering these strategies as the basis of a game against the field, we use replicator dynamics within an evolutionary game-theoretic analysis to derive insights into the physical conditions necessary for each of the strategies to be evolutionarily stable. Somewhat surprisingly, we find that the physical channel conditions almost always uniquely determine which one of the three (pure) strategies is selected, and that no mixed strategy ever survives. We show that social tendencies naturally become advantageous for secondary users as they find themselves situated in network environments with heterogeneous channel resources. Hardware test-bed experiments confirm the validity of the analytic conclusions. Taken together, these results predict the emergence of social behavior in the spectrum access etiquette of secondary users as cognitive radio technology continues to advance and improve. The experimental results show an increase in the throughput of up to 90%, when strategy evolution is continuously operational, compared with any static strategy. We present use cases to envision the potential application of the proposed evolutionary framework in real-world scenarios."
  },
  {
    "year": "2017",
    "abstract": "While achieving reduced/good peak-to-average power (PAPR) in orthogonal frequency division multiplexing (OFDM) systems is attractive, this must not be performed at the expense of the transmitted signal with over-reduced signal power, as it leads to degraded bit error ratio (BER). We introduce a uniform distribution approach to solving the PAPR reduction problem of OFDM signals and then use Lagrange multiplier (LM) optimization to minimize the number of iterations involved in an adaptive fashion. Due to the nonlinear attenuation of the PAPR reduction scheme, we compensate the output signal using a correlation factor that minimizes the error floor in the in-band distortion of the clipped signal using the minimum mean square error method so as to improve the BER performance. Three different methods are introduced each enabling PAPR reduction by clipping followed by filtering with no direct dependence on a clipping ratio parameter. We find that our approach significantly reduces the PAPR of the OFDM signals (especially with LM optimization) better than the conventional adaptive iterative clipping and filtering operating without LM optimization. Based on our proposed methods, we additionally outline two simple steps for achieving perfect PAPR reduction (i.e., 0 dB). We also evaluate the performance of the three new models over high power amplifier (HPA) for completeness; the HPA is found to induce negligible BER degradation effects on the processed signal compared with the unprocessed signal."
  },
  {
    "year": "2017",
    "abstract": "The advent of industry 4.0 with its idea of individualized mass production will significantly increase the demand for more flexibility on the production floor. Wireless communication provides this type of flexibility but puts the automation system at risk as potential attackers now can eavesdrop or even manipulate the messages exchanged even without getting access to the premises of the victim. Cryptographic means can prevent, such attacks if applied properly. One of their core components is the distribution of keys. The generation of keys from channel parameters seems to be a promising approach in comparison with classical approaches based on public key cryptography as it avoids computing intense operations for exchanging keys. In this paper, we investigated key generation approaches using channel parameters recorded in a real industrial environment. Our key results are that the key generation may take unpredictable long and that the resulting keys are of low quality with respect to the test for randomness we applied."
  },
  {
    "year": "2017",
    "abstract": "This paper is concerned with the computational efficient nonlinear analysis of phasor measurement unit data and presents a Nyström principal components analysis-based algorithm for events detection and localization in an electrical power system. Based on the properly chosen sample subset of every moving window data, the Nyström approximation is carried out to obtain the principal eigenvalues and related eigenvectors of a mapped kernel matrix. Then, the T2statistic is constructed to detect the abnormal states of an electrical power system. In addition, the contribution of each variable to the T2statistic is derived to determine the location of the fault bus. Compared with the previous works, the novel version proposed in this paper efficiently reduces the computational burden, and accurately locates the fault bus. Computer simulations using both realistic data, collected from the China power system, and simulated voltage and phase-angle data, validate the reliability of the proposed algorithm."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we address the problem of accurately modeling the cloud data center energy consumption. As minimizing energy consumption has become a crucial issue for the efficient operation and management of cloud data centers, an energy consumption model plays an important role in cloud datacenter energy management and control. Moreover, such model is essential for guiding energy-aware algorithms, such as resource provisioning policies and virtual machine migration policies. To this end, we propose a holistic cloud data center energy consumption model that is based on the principal component analysis and regression methods. Unlike the exiting approaches that focus on single system component in the datacenter, the proposed approach takes into account the energy consumption of the processing unit, memory, disk, and network interface card as well as the application characteristics. The proposed approach is validated through extensive experiments with the SPECpower benchmark. The experimental results show that the proposed energy consumption model achieves more than 95% prediction accuracy."
  },
  {
    "year": "2017",
    "abstract": "Multi-tenant software-defined networks have emerged as a promising service platform to manage and share virtual network services between tenants and end-users. However, when using a service level agreement (SLA) in a multi-tenant circumstance, the resource competition among tenants incurred in many challenges on the quality of services (QoS) provisioning. First, as the existing QoS provisioning was to translate the high-level SLA contact into a group of corresponding low-level QoS rules, this traditional top-down translation mechanism was too ossified to support the dynamic SLA negotiation. Second, since an end-user usually requested multiple services and different services had different QoS requirements, the QoS provisioning required tenants to monitor and control the network status though OpenFlow protocol in a fine-grained way. To address these issues, we propose an SLA-aware fine-grained QoS provisioning (SFQP) scheme for MTSDN. The SFQP scheme extracts the eigen characteristics of each packet by applicationaware technology automatically. Considering tenants are more willing to serve for users which have popular SLA contact to earn more revenues, we predict the SLA popularity by K-nearest neighbor. Moreover, we present an SLA-aware dynamic bandwidth allocation algorithm to implement the proposed SFQP scheme. The feasibility of the proposed scheme is verified by simulations of the SLA taxonomy, bandwidth utilization, and bandwidth fluctuation."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we examine the combined impacts of distance-dependent Rician fading channel model and the absolute difference between the heights of base station (BS) and user equipment (UE) antennas on the coverage probability and the area spectral efficiency in an interference-limited ultra-dense (UD) small cell network (SCN). Exploiting distance dependent models for both path loss and multi-path fading, we show that in interference-limited UD-SCNs, Rician fading with variant Rician K factor aggravates the performance loss caused by the difference between the heights of the BS and UE antennas in comparison to Rayleigh fading. In particular, we demonstrate that due to presence of the specular line-of-sight component in the Rician fading, both the coverage probability and the area spectral efficiency experience a steeper decline towards zero as the BS density increases. Our performance analysis has a prominent impact on the deployment of UD-SCNs in the 5th-generation of mobile networks, as it indicates that the right modeling of multi-path fading makes a significant difference when assessing the performance of UD-SCNs with non-identical UE-BS antenna heights."
  },
  {
    "year": "2017",
    "abstract": "The active learning method involves searching for the most informative unmarked samples by query function, submitting them to the expert function for marking, then using the samples to train the classification model in order to improve the accuracy of the model and use the newly acquired knowledge to inquire into the next round, with the aim of getting the highest accuracy of classification using minimal training samples. This paper details the various principles of active learning and develops a method that combines active learning with transfer learning. Experimental results prove that the active learning method can cut back on samples redundancy and promote the accuracy of classifier convergence quickly in small samples. Combining active learning and transfer learning, while taking advantage of knowledge in related areas, could further improve the generalization ability of classification models."
  },
  {
    "year": "2017",
    "abstract": "This paper proposed a reinforcement learning method to improve the level-of-service (LOS) for a shared-taxi system. In practice, shared-taxi operators usually insert a new arrival request into a vehicle routing system that can minimize current total waiting time and detour distance. However, the LOS of a shared-taxi system does not involve only the total waiting time and detour distance but also the quantity of serviced trip volume. If operators emphasize only on the reduction of the total waiting time and detour distance for current requests, the transport capacity of a shared-taxi system can be excessively expended and cannot reflect future requests effectively. This could lead to a high rejection rate for future requests and damage the global LOS. The proposed reinforcement learning method takes into account the uncertainty of future requests and can make a look-ahead decision to help the operator improve the global LOS of a shared-taxi system. We also tested the proposed method on large-scale networks to verify the performance of the method."
  },
  {
    "year": "2017",
    "abstract": "Cybersecurity has become a key factor that determines the success or failure of companies that rely on information systems. Therefore, investment in cybersecurity is an important financial and operational decision. Typical information technology investments aim to create value, whereas cybersecurity investments aim to minimize loss incurred by cyber attacks. Admittedly, cybersecurity investment has become an increasingly complex one, since information systems are typically subject to frequent attacks, whose arrival and impact fluctuate stochastically. Furthermore, cybersecurity measures and improvements, such as patches, become available at random points in time making investment decisions even more challenging. We propose and develop an analytical real options framework that incorporates major components relevant to cybersecurity practice, and analyze how optimal cybersecurity investment decisions perform for a private firm. The novelty of this paper is that it provides analytical solutions that lend themselves to intuitive interpretations regarding the effect of timing and cybersecurity risk on investment behavior using real options theory. Such aspects are frequently not implemented within economic models that support policy initiatives. However, if these are not properly understood, security controls will not be properly set resulting in a dynamic inefficiency reflected in cycles of over or under investment, and, in turn, increased cybersecurity risk following corrective policy actions. Results indicate that greater uncertainty over the cost of cybersecurity attacks raises the value of an embedded option to invest in cybersecurity. This increases the incentive to suspend operations temporarily in order to install a cybersecurity patch that will make the firm more resilient to cybersecurity breaches. Similarly, greater likelihood associated with the availability of a cybersecurity patch increases the value of the option to invest in cybersecurity. However, the ab..."
  },
  {
    "year": "2017",
    "abstract": "Road detection with high-precision from very high resolution remote sensing imagery is very important in a huge variety of applications. However, most existing approaches do not automatically extract the road with a smooth appearance and accurate boundaries. To address this problem, we proposed a novel end-to-end generative adversarial network. In particular, we construct a convolutional network based on adversarial training that could discriminate between segmentation maps coming either from the ground truth or generated by the segmentation model. The proposed method could improve the segmentation result by finding and correcting the difference between ground truth and result output by the segmentation model. Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art methods greatly on the performance of segmentation map."
  },
  {
    "year": "2017",
    "abstract": "Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient's home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a batterypowered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient's sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home."
  },
  {
    "year": "2017",
    "abstract": "Cloud computing and Internet of Things (IoT) are computing technologies that provide services to consumers and businesses, allowing organizations to become more agile and flexible. Therefore, ensuring quality of service (QoS) through service-level agreements (SLAs) for such cloud-based services is crucial for both the service providers and service consumers. As SLAs are critical for cloud deployments and wider adoption of cloud services, the management of SLAs in cloud and IoT has thus become an important and essential aspect. This paper investigates the existing research on the management of SLAs in IoT applications that are based on cloud services. For this purpose, a systematic mapping study (a well-defined method) is conducted to identify the published research results that are relevant to SLAs. This paper identifies 328 primary studies and categorizes them into seven main technical classifications: SLA management, SLA definition, SLA modeling, SLA negotiation, SLA monitoring, SLA violation and trustworthiness, and SLA evolution. This paper also summarizes the research types, research contributions, and demographic information in these studies. The evaluation of the results shows that most of the approaches for managing SLAs are applied in academic or controlled experiments with limited industrial settings rather than in real industrial environments. Many studies focus on proposal models and methods to manage SLAs, and there is a lack of focus on the evolution perspective and a lack of adequate tool support to facilitate practitioners in their SLA management activities. Moreover, the scarce number of studies focusing on concrete metrics for qualitative or quantitative assessment of QoS in SLAs urges the need for in-depth research on metrics definition and measurements for SLAs."
  },
  {
    "year": "2017",
    "abstract": "Nowadays, biological recognition technologies attract more attention in electrocardiograph (ECG) signals, which vary among different people and are difficult to counterfeit. However, the robustness of recognition cannot be well sustained in the case of diversified application scenarios and huge human crowds. In order to tackle this problem, this paper puts forward a fiducial and non-fiducial mixed feature extraction method, which can effectively complete the multidimensional feature modeling of ECG signal. In addition, this paper proposes a linear discriminant analysis (LDA) based on multiple features (LOMF) algorithm based on ECG mixed feature to solve time-overhead problem of big data training. LOMF includes ECG signal preprocessing, sub-block division, and block training. By combining the MapReduce distributed computing framework and the secondary retrieval method based on the multidimensional feature space, LOMF is parallelized to improve recognition rate and computing efficiency at the same time. The experiment results show that, in the diversified scenarios, utilizing ECG mixed feature can return a higher recognition rate than the traditional ECG 1-D feature. Moreover, compared with the traditional LDA and support vector machine algorithms, the precision of LOMF increases by 7%-8%, which depends on the most competitive advantage of using LOMF. LOMF fits MapReduce parallel framework well so it is more effective than traditional algorithms, especially on diversified application scenarios (such as Internet) where the amount of data grows rapidly."
  },
  {
    "year": "2017",
    "abstract": "Today, the stability of the electric power grid is maintained through real time balancing of generation and demand. Grid scale energy storage systems are increasingly being deployed to provide grid operators the flexibility needed to maintain this balance. Energy storage also imparts resiliency and robustness to the grid infrastructure. Over the last few years, there has been a significant increase in the deployment of large scale energy storage systems. This growth has been driven by improvements in the cost and performance of energy storage technologies and the need to accommodate distributed generation, as well as incentives and government mandates. Energy management systems (EMSs) and optimization methods are required to effectively and safely utilize energy storage as a flexible grid asset that can provide multiple grid services. The EMS needs to be able to accommodate a variety of use cases and regulatory environments. In this paper, we provide a brief history of grid-scale energy storage, an overview of EMS architectures, and a summary of the leading applications for storage. These serve as a foundation for a discussion of EMS optimization methods and design."
  },
  {
    "year": "2017",
    "abstract": "The recent expansion of the Internet of Things (IoT) and the consequent explosion in the volume of data produced by smart devices have led to the outsourcing of data to designated data centers. However, to manage these huge data stores, centralized data centers, such as cloud storage cannot afford auspicious way. There are many challenges that must be addressed in the traditional network architecture due to the rapid growth in the diversity and number of devices connected to the internet, which is not designed to provide high availability, real-time data delivery, scalability, security, resilience, and low latency. To address these issues, this paper proposes a novel blockchain-based distributed cloud architecture with a software defined networking (SDN) enable controller fog nodes at the edge of the network to meet the required design principles. The proposed model is a distributed cloud architecture based on blockchain technology, which provides low-cost, secure, and on-demand access to the most competitive computing infrastructures in an IoT network. By creating a distributed cloud infrastructure, the proposed model enables cost-effective high-performance computing. Furthermore, to bring computing resources to the edge of the IoT network and allow low latency access to large amounts of data in a secure manner, we provide a secure distributed fog node architecture that uses SDN and blockchain techniques. Fog nodes are distributed fog computing entities that allow the deployment of fog services, and are formed by multiple computing resources at the edge of the IoT network. We evaluated the performance of our proposed architecture and compared it with the existing models using various performance measures. The results of our evaluation show that performance is improved by reducing the induced delay, reducing the response time, increasing throughput, and the ability to detect real-time attacks in the IoT network with low performance overheads."
  },
  {
    "year": "2017",
    "abstract": "Using diagnostic imaging, asymmetry in the mechanic of the left and right lungs has been discovered in unilateral lung disease. Unilateral lung disease might affect information interaction between two lungs, which is often neglected in the study of lung function. In this paper, twenty-one subjects were recruited to collect bio-impedance respiratory signals of the left and right lungs. The differences of correlation and amplitude between the two respiratory signals were combined to verify three types of respiration movement: respiration symmetry (RS), respiration asymmetry type I (T1RA), and respiration asymmetry type II (T2RA). We extracted the correlation coefficient, mutual information (MI), and transfer entropy (TE) to evaluate lung function in these three types of lung respiration. Results showed that MI was significantly larger in RS than in T1RA and T2RA. TE in both directions (TE(L→R) and TE(R→L)) were significantly different in RS, T1RA, and T2RA. TE(R→L) increased progressively when shifting RS to T1RA and then to T2RA. The prominent direction of transferred information in two lungs was significantly different for T1RA and T2RA. The results indicate that MI is suitable parameters for detecting respiration symmetry and asymmetry. TE is a useful tool for detecting two respiration movement asymmetry. The results provide a better understanding of the mechanisms underlying responsible for pulmonary ventilation redistribution and could provide novel clinical markers to evaluate asymmetry of two lungs effectively."
  },
  {
    "year": "2017",
    "abstract": "This paper presents robust virtual inertia control of an islanded microgrid considering high penetration of renewable energy sources (RESs). In such microgrids, the lack of system inertia due to the replacement of traditional generating units with a large amount of RESs causes undesirable influence to microgrid frequency stability, leading to weakening of the microgrid. In order to handle this challenge, the H robust control method is implemented to the virtual inertial control loop, taking into account the high penetration of RESs, thus enhancing the robust performance and stability of the microgrid during contingencies. The controller's robustness and performance are determined along with numerous disturbances and parametric uncertainties. The comparative study between H and optimal proportionalintegral (PI)-based virtual inertia controller is also presented. The results show the superior robustness and control effect of the proposed H controller in terms of precise reference frequency tracking and disturbance attenuation over the optimal PI controller. It is validated that the proposed H -based virtual inertia controller successfully provides desired robust frequency support to a low-inertia islanded microgrid against high RESs penetration."
  },
  {
    "year": "2017",
    "abstract": "Internet of Things (IoT) has been widely used in our daily life, which enables various objects to be interconnected for data exchange, including physical devices, vehicles, and other items embedded with network connectivity. Wireless sensor network (WSN) is a vital application of IoT, providing many kinds of information among sensors, whereas such network is vulnerable to a wide range of attacks, especially insider attacks, due to its natural environment and inherent unreliable transmission. To safeguard its security, intrusion detection systems (IDSs) are widely adopted in a WSN to defend against insider attacks through implementing proper trust-based mechanisms. However, in the era of big data, sensors may generate excessive information and data, which could degrade the effectiveness of trust computation. In this paper, we focus on this challenge and propose a way of combining Bayesian-based trust management with traffic sampling for wireless intrusion detection under a hierarchical structure. In the evaluation, we investigate the performance of our approach in both a simulated and a real network environment. Experimental results demonstrate that packet-based trust management would become ineffective in a heavy traffic environment, and that our approach can help lighten the burden of IDSs in handling traffic, while maintaining the detection of insider attacks."
  },
  {
    "year": "2017",
    "abstract": "Wireless sensor networks, due to their nature, are more prone to security threats than other networks. Developments in WSNs have led to the introduction of many protocols specially developed for security purposes. Most of these protocols are not efficient in terms of putting an excessive computational and energy consumption burden on small nodes in WSNs. This paper proposes a knowledge-based context-aware approach for handling the intrusions generated by malicious nodes. The system operates on a knowledge base, located at the base station, which is used to store the events generated by the nodes inside the network. The events are categorized and the cluster heads (CHs) are acknowledged to block maliciously repeated activities generated. The CHs can also get informational records about the maliciousness of intruder nodes by using their inference engines. The mechanism of events logging and analysis by the base station greatly affects the performance of nodes in the network by reducing the extra security-related load on them."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we consider the secure communications in a cognitive untrusted relay network, where the secondary source intends to communicate with a secondary destination through an untrusted relay in the presence of the direct source-destination link. Specifically, we first examine the connection outage probability (COP) and secrecy outage probability (SOP) to investigate the reliability and security performance in two cases, where the secondary destination exploits the maximum ratio combining (MRC) scheme or the selection combining (SC) scheme. To characterize the tradeoff between reliability and security, we then investigate the effective secrecy throughput (EST) performance by including the COP and SOP in a unified manner. In order to gain additional insights from the performance evaluation, we also provide the asymptotic expressions for the COP, SOP, and EST in high signal-to-noise ratio region. It is demonstrated that the interference temperature constraint incurred from the primary network enables a tradeoff between reliability and security of the secondary network. Moreover, the resulting analysis shows that using the untrusted relay to forward the transmitted message is unnecessary when the secondary destination employs the SC scheme and the untrusted relay operates in half-duplex mode."
  },
  {
    "year": "2017",
    "abstract": "Siphons, as a structural object of Petri nets (PNs), are closely related to deadlock-freedom in PNs. Efficient siphon computation is of great importance in developing siphon-based deadlock control strategies with good performance. This paper is concerned with the enumeration of minimal siphons in a subclass of PNs called systems of sequential systems with shared resources (S4PR). First, a method with polynomial complexity is proposed to decide whether a subset of resource places can generate a minimal siphon. Next, by utilizing the technique of problem partitioning, we develop an approach to compute all minimal siphons in S4PR. The proposed approach is illustrated by an example and its advantage is finally demonstrated via a comparison with other approaches."
  },
  {
    "year": "2017",
    "abstract": "We propose a low-latency approach for generating secure electrocardiogram (ECG) feature-based cryptographic keys. This is done by taking advantage of the uniqueness and randomness properties of ECG's main features. This approach achieves a low-latency since the key generation relies on four reference-free ECG's main features that can be acquired in short time. We call the approach several ECG features (SEF)-based cryptographic key generation. SEF consists of: 1) detecting the arrival time of ECG's fiducial points using Daubechies wavelet transform to compute ECG's main features accordingly; 2) using a dynamic technique to specify the optimum number of bits that can be extracted from each main ECG feature, comprising of PR, RR, PP, QT, and ST intervals; 3) generating cryptographic keys by exploiting the above-mentioned ECG features; and 4) consolidating and strengthening the SEF approach with cryptographically secure pseudo-random number generators. Fibonacci linear feedback shift register and advanced encryption standard algorithms are implemented as the pseudo-random number generator to enhance the security level of the generated cryptographic keys. Our approach is applied to 239 subjects' ECG signals comprising of normal sinus rhythm, arrhythmia, atrial fibrillation, and myocardial infraction. The security analyses of the proposed approach are carried out in terms of distinctiveness, test of randomness, temporal variance, and using National Institute of Standards and Technology benchmark. The analyses reveal that the normal ECG rhythms have slightly better randomness compared with the abnormal ones. The analyses also show that the strengthened SEF key generation approach provides a higher security level in comparison to existing approaches that rely only on singleton ECG features. For the normal ECG rhythms, the SEF approach has in average the entropy of about 0.98 while cryptographic keys which are generated utilizing the strengthened SEF approach offer the entro..."
  },
  {
    "year": "2017",
    "abstract": "Sparse code multiple access (SCMA) is a promising candidate air interface of next-generation mobile networks. In this paper, we focus on a downlink SCMA system where a transmitter sends confidential messages to multiple users in the presence of external eavesdroppers. Consequently, we develop a novel secure transmission approach over physical layer based on a highly structured SCMA codebook design. In our proposed scheme, we rotate the base constellations (BCs) with random angles by extracting channel phases from the channel state information. By employing randomized constellation rotation, the security of downlink SCMA can be ensured. In addition, a tight SCMA upper bound is introduced to guide the design of the encrypted codebook. As a result, we propose an approach to avoid the significant error rate performance loss caused by using codebooks that are designed using our method. The proposed upper-bound-aided codebook design scheme can select relatively good codebooks with low complexity. By combining SCMA codebook design and secure communication, our scheme ensures security for massive quantities of users with low encrypted and decrypted complexity at the cost of transmission rate and possible error rate performance loss. Moreover, the proposed scheme can achieve robustness against channel estimation errors. Analyses and Monte Carlo simulations confirm the effectiveness of our scheme."
  },
  {
    "year": "2017",
    "abstract": "In 5G-based cognitive radio, the primary user signal is more active due to the broad frequency band. The traditional cooperative spectrum sensing only detects one characteristic of PU using one kind of detector, which may decrease the sensing performance when the wideband PU is in severe fading channel. In this paper, a multi-modal cooperative spectrum sensing is proposed to make an accurate decision through combining multi-modal sensing data of the PU signal, such as energy, power spectrum, and signal waveform. Each secondary user (SU) deploys multiple kinds of detectors, such as energy detector, spectral detector and waveform detector. The multi-modal sensing data from different detectors are sent to a fusion center. In the fusion center, the local decision is achieved through the Bayesian fusion, while the global decision is determined by the DS fusion. The sensing credibility of each detector can be fully considered in the DS fusion, in order to avoid the performance difference of different detectors. Weight DS fusion is also proposed to improve the decision performance through decreasing the sensing impact of malicious SU while increasing the fusion proportion of dominant SU. The simulation results have shown that the proposed multimodal cooperative spectrum sensing can achieve better sensing performance in fading channel."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we study the performance of spatial modulation (SM) employing Euclidean distance-based antenna selection (EDAS) operating in a realistic error-infested feedback channel, which has hitherto only been studied under ideal feedback channel conditions. Specifically, we model the feedback channel by a bit-flip probability δ and study its impact on the forward link employing EDAS. We show that the erroneous feedback channel severely degrades the performance of EDAS-aided SM (EDAS-SM) system by imposing an error floor in the forward link. Furthermore, we quantify the error floors associated both with the spatial and with the conventional symbols with the aid of asymptotic symbol error rate analysis. The expressions derived for the error floors in the forward link are utilized for optimizing the feedback signaling, which are shown to help reduce the error floor levels. Furthermore, a pilot-aided selection verification (PSV) algorithm is proposed for mitigating the effects of antenna-set mismatch between the transmitter and the receiver, which eliminates the error floor in the forward link. Simulations are conducted in order to validate the theoretical results presented in this paper. Furthermore, the bit-error ratio (BER) performance of the EDAS-SM is compared with that of the conventional antenna selection (C-AS) both in the PSV as well as in the no selection verification scenarios. It is observed that EDAS-SM outperforms C-AS in both the scenarios considered. Specifically, at a BER of 10-5, EDAS-SM is observed to give a 3-dB signal-to-noise ratio gain compared with the C-AS, when operating at a spectral efficiency of 7 bits per channel use in the face of a feedback BER of δ = 0.05."
  },
  {
    "year": "2017",
    "abstract": "Since 2006, there have been significant advances in deep learning algorithms, and they have shown superior performance in audio and image processing. In this paper, we explore the feasibility of applying deep learning algorithms to branch prediction. We treat branch prediction as a classification problem and compare the effectiveness of deep learning with existing branch predictors. We make several interesting observations from our study. The first is that for branch prediction, the deep learning algorithm based on deep belief networks outperforms the prior work, but only outperforms state-of-the-art branch predictors, such as the TAgged GEometric length (TAGE) predictors, for several benchmarks. Compared with the much simpler perceptron branch classifier, the deep learning classifier reduces the average misprediction rate by 3%-4% for the benchmarks in this paper. Second, we analyze the impact of the length of hashed program counter, local history register, global history register, and branch global addresses of deep learning classifiers on the misprediction rate. Our results show that an adaptive length of the history information is a better choice than the longest history. Third, compared with TAGE, the hardware budget of our model is less than 1% of the TAGE predictor."
  },
  {
    "year": "2017",
    "abstract": "In this paper, we investigate the secrecy performance of dual-hop decode-and-forward cognitive relay networks taking into account the channel correlation between the main and wiretapping channels. For the enhancement of the secrecy performance, a generalized relay selection scheme is utilized, where thekth strongest relay node is selected based on the main channel. In order to analyze the impact of key parameters on the secrecy performance, we first derive the exact closed-form expression for secrecy outage probability (SOP) of the considered networks. Moreover, to extract deep insights, the asymptotic approximation for SOP in high main-to-eavesdropper ratio (MER) regime is also provided. Our theoretical results as well as simulations demonstrate that: 1) the channel correlation does not affect the achievable secrecy diversity order, but has a positive impact on the secrecy coding gain in high MER regime; 2) the secrecy diversity order is decided by the generalized selection coefficient and the number of relays that can successfully decode the information transmitted from the secondary transmitter; and 3) the total amount of relays cannot influence the secrecy diversity order directly, but has a significant impact on the secrecy coding gain."
  },
  {
    "year": "2017",
    "abstract": "In this paper, the model-based fuzzy control application for double-layer operation systems with uncertainty is addressed. Due to the multiple-time scales of complex industrial systems, as well as the inborn uncertainties of the system, the challenge of feedback control is presented. A new approach based on a class of fuzzy models with uncertainty fulfilling the condition of sector bound for the operation process system is proposed. First, a fuzzy model of the system is considered in terms of the system's described dynamical characteristics, and the PI fuzzy controller is then employed for the model, which will ensure controlled plant tracking set-points. Second, with different sampling rates, a dual-layer model combining PI fuzzy controller and dynamical fuzzy output feedback controller are presented. Third, the S-procedure is applied to derive the feedback controller, which can simultaneously guarantee the mean value of steady-state error between the realistic and target operational index is zero and the stability of the dual closed-loop control system is established. Finally, significant simulations have been executed to show the effectiveness of the proposed approach."
  },
  {
    "year": "2017",
    "abstract": "Environmental concerns and depletion of traditional energy lead to the booming development of renewable distributed generation (RDG) in the past decade. However, due to intermittent nature of renewable energy sources, to what extent RDG could provide capacity to power systems becomes a critical issue to the utility company when implementing long-term system strategic (generation expansion) planning. On the other hand, in a smart-grid frame, the popularization of different varieties of demand-side resources enables the system to operate at more flexible modes ever before. The potential variability in load demand not only introduces additional dynamics and uncertainties to the system, but could also affect the reliability benefits of RDG. Therefore, in practice, to effectively estimate the reliability value of RDG in power systems, the potential interaction between generation- and demand-side must be properly captured. In this paper, a study to assess the capacity credit (CC) of RDG in a context of distributed generation system is performed with consideration of the impacts of demand response (DR). A compound reliability model for DR is presented, which considers the uncertainties involved in both instant response and follow-on load recovery processes. On this basis, an assessment framework for the CC of RDG based on sequential Monte Carlo simulation is developed by which the inter-temporal characteristics of DR resources can be fully captured. The numerical study is implemented based on the IEEE-38 bus test case. The calculation results demonstrate that the CC of RDG would depend on a variety of factors, including penetration level, responsiveness of load demand and the correlations between RDG and DR availability. Also, it is shown that accounting for the underlying effect of DR is of absolute importance, otherwise the CC of RDG might be estimated erroneously in real practices."
  },
  {
    "year": "2017",
    "abstract": "Tensor completion is a higher way analog of matrix completion, which has proven to be a powerful tool for data analysis. In this paper, we formulate the missing data recovery problem of a three-way tensor as a tensor completion problem. We propose a novel tensor completion method based on tensor-CUR decomposition to estimate the missing data from limited samples. Computational experiments demonstrate that the proposed method yields a superior performance over other existing approaches."
  },
  {
    "year": "2017",
    "abstract": "Data are the basis of analysis and modeling. It is essential and necessary for performance optimization to extract useful data or characteristic variables from a large amount of data. In this paper, variable selection and trusted computing in rapid detection of soybean straw biomass is studied. Competitive adaptive reweighted sampling (CARS) is a variable selection method, which simulate the survival of the fittest principle of Darwin's evolution theory. CARS is applied in to soybean straw near infrared spectroscopy (NIRS) analysis data and compared with other variable selection methods, such as interval partial least squares (iPLS), synergy interval partial least square (siPLS), backward interval partial least square (biPLS), and successive projection algorithm (SPA). Built PLS model using the optimization data based on above five methods, and contrasted the root-mean-square error of prediction (RMSEP) of the PLS model and the difference between root-mean-square error of cross validation (RMSECV) and RMSEP. The experimental results show that the iPLS and SPA methods are not suitable for analyzing soybean straw NIRS data. Also, the CARS method is found to be more effective in extracting character variables than siPLS and biPLS. Performance of prediction model is improved by variable selection. In contrast to the global PLS model, the RMSECV is reduced to 0.6572 from 0.8082, the RMSECP is reduced to 0.5710 from 0.6250, and correlation coefficient of the calibration model is increased to 0.8162 from 0.7087 for the hemicellulose. The difference between RMSECV and RMSEP is small, so the model will be stable. Similar results appear in the cellulose and lignin analyzing process. It is concluded that CARS method is effective in variables selection and optimization for soybean straw NIRS data."
  },
  {
    "year": "2017",
    "abstract": "Nowadays an increasing number of companies and organizations choose to deploy their applications in data centers to leverage resource sharing. The increase in tasks of multiple applications, however, makes it challenging for a provider to maximize its revenue by intelligently scheduling tasks in its software-defined networking (SDN)-enabled data centers. Existing SDN controllers only reduce network latency while ignoring virtual machine (VM) latency, which may lead to revenue loss. In the context of SDN-enabled data centers, this paper presents a workload-aware revenue maximization (WARM) approach to maximize the revenue from a data center provider's perspective. Its core idea is to jointly consider the optimal combination of VMs and routing paths for tasks of each application. This work compares it with state-of-the-art methods, experimentally. The results show that WARM yields the best schedules that not only increase the revenue but also reduce the round-trip time of tasks for all applications."
  },
  {
    "year": "2017",
    "abstract": "A low-profile wideband metasurface antenna with quad-polarization reconfiguration ability is presented in this paper. The proposed metasurface antenna is composed of a square patch, a metasurface formed by a lattice of4×4periodic metal plates, and four switchable feeding probes connected with two designed single-pole double-throws switches. By properly selecting the feeding probes, the polarization of the metasurface antenna can be dynamically reconfigured among four polarization states, i.e.,x-direction linear polarization,y-direction linear polarization, left-hand circular polarization, and right-hand circular polarization. To validate the proposed concept, a prototype operating at 5.6 GHz with a relatively height of0.067λ0(λ0is the operating wavelength in free space) is designed, fabricated, and measured. The measured results show that both the 10-dB impedance bandwidths and the 3-dB axial ratio bandwidths are wider than 5.1–6.0 GHz for the linear and circular polarization states. The measured maximum gains are 9.39 dBic and 9.85 dBi for the circular polarization states and the linear polarization states, respectively. The simulation and experimentation verify that the proposed antenna can achieve quad-polarization reconfigurable features in a wide frequency band, which indicate the good performance of the proposed polarization reconfigurable metasurface antenna."
  },
  {
    "year": "2017",
    "abstract": "This paper proposes a blind interleaver parameters estimation method enhanced by identifying relatively error-less partial symbols among intercepted streams. By exploiting the distribution of the ranks of the random matrices, we can choose partial symbols having relatively small errors. Calculating the rank of the matrix constructed using these symbols can improve estimation of the blind interleaver parameters. Experimental results show that the proposed algorithm performs better than the previous ones."
  },
  {
    "year": "2017",
    "abstract": "The evolution of business software technologies is constant and is becoming increasingly complex which leads to a great probability of software/hardware failures. Business processes are built based on web services as they allow the creation of complex business functionalities. To attack the problem of failures presented by the use of web services, organizations are extrapolating the autonomic computing paradigm to their business processes as it enables them to detect, diagnose, and repair problems improving dependability. Sophisticated solutions that increase system dependability exist, however, those approaches have drawbacks; for example, they affect system performance, have high implementation costs, and or they may jeopardize the scalability of the system. To facilitate evolution to self-management, systems must implement the monitoring, analyzing, planning, and execution (MAPE) control loop. An open challenge for MAPE loop is to carry out in an efficient manner the diagnosis and decision-making processes, recollecting data from which the system can detect, diagnose, and repair potential problems. Also, dealt by systems dependability, specifically as fault tolerant mechanisms. One useful tool for this purpose is the communication induced checkpointing (CiC). We use CiC in attacking the dependability problem of using web services in a distributed and efficient manner. First, we present an approach for web services compositions that supports fault tolerance based on the CiC mechanism. Second, we present an algorithm aimed at web services compositions based on an autonomic computing and checkpointing mechanism. Experimental results support the feasibility of this concept proposal."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a novel approach to fault detection for nonlinear processes is proposed. It is based on a manifold learning called modified kernel semi-supervised local linear embedding. Local linear embedding (LLE) is widely applied to fault detection of complex industrial process. However, the LLE only preserves the local structure information of the sample, which ignores the global characteristics of the original data. The main contributions of the presented approach are as follows: 1) in order to utilize labeled data, the semi-supervised learning is introduced into LLE; 2) the regularization term is added to the calculation of local reconstruction weights matrix to strengthen the anti-noise ability in nonlinear processing; and 3) in order to extract the global and local characteristic of the observation data, the kernel principal component analysis objective function is integrated with the objective function of LLE. Experimental results on the production process of fused magnesia verify the performance of the proposed method."
  },
  {
    "year": "2017",
    "abstract": "Vehicular ad-hoc networks (VANETs) play an important role in enabling ubiquitous communications and connectivity among vehicles in intelligent transportation systems. Various messages can be transmitted in a VANET to improve road safety and furnish multiple types of application services. Therefore, the evaluation of VANET performance and its optimization should be considered. Previous conventional considerations regarding VANET modeling merely incorporated a general homogeneous road traffic scenario. Furthermore, prior research works primarily focused on the broadcasting performance in VANETs, since the safety beacon packets are transmitted in periodic broadcast. However, the exchange of some important data between vehicles is better accomplished by using unicast instead of broadcast with the retransmission mechanism. On the other hand, in the context of VANET optimization, most conventional schemes required continuous monitoring of the network by measuring the number of neighboring nodes to configure the transmission power or adjusting the transmission rate accordingly. Such constant tracking leads to large transmission overheads and measurement delay. In this paper, we propose a set of 802.11p unicast modeling and optimization methodologies to determine the optimal network parameters without continuously monitoring the vehicles in vicinity. This is accomplished by integrating a stochastic urban traffic model in the analysis then performing a cross-layer optimization for each network node to reduce packet collisions. The optimal transmission range and contention window size at different locations are derived based on the spatio-temporal velocity profile and are made known to entering vehicles. These aid the vehicles to configure their transmission power and rate accordingly upon entering a road segment. We evaluate the proposed system in terms of the network delay and throughput performance. Considerable simulation runs to verify the feasibility of the proposed mod..."
  },
  {
    "year": "2017",
    "abstract": "Flexible nature of scope definition in agile makes it difficult or impossible to measure its completeness and quality. The aim of this paper is to highlight the important ingredients of scope definition for agile projects and to present a method for agile projects in order to measure the quality and completeness of their scope definitions. The proposed method considers the elements that are retrieved as a result of the systematic literature review. An industrial survey is conducted to validate and prioritize these elements. Elements are then assigned weights according to their importance in scope definition to build a scorecard for calculating the score of user stories present in the product backlog. The proposed method is able to identify the clear and complete user stories that can better be implemented in the coming iteration. Formal experiments are performed for the evaluation of the proposed method, and it suggests that the method is useful for experts in order to quantify the completeness and quality of scope definition of an agile software project."
  },
  {
    "year": "2017",
    "abstract": "Military heterogeneous networks often suffer from node or edge failures due to attacks, which lead to whole network topology segmentation or even paralysis. Therefore, structural invulnerability is the major technical bottleneck that impedes the combat capability of military heterogeneous system. Nodes are mainly considered in current methods, with little attention paid to edges. As such, current methods cannot accurately evaluate the structural invulnerability of military heterogeneous networks. This paper presents a new method of evaluating the survivability of military heterogeneous networks, based on network structure entropy. A model of survivability is proposed based on the network irreversibility which considers not only the nodes but also the edges. The node criticality is calculated by the level flow betweenness. Edge criticality is put forward based on the edge correlation factor and information transmission efficiency. Simulation results show that this invulnerability measure has the characteristics of high sensitivity and high precision, which will provide a theoretical basis for designing and optimizing the structure of the military heterogeneous network."
  },
  {
    "year": "2017",
    "abstract": "Mobile video traffic and mobile devices have now outpaced other data traffic and fixed devices. Global service providers are attempting to propose new mobile infrastructures and solutions for high performance of video streaming services, i.e., high quality of experience (QoE) at high resource efficiency. Although device-to-device (D2D) communications have been an emerging technique that is anticipated to provide a massive number of mobile users with advanced services in 5G networks, the management of resource and co-channel interference between D2D pairs, i.e., helper-requester pairs, and cellular users (CUs) is challenging. In this paper, we design an optimal rate allocation and description distribution for high performance video streaming, particularly, achieving high QoE at high energy efficiency while limiting co-channel interference over D2D communications in 5G networks. To this end, we allocate optimal encoding rates to different layers of a video segment and then packetize the video segment into multiple descriptions with embedded forward error correction before transmission. Simultaneously, the optimal numbers of descriptions are distributed to D2D helpers and base stations in a cooperative scheme for transmitting to the D2D requesters. The optimal results are efficiently in correspondence with intrapopularity of different segments of a video characterized by requesters' behavior, characteristic of lossy wireless channels, channel state information of D2D requesters, and constraints on remaining energy of D2D helpers and target signal to interference plus noise ratio of CUs. Simulation results demonstrate the benefits of our proposed solution in terms of high performance video streaming."
  },
  {
    "year": "2017",
    "abstract": "The detection and recognition and then conversion of the characters in an image into a text are called optical character recognition (OCR). A distinctive-type of OCR is used to process Arabic characters, namely, Arabic OCR. OCR is increasingly used in many applications, where this process is preferred to automatically perform a process without human association. The Quranic text contains two elements, namely, diacritics and characters. However, processing these elements may cause malfunction to the OCR system and reduce its level of accuracy. In this paper, a new method is proposed to check the similarity and originality of Quranic content. This method is based on a combination of Quranic diacritic and character recognition techniques. Diacritic detections are performed using a region-based algorithm. An optimization technique is applied to increase the recognition ratio. Moreover, character recognition is performed based on the projection method. An optimization technique is applied to increase the recognition ratio. The result of the proposed method is compared with the standard Mushaf al Madinah benchmark to find similarities that match with texts of the Holy Quran. The obtained accuracy was superior to the other tested K-nearest neighbor (knn) algorithm and published results in the literature. The accuracies were 96.4286% and 92.3077% better in the improved knn algorithm for diacritics and characters, respectively, than in the knn algorithm."
  },
  {
    "year": "2017",
    "abstract": "Device-to-Device (D2D) communication and heterogeneous networks have been considered as promising techniques for alleviating the demand both for increased spectral resources and for additional infrastructure required for meeting the increased tele-traffic. For the sake of improving both the bandwidth efficiency and the network capacity of heterogeneous cellular networks constituted by multiple tiers, a direct D2D communication is arranged between a pair of nearby devices without involving the base station (BS), whilst reusing the cellular resources. We aim for maximising the sum-rate of the energy harvesting (EH) aided D2D links in a two-tier heterogeneous network by superimposing their messages on the downlink resources of mobile users (MUs), which is achieved without unduly degrading MU's throughput. Specifically, our optimization problem relies on the objective function of maximising the D2D sum-rate based on the joint assignment of both the resource blocks (RBs) and of the transmission power for both the EH aided D2D links and the MUs. This non-convex optimization problem, which is intractable in its original form, is then converted to a tractable convex problem, which is then analyzed by invoking the method of Lagrange multipliers of constrained optimization. As a result, an algorithmic solution defined as joint optimization of RB and power allocation (JORPA) is proposed, which jointly allocates the RBs and power for the D2D links, whilst relying on the results of Lagrangian constrained optimization, when the base stations (BSs) of different tiers obey one of the following regimes: (a) orthogonal; (b) co-channel; and (c) the proposed co-orthogonal channel deployments. We also propose low complexity heuristic methods for optimizing the D2D transmit power, while defining the D2D-MU matching heuristically and vice versa. The performance of both the JORPA algorithm as well as of the low-complexity heuristic algorithms is quantitatively analyzed using our simulation..."
  },
  {
    "year": "2017",
    "abstract": "Automatic voice pathology detection and classification systems effectively contribute to the assessment of voice disorders, enabling the early detection of voice pathologies and the diagnosis of the type of pathology from which patients suffer. This paper concentrates on developing an accurate and robust feature extraction for detecting and classifying voice pathologies by investigating different frequency bands using autocorrelation and entropy. We extracted maximum peak values and their corresponding lag values from each frame of a voiced signal by using autocorrelation as features to detect and classify pathological samples. We also extracted the entropy for each frame of the voice signal after we normalized its values to be used as the features. These features were investigated in distinct frequency bands to assess the contribution of each band to the detection and classification processes. Various samples of the sustained vowel /a/ for both normal and pathological voices were extracted from three different databases in English, German, and Arabic. A support vector machine was used as a classifier. We also performed u-tests to investigate if there is a significant difference between the means of the normal and pathological samples. The best achieved accuracies in both detection and classification varied depending on the used band, method, and database. The most contributive bands in both detection and classification were between 1000 and 8000 Hz. The highest obtained accuracies in the case of detection were 99.69%, 92.79%, and 99.79% for Massachusetts eye and ear infirmary (MEEI), Saarbrücken voice database (SVD), and Arabic voice pathology database (AVPD), respectively. However, the highest achieved accuracies for classification were 99.54%, 99.53%, and 96.02% for MEEI, SVD, and AVPD, correspondingly, using the combined feature."
  },
  {
    "year": "2017",
    "abstract": "For the current 5G era, the deployment of small cells in residential and commercial areas plays an imperious preamble in improving network coverage and the quality of service (QoS). Major technical problems associated with the mass deployment of small cells, such as femtocells are interference management and QoS provisioning. These are important for service-providing operators because the system capacity and achievable data rates mainly depend on interference. Future generation wireless networks will use autonomous and distributed architecture for ameliorating the efficacy and flexibility of communication systems. In this paper, we propose a game theory-based model along with dynamic channel allocation and self-optimizing power control scheme for resolving priority-based access exposure by applying the concept of primary and secondary users. It is expected that the consumers will experience better QoS with reduced interference levels, and the service-providing operators will be able to increase their revenue, while ensuring optimal price for the consumers. We assimilated extensive numerical results to demonstrate the efficacy of our proposed model."
  },
  {
    "year": "2017",
    "abstract": "This paper addresses channel compensation in underwater acoustic communications by proposing a method for inserting physical propagation modeling into a passive time-reversal (PTR) receiver. PTR is known as a low complexity channel equalizer that uses multichannel probing for time signal refocusing, reducing inter-symbol interference caused by multipath propagation. The proposed method aims to improve PTR communications performance by replacing the conventional noisy channel estimates with optimized and noiseless channel replicas computed by a numerical ray trace model. The optimization consists of environmental focalization in an “a priori”physical parameter search space to obtain “a posteriori”channel impulse response replicas that best match the observed data. The results obtained on two data sets acquired during the UAN'11 experiment in a shallow water fjord near Trondheim, in May 2011, show that the proposed method clearly outperformed the traditional PTR by a mean square error gain from 1 up to 4 dB. Channel tracking was effective despite a reduced physical parameter search space that could be exhaustively covered with a minimal computational effort. To the best of our knowledge, this is the first successful report on the usage of a physical parameter fed numerical model for underwater acoustic communications channel equalization with real transmitted data in a useful underwater modem frequency band."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a compact filtering rat-race coupler implemented in low-temperature co-fired ceramic (LTCC) technology is presented. In order to reduce the dimensions, the schematic and the coupling topology of a planar filtering rat-race coupler are first studied and then simplified to fit the 3-D multilayer LTCC structure. An eight-line spatially symmetrical coupled structure is, therefore, proposed to obtain the required coupling topology between resonators. Thus, the filtering rat-race coupler can be constructed only by using four resonators, which is only half that of the planar one. Consequently, the size could be reduced substantially. For validation, a design example centered at 3.5 GHz is simulated, fabricated, and measured. All the measured results are in good agreement with the full-wave simulation results. Besides, the size of the circuit is only 3.8×4×2.1 mm3, which demonstrates that by employing the eight-line spatiallysymmetrical coupled structure, the proposed rat-race coupler obtains good performance and compact size."
  },
  {
    "year": "2017",
    "abstract": "Coverage is one of the important performance indexes in wireless sensor networks. When the target is covered by k degrees by the sensor, more redundant data are generated, which may lead to network congestion, thus reducing the communication and coverage of the network and leading to a rapid depletion of energy. Therefore, this paper presents an energy balance and coverage control algorithm for the overlay network model based on node position relations. Areas are given by the analysis of the overlay network model. In terms of energy consumption, nodes with low energy consumption are scheduled by a given proportion of expected functions between the working nodes and the neighboring nodes, which balances the energy consumption of the entire network and optimizes network resources. Finally, the simulation results show that the proposed k-degree coverage algorithm not only improves the coverage quality of the network but also reduces the rapid energy consumption and prolongs the service life of the network."
  },
  {
    "year": "2017",
    "abstract": "The vehicular ad hoc network (VANET) is one of the promising and encouraging technologies, and it is going to attract great attention in the near future. VANET has turned into a main module of the intelligent transport system. It is a self-controlled, wheeled network (also called network on wheels), and a wider and stimulating class of mobile ad hoc network (MANET). VANETs raise many innovative challenges because of their high-class and unique features, such as high-node mobility, dynamic topology changes, wireless links breakage, network constancy, and network scalability. A well-organized routing protocol is one of the most challenging matters of such networks. In this paper, we propose an intelligent naïve Bayesian probabilistic estimation practice for traffic flow to form a stable clustering in VANET, briefly named ANTSC. The proposed scheme aims to improve routing by employing awareness of the current traffic flow as well as considering the blend of several factors, such as speed difference, direction, connectivity level, and node distance from its neighbors by using the intelligent technique. The proposed technique has proven to be more strong, stable, robust, and scalable than existing ones."
  },
  {
    "year": "2017",
    "abstract": "Start-up lost time is the time lost in the starting of the green time interval when a traffic signal phase changes from red to green and previously stopped vehicles in the curb line queue need time to accelerate to the desired speed. Actual traffic data analytics from newly installed loop coil detectors at all approaching upstream road segments of major intersections on Sathorn Road in Bangkok, Thailand, are used to confirm that the vehicle flow is obstructed considerably by the large start-up lost time. In this paper, the effect of a large start-up lost time is evaluated in terms of the travel time of passenger cars in a calibrated microscopic traffic simulation. The evaluation is based on the simulation of the urban mobility platform, while the traffic signal lights at major intersections are based on the standard Synchro optimization software. By the simulation, the average travel time per vehicle increases from 4% to 37% when the start-up lost time is varied from a baseline value of 1 s to the maximum value of 15 s, which potentially occurred in the actual traffic data collection in this paper. In addition, the optimal traffic signal green phase lengths increase from 2% to 42%, depending on the volume-to-capacity ratio. The similar increasing trend of optimal green time and average travel time per vehicle is observed using theoretical analysis based on M/M/1 and D/D/1 queues to support the results from Synchro. Findings of this paper are beneficial for understanding the impact of start-up lost time at signalized intersections."
  },
  {
    "year": "2017",
    "abstract": "Particle size distribution (PSD) measurement based on the static light scattering method has been widely used in the environmental field and combustion diagnostics, such as PM2.5 measurement and combustion process monitoring. The PSD inversion is mathematically related to the Fredholm integral equation of the first kind. Although the Tikhonov regularization algorithm is one of the effective inversion methods to solve the ill-posed linear equation, it still has the disadvantages of excessive smoothness and low accuracy. Thus, a preconditioned Landweber algorithm combined with the Tikhonov regularization theory (the improved algorithm) is proposed in this paper. The Tikhonov regularization theory is used to pretreat the preconditioner B contained in the preconditioned Landweber algorithm. Simulations are conducted to compare the inversion results of the conventional Landweber algorithm, the preconditioned Landweber algorithm, the Tikhonov Chahine algorithm, and the improved algorithm at different signal-to-noise ratios. A CCD-based small-angle forward scattering measurement system is built. A standardized polystyrene microsphere with a diameter of 35.05 μm is used to evaluate the above algorithms. Both numerical and experimental results show that the improved algorithm improves the accuracy of the inversion results and is insensitive to the ring parameter of the detector. The experimental results of the standardized polystyrene microsphere reveal that the relative errors for the median diameter 50 μm are better than 3%. The improved algorithm can provide a highly reliable and stable inversion result."
  },
  {
    "year": "2017",
    "abstract": "Precoding can effectively reduce the peak-to-average power ratio (PAPR) of the transmitted waveform but will usually degrade the bit error rate (BER) performance. In this paper, we investigate the PAPR-guaranteed BER minimization problem through precoding in uplink massive multiple input-multiple output (MIMO) systems. First, we formulate an optimization problem to minimize the BER via precoding design and derive the necessary condition of the optimal precoding matrix. Second, we discuss the BER minimization with PAPR constraint and propose a two-step distributed precoder to deal with this problem. Simulation results verify the effectiveness of the proposed precoding. Particularly, it is efficient for massive MIMO systems in terms of energy efficiency."
  },
  {
    "year": "2017",
    "abstract": "Flexible modulation schemes and smart multiple-input multiple-output techniques, as well as low-complexity detectors and preprocessors may become essential for efficiently balancing the bit error ratio performance, throughput, and complexity tradeoff for various application scenarios. Millimeter-Wave systems have a high available bandwidth and the potential to accommodate numerous antennas in a small area, which makes them an attractive candidate for future networks employing spatial modulation and spacetime shift keying (STSK). Non-Orthogonal Multiple Access (NOMA) systems are capable of achieving an increased throughput, by allowing multiple users to share the same resources at the cost of a higher transmission power, or an increased detection (preprocessing) complexity at the receiver (transmitter) of an uplink (downlink) scenario. In this paper, we propose the new concept of joint-alphabet space time shift keying. As an application scenario, we employ it in the context of the uplink of NOMA mm-Wave systems. We demonstrate with the aid of extrinsic information transfer charts that a higher capacity is achievable when compared with STSK, while retaining the attractive flexibility of STSK in terms of its diversity gain and coding rate. Finally, we conceive quantum-assisted detectors for reducing the detection complexity, while attaining a near-optimal performance, when compared with the optimal iterative maximum A posteriori probability detector."
  },
  {
    "year": "2017",
    "abstract": "Intelligent fault diagnosis of bearings has been a heated research topic in the prognosis and health management of rotary machinery systems, due to the increasing amount of available data collected by sensors. This has given rise to more and more business desire to apply data-driven methods for health monitoring of machines. In recent years, various deep learning algorithms have been adapted to this field, including multi-layer perceptrons, autoencoders, convolutional neural networks, and so on. Among these methods, autoencoder is of particular interest for us because of its simple structure and its ability to learn useful features from data in an unsupervised fashion. Previous studies have exploited the use of autoencoders, such as denoising autoencoder, sparsity aotoencoder, and so on, either with one layer or with several layers stacked together, and they have achieved success to certain extent. In this paper, a bearing fault diagnosis method based on fully-connected winner-take-all autoencoder is proposed. The model explicitly imposes lifetime sparsity on the encoded features by keeping only k% largest activations of each neuron across all samples in a mini-batch. A soft voting method is implemented to aggregate prediction results of signal segments sliced by a sliding window to increase accuracy and stability. A simulated data set is generated by adding white Gaussian noise to original signals to test the diagnosis performance under noisy environment. To evaluate the performance of the proposed method, we compare our methods with some state-of-the-art bearing fault diagnosis methods. The experiments result show that, with a simple two-layer network, the proposed method is not only capable of diagnosing with high precision under normal conditions, but also has better robustness to noise than some deeper and more complex models."
  },
  {
    "year": "2017",
    "abstract": "Upcoming smart scenarios enabled by the Internet of Things envision smart objects that expose services that can adapt to user behavior or be managed with the goal of achieving higher productivity, often in multi-stakeholder applications. In such environments, smart things are cheap sensors (and actuators) and, therefore, constrained devices. However, they are also critical components because of the importance of the provided information. Therefore, strong security is a must. Nevertheless, existing feasible approaches do not cope well with the principle of least privilege; they lack both expressiveness and the ability to update the policy to be enforced in the sensors. In this paper, we propose an access control model that comprises a policy language that provides dynamic fine-grained policy enforcement in the sensors based on local context conditions. This dynamic policy cycle requires a secure, efficient, and traceable message exchange protocol. For that purpose, a security protocol called Hidra is also proposed. A security and performance evaluation demonstrates the feasibility and adequacy of the proposed protocol and access control model."
  },
  {
    "year": "2017",
    "abstract": "Learning autonomous vehicle programming can be very challenging for students, especially when combined with robotic vehicle design and construction. This paper presents a methodology successfully used over the past six years to teach autonomy using a versatile platform built upon a commercially available product. A number of courses have been taught using the methodology at both the undergraduate and graduate levels. Students' ability to successfully learn and produce a solution to an autonomous robot control challenge has shown to be very effective."
  },
  {
    "year": "2017",
    "abstract": "In this paper, a wideband tunable reflectarray consisting of a graphene-based metamaterial structure has been developed to generate an orbital angular momentum (OAM) vortex wave in terahertz. In the proposed reflectarray, a multi-layer graphene metamaterial unit cell is designed, and through varying chemical potentials of the graphene sheets, reflection phase range of 360° and reflection magnitude better than -2.5 dB can be achieved. By suitably choosing the chemical potentials of the graphene layers, the designed reflectarray can produce the OAM vortex waves with l = ±1, ±2, and ±3 modes. Moreover, the OAM beams operating in a wide frequency band from 1.8 to 2.8 THz can be generated with the adjustment of the chemical potentials. Simulation results demonstrate good performance of the proposed reflectarray in the efficient generation and manipulation of the OAM vortex waves, which is promising to be used in wireless communication."
  },
  {
    "year": "2017",
    "abstract": "The control accuracies of the injection time and fuel quantity are the most important factors affecting the fuel economy and emissions of an engine equipped with a high-pressure common-rail fuel injection system. This paper presents an intelligent dual-voltage driving control that can simultaneously reduce the response time of the injector and improve the accuracy of the injected fuel quantity. The designed method employs a novel boost dc–dc circuit and does not require an additional independent dc–dc module that includes an inductor switch MOSFET and a controller. During the time interval between two continuous injections, the low-side MOSFET serves as a dc–dc switch, and the software in the controller controls the dual-voltage dc–dc, which uses the injector as a charging inductor of the dc–dc module. The operation principle of this intelligent driving circuit is described. Experimental results show that this method can not only significantly decrease the response time of the injector but also improve the stability of the fuel injection process."
  },
  {
    "year": "2017",
    "abstract": "The so-called mode-selective transmission line or simply “MSTL” is studied theoretically and experimentally. This low-loss and low-dispersion transmission line operates with a frequency-dependent mode-switching behavior. This self-adaptive mode-selective guided-wave structure begins with the propagation of electromagnetic waves over the lower frequency range in the form of a quasi-TEM fundamental mode similar to the microstrip line case, then followed by a fundamental quasi-TE10 mode with reference to rectangular waveguide over the higher frequency region. To gain insight into the physical mechanism and fundamental features of this mode-selective transmission line, a detailed semi-analytical hybrid-mode analysis is developed through the application of a method of lines. This method allows accurate and effective modeling of MSTL guided-wave properties. Propagation characteristics of this proposed mode-agile structure in terms of dispersion, modal, and loss properties are examined, which leads to the establishment of some basic MSTL design guidelines. Numerical results confirm the expected mode conversion and low-loss behavior through the observation of field evolutions along the structure. For experimental verification, a set of MSTL prototypes are fabricated on two different substrates through dissimilar fabrication processes. Measurements are carried out from dc-to-500 GHz using a vector network analyzer. Excellent agreement between theoretical and experimental results is observed. It is confirmed that the low-dispersion and low-loss behavior of MSTL makes it an outstanding integrated waveguide in support of high-performance super-broadband signal transmission and/or ultra-fast pulse propagation in a fully-integrated platform."
  },
  {
    "year": "2017",
    "abstract": "Efficient power line outage identification is an important step which ensures reliable and smooth operation of smart grids. The problem of multiple line outage detection (MLOD) is formulated as a combinatorial optimization problem and known to be NP-hard. Such a problem is optimally solvable with the help of an exhaustive evaluation of all possible combinations of lines in outage. However, the size of search space is exponential with the number of power lines in the grid, which makes exhaustive search infeasible for practical sized smart grids. A number of published works on MLOD are limited to identify a small, constant number of lines outages, usually known to the algorithm in advanced. This paper applies the Bayesian approach to solve the MLOD problem in linear time. In particular, this paper proposes a low complexity estimation of outage detection algorithm, based on the classical estimation of distribution algorithm. Thanks to an efficient thresholding routine, the proposed solution avoids the premature convergence and is able to identify any arbitrary number (combination) of line outages. The proposed solution is validated against the IEEE-14 and 57 bus systems with several random line outage combinations. Two performance metrics, namely, success generation ratio and percentage improvement have been introduced in this paper, which quantify the accuracy as well as convergence speed of proposed solution. The comparison results demonstrate that the proposed solution is computationally efficient and outperforms a number of classical meta-heuristics."
  },
  {
    "year": "2017",
    "abstract": "This paper explores computational methods to address the problem of doing inference from data in multiple modalities, where there exists a large amount of low dimensional data complementary to a much smaller set of high dimensional data. In this instance the low dimensional time-series data are active acoustics from a bio-inspired micro-Doppler sonar sensor system that include no or very limited spatial information, and the high dimensional data are RGB-depth data from a 3-D point cloud sensor. The task is human action recognition from the active acoustic data. To accomplish this, statistical models, trained simultaneously on both the micro-Doppler modulations induced by human actions and symbolic representations of skeletal poses, derived from the 3-D point cloud data, are developed. This simultaneous training enables the model to learn relations between the rich temporal structure of the micro-Doppler modulations and the high-dimensional pose sequences of human action. During runtime, the model relies purely on the active acoustic sonar data to infer the human action. Our approach is applicable to other sensing modalities, such as the millimeter wave electromagnetic radar devices."
  },
  {
    "year": "2017",
    "abstract": "Reactive power reserve (RPR) management is a critical issue to power system voltage stability. Two RPR definitions are first proposed in this paper to evaluate the levels of RPR and improve voltage stability, namely long-term voltage stability-related RPR (LVRPR) and short-term voltage stability-related RPR (SVRPR). Both definitions consider two factors: 1) the RPR of each online generator and 2) the relative contribution of the RPR to voltage stability varying with location and scenario. For LVRPR, the generator participation factor is used to describe the contributions of RPR. For SVRPR, an voltage support coefficient considering the generator's dynamics is proposed to evaluate the RPR's contribution. In normal condition, short-term voltage stability is expected to be improved by the optimization of SVRPR, ensuring enough longterm voltage stability margin. A bi-objective optimization model that coordinates LVRPR and SVRPR is formulated to enhance longand short-term voltage stabilities simultaneously. The proposed model is solved using the normal boundary intersection technique. The proposed method is performed using an IEEE39-bus system, and the results show that the optimal solution improves both longand short-term voltage stabilities by optimizing the trade-off between LVRPR and SVRPR."
  },
  {
    "year": "2017",
    "abstract": "Elderly people care is a major challenge for the smart-cities of future. This represents a valuable opportunity to develop scalable applications to cover the special needs in terms of health monitoring and accessibility for people with cognitive impairments. In this paper, a complete system to support daily activities of elderly people based on a multi-sensor scheme is presented. This system is intended to be deployed not only at home, but also at crowded places, such as daily care centers. A multi-layer architecture is drawn to ensure system modularity and interoperability of heterogeneous data with concurrent services. The proposed system includes a set of algorithms for data gathering and processing to detect abnormal events in the considered scenarios. The experiments performed in real scenarios have led to a good performance of the algorithms proposed as well as high accuracy in event detection for both environments."
  },
  {
    "year": "2017",
    "abstract": "We present results from the first phase of our measurement campaign designed to provide information on the current radio noise levels. Our focus is to understand if the increasing number of users and devices with inbuilt low-cost wireless transceivers has increased the noise levels considerably. We also study the stochastic properties of contemporary radio noise. In the literature, it is almost universally assumed that radio noise is well modeled by a white Gaussian stochastic process, and we study how often deviations from this baseline are found. Our measurement approach is able to capture frequencyand time-domain data with very high accuracy in diverse indoor and outdoor locations, providing a broad overview of the influence the environment has on noise and man-made interference. The results cast doubts on the widely used assumptions that consider man-made interference as an extra AWGN component over thermal noise floor. We also discuss the issue of modeling the measured radio noise and we explain the major research challenges for future work."
  },
  {
    "year": "2017",
    "abstract": "Gaze estimation using monocular cameras has significant commercial applicability, and many studies have been undertaken on head pose-invariant and calibration-free gaze estimation. The head positions in existing data sets used in these studies are, however, limited to the vicinity of the camera, and methods trained on such data sets are not applicable when subjects are at greater distances from the camera. In this paper, we create a room-scale gaze data set with large variations in head poses to achieve robust gaze estimation across a broader range of widths and depths. The head positions are much farther from the camera, and the resolution of the eye image is lower than in conventional data sets. To address this issue, we propose a likelihood evaluation method based on edge gradients with dense particles for iris tracking, which achieves robust tracking at low-resolution eye images. Cross-validation experiments show that our proposed method is more accurate than conventional methods on all the individuals in our data set."
  },
  {
    "year": "2017",
    "abstract": "Parameter estimation is an important issue in nonlinear science, which can be formulated as a multi-dimensional problem. Numbers of nature-inspired meta-heuristic algorithms have been applied for parameter estimation of chaotic systems; however, many of them are not able to achieve an appropriate trade-off between exploration and exploitation. Therefore, this paper proposes an effective hybrid cuckoo search (HCS) algorithm to obtain higher quality solutions and convergence speed. Inspired by the powerful efficiency of differential evolution, the proposed HCS provides two novel mutation strategies to fully exploit the neighborhood among the current population. Furthermore, a crossover operator under self-adaptive parameters control is introduced to balance the exploration and exploitation ability of the proposed two mutation strategies. Besides, the opposition-based learning is incorporated into HCS for initializing population and producing new candidate solutions during the evolutionary process. HCS is further employed to estimate the unknown parameters and time delays of chaotic systems. Numerical simulations and comparisons with some other optimization methods are conducted on three chaotic systems with and without time delays to demonstrate the performance of HCS. The experimental results show a superiority of HCS in parameter estimation of chaotic systems, and can be regarded as a promising method in terms of its high calculation accuracy, fast convergence speed, and strong robustness."
  },
  {
    "year": "2017",
    "abstract": "Lane marks on roads are among the most important items of road scene information in the process of autonomous driving, and lane-mark extraction based on visual cognitive computing is one of the most important components of advanced driving assistance systems in intelligent transportation system. Onboard cameras mounted on the front of autonomous vehicles capture road scene images from which lane marks are extracted. This paper proposes a new lane-mark extraction algorithm with four major parts. First, this paper handles the road images captured from onboard cameras by grayscale and fast median filter. Then, we exploit the characteristics of lane marks in road images as constraints to propose lane-features filter based on multi-constraints used to extract lane marks. Then, a clustering algorithm based on the double point removal of a p-least squares algorithm is proposed to cluster features, and recursive dichotomy algorithm is used to fit the candidate lane marks. Finally, we carry out verification and optimization on candidate lane marks to obtain more accurate and stable extraction results. In our experiment, we divide the common complex road scenes into four categories. The results show that the proposed method can robustly extract lane marks under various complex real conditions. This paper also proposes forward a method to evaluate the results of lane-mark extraction, and partial test results are evaluated."
  },
  {
    "year": "2017",
    "abstract": "Mobile instantaneous messaging (MIM) services significantly facilitate personal and business communications, inevitably consume substantial network resources, and potentially affect the network stability. In this paper, we aim to understand the traffic nature of MIM in cellular networks. Specifically, in order to reach credible conclusions, our research takes account of practical measurement records of MIM services from China Mobile at two different levels. First, a data set of individual message level (IML) traffic is exploited and reveals power-law distributed message length and lognormal distributed interarrival time, the heavy-tailness of which completely diverts from the geometric model and the exponential model recommended by the 3rd generation partnership project (3GPP). Second, another data set considers the statistical pattern of aggregated traffic within one whole base station, and demonstrates the accuracy ofα-stable models for the aggregated traffic. Furthermore, it verifies that theα-stable models are suitable for characterizing the traffic in both the conventional fixed core networks and the cellular access networks. At last, with the aid of the generalized central limit theorem, we build up a theoretical relation between the distributions of IML traffic and aggregated traffic."
  },
  {
    "year": "2017",
    "abstract": "Enterprises exist in a competitive manufacturing environment. To reduce production costs and effectively use production capacity to improve competitiveness, a hybrid production system is necessary. The flexible job shop (FJS) is a hybrid production system, and the FJS problem (FJSP) has drawn considerable attention in the past few decades. This paper examined the FJSP and, like previous studies, aimed to minimize the total order completion time (makespan). We developed a novel method that involves encoding feasible solutions in the genes of the initial chromosomes of a genetic algorithm (GA) and embedding the Taguchi method behind mating to increase the effectiveness of the GA. Two numerical experiments were conducted for evaluating the performance of the proposed algorithm relative to that of the Brandimarte MK1–MK10 benchmarks. The first experiment involved comparing the proposed algorithm and the traditional GA. The second experiment entailed comparing the proposed algorithm with those presented in previous studies. The results demonstrate that the proposed algorithm is superior to those reported in previous studies (except for that of Zhang et al.: the results in experiment MK7 were superior to those of Zhang, the results in experiments MK6 and MK10 were slightly inferior to those of Zhang, and the results were equivalent in other experiments) and effectively overcomes the encoding problem that occurs when a GA is used to solve the FJSP."
  },
  {
    "year": "2017",
    "abstract": "A multipath component distance (MCD)-based automatic clustering identification algorithm is proposed to group multipath components (MPCs) obtained from radio channels. The developed algorithm iteratively and dynamically assigns the MPCs to the best cluster thanks to the MCD metric. Its performance and robustness are compared with the K-means MCD algorithm using cluster data simulated with four reference scenarios of the WINNER II channel model. The results indicate that K-means MCD is outperformed for all investigated scenarios in spite of its having a lower computational complexity and faster convergence. Moreover, a by-product of the algorithm is an optimal MCD threshold, that is, the characteristic of the cluster statistical properties for a given propagation scenario. This parameter provides a stronger physical link between the MPCs distribution and the propagation scenario. Therefore, it could be introduced in radio channel models with clusterlike features."
  }
]