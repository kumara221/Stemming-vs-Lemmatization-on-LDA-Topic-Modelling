[
  {
    "year": "2025",
    "abstract": "Metropolitan area networks (MANs) are crucial for establishing beyond 5G (B5G) infrastructure. Although regional railways information has been used to design MAN models, regional railways information is inadequate for designing the topology of metropolitan areas with underdeveloped railway lines. A MAN model algorithm using regional railways information and other regional data is necessary for designing the network models of many metropolitan areas. Therefore, we proposed a novel MAN model design algorithm that incorporates railroad route information and daily movement data to enhance B5G research. In the proposed algorithm, first, the topology is designed with the existing algorithm that incorporates only railway line information. Next, links are added in the topology according to the daily movement data such as person trip (PT) data. By using the proposed algorithm with daily movement data, the MAN model can be designed in metropolitan areas that are not completely covered by railways. We designed the Nara NMN39 model, Wakayama WMN30 model, and Fukui FMN17 model, for Nara, Wakayama, Fukui prefectures. There prefectures are not entirely covered by the railways in Japan. The designed MAN models are a simple plane graph and are widely used in numerous research domains. We compared the designed models with those developed using the existing algorithm that uses only railway line information. We confirmed that the proposed models could be used in various research applications. We provided insights into the characteristics of the proposed models to facilitate their use in research."
  },
  {
    "year": "2025",
    "abstract": "Image misalignment is a significant challenge in the field of pedestrian re-identification. Previous studies typically align pedestrian features using additional models or by leveraging auxiliary information. However, these methods are data-dependent and can fail when dealing with substantial scene variations. To address these challenges, this paper proposes an efficient adaptive channel feature matching (ACFM) strategy. This method adaptively aligns channel feature maps according to image content, enables accurate matching of local features across images, and mitigates the need for supplementary data. Building on the ACFM approach, this paper develops a multi-branch adaptive matching network model. The model incorporates a channel attention mechanism to enhance the representation capacity of individual channels and integrates the ACFM algorithm within local branches to optimize the distance metric computation, effectively capturing and aligning local details. The multi-branch structure is designed to handle both global and local features, enabling the network to comprehensively capture and integrate image information. Evaluation experiments conducted on two widely-used benchmark datasets, Market-1501 and DukeMTMC-ReID, demonstrate that the proposed method offers significant advantages over current state-of-the-art approaches."
  },
  {
    "year": "2025",
    "abstract": "Presents corrections to the paper, (Corrections to “Green Traffic-Oriented Heavy-Duty Vehicle Emission Characteristics of China VI Based on Portable Emission Measurement Systems”)."
  },
  {
    "year": "2025",
    "abstract": "Process mining is an emerging scientific discipline focused on discovering, inspecting, and enhancing process models using event data collected from information systems, automating the detailed modeling work without the need for extensive manual labor. However, privacy preservation issues arise when handling such data. Although various process mining methods, models, and tools exist to support the Business Process Management life cycle, no systematic review has been conducted to evaluate these methods and models under the lens of privacy. This work aims to fill this gap by analyzing the applicability of privacy-enhanced methods for process mining. Through a systematic literature review, we identified 39 relevant papers, examining them to understand demographic trends, challenges, characteristics, and implementations related to privacy in process mining. Our findings indicate that privacy-preserving process mining approaches have gained significant attention, especially post-2018, with a predominant focus on anonymizing event logs rather than developing privacy-compliant methodologies for process mining. Most approaches aim to prevent linkage attacks while adhering to privacy regulations, with many utilizing noise addition techniques for anonymization. Despite several issues in defining and using privacy in process mining, this review provides valuable insights for researchers and practitioners, marking the first comprehensive analysis in this domain and highlighting areas for future research."
  },
  {
    "year": "2025",
    "abstract": "Although coffee is a crucial commodity for developing nations’ economies, processing defects can significantly impact the safety, commercial value, and quality of coffee beans. Traditional coffee bean grading methods are labor-intensive and prone to error, necessitating automated and accurate classification of bean diseases. This study proposes a novel transfer learning-based deep neural network, VGGBM-Net, for classifying coffee bean diseases. It focuses on the timely and precise identification of diseases to improve export quality without compromising safety during production. In this research, the proposed approach is trained using a dataset USK-Coffee of coffee beans to classify healthy and unhealthy beans. The performance of multiple machine learning classifiers, including Random Forest (RF), Logistic Regression (LoR), LightGBM (LGBM), and K-Nearest Neighbor Classifier (KNC), is evaluated alongside neural network techniques such as Convolutional Neural Networks (CNN) and VGG-19. A novel transformation of the VGG-19 model for feature engineering based on transfer learning is introduced, where spatial features extracted from coffee bean images are transformed into class prediction probabilities using LGBM. These enhanced features are then used as inputs for advanced machine-learning algorithms. Unlike traditional models, this feature extraction enhances classification accuracy and robustness. This transformation improves feature extraction by capturing more discriminative patterns, leading to superior performance compared to conventional methods. Experimental results highlight the superior performance of the LGBM classifier, achieving an impressive 99% accuracy, recall, f1, and precision score of 98% with a computational runtime of just 0.084 seconds. K-fold cross-validation ensured the robustness of the models, and optimization techniques were applied to fine-tune parameters for maximum accuracy. This research establishes a highly effective framework for automat..."
  },
  {
    "year": "2025",
    "abstract": "The transition from conventional power systems to converter-based microgrids has significantly advanced sustainability, clean energy integration, and operational reliability. However, this paradigm shift introduces operational challenges due to the intermittent nature of renewable energy sources and the non-linear characteristics of power electronic loads, inducing voltage fluctuations and harmonic distortions that complicate voltage and frequency regulation. Accurate dynamic modeling is hypothesized to be critical for capturing such effects, enabling reliable simulation and control strategy development. This study introduces an innovative dynamic modeling framework for a real-world converter-based microgrid, utilizing both root mean square (RMS) and electromagnetic transient (EMT) simulation methods. The microgrid was modeled in DIgSILENT PowerFactory, with simulations calibrated against high-resolution field measurements from SEL-735 power quality meters. Results show that RMS simulations effectively characterize steady-state dynamics, while EMT simulations are essential for capturing high-frequency transients and non-linear effects from photovoltaic inverters and variable frequency drives (VFDs). This complementary approach provides a comprehensive understanding of microgrid behavior, providing critical insights for improving simulation accuracy, advancing protection schemes, and improving resilience in future low-inertia power networks."
  },
  {
    "year": "2025",
    "abstract": "Conflict-free Replicated Data Types (CRDTs) are vital for achieving strong eventual consistency in distributed systems, but their development and evaluation face significant challenges by inadequate tooling. While CRDT research focus on algorithms and applications, critical gaps persist in validation and performance benchmarking. To address this, a novel Rust-based framework “Crust” designed to offer a modular, configurable, and extensible platform for developing, validating, and benchmarking CRDT implementations. Crust includes Core, Config, Network, Validation, and Benchmark moduels, supporting various synchronization methods and emphasizing correctness and performance analysis. This paper details Crust’s design and theoretical basis, showing how it bridges the gap between CRDT theory and practice, addressing tooling gaps to enhance adoption and real-world use. By enabling rigorous testing and performance evaluation, Crust has the potential to accelerate the development and adoption of CRDTs in real-world distributed systems."
  },
  {
    "year": "2025",
    "abstract": "Class-incremental semantic segmentation (CSS) aims to continuously classify every pixel in an image to its corresponding semantic class. Existing CSS models suffer from two challenges: catastrophic forgetting and background shift. Moreover, when new classes are introduced over time, they struggle to differentiate between new and old classes that are visually similar. We refer to this problem as class confusion. To address the above issues, we propose a novel CSS approach to mitigate class confusion, called MC-Seg. First, we introduce a graph attention decoder (GAD) to capture semantic relationships between embeddings, enabling clearer segmentation across classes. GAD uses joint embeddings as nodes in a graph, enabling visual embeddings to incorporate class information. Furthermore, we propose similarity-aware class discrimination (SCD) to prevent old knowledge from being overwritten by new knowledge, particularly when the two are visually similar. Since visually similar classes are more likely to be confused with each other, SCD increases the distances between their embeddings to preserve essential distinctions. Moreover, to retain the knowledge of other, non-similar classes, we maintain the distances between their embeddings. Extensive experiments on PASCAL VOC 2012, ADE20K and PASCAL Context show that MC-Seg outperforms state-of-the-art CSS methods, especially in alleviating class confusion in incremental learning."
  },
  {
    "year": "2025",
    "abstract": "In industrial manufacturing, anomaly inspection performance is frequently hampered by the scarcity of anomaly data. To address this issue, synthetic anomaly masks and corresponding images are generated using various methods. These methods typically employ separate branches within a single backbone or distinct models for generating anomaly masks and images. However, such approaches frequently result in misalignment between the anomaly mask and image, and a reduction in realism, which adversely affects the performance of downstream tasks. To address these challenges, we introduce Anodapter, a unified few-shot anomaly generation model that utilizes a single diffusion model to sequentially generate well-aligned anomaly masks and images. Unlike earlier models such as AnomalyDiffusion, which use separate models for mask and image generation, Anodapter integrates both tasks into a single diffusion model through its proposed Switch Adapter, eliminating misalignment and improving realism. This unified approach not only enables the alternating generation of masks and images within a single model, but also significantly enhances both precision and realism. The model is designed to facilitate the generation of anomaly images either from generated or user-specified masks, ensuring precise alignment and high-quality results. To achieve this, Anodapter efficiently separates anomaly information into appearance and spatial components. For spatial control, we introduce a Switch Adapter that manages the spatial arrangements of anomalies. This adapter provides targeted conditioning to the backbone diffusion model to generate well-aligned anomaly masks and images. For appearance control, the model employs specialized prompts with unique identifiers, enabling selective generation of anomaly images or masks. These identifiers assist the model in learning the features of anomalous regions and the overall structure of the image. Through extensive experiments with various datasets, including..."
  },
  {
    "year": "2025",
    "abstract": "To address the challenges of incomplete feature representation and insufficient localization accuracy in multimodal fault diagnosis of electrical equipment, this paper proposes a dual-modal feature co-registration algorithm termed Contour Angle Orientation-Speeded Up Robust Features (CAO-SURF). The methodology establishes a three-stage progressive feature enhancement framework through feature space fusion and adaptive registration mechanisms for multimodal sensing data. First, a Modal Perception-Based Canny Edge Detection Strategy (MP-Canny) is developed to resolve feature sparsity in low-contrast infrared images and noise interference in visible-light images. Subsequently, a contour angle orientation (CAO) and a Null-Value Area Compensation Strategy (NVACS)-based gradient field reconstruction model are developed to achieve rotation-invariant feature representation. Finally, an improved SURF descriptor integrated with bidirectional geometric constraint matching significantly enhances feature robustness. Systematic ablation experiments demonstrate that the proposed method outperforms state-of-the-art approaches in core metrics, including registration accuracy and recall rate. The innovatively developed mechanism establishes a novel multimodal information fusion paradigm for electrical equipment condition monitoring."
  },
  {
    "year": "2025",
    "abstract": "Recent advances in imitation learning have enabled robots to learn multiple tasks from large-scale datasets. However, developing a model for multi-tasking humanoid control faces significant challenges. Human kinematic data is available in open-source datasets for humanoid motion learning, but learning policies from this data requires simulation due to the lack of actions. While dynamic data can accelerate learning via supervision, datasets typically lack substantial amounts of such action labels, that are also difficult to be directly used for training due to the unique structure of each human/humanoid systems. In this study, we pre-trained a Generative Pre-trained Transformer (GPT) based model on expert policy-rollout observations only (without actions) from a humanoid motion dataset. Upon fine-tuning on a smaller dataset with both observations and action labels, we demonstrate that our GPT-based model can predict actions to achieve human-like movements faster in training than training a GPT on the entire dataset from scratch directly. Furthermore, performance evaluation based on motion generation across various behaviors showed that our approach achieves efficient learning comparable to baselines."
  },
  {
    "year": "2025",
    "abstract": "DDoS attacks are relevant threats that continue to grow in number, power, and complexity. These attacks are not only materialized through stealthy and fast variants in different network layers but also adapt their behavior and objectives, increasingly targeting less protected devices, particularly those prevalent in Internet of Things (IoT) environments. Recent studies have demonstrated the effectiveness of employing paradigms such as Software-defined Networking (SDN) and its complete realization through programmable data planes for the detection and mitigation of DDoS attacks. However, the complexity of real-world implementation, especially leveraging the Programming Protocol-Independent Packet Processors (P4) programming language (de facto standard in programmable data planes), has posed significant challenges, prompting researchers to concentrate primarily on simulation-based approaches. In this work, we propose an SDN-based Intrusion Prevention System (IPS) that leverages the coordination between the programmable data plane and the control plane to detect and mitigate slow-rate DDoS attacks in IoT environments. A decision tree model is deployed within a programmable switch (P4) to detect the attacks. Furthermore, an SDN controller is responsible for generating mitigation policies and deploying them to the programmable switches, effectively blocking malicious flows. Notably, we implement our solution on a high-performance Tofino P4 ASIC switch, achieving an accuracy of up to 88.74% in detecting attacks, with less than 3% of false positives in mitigation. Our implementation proposes alternatives for IoT environment protection, filling gaps by addressing understudied slow-rate attacks and bridges theoretical and physical implementations of programmable data planes."
  },
  {
    "year": "2025",
    "abstract": "Interference resource optimization is a prerequisite for air defense suppression mission planning, and the degree of optimization of interference resources directly determines the quality of the interference results. In this problem, this paper establishes an interference resource optimization model with radar detection probability, interference effectiveness, and interference bandwidth utilization as the objective functions. Then, in the solution process, to address the issues of the Whale Optimization Algorithm (WOA) easily falling into local optima and low convergence accuracy, the BIO-WOA (Bernoulli Chaotic mapping In-nonlinear Factors and Opposition-based Learning Improved Whale Optimization Algorithm, BIO-WOA) is proposed. First, the population initialization is completed using Bernoulli chaotic mapping based on the whale optimization algorithm, increasing the diversity and uniformity of solutions and enhancing the algorithm’s global search capability. Then, a nonlinear convergence factor is proposed to balance the local and global search capabilities of the algorithm. Subsequently, the centroid opposition-based learning is used to generate mutated whales, improving the algorithm’s ability to escape local optima. Finally, the effectiveness of the algorithm is verified through test functions and simulation experiments."
  },
  {
    "year": "2025",
    "abstract": "Pneumonia is a critical respiratory condition characterized by inflammation in the alveoli, leading to impaired gas exchange and severe respiratory distress. It poses a significant threat to high-risk populations, including neonates, geriatric patients, and immunocompromised individuals. Early and precise detection is crucial to optimizing treatment strategies and reducing morbidity and mortality rates. To address this problem, we propose PneuX-Net, an ensemble-based feature extraction framework that integrates multiple machine learning (ML) models Random Forest (RF), Gaussian Naïve Bayes (GNB) and K-Nearest Centroid (KNC). Random Forest (RF) builds multiple decision trees to identify complex, non-linear patterns within the feature space. Gaussian Naïve Bayes (GNB) utilizes a probabilistic framework based on Bayes’ theorem to manage uncertainty in feature distributions. K-Nearest Centroid (KNC) improves class distinction by clustering feature vectors according to their proximity to centroids. The ensemble methodology harnesses the complementary strengths of these models, improving feature representation and mitigating overfitting, a prevalent issue in white-box models. To validate the effectiveness of PneuX-Net, we conduct extensive experimentation using a 10-fold cross-validation approach. Our results demonstrate that the PneuX-Net+KNC model achieves a remarkable 99.91% accuracy, highlighting its robustness and reliability in pneumonia classification tasks. This ensemble-driven methodology underscores the potential of machine learning in augmenting clinical decision-making by providing an accurate and automated pneumonia detection framework."
  },
  {
    "year": "2025",
    "abstract": "A new meta-heuristic algorithm, termed the House Swallow Optimizer (HSO), is proposed. Inspired by the sophisticated behavioral repertoire of house swallows, this algorithm addresses the limitations of conventional optimization methods in solving complex, high-dimensional problems. The HSO systematically simulates 6 key survival strategies observed in house swallows—roosting, hovering, preying, nesting, breeding and seasonal migration—through a 5-phase mathematical model to achieve effective exploration-exploitation balance. To evaluate the algorithm’s performance, we conducted comparative studies using 23 standardized benchmark functions against 5 established meta-heuristics: BKA, SCA, SOA, DE, and PSO. The experimental outcomes prove that HSO has a strong ability to balance exploration and development, with out-performance over comparative algorithms. In order to verify the engineering application potential of the optimization algorithm proposed in this paper, aiming at the problems of large estimation error, high computational complexity and low accuracy in the DOA estimation of broadband signal of vector hydrophone array, the HSO algorithm is applied to the ML algorithm, and the DOA estimation of broadband signal is successfully carried out. Initially, the SST algorithm is employed for signal preprocessing, where broadband signals are transformed into narrowband equivalents through eigenvalue decomposition. This step facilitates the formulation of a ML-based DOA estimation model, which is subsequently optimized using the HSO algorithm. Simulation results demonstrate that the proposed HSO-ML method is superior to the ML implementation of other algorithms. Specifically, our approach achieves faster convergence speed, lower root mean square error, lower computational complexity and more robust performance."
  },
  {
    "year": "2025",
    "abstract": "Presents corrections to the paper, (Corrections to “Research on Underwater Small Target Detection Technology Based on Single-Stage USSTD-YOLOv8n”)."
  },
  {
    "year": "2025",
    "abstract": "The flexibility of Decentralized Finance (DeFi) has made it popular and fueled the rapid adoption. However, it introduces security vulnerabilities, fraud risks, and data integrity challenges that traditional financial frameworks fail to address. This paper presents DeFiSentinel, a novel AI-enhanced DeFi architecture that integrates Federated Learning (FL), Blockchain, and Cryptographic Smart Contracts to improve financial security and risk management. In this approach, the privacy-preserving risk assessment is done through FL, allowing multiple financial institutions to collaboratively train fraud detection models while maintaining the confidentiality of sensitive data. The integration of a deep neural network (DNN)–based fraud detection mechanism enhances real-time threat resilience. The blockchain-based anomaly detection and cryptographic smart contracts ensure data integrity and tamper-proof financial transactions through DeFiSentinel. According to the findings from the experimental analysis, the FL model achieves an MSE of 0.021 for risk assessment and anR2score of 0.96. The DNN-based fraud detection framework attains a precision of 92.4%, a recall of 91.1%, and an F1-score of 91.7%. Additionally, blockchain latency remains at an average of 3.70 seconds, while smart contract execution maintains low computational overhead. The results confirm that DeFiSentinel effectively mitigates fraud, enhances transaction security, and ensures regulatory compliance in decentralized financial ecosystems. The findings pave the way for scalable, secure, and efficient financial transactions in DeFi, with future work focusing on optimizing scalability and regulatory adaptation."
  },
  {
    "year": "2025",
    "abstract": "This paper presents two fully standard-cell-based synthesizable Successive Approximation Register Analog-to-Digital Converters (SAR ADCs) and the automated layout generation framework. The 1st design is an 8-bit charge-redistribution SAR ADC. A 4-inverter-cell-based analog switch is proposed, effectively mitigating charge injection/absorption in the capacitive digital-to-analog converter. This prototype is fabricated in a 65nm CMOS process and occupies 0.095mm2. With a Nyquist input, the ADC achieves 55.8dB spurious-free dynamic range (SFDR) and 47.7dB signal-to-noise-and-distortion ratio (SNDR) at a sampling frequency of 33.3MS/s without calibration. The power consumption is 0.91mW, achieving Walden Figure of Merit (FoMW) of 0.13pJ/conversion-step. The 2nd design is a 12-bit 2-stage pipelined SAR ADC, where a standard-cell-based amplifier is proposed to amplify the residue voltage after the 1st-stage conversion. This prototype is fabricated also in a 65nm process and occupies 0.136mm2. With a Nyquist input, the pipelined ADC achieves 72.1 dB SFDR and 63.1 dB SNDR at a sampling frequency of 22.2MS/s with a simple foreground calibration of the inter-stage amplifier gain. The power consumption is 2.7mW, yielding a FoMW of 0.105pJ/conversion-step. A layout automation framework based on placement and routing (P&R) tool for the standard-cell-based ADCs is proposed and demonstrated with the 8-bit SAR ADC design as an example."
  },
  {
    "year": "2025",
    "abstract": "Increasing penetration of distributed energy resources (DER) has already resulted in several operational challenges in the power system. While literature focuses on stability challenges to the bulk power system due to high penetration of inverter-based resources (IBR), the challenges from a distribution system becoming unstable due to high DER penetration are not sufficiently addressed. Increasing DER penetration also creates opportunities for a local resource to improve stability in the distribution network without fully relying on support from the transmission system. This work utilizes real-world distribution feeders to first analyze stability challenges due to high-DER penetration and evaluates solutions from GFM-based local resources in a distribution network. This paper then proposes a new screening or system strength index that is based on the equal area method and utilizes only steady-state information in evaluating relative stability of DER interconnections in a large distribution area. The proposed index is further utilized in identifying distribution system strength improvement with advanced inverter controls."
  },
  {
    "year": "2025",
    "abstract": "In the anime industry, character design frequently encounters challenges such as oversimplification and homogenization, which severely restrict the diversity and creativity of character appearances. To tackle these issues, we introduce a Hybrid Structural Decomposition Network (HSDN) that aims to generate anime characters with a realistic style by learning the expressive techniques of traditional anime, thereby providing valuable inspiration and references for designers. The proposed HSDN utilizes an encoder to separately extract structural and color features from input images. The structural features are then processed by our style transfer sub-network, which is based on diffusion models. Subsequently, the structural and color features are fused at multiple scales, and a specially designed decoder is employed to generate the final style-transferred image. Additionally, we have incorporated specific skip connections to mitigate local detail loss during image generation and to enhance the stability of the diffusion process. Experimental results demonstrate that our proposed model not only visually generates anime characters with realistic styles but also achieves superior performance in terms of Style FID and Semantic FID compared with state-of-the-art methods."
  },
  {
    "year": "2025",
    "abstract": "Recently, transformer-based learning models have shown promising results in network traffic prediction across various contexts. However, their potential in Mobile Edge Computing (MEC) environments remains largely unexplored, despite the unique requirements of MEC such as low latency and high-bandwidth communication between end-users and edge servers. This study evaluates the performance of four transformer-based learning models for Internet traffic prediction in MEC environments, comparing them against state-of-the-art models using a real-world dataset from publicly available mobile operator networks. Performance is assessed using mean squared error (MSE) and mean absolute error (MAE) as evaluation metrics. Our experiments demonstrate that the proposed GAN-based transformer model, referred to as 5GT-GAN-Trans, achieves an MSE of 0.428 and an MAE of 0.441, considerably outperforming baseline models such as FED-Former-F (MSE: 0.791, MAE: 0.606), FED-Former-W (MSE: 0.622, MAE: 0.508), Informer (MSE: 0.814, MAE: 0.649), and a standard Transformer model (MSE: 0.803, MAE: 0.640). These numerical improvements underscore the efficacy of transformer-based models for precise Internet traffic forecasting in MEC environments, offering valuable insights for improved network management and enhanced user experience."
  },
  {
    "year": "2025",
    "abstract": "The increasing reliance on medical image segmentation for disease diagnosis, treatment planning, and therapeutic assessment has highlighted the need for robust and generalized deep learning (DL)-based segmentation frameworks. However, existing models often suffer from task-specific limitations, catastrophic forgetting, and poor scalability due to their dependency on narrowly annotated datasets. This creates a significant gap in developing unified, multi-organ segmentation systems that leverage distributed and partially labeled datasets across diverse clinical institutions. To address these challenges, we propose the Federated 3D Knowledge Distillation Network (Fed3D-KDNet), a hybrid federated learning (FL) framework that integrates both global and local knowledge distillation mechanisms. Our model adapts the Segment Anything Model (SAM) for volumetric medical imaging by introducing architectural enhancements, including 3D spatial feature adapters and an Auto Prompt Generator (APG), to optimize spatial representation and reduce reliance on manually crafted prompts. Fed3D-KDNet employs a dual knowledge distillation strategy to mitigate catastrophic forgetting and improve cross-client knowledge transfer, ensuring robust generalization across heterogeneous datasets. The proposed methodology was evaluated on multi-organ CT datasets, including the BTCV benchmark, under centralized and federated settings. Experimental results demonstrate that Fed3D-KDNet achieves state-of-the-art performance with an average Dice score of 80.53% and an average Hausdorff Distance (HD) of 11.43 voxels in federated experiments involving seven clients, showing 5.04% improvement in Dice accuracy and a 4.35 voxel reduction in HD. Moreover, our model demonstrates superior efficiency with a computational cost of 371.3 GFLOPs, 26.53 million tuned parameters, and an inference time of 0.058 seconds per iteration. These results validate the efficacy, scalability, and computational efficiency of Fed3D-K..."
  },
  {
    "year": "2025",
    "abstract": "With the widespread application and rapid proliferation of agricultural solutions in plant factories, “intelligent environmental control technology” has become an important research topic as one of the core functions of plant factories. Accurately obtaining the growth status of plants is the core of intelligent control technology and has been capturing more and more researchers’ attention. In the study of detecting the growth status of cucumber plants, the accurate segmentation of cucumber leaves is crucial. However, under fully artificial lighting conditions in plant factories, the complexity of light is the main challenge for leaf segmentation. Aiming at the challenging problem of cucumber seedling leaf segmentation under a complex artificial lighting environment, this study proposes an improved complex lighting YOLOv8 (CL-YOLOv8) model based on YOLOv8. First, the C2f module in the YOLOv8 backbone network is optimized by replacing the bottleneck with the multi-scale feature module (MSFM) we designed. The convolution kernels of different sizes are employed to capture features at multiple scales in the image, thereby processing target and background information more effectively. Simultaneously, the Efficient Multi-Scale Attention (EMA) mechanism is introduced after MSFM, enabling the model to flexibly adjust the attention allocated to different regions within the image, thus enhancing its robustness to complex lighting variations. Finally, the efficient sub-pixel upsampling block (ESPUB) is designed to improve image resolution without compromising computational efficiency, thereby enhancing the model’s adaptability. The verification results demonstrate that the improved CL-YOLOv8 model, based on the YOLOv8 network, enhances the mAP@50 and mAP@50-95 metrics by 2.4% and 4.1%, respectively, achieving real-time and accurate segmentation of cucumber leaves. The effectiveness and superiority of this approach are validated through comparisons with other widely used segment..."
  },
  {
    "year": "2025",
    "abstract": "The increasing penetration of renewable energy sources (RESs) has transformed power system operations. However, balancing supply and demand is more challenging due to the inherent variability of RESs. This paper presents an efficient framework that integrates demand flexibility, RESs, and energy storage in distribution systems to enhance distribution system performance. The study implements a detailed time-series power flow analysis to investigate the impact of distributed energy resources (DERs) on system performance over a 24-hour period. The simulations incorporate a modified IEEE 123-bus network with two PV systems, flexible loads, and a 300 kW/1200 kWh battery. Additionally, the IEEE 8500-node distribution feeder integrates higher-rated PV, wind generators, and a 500 kW/2000 kWh battery to evaluate grid performance under diverse operational conditions. The battery storage system provides essential grid support through strategic charging during high PV generation and discharging during peak demand periods. The simulation results demonstrate robust voltage regulation and effective demand response throughout the feeder despite varying generation and load conditions. The flexible loads effectively respond to system conditions, varying between 23 to 82 kVA. This study demonstrates the viability of coordinated DER operations and their impact on modern distribution networks."
  },
  {
    "year": "2025",
    "abstract": "The traditional methods of solving topology optimization depends on finite element method (FEM). However, the iterative calculation of FEM increases the time cost of topology optimization significantly. In this paper, a novel strategy based on deep learning is proposed to speed up the topology optimization process. Conditional Generative Adversarial Network (CGAN) is used as the basic network in which the constraints of optimization are taken into consideration as the conditions of generation. Additionally, the stress and strain are generated from initial physical information by networks, and used as the inputs of optimization network. The cascaded network can realize structural topology optimization without iterative calculations in the whole process. In the experiments, the traditional Solid Isotropic Material with Penalization (SIMP) method was replicated and implemented multiple times. It was found that the SIMP method takes 30 - 40 seconds to conduct topology optimization, while the proposed mcGANs only need 1.7682 seconds. Moreover, performance indicators such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and Peak Signal-to-Noise Ratio (PSNR) are used to evaluate the performance of mcGANs, which demonstrate the effectiveness and superiority of this strategy."
  },
  {
    "year": "2025",
    "abstract": "As the Internet of Things (IoT) continues to grow, networks are increasingly at risk from vulnerable devices that allow access to attackers. Two particular threats are posed by rogue devices (i.e. devices present on a network that should not be) and unpatched devices (devices with out-of-date software or firmware). A growing body of research attempts to address these risks: automated IoT device identification. By using methods to quickly and easily identify IoT devices on a network, vulnerable devices can be identified, improving network security. Although there have been publications that survey this research, they are typically broad, discussing IoT device identification only in passing, and do not provide a methodology to clearly compare existing (or future) research. Our novel approach in this paper is to provide a simple methodology for assessing and comparing research into IoT device identification, bypassing the need to delve into granular details such as specific algorithmic choices or feature selections, which are attributes not all papers have, and instead to focus on common attributes shared across papers. We provide a comprehensive literature review for the topic of identifying IoT devices in networks using passive network traffic, resulting in 69 publications examined. We systematically analyse the literature for key elements common across the studies that can allow a comparative analysis, and define five we determine to be most important. We state why these five elements in particular are important, and discuss trends in these elements across the studies. We then produce a summary table containing just the information for the five elements for each study, and how they can be used to understand and compare techniques, considering their context. This gives security professionals and researchers the necessary tools to compare studies, both current and future, to understand how to secure their networks and what they must consider when completing further re..."
  },
  {
    "year": "2025",
    "abstract": "The 2019 coronavirus disease (COVID-19) spread quickly throughout the world, causing a global pandemic. After proper diagnosis, digital images storing patient personal health information are saved and transferred over a public network. As a result, the security aspects of preserving sensitive patient health information are becoming crucial. In this study, we presented an encryption system for COVID-19 CT images to address this problem. This work describes an effective inter-intra bit-level (BL) pixel processing solution for secret medical images through an encryption technique that does not rely on pixel correlation. The hybrid multi-logistic sine chaotic map (MLSCM) technique combines logistic and sine maps, improving randomness and ergodicity and leading to stronger security. The utilization of hybrid MLSCM technology further enhances time efficiency. The system’s security is strengthened by the simultaneous rearrangement and spreading of pixels, which helps to prevent statistical and frequent types of attacks. The SHA-512 hash algorithm is incorporated to generate highly secure keys, ensuring resilience against brute-force and differential attacks. Row-wise and column-based permutation algorithms further enhance security by disrupting statistical processes. The suggested method yields an optimal entropy of 7.9982, which is more significant than the comparable recorded work. The proposed work beats other existing work on calculating the number of pixel change rates (NPCR) and the unified average change intensity (UACI), with values of 99.6233 and 33.5065, respectively. The impact of avalanches for sensitive key analysis has been confirmed with a key space of1.5491×2526, enough to withstand multiple attacks."
  },
  {
    "year": "2025",
    "abstract": "The classification of software requirements into functional (FRs) and non-functional requirements (NFRs) is indispensable for the efficacious implementation of software systems. Traditionally, this endeavor reliant on manual exertion, this process has proven to be both protracted and inherently susceptible to errors, and inaccuracies. Recent advancements in machine learning (ML) have begun to offer promising avenues for automation, enhancing both the efficiency and accuracy of requirement classification. The following research study proposes “NLPReqClassifier,” a lightweight automated classification model that integrates Term Frequency-Inverse Document Frequency (TF-IDF) and Cosine Similarity. Leveraging the PROMISE dataset, which is enriched continually by academic and professional input, this model addresses the existing shortcomings of traditional classification methods. The proposed model utilizes a dual-evaluation approach, ensuring relevance and precision across varied software development contexts. By incorporating iterative feedback into the model’s training process, this research not only aligns with academic standards but also meets the practical demands of the industry. The model’s performance was tested in both academic settings dataset and real-world industry dataset, particularly focusing on its application in Enterprise Resource Planning (ERP) systems. The proposed model demonstrated superior capability to categorize a broad spectrum of software requirements accurately, outperforming existing traditional methodologies in terms of adaptability and efficiency. It showed significant improvements over traditional classification methods, particularly in its ability to dynamically adapt to new and evolving requirements. The dual-evaluation process verified the model’s effectiveness, showcasing high precision and recall rates in both controlled and practical environments."
  },
  {
    "year": "2025",
    "abstract": "Electromagnetic radiation (EMR) exposure from fifth-generation (5G) mobile technology influences human health. This article proposes a numerical analysis to investigate the specific absorption rate (SAR) using an anatomical human head and accurate dipole model to examine the EMR effect at 700 MHz, a low-band frequency for 5G mobile communication. A three-dimensional (3D) digital model of a realistic human head is reconstructed using a series of magnetic resonance imaging (MRI) scans. This model encompasses various tissue types with their respective bio-material properties. The radiation from a mobile terminal is modeled using a dipole-based structure. In this study, the Unsplit-Field Finite-Difference Time-Domain (UF-FDTD) algorithm is modified for numerical analysis, with a perfectly matched layer (PML) serving as the boundary condition. The electromagnetic (EM) simulation is conducted to study the interaction between the two computational objects in the artificial absorbing environment. The Yee cell is utilized for a structured lattice in the UF-FDTD approach, characterized by its uniformity and consistent application throughout the model. The research problem involves correlating the size of the human head model with the unit cell size, which is associated with the average weight of the human brain for adults. The Yee cell is optimized based on the Courant-Friedrichs-Lewy (CFL) condition. This work enhances simulation accuracy twofold. First, the optimization of the unit cell size relative to the wavelength is refined in comparison to other unit cells without a phase error. This optimization leads to an accurate time-step parameter via the CFL criterion, ensuring the stability of the computer simulation. Second, the optimized grid structure of the UF-FDTD algorithm closely approximates the infinitesimal feeding gap, ensuring precise alignment with the exact dimensions of the feed-gap point in the dipole antenna configuration and accurately reflecting the effects ..."
  },
  {
    "year": "2025",
    "abstract": "In recent years, advancements in electrification, intelligent connectivity, and autonomous driving have made functional safety, particularly the vehicle-level controllability, a critical research focus. Although the ISO 26262 standard provides a systematic framework for automotive functional safety, challenges remain in accurately defining and quantifying controllability levels. In this paper, we analyze the influence of potential faults—such as unintended torque and loss of regenerative braking force—on vehicle controllability under various operating conditions. A database of vehicle attitude data and corresponding controllability levels is established through real-vehicle tests. Feature screening is then performed to identify the most relevant attributes that significantly affect controllability. Based on this database, a controllability model is developed using the Support Vector Machine (SVM) method, which can effectively predict controllability levels. The model is applied in multiple simulation scenarios to assess vehicle controllability under different conditions. Additionally, the safety boundaries of motor torque are determined at varying speeds, providing insights into critical thresholds beyond which the vehicle’s controllability may be compromised. This work presents a novel approach for the quantitative analysis of vehicle controllability and safety risks, offering a reliable tool for evaluating functional safety in modern vehicles."
  },
  {
    "year": "2025",
    "abstract": "Emergency response is any systematic response to unexpected events that pose potential risk and/or damage to human life or property. Outbreak of virus, leak of poisonous chemicals, and terrorist attack are just a few examples. The goal of emergency response is to minimize the adverse impact of an incident to society and the environment. To guarantee the implementation of its handling procedure, adequate resources must be available. The success of emergency response also relies on the timeliness of related rescue actions. This paper presents resource-oriented timed workflow nets for the modeling and analysis of the resource requirements in responding to an emergency incident, as well as the time required to complete prescribed response tasks. This new model provides a formal basis for process designers and practitioners to examine the readiness and efficiency of their emergency plans. The presented algorithm can be applied to workflows with sequential, concurrent, decision-making and repetitive structures. A case study on chemical spill response is presented to illustrate the application of the proposed model."
  },
  {
    "year": "2025",
    "abstract": "Finding all data distributed across numerous systems, understanding its meaning, and assessing its quality are major challenges for many companies and organizations. As a result, both researchers and practitioners have become increasingly interested in data catalogs, as such tools maintain a repository of technical metadata annotated with domain knowledge. Data catalog tools thus significantly improve the findability, accessibility, interoperability, and reusability (FAIR principles) of datasets. Currently, there is no generally accepted definition or interpretation regarding the required functionality of data catalog tools. This has not only led to a wide range of so-called data catalog tools but has also made it difficult for practitioners to gain an overview in order to make a targeted selection of a tool. Therefore, the main contributions of this paper are 1) an analysis and discussion of the most important data cataloging functionalities and 2) a systematic survey that investigates the extent to which existing data catalog tools implement these functionalities. The detailed results of this survey (i.e., the identified features, data source connectors, support of artificial intelligence for each data catalog tool) are additionally provided in a table that can be customized, sorted, and filtered. While the evaluation table is intended primarily to support practitioners, and in particular data stewards and data engineers, we want to promote a common interpretation of data catalogs in the scientific community with the results compiled in this paper."
  },
  {
    "year": "2025",
    "abstract": "The Interferometric Synthetic Aperture Radar (InSAR) technique is capable of evaluating and calculating the rate of earth surface displacement over time and across large spatial dimensions with millimeter accuracy. The most common InSAR algorithms for monitoring displacement are SBAS and PS time series. Recent investigations indicate that Multi-Look (ML) Synthetic Aperture Radar (SAR) interferograms with very short baselines are significantly impacted by unwanted short-lived phase artifacts, ultimately impairing the dependability of the InSAR products. In this study, we first calculated the average displacement velocity using a full connection between the interferograms processed with the SBAS algorithm. The results show that the SBAS (full-connection) algorithm is almost free of phase bias and has an 88% correlation with the results obtained from PS-InSAR. By using networks with fewer connections, the processing speed can be increased and the processing volume can be reduced compared to using a full connection SBAS network. Additionally, various networks were processed to assess the amount of phase bias in the SBAS algorithm and to propose an optimal network for this algorithm. The results indicated that the network with eight interferogram connections has the highest correlation with the full SBAS network and the lowest phase bias. Conversely, networks with one to three interferogram connections exhibited the lowest correlation and the highest phase bias. Incorporating interferograms with long time intervals (2, 3, and 4-month) into short-term interferograms (6, 12, and 18-day) has reduced the amount of phase bias. Furthermore, the phase bias varies in soil moisture and different types of vegetation. The results demonstrate a direct correlation between the amount of soil moisture and vegetation and the amount of phase bias; as their levels increase, so does the phase bias."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel compensated PID controller for a class of strongly uncertain, time-varying nonlinear systems with nonaffine control input structures. The main objective is to ensure Lyapunov stability of the closed-loop system, which consists of a classical PID controller augmented with a compensating term and an unknown nonlinear plant subject to significant unstructured uncertainties. The proposed method integrates a conventional PID control structure with an additional compensating control signal designed to mitigate the effects of unknown nonlinearities. To address the challenge of unmeasurable derivative signals, a higher-order serial differentiator with asymptotic convergence properties is utilized to estimate the time derivatives of the output tracking error. A systematic approach for selecting PID gain parameters is presented to ensure system stability. Numerical simulations are conducted to verify the effectiveness and robustness of the proposed controller, demonstrating its practical applicability."
  },
  {
    "year": "2025",
    "abstract": "Multi-sensor data has become a foundation of Earth Observation (EO) research, offering models with enhanced accuracy via optimal fusion strategies. However, the unavailability of sensor data at the regional or country scale during inference can significantly undermine model performance. The literature explores diverse approaches to increasing model robustness to missing sensor scenarios, i.e., to reducing the decline in accuracy caused by missing data at inference time. Nevertheless, most of them have suboptimal behavior when a single-sensor is available for prediction. To address this challenge, we propose a novel method for multi-sensor modeling, Decision-level Sensor Dropout with mutual distillation (DSensD+). This employs a decision-level fusion, ignoring predictions from missing sensors and incorporating the Sensor Dropout (SensD) technique. Unlike works that use the SensD at the input or feature level, we use it at the decision level. Moreover, we include a mutual distillation strategy to improve the robustness. From a practical viewpoint, the additional components in the DSensD+ method are incorporated only for the training phase. During inference, it operates as a standard decision-level fusion model that ignores missing sensors. We validate our method on three EO datasets, spanning binary, multi-class, and multi-label classification tasks for crop- and tree-mapping related applications. Notably, DSensD+ outperforms several state-of-the-art methods, achieving consistent improvements across moderate (single-sensor missing) and extreme (single-sensor available) conditions, as well as with full-sensor data. These results demonstrate the robustness of DSensD+ and highlight the effectiveness of our method for the missing sensor problem, advancing the field of multi-sensor modeling in EO."
  },
  {
    "year": "2025",
    "abstract": "The future Heterogeneous Cellular Network (HCN) is expected to fulfill the demand for the Internet of Things, Industry 4.0, extended reality, connected vehicles and mobile gadgets. In HCN, the deployment of low power nodes inside the coverage area of a high power node yields the benefit of providing improved data rates to users by offloading a portion of users from a highly loaded high power node to relatively lightly loaded low power nodes. However, the offloading of users through conventional cell association schemes may not guarantee improved load balancing along with the energy efficiency (EE) of critical users such as user equipment (UE) with low battery power. This paper proposes improved cell association schemes based on the battery levels of UE and Deep Q-learning (DQL) to achieve load balancing and to decrease the power consumption of Low Battery Users (LBUs). The proposed approach combines UE battery levels with three conventional association schemes for improvement: minimum distance based cell association, maximum biased received power (MBRP), and maximum biased SINR (MBSINR). Results on cell association, load balancing, and EE of LBUs have been compared with conventional association schemes. The proposed battery based cell association models perform well in favor of LBUs and clearly show the significance of the proposed approach."
  },
  {
    "year": "2025",
    "abstract": "Effective clinical deployment of deep learning models in healthcare demands high generalization performance to ensure accurate diagnosis and treatment planning. In recent years, significant research has focused on improving the generalization of deep learning models by regularizing the sharpness of the loss landscape. Among the optimization approaches that explicitly minimize sharpness, Sharpness-Aware Minimization (SAM) has shown potential in enhancing generalization performance on general domain image datasets. This success has led to the development of several advanced sharpness-based algorithms aimed at addressing the limitations of SAM, such as Adaptive SAM, Surrogate-Gap SAM, Weighted SAM, and Curvature Regularized SAM. These sharpness-based optimizers have shown improvements in model generalization compared to conventional stochastic gradient descent optimizers and their variants on general domain image datasets, but they have not been thoroughly evaluated on medical images. This work provides a review of recent sharpness-based methods for improving the generalization of deep learning networks and evaluates the methods’ performance on three medical image datasets, including breast ultrasound, chest X-ray, and colon histopathology images. Our findings indicate that the initial SAM method successfully enhances the generalization of various deep learning models. While Adaptive SAM improves generalization of convolutional neural networks, it fails to do so for vision transformers. Other sharpness-based optimizers, however, do not demonstrate consistent results. The results reveal that contrary to findings in the non-medical domain, SAM is the only recommended sharpness-based optimizer that consistently improves generalization in medical image analysis, and further research is necessary to refine the variants of SAM to enhance generalization performance in this field."
  },
  {
    "year": "2025",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing, yet their deployment remains challenging due to substantial computational, memory, and energy demands. Post-training quantization has emerged as a key strategy for enabling efficient inference, particularly in resource-constrained settings. This systematic review focuses on weight-activation quantization, with a unique emphasis on the emergent outlier phenomenon in LLM activations. This work evaluates recent techniques that mitigate activation outliers and improve quantization efficiency, distinguishing itself from prior reviews. Using the PRISMA methodology, we examine 52 recent studies to uncover key trends and evaluate the effectiveness of different approaches. By synthesizing insights from these works, this review presents a diverse set of techniques and their implications for activation quantization, laying the groundwork for future research and practical advancements in LLM deployment."
  },
  {
    "year": "2025",
    "abstract": "Prediction models for disease onset are critical in biomedical research and survival analysis. With machine learning methods increasingly being used to handle survival data with censoring, unbiased transformation theory offers an alternative method for estimating survival tasks in the presence of such censoring, thereby enhancing model accuracy. This study aims to develop a reliable and efficient prediction algorithm that utilizes unbiased transformation to improve machine learning model performance on interval-censored data. Therefore, we present ICBoost, a novel survival algorithm that integrates regression trees and ensemble methods specifically designed for interval-censored data. Unlike right-censored data, where the exact event time is unknown but occurs after a known time point, interval-censored data only provides intervals within which the event occurred. The inherent complexity of interval-censored data poses challenges for accurate survival prediction. To overcome these challenges, we propose a kernel density estimation-based unbiased transformation approach to estimate failure time. Furthermore, we develop a novel ensemble framework that combines XGBoost with censoring unbiased transformation. This framework allows for investigating the relationships between patient survival and covariates, thereby enhancing prediction accuracy and model interpretability. We evaluated the performance of the ICBoost algorithm against existing methods using various real and simulated datasets. Our results showed that ICBoost exhibited superior performance in identifying hidden patterns for survival prediction tasks, particularly in datasets related to Alzheimer’s disease and the emergence of permanent teeth in the medical field. ICBoost outperformed other methods, as evidenced by lower root-mean-square error, mean absolute error, and Brier score values."
  },
  {
    "year": "2025",
    "abstract": "This study investigated the 3-axis gait kinematics of people with stroke to healthy individuals. The specific focus was stroke effects on shank movements in the sagittal, frontal and transverse planes. Sixteen stroke patients and sixteen healthy participants walked along a 10-meter walkway at self-comfortable walking speed, with shank angular velocity measured using two gyroscopes integrated into an Inertial Measurement Unit (IMU). Gait events in all motion planes, temporal gait parameters, kinematic data, asymmetry indexes (ASI), and Bland-Altman-liked correlations were also computed. Greater diversity gait patterns were observed in stroke patients. Compared with healthy controls, stroke patients showed reduced stance time on their affected side and lower non-affected swing time, causing gait asymmetry, as reflected in higher ASIs. The stroke patients’ shank exhibited limited motion in all motion planes resulting in lower angular velocity and displacement. Sagittal plane angular velocity results were validated using intra-subject comparisons that showed good agreement between limbs in healthy subjects. These empirical findings in this study provide evidence that shank-based IMUs are effective in revealing temporal-spatial gait alterations in people with stroke compared to healthy individuals which can be exploited to develop a targeted rehabilitation plan to reduce abnormalities in the stroke patient group."
  },
  {
    "year": "2025",
    "abstract": "Access to the internet has become a vital part of modern life, especially for communication and essential services. However, during politically sensitive times, internet blackouts can disrupt daily routines, leading to significant psychological impacts. This study explores the mental health effects of the internet shutdown imposed during the Bangladesh Quota Movement in July 2024, when the government cut off access to control information flow. The blackout hindered communication, financial transactions, and critical services, amplifying stress, feelings of isolation, and emotional distress. A survey of 2,085 participants was conducted to assess the behavioral, emotional, and psychological consequences, particularly in academic, work, and social settings. Stress levels among respondents varied from minimal to extreme, reflecting widespread mental distress. To classify these stress levels, machine learning models; Decision Tree (DT), Random Forest (RF), Bernoulli Naive Bayes (BNB), Logistic Regression (LR), eXtreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM) were applied. The SVM model outperformed others, achieving high precision (99.33%), recall (99.00%), F1-score (99.33%), and accuracy (99.49%). This study underscores the urgent need for mental health support during such crises, particularly in low- and middle-income countries like Bangladesh, where mental health care is often neglected. These findings are aligned with Sustainable Development Goal (SDG 3), “Good Health and Well-Being,” stressing the importance of mental health interventions in fostering resilience, well-being, and social stability during crises."
  },
  {
    "year": "2025",
    "abstract": "This paper addresses the challenge of Chinese-Malay speech-to-text translation (S2TT), a crucial yet under-resourced language pair in computational linguistics. We introduce Layer-Freezing Adaptive Fine-Tuning (LFAFT), a parameter-efficient strategy that selectively freezes and unfreezes Transformer layers to optimize model adaptation. LFAFT achieves an 11.8% relative improvement in BLEU-4 scores while reducing trainable parameters by 45% compared to full fine-tuning. Using our newly constructed Chinese-Malay parallel corpus, our approach improves BLEU scores from 1.86 to 9.30 (+7.44 points) compared to existing Chinese-Malay speech translation systems. This work not only establishes the first large-scale Chinese-Malay S2TT dataset but also presents an efficient adaptation method that makes low-resource speech translation more accessible and computationally feasible."
  },
  {
    "year": "2025",
    "abstract": "Breast cancer remains a significant global health challenge, requiring accurate and effective diagnostic methods for timely treatment. Ultrasound imaging is a valuable diagnostic tool for breast cancer because of its affordability, accessibility, and non-ionizing radiation properties. This study proposes a classification method for breast ultrasound images that integrates segmentation and feature extraction. Initially, ultrasound images are pre-processed to enhance quality and reduce noise, followed by segmentation using the U-Net++ architecture. Feature extraction is then performed using MobileNetV2, and these features are used to train and validate classification models to differentiate between malignant and benign breast masses. The model’s performance is assessed using accuracy, precision, recall, Mean IoU, and Dice Score metrics. The U-Net++ model achieved superior segmentation performance with a Dice Score of 0.911 and a Mean IoU of 0.838, outperforming related methods such as U-Net (0.888 Dice, 0.79 IoU) and Efficient U-Net (0.904 Dice, 0.80 IoU). In the classification task, MobileNetV2 when paired with the ANN classifier, produced the highest test accuracy at 96.58%, with a precision of 97% and recall of 96%. Our approach demonstrates superior performance compared to other models, such as RMTL-Net, which achieved 91.02% accuracy, and hybrid CAD models with 94% accuracy. This highlights the benefits of combining advanced segmentation and feature extraction techniques, with MobileNetV2 proving to be the better model, offering superior accuracy and robustness in classification tasks. This approach has the potential to support promise for supporting radiologists, enhance diagnostic accuracy, and ultimately improve outcomes for breast cancer patients. In the future, we will use comprehensive datasets to validate our methodology."
  },
  {
    "year": "2025",
    "abstract": "Quality control, particularly through the use of control charts, has become essential in industry to ensure that processes free from special causes of variability. Many processes are subject to instrument uncertainty, human subjectivity, and operator hesitation at the time of measurement. In such cases, traditional control charts may not be as viable, so intuitionistic fuzzy control charts should be used, as they are able to represent the uncertainty and hesitation of the process. This study evaluates the performance of theX¯-R intuitionistic fuzzy control charts was measured by the Average Run Length (ARL), Standard Deviation Run Length (SDRL) and Run Length Percentiles. Additionally, computational interface was developed in the R programming language, using the Shiny package, capable of facilitating the user’s experience in combining the concepts presented. Different combinations of thecLandcRcoefficients in the IF-WABL (Intuitionistic Fuzzy - Weigthed Average Based on Level) defuzzification method were considered, resulting in 17 scenarios. As these coefficients can be adjusted by the user, it is recommended that scenarios 4 to 7 be used for the general performance of the intuitionistic fuzzyX¯-R control chart, as they lead to reductions in ARL and SDRL values and percentiles close to those of the traditional control chart. A maximum reduction of 5.88% in ARL and 5.45% in SDRL was observed, both in scenario 4. This work showed that intuitionistic fuzzy control charts are efficient at detecting special causes, and that the computer interface developed is capable of performing the proposed functions."
  },
  {
    "year": "2025",
    "abstract": "Nakagami-m distribution is typically used to model various multipath fading channels in relaying networks. This work analyses a NOMA-based vehicle-to-vehicle (V2V) relaying over Nakagami-m fading channels. Specifically, we investigate the performance of a NOMA over the Nakagami-m distributed channels by leveraging a dual-hop full-duplex amplify-and-forward scheme in V2V communications. To this end, we derive closed-form expressions of rate outage probabilities and average received signal-to-interference plus noise ratios for the two vehicular users at non-identical destinations in terms of Tricomi confluent hypergeometric function. The derived analytical results are valid for arbitrary values of the fading parameter m. Furthermore, we also derive the expressions for the lower and upper bounds on rate outage probabilities. The residual self-interference, inherent in the full-duplex V2V relaying is also considered and its impact on the system’s performance is studied. The accuracy of the analytical expressions is validated by simulation results which are found to be in good agreement."
  },
  {
    "year": "2025",
    "abstract": "Currently, many urban rail or subway vehicles obtain electrical energy through their receptors in contact with the contact rail linked to the traction network. As urban rail vehicles arrive at the station frequently or stop temporarily on the rail line, the contact rail still needs to provide the electric power for the on-board equipments. At this point, the receptor is in a static state, where the local overheating happens. This could lead to the damage of the receptor, even causing the vehicle to stop running. Based on the electrical contact theory and Fourier’s law, this paper establishes a three-dimensional thermal field finite element model for the receptor and contact rail (referred to as the boot and rail, BAR). Using the model, the change of the contact resistance under the working conditions is investigated. And the effects of the contact force, transmitted (or power supply) current and receptor wear on the temperature behaviors of the receptor are discussed. The results show that the temperature is negatively related to the contact force but closely related to the contact resistance. When the contact force is less than 100 N, the contact resistance is larger and the temperature is obviously enhanced, with the rise rate of0.05∘C/s. The temperature of the receptor is positively related to the transmitted current. The larger the current, the higher the temperature, more intense the temperature rise; the smaller the current, the more obvious the saturation phenomenon of the temperature, i.e. the rapid attainment of the thermal equilibrium. The larger the wear area of the BAR, the larger the convective heat flux of the receptor, leading to a lower temperature in its steady state. The innovation of this paper is to establish a three-dimensional thermal field model that can more accurately characterize the BAR system under the static electrical contact, by applying the electrical contact theory to the finite element method. Its contribution is to pr..."
  },
  {
    "year": "2025",
    "abstract": "Fatigue and distracted driving are two of the leading causes of major accidents. Drivers play a crucial role in automobile safety, and accurately detecting their driving states can significantly enhance the safety of urban road traffic and improve road operation efficiency. Currently, mainstream research relies on visual features, EEG (Electroencephalography), EOG(Electrooculography), and EMG (Electromyography) to identify driving status. However, these methods are not easily scalable due to the high cost of the data acquisition devices and the fact that physical contact with the body can interfere with normal driving functions. This study conducted a simulation experiment using a driving simulator and physiological wristbands, with a highway as the experimental scenario. Data on the physiological and psychological parameters, driving performance, and wrist movement information of 33 drivers were collected. Firstly, features were extracted through time, frequency domain, and nonlinear analyses, and non-parametric tests were performed to analyze the differences in these features under different driving states, thus selecting an effective feature subset. Secondly, based on this, an impaired driving state recognition model was established by combining feature recursive elimination and machine learning, and the impact of different modal inputs on the model performance was analyzed. Finally, SHAP (SHapley Additive exPlanations) interpretable machine learning was employed to analyze the model results in depth. The results indicate that the XGBoost model based on multimodal information input performs the best, with accuracy, precision, F1 score, and recall reaching 94.28%, 94.28%, 94%, and 94.27%, respectively, demonstrating its effectiveness in recognizing driving status. The mean X-axis angular velocity of wrist motion is a key feature for identifying a driver’s driving status. Additionally, the mean X-axis angular velocity, mean lane offset, and mean X-axis acceleration..."
  },
  {
    "year": "2025",
    "abstract": "Intelligent transportation systems (ITS) are revolutionizing road safety, particularly in urban areas. Innovative sensors like LiDAR are being deployed to monitor traffic flow in real-time, providing precise data on vehicle movements, road conditions, and congestion patterns. These advancements open the path for safer roads and more efficient transportation, with the potential for autonomous driving in the future. In this context, since various environmental factors, such as weather fluctuations and terrain diversity, can introduce anomalies that pose risks and malfunctions to a variety of sensor driving systems, the detection of anomalies in spatial-temporal (ST) preprocessed LiDAR data becomes crucial to ensuring safety. In this paper, we propose a novel low-complex unsupervised model for anomaly detection (AD) within ST preprocessed LiDAR data named CNN-BiLSTM VAE that combines variational auto-encoder (VAE) reconstruction capabilities, convolutional neural networks (CNN) spatial characteristic learning capabilities, and bidirectional long-short-term memory (BiLSTM) networks time series learning capabilities in a symmetric mirror-to-mirror (M2M) architecture. Our method aims to detect abnormal behavior and unusual ST patterns in preprocessed, unlabeled LiDAR data without any prior knowledge of the presence of anomalies by learning complex patterns and dependencies within the ST data, while considering the effects of multiple environmental factors. Experimental validation against benchmark models demonstrates the effectiveness of our proposed model in detecting anomalies within preprocessed multidimensional ST LiDAR data. The model strikes a good balance between complexity and efficiency, achieving a 10% accuracy improvement compared to existing models, with an accuracy of 95.1% and an F1-score of 82.6%. Additionally, injecting diverse environmental anomalies enables testing the model’s performance and reliability in real-world scenarios influenced by environmenta..."
  },
  {
    "year": "2025",
    "abstract": "Pathological image segmentation is a cornerstone in medical image analysis and is crucial for tumor detection, tissue classification, and pathological diagnosis. Existing methods face challenges in addressing complex and diverse tissue structures, multi-scale features, and blurred boundaries, limiting their segmentation accuracy and generalization across datasets. This paper proposes a novel pathological image segmentation method, DMoC-UNet, which integrates Dynamic Mixture-of-Convolution (DMoC) modules, Haar wavelet downsampling, and Dual Attention Fusion (DAF) modules to enhance multi-scale feature extraction and fine-grained boundary segmentation. The DMoC modules enable dynamic routing of features to specialized expert networks, adapting effectively to the diverse tissue characteristics of pathological images. Haar wavelet downsampling preserves spatial details while improving multi-scale representation, and the DAF modules facilitate efficient fusion between shallow and deep features, ensuring semantic consistency. Extensive experiments on three publicly available datasets—EBHI, CRAG, and GlaS—demonstrate that DMoC-UNet outperforms state-of-the-art models, achieving significant improvements in Accuracy of Classification (ACC), Dice Similarity Coefficient (DSC), and Intersection over Union (IoU) metrics.Specifically, DMoC-UNet achieves ACC, DSC, and IoU values of 92.46%, 94.65%, and 90.20% on the EBHI dataset; 85.71%, 88.26%, and 82.79% on the CRAG dataset; and 85.81%, 87.97%, and 83.56% on the GlaS dataset. These results highlight the robustness and adaptability of DMoC-UNet, making it a promising approach for pathological image segmentation. Our code will be released after acceptance."
  },
  {
    "year": "2025",
    "abstract": "Data augmentation (DA) tailored to instances is vital for instance segmentation to improve model robustness and accuracy without high manual annotation costs. Existing erasing methods risk losing information about instances, whereas instance-level methods necessitate additional overhead, such as an object bank and context calculations to decide locations to attach objects to an image. Thus, we propose the instance-centric erasing-based DA method, FlickBI, which enhances focus on the target object and diversity by randomly eliminating confusing information. FlickBI consists of two separate methods: FlickBack and FlickIns. FlickBack removes the unrelated background information based on the given annotations. FlickIns stochastically deletes instances, assuming that instances within one image are independent of each other. The experiments reveal that the proposed simple yet effective method consistently enhances performance across detectors and backbones on three benchmark datasets with just a few lines of code, even if the diversity of transformed images and the number of used instances are lower. On the COCO dataset, FlickBI achieves mask mAP improvements ranging from 0.6 to 5.5. Moreover, on the Cityscapes and LVIS datasets, there is an average improvement in mask AP of +3.1 and +4.8, respectively. Furthermore, FlickBI demonstrates synergistic improvements with other instance-level DA methods."
  },
  {
    "year": "2025",
    "abstract": "Historically Black Colleges and Universities in the United States serve a vital role in providing educational opportunities and training, particularly for underrepresented students, facing a challenge of lower retention and graduation rates compared to other institutions. To overcome this challenge, this study explores the application of generative artificial intelligence models to generate synthetic data, augmenting real datasets to improve student learning outcome tracing at these colleges and universities using Deep Knowledge Tracing techniques, which potentially offers actionable insights to identify at-risk students and enables proactive interventions to enhance retention and graduation rates in Science, Technology, Engineering and Math education. Utilizing two years of educational data from Prairie View A&M University, it applied data augmentation with tabular generative artificial intelligence models. The experimental results indicate that augmenting training data with synthetic samples generated by these models improved tracing performance measured by AUC and accuracy by approximately 5% and 3%, respectively, underscoring the potential of synthetic data to enhance the monitoring of student learning outcomes in diverse educational contexts. These findings highlight the critical role of data augmentation through generative artificial intelligence in improving the student learning outcome tracing, offering valuable insights for strategies to enhance retention and graduation rates."
  },
  {
    "year": "2025",
    "abstract": "Tuberculosis (TB), caused by Mycobacterium tuberculosis (MTb), remains one of the leading causes of death globally, primarily affecting the lungs. Recent technological advancements have improved TB detection, particularly through the application of deep learning (DL) techniques. This research involves a pathologist using microscopy to identify acid-fast bacilli (AFB), combined with a proposed method that incorporates DL for TB detection. The DL models’ accuracy and efficiency are assessed and compared. The integration of DL aims to assist pathologists by providing an initial analysis, potentially streamlining their workflow. The proposed method provides the accuracy of 94%, which is equivalent to the traditional method. In contrast, the workload of pathologists, who is the bottleneck of the diagnosis, is considerably reduced. This novel approach not only demonstrates the potential of DL in healthcare but also emphasizes the significance of advanced diagnostic methods in addressing global health challenges like TB, ultimately improving healthcare outcomes and reducing mortality rates."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we introduce a novel wideband CMOS low noise amplifier (LNA) that employs a current-reuse stacked inverter (CRSI) in conjunction with advanced inductive peaking to significantly enhance noise performance and gain flatness across an ultrawide frequency range. The proposed CRSI integrates two resistive feedback inverters with source-degeneration inductors in a current-reuse configuration. This unique topology not only boosts the transconductance but also aligns the input impedance with the optimal impedance for the minimum noise figure (NF) through precise tuning of the source-degeneration inductors. By incorporating an input-matching network and an output-matching network, simultaneous input and noise matching achievements—resulting in reduced return loss and minimized NF—and a high-pass filter (HPF) configuration for suppressing low-frequency output are realized, respectively. Our meticulously engineered multiple inductive peaking inductors—comprising inter-stage and inter-cell matching inductors—are strategically optimized to maximize gain and enhance NF over the entire operating frequency range of 9.2 to 18 GHz. Fabricated using 65-nm CMOS technology, the proposed LNA occupies a total chip area of 0.38 mm2, including input and output testing pads. Measured results show that the LNA achieves a peak gain of 26.6 dB and a minimum NF of 2.3 dB within the frequency range of 9.2 to 18 GHz. The power consumption of the LNA is 11.4 mW at 2 V, achieving a competitive figure of merit (FoM) among recently reported wideband CMOS LNAs."
  },
  {
    "year": "2025",
    "abstract": "Scanning electron microscopy (SEM) plays an important role in providing high-resolution imaging in various fields, including industrial chip manufacturing, materials science, and nanoscale biology. However, high-resolution imaging often compromises image quality due to noise, such as Gaussian noise, which is caused by electronic noise and signal amplification. Overcoming noise in SEM images traditionally involves the use of various filters, such as the Wiener filter and Gaussian filter, but these methods are often limited in efficiency when handling complex noise patterns, and they can be time-consuming. In recent years, the rapid evolution of deep learning technology has been applied to various machine vision tasks such as classification, detection, denoising, and super-resolution. In this study, a deep learning network, the Gaussian Noise Level Classification Network (GNLCN), is proposed to Classify noise levels in SEM images from 0.0000 to 0.0100, incremented by 0.001. A novel Hybrid Spatial State-Space Model (SSM) block is introduced which uniquely integrates a state-space model with Residual Squeeze-and-Excitation (SE) and other feature enhancement mechanisms to improve spatial feature extraction. The network uses a dual-head classifier, consisting of both a standard classification head and an ordinal classification head. GNLCN is compared with other state-of-the-art (SOTA) models, including ConvNeXT, ResNeXt, EfficientNetV2, Vision Transformer, and VGG-19. Three different SEM datasets are used, namely the NFFA-EUROPE dataset, EPFL CVLab EM dataset, and Biofilms SEM dataset. The proposed network achieved the highest evaluation in accuracy (92.76%), precision (92.77%), recall (92.76%), and F1 score (92.74%), as well as the shortest training time in the NFFA-EUROPE dataset. It also demonstrated consistently strong results on the EPFL CVLab EM dataset and Biofilms SEM dataset, surpassing most competing methods, and thus sets a new benchmark in SEM image analysis. ..."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel dynamic model in the Laplace domain for an advanced ac microgrid with centralized secondary control. The model applies a centralized power-based control strategy and incorporates communication non-idealities such as latency and packet error. Packet loss and communication failure are considered herein as latency issues. The central controller incorporates an anti-aliasing filter that constrains the frequency of the transmitted signal and the packet transmission rate in compliance with Nyquist’s sampling theorem. The model is validated on a test bench, with experimental implementation of the communication system and central controller, and a real-time simulation of the electrical power system via hardware-in-the-loop. The impact of latency on the controller’s performance is evaluated through stability, control bandwidth, load rejection bandwidth, settling time, and rejection of packet errors. The results show that communication latency directly impacts the controller’s performance, affecting all analyzed performance metrics. Meanwhile, the cutoff frequency of anti-aliasing filter and packet transmission rate influence control stability, response dynamics, and the system ability to reject load variations and packet errors. Finally, the paper proposes a flowchart-based guideline for configuring the microgrid central controller and selecting communication technologies to implement ancillary services with predefined durations in advanced microgrids."
  },
  {
    "year": "2025",
    "abstract": "Throughout the years, technology has faced many advancements, the star being the power of Artificial Intelligence (AI), which continues to strike through. This concept has rapidly gained popularity and has raised points of concern in almost every government from the European Union (EU) because of the challenges it possesses in terms of efficiency, decision-making and transparency. This paper revolves around building up an extensive literature review of the academic landscape surrounding the role of AI in Human Resources (HR) in the public sector, analyzing Web of Science publication trends and thematic patterns, spanning 12,121 publications from 2020 to 2024, where both Python and R scripts are applied to extract insights. The findings highlight the relevance of a human-centric approach to AI adoption by addressing ethical, cultural and compliance concerns, with the aid of advanced Natural Language Processing (NLP) techniques, such as Latent Dirichlet Allocation (LDA) for topic modelling and keyword co-occurrence networks for thematic exploration. Moreover, a Hugging Face Named Entity Recognition (NER) model is employed to systematically identify and categorize AI techniques within the analyzed abstracts, providing a foundation for subsequent frequency and trend analyses. The analysis brings out a steady growth in publication volume, with an average of 2,500 papers annually and a significant concentration of research within domains such as neural networks, algorithm optimization and digital transformation. Apart from the interdisciplinary focus of the subject, we aim to shed light on the importance of AI-driven HR strategies in directing administrative insufficiencies of the public sector."
  },
  {
    "year": "2025",
    "abstract": "The growing interest in electroencephalography (EEG) research has highlighted the need for low-cost, wearable EEG acquisition systems. The high cost of commercially available EEG equipment poses a significant challenge to the widespread adoption of these systems and, consequently, to the advancement of potential real-world applications. This paper presents the design of a low-cost, wearable, 4-channel EEG acquisition system. The solution is based on the ADS1299, a 24-bit analog front-end optimized for biomedical signal acquisition. Control and Bluetooth Low Energy (BLE) communication are handled by a CC2650 BLE-enabled microcontroller. Active wet electrodes are employed, each fitted with a preamplification board. The electrodes are affixed to elastic bands using 3D-printed parts designed to facilitate rapid and straightforward electrode placement. An additional reference electrode is placed in an ear-clip. The headbands allow for the precise positioning of the electrodes at various strategic points on the scalp, adhering to the 10-10 system, thus making it adaptable to a wide range of applications. To evaluate the viability of our design, EEG signals from ten healthy subjects were registered and compared to commercial equipment. Our design demonstrated signal quality comparable to reference EEG equipment, while drastically reducing the cost and enhancing usability for practical applications."
  },
  {
    "year": "2025",
    "abstract": "Accuracy in floating-point computations is critical for reliable software, especially in systems where precision impacts safety and performance. Inaccuracies from rounding errors and precision loss can lead to significant issues in applications like scientific computing and engineering simulations. To address these challenges, we introduce ForBac, a static analysis model designed to enhance floating-point precision by combining forward and backward analysis techniques. This dual approach improves the accuracy of floating-point computations compared to traditional methods. We evaluated ForBac on standard benchmarks, including Newton-Raphson and Jacobi Iteration methods, demonstrating its ability to maintain accuracy across complex computations. Results show that ForBac not only improves precision but also offers a scalable solution for analyzing floating-point operations in varied computational contexts."
  },
  {
    "year": "2025",
    "abstract": "The integration of high levels of inverter-based generation (IBG) into power grids requires meticulous planning, especially as IBGs lack the inherent short-circuit capacity of conventional generators, potentially weakening system strength. To mitigate this, synchronous condensers (SCs) are deployed in weak areas to enhance fault current and voltage support. Traditional SC allocation methods use the short-circuit ratio (SCR) as a key metric, but this may not account for control interactions in grids with significant IBG penetration. This study compares two approaches for optimizing SC placement and sizing: SCR-based and network-response short-circuit ratio (NRSCR)-based, a metric that captures dynamic IBG interactions. Applying a genetic algorithm (GA) to the Nigerian power grid as a case study, the SCR-based approach identified two critical points of interconnection (PoIs) requiring 68 MVA of SC capacity, while the NRSCR-based method identified four PoIs, requiring a total of 674 MVA. Although the NRSCR-based method significantly improved system performance during faults—offering faster voltage recovery post-fault and higher fault current contributions—it resulted in a cost increase of approximately 7 times. This highlights the trade-off between cost and performance, underscoring the need for utilities to balance economic and technical considerations when deploying SCs in IBG-dominated grids."
  },
  {
    "year": "2025",
    "abstract": "The integration of artificial intelligence (AI) technologies into education has gained considerable attention for its potential to revolutionize teaching and learning practices. Despite this, the adoption of AI in higher education, particularly to support inclusive learning environments, remains insufficiently studied. This research examines the factors affecting the adoption of AI for collaboration among university students, with a focus on promoting inclusivity. Data was gathered from 443 students at King Faisal University using a survey designed to measure constructs related to AI adoption in collaborative learning. The questionnaire, based on the Technology Acceptance Model (TAM), was tailored to the educational AI context. “Structural equation modeling (SEM)” and hypothesis testing were applied to evaluate the relationships between constructs. The results indicated that “perceived ease of use”, “perceived usefulness”, and “behavioral intention to use AI” are significant predictors of AI adoption among students. Additionally, trust and familiarity with AI were identified as key drivers of behavioral intention. However, the hypothesis that the perceived quality of AI output influences “perceived usefulness” was not supported, suggesting students may not strongly link the quality of AI outputs to its usefulness in academic contexts. This study adds to the body of literature by providing empirical insights into the factors influencing AI adoption for collaboration, offering practical recommendations for creating more inclusive and effective educational environments. The study highlights the importance of building student trust and familiarity with AI to enhance its adoption for inclusive and collaborative learning in higher education."
  },
  {
    "year": "2025",
    "abstract": "The objective of this research was to study the use of rice bran oil mixed with nanoparticles as liquid insulation in transformers by enhancing the efficiency of properties for rice bran oil. To clarify, 3 types of nanoparticles were mixed, i.e., magnetite (Fe3O4), titanium dioxide (TiO2), and aluminium oxide (Al2O3). All of these were mixed in rice bran oil at a 0.01 wt% concentration of rice bran oil volume to improve its electrical, chemical, and physical properties. According to the electrical test, it was found that rice bran oil mixed with 0.01 wt% Fe3O4 nanoparticles of rice bran oil volume contained the highest AC breakdown voltage, with the best lightning impulse breakdown voltage at anode and cathode. As for power loss in the insulators, it was found that Fe3O4, TiO2, and Al2O3 nanoparticles added into rice bran oil could reduce power loss factors in rice bran oil, indicating better electrical efficiency. Besides, rice bran oil mixed with these nanoparticles also contained close relative permittivity to regular rice bran oil and transformer oil. In the test of electrical resistance, it was discovered that transformer oil and rice bran oil mixed with nanoparticles had lower resistance than regular rice bran oil. This meant that the mixture was better at insulating. The chemical property test showed that rice bran oil mixed with nanoparticles had more water than mineral oil and more acidity than transformer oil. This suggests that rice bran oil might still have some issues with long-term use if the right amount of water and acidity are not controlled. The physical property test showed that the surface tension of rice bran oil mixed with all three types of nanoparticles was higher than that of regular transformer oil. For the dynamic light scattering test (DLS) to observe dispersity of nanoparticles in oil, it was found that rice bran oil mixed with Fe3O4 nanoparticles contained a better polydispersity index (PDI) than rice bran oil mixed with TiO2 and Al2O3 ..."
  },
  {
    "year": "2025",
    "abstract": "This study reports low power-dissipation (PD) and low noise-figure (NF) ultra-wideband CMOS variable-gain amplifiers (VGAs). VGA1 and VGA2 use coupled microstrip-line (CL) neutralization with an adjustable-gain-flatness inductor and multiple inductive peaking, featuring complementary common-source (CCS) input and common-source (CS) output stages to achieve low PD and NF values and wide bandwidths. The concurrent current steering of the first and second stages yields large gain-tuning ranges with low NFs. VGA1 and VGA2 with PD of 5.85 mW in the low-noise mode achieve excellent S21 bandwidths (BWs) of 32.3 GHz (2.9–35.2 GHz) and 26 GHz (3.8–29.8 GHz), maximum S21 of 11.9 dB and 13.6 dB, average NF (NFavg) of 4.11 and 3.93 dB, respectively, and minimum NF of 2.43 dB. The input 1-dB compression point (IP1dB) of VGA1 is −11.5 dBm. The chip area of both VGA1 and VGA2 is 0.356 mm2. Moreover, VGA1 attains a decent gain tunning range of 20 dB (−3.8–16.2 dB) under 1.35 dB/step for 5G NR band N257. Additionally, VGA2 attains an excellent gain tunning range of 32 dB (−14.6–17.4 dB), gain flatness of±0.75dB, and NFavg of 3.62 dB between 3.8–24.1 GHz. To the authors’ knowledge, the BW and NFmin/ FOM performance are one of the best results ever reported for millimeter-wave CMOS VGAs (or low-noise amplifiers) with a PD of less than 15 mW."
  },
  {
    "year": "2025",
    "abstract": "The optimization of biofuel production involves balancing multiple conflicting objectives such as yield maximization, cost minimization, and environmental impact reduction. Recent studies have explored various multi-objective optimization (MOO) techniques integrated with machine learning (ML) models to enhance process efficiency. This review synthesizes key advancements in biofuel optimization, highlighting the use of techniques such as Artificial Neural Networks (ANN), Genetic Algorithms (GA), Non-Dominated Sorting Genetic Algorithm II (NSGA-II), and Response Surface Methodology (RSM). Studies have leveraged hybrid models, including Convolutional Neural Network - Gated Recurrent Unit (CNN-GRU) networks for emission control and Neutrosophic Fuzzy Optimization (NFO) for uncertainty handling. While existing models demonstrate improvements in predictive accuracy and optimization effectiveness, challenges remain in model generalization, computational complexity, and real-time adaptability. Future research directions include expanding datasets, incorporating adaptive optimization strategies, integrating uncertainty quantification, and refining hybrid modeling approaches for robust decision-making in biofuel production systems."
  },
  {
    "year": "2025",
    "abstract": "Dysarthria, a motor speech disorder, impairs the muscles involved in speech production, leading to challenges in articulation, pronunciation, and overall communication. This results in slow, slurred speech that is difficult to understand. Augmentative and Alternative Communication (AAC) aids integrated with speech recognition technology offer a promising solution for individuals with dysarthria. However, Automatic Speech Recognition (ASR) systems trained on typical speech data often struggle to recognize dysarthric speech due to its unique speech patterns and limited training data. To address these challenges, a hybrid Transformer-CTC model has been proposed for improving ASR performance on dysarthric speech. The Transformer architecture employs a self-attention mechanism that models complex dependencies between speech features, enabling it to identify and emphasize important patterns even when training data is limited. This ability is particularly crucial for dysarthric speech, where speech signals often exhibit high variability. On the other hand, Connectionist Temporal Classification (CTC) acts as an effective transcription layer. It aligns speech features with character sequences without requiring precise input-output alignment, making it well-suited for handling the inconsistencies and distortions present in dysarthric speech. The integration of these components creates a powerful architecture capable of learning nuanced speech patterns and delivering accurate transcriptions for dysarthric speech. The model was trained using the UA speech corpus, containing 13 hours of speech from 15 speakers with varying dysarthria levels. The proposed hybrid system achieves an impressive Word Recognition Accuracy (WRA) of 89%, demonstrating its effectiveness in accurately transcribing dysarthric speech. This innovative approach significantly advances the development of ASR technologies tailored to diverse and variable speech patterns, ultimately enhancing communication for in..."
  },
  {
    "year": "2025",
    "abstract": "With the arrival of 5G technology, networks face critical challenges in detecting anomalies that can significantly impact performance and reliability. This paper introduces QAED (Quantized Auto Encoder Detector), a novel deep learning approach for anomaly detection in 5G networks with three key innovations: 1) a vector quantization mechanism that effectively captures discrete network states, 2) a kernel density estimation preprocessing step that enables detection of both outliers and distribution shifts, and 3) an integrated architecture that processes multivariate time series data in a unified framework. We provide a detailed evaluation of our model across 5G data scenarios, demonstrating its enhanced accuracy and efficiency in anomaly detection compared to existing state-of-the-art methods, with gains of up to 8%."
  },
  {
    "year": "2025",
    "abstract": "Speech Emotion Recognition (SER) technology analyzes speech characteristics in human-computer interactions to understand user intent and improve interaction experience. It is widely used in the field of intelligent interaction. The significant challenge is to recognize the speech emotion of the speaker faster and more precisely. To address this issue, we propose a lightweight forward-backward independent temporal-aware causal network termed I-TCN to construct bi-directional efficient representations of causality in speech time domain sequences. Specifically, a forward temporal-aware component constructed with dilated causal convolutions and skip connections is deployed to perform forward sequences feature modeling, which captures forward semantic information and causal relationships in the speech signal. It facilitates the prediction of emotional changes in the future. Furthermore, the backward temporal-aware module uses dilated causal convolutions to learn backward information and weighted fusion of multi-level temporal features to enhance the perception of backward emotion changes. Finally, different levels of forward-backward features are fused to refine historical-future emotion change trends and better perceive the details of emotion changes. Experimental results on six different linguistic datasets (EMODB: 95.52%; EMOVO: 92.00%; RAVDESS: 93.75%; SAVEE: 88.54%; CASIA: 94.50%; IEMOCAP: 71.47%) show that the emotion recognition capability of the proposed method is extremely competitive with state-of-the-art technologies. Meanwhile, the numerical results show that the proposed method has a good application prospect with a small number of parameters (0.21M) and low computational cost (80.72 MFLOPs)."
  },
  {
    "year": "2025",
    "abstract": "This study investigates the use of natural language processing language representation models as an early warning system for economic crises, and compares the performance of time series analysis and machine learning models in financial markets before and during the economic crises in order to select the best model. The data used in the research was collected based on the economic crises that occurred in Turkey in December 2021. The aim is to identify an economic crises period by using language representation models for economic news between August 2021 and January 2022. After identifying the economic crises period, short term (1 day), medium term (15 days) and long term (30 days) forecasts were made for the index of thirty companies with the highest trading volume (BIST30) of Borsa Istanbul between 01/01/2021 and 31/12/2021 and performance comparisons were made between the models. The aim is to develop an effective “smart, automatic crises detection and forecasting model selection application”. The CHIT algorithm introduced in the study is a new missing data filling algorithm used in time series forecasting comparisons. Since the CHIT algorithm has a high impact on the model performance, this algorithm is used in the pre-processing step and comparisons are made."
  },
  {
    "year": "2025",
    "abstract": "The inevitable trajectory of future distribution network evolution is characterized by automation and digitization. With the development of tunnel magnetoresistance (TMR) sensor technology, the application of non-invasive and non-contact current detection technology is receiving more and more attention. Based on the analysis of the magnetic field around the three-phase cable, this paper presents a non-invasive current measurement system using a magnetic field sensor array. The system employs 8 TMR sensors arranged in a circular array surrounding the measured cable to reconstruct the currents flowing in individual conductors within the cable. Characteristics of magnetic field distribution in the external space of cables and its influence on the measurement error were investigated by finite element simulation. The performance of the TMR sensors was tested using a dedicated platform to ensure stable measurements. The sensor array was calibrated using the method proposed for sensitivity, phase shift, spatial position, and direction deflection angle to minimize measurement errors. The current reconstruction method was introduced by minimizing the difference between the measured and calculated magnetic flux density using a stochastic optimization algorithm. Simulation and experimental results demonstrate that the proposed system can accurately reconstruct current with an error of less than 2% after calibration, highlighting its potential for non-invasive current monitoring in three-phase power cables."
  },
  {
    "year": "2025",
    "abstract": "The analysis of ECG signals plays an important role in healthcare, particularly for the detection of heart conditions such as arrhythmia, coronary artery disease, or heart attack. Accurate diagnosis often depends on the effective classification of ECG signals. Over the years, numerous methods and algorithms have been developed to classify ECG signals with reliable accuracy. These methods generally follow a two-stage process: signal preprocessing and classification. Preprocessing is focused on removing noise and extracting relevant features that are used in the classification stage. However, preprocessing can also lead to the loss of small but potentially important information, which may affect the performance of classification algorithms. In this paper, we present an approach for ECG signal classification that addresses the issue of information loss during preprocessing. The proposed method incorporates a fuzzy classifier in the classification stage, which is designed to handle the uncertainty introduced by the loss of information. The proposed approach is evaluated through experimental studies, which include comparisons with other classification approaches. The results show that the use of a fuzzy classifier can improve the accuracy of ECG signal classification, especially in cases where preprocessing leads to information loss. The findings suggest that fuzzy classifiers are suitable for ECG signal analysis."
  },
  {
    "year": "2025",
    "abstract": "Adaptive cruise control (ACC) systems are critical for ensuring safe and efficient operation in autonomous vehicles, especially in scenarios requiring precise stopping, such as approaching traffic lights or handling emergency braking. However, many existing ACC systems rely on controllers that become infeasible or fail to ensure stability in safety-critical situations, particularly under short prediction horizons and high velocity. This paper presents a novel approach that integrates invariant sets and linear quadratic regulator (LQR) into model predictive control (MPC) to address these limitations, enabling reliable stopping performance. This approach maximizes the set of recursively feasible states for the ACC compared to the current approaches. The present MPC-LQR–invariant set framework is robust under sensor noise, parameter uncertainty, and external disturbances, validating the approach for real-world scenarios. Additionally, we analyze and compare the feasibility and energy efficiency of the system for different terminal set strategies as control invariant set (C∞) and positive invariant set (O∞). The results suggest an interplay between energy efficiency and feasibility in short-horizon cases, providing actionable insights into selecting appropriate invariant set based on specific application. While control invariant set offers a larger feasible region, positive invariant set provides a more efficient energy consumption. This approach enhances ACC systems compared to previous controllers, providing safer and more reliable stopping for critical situations."
  },
  {
    "year": "2025",
    "abstract": "Precise force control in remote robotic ultrasound systems is critical for optimizing image quality and ensuring patient safety. However, conventional admittance control strategies face limitations in achieving high-precision force tracking during interaction while maintaining accurate position tracking in free motion. To address this challenge, we propose an adaptive variable admittance approach integrated with a novel coarse-to-fine force control strategy, which requires online estimation of environmental properties. The environmental information is estimated by a fusion algorithm that combines force and position data from sensors with confidence scores derived from ultrasound images. Furthermore, a compensation term is introduced to the variable stiffness control law to mitigate estimation uncertainties, thereby enhancing force tracking accuracy. Additionally, an energy tank mechanism is implemented to guarantee system passivity under varying damping and stiffness conditions. The effectiveness of the proposed method was experimentally validated using a teleoperated ultrasound system, tested on both a vascular phantom model and human upper limb. The proposed controller demonstrated stable force tracking performance while maintaining compliance throughout the interaction process. The force tracking errors were maintained within ranges of 0.2 N and 0.4 N with standard deviation of 0.02 N and 0.2 N for the phantom and human experiments, respectively."
  },
  {
    "year": "2025",
    "abstract": "We introduce Agora, a Generative AI-driven system that delivers expert answers and recommendations on climate and agriculture, transforming complex data into clear, natural language explanations. While built for the rural domain, Agora is highly adaptable and can be deployed across various domain applications. It operates as a “mixture-of-experts” language model system, selectively utilizing multiple fine-tuned large language models for inference. By dynamically integrating external data through API calls, Agora ensures real-time, contextually relevant responses. Agora is built for extensibility—it seamlessly integrates new APIs and domains without requiring a full system retrain. Developed entirely with open-source large language models from the LLaMA family, Agora remains open and adaptable, allowing anyone to extend and enhance its capabilities. Optimized for accessibility, Agora runs efficiently on commodity GPUs without compromising performance. By eliminating the need for expensive hardware like NVIDIA’s A100, it makes text generation more affordable and widely accessible. Agora outperforms closed-source models, achieving 78% accuracy on our question-answering benchmark. This result is achieved via dynamic API integration, which pulls in real-time external data, making responses more adaptive, precise, and context-aware."
  },
  {
    "year": "2025",
    "abstract": "The paper analyses new techniques in the field of fast network recovery. It addresses the issues of network convergence, fast network recovery, and mechanisms designed for fast network recovery – Fast Reroute, which minimizes the impacts of outages. The paper describes LoRa technology and its communication protocol, LoRaWAN, which is used mainly in smart cities. The article deals with integrating fast link failure detection in the LoRaWAN network. We address increasing availability in the LoRaWAN network and implement the fast failure detection mechanism, Bidirectional Forwarding Detection (BFD), in the OMNeT++ simulation environment. The implementation is done by modifying and supplementing the source code for the FLoRa simulation framework. BFD accelerates network failure detection in LoRaWAN and reduces packet loss by redirecting to a backup route."
  },
  {
    "year": "2025",
    "abstract": "Complementary Field Effect Transistors (CFETs) have surfaced as a hopeful path to the continued logic area scaling in CMOS technology. This comprehensive review paper explores recent advancements and integration strategies in CFET technology, spanning monolithic CFET processes, vertically stacked nanosheets, and dynamic complementary pin allocation (DCPA) schemes for physical synthesis. Additionally, the paper investigates fabrication and characterization methodologies for vertically stacked junctionless poly-Si nanosheet CMOS inverters for enhanced performance and scalability. This paper delves into the analytical modeling and performance enhancement of CFETs for advanced technology nodes, comparing them with other transistor architectures like lateral GAAFETs. Various CFET configurations, including Hybrid Channel CFETs and sheet-based CFETs, are explored in terms of parasitic capacitance, self-heating effects, and power-performance-area-cost (PPAC) trade-offs. Moreover, the paper discusses recent research advancements in CFET technologies, covering applications, challenges, and prospects. Topics include gate stack solutions for BTI reliability, design rule considerations, heterogeneous stacked RRAM integration, device and system co-optimization, and electrothermal characterization. The semiconductor industry’s transition focuses on the utilization of (EUV) Extreme Ultraviolet lithography for three-nanometer logic processes of CFET and proposing novel CDU and process window analysis techniques. Furthermore, the paper presents a novel CFET-based NAND gate design, termed the double-cell-height (DCH) architecture, to mitigate challenges associated with increased parasitic capacitance and routing congestion. Advancements in process technologies towards (SRAM) Static Random Access Memory cells based on CFET, also design optimization for sub-2nm CMOS nodes are discussed. Additionally, a modeling framework using Artificial Neural Networks (ANN) to estimate process variati..."
  },
  {
    "year": "2025",
    "abstract": "In this paper, a D-band low-noise amplifier (LNA) using the linearity-enhanced technique in 40-nm CMOS process is presented. In this D-band LNA, multiple-gated transistors are used to improve the third-order intercept point (IIP3) while maintaining minimal small-signal gain reduction and nearly identical DC power consumption. This linearized LNA includes three conventional capacitive neutralization common-source differential stages and one multiple-gated transistor (MGTR) stage as the final stage. From the two-tone large-signal measurement results, the linear mode demonstrates a 5 dB improvement in the third-order intercept point (IIP3). In the one-tone large-signal measurement, a 4 dB improvement of the input 1-dB compression point (IP1dB) can be observed in the linear mode. For the small-signal measurement, this LNA achieves peak small-signal gains of 16.5 dB in normal mode and 14.2 dB in linear mode. The 3-dB bandwidth is 35 GHz (110-145 GHz) in both operating modes. Using the Y-factor method, the measured noise figure is 8.8 dB in normal mode and 9.5 dB in linear mode at 140 GHz. The DC consumption is 42 mW and 43 mW at 0.9 V for normal mode and linear mode. The whole chip area is0.32mm2. To the author’s knowledge, this is the first implementation of the MGTR technique in CMOS circuits operating beyond 100 GHz."
  },
  {
    "year": "2025",
    "abstract": "Electricity-intensive industries are highly impacted by electricity prices and their fluctuations. While these industries can change their consumption profiles to avoid peak price periods, they must also adhere to production schedules dictated by their unique manufacturing processes and related constraints. Balance Responsible Parties (BRPs), seek to optimize the electricity costs of their portfolio of customers and have limited access to real-time industrial flexibility. So, the concept of Daily Industrial Flexibility (DIF) is introduced as a trade-off between real-time flexibility and predetermined industrial schedules. Each factory can propose different fixed day-ahead consumption profiles to the BRP, each with a specific activation cost. In this context, this paper proposes a day-ahead flexibility service to minimize the BRP’s costs of electricity purchase on the day-ahead market, activating DIFs within the portfolio of industrial customers. A forecasting model for the electricity price is implemented and an optimization model is formulated to minimize day-ahead portfolio costs. Finally, the case study of a Catalan BRP is presented, considering DIF offers from its largest customers. Results demonstrate that the proposed approach enables accurate predictions of the BRP’s customers operation before DAM closure, successfully identifying alternative schedules to reduce portfolio costs."
  },
  {
    "year": "2025",
    "abstract": "An aggregate transmission of 96 Gbps over 50 m of graded index plastic optical fiber (GI-POF) is demonstrated using six coarse wavelength multiplexing (CWDM) channels in S, C and L optical bands. Each channel transmits an equal rate of 16 Gbps with NRZ formats. The used CWDM channels are 1490 and 1510 in the S band, 1530 and 1550 in the C band, and 1570 and 1590 in the L band. In addition, 16, 14 and 12 Gbps were tested at varying levels of optical power for each CWDM channel, and the BER levels were measured for 50 m GI-POF transmission and compared to that of back-to-back transmission."
  },
  {
    "year": "2025",
    "abstract": "Voice-over-Internet-Protocol (VoIP) based speech steganography techniques provide convenience for covert communication while posing significant threats to network security. Accurately detecting hidden information in voice signals is of critical significance for cybersecurity. In this paper, we focus on comprehensive feature extraction to enhance detection accuracy across varying embedding rates. We propose a steganalysis approach that combines 3D convolution with Bi-LSTM, incorporating an attention mechanism. Firstly, the encoded speech data is partitioned into three-dimensional data blocks, and 3D convolution is used to capture the correlation between consecutive frames. Subsequently, Bi-LSTM is employed to extract the contextual features. Finally, the extracted features are fused and fed into a classification network to determine whether secret information is embedded within the speech stream. We design corresponding experiments on a publicly available dataset comprising 41 hours of Mandarin speech and 72 hours of English speech encoded with the G.723 standard. The proposed method demonstrates superior performance, accuracy improvements of approximately 2%, 3%, 3%, and 4% over state-of-the-art methods."
  },
  {
    "year": "2025",
    "abstract": "In this paper, a new high-voltage and high-current compliance integrated electrical neurostimulator with charge balancing stimuli is presented. The proposed stimulator uses a stacked structure to provide the 11.2 V power supply delivering a biphasic stimulation current of 3.2 mA. It includes a novel charge balancing method to secure safe symmetric and asymmetric biphasic pulse trains with a low charge mismatch of 0.21%. Also, the proposed device properly cancels the switching current spikes generating biphasic stimuli. In addition, two methods based on a gate driver circuit and zero current switching are proposed securing advanced stimulator feature which are validated through extensive testing phase, including a simulation of 29 million periodic stimulation cycles delivering a current of 3.2 mA. The stimulator demonstrates robust performance with an average residual DC current of 11.4 nA after the charge balancing phase. The stimulator is implemented using the standard TSMC 180 nm 1.8 V/3.3 V LV CMOS technology. It operates at a low power budget of90μW. The main core of the circuit occupies an area of 0.181mm2. The fabricated chip has been packaged and successfully tested in a motor function of intraspinal paralysis application."
  },
  {
    "year": "2025",
    "abstract": "Non-invasive crowd estimation has remained a challenging issue among researchers. Methods such as image analysis and Wi-Fi/Bluetooth probing can always be used to identify and track people. Lately, the authors have introduce a non-invasive method for crowd estimation based on ambient RF energy measurements. In this paper, a sensitive sensor based on metamaterials is introduced to measure the variations within an environment of the available RF energy levels for crowd estimation purposes. Considering human body resonance at 2 GHz, a metamaterial absorber is designed to operate at 2.4 GHz while remaining insensitive to polarisation and incident angle. This absorber, is equipped with a feed network and rectifier to efficiently absorb and transfer the maximum available Wi-Fi energy into a measurable DC voltage. To evaluate the performance of the sensor, the proposed structure is fabricated as an array, and its performance is tested in both the lab and a controlled real-world environment."
  },
  {
    "year": "2025",
    "abstract": "Despite rapid progress in natural language processing (NLP), the development of specialized resources for niche domains—critical for specialized applications like affective computing and emotionally intelligent AI—remains a persistent challenge. While benchmark datasets abound for general tasks, languages like Arabic and fields like multi-dimensional sentiment analysis beyond binary classification as positive or negative suffer from resource scarcity, limiting progress in human-centric applications. To address this gap, we present ArabSis: a novel Arabic corpus for multi-dimensional sentiment analysis across five categorical emotions (Joy, Sadness, Fear, Liking, Hatred). Our work introduces a reproducible framework for creating specialized corpora in low-resource languages, enabling future research in regressive dimensional sentiment analysis and other specialized NLP applications. The ArabSis corpus, developed through systematic data augmentation and human labelling, facilitates advanced analysis using traditional NLP techniques (TF-IDF, Bag of Words) and modern deep learning approaches. It also targets the universal Arabic language whereas previous research focuses on Arabic regardless of the dialect which make small nuances and inconsistencies among dialects unnoticeable and unfixable. We evaluate machine learning (ML) and deep learning (DL) models in one-vs-all classification tasks, demonstrating that ML models (e.g., SVMs, Random Forests) outperform DL counterparts on smaller datasets. An ensemble method combining top-performing models achieves 98.6% accuracy through score averaging and majority voting systems, though revealing inherent biases in ensemble voting mechanisms. The study provides a comprehensive pipeline encompassing data preprocessing, exploratory analysis, and model training, validated through 5-fold cross-validation, establishing a blueprint for developing specialized NLP resources, particularly for under-resourced languages."
  },
  {
    "year": "2025",
    "abstract": "Currently there is a growing demand for accurate and reliable positioning indoors or in other environments, where Global Navigation Satellite Systems (GNSS) are unavailable. The precise positioning is required for example by autonomous vehicles used in the industry, safety anti-collision systems or for tracking of goods. Ultra-Wide Band (UWB) positioning systems provide precise location information and are therefore often utilized in such scenarios. The GNSS-like Downlink Time Difference of Arrival (TDoA) method is well suited for these problems, enabling unlimited number of simultaneous users. The addition of independent measurements is often sought for improved precision and robustness of the position estimates. So far, only time-based measurements were available, however, UWB boards capable of Phase Difference of Arrival (PDoA) and thus Angle of Arrival measurements have been introduced recently. In this article we leverage UWB-PDoA board with two Qorvo DW1000 transceivers that share a common clock. Its position is estimated by fusing the TDoA and PDoA by Extended Kalman Filter (EKF) in downlink-based system. The EKF tracks the clock bias between the two chips; consequently, prior calibration is unnecessary, as it is done online. Moreover, precise localization is enabled through the algorithm that resolves the ambiguity of PDoA measurements. The positioning performance evaluation shows improvement in accuracy with respect to the TDoA-only solution. The root-mean-square error decreased from 16.38 cm to 15.09 cm, i.e., 8 %, when evaluated among all test points. In the best case, reduction from 14.79 cm to 10.14 cm, i.e., 35 % was observed."
  },
  {
    "year": "2025",
    "abstract": "In recent years, the field of soft robotics has gained considerable attention, due to the high versatility of soft robots in adapting their flexible bodies to unknown environments, resulting in the development of a wide range of robots. Inspired by the morphology and locomotion mechanisms of inchworms and earthworms, various worm-like soft robots have been proposed, typically utilizing a single mode of locomotion such as crawling. In this paper, a worm-like pneumatic soft robot with an interlocking design that realizes bidirectional rolling on flat surfaces and bidirectional crawling on flat platforms and within a pipe, is presented. The crawling locomotion is inspired by the two-anchor crawling observed in biological species, where the animal alternately anchors its rear and front ends as its body elongates or shrinks. The robot consists of two multi-chamber radial actuators encapsulated in plastic cage frames and an axial actuator housed between the interlocking parts. The inflation of one of the radial actuators results in anchorage of the robot on that side, allowing the body to move when the central axial actuator is engaged. Sequential actuation of the individual chambers, near the dead ends on both sides, allows the robot to roll. A prototype of the robot was developed and tested. The results confirmed the robot’s ability to crawl bidirectionally at approximately 16 cm/min on flat surfaces, 15 cm/min inside pipes, and roll up to 40 cm/min on flat surfaces. The transition between these modes was achieved through usage of different patterns, without any hardware modifications."
  },
  {
    "year": "2025",
    "abstract": "The integration of Knowledge Graphs (KGs) with Question Answering (QA) systems is transforming the landscape of Artificial Intelligence (AI). Through the combination of these technologies, novel features can be provided for the translation of questions in natural language into database queries. Even if a lot of work is emerging in this domain, this is not the case when we refer to translation of text to Cypher queries, where Cypher is one of the dominant query languages used for the development of KGs (e.g., based on the Neo4j technology). In this context, this paper provides a robust and efficient framework to systematically assess the efficiency of Large Language Models (LLMs) to support Text-to-Cypher conversion, focusing on the evaluation of open-source LLMs. The framework utilizes metrics and validators offered by an open-source software library that we developed, called CyVer. This study also assesses the impact of different schema representations of the KG on schema-aware query generation and the performance of LLMs on questions of different complexity requiring a depth of reasoning on the KG. A case study is described based on the application of the detailed framework in a KG with a large and complex schema that hosts data to track information related to the Sustainable Development Goals (SDGs). The experimental results demonstrate the effectiveness of the proposed framework, highlight the importance of the size of open-source models in the semantic comprehension of questions and the generation of valid Cypher queries, and stress the challenge for the generation of accurate queries in the case of questions requiring complex Cypher logic."
  },
  {
    "year": "2025",
    "abstract": "The analysis of body fluid cytology images is a faster and easier diagnostic test than traditional methods for detecting cancer cells. Currently, there is limited statistical information on the performance of metric measurements obtained from different deep learning architectures (DL). In this study, the simulation results produced by different deep learning architectures are statistically analyzed in detail and the differences between the models are analyzed. Five different DL architectures (VGG16, VGG19, MobileNet, InceptionV3 and DenseNet121) are evaluated. The mean values of the metric measurement parameters (consistency, specificity, precision, accuracy and F1-score) obtained from the confusion matrix were evaluated using the non-parametric statistical methods Kruskal-Wallis and Mann-Whitney U tests. In addition, pairwise comparisons between AUC (Area Under the Curve) values obtained from ROC analysis were statistically evaluated. When the results were analyzed, the highest success performances were obtained in VGG16 with 98.60% sensitivity, InceptionV3 with 95.69% specificity, DenseNet121 with 95.02% accuracy, DenseNet121 with 89.48% F1-score and DenseNet121 with 91.42% AUC. The results obtained in the study showed that the criteria used in the evaluation metrics have different performances for different CNN architectures. In future studies, it will guide researchers on which CNN architecture gives strong results in which evaluation metric."
  },
  {
    "year": "2025",
    "abstract": "Bounding Box Regression (BBR) plays a critical role in object detection by refining the predicted location and size of objects to enhance model accuracy. This process involves adjusting the coordinates of the proposed bounding boxes to enhance their precision. The Intersection over Union (IoU) loss metric was introduced to improve the IoU metric for integration into the model training process, measure discrepancies between the model’s predictions and ground truth, and ensures meaningful gradient updates during training. In practice, IoU loss has demonstrated improvements in object detection performance by enhancing the localization accuracy of bounding boxes. Despite significant technological advancements and the various advantages and disadvantages of IoU loss, improving the accuracy and efficiency of BBR remains an active research area in computer vision. Various IoU loss variations have evolved with new formulations and methods to improve accuracy and convergence speed. A new loss function, Dimensional Angle Precision IoU (DAPIoU) loss, is introduced in this research to enhance BBR and serve as a new object detection loss function to address the limitations in previous loss function research results. This study conducts three types of experiments: single-group BBR simulation experiment on synthetic data, simulation experiment on synthetic data, and experiment on real-world datasets. The datasets used are MS-COCO and PASCAL VOC datasets. The object detection models used are YOLOv7, YOLOv9, and Faster R-CNN. The results from the real-world datasets experiments are evaluated using the mean Average Precision (mAP) method, including object size metrics, comparing several previous loss functions based on IoU."
  },
  {
    "year": "2025",
    "abstract": "Wind is unstable and unpredictable, and power generation is not constant. Wind speed prediction reduces these disadvantages, and it is essential to measure accurate wind speed predictions to install and stabilize wind power generation systems. This research focused on predicting wind speed data collected from various locations in India, such as Amaravati, Bangalore, Kanyakumari, and Kochi, at heights of 10 m and 50 m, with a sampling period of 1 h for small wind turbine (SWT) applications. This study discusses various deep learning (DL) algorithms for enhancing wind speed forecasting accuracy. The performance of deep learning algorithms is evaluated using multiple metrics, namely, mean square error, normalized mean square error, root mean square error, normalized root means square error, relative root mean square error, mean absolute percentile error, symmetric mean absolute percentage error, and coefficient of determination. For the short-term wind speed prediction, the ensemble learning model approach gave the best results in all sites and among all models applied. The results of the wind speed prediction algorithms show that the Kanyakumari datasets have improved accuracy compared to other locations. At this location, the R2 value is about 0.9942 at a height of 10 m and 0.9955 at 50 m. Further, this dataset is segregated into seasons and months. During the summer seasons, short-term wind speed predictions are more accurate, with R2 values of 0.9885 at 10 m and 0.9904 at 50 m, and November stands out for its highest efficiency in monthly wind speed forecasts, with R2 values reaching 0.9910 at 10 m and 0.9919 at 50 m."
  },
  {
    "year": "2025",
    "abstract": "The transition to a sustainable energy future will result in greater dynamics of aggregated power generation and demand in distribution networks. A vast network with limited real-time measurements presents challenges in comprehensively monitoring the system status and responding promptly to localized disturbances. Sparse signal reconstruction techniques based on affine-constrained rank minimization have been proposed to estimate distribution feeder states with a few measurements, which are presumably well-suited for contexts with very limited observability. Although previous studies on matrix completion-based distribution system state estimation (MCDSSE) have demonstrated acceptable node voltage estimation performance, their effectiveness in estimating branch flow states, to monitor line and transformer loading, remains unproven in the literature. This study assesses the consistency between estimated system states obtained using a variant of the MCDSSE method and actual branch flows and node injection powers to judge the method’s applicability in distribution system monitoring with limited available measurements. The test results confirm that solving a low-rank minimization problem does not enable MCDSSE to recover a realistic AC solution in areas with insufficient measurements, and show that degenerate solutions and multiplicity appear to occur frequently. To leverage its advantage in providing complete solution of the system states, based on operator-defined visibility requirements, four fidelity-monitoring-driven MCDSSE meter placement methods were tested to enhance its acceptability for system monitoring with affordable additional measurements. Numerical examples highlighting practical implications are provided."
  },
  {
    "year": "2025",
    "abstract": "Ensuring the safety of children, the elderly, and individuals with disabilities remains a significant challenge in modern transportation environments, particularly in urban areas with mixed traffic comprising both vehicles and pedestrians. Real-time detection of long-distance and small-scale objects remains difficult due to resolution and computational constraints. This study proposes an improved lightweight object detection model, You Only Look Once – Long-distance Small-target Detection (YOLO-LSD), designed for the long-range recognition of small objects in intelligent transportation applications. The proposed model integrates the C3C2 and the new Efficient Layer Aggregation Network - Convolutional Block Attention Module(ELAN-CBAM) modules to improve the efficiency of feature extraction while reducing computational overhead. The C3C2 module optimizes the network structure by reducing redundant operations, making it more suitable for real-time deployment on embedded devices. The CBAM module improves feature selection by incorporating channel and spatial attention mechanisms, thereby enhancing the robustness of small-object detection under complex urban conditions. The proposed YOLO-LSD model was tested on a customized wearable backpack system equipped with front and rear cameras for environmental perception. YOLO-LSD attains higher detection accuracy for small and distant objects while maintaining lower computational complexity. This study employs the PASCAL VOC2007+2012(VOC0712) dataset to evaluate the proposed model. Compared with YOLOv7, the model achieves a maximum mean Average Precision (mAP) of 80.1%, a minimum parameter count of 30.539M, and the lowest computational cost of 91.6 GFLOPS. This lightweight architecture makes it particularly suitable for intelligent transportation, pedestrian safety, and autonomous mobility applications. In summary, this lightweight architecture, YOLO-LSD, is particularly suitable for intelligent transportation, pedestrian ..."
  },
  {
    "year": "2025",
    "abstract": "Accurately distinguishing between real and imagined motor intent is a fundamental challenge in assistive robotics, as it directly affects human-machine interfaces’ (HMIs) ability to effectively interpret user intent. This distinction is particularly critical for individuals with disabilities who may rely on imagined motor intent, as they cannot perform actual physical movements. In such cases, the ability to differentiate between real and imaginary motor actions allows HMIs to respond appropriately, which improves the precision and usability of assistive devices. Many modern approaches lack the precision required to differentiate these motor actions from Electroencephalogram (EEG) signals. Real-time applications need a high level of precision to guarantee smooth interaction and control, especially for users who depend on imagined movements. It’s important to understand the difference between real and imagined intent to accurately detect user intentions. This is particularly crucial for individuals with disabilities, as it facilitates more effective control of assistive technologies. In this article, we utilize the EEG Motor Movement/Imagery Dataset, consisting of 4087 training samples and 818 test samples, to develop TransNN-MHA, a new Transformer-based Neural Network that incorporates Multi-Head Attention (MHA) mechanisms for classifying real and imaginary motor actions. The proposed model employs a minimalist architecture that omits decoders and positional encodings to optimize EEG classification. We believe this is the first study focused on classifying real and imaginary motor actions using EEG data. We compare TransNN-MHA with Deep learning (CNN, GRU) and hybrid (CNN-Transformer, GRU-Transformer) models. TransNN-MHA achieves 92% accuracy, outperforming CNN-Transformer (86%) and GRU-Transformer (91%), as well as attention-based models like Self-Attention and Spatial-Temporal Transformers. Our novel use of transformers with MHA enhances the classification of EEG ..."
  },
  {
    "year": "2025",
    "abstract": "The integration of sustainable energy sources into modern power grids is crucial for achieving a more resilient, equitable, and environmentally sustainable electricity infrastructure. As the demand for renewable energy increases, tidal turbines have emerged as a promising solution for expanding power generation and contributing to a more diverse mix of sustainable energy sources. However, tidal energy is influenced by variations in environmental and hydrodynamic conditions, which affect tidal turbine power output. As a result, the amount of power a tidal turbine generates at any given moment remains uncertain. This uncertainty poses significant challenges for grid energy management and maintaining a supply-demand balance. To address this issue, this study introduces a systematic approach to quantifying, modeling, and predicting uncertainty in tidal turbine power output. Unlike conventional methods that focus on variability, this framework defines uncertainty as unpredictability and applies time-series modeling to characterize and forecast uncertainty in power generation. The methodology employs an Autoregressive Integrated Moving Average (ARIMA) model to capture predictable patterns, while a Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model quantifies and predicts uncertainty in tidal turbine power output. The proposed method was implemented using high-resolution experimental data from controlled tidal turbine tests conducted at the FloWave facility at the University of Edinburgh. The results confirm that the GARCH model effectively predicts future uncertainty levels. The findings establish a foundation for advancing tidal energy deployment and enhancing the integration of renewable resources into the power grid."
  },
  {
    "year": "2025",
    "abstract": "The present study applies a hybrid Multi-Criteria Decision Method called Multicriteria Instant Runoff Voting (MIRV) to select the most appropriate coastal protection measure for Balneário Camboriú, Brazil, a city that is highly vulnerable to rising sea levels. MIRV combines the features of Instant Runoff Voting and the Borda method to integrate multi-criteria assessment while addressing the monotonicity shortfall of traditional voting systems. The research engages a multidisciplinary team of seven professionals to evaluate seven coastal protection alternatives against 11 criteria, including implementation cost, environmental impact, social impact, and adaptability. The results identify Submerged Artificial Reefs (SAR) as the most suitable measure, balancing protection with ecological and social benefits. Sensitivity analysis confirms the method’s robustness despite varying decision-maker preferences. MIRV demonstrates a scalable, intuitive framework that accommodates diverse stakeholder inputs, facilitating decision-making in complex scenarios. This approach can be extended to similar challenges globally, offering a practical solution for integrating scientific rigor and stakeholder values in environmental planning."
  },
  {
    "year": "2025",
    "abstract": "Ground segmentation plays an increasingly important role as a preprocessing module for numerous applications such as Simultaneous Localization and Mapping (SLAM), place recognition, and point cloud registration. The efficiency and accuracy of ground segmentation can directly influence the performance of these applications. While several methods have been proposed, they continue to struggle to meet the comprehensive requirements of robust ground segmentation. To this end, we propose a ground segmentation method called gTRAVEL+, an improvement of TRAVEL that focuses exclusively on enhancing ground segmentation performance. Our method exploits a temporal and locally-aware noise removal strategy, termed Temporal Node-Wise Noise Removal (TNNR), which effectively eliminates noise points that compromise the ground plane fitting process. Additionally, Merge Node Plane Fitting (MNPF) is proposed to address issues of partial under-segmentation arising from suboptimal region sizing. Finally, Rejected Ground Node Revert (RNGR) ensures thorough geometric relationship verification, significantly improving true positives. Quantitative and qualitative experiments conducted on both urban and off-road environments show that our proposed method demonstrates superior performance, achieving aF1-score of 95.16% and competitive speed compared to state-of-the-art methods."
  },
  {
    "year": "2025",
    "abstract": "In order to solve the problem of rotor vibration caused by the unbalanced mass of the Active magnetic bearing (AMBs) rotor system, an Enhanced Linear Extended State Observer (ELESO) is designed based on the linear Extended State Observer (LESO). Firstly, the lumped disturbance including the unbalanced force is observed by ELESO, and the observed value is filtered by the band-pass filter (BF), and secondly, the lumped disturbance is compensated in the frequency band where the peak of rotor vibration is generated, so as to reduce the peak vibration of the rotor, and the saturation of the power amplifier caused by compensation in the full frequency band can be avoided. Then, the poles of the closed-loop AMBs rotor system are analyzed, and it is proved that the proposed control method can ensure the stable operation of the system. Finally, the correctness and effectiveness of the proposed method are verified under the working conditions of no disturbance and sensor runout. The results show that the designed control method has a smaller unbalanced vibration peak and a significant reduction in the control current when the rotor is operating in the full speed range compared with the direct use of LESO."
  },
  {
    "year": "2025",
    "abstract": "Planning the construction of an offshore wind power plant involves balancing design details that affect both technical and financial viability. The electrical balance of plant is a significant part of installation costs, and modeling it can help developers optimize solutions and reduce expenses. This paper presents an approach to model the electrical balance of plant, including inter-array cable routing and sizing, the number and size of HVAC and HVDC export cables, optimized reactive power compensation, offshore and onshore equipment, and grid connection transmission line. The model also accounts for the physical dimensions and weight of offshore and onshore substation components that are significant information for planning further steps such as the constructibility and foundation. This approach is part of CPE-Offshore, software designed to support decision-making for Brazilian offshore wind farms, considering 60 Hz 138 kV and 230 kV HVAC transmission voltages. A generic 1920 MW Brazilian wind farm located 65 km from shore is used as a case study to demonstrate results for different numbers of offshore substations. Additionally, a sensitivity analysis explores reactor combinations and cost comparisons between HVAC and HVDC systems for various plant capacities and distances to the coast. The results indicate a break-even distance of up to 180 km and the most suitable combinations to be evaluated for a 60 Hz system to avoid waste of computational time. This electrical balance of plant approach can be applied to plan an offshore wind power plant in other regions worldwide."
  },
  {
    "year": "2025",
    "abstract": "Data integrity and traceability are important challenges to provide security in the Internet of Things (IoT) networks, which are often vulnerable to data manipulation attacks due to their use of low-resource devices and wireless communication technologies. In this regard, blockchain is a promising solution to enhance IoT security, but the implementation of a conventional blockchain requires high computational and network connectivity resources that are not compatible with IoT networks. In this paper, we propose a lightweight blockchain for data integrity and traceability in IoT networks that adapts the Distributed Ledger Technology (DLT) feature of blockchain to the LoRaWAN wireless communication protocol. Our proposal offers data integrity without the need for complex consensus algorithms or cryptographic operations. We also have designed and implemented a logical LoRaWAN P2P topology that enables communication between the IoT nodes which comprise LoRaWAN’s characteristic star topology. Finally, we evaluate our proposal and demonstrate its feasibility and performance in terms of data traceability, and network overhead."
  },
  {
    "year": "2025",
    "abstract": "The pathfinding problem in a graph has been solved using several classical algorithms, notably Dijkstra’s and A* algorithms. However, most classical algorithms are most effective on static graphs. They either cannot be adapted to dynamic graphs or become computationally expensive. The challenge of processing dynamic graphs, which demands significant computational resources, can be addressed using Classical and Quantum Machine Learning methods. For this review, we consider a dynamically changing graph representing a disaster-stricken city. Our problem, termed the Disaster Escape Routing problem, aims to find the optimal path within this dynamic graph. We review and analyze an existing hybrid quantum-classical machine learning model alongside classical machine learning models specifically for this problem. We also explore Variational Quantum Circuits and Encoding Methods. Our study suggests that hybrid quantum-classical machine learning, Graph Neural Networks, and Temporal Graph Networks offer high performance in terms of path prediction and accuracy in finding the optimal path. This review also identifies Kolmogorov Arnold Networks as a promising approach to solving escape routing problems. Additionally, an integrated approach combining strengths of all the models has been hypothesized to enhance emergency escape route planning."
  },
  {
    "year": "2025",
    "abstract": "Mountain flood water levels exhibit high variability and complexity, making them challenging to predict, and gathering long-term data of disaster-causing factors is difficult in small watersheds, the available disaster-causing variables are short-term multimodal data. In order to improve the accuracy and real-time performance of mountain flood forecasting, we import Deep Learning (DL) model for mountain flood level prediction utilizing compound time series Long Short-Term Memory (LSTM) model and multimodal short data. On the basis of LSTM model, Convolutional Neural Networks (CNN) module is added to increase the short-term window prediction ability, and Attention module is further added to improve the prediction ability of complex water level changes, forming the compound LSTM, including LSTM-CNN and LSTM-CNN-Attention model. The data of multimodal short disaster-causing factors includes hydrology, meteorology, geography, etc., by integrating the short duration time series data for compound LSTM’s input data. This study evaluates the performance of advanced models on three test data set from representative small watersheds in Zhejiang Province, China, highlighting the effectiveness of the compound LSTM model in these specific areas. The findings emphasize the benefits of utilizing the compound LSTM model for flood forecasting. In particular, the LSTM-CNN-Attention model demonstrates enhanced accuracy and real-time processing capabilities."
  },
  {
    "year": "2025",
    "abstract": "The sophistication of Android malware poses significant threats to user security and privacy. Traditional detection methods struggle with rapid malware evolution and benign application diversity, leading to high false positive rates and limited adaptability. This paper introduces a hybrid methodology leveraging advanced machine learning techniques to enhance accuracy and adaptability in Android malware detection. It begins with collecting and preprocessing a comprehensive dataset of benign and malicious applications. An efficient Generative Adversarial Network (GAN) is employed to generate synthetic malware samples, effectively augmenting the dataset and enhancing the diversity of the malware samples under study process. To model the intricate relationships between applications, an efficient Graph Neural Network (GNN) process is utilized. Incorporating transformers, sequences of system and API calls are analyzed, harnessing this ability to discern patterns indicative of malicious activities. Additionally, a one-shot learning model tailored for the detection of new malware variants with minimal examples is introduced, enabling rapid adaptation to emerging threats. Federated learning preserves user privacy by training the model across a distributed network. A reinforcement learning model initiates proactive defenses, identifying optimal actions against malware threats. This methodology advances Android malware detection, showing over 5.9% improvement in detection accuracy, 4.5% reduction in false positives, and enhanced adaptability to new malware variants. It ensures enhanced security for Android users while preserving privacy. Evaluation results highlight its practical applicability in real-time scenarios."
  },
  {
    "year": "2025",
    "abstract": "This study proposes a novel Circular Picture Fuzzy Set (C-PFS) framework integrated with Multi-Attribute Group Decision-Making (MAGDM) using the MACROS method to evaluate the sustainability of sports industry policies. The model addresses limitations of conventional fuzzy and picture fuzzy sets by introducing radius parameters for membership, non-membership, and neutrality, thereby enhancing precision in uncertain decision-making environments. In order to improve on conventional fuzzy and picture fuzzy models, this study makes use of the circular picture fuzzy set (C-PFS) framework, which adds special radius parameters for membership, non-membership, and neutrality. This refined method works especially well for analyzing complicated and unpredictable decision-making situations, like sustainability evaluations of sports industry regulations. In order to thoroughly examine policy sustainability, we suggest a novel analytical approach that combines C-PFS with a multi-attribute group decision-making (MAGDM) technique using the MACROS method. The proposed model effectively lowers uncertainty and subjective biases in policy evaluations by integrating qualitative and quantitative sustainability criteria. To demonstrate its applicability, we assess key sustainability facets of sports industry policies in a case study, including social inclusivity, environmental stewardship, and economic viability. According to the results, the C-PFS-based method offers a more accurate and reliable assessment than traditional techniques. This framework can be applied to other policy evaluation domains and improves decision-making processes in sports policy assessment."
  },
  {
    "year": "2025",
    "abstract": "This work proposes a novel partially powered knee prosthesis to give full support to swing related activities. It represents a technological step forward when compared to microprocessor-controlled knees. The device is based on the electro-hydrostatic actuation principle, combined with the use of a series rotary valve to aid during dissipative phases. Another key feature is the backdrivability enabled by a directly coupled fluid-based actuation principle. To this end, we present a compact design that is subsequently built and tested experimentally with an able-body adapter to simulate a real-case scenario of level walking and stair tasks. Results are compared with the features of existing commercial and research devices. To the best of the authors’ knowledge, the proposed prosthesis is the most compact electro-hydrostatic swing assistive device with the potential to improve the walking gait, for instance by increasing toe clearance and likely reducing the occurrence of stumbling or falling events. Additionally, the prototype enables stair ascent in a step-over fashion, a capability generally unattainable with commercial microprocessor-controlled knees."
  },
  {
    "year": "2025",
    "abstract": "Ensuring the proper use of Personal Protective Equipment (PPE) is critical for safeguarding workers in high-risk environments, such as power distribution systems. This work presents an innovative approach to monitoring PPE usage through Deep Neural Networks (DNNs). Using data from inertial measurement units (IMUs) integrated into PPE items, we propose a solution to classify three usage states—namely carrying, still, and wearing—using raw accelerometer and gyroscope data. More specifically, this work assesses the effectiveness of three distinct network architectures — Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and CNN-BiLSTM—on a publicly released dataset on PPE usage provided by this study, while also comparing them against a traditional baseline Multi-Layer Perceptron (MLP) architecture. Our results demonstrate the superiority of BiLSTM in balancing high accuracy with computational efficiency, achieving above 98% accuracy regardless of the PPE type. This work represents the first application of DNNs for PPE monitoring using IMU data, offering significant implications for enhancing safety compliance and operational monitoring in power distribution."
  },
  {
    "year": "2025",
    "abstract": "Spectrum sensing data falsification (SSDF) attack, i.e., Byzantine attack, is one of the critical threats of the cooperative spectrum sensing where the Byzantine attackers (BAs) forward incorrect local sensing results to mislead the fusion center on channel availability decisions. By using traditional voting rule, the cooperative spectrum sensing performance deteriorates significantly due to incorrect local sensing results. Then, reliability weight strategy becomes the popular solution to avoid incorrect sensing results from BAs and unreliable cognitive radio users (CRUs). However, it is very difficult to detect the attackers since they also occasionally provide correct sensing results to the fusion center for concealing the attack objective. Based on existing techniques, the BAs and CRUs may be assigned with low reliability weights or distinguished from the data fusion account. However, it is very difficult to detect the attackers since they also occasionally provide correct sensing results to the fusion center for concealing the attack objective. Then, existing techniques still suffer from BAs and negative impact of unreliable CRUs. In this paper, we propose the adaptive cooperative quality weight algorithm for mitigating the Byzantine attack issue by distinguishing the BAs and CRUs from the data fusion account while selecting only useful CRUs since the number of members in the account is also the important factor for cooperative spectrum sensing. In our proposed algorithm, we adopt a stable preference ordering towards ideal solution (SPOTIS) for determining the reliability of SUs which shows low computational complexity as compared to other reliability weight-based techniques. To achieve high sensing performance, our global decision threshold is adapted according to the reliability of reliable users. From the simulation results, our proposed algorithm significantly improves global detection probability and total error probability compared to the traditional votin..."
  },
  {
    "year": "2025",
    "abstract": "Predicting the accurate future price of the agricultural crops is important to avoid overproduction or shortages in the food supply chain. To obtain accurate predictions, the process usually involves large and complex datasets, which would add to computational costs for developing a model with good performance. Therefore, this study introduces the single-layer Transformer Convolutional Encoder algorithm (STCE), an improved version of the traditional transformer encoder. STCE is computationally efficient and does not compromise the accuracy of the prediction. In STCE, the fully connected Convolutional Neural Network (CNN) layer is used in the transformer to get the first temporal features and record long-range dependencies with Multi-Head Attention. To minimize complexity while maintaining performance, a single dense layer is used for the output instead of the Multi-Layer Perceptron (MLP) and omit positional encoding, which leverages the natural sequence order of the time series data. Additionally, since time-series price data normally comes with missing values, this study introduce a sequence nearest neighbor imputation algorithm for anchoring that data to complement the STCE method. This study focuses on various vegetable prices, such as tomatoes, long beans, and cucumbers, with empirical validation across various prediction prices, specifically 30-day, 60-day, and 90-day predictions. Predictions made with Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) show that the STCE algorithm is better than other deep learning algorithms, even the traditional transformer encoder. STCE algorithm not only has better performance, but it also reduces the computational time in the training with 12% fewer seconds compared to the transformer encoder and 22% fewer seconds for LSTM. This study not only provides valuable insights for farmers and planners in the agriculture market but also highlights the robust potential of transforme..."
  },
  {
    "year": "2025",
    "abstract": "Near-field focused antennas are one of the most widely concerned industrialization research studies. Among these application scenarios, the microwave near-field focused lens based on transmitarray is one of the intensively designs, which usually consist of Multilayer Frequency Selective Surface (M-FSS). In this paper, the theoretical relationship between the transmission response of a single-layer FSS and that of an M-FSS is established, taking into account the interlayer interactions. Through the derived results, a transmitted element based on four-layer FSS was swiftly identified, which could achieve a phase shift of approximately 330 degrees with a transmission magnitude of better than -1.5 dB. A 3-bit quantized near-field focused lens was subsequently designed, fabricated, and tested, whose operating frequency band is 20.5-21.7 GHz. The simulated and measured results show that the presented near-field focused lens has good electromagnetic wave convergence. And both the simulation and measurement verify the validity of the derived expression, indicating its availability for M-FSS transmitarray element design, thereby streamlining the design process."
  },
  {
    "year": "2025",
    "abstract": "Photogrammetry and LiDAR have become an essential tool for preserving evidence by creating a point cloud of objects such as vehicles and environments. While effective, these methods often struggle with capturing fine details during the mesh generation phase. Neural surface reconstruction methods, such as Neuralangelo, offer a solution by using neural networks to extract 3D geometry from images. Neuralangelo enhances this process by combining numerical gradients with coarse-to-fine optimization for better detail control. In this study, we evaluated Neuralangelo’s accuracy against traditional photogrammetry and LiDAR techniques for mesh generation. Our experiments involved scanning 3D-printed objects of varying complexity. Neuralangelo produced more geometrically accurate meshes compared to industry-standard tools like Polycam and Pix4DCatch. For example, at ±3 mm, Neuralangelo showed a 53.8% improvement over Pix4DCatch and 29.5% over Polycam, with similar results at smaller tolerances. Everyday objects, like chairs, were also scanned, reinforcing Neuralangelo’s superior performance. These findings suggest that Neuralangelo is a promising alternative to traditional methods, offering greater accuracy in capturing complex details during mesh generation. This technology could be especially useful in accident reconstruction for evidence preservation, allowing for detailed mesh generation of crushed vehicles using video inputs from common smartphones."
  },
  {
    "year": "2025",
    "abstract": "Pretreatment methods are critical for metabolomics data analysis, yet their impact on machine learning performance remains insufficiently explored. This paper introduces a novel approach to systematically evaluate eight pretreatment methods—Centering, Autoscaling, Range Scaling, Pareto Scaling, Vast Scaling, Level Scaling, Log Transformation, and Power Transformation—across four diverse metabolomics datasets (MTBLS161, MTBLS547, ST001000, and ST001047). The novelty of this paper lies in its comprehensive assessment of how these methods influence model-specific performance, particularly for Gradient Boosting Classifier, Multi-Layer Perceptron, Support Vector Classifier, and Random Forest. The findings reveal that Vast Scaling and Autoscaling consistently outperform other methods, enhancing classification accuracy and robustness by effectively normalizing metabolite intensities and preserving variance. Simpler methods, like Centering and Log Transformation, offered limited improvements in high-dimensional datasets. This study establishes a novel framework for designing tailored preprocessing pipelines, advancing metabolomics data analysis and enabling the extraction of meaningful biological insights through machine learning."
  },
  {
    "year": "2025",
    "abstract": "The global elderly population is projected to double by 2050, creating challenges in mobility, social isolation, and cognitive decline. Socially Assistive Robots (SARs) offer a promising solution, yet gaps remain in integrating mobility assistance with cognitive and emotional support. The research developed a comprehensive framework for SARs, emphasizing user-centered design, technological innovation, and cultural adaptability. A mixed-methods approach was employed with 200 participants aged 60+, from diverse settings, including rehab centers, retired groups, old age communities and nursing homes. Results demonstrated a 33.3% improvement in mobility scores and a 40% increase in social engagement. Health metrics revealed a 22% reduction in falls, a 15% rise in physical activity, and a 90% user satisfaction rate. Gender and age differences were evident, with males aged 71+ showing higher mobility improvements (35.6%) and females aged 71+ reporting the highest satisfaction (93%). Long-term data indicated sustained benefits, with participants retaining 80% of mobility gains and social engagement levels 38% above baseline after six months. These findings highlight the importance of culturally sensitive and user-centered SAR designs in promoting elderly well-being. The research offers a robust foundation for integrating SARs into elderly care systems, emphasizing adaptability, sustainability, and ethical considerations for future implementation."
  },
  {
    "year": "2025",
    "abstract": "The Ontology Development Tracker (OnDeT) has been developed to facilitate the computation and interactive exploration of differences between multiple versions of a Git-hosted ontology throughout its temporal evolution. Existing tools focus primarily on pairwise comparisons, which limits the ability to analyze the entire evalutionary history of the ontology. OnDeT addresses this limitation by integrating three existing tools for pairwise comparisons between ontologies. Based on changes have been made to the ontology, the OnDeT tool captures and processes differences between different versions of the same ontology. A comprehensive user interface allows users to examine and explore differences in chronological order, as well as to explore specific differences based on a selected class name and dates. In addition, a semantic representation of these differences has been developed using the Provenance Ontology (PROV-O) specification. The OnDeT Knowledge Graph (KG) leverages this representation to provide a detailed semantic overview of all differences. OnDeT is integrated into the Technische Informationsbibliothek (TIB) Terminology Service (TS). Finally, to validate its correctness, OnDeT was evaluated using reasoners and a series of competency questions."
  },
  {
    "year": "2025",
    "abstract": "In recent years, microgrids (MGs) have become increasingly popular as a means of improving the efficiency and reliability of power systems. MGs need efficient controllers to guarantee high power quality and system stability in the face of various disturbances to which they may be subjected. This paper investigates the dynamic performance of three interconnected MGs and presents a dual control strategy to improve the dynamic performance during both the grid-connected mode and unintentional islanding occurrence. Conventional fixed-parameter linear controllers such as PI and droop controllers are widely used in MG applications; however, they may not be efficient at rejecting disturbances to MGs. To address this issue, this paper proposes a self-tuning PI (ST-PI) controller, which is a nonlinear adaptive controller that can adapt to different operating points to regulate the system voltage and frequency. The performance of the ST-PI controller is evaluated and compared with that of the conventional PI controller under various scenarios, including severe conditions and transitions between grid-connected and islanded modes. The simulation results demonstrate that the ST-PI outperforms the PI controller under different disturbances in terms of overshoot, undershoot, settling time, and integral time absolute error (ITAE). Additionally, the paper utilizes an advanced bioinspired metaheuristic algorithm, the Newton-Raphson-based optimizer (NRBO), to optimize the design of the proposed controllers via the ITAE as a performance measure."
  },
  {
    "year": "2025",
    "abstract": "Functional organization of the brain can be characterized as a network of interconnected regions. Study of brain networks has offered new insights on human behavior and neurodegenerative diseases. Recent studies show that the functional connectivity networks are dynamic with the topology and community structure evolving with time during task performance and rest. Most of the current work on analyzing the community structure of dynamic networks either focus on single subjects or extract the group level community structure. In this paper, we present a framework for community detection in dynamic functional connectivity networks across multiple subjects and at the individual level, simultaneously. The proposed approach is based on a structured robust tensor decomposition with spectral clustering, temporal smoothness and co-clustering regularization terms to extract both the group and individual level community structures. Moreover, the temporal evolution of the community structure within the group is tracked to identify change points that may correspond to events of interest. The proposed framework is applied to dynamic functional connectivity networks constructed from task-based electroencephalogram (EEG) data."
  },
  {
    "year": "2025",
    "abstract": "Accurate 3D object detection is essential for robust perception systems in autonomous vehicles. This paper presents Pillar-X, a 3D object recognition framework designed to generate and use self-learned image features. Unlike approaches that rely on pre-trained networks, Pillar-X efficiently learns and fuses features from an image directly within an end-to-end pipeline. Comprehensive evaluations on the KITTI and CARLA-generated dataset demonstrate Pillar-X’s significant reduction in false positive detections, especially for the pedestrian and cyclist classes. The proposed model achieves this while maintaining a speed similar to the baseline algorithm (¿20 Hz). By comparing the network using both PASCAL and a specific criterion, it can be concluded that Pillar-X is able to improve accuracy and reliability in 3D object detection tasks."
  },
  {
    "year": "2025",
    "abstract": "Orbital angular momentum (OAM) is an intrinsic property of electromagnetic (EM) waves that has opened new possibilities for enhancing the capacity of wireless communications. Consequently, it has garnered significant attention in recent years. For wireless communications, antenna arrays are the most effective and widely studied approaches for OAM-wave generation. Various types of antenna arrays have been explored in research and development; however, a comprehensive comparison of these arrays remains lacking. This paper addresses this gap by first reviewing the various types of phased arrays that have been considered for OAM generation in the literature. Subsequently, it addresses the key performance indicators (KPIs) of the antenna arrays for OAM-wave generation. These KPIs include directivity, the largest producible OAM-mode (LPM), OAM-mode multiplexing capability, divergence angle, and mode purity. Based on the KPIs, a comparative analysis is conducted across several types of antenna arrays, including uniform square arrays (USA), uniform circular arrays (UCA), three-dimensional (3D) helical circular arrays (HCA), 3D helical circular sub-arrays (HCSA), and concentric UCAs (CUCA), under various settings. The study highlights the advantages and limitations of each antenna array type and examines how different parameters influence their performance."
  },
  {
    "year": "2025",
    "abstract": "This study explores the application of the Artificial Intelligence of Things (AIoT) in viticulture for the early detection of grapevine diseases. By integrating Internet of Things (IoT) sensors with machine learning algorithms, the system is designed to detect potential grapevine pathogens in real time. Deployed at the Murfatlar vineyard in Romania, which grows Cabernet Sauvignon and Sauvignon Blanc, the system allows for proactive disease management, thus improving grapevine health and reducing crop losses. IoT sensors are installed in the field to collect real-time data on grapevine health, which is then transmitted to the cloud for storage and analysis. Machine learning (ML) algorithms, running on a server with an NVIDIA R3900 card, process this data to predict potential infections caused by pathogens such as Plasmopara viticola, Uncinula necator, and Botrytis. Cloud computing facilitates data processing and real-time visualization, allowing farmers to make timely, data-driven decisions for disease control. The paper outlines the hardware and software components that constitute the diagnostic system."
  },
  {
    "year": "2025",
    "abstract": "Network compression is a crucial technique for applying deep learning models to edge or mobile devices. However, the cost of achieving higher benchmark performance through compression is continuously increasing, making network compression a significant burden—especially for small industries focused on developing compact models. Specifically, existing network compression techniques often require extensive computational resources, rendering them impractical for edge devices and small-scale applications. To democratize network compression, we propose a general-purpose framework that combines novel filter pruning and knowledge distillation techniques. First, unlike conventional filter pruning methods based on static heuristics and costly neural architecture search (NAS)-based approaches, our method leverages meta-learning for rapid and fine examination of the importance of each gate. This enables rapid and stable sub-network discovery, significantly improving the pruning process. Second, to minimize the computational cost of knowledge distillation, we introduce a synthetic teacher assistant that leverages precomputed fixed knowledge—referring to the stored feature maps/logits of the teacher network. By leveraging fixed knowledge, we mitigate the cost incurred by the teacher network and facilitate the transmission of fixed knowledge to the student via synthetic teacher assistants, thereby preventing distribution collapse. Our proposed framework dramatically reduces the compression overhead while maintaining high accuracy, achieving a 55.2% reduction in FLOPs of ResNet-50 trained on ImageNet while preserving 76.2% top-1 accuracy with only 199 GPU hours—significantly lower than previous state-of-the-art methods. Overall, our framework democratizes deep learning compression by offering a cost-effective and computationally feasible solution, enabling broader adoption in low-resource environments."
  },
  {
    "year": "2025",
    "abstract": "Advanced Persistent Threats (APTs) involve attackers maintaining a long-term presence on victim systems, leading to the stealthy exfiltration of sensitive data during network transfers. Despite existing methods to detect and halt APT data exfiltration, these attacks continue to pose significant threats to sensitive information and result in substantial commercial losses. Current approaches primarily focus on preemptive measures, which are insufficient once early-stage detection fails due to a lack of continuous monitoring. We propose an effective and efficient network monitoring method to address this gap and detect APT exfiltration during data transfer. Our approach assumes the presence of an undetected APT attacker within the victim system. We examine data exfiltration across three exfiltration traffic environments: exfiltration over command control channels, exfiltration over transfer size limitations, and their combinations. We introduce two detection metrics: Package Transfer Rate and Byte Transfer Rate. Utilizing these metrics, we measure network traffic, categorize APT attack environments, and train deep neural network models, named EDXGB, using ensembled decision trees to predict APT exfiltration. Our method is validated on two public datasets and compared against six baseline methods. Additionally, we simulate real-world exfiltration scenarios by creating three exfiltration traffic environments for each dataset. The results demonstrate that our method effectively detects APT exfiltration across various network environments, enhancing data protection and secure transfer. The code is open source and available athttps://github.com/cxjuan/EDXGB-for-APT."
  },
  {
    "year": "2025",
    "abstract": "Human Pose Estimation (HPE) is the technique of precisely estimating the locations of human joints in images and videos. Deep learning has been frequently applied recently to improve HPE performance. However, a number of challenges, including occlusions, crowded environments, and hidden joints, make it difficult to create an effective HPE model. This systematic review provides a comprehensive analysis of HPE reported challenges, focusing on hidden joint issues due to their significant impact on performance. This study systematically examines a number of HPE models, choosing 74 papers on deep learning-based HPE that have been published since 2018 based on specific criteria. The reported challenges are listed along with their frequency and related references, the review also covers datasets, loss functions, evaluation metrics, and pre-trained models used in HPE. Our analysis demonstrates that occlusion and crowded scenes are still the main issues that affect the model performance, highlighting the importance of addressing hidden joint problem. The review presents a number of findings, such as the most widely utilized architecture in HPE literature is the residual network, the mean square error is the most frequently used loss function. Furthermore, MPII and Human3.6M are the most used datasets for 2D and 3D pose estimation, respectively. Finally, this study highlights the gaps in the field, which could lead to new research opportunities."
  },
  {
    "year": "2025",
    "abstract": "This paper presents an innovative approach to enhancing the time windowing waveform relaxation (WR) technique in electrical-to-mechanical co-simulation by optimizing relaxation parameters for improved performance. An analytical model is introduced to determine the optimal number of time windows, considering the circuit’s dynamic characteristics. Additionally, a genetic algorithm (GA) is applied to refine relaxation parameters (e.g., impedance values), effectively addressing challenges posed by nonlinear device behaviors and improving the accuracy of co-simulation results. In the case study, it is crucial to emphasize that the full system simulation is used exclusively for retrospective validation of the co-simulation, without incorporating its results as inputs or convergence criteria. The proposed method significantly reduces the average error between co-simulation results and the full system output voltage, decreasing it from -2.8 dB to less than −26.2 dB. This demonstrates improved alignment and faster convergence compared to using the WR method. The validation of GA method is then applied to the co-simulation of an electrical (buck converter) and mechanical (DC motor) system, with results compared against the full system. The WR method exhibited significantly lower power efficiency (57.4%) compared to the full system (81.4%), rendering it insufficient. Time windowing WR enhanced power efficiency through simulation segmentation, reaching 74.6%, though it still fell short of the full system. The most advanced approach, time windowing WR with GA optimization, dynamically adjusted relaxation parameters, resulting in a power efficiency of 80.8%, nearly matching the 81.4% recorded in the single-kernel simulation. These findings underscore the effectiveness of integrating time segmentation with adaptive optimization to enhance simulation performance."
  },
  {
    "year": "2025",
    "abstract": "The growth of international trade has accelerated the development of waterway transportation, thereby increasing the demand for the construction of container terminals. Optimizing the Berth Allocation and Crane Assignment Problem (BACAP) is a critical aspect of this process. In this paper, we investigate the capability of differential evolution (DE) algorithms in solving BACAP by modeling berth allocation as a continuous optimization problem. We first analyze an efficient clustering algorithm, Nearest-Better Clustering (NBC), and its effectiveness in partitioning candidate solutions for BACAP into multiple sub-populations. Subsequently, within each sub-population, we propose a novel memetic algorithm (MA) that utilizes the Adaptive Differential Evolution with Optional External Archive (JADE) as a global optimizer, combined with a Neighborhood Search (NS) to enhance the convergence capability of the sub-populations. Finally, to improve search efficiency, we introduce a berth offset distance as a penalty mechanism to minimize berth space wastage. In the experimental section, we conduct experiments on 15 cases and compare the results with four existing algorithms. The experimental results demonstrate that the proposed MA-NBC exhibits superior competitiveness and performance in solving BACAP."
  },
  {
    "year": "2025",
    "abstract": "Electric machine performance can be enhanced through torque ripple mitigation, which reduces mechanical vibrations and improves system stability and operation. This paper proposes a novel two-level optimization method for synchronous flux-switching and hybrid excitation machines, featuring an innovative multi-point spline shaping approach for torque ripple minimization. The study employs experimentally validated models based on a prototype with a similar topology. The optimization process is implemented on two distinct designs: a 20-pole inner rotor PM-excited stator machine and a 28-pole outer rotor DC-excited stator machine. Analysis results demonstrate that the proposed innovative method significantly reduces torque ripple in both configurations. Force calculations and structural stress analysis confirm the machines’ manufacturability and their capability to operate at rated speeds, validating the effectiveness of the multi-point spline pole shaping method."
  },
  {
    "year": "2025",
    "abstract": "Deepfake techniques have been evolving rapidly in recent days and pose a severe security threat. Detecting such generated fake videos is a challenging task. Existing deep learning based deep fake detection model struggle in identifying fake videos when experimented on challenging dataset. In this paper, we propose a Fuzzy logic based Deepfake Detector system (Fuzzy-DFD) using a deep learning model ResNet-50 as encoder. The system workflow includes preprocessing, frame extraction, deep fake detection and decision fusion. In preprocessing, frames are extracted from video, facial region is cropped, and frame resizing is performed. Next, optical flow maps are generated using SEA-RAFT model and edge defined frames generated using Frei-Chen mask technique. These three frame variants present a rich representation of video for the deep learning model. 3 ResNet-50 models are employed as encoders to generate feature maps trained using above frame types, ensuring anomaly identification in spatial, temporal and structural domains. A novel three input and one output Fuzzy Inference System is designed for decision fusion combining the detection results of all three classifier models to make decision on video being a fake. The performance of the proposed Fuzzy-DFD system is evaluated by training the model on well-known deep fake classification datasets namely FakeForensics++ and Celeb-DF(v2). Further results are compiled and evaluated using performance indicators like accuracy, Precision, F1-Score, Recall and AUC. Fuzzy-DFD system attained accuracy of 99% and 93% for FaceForensics++ and Celeb-DF(v2) datasets respectively. Comparison study with other SOTA deep fake detection models is conducted, and Fuzzy-DFD significantly outperformed the other models taken for comparison. The anomaly learning through RGB, optical flow and structural characteristics with fuzzy system-based decision fusion technique contributes to a robust deep fake detection system."
  },
  {
    "year": "2025",
    "abstract": "Natural Language Processing (NLP) is a tract of artificial intelligence and linguistics devoted to making computers understand the statements or words written in human languages. Amharic, the most widely spoken language in Ethiopia, uses a lot of idiomatic expressions and proverbs to emphasize the message of the text. The meaning of an idiomatic phrase cannot be inferred from individual words. Developing a model to identify Amharic idiomatic terms is helpful for different NLP applications like machine translation, sentiment analysis, spam classification, intent recognition, and so on. Few studies have been conducted to identify idiomatic expressions using K-Nearest Neighbors (KNN) and Convolutional Neural Network (CNN) algorithms for the Amharic language. The KNN model was designed to identify only dual-word idioms by neglecting idioms with three or more words, and this study didn’t use the n-gram technique to identify idioms found in a sentence or paragraph. Like the former model, the CNN model did not use the n-gram technique, and the testing accuracy was not greater than 80%. Due to this gap, we need to develop a deep learning model that identifies Amharic idioms constructed from two or more words. To identify idioms found in a sentence or paragraph, we used the n-gram method to divide the sentence or the paragraph into phrases for enhancing the previous works. For designing our model, we used 4053 idiomatic phrases and 4051 literal Amharic phrases. After the data were collected, text preprocessing techniques were applied to the collected data, and FastText and Word2Vec models were used for word embedding purposes. We conducted experiments with 70:30 and 80:20 data split ratios with FastText and Word2Vec word embedding models along with long short-term memory (LSTM) and bidirectional LSTM (Bi-LSTM) with and without attention layer algorithms. Among those experiments, the highest accuracy of 98.95% was attained using an 80:20 train-test split ratio, Adamax optimiz..."
  },
  {
    "year": "2025",
    "abstract": "Power system planning tools require hourly weather data to capture the variable conditions that influence electricity supply and demand (e.g., temperature, wind, and solar). It is well-established that using current or historical weather conditions is insufficient for planning a resilient system under climate change and that forward-looking data are needed when conducting energy transition studies through 2050. However, nearly all global climate model (GCM) projections are limited to daily temporal resolution, presenting a data gap that must be addressed to incorporate climate change projections directly into existing commercial tools for power system modeling. This paper presents an innovative approach to create hourly weather timeseries for future climates. A monthly quantile delta mapping technique is used to produce realistic hourly weather data for a future climate by adding the monthly climate change signal projected by climate models to historical weather data. This method preserves important, real-world characteristics from the historical record that are otherwise missing from climate model output, such as locationally specific extremes which can be missing from coarse climate projections, local natural variability which may not be well represented in the climate models, and important joint correlations among physically linked variables such as wind, solar, and temperature. This approach has many potential applications in the power sector, including for capacity expansion and production cost modeling where select hourly timeseries are used for complex optimizations or simulations, as well as for resource adequacy assessments that evaluate large samples of realizations to identify possible extremes for stress-testing a future year of interest."
  },
  {
    "year": "2025",
    "abstract": "This paper provides a detailed review of reliability assessment methods for composite power systems, focusing on integrating renewable energy and advanced computational approaches. The study classifies existing research into three main areas: investigation studies, planning and optimization studies, and efficient evaluation studies. Findings indicate that machine learning techniques are increasingly important in improving accuracy and computational performance in reliability analysis. A comparative examination of conventional and Machine Learning (ML)-based methods demonstrates that deep learning models, such as Convolutional Neural Networks, offer substantial reductions in computational time while maintaining reliability assessment precision. The review also identifies key research gaps, such as the need for realistic test systems and enhanced hybrid ML strategies. Additionally, recommendations are proposed to address these challenges and strengthen the effectiveness of future reliability evaluation methodologies. The insights presented in this study aim to support researchers and industry professionals in developing more efficient and scalable reliability assessment models for evolving power systems."
  },
  {
    "year": "2025",
    "abstract": "Incorrect connection of metallic sheath is a typical defect in long HV(High-Voltage) cross-boned cable systems. However, the previous detection methods based on sheath current rely on three criteria: the amplitude of the sheath current, the ratio of the sheath current to the load current, and the relative values of the sheath current across the three sheath loops. These criteria, however, are insufficient for accurately identifying the defect. In this paper, a CNN (Convolutional Neural Network) based methodology using the sheath current phasor difference at both ends of the same sheath loop is proposed to distinguish the 34 types of incorrect connection with 2 types of correct connection. Taking an 110 kV cable as the simulation case, the results show that the sheath current phasor difference is significantly affected by the unequal lengths of the three small segments of the cable. Besides, the sheath current phasor difference at both ends of the same loop can not only distinguish the correct and incorrect connection states of cross-bonded high-voltage cable sheaths but also differentiate different connection error modes. The classification model for high-voltage cable cross-bonding errors based on CNN can effectively recognize 36 different cross-bonding configurations of high-voltage cables, with a model accuracy of over 98%. Through comparison with other algorithms, it is found that the CNN exhibits the best performance in identifying various cross-bonding error scenarios."
  },
  {
    "year": "2025",
    "abstract": "Power networks have traditionally been designed to withstand credible outages, such as N-1 or N-2, often overlooking the complex interdependencies that can lead to cascading outages in modern systems. To address these evolving risks, planning models must adapt to better anticipate and mitigate cascading outages, while also guiding network expansion and the integration of advanced technologies. This paper presents a methodological framework for optimizing network expansion and battery storage investments to mitigate cascading outages. The framework uses an Optimization via Simulation (OvS) approach that incorporates detailed system failure simulations to assess the effectiveness of various network enhancements, including transmission lines, power transformers, reactive power compensation devices and battery storage units. In addition, a sampling process is used to select the number of trigger outage scenarios to be considered within the OvS approach. The effectiveness of the proposed framework is demonstrated on two test networks: a modified version of the IEEE 24-bus test network and the German transmission network. The main findings demonstrate: (a) that incorporating cascading outages into investment planning leads to different network enhancement decisions compared to conventional planning models (which exclude cascading outages), (b) that an optimal mix of network enhancements can significantly mitigate cascading outages, and (c) the computational scalability of the proposed framework."
  },
  {
    "year": "2025",
    "abstract": "The paper considers the problem of video activity recognition in real-life collaborative classroom learning environments. Video analysis of real-life collaborative classroom learning environments faces significant challenges not encountered in current, advanced video recognition datasets. In collaborative learning environments, students are arranged in small groups where they interact within their group. Video analysis needs to deal with long-term activity recognition (of one hour or more session videos), detect multiple simultaneous activities, rapid transitions between activities, occlusions, and numerous individuals performing similar activities in the background that are not part of the group being analyzed. Developing ground truth datasets for analyzing complex video datasets is prohibitively expensive. We dramatically reduce the requirement for large ground truth datasets by creating separate, custom datasets for object detection and video activity recognition. We then introduce a separable, extremely low-parameter system for video activity recognition that can be optimally trained using the derived datasets without the need for transfer learning from larger systems trained on large datasets. We further develop an interactive WebApp for visualizing the results over long video sessions. Overall, the extremely low-parameter activity classification model uses just 18.7K parameters for each activity, requiring 136.32 MB of memory. On a moderate GPU (RTX 5000), the activity classification model runs at an impressive 4,620 (154×30) frames per second. Our approach uses at least 1,000 fewer parameters than several well-established methods for video recognition. Our extremely low-parameter classifiers can process 90 minutes of video in just 26 seconds. Furthermore, our models are much easier to train, they are much faster, and outperform comparable methods."
  },
  {
    "year": "2025",
    "abstract": "Multi-object tracking (MOT) has been at the center of numerous applications from autonomous vehicles (AVs) to surveillance and even retail analytics. Traditional MOT methods typically rely on motion-based and appearance-based similarity information to associate detections across frames. However, the new transformer attention-based approach to MOT has removed the need for complex post-processing steps, such as graph optimization, allowing for end-to-end query tracking across frames. While the new transformer-based approaches offer many advantages, in the majority of these models the temporal dimension of the sequence is only considered in either the iterative processing of the frames or the memory of the queries. The proposed cross-frame multi-object tracking transformer (CFTforrmer) aims to improve one of the challenging areas of tracking, the association across different frames in the temporal dimension. In the proposed approach, the temporal identities of the frames are included in the positional encoding of the patches. This approach allows the encoder-decoder to track the queries more efficiently across the frames. For this model, scalable deformable-attention layers were used to design the encoder and decoder to decrease the computational cost. CFTformer also employs the proposed attention-based trajectory refinement (ATR) scheme to improve the tracking performance in blurred frames. The three-dimensional positional encoding of the patches helps the proposed ATR module to better capture the trajectories of the queries and generate smoother predictions. Overall, the model was able to achieve 1.7% and 0.6% improvement in the identification F1 score (IDF1) metric on MOT17 and MOT20 datasets while having ~0-15% lower number of identity switches, compared to other transformer-based approaches. More accurate tracking and lower identity switches make this algorithm more suitable to be used in the field of autonomous driving. To access model’s performance in AV applica..."
  },
  {
    "year": "2025",
    "abstract": "This paper describes how user engagement affects users’ trust in audio guide agents to adapt to their environment. Audio guide agents are expected to be used more in the future because they can perform without interrupting the user’s actions. Because agents adapt to their environment and work collaboratively with users, trust in the agent is important. Therefore, we examined whether adaptation itself affects trust and whether intentional user operations as a means of user engagement affect trust. A participant experiment was conducted with two independent variables (the degree of adaptation to ambient noise and the availability of user operation), and the subjective evaluation of the impression of the agent was the dependent variable. For the factor of adaptability, agents with low and high noise-canceling performance were provided. For the factor of user engagement, a volume adjustment function for ambient noise was or was not provided. In an experimental laboratory environment where environmental sounds were controlled, it was verified that users perceive the agent as more intelligent and human-like only when the agent’s adaptation to the environment is low. However, agent adaptation increased trust in the agent, and user engagement also increased trust regardless of the agent’s adaptation level. On the other hand, in a real-world environment, adaptation tended to increase trust, but user engagement did not affect trust. This may be attributed to the impact of cognitive load on users in real environments, which could have hindered participants from operating as intended, even under conditions with operations. In systems where users and agents work collaboratively, the results suggest that intentionally increasing user engagement may increase trust in the agent when users are able to operate appropriately."
  },
  {
    "year": "2025",
    "abstract": "In numerous survival analysis experiments, subjects may experience failure or death due to multiple causes. Whether these causes are dependent or independent, this study delves into the competing risk lifetime model under progressively type-II censoring schemes, where removal events follow a binomial distribution. Specifically, we focus on the generalized power half logistic geometric lifetime failure model in the context of independent causes. We consider the removal of subjects at each failure time according to a binomial distribution with known parameters. Both classical and Bayesian approaches facilitate point- and interval-estimation procedures for parameters and parametric functions. The Bayesian estimate is derived using the Markov Chain Monte Carlo (MCMC) method, incorporating symmetric and asymmetric loss functions. The Metropolis-Hasting algorithm is applied to generate MCMC samples from the posterior density function. A simulated data set is utilized to evaluate the performance of the two estimation approaches under the proposed censoring scheme. In addition, a real dataset is employed for illustrative purposes."
  },
  {
    "year": "2025",
    "abstract": "The Great Wall Construction Algorithm (GWCA) is an innovative meta-heuristic algorithm for solving engineering challenges. Parallel strategies are an effective approach to enhancing the performance of algorithms. In this paper, parallel technology is introduced into GWCA by proposing a new communication strategy named Differential Exchange, which is combined with GWCA to design the Parallel Great Wall Construction Algorithm (PGWCA). The goal is to avoid local optima and improve the algorithm’s performance. The performance of the proposed PGWCA has been critically compared with seven other meta-heuristic algorithms on 10, 30, and 50 dimensions, respectively, using the CEC 2017 benchmark function suite. In addition, the PGWCA algorithm has been used to solve the multilevel image threshold segmentation problem by segmenting eight images and evaluating the segmentation results using three metrics: PSNR, SSIM, and FSIM. The results show that out of 29 test functions, PGWCA achieved the best (minimum) value 17, 20, and 16 times, respectively. In the image threshold segmentation experiments, the best performance was achieved 60 times out of all 72 evaluated comparisons. The experimental results show that PGWCA achieves better performance in identifying the optimal solution and improving the convergence performance, and has good performance in image segmentation. The code is available for download at the following link:https://drive.google.com/drive/folders/1I-5k-IzTP7cUvZqdo7YV-jOz1Zfka42j?usp=sharing"
  },
  {
    "year": "2025",
    "abstract": "With a focus on industrial cyber-physical systems (ICPSs) that are subject to dual-ended denial-of-service (DoS) attacks and actuator faults, and in the context of a double-ended adaptive discrete event-triggered communication scheme (ADETCS), we study the design method of ICPS comprehensive security controller with multi-target constraints. Firstly, a novel double-ended ADETCS is designed to double-screening the transmitted data on both the sensing and execution sides, and a comprehensive security control architecture based on ICPSs with multi-objective constraints that can simultaneously resist dual-ended DoS attacks and actuator failures has been constructed. Secondly, on the sensing side, a method based on integration of data driven and model mechanisms is used to deal with DoS attacks with different levels of severity. On the execution side, a Principal Component Analysis - Long Short-Term Memory (PCA-LSTM) data-driven method is used to reconstruct and compensate the lost data caused by DoS attacks. Thirdly, by introducing multi-target constraints, such asα-stability andH∞performance index, and based on the constructed Lyapunov-Krascovskii function, a cooperative design method is derived for the observer and the comprehensive security controller under multi-target constraints. Finally, the effectiveness and practicability of the proposed method are verified by a simulation experiment involving an industrial four-capacity water tank. The results indicate that the integration method of data driven and model mechanisms enhances the ability of ICPSs to resist dual-ended DoS attacks, and the double-ended ADETCS further saves network communication resources."
  },
  {
    "year": "2025",
    "abstract": "Due to the emergence of computation-intensive and latency-sensitive applications, the Industrial Internet of Things (IIoT) paradigm imposes several new challenges to the Mobile Edge Computing (MEC) platform with minimal compute resources. MEC has emerged as a new paradigm that can enhance the performance of edge services through optimal service execution. As IIoT devices are mostly resource and energy-constrained, therefore it provides several challenges: 1) maximization of resource utilization; 2) minimization of average delay; 3) high throughput required to execute the edge services. To handle such issues, a trust-based distributed resource allocation (TDRA) framework is developed to offer optimal throughput and resource utilization to IIoT-enabled MEC. On the other hand, we set different priorities for edge services based on application types for optimal resource allocation. We formulate the proposed scheme mathematically and analyze the complexity of TDRA. We present extensive experimental results to illustrate the superiority of TDRA compared to existing solutions in the literature with regard to resource utilization, utility, delay, cost, and fairness."
  },
  {
    "year": "2025",
    "abstract": "This study investigates an automatic navigation method for one type of underactuated system, ball-balancing robot (ballbot), in complex environments with both dynamic obstacles and complex-shaped obstacles. To ensure safe operations, which means that ballbot has to avoid obstacles and maintain tilt angles in a desired range, Nonlinear Model Predictive Control (NMPC) is formulated to predict the position and behavior of the ballbot, followed by the optimization problem assisted by Control Barrier Function (CBF) constraints to drive the ballbot in the safe trajectory. Instead of directly implementing tilt angle limitations on the main NMPC, another Quadratic Programming Optimizer based on CBF is designed outside the main controller to reduce the constraint complexity of optimization. An elliptic-bounded generation method is used to simplify the object boundary, especially concave obstacles definition in NMPC constraints, while Extended State Observer is used for observing, compensating the uncertainty terms, and estimating the velocities of the ballbot. In general, by combining this CBF-based NMPC and Quadratic Programming, this research addresses simultaneously high-quality observer, tracking control, balancing control, complex motion planning and safe-angle constraints for the 3D-ballbot system. The effectiveness of our proposed method is determined by simulations in complicated tracking scenarios with static, dynamic and complex-shaped objects."
  },
  {
    "year": "2025",
    "abstract": "This paper presents the development of a Yagi antenna optimized for third-order mode operation within the millimeter-wave (mmWave) spectrum. A third-order mode driven dipole, along with a reflector, is introduced to enhance the antenna’s gain. The rigorous numerical optimization procedure was employed to precisely adjust the dimensions and positions of the driven dipole, director, and reflectors. The optimized Yagi antenna operates within the fifth generation (5G) band at 28 GHz, with a bandwidth of 2.6 GHz. Radiation pattern analysis indicates that the gain of the antenna in this higher resonant mode exceeds that of a conventional Yagi-Uda antenna, achieving a gain of 9.35 dBi at 28 GHz. To further increase the gain and address the path loss challenges in the mmWave spectrum, a near-zero index metamaterial (NZIM) array was integrated. A5×5unit cell array was embedded into the same antenna substrate, positioned in front of the reflector. The metamaterial array was optimized using the trust-region (TR) algorithm, resulting in a significant gain enhancement, reaching 13.8 dBi at 28 GHz while maintaining the operational bandwidth in terms of impedance matching. The antenna was subsequently fabricated and tested, with experimental results demonstrating a strong correlation with the simulated outcomes across all key parameters."
  },
  {
    "year": "2025",
    "abstract": "This paper presents an evaluation of the effectiveness of virtual reality (VR) as a training tool for electricians working in high-risk environments within the energy infrastructure sector. A study was conducted involving 124 participants, divided into four groups, to compare the outcomes of VR-based training, traditional training, and a combination of both methods. The Virtual Electrician Training system, a comprehensive VR platform featuring realistic 3D models and interactive scenarios, was used to simulate real-world tasks. Results indicate that participants who received VR training followed by traditional training demonstrated the highest knowledge retention and skill acquisition, suggesting that VR is an effective introductory training tool. The study also identified challenges such as user discomfort and varying ease of use, highlighting the need for further refinement of VR systems. The findings support the integration of VR into technical training programs, with potential benefits including improved safety, enhanced learning outcomes, and cost savings. This research contributes to the growing body of knowledge on the application of VR in industrial training and offers insights into optimizing training sequences for maximum effectiveness."
  },
  {
    "year": "2025",
    "abstract": "Large-scale media data, such as 3D point cloud videos, have received increasing attention as a key content type for 6G mobile communication services. When delivering large-scale media in real time, it is necessary to transmit high-resolution data to meet the high demands of users. However, frequent retransmissions due to transmission errors may cause various issues across the entire system. Ultra-low latency and ultra-high-speed transmission are critical factors that guarantee high Quality of Experience (QoE) in real-time, large-scale media transmission systems. However, conventional modulation and coding scheme (MCS) selection approaches, which primarily focus on maximizing cell throughput, operate based on a fixed target block error rate without considering user content characteristics or usage environments. Consequently, these approaches face limitations in supporting a wide range of future services with diverse QoE requirements. This study proposes a novel MCS selection scheme that not only considers cell throughput maximization but also ensures retransmission stability for real-time, large-scale media data transmission. The proposed scheme adaptively adjusts the MCS selection thresholds based on user network conditions and feedback information associated with each MCS level. In addition, by enabling the selection of only the essential MCS levels needed for service provision, it maximizes the transmission efficiency while enhancing the reliability of real-time, large-scale media data transmission. Moreover, to address diverse QoE requirements, the proposed scheme is further enhanced through the introduction of a mode-switching mechanism for MCS selection based on service types and user mobility. Finally, the simulation results based on 3D point cloud video transmission demonstrate that the proposed scheme effectively mitigates retransmission issues in large-scale data services with high resolution, thereby enhancing user QoE."
  },
  {
    "year": "2025",
    "abstract": "Support Vector Machine (SVM) is a widely used algorithm for classification, valued for its flexibility with kernels that effectively handle non-linear problems and high-dimensional data. Businesses across industries face challenges in improving customer retention and reducing churn, making predictive models essential for identifying at-risk customers and enhancing revenue. This paper investigates an optimized quantum embedding kernel for SVM (Quantum SVM - QSVM) applied to a public bank customer dataset, featuring variables on customer relationships and churn indicators. While focused on the financial sector, the methodology is broadly applicable for reducing churn and boosting revenue across industries. QSVM performance is compared to SVMs with established kernels, including Radial Basis Function (RBF), linear, polynomial, and sigmoid. Experiments varied the number of variables from two to seven to evaluate their impact on model performance and kernel behavior. The experiments were conducted on quantum simulators, which faced scalability challenges addressed using reduced datasets. Even so, this study sheds light on the potential of QSVMs to effectively manage increasing numbers of variables in predictive models, offering valuable insights into their capability to handle complex, high-dimensional data and their applicability in real-world scenarios."
  },
  {
    "year": "2025",
    "abstract": "The rapid expansion of Bangladesh’s digital economy has unlocked new opportunities for online businesses, but it has also heightened the challenges of delivering high-quality e-services in an increasingly competitive environment. While previous studies have largely focused on customer satisfaction and consumer experiences, the perspective of business owners—those managing daily operations and strategic decisions—has been notably underexplored. Addressing this gap, the present study aims to identify and prioritize the critical success factors (CSFs) influencing the performance of online businesses in Bangladesh from the owners’ viewpoint.A structured survey has been conducted among 57 online business owners, collecting data across ten essential dimensions, including website infrastructure, information sharing, delivery practices, responsiveness, customization, customer service, reliability, payment security, return policies, and service quality challenges. To ensure a data-driven analysis, the Random Forest algorithm is utilized for feature importance extraction, followed by pairwise comparisons through fuzzy triangular matrices. Subsequently, FAHP and TOPSIS techniques are applied to systematically rank the factors and alternatives. Model validation using the XGBoost classifier results in 93% accuracy and a 93% F1-score, demonstrating the robustness of the proposed approach. The results reveal that service quality concerns, payment security, and effective customer support are the most influential determinants of business success. Beyond offering a methodological advancement that integrates machine learning with MCDM, this study delivers actionable insights for business owners, digital strategists, and policymakers aiming to enhance the competitiveness and resilience of Bangladesh’s e-commerce landscape."
  },
  {
    "year": "2025",
    "abstract": "Tree species classification plays a crucial role in forest management, biodiversity conservation, and ecological monitoring. Light detection and ranging (LiDAR) technology, capturing highly detailed 3D structural information of vegetation, has become a powerful tool for automated tree classification. Among LiDAR techniques, terrestrial LiDAR provides high-resolution point-cloud data by scanning trees from the ground level, enabling precise species identification. However, applying deep learning models to LiDAR-based tree classification remains challenging due to the computational complexity of existing 3D architectures, which often struggle with scalability and practical large-scale implementation. To address these critical limitations, we propose ResTreeNet, an efficient and lightweight deep learning model designed explicitly for tree classification using terrestrial LiDAR point clouds. Our innovative approach combines residual networks for hierarchical feature extraction, a height-based grouping strategy to enhance structural representation, and a parameterized geometric transformation module to improve translation invariance and model adaptability. This work integrates explainable artificial intelligence (XAI) techniques, including gradient-weighted class action mapping (Grad-CAM) visualizations, to provide transparent and interpretable insight into the classification reasoning of the model, addressing the critical need for understanding automated decision-making processes. The comprehensive evaluation on a terrestrial LiDAR dataset demonstrates the superior performance of ResTreeNet, achieving a state-of-the-art accuracy of 94.02% on samples with 1024-points, surpassing the existing models by 2.03%. The robust capabilities of the model are further validated by outstanding classification metrics, including precision (94.24%), recall (93.63%), and the F1-score (93.54%), ensuring a balanced and reliable approach to tree species classification. With its lightweight ..."
  },
  {
    "year": "2025",
    "abstract": "Blockchain technology has emerged as a key enabler for achieving the United Nations’ Sustainable Development Goals (SDGs) by offering transparent, decentralized solutions across multiple sectors. However, its inherent transparency introduces significant privacy challenges, particularly in sensitive areas such as healthcare, energy, finance, and supply chains, where confidentiality is critical. To address this tension, this paper explores a range of emerging privacy-preserving techniques, including Ring Signatures, Zero-Knowledge Proofs (ZKPs), Secure Multi-Party Computation (SMPC), Trusted Execution Environments (TEEs), and mixers, analyzing their implementation, effectiveness, and limitations. Furthermore, we conduct a detailed technical study of next-generation blockchain platforms that integrate these techniques to balance privacy, scalability, and interoperability. Our contributions include a deep dive into privacy challenges in blockchain applications for SDGs, a comparative analysis of privacy-preserving solutions, a comprehensive evaluation of emerging platforms, and a review of existing research that leverages these privacy techniques in SDG-related domains. This work aims to provide critical insights into how blockchain technology can be effectively adapted to support sustainable development while safeguarding sensitive data."
  },
  {
    "year": "2025",
    "abstract": "Early screening and intervention for children with autism spectrum disorder (ASD) is crucial for their long-term outcomes and quality of life, and response-to-name (RTN) tests have shown promise in aiding early detection. Leveraging computer vision (CV) and deep learning techniques, this study explores an automatic recognition algorithm for RTN tests based on Residual Network 18 (ResNet18) and Bidirectional Long Short-Term Memory (Bi-LSTM) for enhanced early screening of ASD in children. Using a dataset of 45 RTN cases, including 22 children with ASD and 23 typically developing (TD) children, various deep learning architectures such as Visual Geometry Group 16 (VGG16) and ResNet18 combined with Convolutional Neural Networks (CNN), Gated Recurrent Unit (GRU), and Bi-LSTM were employed to automate RTN test recognition and evaluate algorithm performance. The results revealed that the ResNet18-Bi-LSTM combination achieved the highest efficacy, with a remarkable accuracy of 100%, demonstrating robust stability and accuracy even with small datasets, and holding potential to assist in early ASD screening for children."
  },
  {
    "year": "2025",
    "abstract": "Although hand-pose estimation using external camera systems has made significant progress driven by large annotated datasets, wrist-worn camera-based hand-pose estimation offers unique advantages owing to its ability to capture nearby images. However, datasets primarily collected from multi-angle external systems are unsuitable for wrist-camera-based estimation. To address this gap, we developed LightHand99K, a synthetic dataset comprising 99,792 synthetic RGB hand images designed explicitly for hand-pose estimation using wrist-worn cameras. The dataset was generated using a Unity 3D-based hand image generator optimized to efficiently enhance the performance of hand-pose estimation models for wrist-worn camera images by incorporating human finger joint movement information while minimizing computational cost. This tool allows users to customize their poses, camera angles, backgrounds, lighting, and hand-orientation settings. Incorporating three data augmentation techniques, LightHand99K demonstrated a 36% increase in area under the curve (AUC) and a 6.2-mm reduction in average endpoint error (EPE) compared to existing datasets. These results underscore the value of LightHand99K in advancing hand-pose estimation, particularly in wrist-worn camera applications. The dataset and generation tool are publicly available at (https://github.com/leejeongho3214/LightHand)."
  },
  {
    "year": "2025",
    "abstract": "As semiconductor technology continues to scale, power consumption has become a primary focus of researchers and engineers. In particular, cross-PVT (Process, Voltage, and Temperature) full-chip leakage power estimation is urgently necessary, as it provides crucial guidance for power delivery network design and low-power design strategies and ensures efficient chip design. To address this challenge, we propose an Artificial Neural Network (ANN) model that efficiently integrates data from multiple PVT and provides accurate estimation, given the limited data available for training. This approach enables full-chip leakage power estimation using only one critical cell at one operating state. Our method has been validated using data from a 14 nm industrial FinFET technology node. Compared to the traditional simulation-based method, our method can achieve around 1.76% relative error on average and largely reduced turnaround time, considering all cell types and states. In this case, our method outperforms previous leakage power estimation techniques which fail to provide accurate estimation in low temperature range. When focusing solely on one type of critical cell, the method delivers further acceleration, while maintaining 8.5% maximum relative error."
  },
  {
    "year": "2025",
    "abstract": "Computer vision (CV) is a subfield of computer science that enables machines to perceive, interpret, and understand visual data. It combines image processing, analysis, and machine learning to extract meaningful insights from images and videos. One key application of CV is the classification of gender from handwritten text images-a complex task, especially in languages such as Pashto due to the intricacy of the script and the limited resources. This research presents a novel approach to gender classification using Pashto Handwritten Text Images (PHTI). The study evaluates and compares the performance of traditional machine learning and modern deep learning models: Support Vector Machine (SVM) and You Only Look Once version 8 (YOLO8), a CNN-based object detection framework. The PHTI dataset, introduced in this study, consists of36,086text line images written by 200 male and 200 female native Pashto writers. The goal is to assess how effectively SVM and YOLO8 can classify gender based on visual handwriting patterns in the Pashto language. The experimental results reveal that YOLO8 outperforms SVM in classification accuracy. Although SVM, a widely used machine learning model, achieved an accuracy of 61.29%, YOLO8 reached a significantly higher accuracy of 77% in the same data set. This performance gap highlights the advantages of using advanced deep learning models for complex pattern recognition tasks in CV. This research provides a pioneering contribution by focusing on Pashto, a low-resource language, in the context of gender classification using handwritten text images. It opens new pathways for applying CV in regional languages and supports the development of intelligent systems capable of handling various scripts."
  },
  {
    "year": "2025",
    "abstract": "This study presents a methodology for developing models that replicate the complex pop-up attack maneuver in air combat operations, using flight data from a Brazilian Air Force pilot in a 6-degree-of-freedom flight simulator. By applying imitation learning techniques and comparing three algorithms – Multi-Layer Perceptron (MLP), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) – the research trains models to predict aircraft control inputs through sequences of state-action pairs. The performances of these models were evaluated in terms of Root Mean Squared Error (RMSE), coefficient of determination (R2), training time, and inference time. To further enhance the training dataset with the aim of improving the robustness of the models, a Variational Autoencoder (VAE) was employed to generate synthetic data. These findings demonstrate the potential for deploying such models in fully autonomous aircraft, enhancing autonomous combat systems’ reliability and operational effectiveness in real-world scenarios."
  },
  {
    "year": "2025",
    "abstract": "Aiming at the challenges of high intra-class disparity and low inter-class disparity in fine-grained image classification, a multi-branch fine-grained image classification method based on ConvNeXt network as the backbone and using GradCAM heatmap for cropping and attention erasure is proposed. This method uses GradCAM to obtain the attention heatmap of the network through gradient reflow, locates the region with discriminative features, crops and enlarges the region, and makes the network focus on local deeper features. In addition, supervised contrastive learning is introduced to expand between-class differences and reduce intra-class differences. Finally, a heatmap attention erasure operation is performed to enable the network to focus on other regions useful for classification while focusing on the most discriminative features. The proposed method achieved 91.8%, 94.9%, 94.0% and 94.4% classification accuracy on CUB-200-2011, Stanford Cars, FGVC Aircraft, and Stanford Dogs datasets, respectively, which is better than many mainstream fine-grained image classification methods. And our method proposed in this paper achieves stop-3 and top-1 classification accuracy on the CUB-200-2011 and Stanford Dogs datasets, respectively."
  },
  {
    "year": "2025",
    "abstract": "Embodied conversational agents (ECAs) that can interact with users in a human-like manner have demonstrated promising potential in various endeavors. With the ongoing advancement in extended reality (XR) and artificial intelligence (AI), ECAs are becoming increasingly sophisticated. Although previous reviews have predominantly focused on ECAs for non-XR applications, a growing number of research papers are exploring the capabilities of ECAs that utilize XR technologies. However, no prior systematic review has focused explicitly on XR ECAs, leading to a gap in understanding how ECAs are designed, implemented, and evaluated within immersive environments. Our work identified the gap between the existing reviews and the current trends in XR ECAs. We began with 1,717 related papers from January 2014 to June 2024. We narrowed down the selection to 23 papers using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, which employed an iterative screening procedure and criteria defined by our research team. The resulting papers were analyzed and discussed in terms of the features of the ECA application, its design and implementation, and use cases. Our analysis highlights key trends in XR ECA design, including the dominance of VR-based implementations using head-mounted displays, the prevalence of human-like and female-presenting agents, the move from rule-based to neural-based conversational systems, and the primary use cases in training, therapy, and social interaction. We also summarize the evaluation methods employed across studies and discuss future research directions for developing more adaptive and human-like ECAs in XR environments."
  },
  {
    "year": "2025",
    "abstract": "The Internet of Things (IoT) demands robust mechanisms for secure communication and trust establishment among connected devices. Traditional Public Key Infrastructure (PKI) solutions face limitations in scalability, centralization and single points of failure. These limitations hinder their effectiveness in dynamic IoT environments. To address these challenges, this paper introduces a new decentralized authentication protocol for secure identity management and data exchange in IoT, called ISIF (IOTA-Assisted Self-Sovereign Identity Framework). This framework is based on Self-Sovereign Identity (SSI) principles and leverages Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to enable mutual authentication without relying on centralized authorities. DIDs ensure decentralized identity management and VCs provide verifiable context-specific claims. This dual-layer approach enables robust and attribute-based authentication, which reduces the risk of unauthorized access and improving interoperability in decentralized IoT environments. ISIF employs the IOTA Tangle as a distributed ledger to manage and verify DIDs and VCs. This offers a decentralized, immutable record that supports efficient and tamper-resistant identity management. ISIF ensures that all interactions within the IoT network are securely authenticated and resilient to tampering. The experimental results show that the framework maintains efficient DID generation and VC issuance times even as network size scales, overcoming the bottlenecks inherent in PKI-based systems. Experimental results demonstrate that ISIF maintains efficient DID generation and VC issuance, even as network size scales. Experimental results show that DID generation time increases from 1.85 ms (for 50 nodes) to 10.81 ms (for 250 nodes), while VC issuance time ranges from 2.66 ms to 13.21 ms. Similarly, VC verification time increases from 3.54 ms to 22.27 ms as the network scales. Despite these increases, the overall end-to-en..."
  },
  {
    "year": "2025",
    "abstract": "Domestic fires (residential and indoor) result in substantially higher deaths compared to other types of conflagrations, making early detection crucial to minimizing the loss of life and property. Existing studies and datasets predominantly focus on wildfire detection, with few datasets that capture the complexity of indoor environments and the subtle characteristics of early-stage fires. This gap causes object detection algorithms to produce high false positive and false negative rates in research on the early detection of such fires. To address this, we developed a domestic-fire dataset and proposed YOLO-HF, an early home-fire detection model based on YOLOv5s. To enhance the detection performance for small flames and smoke in a fire’s early stages, we proposed the parametric boosted channel attention (PBCA) mechanism. PBCA fuses global information and adaptively adjusts weights, improving the model’s ability to select and represent key features with minimal parameter overhead. Additionally, we incorporated the RepNCSPELAN4 feature extraction module, which preserves and leverages multi-scale feature information through multi-stage convolution and multi-layer feature fusion. To mitigate information loss caused by the stride setting in traditional downsampling methods, we employed space-to-depth (SPD) downsampling, which retains more spatial details. The experimental results demonstrate that YOLO-HF achieves a 4.6% improvement in Recall, 2.8% in mAP50, and 4.2% in mAP50-95 compared to existing models, all while maintaining its lightweight design. The model size is 13.8 MB, and its frame rate of 66.9 fps, meets real-time detection requirements. Detection experiments using content captured with domestic cameras validated the model’s generalization capability and robustness."
  },
  {
    "year": "2025",
    "abstract": "Light electric vehicles (LEVs) offer environmentally friendly solutions to challenges in sustainable transport, zero emissions, noise reduction, and parking. Among the various motor types, interior permanent magnet synchronous motors (IPMSMs) are the most commonly used in LEVs with belt-drive systems due to their high-power density and efficiency. The main disadvantages of IPMSMs are torque ripple, which can cause noise and vibration, and the cost and availability of the permanent magnets (PMs), which are particularly crucial for LEVs. In this study, the requirements and dimensions of the IPMSM have been determined through analytical analyses and experimental studies of the motor used in a commercial two-wheeled LEV. Electromagnetic analyses were performed to evaluate four magnet configurations—V-shape, U-shape, double V-shape, and double I-shape—leading to the selection of the double I-shape arrangement for its superior performance. Optimization studies, guided by defined cost functions, were then carried out using ANSYS OptiSlang to enhance the motor’s design and overall efficiency. The designed IPMSM achieved a 1.4% improvement in efficiency compared to the commercially used motor, with an expanded high-efficiency operating region on the efficiency map and a 2% reduction in torque ripple. Additionally, the motor cost was reduced by 13% through a 22% increase in reluctance torque and a 12% decrease in magnet quantity. Thus, the cost of this cargo-purpose LEV, which is sold in thousands of units per year, has been reduced by 2.7%, while its range has been increased by 2.3% using the WLTC Class-1 drive cycle through the expanded efficiency map. In addition, compared to the delta-type reference PM rotor geometry, the double-I structure enhances manufacturability while maintaining comparable thermal performance."
  },
  {
    "year": "2025",
    "abstract": "We propose a multi-period multi-product location-inventory model considering an (R, s, S) periodic review policy and modular stochastic capacity constraints. The objective is to define which regional warehouses to open, maintain, operate, or close, which products to assign, and which customers should be supplied by the chosen distribution centers. Additionally, it involves setting order sizes and reorder points to minimize system costs while meeting service level conditions. This problem is structured as a non-convex mixed integer nonlinear programming model. We propose a Lagrangian relaxation algorithm and the subgradient approach as a solution method. We relax the customer allocation, distribution center variance, and demand constraints. Then, the relaxed problem is decomposed into location subproblems for each warehouse, in which inventory subproblems are embedded. So, each location subproblem is discomposed for each period and exactly solved through dynamic programming. Computational experiments prove that the presented approach gives solutions close to optimal and low gaps in a low computational time. Additionally, it exhibits meaningful incidences in the decisions on inventory control policy, facility location decisions, total costs, and risk pooling effects for different review intervals."
  },
  {
    "year": "2025",
    "abstract": "The field of Cyber-Physical Industrial Internet of Things (CPS-IIoT) is rapidly developing, raising significant concerns about cyber-attacks due to the susceptibility of its devices and networking protocols. A breach in one device can compromise the entire system, necessitating robust security solutions. Existing methods fail to address the diversity and compatibility of CPS-IIoT environments. In this research, we propose a new privacy-preservation via Pearson correlation coefficient and agglomerative clustering with Bidirectional long short-term memory (BiLSTM) integrated with a scaled dot-product attention for cyber-attacks detection in CPS-IIoT. The inclusion of agglomerative clustering and scaled dot product attention mechanism in our proposed system is a unique characteristic, specifically tailored for CPS-IIoT contexts. These mechanisms adaptively modify their emphasis to prioritize crucial features within the CPS-IIoT network traffic data, providing additional computational resources to data segments that are likely to include abnormalities and patterns that indicate security issues. We evaluated the performance of our proposed model by conducting experiments on two relevant datasets: UNSW-NB15, and a novel IIoT dataset named X-IIoTID. The X-IIoTID is a versatile intrusion data designed to accommodate the diversity and compatibility of Industrial IoT systems, regardless of their connectivity and device specifications. The data encompasses the actions of emerging IIoT connectivity protocols, recent device activities, a range of attack types and situations, as well as multiple attack protocols. We used a CPS-IIoT testbed that emulates a real industrial facility to demonstrate our proof of concept. Our system exhibits outstanding performance attaining 99.60% of accuracy, 100% of AUC, 97.98% of recall, 100% of precision, F1 of 98.23%, kappa of 96.07%, and Mathew correlation coefficient of 96.54% on UNSW-NB15. On the representative and realistic X-IIoTID data, our..."
  },
  {
    "year": "2025",
    "abstract": "Efficient deployment of deep learning models on resource-constrained devices requires balancing accuracy with energy consumption and/or latency. Quantization is a proven method to achieve this balance by reducing the precision of neural network weights and activations. However, simply changing the precision does not enable direct iso-accuracy and iso-energy comparisons. To address this, we combine a realistic processor energy model with a network filter multiplier that scales the number of channels, thereby enabling such comparisons. This work presents a Pareto-Optimal Quantization (POQ) methodology aimed at mapping a neural network architecture to a specific hardware platform while systematically exploring the design space in between to identify the most effective quantization strategy. Our approach evaluates how different design choices impact the accuracy-energy trade-off. Using detailed energy modeling instead of proxy metrics, our results reveal that 8-bit integer (int8) quantization is Pareto-Optimal for MobileNetV2, providing up to2.8×energy savings or 10% higher accuracy compared to 16-bit floating-point (fp16). Furthermore, employing high-precision residuals shifts the Pareto frontier, making 4-bit integer (int4) quantization optimal, achieving up to1.9×additional energy reduction or 2% additional accuracy gains. Moreover, our findings emphasize the role of DRAM energy in certain model configurations and highlight the importance of precise energy modeling. These results reflect the application of our POQ methodology to the practical deployment of energy-efficient deep learning models on constrained hardware."
  },
  {
    "year": "2025",
    "abstract": "Software defect prediction, leveraging machine learning techniques to proactively identify potential defects in software systems, plays a crucial role in enhancing software quality and reliability. However, a major challenge in this field lies in the opacity of the prediction process and the lack of interpretability of the results, which significantly limits its practical application. To address this issue, this paper introduces eXplainable Neural Additive Models (XNAMs). The proposed model constructs single-feature inputs for software defect data, enabling transparent visualization of the impact of individual features on prediction outcomes. Additionally, it employs feature gradient analysis to examine the average absolute values of feature gradients during forward propagation, thereby quantifying and comparing the contribution of each feature to the decision-making process. Furthermore, feature interaction analysis is conducted to uncover nonlinear interactions between different features. Experimental evaluations on six software projects demonstrate that XNAMs outperform existing models in prediction performance while offering clear explanations of feature contributions, ensuring high transparency and practical applicability."
  },
  {
    "year": "2025",
    "abstract": "Insulated Rail Joints (IRJs) are among the critical elements of railway infrastructure, providing structural continuity and electrical isolation within track systems. These joints play a very important role in the detection of trains and in operational safety by segmenting rail networks into electrically isolated sections. Although being a critical part, IRJs suffer from degradation due to high mechanical loads, electrical discharges, and repeated stress. One significant form of localized damage is spark erosion. If left unaddressed, such defects may lead to severe operational failures and safety risks, making effective monitoring systems essential. This paper presents a deep learning-based approach for automatic detection of spark erosion in IRJs. The proposed methodology is based on a two-stage framework: in the first stage, the SqueezeNet convolutional neural network is used for the classification of rail images and the detection of IRJs. In the second stage, a semantic segmentation network is applied to accurately localize and detect spark erosion regions in the detected IRJ images. The study uses two different data sets: one is a high-resolution rail image data set for IRJ classification, and the other labeled images of spark erosion. In addition, advanced image preprocessing and augmentation techniques are adopted to deal with class imbalance and enhance model robustness. Experimental results prove the effectiveness of the proposed method, which achieves 98.1% accuracy in IRJ classification and accurate segmentation of spark erosion areas. These findings underline the potential of two-stage deep learning frameworks to provide real-time, automated, and highly accurate monitoring solutions for railway maintenance. The proposed methodology contributes to enhancing the safety, efficiency, and reliability of railway operations by allowing the early detection of critical defects."
  },
  {
    "year": "2025",
    "abstract": "Dialogue-to-video retrieval is an interesting while challenging task, which exploits an AI agent to retrieve the video that matches and aligns with the conversational context between users. In particular, given a history of dialogue exchanges, the agent is expected to identify the most fitting video content that complements the ongoing conversation. The computational complexity posed by the processing of videos within deep neural networks encourages us to adapt CLIP, a cutting-edge large multi-modal models (LLMs), into the dialogue-video domain. On this basis, we propose a multi-grained attention network (MGAT), integrating query-scoring, dual-softmax and query-bank normalization techniques. We design a multi-grained attention module to optimize the inadequate modeling of conversation semantics in existing pre-trained models, dynamically assign weights during conversation feature extraction, and introduce conversation context features in multimodal alignment. Most importantly, fine-grained similarity by per-round query-frame scoring and coarse-grained similarity by high-level semantics of all rounds of dialogues for each video are respectively calculated, which are further learned via multi-grained attention mechanism. This approach effectively transfers CLIP’s text-image multimodal knowledge into the dialogue-video retrieval system, alleviating the need for resource-intensive and costly fine-tuning dialogue-video procedures. Extensive experiments on multiple datasets demonstrate that our method outperforms state-of-the-art approaches."
  },
  {
    "year": "2025",
    "abstract": "Recently, many studies have proposed knowledge distillation (KD) frameworks for object detection. However, these frameworks did not take into account the inefficiencies caused by the teacher detector. The inefficiency refers to the computational cost incurred during the process of passing input data to the teacher model to acquire its knowledge. To solve this inefficiency in image classification, Fast Knowledge Distillation (FKD) was proposed, which stores the teacher model’s knowledge in advance and then uses it in the distillation process. However, directly applying FKD’s knowledge storage mechanism to dense object detectors causes a storage space problem. To address this issue, we propose NMS-KSD, a novel knowledge storage distillation method designed for dense object detection tasks. The core of NMS-KSD is the integration of Non-Maximum Suppression (NMS) and channel max pooling to effectively select and store key features from the teacher model’s intermediate feature maps. By storing and reusing these key features, NMS-KSD addresses the inefficiencies of traditional KD frameworks, significantly reducing training time while maintaining high performance. We validate the effectiveness and efficiency of our method across various dense object detectors through extensive experiments on the COCO, PASCAL VOC, and Cityscapes datasets."
  },
  {
    "year": "2025",
    "abstract": "With the pervasive integration of artificial intelligence (AI) in various facets of modern technology, the importance of AI security has been thrust into the spotlight. The field is rapidly evolving, with new challenges and solutions emerging at a swift pace. However, the breadth and depth of AI security research have not been comprehensively mapped in recent times, presenting a crucial need for an extensive review and synthesis of existing literature. Given the increasing reliance on AI in critical domains such as healthcare, finance, and national security, ensuring the resilience and trustworthiness of these systems is imperative. This survey fulfills the pressing need for a structured and comprehensive overview of the current research landscape, enabling researchers to address emerging threats and vulnerabilities effectively. This paper presents a systematic mapping study (SMS), aimed at identifying and classifying the prevailing research topics, tools, and frameworks in the field of AI security. A total of 123 studies were meticulously selected and analyzed, leading to the identification of key metrics, tools, standards, and research themes that are currently shaping the landscape of AI security research. This effort not only aids in distilling the collective wisdom of the research community but also sets a firm foundation for future work in this critical area. The findings from this SMS will serve as an invaluable guide for researchers and practitioners alike, enabling them to navigate the complexities of AI security and fostering the development of innovative, robust security solutions. This study also highlights significant gaps in the current literature, thereby outlining potential directions for new research initiatives."
  },
  {
    "year": "2025",
    "abstract": "Industry 4.0 (I4.0) has impacted different areas of organizations in various ways. In Occupational Health and Safety (OHS), I4.0 technologies can benefit organizations and their employees when implemented to improve working conditions and reduce occupational accidents and illnesses. Smart technologies can be used to identify and monitor risks in real time, enabling immediate implementation of corrective actions to prevent accidents. This article aims to propose drivers with recommendations for the development and improvement of OHS in organizations through I4.0 technologies. To this end, we conducted content analysis of scientific articles and reviews selected from the Scopus database. We identified forty-one boosting elements and systematized them into six drivers based on the scientific literature. These drivers contain practical recommendations that help organizations improve OHS, reduce workplace accidents, and improve employee working conditions. This work contributes to enhancing the safety conditions in organizations through I4.0 technologies. It also contributes to advancing knowledge in this area, supporting new research related to OHS and I4.0."
  },
  {
    "year": "2025",
    "abstract": "We consider the problem of inferring the conditional independence graph (CIG) of high-dimensional Gaussian vectors from multi-attribute data. Most existing methods for graph estimation are based on single-attribute models where one associates a scalar random variable with each node. In multi-attribute graphical models, each node represents a random vector. In this paper we provide a unified theoretical analysis of multi-attribute graph learning using a penalized log-likelihood objective function. We consider both convex (sparse-group lasso) and sparse-group non-convex (log-sum and smoothly clipped absolute deviation (SCAD) penalties) penalty/regularization functions. An alternating direction method of multipliers (ADMM) approach coupled with local linear approximation to non-convex penalties is presented for optimization of the objective function. For non-convex penalties, theoretical analysis establishing local consistency in support recovery, local convexity and precision matrix estimation in high-dimensional settings is provided under two sets of sufficient conditions: with and without some irrepresentability conditions. We illustrate our approaches using both synthetic and real-data numerical examples. In the synthetic data examples the sparse-group log-sum penalized objective function significantly outperformed the lasso penalized as well as SCAD penalized objective functions withF1-score and Hamming distance as performance metrics."
  },
  {
    "year": "2025",
    "abstract": "This paper addresses the problem of no reference visual quality assessment in point clouds, useful for extended reality communication service such as remote surgery and education. Accurate, computationally efficient metrics for point cloud visual quality are needed, but the literature lacks a unified view of the signal attributes associated with psycho-visual features of point clouds. We propose a method to estimate point cloud visual quality by jointly assessing geometry and color noise in areas critical to visual perception. Our approach introduces a novel descriptor that identifies visual degradation through variations in local color and normal components. This descriptor, along with its saliency-weighted variant, leverages Non-Euclidean Laplacian Filtering (NEUF). The NEUF algorithm extracts descriptors using advanced non-Euclidean filtering techniques and employs regression learning to predict end-users’ perceived subjective quality by optimally selecting the most relevant features. We show by simulations that the NEUF approach mixing non Euclidean filtering with data-driven learning is effective on various point cloud categories, including human, non-human, natural, and synthetic. The NEUF-based method for point cloud quality estimation outperforms existing methods, offering a no-reference quality estimator that can be used for the design of cutting-edge extended reality services."
  },
  {
    "year": "2025",
    "abstract": "Road surface pothole detection is crucial for ensuring the driving safety and path planning of autonomous vehicles. However, existing detection methods are often affected by variations in lighting, weather conditions, and complex environments, resulting in lower detection precision and recall rates. To address this, this paper proposes an innovative improved algorithm, which is based on the YOLOv8 model, and introduces the MSF-HFEB module in the innovative design. By cleverly blending the strengths of Convolutional Neural Network (CNN) and the Transformer architecture, the algorithm accomplishes multi-scale feature extraction and fusion for both local and global aspects of road potholes. This design significantly improves the robustness of the algorithm under different lighting and complex environmental conditions. Additionally, the algorithm incorporates the LSKA attention mechanism and an integrated MHSA_CGLU module. By utilizing large-scale convolutional kernels for weighted feature screening, it further enhances the capability of multi-scale feature extraction and the richness of nonlinear feature representation. Experiments on public datasets have validated the effectiveness of our approach: compared to the original YOLOv8 model, the detection precision and recall rate of our algorithm have been improved by 9.8% and 11.6% respectively, and the F1 score has reached 84.9%. The outcomes of this research not only enhance the driving safety and comfort of autonomous vehicles in complex environments but also offer robust technical support for obstacle avoidance and path planning in self-driving vehicles."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a comprehensive performance analysis and optimization of ultra-dense Internet-of-Things (IoT) networks. While the high density of Bluetooth Low Energy (BLE) devices in IoT networks improves wireless coverage and enhances connectivity, these coexisting devices can also lead to increased interference and collisions, degrading device discovery performance and increasing the network’s overall latency. In this work, we provide a mathematical analysis of the discovery latency in densely deployed BLE networks. Our mathematical model constructs a Markov chain model that implements the impacts of packet collisions and duplication on discovery latency. Based on a thorough performance analysis, we propose a novel duplication-avoidance protocol in which BLE devices cooperatively adjust advertising and minimize the network’s overall discovery latency. Our simulation results shows that the proposed novel duplication-avoidance protocol consistently reduces latency compared to the standard discovery protocol in densely deployed BLE networks, with relative improvements ranging from 7.63% to 8.16%."
  },
  {
    "year": "2025",
    "abstract": "Visual information plays a crucial role during the final approach and landing phases of an aircraft, serving as a complementary source for the navigation system. It provides additional guidance when radio navigation such as Instrument Landing System is unserviceable or compromised and enables a fully vision-based landing. The relative position and orientation of an aircraft can be derived from the features of the runway captured in images. However, conventional methods for detecting runways often suffer from high latency and low accuracy, making them inadequate and uncertain for ensuring a safe landing. In response to these limitations, this paper introduces a real-time runway detection model named Vision-based Landing System for Fixed-Winged Aircraft (VLS-FWA), which leverages deep convolutional neural networks in cascade. Moreover, predicted variance is also calculated and displayed in the pilot’s Head-Up Display (HUD) by employing methods to aid in the reduction of aleatoric and epistemic uncertainty in both real-world and synthetic scenes."
  },
  {
    "year": "2025",
    "abstract": "Live-streaming e-commerce has achieved significant growth by combining live interactive broadcasts with online shopping, with platform revenues largely depending on a small number of top-tier streamers. However, this dependence grants these top-tier streamers excessive bargaining power and makes platforms vulnerable to their negative impacts. To address this issue, this study aims to provide strategy recommendations for live-streaming e-commerce platform managers to reduce reliance on top-tier streamers. We achieve this goal by constructing a social evolutionary game model (SEGINE). This model utilizes real-world data from Chinese social media and live-streaming e-commerce platforms to simulate the diffusion process of live-streamed product information within social networks and analyzes the impact of different “de-emphasize top-tier streamers” strategies on information dissemination. By integrating the characteristics of live-streaming platforms and social networks, we consider the effects of indirect network externalities on evolutionary game dynamics, thereby providing a basis for platform managers to formulate relevant decisions. The experimental results show that appropriately limiting the influence of top-tier streamers may help build a healthier and more sustainable live-streaming e-commerce ecosystem. The novelty of this study lies in its first-time application of a social evolutionary game model to analyze the interaction between live-streaming e-commerce platforms and social networks, and to explore the potential impacts of strategies that de-emphasize top-tier streamers."
  },
  {
    "year": "2025",
    "abstract": "In the above article [1], reference 24 was retracted. As the work in this reference is no longer reliable, we are removing it from the reference list and replacing it with [2]."
  },
  {
    "year": "2025",
    "abstract": "This research outlines the significance of semi-supervised machine learning (SSML) in dealing with the intricate characteristics of electrical machines. SSML provides a key benefit in enhancing the effectiveness and precision of predictive models for optimizing electrical machine performance, reliability, and maintenance by leveraging labeled and unlabeled data. The research investigates important SSML algorithms such as self-training, co-training, generative models, and graph-based methods, highlighting their particular uses in fault diagnosis, condition monitoring, and predictive maintenance of electrical machines. Moreover, the document discusses the specific difficulties associated with this merger and offers remedies to improve the utilization of SSML in this significant area. A detailed table summarizes various methods and emphasizes their role in furthering machine learning within the realm of electrical machines."
  },
  {
    "year": "2025",
    "abstract": "Hydro power generation is one of the most viable renewable sources to meet future energy demand and being a synchronous source, it has also the capability to enhance power system stability. Low frequency oscillations in power grid poses several challenges to operators and need to be damped at earlier stage to maintain stability of power system. The hydro turbine governors usually impart negative damping to these oscillations. So, there can be modification in governor control action to impart damping for these oscillations. In present work the hydro governors are phase compensated and coordinated with dual static synchronous compensator (STATCOM) so as to provide sufficient damping torque. A state space model of dual STATCOM with compensated hydro governor has been developed. Sudden change in reference voltage, uncertain solar and wind penetrations with plug-in electric vehicle as load being considered with different experimentations to impart critical oscillations in power system and proposed controller has been employed to damp these oscillations. Multimachine two area four hydro generators, 39 bus systems with 10 generators and modified IEEE 68 bus system with sixteen generators at different operating conditions have been investigated with proposed controller for oscillation damping. A new multi-objective mean Differential Evolution with time varying accelerated Particle Swarm Optimization algorithm (MeDETVAPSO) has been implemented to tune controller parameters. The proposed controller shows less values of settling time, oscillations peak value and imparting high damping ratio. Settling time, oscillation peak value and minimum damping ratio with proposed controller have been observed as 1.638s, 0.000375pu and 0.987 respectively. These experimentations have been conducted in MATLAB Simulink and verified with real time simulation based on OPAL-RT 4510. The damping capability of proposed controller has been found to be better in contrast to power system stabilizer (..."
  },
  {
    "year": "2025",
    "abstract": "Multi-user edge computing (MEC) is a network architecture that enables cloud computing capabilities at the edge of a network, reducing latency and user equipment’s energy consumption. An MEC system that can efficiently supports both the ultra-Reliable Low Latency Communication (uRLLC) and enhanced Mobile Broadband (eMBB) services is crucial in providing a diverse and efficient communication for various Internet of Things (IoT) applications. The current MEC models in literature are either deterministic or based on average-based metric hence, not suitable in a practical scenario where task offloading and computation activities are stochastic processes and, the wireless channel is often not interference-free. In this paper, we study the joint task offloading and computation in a mixed traffic of two 5G-based MEC. We consider user equipment (UE) that are cognitive radio enabled and, whose performance are energy constrained. In view of this, energy efficient MEC is formulated as a stochastic optimization with long-term objective while, taking into consideration the tail distribution of the eMBB queue length. The target is to minimize energy consumption and, maximize the achievable data rate subject to probabilistic and statistical constraint on the eMBB task length based on Extreme Value Theorem (EVT), uRLLC reliability and, system capacity. The performance of the proposed MEC model is studied in terms of the latency, energy consumption, user density, and reliability. Finally, we demonstrate numerical results to prove the superior effectiveness in the performance of our proposed model over the existing model."
  },
  {
    "year": "2025",
    "abstract": "Discontinuous pulse width modulation (DPWM) is useful to improve the efficiency of a single-phase five-level T-type neutral-point-clamped (5LT-NPC) inverter and the reliability of the power devices. However, depending on how it is applied, the thermal loading imbalance between the two legs of the 5LT-NPC inverter occurs, which results in a reduction in the reliability improvement effect in the power devices by the DPWM. Furthermore, the DPWM strategy should be equipped with the ability to balance the neutral point voltage since the imbalance between the voltages of the two capacitors leads to the distortion of the output current and also the failure of the DC-link capacitor and power devices if its voltage is over the rated value. This paper proposes a Thermally Balanced DPWM (TB-DPWM) method with neutral point voltage balancing capability for the 5LT-NPC. Through the proposed method, the thermal loading balancing between the two legs can be achieved simply without consideration of the power factor. Furthermore, it is also able to balance the neutral point voltage while maintaining the DPWM. The effectiveness and feasibility of the proposed method are verified through the simulations and experiments."
  },
  {
    "year": "2025",
    "abstract": "Software Modeling Languages (MLs) are essential tools in the fields of systems analysis and documentation, as well as in facilitating communication among stakeholders involved in software development. However, the sheer variety of available MLs presents a significant challenge for software designers in selecting the most suitable language to model a specific problem or situation. To address this issue, this study introduces CLUPIR, a classification model designed to organize and catalog MLs based on a comprehensive set of aspects. The development of CLUPIR involved conducting a systematic mapping of the existing literature on classification models with a particular focus on the classification aspects used by these models. This thorough analysis informed the selection of the aspects for the CLUPIR model. To demonstrate its practical applications, eight distinct MLs were classified using the CLUPIR framework. Additionally, the model’s effectiveness and relevance were validated through a study involving 30 software industry professionals. These participants provided insight into the utility and applicability of CLUPIR in real-world scenarios. Ultimately, this research contributes to streamlining the process of selecting appropriate MLs for software design by offering a structured aspect-driven classification approach tailored to industry needs."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel iterative gradient-based optimization approach aimed at achieving more precise and streamlined approximations for the Gaussian Q function—an essential element in communication system’s design. Our optimization strategy involves determining optimal weights for exponential functions within a defined range of the argument (x) of the Gaussian Q function. The primary goal is to iteratively minimize the error or cost function, progressively refining local minima across successive iterations. The results strikingly highlight the exceptional accuracy of our proposed approach in approximating the Gaussian Q function, positioning it as a robust contender for real-world communication system’s design. Importantly, our method showcases a clear superiority in accuracy over prevailing techniques. Moreover, to comprehensively evaluate the efficacy of our approach, we simplify the key metrics like symbol error probability (SEP) of various coherent digital modulation techniques over a versatile multi-cluster fluctuating two-ray fading model, which includes majority of the classical fading models like Rayleigh, Nakagami-m,q, Rician, Rician-shadowed, fluctuating two-wave, two-wave with diffused power, etc. As an application example, the numerical results of the SEP of square quadrature amplitude modulation (SQAM) are validated against the exact results obtained via MATHEMATICA software package. In addition, a comparative analysis on the time required to compute the exact and proposed SEP values is also highlighted in this paper. The asymptotic SEP is also derived which gives an idea on the diversity order of the system. Lastly, extensive Monte-Carlo simulations have also been carried out to validate the proposed work."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a novel wideband circularly polarized (CP) cavity-backed slot antenna based on Substrate Integrated Waveguide (SIW) technology, designed for compact and high-efficiency performance. The proposed antenna utilizes a hexagonal SIW cavity to simultaneously excite two closely spaced resonant modes (TM110and TM210), resulting in enhanced bandwidth for linear polarization (LP). To achieve circular polarization, a passive, single-layer linear-to-circular polarization converter is integrated above the cavity, offering a structurally simple and PCB-compatible solution. Unlike conventional CP designs that rely on complex feeding networks or multilayered structures, this configuration maintains a planar profile and efficient performance. A fabricated prototype demonstrates strong agreement between simulation and measurement, achieving a peak gain of 9.2 dBic and a 14% axial ratio (AR) bandwidth. These results highlight the antenna’s suitability for modern wireless systems requiring wideband CP functionality, including satellite communications, 5G modules, and compact embedded devices."
  },
  {
    "year": "2025",
    "abstract": "With the rapid development of the new energy industry, accurate prediction of the service life of lithium batteries as core energy storage components is of great significance for optimizing energy configuration and reducing operation and maintenance costs. Traditional prediction methods are difficult to accurately capture their dynamic characteristics. The research aims to utilize the powerful learning ability of hybrid neural networks to achieve accurate prediction of the service life of lithium batteries. The study first analyzed the application of existing neural network models in predicting the service life of lithium batteries. By comparing the predictive performance of these models, a new hybrid neural network model was proposed, which combines the advantages of convolutional neural networks (CNN) in feature extraction and long short-term memory networks (LSTM) in processing time-series data, while introducing the advantages of other neural network structures to improve the predictive ability of the model. The experimental results show that the hybrid neural network model proposed in this study performs well in predicting the inflection point of lithium battery remaining life. Compared with existing models, this model not only improves prediction accuracy, but also significantly enhances prediction stability."
  },
  {
    "year": "2025",
    "abstract": "Machine learning (ML) practitioners are always in pursuit of refined data to develop robust and generalizable ML models to solve real-world problems. However, most real-world datasets are noisy, imbalanced, and contain redundant samples, prompting the need to address these problems before the datasets are processed by ML models. Among other factors, redundant samples are becoming a greater challenge in ML development due to advancements in data-capturing tools (sensors, wearable devices, etc.). Redundant samples can increase computing and storage requirements while minimally contributing to predictive performance, necessitating their removal before the training phase. However, removing redundant samples without degrading predictive performance from ML models is challenging because it requires deep analysis of all the data and the correlations among features. In this paper, we propose a dominant pattern and Hamming distance-based sampling scheme to prune redundant samples from the data without degrading predictive performance. Specifically, we reduce the data size by a reasonable margin while maintaining predictive performance similar to or better than the original data with reduced training time. Our sampling scheme has five key steps: data pre-processing, dominant pattern extraction by exploiting correlations between features, Hamming distance-based data classification into diverse and less diverse parts, data clustering for redundant-sample pruning from less diverse parts, and fine-tuning/synthesizing the final data. The key objective is to curate compact, diverse, and high-fidelity data that accurately preserves the characteristics of original data while solving accuracy-versus-time trade-offs. Experiments are performed on benchmark datasets of binary nature using diverse ML classifiers, and predictive performance, data properties, and computing time are compared with original data and prior data reduction schemes. From the experiments and analysis, our scheme yi..."
  },
  {
    "year": "2025",
    "abstract": "The human ether-a-go-go-related (hERG) gene is crucial in enabling the regulation of repolarisation process in the heart. Some chemicals act as hERG blockers, resulting in prolonged QT intervals. Predicting the binding capability of molecules with hERG channels is expected to reduce the burden of cardiotoxicity testing in drug evaluation. The application of machine learning (ML) and deep learning (DL) models in the field of toxicity has gained burgeoning interest. The current study utilises state-of-the-art ML and DL models for predicting the hERG-blocking ability of chemical compounds using a dataset of 8337 molecules. It is noted that spatial relationships within molecules are crucial in predicting hERG blockers. While the threshold for blockers is defined as≤10μM and for non-blockers, it is>10μM, our analysis indicates that a threshold of 60-80μM provides a more accurate cut-off for non-blockers. This adjustment highlights the importance of concentration levels in reflecting the variability specific to individual interaction sites. The algorithm results show that the internal validation performance of RF, XGBoost, and MLP is strong, with AUC scores of 0.90, 0.90, and 0.87, respectively. In summary, the current study provides a machine learning framework for computation cardiotoxicity assessment by analysis of the hERG blocker concentration cut-offs using different fingerprints at multiple thresholds."
  },
  {
    "year": "2025",
    "abstract": "Software systems are essential in modern life and require rigorous testing to ensure reliability. Pairwise testing, a combinatorial testing methodology, optimizes test case generation by minimizing redundancy while maintaining defect detection effectiveness. This review systematically examines the role of metaheuristic algorithms in pairwise test case generation, focusing on their exploration and exploitation mechanisms to address local optima challenges. Covering research from 2014 to 2024, the review evaluates hybrid and metaheuristic strategies, including Pairwise Migrating Birds Optimization-Based Strategies (PMBOS), Pairwise Gravitational Search Algorithm Strategy (PGSAS), Pairwise hybrid Artificial Bee Colony (PhABC), Genetic and Particle Swarm Optimization (GAPSO) algorithm, Hybrid Optimization Algorithm (HOA), and Parameter Free Choice Function based Hyper-Heuristic (PCFHH), among others. These methods consistently outperform traditional techniques by reducing test suite sizes and enhancing fault detection capabilities. The findings underscore the growing adoption of the one-test-at-a-time (OTAT) approach over the one-parameter-at-a-time (OPAT) approach and identify key challenges in scalability, hyperparameter tuning, and constraint handling, highlighting the need for hybrid strategies and adaptive optimization techniques. This review offers valuable insights into advancing Software testing methodologies and presents recommendations for future research to improve efficiency, scalability, and fault detection in pairwise testing."
  },
  {
    "year": "2025",
    "abstract": "This article presents the measurement of stripe density using image processing. The two essential techniques are a digital grid overlay on the target image to create a moiré pattern and a moving average filter to remove the high-frequency components of the moiré pattern image. The moving average filter produces a low-frequency signal whose frequency is equal to the difference between the frequency (density) of the target stripes image and the frequency of the overlaid grid stripes. We use a method where grid lines are drawn with a lower density on the left side and progressively increase in density towards the right, surpassing the target stripe density. When superimposed on the target image, if the frequency of the grid stripes matches the frequency of the target stripes, the moving average filter will produce an output signal with a frequency equal to zero. An automatic stripe density measurement system is achieved by detecting situations where the frequency value of the output signal from the moving average filter equals zero. The results of measuring the density of simulated stripes created with the program for densities ranging from 30-180 per unit length (L−1) and the number of threads of the fabric on six images showed that the system could measure the actual values consistently, with an error of less than ±1 L−1."
  },
  {
    "year": "2025",
    "abstract": "Post-Training Quantization (PTQ) has been effectively compressing neural networks into very few bits using a limited calibration dataset. Various quantization methods utilizing second-order error have been proposed and demonstrated good performance. However, at extremely low bits, the increase in quantization error is significant, hindering optimal performance. Previous second-order error-based PTQ methods relied solely on quantization scale values and weight rounding for quantization. We introduce a weight-activation product scaling method that, when used alongside weight rounding and scale value adjustments, effectively reduces quantization error even at very low bits. The proposed method compensates for the errors resulting from quantization, thereby achieving results closer to the original model. Additionally, the method effectively reduces the potential increase in computational and memory complexity through channel-wise grouping, shifting, and channel mixing techniques. Our method is validated on various CNNs, and extended to ViT and object detection models, showing strong generalization across architectures. We conducted tests on various CNN-based models to affirm the superiority of our proposed quantization scheme. Our proposed approach enhances accuracy in 2/4-bit quantization with less than 1.5% computational overhead, and hardware-level simulation confirms its suitability for real-time deplo1yment with negligible latency increase. Furthermore, hardware-level simulation on a silicon-proven ASIC NPU confirms that our method achieves higher accuracy with negligible latency overhead, making it practical for real-time edge deployment."
  },
  {
    "year": "2025",
    "abstract": "Integrating Deep Learning (DL) into abdominal imaging represents a significant leap forward in diagnosing and managing abdominal conditions, offering the potential to transform conventional medical practices. This comprehensive survey explores the application of DL techniques, such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Generative Adversarial Networks (GAN), across various domains of abdominal imaging, including liver, spleen, kidney, and other structures such as subcutaneous adipose tissue (SAT), muscle, viscera, and bone. It discusses the critical role of performance metrics in evaluating model efficacy and clinical applicability. Furthermore, the paper highlights emerging trends in DL, such as integrating multimodal data and exploring unsupervised and semi-supervised learning techniques, which promise to address current limitations and pave the way for future advancements. Ethical considerations, including algorithmic bias, transparency in model development, and equitable patient care, are thoroughly examined to underscore the importance of ethical practices in deploying Artificial Intelligence (AI) technologies in healthcare."
  },
  {
    "year": "2025",
    "abstract": "MEMS (Micro-Electro-Mechanical System) hydrophone, with the advantages of low cost, low power consumption, and miniaturization, has rapid development and wide application in acoustic detection. The complexity of the marine environment and the development of underwater equipment have proposed higher requirements for the performance of MEMS hydrophones. However, the sensor performance of MEMS hydrophones is affected by multiple factors, such as structure, principle, and MEMS processing technology. Many novel MEMS hydrophones with new principles, new structures, and new materials have been established to improve the sensitivity and bandwidth of MEMS hydrophones. In this study, MEMS hydrophones are divided into optical MEMS hydrophones, electrical MEMS hydrophones, and thermal MEMS hydrophones according to the principle used. Additionally, the basic working principles of different MEMS hydrophones are summarized, and the characteristics of MEMS hydrophones with different principles are analyzed. Furthermore, the advantages and disadvantages of different materials and structures are compared regarding the tested performance parameters. The contribution of this study lies in systematically reviewing the development process of three types of MEMS hydrophones, especially the development and improvement of piezoresistive, hot-wire, and interferometric MEMS hydrophones, involving the research hotspots and latest progress. Finally, the characteristics of MEMS hydrophone development are demonstrated, the existing problems are discussed, and the future development trend is prospected."
  },
  {
    "year": "2025",
    "abstract": "Port congestion and prolonged ship waiting times pose challenges for global trade and increase operational costs and inefficiencies. In this study, a novel machine learning-based predictive approach was proposed to improve port operations by accurately forecasting vessel waiting times. By using a dataset of 121,401 voyage records, we evaluated nine regression models, including conventional, ensemble-based, and deep learning models. Shapley additive explanation (SHAP)-based feature selection is typically applied to enhance interpretability, and its effect is compared with principal component analysis-based dimensionality reduction and nonselection methods. The XGBoost Regressor (XGBR) is optimized using genetic-algorithm-based hyperparameter tuning, reducing mean squared error (RMSE) from 20.9531 to 19.6387, mean absolute error (MAE) from 13.6821 to 12.6753, and improving coefficient of determination (R2) from 0.2791 to 0.2949. A stacking ensemble model, integrating random forest regressor, XGBR, LightGBM regressor, and CatBoost regressor, improves performance, achieving an RMSE of 18.9023, MAE of 12.3287, and an R2 of 0.3265. ANOVA tests confirm numerous differences in model performance and computational complexity. The results demonstrated that tree-based ensemble models outperform deep learning models in this setting. The proposed approach enables proactive scheduling, reduces congestion, and cost savings. The scalability of the model renders it suitable for broad maritime logistics and intelligent transportation systems."
  },
  {
    "year": "2025",
    "abstract": "Usability is a key factor for successfully integrating new technology to aid an operator in production. It is measured using three metrics: efficiency (productivity), effectiveness (quality), and user satisfaction. One prominent technology for operator support is augmented reality (AR), which is mostly handheld or head-mounted. A human-centered approach is required to align the AR integration with the operator’s capabilities. The underlying use case in this study is an energy dashboard visualized using AR and non-AR media, namely, a monitor, tablet, and HoloLens. The resulting media applications were evaluated for usability in terms of efficiency, effectiveness, and satisfaction in the within-study experiments by 16 participants. Overall, the results showed increased efficiency and satisfaction for traditional-monitor users and increased effectiveness for tablet users. Despite the participants’ lack of experience with AR, the AR applications performed comparably to the monitor and even slightly better in some aspects. With the ongoing development of AR software and hardware, AR can become increasingly useful for machine monitoring in production. However, to use AR for more comprehensive tasks, its strengths and weaknesses must be considered."
  },
  {
    "year": "2025",
    "abstract": "Mobile video viewing on popular platforms such as YouTube and Netflix is widespread, yet the role of specific viewing interactions in shaping user engagement remains underexamined. This study investigates how skipping behaviors (including their types and directions) and playback speed adjustments relate to user engagement, with a focus on video abandonment and user satisfaction. We developed a custom mobile web application for video viewing and collected viewing logs and self-reports from 25 participants during two 10-day field studies. Our findings reveal that different skip types and directions are associated with distinct engagement outcomes. For example, scrubbing often correlates with higher abandonment, whereas backward skips may indicate greater engagement. Playback speed adjustments can signify deeper involvement, allowing users to tailor their viewing speeds without missing key content. Notably, video abandonment did not always equate with dissatisfaction; some users left after meeting their immediate viewing goals. These insights suggest that users’ playback interactions may serve as indicators of user engagement and can be incorporated into video recommendation systems to enhance user satisfaction. We conclude by discussing the design implications of enhancing user satisfaction."
  },
  {
    "year": "2025",
    "abstract": "Scene text segmentation is to predict pixel-wise text regions from an image, enabling in-image text editing or removal. One of the primary challenges is to remove noises including non-text regions and predict intricate text boundaries. To deal with that, traditional approaches utilize a text detection or recognition module explicitly. However, they are likely to highlight noise around the text. Because they did not sufficiently consider the boundaries of text, they fail to accurately predict the fine details of text. In this paper, we introduce leveraging text signed distance function (SDF) map, which encodes distance information from text boundaries, in scene text segmentation to explicitly provide text boundary information. By spatial cross attention mechanism, we encode the text-attended feature from the text SDF map. Then, both visual and text-attended features are utilized to decode the text segmentation map. Our approach not only mitigates confusion between text and complex backgrounds by eliminating false positives such as logos and texture blobs located far from the text, but also effectively captures fine details of complex text patterns by leveraging text boundary information. Extensive experiments demonstrate that leveraging text SDF map in scene text segmentation provides superior performances on various scene text segmentation datasets."
  },
  {
    "year": "2025",
    "abstract": "In the Korean font market, a wide variety of new fonts with diverse designs are continuously being developed, making the selection of appropriate fonts crucial for effective information delivery. However, there has been no standardized method to systematically define and quantify the structural characteristics of Korean fonts. As a result, analyzing the morphological features of fonts in a quantitative manner and using this information for classification or comparison has remained a challenge. PANOSE is a system that quantifies the visual characteristics of fonts, enabling structured classification and similarity evaluation. While it effectively organizes and compares fonts, it was primarily designed for English scripts, failing to fully capture the unique typographic properties of Korean fonts. To address this limitation, this study defines the key morphological elements of Korean fonts and develops an algorithm, K-PANOSE (Korean font PANOSE), to measure them. Based on prior research, we first established key structural attributes of Korean fonts, such as character composition, stroke thickness, and proportional balance. We then designed an algorithm to quantitatively assess these attributes. Finally, we validated that K-PANOSE performs at a comparable level to the existing PANOSE system, demonstrating its ability to effectively analyze and classify Korean fonts. K-PANOSE is not merely a tool for font selection; rather, it introduces a new standard for quantifying and systematically analyzing the structural characteristics of Korean fonts. This advancement enables broader applications, including font recommendation systems, digital typography, and AI-driven design automation, ultimately contributing to the quality, accessibility, and diversity of Korean typography."
  },
  {
    "year": "2025",
    "abstract": "Twisted stacked-tape conductors (TSTC) have emerged as promising candidates for next-generation high-temperature superconducting (HTS) cables, addressing the challenges of high-current and low-loss operation in high-field applications such as fusion magnets and power systems. This paper presents a rigorous electromagnetic analysis of TSTC and STC cables, integrating advanced numerical modeling with experimental validation to address critical challenges in the physical understanding of their superconducting current distribution and AC loss prediction. For this, a magneto-angular anisotropy model tailored to GdBCO tapes is reported, which accurately captures theJcdependencies on field magnitude and orientation when adequate ansatz for the 3D modelling of the twisted tapes geometry, and no constant in-field direction conditions, are both considered. We validate the model against recent experimental measurements on eight TSTC prototypes, comprising straight and twisted stacks of up to six tapes under sinusoidal magnetic fields (15–100 mT). The simulations achieve deviations of less than 5%, demonstrating exceptional fidelity in predicting magnetization losses and resolving current density distributions across tape thickness. The results highlight the critical role of twisting geometries in reducing magnetization losses while maintaining current-carrying performance, demonstrating the potential of TSTC designs for scalable, low-loss superconducting cables. Furthermore, the developed model provides a robust tool for optimizing conductor architecture, extending from single tapes to multi-tape architectures, and provides critical physical and computational insights into the interplay between geometric design and energy loss mechanisms. These findings establish a robust foundation for optimizing TSTC cables and similar HTS architectures, like the VIPER conductor, advancing their readiness for deployment in fusion energy, power transmission, and large-scale scientifi..."
  },
  {
    "year": "2025",
    "abstract": "In this study, we expand on a previously introduced method for computing the error statistics associated with estimating the time of arrival of a known signal in sampled data with additive white Gaussian noise (AWGN). When matched filtering techniques are used to localize sampled signals, there is a probability of error, which takes the form of a sample index offset from the true time of arrival. This method allows us to fully calculate the probability mass function for the estimation error, which at lower signal to noise ratios (SNR) does not fit a Gaussian shape and depends heavily on the shape of the signal being detected. We show that the method can be extended to work on cases involving complex signals, interpolated signals, and signals that undergo pre-filtering steps. In addition, we demonstrate that the same method can be used to characterize frequency of arrival error probabilities, and the joint estimation of frequency and time of arrival."
  },
  {
    "year": "2025",
    "abstract": "Respiratory sounds serve as early indicators of lung diseases. The development of computer-aided classification systems has become a key enabler for timely diagnosis and treatment. The technology has improved basic services, particularly in resource-limited urban settings. We proposed an advanced hybrid dual-input model tailored for the intelligent classification of respiratory sounds. In this model, we employed Mel-spectrograms and waveform representations as feature extraction methods, utilizing the strengths of multiple modalities to enhance model performance. The classification framework integrates the Squeeze-and-Excitation (SE) attention mechanism into the ResNet architecture to construct the Bi-SEResNet model and adopts the Data-Efficient Image Transformer (DeiT) as the final classification layer. Model performance is evaluated using the SPR-Sound dataset, which includes two classification tasks: a 2-category classification of respiratory sound events into Normal and Abnormal, and a 7-category classification involving Normal, Rhonchi, Wheeze, Stridor, Coarse Crackle, Fine Crackle, and Wheeze & Crackle. Performance was assessed using sensitivity (SE), specificity (SP), average score (AS), and harmonic score (HS) as a composite score. The proposed framework achieved scores of 89.26 and 83.63 for 2-category classification and 7-category classification tasks, respectively."
  },
  {
    "year": "2025",
    "abstract": "Sector coupling (SC) has recently emerged as a solution to alleviate the curtailment caused by surplus power from variable renewable energy sources. Power-to-heat (P2H) is considered an economically viable SC approach that utilizes commercially available technologies. Previous studies demonstrated that electric water heaters and heat-pump water heaters (HPWH) effectively manage the demand and enhance flexibility. However, the practical implementation of P2H has been limited owing to policy limitations. This study proposed a P2H implementation model for South Korea that utilizes existing HPWHs deployed under the midnight power service, with a focus on flexibility provision through a reverse demand response (DR) program. The flexibility provision effect, energy efficiency, and economic impact were analyzed to evaluate the feasibility of the model. The case study results indicated that flexibility provision up to 100% of the device capacity was achievable, participation in the reverse DR program reduced power consumption by 4.4%, and operation costs decreased by 6–17% based on the DR scenarios."
  },
  {
    "year": "2025",
    "abstract": "Vehicular Edge Computing (VEC) is a critical enabler for intelligent transportation systems (ITS). It provides low-latency and energy-efficient services by offloading computation to the network edge. Effective edge server placement is essential for optimizing system performance, particularly in dynamic vehicular environments characterized by mobility and variability. The Edge Server Placement Problem (ESPP) addresses the challenge of minimizing latency and energy consumption while ensuring scalability and adaptability in real-world scenarios. This paper proposes a framework to solve the ESPP using real-world vehicular mobility traces to simulate realistic conditions. To achieve optimal server placement, we evaluate the effectiveness of several advanced evolutionary algorithms. These include the Genetic Algorithm (GA), Non-dominated Sorting Genetic Algorithm II (NSGA-II), Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO), and Teaching-Learning-Based Optimization (TLBO). Each algorithm is analyzed for its ability to optimize multiple objectives under varying network conditions. Our results show that ACO performs the best, producing well-distributed pareto-optimal solutions and balancing trade-offs effectively. GA and PSO exhibit faster convergence and better energy efficiency, making them suitable for scenarios requiring rapid decisions. The proposed framework is validated through extensive simulations and compared with state-of-the-art methods. It consistently outperforms them in reducing latency and energy consumption. This study provides actionable insights into algorithm selection and deployment strategies for VEC, addressing mobility, scalability, and resource optimization challenges. The findings contribute to the development of robust, scalable VEC infrastructures, enabling the efficient implementation of next-generation ITS applications."
  },
  {
    "year": "2025",
    "abstract": "5G New Radio wireless networks based on the International Mobile Telecommunications specifications are fundamental for current mobile communications. This work focuses on the performance analysis of a private 5G network in an experimental and controlled environment. For this purpose, exhaustive experimentation considering 192 combinations of factors has been proposed and carried out in a controlled environment within a semi-anechoic and semi-reverberant chamber. This enables accurate observation of the impact of the studied factors on a series of Key Performance Indicators that are fundamental in 5G networks, such as latency, throughput, and reliability. This dataset has been analyzed using statistical algorithms such as Principal Component Analysis and SHapley Additive ExPlanations. The results show how network performance can be affected not only by the environment, but also by its configuration. Furthermore, the configurations contribute differently depending on the indicator, showing that these can be improved without an excessive impact on other indicators: (i) throughput improves by more than 26% by modifying parameters such as bandwidth, duplexing method, or number of antennas; (ii) latency improves over 7% by modifying the duplexing method or 12% by switching between radio access technologies; (iii) reliability is exceptionally high in controlled environments. Our study shows that reliability can achieve improvements of up to 196.5% in terms of lost and retransmitted packets. The insights found in this work, based on the proposed configurations and their respective improvements, can be extrapolated to proposed use cases for 5G networks."
  },
  {
    "year": "2025",
    "abstract": "Accurate measurement of bladder volume is critical for the effective management of urinary diseases. Among the available modalities, ultrasound imaging is favored due to its cost-effectiveness, non-ionizing nature, and capability to provide real-time bladder volume measurements. To enhance convenience in clinical practice, ultrasound bladder scanners have been developed and adopted in various settings. However, wobbling probe devices present significant limitations, including their inability to provide real-time images, the requirement for pre-scan alignment to ensure precise probe positioning, and the necessity for multiple volume estimations to achieve measurement accuracy. Additionally, conventional image-based estimations utilizing standard ultrasound machines or recently developed bladder scanners face challenges related to the use of shape coefficients. These methods typically rely on two image planes, which fail to fully capture the bladder’s shape, resulting in considerable errors in volume estimation when compensating for shape with coefficients. To overcome these limitations, this study proposes a novel automated bladder volume measurement technique that employs a T-shaped cross-array ultrasound probe in conjunction with free-hand motion-based 3D reconstruction. The T-shaped cross-array enables the simultaneous acquisition of sagittal and transverse view images of the bladder. By moving the probe at the suprapubic region, continuously acquired sagittal images can be combined into a 3D volume, with motion compensation achieved via the transverse images. Consequently, the proposed method can accurately reconstruct the entire bladder and measure its volume without the need for shape correction coefficients, while also reducing errors associated with ultrasound probe positioning. The proposed methodology was validated through phantom experiments simulating both spherical and irregular bladder shapes. The results demonstrated an error rate ranging from -8.8% to..."
  },
  {
    "year": "2025",
    "abstract": "This study explores the application of Artificial Intelligence (AI) in predicting electromagnetic field (EMF) exposure levels in urban environments. Machine Learning (ML) and Deep Learning (DL) models were developed to estimate the electric field (E, in V/m) at specific locations without requiring direct measurements. Measurements were conducted in Thessaloniki, Greece, covering a diverse urban landscape, including commercial and residential areas. The methodology involved collecting EMF data using high-precision equipment, validating and refining publicly available datasets, and extracting key features using Geographic Information System (GIS) tools. Essential input features included distances to the nearest base stations, their installation heights, classification of base stations regarding their emitted power, number of obstructing buildings, built area density, and line-of-sight (LOS) conditions. The AI models demonstrated strong predictive performance, with mean absolute errors (MAE) slightly above 0.3 V/m. The study highlights the importance of proper data preprocessing, feature selection, and integration of real-world measurements into AI-based prediction models. The results suggest that AI can serve as a reliable alternative for EMF exposure assessment, potentially reducing the need for costly and time-consuming field measurements while ensuring compliance with safety regulations."
  },
  {
    "year": "2025",
    "abstract": "The fifth generation (5G) mobile network is designed to facilitate high data rates with massive connectivity with the benefit of small cell technology. The cloud radio access network (C-RAN) is a promising mobile network architecture that can meet the ever-increasing resource demand of a growing number of users. In C-RAN, base station functionalities are separated into baseband units (BBUs) and remote radio heads (RRHs), with BBUs centralized and virtualized via cloud computing. However, this architecture introduces new challenges in efficiently allocating resources to dynamic users. This paper aims to design a resource allocation scheme that improves system efficiency and satisfies dynamic user demands in C-RAN. We propose a hybrid resource allocation approach that combines centralized control and multi-agent-based decision-making. The centralized controller, located within the BBU pool, collaborates with virtual base stations (VBSs) acting as multi-agent system (MAS) agents. The resource allocation solution is derived by jointly considering the real-time resource requests from agents and the historical demand estimates generated by the centralized controller. Through simulation-based evaluation, we compare our proposed scheme with conventional random and fixed resource allocation methods. The results demonstrate improved performance in terms of resource utilization, reduced unfulfilled demand, and fairness among VBS agents. The proposed combined resource allocation strategy effectively meets dynamic user requirements while maintaining system efficiency in C-RAN. Our work highlights the importance of integrating historical demand trends with real-time agent requests for improved long-term resource planning."
  },
  {
    "year": "2025",
    "abstract": "The goal of infrared and visible image fusion is to generate a fused image that integrates both prominent targets and fine textures. However, many existing fusion algorithms overly emphasize visual quality and traditional statistical evaluation metrics while neglecting the requirements of real-world applications, especially in high-level vision tasks. To address this issue, this paper proposes a semantic segmentation-driven image fusion framework based on knowledge distillation. By incorporating a distributed structure of teacher and student networks, the framework leverages knowledge distillation to reduce network complexity, ensuring that the fused images are not only visually enhanced but also well-suited for downstream high-level vision tasks. Additionally, the introduction of two discriminators further optimizes the overall quality of the fused images, while the integration of a semantic segmentation module ensures that the fused images provide valuable support for advanced vision tasks. To enhance both fusion performance and segmentation capability, this paper proposes a joint training strategy that enables the fusion and segmentation networks to mutually improve during training. Experimental results on three public datasets demonstrate that the proposed method outperforms nine state-of-the-art fusion approaches in terms of visual quality, evaluation metrics, and semantic segmentation performance. Finally, ablation studies on the segmentation network further validate the effectiveness of the proposed method."
  },
  {
    "year": "2025",
    "abstract": "This article presents a framework for optimizing cable-driven parallel manipulators (CPMs) in deep-sea environments, addressing factors as failure tolerance, stiffness, and workspace within a unified framework. While previous studies have examined these factors individually, few have integrated them into a unified framework. The presented framework evaluates CPMs with six, eight, and ten cables, using inverse kinematics, optimization, and stiffness analysis. The six-cable framework is fully constrained, whereas the eight-cable and ten-cable systems are over-constrained, providing additional redundancy in failure scenarios. Post-failure tensions are maintained within safe bounds, defined by mechanical load ratings and operational safety margins. Results indicate that increasing the number of cables improves workspace coverage, enhances stiffness, and reduces post-failure tensions. The ten-cable configuration, in particular, increases operational volume by approximately 20% and reduces peak post-failure tensions by around 15% compared to the six-cable baseline. Our framework also considers adaptive positioning strategies to improve system performance under varying ocean conditions. Future work will analyze the effects of wave-induced motions on system stability and develop sensor-based failure-detection techniques to enhance real-time failure mitigation and system robustness in dynamic environments."
  },
  {
    "year": "2025",
    "abstract": "RPL (Routing Protocol for Low-Power and Lossy Networks) is a standardized routing protocol of IoT proposed by IETF (Internet Engineering Task Force) Working Group. The escalating surge of cyberattacks targeting IoT systems has exposed critical security vulnerabilities in RPL-based networks. Attackers exploit routing spoofing, resource depletion tactics, and topology manipulation strategies, while inherent constraints of resource-limited devices and scalability challenges in mass deployments amplify these risks. This critical security gap therefore necessitates the deployment of lightweight IDS (Intrusion Detection Systems) to achieve real-time anomaly detection and monitoring However, the current IDS for RPL-based IoT has certain limitations such as routing attacks dataset lack coverage of a sufficient variety of routing attacks and detection methods involve significant computational overhead. To address these problems, we have conducted the following research work. First, a novel routing attacks dataset that covers four RPL routing attack types is constructed through simulation on the Cooja IoT platform. And we develop feature extraction algorithms for dataset to extract 24 features implementing in IDS model training. Second, we propose an efficient routing detection method that accelerates model training speed by using Hybrid Pearson Correlation and GS-PSO(Grid Search-Particle Swarm Optimization) Optimized Random Forest Technique. The Pearson correlation can effectively extract key data features for different routing attacks. And the hybrid GS-PSO algorithm can optimize the hyperparameters of IDS model and enhance the accuracy of the detection mechanism while significantly reducing computational overhead. Finally, we demonstrate our IDS model has higher detection accuracy and lower computation time compared to other existing models through simulation experiments."
  },
  {
    "year": "2025",
    "abstract": "This study addresses the discomfort and challenges posed by traditional electrooculography (EOG) measurement methods that require skin-contact electrodes by developing a non-contact EOG signal measurement device. The primary objective of this research is to implement a hierarchical deep learning model for classifying data collected from a non-contact EOG device into five types of eye movements. In this study, indium tin oxide (ITO) film was employed as a capacitive coupled electrode to measure EOG signals without skin contact. A hierarchical classification model based on a 1D convolutional neural network (CNN) was proposed for signal analysis, and K-fold cross-validation was used to train and validate the model. Unlike conventional Ag/AgCl electrodes, the proposed device enables EOG signal measurement without direct skin contact. ITO film was integrated into glasses to create non-contact electrodes while minimizing signal noise. Additionally, various signal feature extraction methods, including Fast Fourier Transform (FFT), Band Power, and Hilbert-Huang Transform, were applied to enhance classification accuracy. The model using the FFT method achieved 73% accuracy in Step 1 classification, with 84% accuracy for vertical channels and 81% for horizontal channels in Step 2. The Band Power method yielded 59% accuracy in Step 1, with 62% accuracy for vertical channels and 90% for horizontal channels in Step 2. The Hilbert-Huang Transform method produced 68% accuracy in Step 1, with 63% for vertical channels and 66% for horizontal channels in Step 2. The proposed non-contact EOG measurement system demonstrated improved usability and performance over traditional methods. It is expected to achieve practical applications in human-computer interaction (HCI) systems for patients with neurological disorders."
  },
  {
    "year": "2025",
    "abstract": "The design and analysis of a compact broadband antenna supporting the long-term evolution (LTE) bands 41/42/43/46/48/52 and the sub-6 GHz bands N46/N77/N78/N79, Bluetooth, and Wi-Fi are presented. The proposed antenna consists of a 50-ohm microstrip feedline, a Yagi-shaped patch radiator, and a partial ground plane under the feedline. The slot-loading technique is employed to achieve a wide band of operation and to minimize the overall size of the antenna. Using the low-loss dielectric material substrate, Rogers RO4003C, the form factor of the antenna is appreciably reduced to26×17×0.813mm3 without compromising the performance result of the antenna. The finite element method-based high-frequency electromagnetic solver from ANSYS Corporation is used to simulate and optimize the antenna. A prototype of the designed antenna is fabricated and measured to verify its performance. It is observed that in the operating impedance bandwidth from 2.44 GHz to 5.74 GHz (voltage standing wave ratio <2), a wide bandwidth of 3.3 GHz with a fractional bandwidth of 80.68% is achieved. In addition, the antenna exhibits an omnidirectional radiation pattern with an acceptable average gain level of 2 dBi over the whole operating bandwidth."
  },
  {
    "year": "2025",
    "abstract": "For individuals who are blind or have low vision, tactile maps provide essential spatial information but are limited in the amount of data they can convey. Digitally augmented tactile maps enhance these capabilities with audio feedback, thereby combining the tactile feedback provided by the map with an audio description of the touched elements. In this context, we explore an embodied interaction paradigm to augment tactile maps with conversational interaction based on Large Language Models, thus enabling users to obtain answers to arbitrary questions regarding the map. We analyze the types of questions the users are interested in asking, engineer the Large Language Model’s prompt to provide reliable answers, and study the resulting system with a set of 10 participants, evaluating how the users interact with the system, its usability, and user experience."
  },
  {
    "year": "2025",
    "abstract": "The integration and consideration of communication networks in energy system studies is of critical importance due to the mutual dependencies that exist between the systems. These interdependencies have an impact on the overall performance, stability, and robustness of the energy system. There is no comprehensive guide or overview for integrating communication into power system applications, despite its recognized importance and the wide variety of existing solutions that take into account interdependencies. By providing a detailed overview, characterization, and classification of existing approaches to communication modeling, this paper contributes to filling this gap in existing guidelines or general descriptions for the integration of communication in power system applications. In addition to discussing the multiple objectives associated with different focus for modeling communication, we consider the required data and system perspectives. Therefore, this paper provides guidance on the selection of a suitable and applicable communication modeling approach, given the specific objective and prerequisite."
  },
  {
    "year": "2025",
    "abstract": "Semantic segmentation of ultrasonic images is a crucial and challenging task in computer vision in AI-assisted medicine. In prevailing methods, each pixel in the image is treated equally while ignoring the fact that border pixels contain more critical information. This limitation reduces segmentation performance and may result in irregular and ambiguous segmentation results, even under high-quality manual labels. To address this issue, we propose a novel boundary enhancement scheme that improves segmentation accuracy by incorporating a complementary decoder structure (Bor-decoder). This dual-decoder scheme simultaneously predicts both the target area and its border in ultrasonic images, with feature fusion between these two decoders to boost overall performance. Our approach automatically generates border labels from segmentation mask annotations without requiring additional manual border annotations. Experimental results show that the two baseline models enhanced with our boundary enhancement scheme outperform state-of-the-art methods, achieving the highest Dice scores on three datasets: TN3k 86.41% (85.45% without Bor-decoder), DDTI 82.97% (82.54%), and FLUIS 83.82% (82.43%). Furthermore, our method significantly improves the detection of small and multiple targets in ultrasound images, enhancing clinical diagnostic accuracy and supporting more reliable medical assessment."
  },
  {
    "year": "2025",
    "abstract": "Computational imaging (CI) techniques realized by dynamic metasurface antennas (DMAs) offer significant advantages in the hardware design reducing the cost of such systems. In this paper, we present a physical layout based solely on DMA panels that can be used to synthesize electrically large apertures suitable for microwave imaging. Although hardware is significantly simplified, the challenge of using CI DMA-based systems presents itself in the signal processing layer. This is because in microwave CI the transfer function of the antennas is used to encode information from the imaged target scene and compress it into a single (or a few) channel(s). As a consequence, real-time Fourier-based image reconstruction algorithms cannot be directly applied because of the nature of the compressed back-scattered signals. In this work, we propose an algorithm that employs a decompression step such that the signal is converted to a suitable form for spatial frequency domain processing. The proposed technique mitigates the challenges of applying the algorithm in the near-field. Crucially, it also eliminates the need for a computationally expensive Stolt interpolation step, which can be a significant bottleneck for conventional Fourier-based image reconstruction algorithms. Numerical and experimental CI results are presented to validate the ability of the proposed system and algorithm to produce reconstructed images of good quality. The benefits of the proposed algorithm in terms of execution time and storage requirements are also explored in this work."
  },
  {
    "year": "2025",
    "abstract": "In a dynamic environment with mountains and hazardous peaks, avoiding collisions and maintaining the desired formation is a crucial problem. This paper addresses this problem by presenting a novel formation control strategy of a cluster of UAVs in three different scenarios. The first scenario is designed to test the designed algorithm and hence contains no obstacles. The second scenario introduces some obstacles in the form of mountains to see whether the proposed algorithm can avoid the obstacles while maintaining the formation. In the last scenario, all the UAVs join together in one big cluster and have to avoid the obstacles while maintaining the formation. To design the environment for the scenarios, this study uses graph theory. To address the aforementioned scenarios, this paper offers a novel strategy by integrating a bio-inspired algorithm called the Adaptive Ruminant Optimization Algorithm (AROA) with the Long Range (LoRa) communication to achieve the formation control of multiple UAVs. Initially, AROA offers the best agents of each of the swarm. Then, the proposed method helps choose the best agent to be the leader for each of the swarm. The leader of each swarm finds the best trajectory for each swarm. LoRa-based networking technique is used for the connectivity between the UAVs. In addition, this study uses basis splines (B-splines) to smooth the planned trajectories of UAVs. Lastly, simulations demonstrate the better convergence and efficiency of the designed strategy by comparing it with classic algorithms. The simulations also show that the proposed method successfully maintains formation control in all three scenarios."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes new fault-tolerant (FT) space-vector modulation (SVM) techniques for three-level T-type inverter (3L-T2I) to balance neutral-point voltage (NPV) under faulty conditions. Unlike conventional FT-SVM methods, which use three-nearest vectors to synthesize output voltages, the proposed SVM methods add one small vector to conventional switching sequences to obtain NPV balance. Dwell-time of extra vectors are maximized to decrease NPV balanced time. Comparing to conventional FT-SVM methods, the proposed approaches can significantly reduce the difference in capacitor voltages. As a result, the amplitudes of DC component and high-order harmonics of output currents are also reduced. Consequently, the quality of output current is improved. Experimental results, which are conducted by a 1.1-kVA laboratory prototype, are presented to verify the effectiveness of the proposed FT methods. Comparison studies based on experimental results are also presented to demonstrate the advantages of NPV balance of the proposed method compared to conventional FT methods."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a circuit architecture aiming for FPGA synthesis of a processing stage of an Automatic Target Recognition (ATR) algorithm to classify non-cooperative targets in Synthetic Aperture Radar (SAR) images using the SAMPLE database. A reference algorithm in Python was used to determine whether the mathematical operations performed by the architecture are correct, comparing the results between different processing phases, such as the determination of the equivalence of coordinates between the target and the models (i.e., coordinates “matching”), partial calculations of the mean squared error, and the final result of the operations. The architecture was described in VHDL and synthesized for the Bajie Board development system with an FPGA XC7Z010-1CL400C. For a dataset of 50 coordinate points, the algorithm’s execution time in Python decreased from 4 milliseconds to approximately30μs in the synthesized system. Similarly, for a larger dataset of 400 coordinate points, the reduction was from 184 ms to 1.9 ms."
  },
  {
    "year": "2025",
    "abstract": "Air temperature is an extremely important factor in agriculture, from planting to post-harvest processes, and having the ability to predict air temperature can be a valuable tool for avoiding damage, maximizing production quality, and optimizing resources. In this work, we propose a simple air temperature prediction model based on a small neural network with a relatively small volume of training data. This work uses data from the Climatology and Biogeography Laboratory of the University of São Paulo (USP), from the Experimental Meteorological Station in São Paulo City, Brazil. The dataset corresponds to air temperature data collected during the years 2018 and 2020. For machine learning, two types of artificial neural networks were adopted: one of the long short-term memory recurrent network and one feed-forward network. Three past air temperatures were used to predict the next hour’s air temperature, and chain predictions were used to predict up to 24 hours. The feed-forward neural network presented the best results, with most errors below 2°C. The results show that it is possible to use a simple neural network, using only air temperature as the meteorological variable, to predict air temperature for the next hours. The simplicity of the model makes its application more feasible for various problems in agriculture."
  },
  {
    "year": "2025",
    "abstract": "This article introduces the design of a multi-coupling feed antenna (MCFA) appropriate for 4G LTE, 5G NR (sub-6 GHz), and WLAN frequency bands. Most antenna designs used in different consumer electronic products only include specific 5G NR frequency bands, while the MCFA antenna proposed in this article covers applications in multiple frequency bands and will meet the needs of more communication devices. MCFA is designed on an FR-4 substrate and uses the coupled-feed structure to achieve diverse operating frequencies. This article also uses the antenna to construct a multi-coupling feed antenna MIMO system (MCFA-MIMO system), which is suitable for electronic devices such as laptops, smartphones, and Wi-Fi base stations. The antenna uses a simple structural design and does not require any RLC components to achieve multiple operating frequency bands, isolation below -11dB, a maximum gain of 4.7, and a maximum efficiency of 78%. The measurement and simulation results of the proposed antennas prove that each multi-band antenna performs consistently in MIMO systems and has high gain and high isolation performance. The simulation values of the specific absorption rate (SAR) of MCFA-MIMO system comply with international specifications and will not harm human health. This makes this antenna design a candidate for modern portable electronic devices."
  },
  {
    "year": "2025",
    "abstract": "Dynamic Random-Access Memory Physical Unclonable Functions (DRAM PUFs) are gaining interest in hardware security, particularly for resource-constrained IoT devices such as smart sensors in the era of rapid digitalization. Since DRAM is present in most of the embedded devices, implementing DRAM PUFs does not require a lot of additional hardware components. In addition, DRAM consumes less power than SRAM and DRAM’s size is generally larger, which leads to larger challenge-response pair (CRP) space, enhancing security and robustness. Despite their potential, DRAM PUFs come with some limitations in device authentication. This paper reviews three types of DRAM PUFs, including start-up DRAM PUF, retention-based DRAM PUF, and latency-based DRAM PUF. It explores their various compositions and examines the individual characteristics of each type. Latency-based DRAM PUFs have been identified as one of the highly promising and reliable PUFs for authentication. We then analyze the research gap in this area to identify opportunities for improvement and provide insights that can help shape future research directions."
  },
  {
    "year": "2025",
    "abstract": "Transactions are a key issue in enterprise applications. Considering SOA and microservices as some of the most prevalent solutions for enterprise applications, transaction management differs significantly between these two solutions. This paper defines MOF metamodels for characterizing transaction management in SOA services and microservices. To obtain these metamodels, the paper also defines additional MOF metamodels: one for the main components of the multitier architecture, one for the hexagonal architecture, one that relates both architectures, one for SOA services, and one for microservices. The paper also includes the design of a simple transaction manager that illustrates the details of how to implement global transactions for SOA services. This transaction manager, or other simpler ones, can also be used with microservices. In addition, several types of transactions are analyzed and implemented in SOA services and microservices to compare the differences between both approaches. The paper is intended as a guide for those lecturers with subjects focused on enterprise application architectures. It can also be used by developers looking for a detailed comparison between SOA services and microservices to decide which is best for their needs."
  },
  {
    "year": "2025",
    "abstract": "Software-Defined Networking (SDN) offers a solution for the efficient management of Low Earth Orbit (LEO) satellite networks through centralized control and programmability. However, the dynamic nature of LEO satellites has a unique requirement for balanced controller placement, considering low-latency communication and balanced load distribution. Therefore, a strategic, low-latency controller placement is essential to ensure optimal performance and scalability in LEO satellite networks. The proposed study presents a clustering-based technique, K-Mean++, for placing SDN controllers in the satellite network, aiming to minimize communication delay between the controller and the Open Virtual Switch (OVS) satellites. The satellites are divided into clusters, and a candidate satellite (cluster-head) is selected for controller placement. The proposed technique works in collaboration with the K-Means clustering algorithm. The performance is evaluated on switch-to-controller delay, controller-to-controller delay, controller load coefficient of variance, and traffic distribution efficiency. The results show that the proposed technique outperforms its counterparts with a 59% reduction in worst-case switch-to-controller delay, a 5% reduction in control domain delay, a 26% improvement in controller load distribution, and a 5% enhancement in control domain traffic distribution, making it an optimal solution for SDN controller placement in LEO satellite networks."
  },
  {
    "year": "2025",
    "abstract": "Infectious healthcare waste is a kind of high-risk material. With the continuous outbreak of infectious diseases in recent years, infectious healthcare waste collection (IHWC) has garnered significant attention. As infectious healthcare waste volume has increased substantially, many countries have chosen to incorporate transit points into their IHWC process to leverage consolidation effects. Besides, transporting infectious healthcare waste involves transport risks, and the storage of such waste at medical institutes and transit points also poses storage risks. In this paper, a vehicle routing problem for IHWC with multiple types of risks and transit points (VRP for IHWC-MR-TP) is proposed, considering the complexity introduced by the simultaneous existence of transport risks, storage risks, and transit points, and aiming to simultaneously minimize the total cost and the maximum risk. A bi-objective model of VRP for IHWC-MR-TP is developed. Based on the characteristics of the problem, two different solution methods are proposed, including a global solution method from a global perspective and a two-stage solution method that divides the problem into two stages for optimization. The model and solution methods are tested through numerical experiments. The results indicate that compared to the global solution method, the two-stage solution method can reduce the solving time by an average of 26.6%, while decreasing the Hypervolume by only an average of 0.5%. Finally, managerial insights are derived through sensitive analysis. The results demonstrate that an increase in collection vehicle speed results in lower cost and risk, therefore decision-makers should pay attention to vehicle maintenance and driver training in normal operations to ensure that relatively high vehicles’ speeds can be maintained during IHWC. Furthermore, as the capacities of vehicles increase, both cost and risk demonstrate a significant downward trend, suggesting that decision-makers should choose v..."
  },
  {
    "year": "2025",
    "abstract": "Securing computer systems requires effective methods for malware detection. Memory forensics analyzes memory dumps to identify malicious activity, but faces challenges including large and complex datasets, constantly evolving malware threats, and limited labeled data for training algorithms among others. This research introduces a novel approach for malware detection using memory forensics and prototypical networks. As the first application of prototypical networks to the Dumpware10 dataset (to the best of authors knowledge), our findings highlight the potential of few-shot learning for memory forensics-based malware detection, opening new avenues for research in this domain. Prototypical networks are a type of few-shot learning algorithm that excels at classifying new categories with minimal examples. Utilizing the publicly available Dumpware10 dataset, which includes 10 malware classes and one benign class, we preprocess memory dumps using denoising and A-Hash functions to reduce noise and redundancy. The prototypical network is trained on the first four malware classes and the benign class. It’s then tested on a dataset with one additional class (first five malware classes and the benign class). We progressively increase the number of test classes to eleven. Within each training episode, five training images are used as support samples, with all remaining images designated as query samples. Our goal isn’t to predict exact class labels, but to assess the similarity between query images and prototypes using a distance metric. If the label of a prototype matches the query image and the distance falls below a threshold, it’s considered a true positive. This approach achieves an average accuracy of 92% with eleven classes, the highest across all scenarios and comparable to previous work using machine and deep learning algorithms on this dataset."
  },
  {
    "year": "2025",
    "abstract": "Rapid detection of Acute Respiratory Infections (ARI) is crucial to reduce breathing difficulties and severe life-threatening conditions. Automatic cough identification is being conducted using speech frequency analysis and machine learning models. Learning models trained on Mel frequency spectrum(MFCC) features of cough sounds represented as images have recorded an average binary classification accuracy of 68%. Variable cough sound vs silent intervals between samples of a class in MFCC spectral images has shown to influence training algorithms to learn meaningful patterns for classification. To learn all possible local patterns in the MFCC cough images using a vision transformer model (ViT), we propose an image patch overlapping vision transformerIPO−ViT. The patch overlapping factorkcontrols the quantity of common pixels between them. TheIPO−ViTpatch encoder computes all possible local pixel pattern relationships by breaking the image into overlapping patches and equating them across all classes making a balanced augmented dataset. TheIPO−ViTis evaluated on our own 511 – sound cough dataset (IndiCough_2024) with 5 classes captured at AJ Institute of Medical Sciences, paediatric division along with benchmarks EPFL COUGH VID, Coswara for COVID-19 Diagnosis and Covid19-Cough. TheIPO−ViTachieved higher accuracies of around 92.33% over the state-of-the-art cough sound-based disease identification networks."
  },
  {
    "year": "2025",
    "abstract": "This paper investigates an approach for assessing stirrer performance in a reverberation chamber (RC) using characteristic mode analysis (CMA). In the design of a reverberation chamber, evaluating stirrer performance is crucial; however, it is considered challenging to assess it independently. In this study, we focus on evaluation based on the number of characteristic modes and clarify the quantitative relationship between electric field uniformity and the number of characteristic modes through RC analysis of 117 configurations. For the 117 cases obtained, non-parametric estimation was performed to model the data without assuming any physical relationships. The findings suggest that the stirrer’s influence on field uniformity stabilizes when its characteristic mode count reaches 40 to 60, aligning with the cavity mode density at the lowest usable frequency (LUF). The derived criterion also meets the IEC’s “medium” field anisotropy requirement. Additionally, comparison with geometric parameters in the IEC standard indicates that conventional metrics, such as stirrer length, can distinguish performance variations by up to 33.3%, whereas the characteristic mode-based evaluation improves this distinction to 66.7%. In addition, CMA-based evaluation can reduce design time by 27%."
  },
  {
    "year": "2025",
    "abstract": "Breast cancer remains one of the important global health concerns with high rates of mortality, highlighting the significance of more sophisticated diagnostic methods. Conventional methods, generally comprised of costly imaging and invasive biopsies, are of high burdens. Motivated by the limitations, the present study comes up with an innovative automated solution for the identification of breast cancer using deep learning analysis of mammograms. Moving away from the traditional approaches with inherent pre-processing and feature extraction constraints, this research focuses on a two-pronged improvement strategy: improved mammogram quality and highly optimized deep learning architecture. Specifically, we present a new Optimized InceptionResNetV2 model significantly optimized through the thoughtful addition of large data augmentation to increase robustness, LeakyReLU activation to facilitate gradient flow and accelerate learning, and MeanDropout regularization to mitigate overfitting and improve generalization. The model was also trained using Quantization aware training (QAT) to enable efficient deployment on low-resource devices without significant performance degradation. The performance on our proposed approach for the massive mammogram dataset reflects an evident improvement in detection performance over traditional techniques. Our InceptionResNetV2 optimized achieved state-of-the-art accuracy with outstanding measures of 98.06% sensitivity, 97.05%, positive predictive value (PPV) and specificity of 99.60%, negative predictive value (NPV) of 86.83%, 97.94% accuracy, F1-score of 96.90%, Matthew’s correlation coefficient (MCC) of 90.67%, and AUC of 0.9939. The benefits of proposed system are that it can deliver a more efficient, precise, and possibly cost-effective diagnostic tool for breast cancer. Through synergistic integration of architectural optimization, sophisticated regularization methods, and deployment-aware training, our proposed system enables earlier..."
  },
  {
    "year": "2025",
    "abstract": "Organizations pursuing enduring success in the digital transformation era need to understand employee interactions with rapidly changing technologies. Our research introduces digital climate as a vital organizational climate subdimension that represents employee views about technology readiness, digital resources, and digital leadership. A Grounded Theory research method was used in a public government organization to conduct 25 semi-structured interviews, which uncovered three main digital climate dimensions, including User Digital Experience, Digital Process Efficiency, and Organization’s Digital Effectiveness. Employee involvement in digital tool selection and customization combined with workflow optimization and rapid technical support delivery leads to improved employee well-being through technostress reduction, burnout prevention, and job satisfaction enhancement. The research demonstrates how digital climate affects employee well-being, providing scholars and practitioners with tools to measure and control digital transformation’s impact on employee well-being for sustainable competitive advantage in contemporary workplaces and future development."
  },
  {
    "year": "2025",
    "abstract": "Image manipulation detection has gained significant attention due to the rise of Generative Models (GMs). Passive detection methods often overfit to specific GMs, limiting their effectiveness. Recently, proactive approaches have been introduced to overcome this limitation. However, these methods suffer from two vulnerabilities: i) the manipulation detector is not robust to noise and hence can be easily fooled; ii) they rely on fixed perturbations for image protection, which offers an exploit for malicious attackers, enabling them to evade detection. To overcome these issues, we propose PADL, a novel solution that is able to create image-specific perturbations for protecting images. PADL’s key objective is to provide a secure and adaptive protection mechanism that ensures the authenticity of images by detecting and localizing manipulations, drastically reducing the possibility of reverse engineering. The method consists of two key components: an encoder, which conditions a learnable perturbation on the input image to ensure uniqueness and robustness against attacks, and a decoder, which extracts the perturbation and leverages it for manipulation detection and localization. PADL can detect manipulation of a protected image and pinpoint regions that have undergone alterations. Unlike previous proactive defenses that rely on a finite set of perturbations, PADL’s tailored protection significantly reduces the risk of reverse engineering. Although being trained only on images of faces manipulated with STGAN, PADL generalizes to a range of unseen models with diverse architectural designs, such as StarGANv2, CycleGAN, BlendGAN, DiffAE, StableDiffusion, and StableDiffusionXL and also to unseen data domains. Finally, we propose a novel evaluation protocol that fairly assesses localization performance in relation to detection accuracy, providing a better reflection of real-world scenarios. Future research will aim to extend PADL to work on more challenging scenarios, including ..."
  },
  {
    "year": "2025",
    "abstract": "Detecting anomalies in industrial sound is critical for maintaining operational efficiency, preventing costly equipment failures, and ensuring workplace safety. However, it presents significant challenges due to the complexity and variability of industrial environments, including background noise and fluctuating operating conditions. This paper proposes a comprehensive approach that leverages machine learning (ML) and deep learning (DL) techniques to address these challenges. Using three datasets, the Malfunctioning Industrial Machine Investigation and Inspection for Domain Generalization 2022 (MIMII DG 2022), the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022, and DCASE 2024, we evaluate the performance of various ML and DL models under different experimental conditions. Our study focuses on feature extraction methods such as Mel-spectrograms and Mel-frequency Cepstral Coefficients (MFCCs) to capture critical acoustic characteristics of industrial machinery. Both supervised ML and DL techniques are employed to explore effective anomaly detection strategies. Extensive experimentation and evaluation using metrics such as confusion matrix, accuracy, precision, recall, and F1 score highlight the effectiveness of our approach in real-world industrial scenarios. Experimental results demonstrate that eXtreme Gradient Boosting (XGBoost) outperforms Support Vector Machine (SVM) and Decision Tree (DT) models in the ML approach across both feature sets. In the DL approach, Gated Recurrent Units (GRU) perform better on MFCC features than Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) networks. GRU emerges as the best-performing model on testing datasets, achieving a precision of 99.56% and an F1 score of 99.55% on the DCASE 2024 dataset, a precision of 94% and an F1 score of 93.95% on the DCASE 2022 dataset, and a precision of 92.2% and an F1 score of 92.06% on the MIMII DG 2022 dataset. These results underscore the potential of DL f..."
  },
  {
    "year": "2025",
    "abstract": "With the rapid advancement of urbanization, traffic congestion and parking shortages have emerged as critical challenges for modern cities. Accurate parking demand forecasting plays a pivotal role in supporting intelligent traffic management, resource allocation, and the efficient operation of parking facilities. While deep learning techniques have notably enhanced prediction capabilities, current studies often fail to effectively combine the strengths of diverse model architectures. In this study, we propose a hybrid forecasting model—xLSTM-Informer—which integrates the Extended Long Short-Term Memory Network (xLSTM) and the Informer architecture. To validate the model’s generalizability and scalability, we extend our analysis beyond a single commercial parking lot and include four additional sites representing diverse urban land-use types—office, residential, hospital, and transit hub areas—across different spatial scales. Extensive experiments conducted on real-world hourly parking datasets demonstrate that the proposed xLSTM-Informer model consistently outperforms baseline models. Notably, it achieves a mean absolute percentage error (MAPE) of 3.93% for vehicle entry and 8.66% for vehicle exit prediction, along with strong performance in R2, RMSE, and MAE metrics. These results highlight the model’s robustness, high accuracy, and potential for practical deployment in city-scale parking demand forecasting."
  },
  {
    "year": "2025",
    "abstract": "The use of Low-Power Wide Area Network (LPWAN) technologies, such as Long Range (LoRa), Sigfox, and IEEE 802.15.4g (ZigBee), has grown significantly, addressing a wide range of applications including smart metering, agriculture, smart homes, and healthcare. These technologies are valued for their simplicity, flexible connectivity, low power consumption, efficient modulation techniques, and moderate data rates. As a result, they can coexist within the same environment, serving either similar or distinct applications. However, the increasing deployment of devices and technologies has amplified the likelihood of interference between them, leading to performance degradation, particularly in real-world scenarios under challenging conditions where noise power surpasses signal power. The rapid proliferation of these technologies, especially within unlicensed Industrial, Scientific, and Medical (ISM) frequency bands, underscores the need for effective techniques to ensure seamless coexistence without disrupting communication. To address this challenge, we investigate the role of data representation and propose a Channel Attention-based Denoising Autoencoder U-Net and Classifier (UNA-DAEC). This model is designed to denoise multi-label LPWAN signals affected by white Gaussian noise and accurately classify overlapping transmissions, specifically IEEE 802.15.4g, Sigfox, and LoRa signals, within the same environment. The primary objective of UNA-DAEC is to achieve reliable signal classification in low Signal-to-Noise Ratio (SNR) conditions. This is achieved by first denoising the noisy signals to obtain optimal representations, enabling high classification accuracy with a single forward and backward propagation. Our results further demonstrate that data representation plays a critical role in identifying and classifying LPWAN signals, particularly in challenging low-SNR environments, with a significant performance of 44%, 7%, and 26% over CNN-based IQ, CNN-based FFT and DAE+Cla..."
  },
  {
    "year": "2025",
    "abstract": "Skull fractures of the base and facial regions of the skull are challenging to identify, even by expert radiologists. The intricate nature and subtle features of such fractures, demand meticulous attention and ample time allocation to assure effective diagnosis and positive patient outcomes. This paper introduces a novel approach, utilizing azimuthal equidistant mapping, to better visualize the skull and, thus, enhance the diagnostic speed and accuracy of skull fracture evaluation. The proposed method maps the inherently spherical shape of the skull into a planar representation, providing radiologists with an alternative view of each complete hemisphere. Applying azimuthal equidistant mapping to CT volumetric data preserves the skull’s anatomy, while fractures, which are usually perpendicular to the bone’s surface, become more visible in projection views. The enhanced visibility is particularly useful for subtle basilar or facial fractures and increases the likelihood of detection. The effectiveness of the technique was evaluated using the CQ500 dataset. Azimuthal equidistant mapping and projection can become a valuable addition to conventional radiologic evaluation, offering an alternative view for radiologists and emergency department staff, which can increase the effectiveness and time efficiency of skull fracture detection."
  },
  {
    "year": "2025",
    "abstract": "Livestock monitoring is an important task since it enables real-time tracking of animal health and behaviour, improving productivity, reducing losses, and ensuring better resource management in farming. This paper proposes a strategy to reduce the energy consumption of a microcontroller designed for livestock monitoring in a controlled environment using LoRaWAN and GPS technologies. The aim is to extend the monitoring period implementing a novel method based on the RSSI parameter. The strategy estimates the distance of the livestock to a gateway avoiding the need of continuously using a GPS. Experimental test for different periods of time were carried out, considering variable duty cycles depending on the position of the livestock with respect to the RSSI zone. An important reduction on the energy consumed by the microcontroller was obtained, validating the effectiveness of the proposed method."
  },
  {
    "year": "2025",
    "abstract": "Autonomous indoor AAV navigation in GPS-denied environments is challenging. Issues include low lighting and obstacles. This work proposes a dual guidance framework to address these challenges. A CNN-based model with attention mechanisms and scene aware features serves as input to deep reinforcement learning. The attention module focuses on key visual elements. It highlights important regions and helps the AAV avoid collisions. The scene aware component uses computer vision techniques like pedestrian detection and brightness assessment. It gathers environmental information to assist navigation. These two models enhance the ability of DRL to adjust the AAV trajectory. This ensures safe and efficient navigation in complex indoor spaces. The approach was tested in a simulated indoor environment with pedestrians, created using Unreal Engine. The results show its effectiveness in enabling safe AAV navigation. Both the scene and attention models contribute significantly. Compared to ResNet, EfficientNet, DenseNet, and transformers, the CNN-based attention model performed better in accuracy and F1-score. The proposed navigation method also outperformed PPO and similar approaches in the literature."
  },
  {
    "year": "2025",
    "abstract": "The manual diagnosis of diabetic retinopathy (DR) is often invasive, time-consuming, expensive, and prone to human error. Additionally, it can be subjective, depending on the clinician’s professional experience. Recently, automated computer-aided diagnosis (CAD) systems have significantly reduced the time and effort required for diagnosis while achieving superior performance compared to traditional methods. Researchers have extensively explored deep learning (DL) and convolutional neural networks (CNNs) for diagnosing DR from fundus images, yielding promising results and offering a viable alternative to conventional diagnostic approaches. In this study, a hybrid model named EffNet-SVM is proposed for the classification of DR and no DR cases using retinal fundus images. The model is trained and tested using the Asia Pacific Tele-Ophthalmology Society (APTOS) dataset, which includes both DR and no DR images. The EffNet-SVM utilizes EfficientNetV2-Small for feature extraction from input fundus images, and the extracted features are then classified using a support vector machine (SVM) with a radial basis function (RBF) kernel. The EffNet-SVM model outperformed eight state-of-the-art DL models from the literature, achieving the highest accuracy of 97.26%. Performance metrics validate that the proposed hybrid model can be effectively integrated into CAD systems for the automated analysis of fundus images."
  },
  {
    "year": "2025",
    "abstract": "The global shipping industry, pivotal to international trade, faces inherent financial vulnerabilities due to cyclical asset values, volatile freight rates, and high leverage, rendering traditional credit risk models inadequate. This study proposes a novel framework integrating topological data analysis (TDA) and machine learning (ML) to enhance default prediction in maritime finance. By constructing correlation-based networks of shipping firms and extracting topological persistence features, such as cyclical trends and structural interdependencies, via Vietoris-Rips complexes, the model captures nonlinear risk patterns overlooked by conventional metrics. Network properties (e.g., centrality, clustering) and financial indicators (loan terms, vessel attributes, economic indices) are synthesized, enabling Graph Neural Networks (GNNs) to leverage relational and topological insights. Evaluated on a dataset of shipping loans spanning financial, operational, and macroeconomic variables, the TDA-enhanced models demonstrate significant improvements: logistic regression accuracy rose from 62.8% to 85.1%. At the same time, ROC-AUC for SVM and XGBoost reached 0.931 and 0.973, respectively. Key features like loan amount, vessel age, and debt-to-equity ratios exhibited strong correlations with defaults. Results underscore that incorporating TDA-derived persistence features improves early detection of financial distress, particularly in capturing systemic risks from interconnected market shocks. This hybrid approach offers a robust tool for lenders and policymakers to mitigate defaults in a sector critical to global commerce."
  },
  {
    "year": "2025",
    "abstract": "End-to-end radio communication needs to be optimized against noisy channel conditions and other distortion effects. This paper presents a novel concept, a set of hybrid quantum-classical autoencoder architectures with a comprehensive feasibility study using standard encoded radio signals, to evaluate quantum neural network design requirements for the radio context. The hybrid scenarios include single-sided, i.e., quantum encoder (transmitter) or quantum decoder (receiver), as well as fully quantum radio channel autoencoder (transmitter-receiver) systems. We provide detailed formulas for each scenario and validate our model through an extensive set of simulations. Our results demonstrate model robustness and adaptability. Supporting experiments are conducted utilizing 4 and 16 Quadrature Amplitude Modulation schemes and we expect that the model is adaptable to more general encoding schemes. We explore model performance against both additive white Gaussian noise and Rayleigh fading models. Our numerical findings highlight the importance of designing efficient quantum neural network architectures for meeting application performance constraints – including data re-uploading methods, encoding schemes, and core layer structures."
  },
  {
    "year": "2025",
    "abstract": "The aim of this study was to optimize gear tooth flank modification in a compound planetary reducer with a reduction ratio of 100:1 to achieve uniform load distribution and minimize the face load factor (KHβ). To achieve this, a prototype of the compound planetary reducer was designed and manufactured, and tests were conducted under temperature-controlled, unlubricated conditions to induce wear on gear tooth surfaces. Microscopic image observations confirmed edge contact on the gear tooth surfaces. Based on these observations, a digital mock-up (DMU) simulation model was developed and validated to align with the experimental results. A parametric analysis of lead slope change was performed using the validated model to determine the optimal value. After optimizing the lead slope, crowning modification was applied to shift the load distribution toward the center of the tooth flank. Comparison of the gear face load factor (KHβ) showed that applying the modifications improved load imbalance by up to 83.45%, effectively solving the edge contact problem compared to the results without modification. The combined approach of testing under unlubricated conditions and validating the DMU model through both experimental and analytical methods resulted in highly reliable findings, offering valuable insights into improving the performance and durability of compound planetary reducers."
  },
  {
    "year": "2025",
    "abstract": "Traditional text classification models, such as text kernels, primarily consider the syntactic aspects of text data. This paper introduces Topic-Weighted Kernels, a new text analytics framework that combines global topical themes with word-level semantics in a text kernel architecture. Three new text kernels are proposed to improve text analysis - (a) the Topic-Weighted Base Kernel, (b) the Topic-Weighted Word2Vec kernel, and (c) the Topic-Weighted BERT (Bidirectional Encoder Representations from Transformers) kernel. These kernels leverage topic modeling and deep word embeddings to capture thematic and semantic information within textual data. Text kernels consider global and local semantics for text analysis tasks and improve model performance. Experiments on diverse datasets demonstrate that Topic-Weighted Kernels outperforms existing methods for text analysis tasks. The Topic-Weighted BERT Kernel achieves top-tier performance, with F1 scores reaching 99% on lighter datasets and significantly boosting performance on more complex datasets. For the tasks of multi-label text classification on the Reuters-90 dataset and sentiment analysis on the IMDB dataset, the model achieves F1 scores of 90.76% and 96.66%, respectively, demonstrating state-of-the-art performance. The Topic-Weighted Kernel approach improves the performance while enabling a better contextual representation for various text analysis tasks such as single and multi-label classification and sentiment analysis. The proposed framework integrates semantics from word embeddings and topic models to text kernels for capturing intricate patterns in textual data that aid in more contextual text analytics."
  },
  {
    "year": "2025",
    "abstract": "There are complex discourse relationships between sentences, which can be viewed as a tree structure. This semantic structure provides important information for summarization and helps to generate concise and coherent summaries. However, current neural network-based models usually treat articles as simple sentence sequences, ignoring the intrinsic structure. To integrate discourse tree information, we propose a generative summarization model that incorporates tree structure. The article’s structure can be more accurately captured by this model, which can also produce succinct summaries by leveraging the semantic dependencies of the source material. Also, since large models are difficult to apply in downstream tasks, we try to add noise to the pre-training parameters to improve the performance of the model on the long document summarization task. Experimental results show that our model ROUGE scores outperform the state-of-the-art best models in both pubMed and arXiv datasets. We further performed human evaluation, and N-gram evaluation. The results show that our method also improves the cohesiveness and semantic coherence of abstracts."
  },
  {
    "year": "2025",
    "abstract": "We hereby propose a dual-polarized beam-deflecting metasurface that can double the scan-angle range of a phased-array antenna without compromising the directivity across all scan angles, including broadside. In particular, our research focuses on expanding the scanning range of a dual-polarized phased-array antenna capable of independently steering TE and TM waves. This is achieved by placing a dual-polarized phase-gradient Huygens’ metasurface in front of the antenna. The Huygens’ metasurface employs crossed meander lines in four impedance layers that are suitably optimized to independently control the local electric and magnetic responses for maximizing the transmission for all incident beams. We validate our approach through theoretical analysis, full-wave simulations, and experimental verification. It is demonstrated that the beam-deflecting HMS achieves effective scan range expansion to−30∘∼0∘and0∘∼30∘for TE and TM beams, respectively, using a dual-polarized phased array antenna source that scans from −15° and 15°."
  },
  {
    "year": "2025",
    "abstract": "The exponential growth of network traffic and data-intensive applications demands innovative solutions to manage data efficiently and ensure high-quality user experiences. Proactive edge caching has become a crucial technique for enhancing network performance by predicting and pre-storing content closer to users before access. Accurate prediction models, such as Long Short-Term Memory (LSTM) networks, are crucial for effective proactive caching. However, these models rely on carefully tuned hyperparameters to maintain predictive accuracy, and manual tuning is impractical in dynamic and diverse network environments, limiting scalability and adaptability. To overcome these challenges, we propose a novel framework, SPARCQ, that leverages Q-learning, a reinforcement learning algorithm, to automate hyperparameter tuning for LSTM-based prediction models. By dynamically adjusting hyperparameters, our approach ensures accurate predictions, improving caching efficiency and adaptability. Using the MovieLens dataset, we achieve an average improvement of 8% in cache hit ratios compared to baseline models, including popularity-based and untuned models. Additionally, our framework demonstrates scalability and robustness across geographically distributed regions, consistently adapting to diverse and evolving data patterns."
  },
  {
    "year": "2025",
    "abstract": "People with Disability (PwD) are some of society’s marginalized and vulnerable groups. They are mostly disadvantaged because accessibility to communal structures and social services remains challenging. Sometimes, PwDs are misunderstood because not all disabilities are visible or outward, which makes it difficult to implement useful interventions for them. Thus, the voices of PwDs, as expressed freely on social media, must be studied to better understand the fundamental challenges they face. In this research, we analyze the comments expressed in Disability communities on Reddit in the last 5 years (from 2019 to 2024) to uncover the concerns and sentiments of PwDs. Comments were collected through the Reddit API from 4 Disability subreddits, namely r/ADHD, r/Blind, r/deaf, and r/disability. Overall, a total of 601,215 comments were extracted for analysis. We applied topic modeling algorithms, namely Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and two variations of BERTopic (BERTopic with K-means clustering and BERTopic with HDBSCAN clustering) on each subreddit’s comments to extract hidden topics. The NMF discovered 15 topics in the r/Blind and 20 topics in the r/deaf. Furthermore, related topics were merged into themes, and we discovered nine themes in both r/ADHD and r/Blind, eight themes in r/deaf, and seven themes in r/disability. Additionally, a pre-trained transformer, SiEBERT, was used to determine the sentiments for the themes in each subreddit. The themes discovered across at least two subreddits are Mobility, Diagnosis, Education, Assistive and Accessible Technology, Support, Disability Accommodations, and Relations. PwD with ADHD struggle with the effects of medications, household chores, sleep, attention span, and oversubscribing to online payment services. The PwD, who are visually impaired, feel alienated by society, struggle with public transit systems, have limited employment, and experience harassment. Those with diffic..."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes reconfigurable single-stage three-switch leg multi-port boost inverters (TSLMPBIs) that feature novel hybrid modulation schemes for hybrid DC/AC microgrid system applications. The TSLMPBI topologies are designed to accommodate various configurations, including two DC ports with two AC ports, three DC ports with one AC port, and three DC ports with two AC ports, tailored for different applications. A hybrid modulation scheme was proposed, dynamically adapted to the configuration of DC and AC ports, facilitating seamless boost and dual inversion operations or combined boost, buck, and inversion functionalities within a single converter. The AC ports operate at various voltages, frequencies, and phases, while the DC ports support multiple voltage levels. The proposed control modulation scheme effectively addresses crossover issues in modulation signals, resulting in enhanced AC voltage gain, improved DC bus utilization, and optimized power transfer among DC and AC ports. Additionally, these topologies reduce active switch count compared to state-of-the-art designs, even with increased ports. To validate the performance of the proposed TSLMPBI and its control modulation scheme, a 500 W laboratory prototype was developed, and experimental results under various operating scenarios were presented and analyzed."
  },
  {
    "year": "2025",
    "abstract": "As the global population ages, the prevalence of dementia is expected to surge, necessitating innovative solutions to support the growing number of affected individuals. This research shows a innovative approach for the application of Convolutional Neural Networks for object identification in nursing home environments to enhance the independence and quality of life of dementia patients. Therefore we compare the performance of four well-known Convolutional Neural Network architectures — VGG16, VGG19, InceptionV3, and ResNet50 — to identify the most effective model for this application. Building on this, we use Gaussian blurring as an innovative preprocessing technique to improve model accuracy by reducing high-frequency noise and enhancing feature extraction. Our results indicate that ResNet50 outperforms other models, achieving the highest accuracy with 90.53%. Optimization through data augmentation and fine-tuning further enhances ResNet50’s performance to 94.69%. Applying the Gaussian filter significantly improves the model’s accuracy to 96.81%, demonstrating its potential as a crucial preprocessing step and setting a new benchmark for this application. Our findings provide valuable insight into applying the Gaussian filter on Convolutional Neural Networks and pave the way for developing intelligent support systems to assist dementia patients in their daily tasks and improve their overall well-being."
  },
  {
    "year": "2025",
    "abstract": "The semiconductor supply chain industry is spread worldwide to reduce costs and meet the high demand for integrated circuits (ICs) in electronic systems. The high utilisation of electronic devices in the next decade is forecasted to reach trillions, increasing the already high volume of e-waste. It will lead to concerns about the security and reliability of ICs, particularly those exposed to counterfeiting, i.e., recycled and remarked ICs. This paper harvests aging degradation induced by bias temperature instability (BTI) and hot carrier injection (HCI), observing frequency (f) and discharge time (τdv) affected by changes in drain current and sub-threshold leakage current over the lifetime of an IC to estimate the IC age. This is carried out using Cadence simulations, implementing 13- and 51-stage ring oscillators (ROs) using a 22-nm CMOS technology and aging model provided by GlobalFoundries (GF). The machine learning (ML) algorithm of support vector regression (SVR) is adapted for this application, using a training process that involves operating temperature,τdv, f, aging time and inter-die and intra-die process variation (PV). The data sampling is performed over a simulated 12-year period with representative temperatures between 20°C up to 100°C and with additional testing data from 25°C up to 75°C. Incorporating the PV effect with the SVR model allows the proposed SVR model to be adopted in practical IC implementation. The results demonstrate high accuracy in aging estimation by SVR with/without PV effects. The proposed SVR model detects the age of an IC with an error accuracy between 0.206 and 0.667 (deviation of 74.16 and 240.12 days), and 0.091 and 0.237 (deviation of 32.76 and 85.32 days) based on the Root Mean Square Error (RMSE) for 13- and 51-satge RO, respectively. It outperforms the state-of-the-art IC age prediction models even when learning and validating the model with aging and PV."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a novel approach for achieving high-capacity transmission utilizing sub-terahertz (THz) radio orbital angular momentum (OAM) multiplexing, specifically in scenarios where the radio link is susceptible to antenna misalignment. We focus on a radio OAM multiplexing system incorporating uniform circular antenna arrays (UCAs) at both the transmitter and receiver. While it is established that UCA-based OAM multiplexing can significantly enhance transmission capacity, its performance is notably sensitive to antenna misalignment, leading to capacity degradation. To mitigate this issue, we propose a novel closed-loop OAM system featuring adaptive phase-shift control for transmission signals. We also introduce efficient methods for optimizing the phase shift. An experimental demonstration of the radio OAM system employing the proposed phase-shift control method is provided, showcasing its efficacy in compensating for the effects of misalignment."
  },
  {
    "year": "2025",
    "abstract": "In modern industrial environments, early detection of anomalies is essential to prevent unplanned downtime and maintain operational efficiency. Traditional rule-based and supervised methods often struggle with data drift, limited labeled data, and the inability to capture the complex interdependencies inherent in interconnected industrial systems. To address these challenges, we propose a drift-resistant self-supervised anomaly detection framework specifically designed for industrial applications. Unlike conventional fault classification approaches that identify predefined defect types, our model focuses on detecting subtle, evolving anomalies in time-series vibration data. The framework integrates advanced statistical and spectral feature extraction with a dynamic, rolling-window-based data grouping strategy, enabling the model to adapt robustly to temporal variations. Evaluation is based solely on accuracy and the experimental results demonstrate that our approach achieves up to 75% faster anomaly alerts compared to conventional ISO 10816 standards. Validation in NASA bearing datasets, as well as real-world vibration data from industrial fans, motors, and gearboxes confirms the model scalability and practical applicability. This work provides a cost-effective and reliable solution for continuous condition monitoring, thereby laying a strong foundation for enhanced predictive maintenance in complex industrial settings."
  },
  {
    "year": "2025",
    "abstract": "Ransomware and other malware inflict devastating financial and operational damage on organizations worldwide by exploiting deeply embedded, hard-to-detect vulnerabilities in their systems. Detecting these vulnerabilities in compiled code before malicious actors exploit them remains a critical challenge in cybersecurity. This research introduces TEDVIL (Transformer-based Embeddings for Discovering Vulnerabilities in Lifted Code), a novel framework which uses transformer-based embeddings to train neural networks to detect vulnerabilities in lifted code. The framework was implemented using bidirectional (BERT and RoBERTa) and unidirectional (GPT-1 and GPT-2) transformer-based models to generate embeddings for training Long Short-Term Memory (LSTM) neural networks to detect stack-based buffer overflows in Low-Level Virtual Machine (LLVM) intermediate representation code. For comparison, simpler word2vec models (Skip-Gram and Continuous Bag of Words) were also trained, and their embeddings were used to train LSTMs. The results show that the LSTMs using GPT-2 embeddings outperformed those using GPT-1, BERT, RoBERTa, and word2vec embeddings, achieving a top accuracy of 92.5% and an F1-score of 89.7%. Notably, these results are achieved when the embedding model is trained with a dataset of just 48,000 functions, demonstrating effectiveness in resource-constrained settings. The findings underscore the effectiveness of TEDVIL in identifying hard-to-detect vulnerabilities in compiled code, and lay the groundwork for future research in leveraging transformer-based models for vulnerability detection."
  },
  {
    "year": "2025",
    "abstract": "Cardiac auscultation using a digital stethoscope is an important method for diagnosis of cardiovascular diseases (CVDs). However, heart sound recordings are often contaminated with adventitious noise, especially in crowded, noisy settings such as resource-constrained hospitals. This noise can confound accurate diagnosis of heart pathologies. We propose a method for denoising heart sounds using fully convolutional networks (FCNs) based on the Spleeter U-Net architecture. We first generate a spectrogram of the heart sound recording and then use FCNs to semantically segment this into noise and signal components. We present an adaptation of the full Spleeter design, and also a lighter version operating on smaller spectrograms. This is aimed at reducing latency in a future real-time implementation of this scheme. We investigate whether providing this latter network with context improves the performance. We evaluate the denoising performance by artificially contaminating clean heart sounds with real-world noise (additive white Gaussian noise (AWGN), ambient hospital noise, lung sounds, and speech). Our best model was the lighter model with context, which we call the denoiser with context (DWC). We tested all models with different contamination types at different signal-to-noise ratios (SNRs), and found that the DWC gave an overall average improvement of 10.322 dB, with average increases ranging from 6.151 dB to 14.479 dB. We also implement the denoising inference on an edge device to show the feasibility of running this scheme on an embedded system. This work is a step towards a real-time deep learning-based denoiser for use with a digital stethoscope."
  },
  {
    "year": "2025",
    "abstract": "Vehicle-to-everything (V2X) communications is a crucial area of wireless communications and is of primary interest for automakers, smart cities, municipal services, traffic planners, and law enforcement authorities. V2X systems are beneficial for increasing driving safety, driving time, the ability to avoid accidents, traffic congestion and energy saving. However, the V2X communication is not only characterized by high mobility and but also by rapid and unexpected changes in the communication environment, which drastically degrade the fading features and the quality of the communication channel. Maintaining tolerable quality of service (QoS) in a V2X communication environment is therefore essential. Thus, under the premise of ensuring channel quality, channel coding is employed as the predominant process enhancing reliability by introducing high data redundancy. In this study, we investigate the impact of 4th-Generation Long-Term Evolution (4G-LTE) turbo codes, 5th-Generation New Radio (5G-NR) polar codes, and 5G-NR low-density parity-check (LDPC) codes on the QoS of a V2X communication system. To this end, we propose space and time-varying V2X propagation models, based on real traffic data, that simulate V2X communication in real urban and highway environments and various traffic density conditions, based on the 3rd-Generation Partnership Project (3GPP) specifications. Through these simulations we investigate the frame error rate (FER) performance and QoS efficiency of the V2X dynamic propagation models which are achieved by the 4G-LTE and 5G-NR channel coding schemes. Our analysis introduces novel large-scale V2X fading models and ultimately proves that turbo-based coding schemes have superior performance for small-frame 5G V2X communication."
  },
  {
    "year": "2025",
    "abstract": "Today, considering the complexity of different types of networks worldwide and the variety of different pathways for mobility, researchers are interested in research and analysis in mobility management, one of the critical aspects of network management. Mobility management is used for many cases, such as urban management, location-based services (LBS), collision avoidance and tourism industry improvement. On the other hand, the dramatic advances in artificial intelligence (AI) have attracted much attention to the use of this tool in network management, using which they can quickly predict the following route or destination of users in the network in different scenarios. However, there are many challenges in this field, and ignoring them reduces the accuracy of the models. In this paper, We introduce the methods that researchers have presented and mention the advantages and disadvantages of each. The articles used include reputable journals from 2020 to 2025. Mobility management is done by focusing on four topics human mobility, vehicle, aircraft and ship. After introducing the approaches, we categorized and compared these models with related articles. Then, we showed the important items used in the articles, such as datasets, in the diagram and introduced the most used and famous ones. Also, commonly used metrics were reviewed. We highlight aspects that can help improve the performance of models. By considering these aspects, researchers can introduce more practical models that achieve lower errors using metrics such as Root-mean-square deviation (RMSE)."
  },
  {
    "year": "2025",
    "abstract": "This study investigated a site-specific approach to building entry loss to enable robust mobile wireless access for non-terrestrial networks using high-altitude platform stations and highly efficient fixed wireless access for terrestrial networks. In this study, outdoor-to-indoor propagation measurements were conducted in two distinct high-rise office buildings. These measurements considered various incident elevation and azimuth angles relative to the building façade and different indoor antenna locations. One set of measurements was performed using a helicopter at 1.47 GHz and 3.35 GHz, and the other set of measurements was conducted along a terrestrial path at 3.35 GHz and 29.3 GHz. Based on the obtained measurement results and geometrical optics theory, we analyzed the site-specific building entry loss, observing the nonmonotonic characteristics with the indoor entry distance. Based on the results, we propose a model that incorporates various parameters, e.g., the locations of the outdoor and indoor stations, as well as the dimensions of the building rooms and windows. Compared with standardized frameworks and existing models, the proposed model effectively characterized the site-specific building entry loss and demonstrated higher predictive accuracy on measured data for frequencies from 1 to 30 GHz."
  },
  {
    "year": "2025",
    "abstract": "As the need for high-speed wireless communication continues to grow, millimeter-wave (mm-wave) technologies have become essential for next-generation wireless systems, such as 5G and beyond. High-gain, wide-band antennas are crucial in these applications to ensure efficient signal transmission and reception. In this work, a wide-band, high-gain mm-wave printed Yagi-Uda antenna has been designed for operation in the 58–68 GHz frequency band. The proposed antenna features a bowtie-driven element, three two-arm reflectors, and four rhombus-shaped directors, designed to enhance gain and bandwidth performance. At 63 GHz, the antenna achieves a maximum gain of 12 dB and a best side lobe level (SLL) of −15 dB. Across the entire operational band, the gain remains above 10 dB, while the SLL is maintained below −12 dB, ensuring stable and efficient performance. The compact design, with total dimensions of 15.6 mm×8.5mm, makes it suitable for integration into modern mm-wave communication systems. To validate the proposed design, a prototype is fabricated, and experimental assessments of return loss, radiation patterns, gain, and SLL are conducted. Numerical simulations and experimental measurements exhibit strong agreement, confirming the antenna’s effectiveness in high-frequency applications."
  },
  {
    "year": "2025",
    "abstract": "Presents corrections to the paper, (Corrections to “Analysis and Modeling of Direct Ammonia Fuel Cells for Solar and Wind Power Leveling in Smart Grid Applications”)."
  },
  {
    "year": "2025",
    "abstract": "There is a huge difference in rotational inertia between the wind turbine drivetrain test bench (WTDTB) and the actual wind turbine, which needs to be accurately compensated. As a closed-loop control system with time delay, WTDTB working in the inertia simulation mode is prone to instability. The existing researches solve this problem by the time delay stability control algorithm based on high-order filter, which is on the premise that the filter order and the time delay order of the inertia compensation loop accurately match. However, the torque command response method currently used to measure time delay is not effective in practical applications. In order to accurately obtain the time delay, this paper draws on the idea of soft measurement based on operation parameters, finds and proves that there is a definite quantitative relationship between the compensation torque oscillation period and the time delay. On this basis, a time delay identification method based on instability characteristics observation is proposed. This method causes the controlled oscillation of the test bench by reasonably designing the oscillation experiment, extracts the oscillation period, and determines the time delay accordingly. The experiment results based on 15kW WTDTB verify the feasibility and effectiveness of the proposed method."
  },
  {
    "year": "2025",
    "abstract": "Governments rely on military power to address conflicts, manage crises, and adapt to the evolving nature of modern warfare, which is often characterized by uncertainty and disorder. Wargames, traditionally military tools for simulating conflicts and decision-making, have gained prominence in civilian applications, including business, cybersecurity, disaster management, and critical infrastructure protection. Despite their utility, designing wargames is a time-intensive process with significant challenges, such as scenario creation and decision modeling, necessitating structured and systematic approaches. This research formalizes wargame design through ontology-driven conceptual modeling, structuring its key concepts, characteristics, and elements. Ontologies provide a structured representation of knowledge, facilitating communication, knowledge management, and collaborative design. As a result, we developed core ontologies for wargame design based on the Unified Foundational Ontology (UFO) and implemented them using OntoUML. Our innovation lies in analyzing wargame design processes across various countries and military organizations to develop a comprehensive reference model for wargame design. Additionally, we are the first to apply UFO for conceptual modeling of the wargame domain. These ontologies enhance wargame design by fostering standardization, adaptability, and support for intelligent systems, enabling dynamic and responsive scenarios. These contributions enhance wargame design efficiency and effectiveness, applicable to military and civilian contexts."
  },
  {
    "year": "2025",
    "abstract": "For future six-generation (6G) upper mid-band mobile communications, the higher-order device multi-input-multi-output (MIMO) such as the8×8or8×4MIMO is envisioned for the smartphone to achieve increased data rates for the user. However, it is worth noting that the8×8MIMO requires twice the transmitted power of current fifth-generation (5G)4×4MIMO and has a much more complex system architecture. Thus, whether it is cost effective to apply the8×8MIMO for increased data rates is not clear. In this study, we demonstrate that the8×4MIMO (8 receive antennas for 4 spatial streams) with the same transmitted power as the 5G4×4MIMO can outperform the8×8MIMO to achieve increased data rates and lower energy per bit as well. In the outdoor scenario testing, the8×4MIMO shows a spectral efficiency of about 31 or 26 bps/Hz, while that of the8×8MIMO is only about 22 bps/Hz. Additionally, the required energy per bit transmitted in the8×4MIMO is less than one-half that of the8×8MIMO. The is mainly because the8×4MIMO uses only one-half transmitted power and has a much larger MIMO efficiency (measured system capacity/ideal system capacity) than the8×8MIMO. Thus, the8×4MIMO can support a higher signal modulation of 256 or 1024 Quadrature Amplitude Modulation (QAM), while the8×8MIMO supports only 16 QAM. Hence, although the8×8MIMO has a potentially much larger system channel capacity, its actual data throughput cannot be proportionally larger. We experimentally evaluate the MIMO performance in the 7.1 GHz band by applying compact backcover four-antenna (B4A) modules as receive antennas in the smartphone-like device covering 6.425-8.4 GHz in the upper mid-band, which is promising to be a prime 6G mobile spectrum. The applied compact B4A module provides a promising solution for the challeng..."
  },
  {
    "year": "2025",
    "abstract": "Communication barriers between hard-of-hearing and hearing individuals can be mitigated through advancements in sign language recognition (SLR) systems. These SLR systems can also improve the user experience of hard-of-hearing people when interacting with conversational systems that could emerge in the near future. This work explores a landmark-based approach for word classification within an SLR system. The study investigates the impact of a novel data-cleaning methodology on model performance during training. Specifically, a data cleaning process focused on video trimming and sign placement correction is shown to significantly improve dataset quality, resulting in more accurate classification. This cleaner data not only facilitated a more stable training process for the RNN model but also effectively delayed the onset of overfitting compared to a model trained on the original data. The findings highlight the critical role of data quality, particularly when dealing with the limitations inherent to small datasets commonly encountered in SLR tasks. The contribution of this study lies in demonstrating how targeted data cleaning enhances model stability and performance in resource-limited SLR systems."
  },
  {
    "year": "2025",
    "abstract": "Images captured with wrong exposure conditions inevitably produce unsatisfactory visual effects. Thus, multiple exposure correction has drawn much attention, which should correct for degraded images due to various wrong exposure conditions. However, the problem of handling the different nature of underexposed and overexposed images makes this task challenging. In this work, we introduce the novel multiple exposure correction transformer, named MECFormer, to tackle this problem. MECFormer consists of autoencoder, encoder, and dual-path aggregation decoder. First, the autoencoder extracts multi-scale exposure features representing the level of input exposure. Second, the encoder embeds input images into multi-scale image features. Third, the dual-path aggregation decoder sequentially restores exposures by effectively aggregating multi-scale exposure features and image features. MECFormer achieves the state-of-the art performance on two multi-exposure correction datasets. Also, we provide extensive ablation studies to show the effectiveness of the proposed components."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes PTA-HE, an enhanced Property-based Token Attestation scheme integrated with Homomorphic Encryption (HE), specifically designed to address critical security challenges in mobile cloud computing environments. Traditional Property-based Token Attestation (PTA) protocols, although foundational, inherently lack robust mechanisms to secure sensitive data during active processing stages, exposing data to potential confidentiality and integrity breaches. Our main contributions are: the introduction of PTA-HE, which resolves these vulnerabilities by enabling computations directly on encrypted data, ensuring continuous protection and resilience against unauthorized access and manipulation; a strategic employment of Trusted Third Parties (TTPs) for secure attestation management, leveraging HE to maintain data confidentiality throughout the entire attestation workflow; rigorous experimental evaluations quantifying computational overhead, communication costs, latency, and scalability implications, transparently illustrating the performance trade-offs associated with enhanced security; and formal verification using the Scyther tool demonstrating PTA-HE’s superior correctness and robustness against multiple security threats, such as replay and man-in-the-middle attacks. Consequently, PTA-HE provides a highly effective and practical solution for secure mobile computing applications requiring stringent assurances of data privacy and integrity."
  },
  {
    "year": "2025",
    "abstract": "Segmentation of lung nodules in CT images is an important step during the clinical evaluation of patients with lung cancer. Furthermore, early assessment of the cancer is crucial to increase the overall survival chances of patients with such disease, and the segmentation of lung nodules can help detect the cancer in its early stages. Consequently, there are many works in the literature that explore the use of neural networks for the segmentation of lung nodules. However, these frameworks tend to rely on accurate labelling of the nodule centre to then crop the input image. Although such works are able to achieve remarkable results, they do not take into account that the healthcare professional may fail to correctly label the centre of the nodule. Therefore, in this work, we propose a new framework based on the U-Net model that allows to correct such inaccuracies in an interactive fashion. It is composed of two U-Net models in cascade, where the first model is used to predict a rough estimation of the lung nodule location and the second model refines the generated segmentation mask. Our results show that the proposed framework is able to be more robust than the studied baselines. Furthermore, it is able to achieve state-of-the-art performance, reaching a Dice of 91.12% when trained and tested on the LIDC-IDRI public dataset."
  },
  {
    "year": "2025",
    "abstract": "Differential protection is a fundamental mechanism in power systems for detecting and isolating faults. However, traditional protection schemes face significant challenges in modern smart grids due to communication delays and the inability to dynamically adapt to real-time information. These limitations often result in reduced fault detection accuracy and delayed system response, threatening the reliability and stability of the grid. To address these shortcomings, we propose an Age of Information (AoI)-optimized differential protection strategy tailored for smart grids. By modeling the differential protection problem as a remote Markov Decision Process (MDP), we incorporate AoI as a critical factor to capture the freshness of information in decision-making under stochastic delays. Our analysis reveals that treating AoI as auxiliary side information, rather than a standalone optimization goal, significantly enhances the timeliness of information and indirectly improves fault detection accuracy. By leveraging AoI, we show that it is possible to enhance the timeliness and accuracy of fault detection, even under adverse network conditions, by ensuring that the system relies on the freshest information available. In particular, our results demonstrate a 6.5% improvement in information freshness compared to traditional methods, leading to enhanced system performance. This study provides new insights into leveraging information freshness to overcome the inherent limitations of traditional differential protection schemes, thereby improving the efficiency and resilience of modern power systems."
  },
  {
    "year": "2025",
    "abstract": "Recent advancements in deep learning methods have significantly improved the performance of 3D Human Pose Estimation (HPE). However, performance degradation caused by domain gaps between source and target domains remains a major challenge to generalization, necessitating extensive data augmentation and/or fine-tuning for each specific target domain. To address this issue more efficiently, we propose a novel canonical domain approach that maps both the source and target domains into a unified canonical domain, alleviating the need for additional fine-tuning in the target domain. To construct the canonical domain, we introduce a canonicalization process to generate a novel canonical 2D-3D pose mapping that ensures 2D-3D pose consistency and simplifies 2D-3D pose patterns, enabling more efficient training of lifting networks. The canonicalization of both domains is achieved through the following steps: 1) in the source domain, the lifting network is trained within the canonical domain; 2) in the target domain, input 2D poses are canonicalized prior to inference by leveraging the properties of perspective projection and known camera intrinsics. Consequently, the trained network can be directly applied to the target domain without requiring additional fine-tuning. Experiments conducted with various lifting networks and publicly available datasets (e.g., Human3.6M, Fit3D, MPI-INF-3DHP) demonstrate that the proposed method substantially improves generalization capability across datasets while using the same data volume."
  },
  {
    "year": "2025",
    "abstract": "Accurate and efficient brain tumor diagnosis remains a critical challenge in medical imaging. This study proposes a novel framework that integrates fuzzy logic-based segmentation with deep learning (DL) techniques to enhance brain tumor detection and classification in magnetic resonance imaging (MRI) scans. In the first stage, a fuzzy thresholding approach is applied to segment MRI images into healthy and abnormal regions, enabling the precise extraction of tumor areas. In the second stage, an optimized convolutional neural network (CNN) model classifies tumors into four categories: glioma, meningioma, pituitary tumor, and no tumor. The proposed method is evaluated across three large public datasets comprising more than 23,000 MRI images. Experimental results demonstrate that the model achieved an accuracy of 98% and a Dice similarity coefficient of 97.97%, confirming its high effectiveness in accurately extracting tumor regions and classifying them correctly. Furthermore, the proposed system outperforms conventional machine learning, deep learning, and transfer learning techniques. In addition to classification, the system accurately estimates tumor size, providing valuable clinical insights. These findings highlight the potential of combining fuzzy logic with DL to improve automated brain tumor diagnostics, enhance diagnostic reliability, and support clinical decision-making."
  },
  {
    "year": "2025",
    "abstract": "As one of the key application scenarios of wireless sensor networks, the coverage optimization of underwater wireless sensor networks (UWSNs) requires special consideration of three-dimensional spatial characteristics, which distinctly differs from traditional terrestrial environment coverage issues. To address the problems of low coverage and uneven distribution in UWSNs within a three-dimensional space, we propose a Reinforcement Learning-driven Hunter-Prey Optimization (RL-HPO) algorithm. Firstly, a nonlinear convergence factor is designed to regulate the exploration and exploitation phases, achieving an effective balance between these two stages. Secondly, by incorporating the concept of Q-learning, the algorithm can adaptively select the optimal action strategy at different stages, thereby enhancing the effectiveness of actions executed in each phase. Lastly, the Nelder-Mead simplex strategy is introduced to perturb poorly performing individuals within the population, fully exploiting their search potential and preventing the algorithm from getting trapped in local optima. The performance of the RL-HPO algorithm in three-dimensional WSN environments, both with and without obstacles, was evaluated through simulation experiments. Comparisons were made with PSO, HPO, SSA, ALGWO, and SWOA. The results demonstrate that RL-HPO significantly outperforms other algorithms in key metrics such as coverage rate, moving distance, and network connectivity. In obstacle-free scenarios, RL-HPO achieved the highest coverage rate of 96.5%, while in scenarios with obstacles, the coverage rate reached 93.3%, representing improvements of 12.58%, 13.41%, 4.15%, 8%, and 13.95% over the other algorithms, respectively."
  },
  {
    "year": "2025",
    "abstract": "Federated Learning (FL) facilitates decentralized model training without the exchange of raw data, thereby guaranteeing privacy. However, due to its distributed nature, this paradigm is susceptible to adversarial threats such as sign-flipping attacks, in which malicious clients reverse model parameter signs in order to poison the global aggregation process. This study introduces a detection framework that is graph-based and leverages Graph Attention Networks (GATs) to overcome these challenges. The framework detects malicious clients with high accuracy by representing FL local models as directed graphs and capturing layer-wise statistical features. The efficacy of the approach is demonstrated by extensive experiments on the FEMNIST dataset, which simulate varying attacker percentages (15%, 35%) and attack probabilities (0.5, 0.7, 1.0). The GAT model obtains a 100% detection rate with zero false positives within an optimal threshold range of 0.5–0.9, as demonstrated by the results. Furthermore, isolating detected attackers during targeted rounds (20-60) substantially maintains FL global model performance, thereby mitigating the cascading effects of poisoned updates and ensuring system stability. This work offers a practicable, scalable, and robust solution to improve the security of FL systems against adversarial behaviors."
  },
  {
    "year": "2025",
    "abstract": "Endoscopic imaging has become an indispensable tool in modern medical practice, enabling minimally invasive diagnosis and treatment. A crucial aspect of endoscopic procedures is the accurate reconstruction of the observed scene, which facilitates spatial understanding, surgical planning, and guidance. This comprehensive review delves into the latest advancements and applications of Gaussian splatting in endoscopic scene reconstruction. We explore the fundamental principles of this technique, examining how Gaussian kernels are utilized to fuse depth cues and generate detailed 3D models. Furthermore, we analyze the various refinements and extensions that have been proposed to enhance the performance and robustness of Gaussian splatting, addressing challenges such as occlusions, sparse data, and real-time processing. Through this comprehensive survey, we aim to provide researchers and medical professionals with a deep understanding of the state-of-the-art in Gaussian splatting for endoscopic scene reconstruction, highlighting its pivotal role in advancing endoscopic imaging and interventions."
  },
  {
    "year": "2025",
    "abstract": "Named Entity Recognition (NER) aims to automatically extract specific entities from unstructured text. Compared with English NER, Chinese NER faces challenges due to heterophony, where the same Chinese character may have different pronunciations and meanings. Additionally, the lack of clear separators between Chinese characters exacerbates these challenges, leading to difficulties in boundary detection and entity category determination. Inspired by the hieroglyphic and phonetic features of Chinese characters, this study proposes a multi-feature fusion embedding model (MP-NER). The model employs CNN for extracting radicals and phonetic features of Chinese characters, combines the encoded information from these features with pre-trained word vectors to generate fusion embedding vectors, and uses a fully-connected layer for feature transformation. Experiments were conducted on the Chinese benchmark datasets Resume, Weibo and MSRA. Compared to current mainstream models, the proposed model demonstrates superior performance in terms of F1 score, F1 score stability, and individual entity recognition accuracy. Ablation experiments further validate the effectiveness of the introduced radicals and phonetic features. The experimental results demonstrate that this model effectively captures the semantic information of Chinese characters, addresses the problem of Chinese character heterophony, and improves entity recognition performance. The code and datasets available at:https://github.com/FAKLITS/MP-NER"
  },
  {
    "year": "2025",
    "abstract": "This research aims to study the fabrication of electronic devices using pellet extrusion 3D printing with composite material. The process employed a polymer-based composite material that incorporated a substantial amount of barium titanate powder, reaching 80 wt.%. A thorough examination was conducted to understand the various factors influencing the printed components, using a design of experiments (DOE) approach. This method identifies the optimal printing parameters for a Custom Fused Granular Fabrication printer, such as layer height (0.32), barrel temperature (240°C), flow rate (500), and printing speed (2 mm/s). The dielectric constant of the polylactic acid - barium titanate composite reached 8.47 and a loss tangent of 0.099 in the X-band, making it suitable for applications involving high frequencies with a lower cost process and using a more sustainable polymer."
  },
  {
    "year": "2025",
    "abstract": "UAV imagery is widely used in areas like traffic safety, disaster rescue, and airspace management, due to its small size and low cost. However, it poses unique challenges for object detection due to small objects, complex backgrounds, and noise interference. To tackle these challenges, we propose YOLO-Air, a novel small object detection network designed specifically for UAV imagery. We propose SECAConv (Squeeze-Excitation Convolution with Attention), which enhances the feature representation of small objects through dynamic weight allocation and channel attention mechanisms. Additionally, we design the novel AeroFPN (Aerial Feature Pyramid Network) to optimize feature transmission by alleviating shallow feature loss through the inclusion of the xsmall detection head. Furthermore, we develop ASFM (Adaptive Scale Fusion Module), which suppresses background noise interference through effective multi-scale feature fusion and adaptive channel attention mechanisms, thereby improving the network’s ability to detect small objects. Experimental results demonstrate that YOLO-Air achieves significant accuracy improvements on both the VisDrone-DET2019 and AI-TOD datasets. Compared to the baseline YOLOv8n, YOLO-Air improvedmAP50from 41.2% to 44.5% on the VisDrone-DET2019 dataset, and from 44.9% to 47.5% on the AI-TOD dataset, while maintaining computational efficiency. These results validate YOLO-Air as an effective solution for small object detection in UAV aerial imagery."
  },
  {
    "year": "2025",
    "abstract": "The Hadamard product (also known as element-wise multiplication) is a fundamental operation in linear algebra, performed by multiplying corresponding elements of two matrices with the same dimensions. This operation plays a crucial role in various fields, including cryptography, where it enables efficient and parallelizable computations on large datasets—particularly in the design of cryptographic protocols such as zero-knowledge proofs. In this paper, we propose a transparent and efficient method for proving the Hadamard product between vectors that are independently committed in the groupsG1andG2under a pairing operatione:G1×G2→GT. For a vector of length n, the prover has a complexity ofOλ(n), while the proof size isOλ(logn). The verifier operates with a complexity ofOλ(logn), which includesO(logn)operations inGTand onlyO(1)pairing operations, making verification highly efficient. We prove the security of our scheme under the Symmetric External Diffie-Hellman (SXDH) assumption. Furthermore, we propose an aggregator for Groth16 (EUROCRYPT 2016) zk-SNARKs and a proof aggregation technique for the general case of the KZG polynomial commitment scheme (ASIACRYPT 2010), where allcrsare distinct. Both applications do not require an additional trusted setup, support logarithmic-sized aggregated proofs, and significantly reduce the verifier’s pairing operations toO(1)."
  },
  {
    "year": "2025",
    "abstract": "This paper focuses on a DC/3ϕpower converter combining the single-delta bridge-cell (SDBC) converter and a single-phase PWM converter via a medium-frequency transformer for voltage flicker mitigation. In this application, the converter is required to produce negative-sequence reactive power and active power in addition to positive-sequence reactive power and harmonic power. However, in conventional SDBC-based STATCOM, steady-state active power control is not possible, and furthermore, it suffers from large voltage fluctuation in the DC-capacitor voltages when low-frequency active power is controlled. On the other hand, the proposed converter is capable of controlling active power and has been confirmed to operate at 37% of the rated reactive power, demonstrating its adaptability for flicker compensation. Nevertheless, the proposed converter still faces two challenges when intended for flicker compensation operation. The relationship between the deliverable negative-sequence reactive power and active power has not been clarified in previous research. Additionally, the operation of the system during low-frequency active power control has not been analyzed. This paper attempts to solve the first problem by conducting theoretical power analysis when negative-sequence reactive power is controlled by supplying circulating current from the single-phase converter. The second problem is also addressed by presenting current reference values for low-frequency active power control and conducting circuit analysis. The validity of the control and theoretical analysis developed in this paper is experimentally verified using a 100-V, 5-kVA downscaled model."
  },
  {
    "year": "2025",
    "abstract": "As power grids modernize, ensuring reliable substation operation grows increasingly critical. Uncrewed aerial vehicle (UAV) inspections provide significant advantages over traditional manual and robotic methods, such as cost-effectiveness, greater maneuverability, improved efficiency, and the ability to operate in closer proximity to equipment. However, the complex electromagnetic-field environment within substations poses challenges for UAV operations. Determining a safe distance between UAVs and high-voltage equipment is essential for deploying UAVs effectively in substation inspections. This study investigates electromagnetic field exposure during UAV-based substation inspections. A computational model was developed to evaluate the electromagnetic field and simulate the surface field distribution during UAV operation. The results indicate that the UAV is affected by strong electromagnetic fields near the four rotor blades and the central wing section. Laboratory high-voltage tests, combined with simulations, confirmed that the UAV can perform inspections while maintaining a 50 cm distance from high-voltage equipment. Furthermore, when the UAV approaches the equipment to the point of gap discharge, it can continue operating normally for a limited time, demonstrating its certain ability to withstand high-voltage electric fields. These findings provide critical insights for establishing safe operating distances for UAVs in substations."
  },
  {
    "year": "2025",
    "abstract": "This study, aimed at professionals in research and development in the fields of computer vision, artificial intelligence, and intelligent transportation, presents a systematic literature review on recent machine learning methodologies applied to the detection and tracking of vehicles, pedestrians, and traffic flow. The analysis of articles published between 2022 and 2025 (early access) in the post-COVID era explored the integration of machine learning and deep learning to address traffic challenges, allowing for the comparison of different approaches and the formulation of hypotheses based on the 46 articles that comprised the review corpus. Furthermore, the evaluation of the reported metrics revealed inconsistencies in the methodologies employed, attributed to the lack of standardization across the studies. In light of this, this work proposes alternatives for future experiments, emphasizing the emerging potential of the field through the adoption of new standardization systems and the exploration of experimental combinations."
  },
  {
    "year": "2025",
    "abstract": "Recent advancements in wireless technologies, particularly in the context of the sixth generation (6G) mobile communications and Internet of Things (IoT) systems, have introduced a wide range of requirements and challenges in wireless communication. These developments necessitate comprehensive channel information, encompassing the three-dimensional (3D) features of electromagnetic (EM) signals. Such signals are now typically transmitted by antenna arrays, manipulated by Reconfigurable Intelligent Surface (RIS) structures, and received by another set of antenna arrays. This complex propagation environment demands sophisticated modeling techniques to accurately capture and predict channel behavior, essential for the design and optimization of next-generation wireless systems. Ray tracing (RT) based simulators have gained significant traction in recent years, proving their worth in accurately and efficiently simulating EM propagation environments. These simulators have demonstrated remarkable accuracy in modeling complex wireless scenarios, making them invaluable tools for researchers and engineers. However, the intricate interactions between EM waves and the physical environment in three-dimensional space can still render the simulation process time-consuming, especially for scenarios with high complexity. Fortunately, recent state-of-the-art developments in Graphics Processing Unit (GPU) and Central Processing Unit (CPU) technologies have substantially mitigated this challenge. These hardware advancements have dramatically reduced the computational overhead associated with complex environmental simulations, making it feasible to conduct comprehensive and realistic RT-based analyses of sophisticated wireless environments. This paper introduces WiPy-RT, a high-performance ray tracing simulator designed for modeling RIS-enabled wireless environments. WiPy-RT features an interactive interface that leverages highly configurable and open-source Python libraries for 3D stru..."
  },
  {
    "year": "2025",
    "abstract": "Recommender systems encounter the potential problem of filter bubble, neglecting the diversity of recommendations. These systems are inevitable to lower user experience because they cannot but provide tedious recommendations. Although several solutions have been introduced to increase diversity, it is still challenging to prevent accuracy loss with diversity enhancement. This study presents a new user-oriented algorithm for session-based recommendations that aims to improve diversity in consideration of two serendipity components—relevance and unexpectedness. Specifically, our approach first adopts serendipitous preference embedding into the recommender system based on session and graph neural networks. Next, we leverage a greedy algorithm of the maximum a posteriori (MAP) inference for the determinantal point process to re-rank items. Lastly, it additionally incorporates personalized trade-off balancing through a parameter that can be controlled by the user. To validate our approach, we conducted an experiment with two real-world datasets to demonstrate its ability to balance accuracy and diversity. The results showed that our approach generated not only relevant but unexpected recommendations, successfully improving diversity without accuracy loss. This study contributes to recommendation diversification methods, especially for session-based recommender systems under the user-centric perspective."
  },
  {
    "year": "2025",
    "abstract": "Deep learning-based object detection research has primarily evolved around RGB camera imagery. While state-of-the-art models like YOLO, SSD, and RetinaNet demonstrate high accuracy in RGB images, their direct application to thermal imagery faces performance degradation due to the inherent differences between RGB and thermal characteristics, coupled with computational demands unsuitable for embedded environments. These challenges are particularly pronounced when using low-resolution thermal sensors, where object boundary ambiguity and thermal pattern uncertainty become significant obstacles. We propose FLARE (Fast and Lightweight Architecture for Real-time Estimation), an ultra-lightweight deep learning model for real-time object detection in low-resolution (32×24) thermal images. FLARE implements a Feature Compression Block for efficient feature map compression and integration, along with a Spatial Denoise Block that enables adaptive processing across temperature regions to handle thermal sensor noise characteristics. To address the scarcity of thermal data, we developed the TOI (Thermal Object Insertion) data augmentation technique, which generates new training data while preserving thermal pattern characteristics. A composite loss function combining box, classification, and confidence losses was implemented to enhance object detection performance. Implementation on an STM32 MCU demonstrated that our proposed model achieved a higher mAP compared to existing lightweight models, while reducing Flash usage by 40.39 %, RAM by 49.02 %, inference time by 35.18 %, and MAC operations by 38.00 %. Comparative experiments with YOLOv8n, a state-of-the-art lightweight object detection model, on Raspberry Pi 4B showed that FLARE achieved higher mAP (0.72% improvement) while utilizing only 4.72% of YOLOv8n’s memory consumption and achieving 11.34 times faster execution speed."
  },
  {
    "year": "2025",
    "abstract": "The use of Ultra-Dense Networks within 5G communications can be leveraged by the adoption of Millimeter-Wave (mmWave) technology for the backhaul, resulting in cost reductions and faster deployment of the infrastructure. However, this shift also introduces new concerns and restrictions. The wireless link susceptibility to signal strength and link loss degradation, due to loss of line-of-sight, makes the link quality inconsistent. The heterogeneity of network nodes poses an additional challenge for tracking link quality changes reliably. An effective network monitoring system using 5G Quality of Service (QoS) Indicators is necessary to correctly characterize and track channel and flow quality conditions in a 5G wireless backhaul. To tackle these challenges, we introduce an In-Band Telemetry (INT) approach, consisting of a P4-compatible dataplane model and an aggregation agent capable of gathering and processing per-packet measurements, exposing them as link and QoS flow quality metrics, suitable for integration with Software Defined Network (SDN) environments and 5G networks. Our study compares the accuracy achieved by the proposed in-band solution to a commercial network management system, in an outdoor test-bed with an obstructed mmWave backhaul link. The results demonstrate that this approach exhibits minimal measurement errors when assessing the throughput, latency, and Packet Error Rate (PER) of mmWave links. The solution attains an average forwarding overhead of approximately 17%, while maintaining a per-node aggregation processing total time upper-bound of 45 ms at 2.5 Gbps line rate."
  },
  {
    "year": "2025",
    "abstract": "Gastrointestinal (GI) cancers are among the most prevalent globally. Wireless capsule endoscopy (WCE), a minimally invasive technology, offers a promising alternative for diagnosing and treating GI diseases. Accurate depth estimation from WCE but remains challenging due to the complexity of the GI environment and limited datasets. In this paper, we propose an automatic endoscopic navigation system for monocular depth and ego-motion estimation in wireless capsule endoscopy (WCE) through a Transformer-based encoder-decoder network. Minimally invasive surgeries, including gastrointestinal (GI) procedures, face unique challenges such as restricted field of view, illumination variation, and texture sparsity, which complicate depth estimation and pose estimation tasks. Traditional Structure from Motion (SfM) and SLAM methods are often inadequate for GI scenes due to these inherent complexities. To address these issues, we introduce a novel self-supervised neural network framework that integrates a dual-attention mechanism within a modified ResNet. This model simultaneously predicts depth maps and ego-motion from monocular GI images, without requiring ground truth depth data. Our approach enhances feature extraction through spatial and channel-wise attention, allowing the network to capture both local and global contextual information. Furthermore, a multi-scale structural similarity index combined with L1 loss function is employed to improve the accuracy of depth estimation in challenging endoscopic environments. The model leverages a multi-interval frame sampling strategy to simulate diverse ego-motion scenarios, making it robust to low frame rate inputs typically seen in WCE. For ego-motion estimation on the ColonSim dataset, our model achieves an Absolute Trajectory Error (ATE) of 0.09 m at 30 FPS, outperforming the next-best model, SC-SfMLearner, by 44.4%. Additionally, for depth estimation, our model records an Absolute Relative Error (Abs Rel) of 0.33, a Squared Rel..."
  },
  {
    "year": "2025",
    "abstract": "In recent years, Computer-Aided Design (CAD) software have become indispensable tools for designing, testing, and synthesizing logic circuits. Commercial software provided by companies like Synopsys, Cadence, or Mentor dominate the Electronic Design Automation (EDA) field. Nevertheless, several Open Source tools are also available, and some of them aim at assisting the designer in emerging Beyond-von-Neumann computing paradigms, such as Logic-in-Memory (LiM). LiM is a promising architectural and technological solution to the von Neumann Bottleneck, i.e. the performance gap between the CPU and the memory in classical CPU-Memory structures. In literature, various approaches to the LiM paradigm have been proposed. This paper introduces the Design Explorer for In-Memory Architectures (DExIMA) tool, which has the ambitious aim of providing a well-defined design flow strategy for the development, validation and performance estimation of a wide range of LiM architectures. Currently, DExIMA focuses on Coarse-grain Logic-in-Memory (CGLiM) architectures, which integrate memory and computation elements at a coarse-grain level. Nevertheless, DExIMA encompasses a flexible architectural model and a modular performance estimation engine that can be adapted to LiM implementations where memory and logic elements are more finely integrated. Hence, DExIMA is a versatile tool offering an environment for testing and comparing different LiM solutions, empowering designers to explore novel approaches in LiM architecture design."
  },
  {
    "year": "2025",
    "abstract": "Seismic facies analysis, as a crucial step in the study of depositional facies, effectively delineates the distribution patterns of depositional facies between wells. To address the limitations of conventional manual interpretation methods, particularly their low efficiency and strong subjectivity, this study proposes a hybrid CNN-LSTM model integrated with Particle Swarm Optimization (PSO-CNN-LSTM). The model systematically extracts spatial features of seismic reflections through CNN architecture while capturing temporal waveform dependencies via LSTM networks, with PSO automatically optimizing critical parameters including initial learning rate and LSTM neuron count. Experimental results demonstrate that PSO-CNN-LSTM achieves a classification accuracy of 89.74%, surpassing CNN (81.48%), LSTM (81.63%), and basic CNN-LSTM (84.61%) models by 8.26%, 8.11%, and 5.13% respectively. The model exhibits superior performance on the SEG 2020 benchmark dataset, confirming that automated parameter optimization effectively reduces manual intervention while enhancing convergence stability. Practical applications reveal consistent interpretation outcomes between the model’s predictions (using limited training samples) and expert analyses, providing reliable evidence for identifying favorable zones in heterogeneous carbonate reservoirs. The established intelligent waveform classification workflow validates PSO-CNN-LSTM model’s robustness and offers an efficient solution for seismic facies analysis, particularly in complex geological settings."
  },
  {
    "year": "2025",
    "abstract": "DC microgrids (MGs) have emerged as an alternative interconnection method for DC-type loads and distributed energy resources (DERs). Owing to the vulnerability of grid-connected converters (GCCs) to overloading, it is crucial to effectively manage both the controllable devices within DC MGs and the power exchange through GCCs to ensure the stable and economical operation of DC MGs. Among the various types of DC MGs, this paper proposes a novel scheduling method specifically for home DC MGs, which are small-scale DC MGs, to account for various controllable devices and mitigate overloading at GCCs more effectively. The proposed method primarily addresses three limitations in the previous research: the use of device-specific models, GCC power limits expressed by hard constraints, and the absence of effective strategies for reducing the risk associated with prediction errors. Initially, controllable devices are classified into three types based on their operational characteristics: power-controllable, state-controllable, and time-controllable devices. For each of these types, a unified model is developed, which will then be used in the scheduling problem. For stable and economical operation, three prioritized strategies are proposed: 1) minimizing overloading at the GCC, i.e., GCC limits are represented by soft constraints, 2) minimizing operational costs, and 3) addressing the required power demand as quickly as possible, while delaying the use of stored energy as late as possible, thus reducing load shedding possibility due to prediction errors. The scheduling problem in which to implement these strategies is formulated as a mixed-integer nonlinear programming (MINLP) problem, for which finding optimal solutions can be challenging. Therefore, a method to relax the MINLP problem into a mixed-integer linear programming (MILP) problem is also proposed. Finally, the effectiveness of the proposed method is validated through various case studies using MATLAB."
  },
  {
    "year": "2025",
    "abstract": "Modern society is experiencing a data explosion thanks to rapid IT development and the increasing intelligence of devices. The vast and complex data can be utilized to extract actionable insight using a big data processing framework. Hadoop is a popular big data processing framework on heterogeneous commodity hardware. While Hadoop offers a robust framework for large-scale, data-intensive tasks via its MapReduce paradigm, hardware heterogeneity across nodes often leads to straggler effects that degrade Hadoop cluster performance. This paper introduces the Adaptive Node-Oriented Data placement for Efficient Hadoop Execution (ANODE) method, which leverages historical job execution data to dynamically assess each node’s processing capability. By employing an agent-based mechanism, ANODE optimizes block allocation within the data node, alleviating imbalances caused by Hadoop’s default uniform placement strategy. Experimental results on a heterogeneous eleven-node Hadoop cluster demonstrate that ANODE reduces job completion times by up to 25%, significantly enhancing data locality and resource utilization compared to the default approach."
  },
  {
    "year": "2025",
    "abstract": "The Modular Multilevel Converter (MMC) is a promising topology for STATCOM applications due to its key features, such as modularity, scalability, and reduced harmonic content. Increasing the number of voltage levels in MMC reduces harmonics but simultaneously increases the number of submodules (SMs) per arm, leading to larger sizes and higher costs, which presents a challenge. To address this, this article introduces a novel 17-level MMC-STATCOM based on the Z Packed U-Cell (ZPUC) converter as its SM, which enables the generation of more voltage levels with fewer components and reduced harmonic content, offering significant advantages in terms of size and cost. Given the complex structure of the proposed converter and the associated challenges in building a physical prototype, real-time (RT) simulation using FPGA technology is employed for validation. The key contributions include integrating the ZPUC-SM into a three-phase STATCOM for the first time and adapting the converter model and its control system to RT tools, including RT-LAB with an electric hardware solver for FPGA execution. In addition, capacitor voltage balancing and energy sorting algorithms are integrated within Phase-Shift Pulse Width Modulation, eliminating the need for an additional controller while maintaining the floating capacitors of ZPUC-SMs balanced and regulated. The specifications of the proposed converter are defined, the mathematical model and control system are derived, and a real-time implementation based on CPU and FPGA execution is built to verify the scheme. The obtained RT simulation results provide practical evidence confirming the effective operation of the proposed scheme in VAR compensation mode."
  },
  {
    "year": "2025",
    "abstract": "The sampling-based RRT* algorithm has been extensively employed for path planning. The improved variant, F-RRT*, significantly reduces the initial cost by generating new nodes; however, it also leads to increased computational time and poses challenges in narrow passage environments. To address these issues, this paper proposes an improved F-RRT* algorithm based on the Generalized Voronoi Diagram (GVD), called GVDF-RRT*. First, a sparse sampling strategy based on GVD is proposed, which improves the sampling efficiency and reduces the initial sampling nodes and initial time by guiding the random tree to explore the space quickly through GVD nodes. At the same time, the success rate of planning in narrow passage environments is improved by equalizing the sampling probability of each channel in the map. Secondly, a node direct connection mechanism is established, which reduces the redundant computation and further reduces the initial time by hierarchical processing of creation nodes, while combined with the forward optimization mechanism to optimize the paths in iteration, effectively reducing the path cost. Finally, simulations in three test environments show that, compared to RRT*, Q-RRT*, and F-RRT*, the GVDF-RRT* algorithm reduces the initial number of sampled nodes by 47.42%-76.57%, the initial time by 37.07%-86.00%, and the initial path cost by 0.47%-0.91%, while significantly improving the success rate in narrow passage environments. This further demonstrates that the proposed GVDF-RRT* significantly outperforms the baseline method in terms of initial performance and adaptability to narrow passage environments."
  },
  {
    "year": "2025",
    "abstract": "Accurate online high-definition (HD) map construction is crucial for visually impaired individuals navigating complex outdoor environments. Existing methods relying on single-frame inputs suffer from occlusions and distortions in dynamic scenes. To address these challenges, this paper proposes TMFPMap-NVIG, a novel online HD map generation framework designed specifically for assistive navigation. TMFPMap-NVIG introduces an Adaptive Feature Extractor using multi-scale strategies for capturing global and local information, a Vectorized Element Decoder that integrates hierarchical decoding and critical region prioritization to generate detailed map elements, Temporal Query Mapping for cross-frame consistency of static elements, and a Multi-Frame Feature Aggregator enhancing spatiotemporal coherence via recursive feature updates. Evaluations conducted on the nuScenes and Argoverse2 datasets show TMFPMap-NVIG surpasses state-of-the-art methods by 4.8%-15.2% in mean Average Precision (mAP), with accuracy improvements of 7.3%, 4.9%, and 2.2% for detecting crosswalks, lane lines, and road boundaries, respectively, demonstrating robust performance under environmental disturbances."
  },
  {
    "year": "2025",
    "abstract": "The rise of deep-fake technology has sparked concerns as it blurs the distinction between fake media by harnessing Generative Adversarial Networks (GANs). This has raised issues surrounding privacy and security in the realm. This has led to a decrease in trust during online interactions; thus, emphasizing the importance of creating reliable methods for detection purposes. Our research introduces a model for detecting deepfakes by utilizing an Enhanced EfficientNet B0 structure in conjunction with Temporal Convolutional Neural Networks (TempCNNs). This approach aims to tackle the challenges presented by the evolving sophistication of deep-fake techniques. The system dissects video inputs into frames to extract features comprehensively by using Multi Test Convolutional Networks (MTCNN). This method ensures face detection and alignment by focusing on facial regions. To enhance the model’s adaptability, to different scenarios and datasets we implement data augmentation techniques such as CutMix, MixUp and Random Erasing. These strategies help the model maintain its strength, against distortions found in deepfake content. The backbone of EfficientNet B0 utilizes Mobile Inverted Bottleneck Convolutions (MBConv) and Squeeze and Excitation (SE) blocks to enhance feature extraction by adjusting channels to highlight details effectively. A Feature Pyramid Network (FPN) facilitates the fusion of scale features capturing intricate details as well, as broader context. When tested on the FFIW 10 K dataset, which comprises 10,000 videos evenly split between manipulated content, the model attained a training accuracy of 91.5 % and a testing accuracy of 92.45 %, after 40 epochs. The findings showcase the model’s proficiency, in identifying videos with precision and tackling the issue of class imbalances found in datasets – a valuable contribution, to advancing dependable deepfake detection solutions. Furthermore, the model achieves an impressive balance between accuracy and computat..."
  },
  {
    "year": "2025",
    "abstract": "Aiming at the current problems of increasingly serious tailpipe pollution of urban distribution vehicles and irrational distribution route planning, we construct a fuel-electric hybrid multi-trip multi-center half-open joint distribution vehicle routing optimization model (F-EHOMTMDVRPOPTW) considering order priority and fuzzy time window, and introduce Tent chaotic mapping combined with an improved discrete sparrow search algorithm (DSSA) with stochastic key encoding strategy for solving. Based on the traditional fuel VRP, new energy vehicles are added to form a multi-energy vehicle formation. Considering the order priority and customer time window in the context of urban distribution with non-new energy vehicle restriction, and constructing a distribution model for minimizing the total cost with the transportation cost, charging cost of new energy vehicles, carbon emission and fuel consumption cost, and penalty cost for violating the time window. On the basis of the sparrow search algorithm, Tent chaotic mapping is added and random key coding strategy is inserted for discretization, which increases the diversity of the initial population of the sparrow search algorithm and improves the algorithm’s global optimization seeking ability. Finally, the algorithms and models are analyzed in simulation experiments using benchmark test functions and arithmetic examples to verify the reasonableness of the models and the effectiveness of the algorithms, which provides theoretical basis for urban distribution and utilization of energy."
  },
  {
    "year": "2025",
    "abstract": "In modern power systems, characterized by converter-interfaced generation and electronic interface loads, system inertia (Msys) is declining. While existing methods primarily focus on inertia estimation, a broader understanding of its impact on frequency response is imperative. This study proposes a comprehensive approach to quantify reserve supports beyondMsys, i.e., self-regulation (Dself) from frequency-dependent loads, governor response (FRGov), and effective governor-droop (Reff.droop) performance. Using high-resolution frequency dynamics and rate of change of frequency (RoCoF) data, a Gaussian filter (GF) is applied to remove transients and detect event onset based on RoCoF triggers. The response time frames of different ancillary support mechanisms are distinguished through robust curve fitting and RoCoF analysis over the average frequency trajectory. This method provides precise time-frequency coordinates corresponding to inertia, load, and governor response time frames. The proposed method is first validated through real-time simulation on the IEEE 24-bus system using a high-fidelity real-time digital simulator (RTDS). Additionally, it is tested on nine real-frequency excursion events following renewable generation trips in the Indian power system between May 2020 and 2023. The calculated results closely align with actual system event estimates, demonstrating the effectiveness of the approach with minimal deviations. Furthermore, a case study on operational challenges arising from high renewable energy penetration in the Indian power system on August 11, 2022, is discussed."
  },
  {
    "year": "2025",
    "abstract": "In this work, we present a generalized formulation of the Transformer algorithm by reinterpreting its core mechanisms within the framework of Path Integral formalism. In this perspective, the attention mechanism is recast as a process that integrates all possible transition paths leading to future token states, with temporal evolution governed by the feed-forward network (FFN). By systematically mapping each component of the Transformer to its counterpart in the Path Integral formulation, we obtain a more compact and efficient representation, in which the contextual information of a sequence is condensed into memory-like segments. These segments are recurrently processed across Transformer layers, enabling more effective long-term information retention. We validate the effectiveness of this approach through the Passkey retrieval task and a summarization task, demonstrating that the proposed method preserves historical information while exhibiting memory usage that scales linearly with sequence length. This contrasts with the non-linear memory growth typically observed in standard attention mechanisms. We expect that this quantum-inspired generalization of the Transformer architecture will open new avenues for enhancing both the efficiency and expressiveness of future Transformer models."
  },
  {
    "year": "2025",
    "abstract": "The passing of the CHIPS and Science Act in the United States has signaled a renewed interest in expanding the domestic semiconductor industry. To fuel this expansion and the new job opportunities it creates, academic institutions and companies alike will need to educate and train a new and growing workforce in the field of semiconductor fabrication. Unfortunately, the ability to provide hands-on learning experiences currently lacks accessibility due to the costs of starting and maintaining a cleanroom. However, extended reality (XR) offers a lower-cost alternative to address this issue. This scoping review seeks to determine the features present in existing XR environments used for semiconductor fabrication process education. Using the framework outlined by Arksey and O’Malley, only five conference articles from an initial pool of 1,116 articles were included in the review. These papers were all published between 2018 and 2023 and only focused on virtual reality devices. Across the five articles, 12 different features were identified. Notable limitations of this work include restricting the scope to six semiconductor fabrication processes, as well as excluding articles that did not specify the XR device used. Overall, the findings show that there has been very little research on the use of XR in the field of semiconductor fabrication education."
  },
  {
    "year": "2025",
    "abstract": "Segmentation of breast tumors using imaging techniques remains a critical challenge in medical diagnostics, with limitations in contrast and resolution affecting early detection. Conventional mammography methods still have some limitations in differentiating between healthy and tumorous tissue, particularly in cases with low-density differences. This study investigates the potential of combining ultrahigh-sensitivity Talbot-Lau interferometry with Convolutional Neural Networks (CNNs) to enhance breast tumor segmentation from scattering images. The research aims to improve tumor segmentation accuracy and efficiency by leveraging phase contrast imaging. The experimental setup utilized an ultrahigh-sensitivity Talbot-Lau interferometer operated with a conventional X-ray tube to generate scattering images, which were processed using a Fourier Transform-based algorithm. Five CNN architectures - U-Net, ResNet50, DeepLabV3, PSPNet, and SegNet -were trained and tested on an augmented dataset of 320 images. Performance was evaluated based on accuracy, precision, specificity, recall, and F1-score. DeepLabV3 achieved the highest accuracy (87.07%) and F1-score (90.92%), followed by PSPNet with 85.94% accuracy. However, significant fluctuations were observed in validation accuracy, indicating sensitivity to dataset variability. U-Net demonstrated the most stable performance with an accuracy of 86.34% and an F1-score of 90.2%, making it the most reliable model for tumor segmentation in scattering images. The combination of Talbot-Lau interferometry with CNNs presents a promising approach for breast tumor segmentation. U-Net emerged as the most stable model, suggesting its potential application in medical diagnostics. Future work will focus on optimizing CNN architecture and expanding the dataset to improve the segmentation of small tumor-like masses."
  },
  {
    "year": "2025",
    "abstract": "Non-invasive transcranial ultrasound imaging for older children and adults is constrained by acoustic effects caused by cranial bone in humans. There is very significant acoustic degradation of wave propagation through the cranium, particularly the diploe layer which is characterized by high porosity. Due to limited access to human skull samples for transcranial ultrasound imaging studies, the authors propose an epoxy resin-based skull-shaped phantom. This phantom mimic the multiple layers (inner/outer tables and the diploe region), enabling the creation of samples with realistic thickness and porosity variability. Appropriate material, replicating human bone composition, and poppy seeds, simulating diploe porosity, are incorporated. Using the data generated in this study, we developed a formula that allows inputting the desired acoustic properties of the skull to obtain the optimal material ratios for skull construction. The experimental evaluation setup involves acoustic transmission measurements and mechanical characteristic assessments. Results show that the developed phantoms exhibit comparable properties to actual human skulls. This research contributes to understanding and overcoming challenges in transcranial ultrasound imaging, paving the way for advancements in diagnostic tools by proposing accurate alternatives to human skulls for system design and development."
  },
  {
    "year": "2025",
    "abstract": "The performance of multilevel inverters (MLIs) in microgrids plays a vital role in managing daily fluctuations in power demand and supporting the reliable operation of renewable energy sources (RES). To enhance reliability, a 3-stage, 15-level inverter is designed, offering improved performance with a reduced number of switches and lower Total Harmonic Distortion (THD). The number of switches is lowered by using a better Pulse Width Modulation (PWM) method, and Artificial Neural Network (ANN) algorithms help with finding faults. The research integrates both PWM and ANN techniques to enhance the power quality of multilevel inverters (MLIs). A controller using an ANN and a Field-Programmable Gate Array (FPGA) is suggested to correctly identify problems and measure Total Harmonic Distortion (THD) in different fault situations. Datasets for training and testing the ANN models are collected from MATLAB simulations and experimental setups. The performance of different ANN algorithms is analyzed to identify the most effective approach. Fault classification is conducted based on THD measurements for various fault types, including first module failure, second module failure, third module failure, single switch failure, two switches failing in the same leg, and two switches failing in different legs."
  },
  {
    "year": "2025",
    "abstract": "Calibration is essential for risk evaluation in various fields; including medicine, finance, and reliability analysis. Although extensive research has focused on calibration in classification and regression tasks using deep neural networks, survival analysis remains relatively underexplored, resulting in the lack of improved calibration methods. In particular, while previous work has proposed a calibration method for survival analysis, it relies on fixed bins, which can lead to biased calibration assessments and substantial loss of predictive accuracy in pursuit of calibration. This gap can hinder an accurate assessment of survival functions, leading to increased risk management costs. In this study, we introduce Stochastic Explicit Calibration (S-cal), an algorithm that employs random intervals instead of fixed bins, thereby advancing the calibration methods used in deep networks. The calibration performance of S-cal is evaluated using metrics specifically designed for handling censored data, such as D-calibration and the Kolmogorov-Smirnov metric. Extensive experiments on synthetic and real-world datasets demonstrate that S-cal consistently outperforms existing methods in terms of calibration accuracy. In addition, we highlight how improved calibration can improve downstream tasks, including optimizing resource allocation and improving patient care decisions. This work presents a significant advancement in the study of calibration for survival analysis, offering valuable information for more reliable risk assessment models."
  },
  {
    "year": "2025",
    "abstract": "Context-aware beam management in millimeter-wave (mmWave) wireless communication systems has received increasing attention over the past few years. Machine learning (ML) has played a key role in leveraging different types of context information from the device position and orientation to more ambitious scenarios using RADAR, LIDAR, or camera images. However, most studies in this area consider simplified configurations for user terminals without considering the self-blockage effects owing to the user’s hand and body. This study is a step towards more realistic configurations and scenarios, where methods for location- and orientation-aware beam alignment are evaluated for multi-panel hand-held devices under mild and severe self-blockage conditions. We propose deterministic and probabilistic hand grip schemes that determine the blockage status of device panels. The probabilistic schemes are introduced to account for the inherent randomness of self-blockage owing to variations in the user’s hand grip. Contrary to the blockage models that introduce attenuation in multipath components depending on their angles-of-arrival, we propose two blockage models that introduce blockage losses over all the received paths, which more realistically emulate panels blocked by “hard” hand gripping. Our numerical simulations show that the multi-panel ML-based beam alignment method is capable of leveraging the terminal’s location and orientation information even under severe self-blockage conditions, achieving performance close to genie-aided alignment with just a few beam-pair measurements."
  },
  {
    "year": "2025",
    "abstract": "The recent leap in Large Language Models (LLMs) has paved the way for several research ideas. LLMs are employed not only for personal use but also in professional contexts to enhance human productivity at work. A significant area of research is human-robot collaboration (HRC), which focuses on developing methodologies for effective interaction between humans and AI-enabled machines. In this regard, exploitation of LLMs appears to be a practical approach. However, these models are susceptible to several limitations, including context-induced errors, the propagation of misleading information, and hallucinations. Such deficiencies impede the seamless application of LLMs in scenarios where a high degree of accuracy is essential. To address this issue, this study introduces a dual-agent system designed to validate the responses generated by LLMs. This novel system is integrated into a framework called “CogniVera”, which facilitates collaborative tasks involving a collaborative robot (cobot) through vocal interactions. This initiative represents a significant advancement in HRC, enabling robots to communicate vocally with human operators during assembly tasks. To evaluate the feasibility of this approach, a focused case study will be conducted, concentrating on the human-robot collaborative task of box assembly utilizing vocal communication. The outcomes of this study are anticipated to yield valuable insights into the efficacy of the proposed dual-agent system in enhancing the reliability and performance of LLMs in practical applications."
  },
  {
    "year": "2025",
    "abstract": "This paper examines customers’ online shopping behavior and its relationship to purchase decisions. There are two research questions for the paper: 1) How can marketers segment prior customers’ online shopping behavior to develop a more accurate consumer segmentation for forecasting purchase behavior? 2) Which factors influence customers’ online shopping behavior? The analysis used a dataset of 12,330 samples with ten continuous and eight categorical variables. Cluster and logistic regression analyses were conducted on the dataset. Cluster analysis grouped customers by operating system, browser, location, and traffic type, while logistic regression estimated online customers’ purchase intentions. The results show that different factors influence various customer segments. In Group 1, administrative factors, product-related duration, exit rate, and page value significantly affect purchase behavior. In Group 2, product-related factors, exit rate, page value, and special days play an important role. In Group 3, product-related factors, bounce rate, page value, and visitor type are key factors. This paper contributes by using cluster analysis and logistic regression to segment online customer usage behavior and forecast purchase behavior. It evaluates key predictors of online shopping behavior that differ across customer groups, supporting targeted marketing strategies and decision-making."
  },
  {
    "year": "2025",
    "abstract": "The state of health (SOH) can usually be described by an exponential model. Traditional least squares and gradient descent algorithms are inefficient for such a special model. In this paper, a Volterra series model is used to approximate the exponential SOH model, where some of the collected data are contaminated by outliers. To alleviate the harmful effects caused by the outliers, a weighted least squares algorithm and a weighted gradient descent algorithm are proposed. The algorithms can adaptively ignore those data which are contaminated by outliers, and only utilize the normal data to identify the Volterra model. Compared with the traditional algorithms, the proposed methods have the following advantages: 1) approximated model has a more simple structure; 2) proposed algorithms can adaptively ignore those data which are contaminated by outliers. A simulation example demonstrates the effectiveness of the proposed methods."
  },
  {
    "year": "2025",
    "abstract": "This study proposes a scheme for determining the loss of synchronism in synchronous generators based on the direct method, utilizing a single local speed measurement within a generator system. By employing individual machine energy functions, this approach establishes a theoretical foundation for determining synchronization thresholds from the perspective of a single generator. Building on this foundation, clear criteria are suggested for determining whether a generator remains stable. The feasibility of the proposed method is verified through its application to synchronous generators, considering a comprehensive setup environment for implementing the proposed algorithm. Case studies are conducted using time-domain simulations in MATLAB/Simulink on the IEEE 39-bus system with varying system inertia and the IEEE 118-bus system. These case studies evaluate the robustness of the proposed criteria and algorithm in determining out-of-step conditions from an energy conversion perspective, analyzing variations in system inertia, control system parameters, power system scale, and fault scenarios across benchmark systems. Furthermore, the performance of the proposed protection scheme is compared with previous studies, highlighting its advantages. By interpreting the loss of synchronism phenomenon using only local measurements from existing systems, the proposed scheme demonstrates robustness against changes in the characteristics of the connected power system. It also simplifies the detailed settings required for effective operation of the protection scheme."
  },
  {
    "year": "2025",
    "abstract": "Short-Term Load Forecasting (STLF) is essential for ensuring efficient and reliable power system operations, requiring accurate predictions of electricity demand. Deep Residual Networks (DRNs), with their ability to mitigate gradient vanishing and model complex nonlinear relationships in load data, have emerged as a powerful tool for STLF. This study evaluates the performance of various activation functions within DRN models, focusing on their impact on predictive precision and generalization. Experiments were conducted using the DRN architecture for STLF on two distinct datasets: ISO-NE and Malaysia. The findings demonstrate that activation functions significantly influence the predictive performance of DRN-based STLF models. Specifically, the DRN model using Swish achieved the best results on the ISO-NE dataset (Mean Absolute Percentage Error, MAPE = 1.3806%), while the DRN model with Hyperbolic Tangent (Tanh) excelled on the Malaysia dataset (MAPE = 4.9809%). These results underscore the importance of aligning activation function selection with dataset characteristics to optimize the performance of DRN models in STLF. This study provides valuable insights for advancing STLF research and guiding practical applications in load forecasting."
  },
  {
    "year": "2025",
    "abstract": "This study investigates the application of advanced fine-tuned Large Language Models (LLMs) for Turkish Sentiment Analysis (SA), focusing on e-commerce product reviews. Our research utilizes four open-source Turkish SA datasets: Turkish Sentiment Analysis version 1 (TRSAv1), Vitamins and Supplements Customer Review (VSCR), Turkish Sentiment Analysis Dataset (TSAD), and TR Customer Review (TRCR). While these datasets were initially labeled based on star ratings, we implemented a comprehensive relabeling process using state-of-the-art LLMs to enhance data quality. To ensure reliable annotations, we first conducted a comparative analysis of different LLMs using the Cohen’s Kappa agreement metric, which led to the selection of ChatGPT-4o-mini as the best-performing model for dataset annotation. Our methodology then focuses on evaluating the SA capabilities of leading instruction-tuned LLMs through a comparative analysis of zero-shot models and Low-Rank Adaptation (LoRA) fine-tuned LlaMA-3.2-1B-IT and Gemma-2-2B-IT models. Evaluations were conducted on both in-domain and out-domain test sets derived from the original star-ratings-based labels and the newly generated GPT labels. The results demonstrate that our fine-tuned models outperformed leading commercial LLMs by 6% in both in-domain and out-domain evaluations. Notably, models fine-tuned on GPT-generated labels achieved superior performance, with in-domain and out-domain F1-scores reaching 0.912 and 0.9184, respectively. These findings underscore the transformative potential of combining LLM relabeling with LoRA fine-tuning for optimizing SA, demonstrating robust performance across diverse datasets and domains."
  },
  {
    "year": "2025",
    "abstract": "genai and communication networks are expected to have groundbreaking synergies for 6G. Connecting Generative Artificial Intelligence (GenAI) agents via a wireless network can potentially unleash the power of Collective Intelligence (CI) and pave the way for Artificial General Intelligence (AGI). However, current wireless networks are designed as a “data pipe” and are not suited to accommodate and leverage the power of GenAI. In this paper, we propose the GenAINet framework in which distributed GenAI agents communicate knowledge (facts, experiences, and methods) to accomplish arbitrary tasks. We first propose an architecture for a single GenAI agent and then provide a network architecture integrating GenAI capabilities to manage both network protocols and applications. Building on this, we investigate effective communication and reasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI agents extract semantics from heterogeneous raw data, build and maintain a knowledge model representing the semantic relationships among pieces of knowledge, which is retrieved by GenAI models for planning and reasoning. Under this paradigm, different levels of collaboration can be achieved flexibly depending on the complexity of targeted tasks. Furthermore, we conduct two case studies in which, through wireless device queries, we demonstrate that extracting, compressing and transferring common knowledge can improve query accuracy while reducing communication costs; and in the wireless power control problem, we show that distributed agents can complete general tasks independently through collaborative reasoning without predefined communication protocols. Finally, we discuss challenges and future research directions in applying Large Language Models (LLMs) in 6G networks."
  },
  {
    "year": "2025",
    "abstract": "This study presents a preventive care system for monitoring sudden infant death syndrome (SIDS), integrating digital image infosecurity and facial expression recognition (FER) technologies. For image infosecurity, a symmetric advanced encryption standard (SAES)-based scheme is introduced to ensure the secure transmission of infant images over public communication channels. In the FER, the YOLOv10 (You Only Look Once, version 10)-based classifier functions as an automatic object detection (OD) framework, enabling infant facial capture and expression recognition. Its classification mechanism categorizes expressions into four classes: normal, smile, sleep, and crying. Thus, to ensure secure SIDS monitoring, the SAES-based scheme implements robust block encryption and decryption processes to protect the privacy and security of infant images, while the YOLOv10 model enhances real-time OD, feature extraction, and pattern recognition capabilities. In experimental evaluations, a dataset of 5000 different facial expression images was self-collected and labeled with four classes of expressions. For training the YOLOv10-based classifier, the dataset was split into 60% for training (3,000 images) and 40% for testing (2000 images). The stochastic gradient descent (SGD) algorithm was employed to optimize the classifier’s model parameters for further enhancing accuracy for the intended purposes. For image infosecurity testing, the number of pixel changing rate (NPCR), unified averaged changed intensity (UACI), and structural similarity index measurement (SSIM) were employed to evaluate the performances for encryption and decryption processes, ensuring confidentiality, recoverability, and availability of transmitted images. For FER testing, the ten-fold cross-validation method was applied to evaluate the classifier’s performances, and the feasibility of the proposed method could be evaluated, achieving average Precision (%) of 91.40%, average Recall (%) of 91.15%, and average Accur..."
  },
  {
    "year": "2025",
    "abstract": "This study explores the development of a 28 GHz array antenna with beam-steering capability, consisting of four elements with dual linear polarization at ±45 degrees. We propose a method for synthesizing the array antenna’s radiation pattern using an active element pattern-deep neural network (AEP-DNN). Beam-steering has become an attractive feature for researchers, as it enables users to move freely without affecting signal strength. An array analysis was conducted using a feedforward deep neural network (DNN) to generate a radiation pattern that achieves the desired steering angles. The proposed method takes radiation patterns as inputs and outputs the corresponding phase values for the antenna elements. The training dataset for the array antenna consisted of 6,859 radiation patterns, generated by adjusting the antenna element phases, which were then used to train the DNN model with minimal complexity. The radiation pattern was computed using AEP method since it is faster and less complex compared to full-wave modelling methods. The DNN model was initially tested using radiation patterns from an ideal square shape. After training, the model was evaluated by inserting desired beam-steering angles of 5 and 10 degrees, and it was found that the radiation pattern produced by the DNN closely matched the intended input pattern. The DNN learning process takes approximately 2 to 3 minutes in terms of processing time. The training and validation Root Mean Square Error (RMSE) and loss values converge to a minimum range of 1.3 to 2.3. Furthermore, the AEP-DNN method was successfully validated using the pattern multiplication method, full-wave modelling, and measurement methods to verify the feasibility and reliability of the training and validation data, as well as the resulting radiation pattern. This antenna, incorporating AEP-DNN technology, holds significant potential for various applications, particularly in mobile communications."
  },
  {
    "year": "2025",
    "abstract": "Nonlinear dimensionality reduction techniques, often referred to as manifold learning, are increasingly valuable for data visualization and unsupervised clustering. In the context of surgery and medicine, these methods facilitate the analysis of complex datasets, enabling pattern recognition in surgical data. This study explores the characterization of six tissue types through manifold learning and unsupervised clustering, utilizing vibro-acoustic (VA) signals collected from manual palpation experiments. A wireless sensor mounted at the tip of a surgical instrument was used to acquire 1,680 VA signals, which were processed using Fourier transform and cepstral analysis for feature extraction. We assessed the performance of two dimensionality reduction techniques: uniform manifold approximation and projection (UMAP) and variational autoencoder (VAE). Results indicate that cepstral features combined with UMAP yield superior clustering performance compared to VAE, achieving higher classification accuracy (92%vs.87%) and better-defined clusters with greater compactness. The observed differences in performance are linked to the intrinsic properties of the tissues, particularly surface characteristics such as friction and moisture, which affect signal consistency. Additionally, we compared our approach with previous works, including a study utilizing the same dataset, where our methodology demonstrated improved accuracy. Future research will focus on refining the VAE model, increasing the diversity of tissue samples, and validating the proposed approach in real surgical settings to enhance its applicability in minimally invasive surgery."
  },
  {
    "year": "2025",
    "abstract": "Predicting the locations an individual will visit in the future is crucial for solving many societal issues like disease diffusion and pollution reduction. However, next-location predictors often require a significant amount of individual-level information that may be scarce or unavailable (e.g., in cold-start scenarios). Large Language Models (LLMs) have demonstrated strong generalization and reasoning capabilities while being rich in geographical knowledge, suggesting that they can operate as zero-shot next-location predictors. In our study, we evaluate over 15 LLMs on three real-world mobility datasets and find that they achieve accuracies up to 36.2%, representing a relative improvement of almost 640% compared to traditional models designed for human mobility. We further assess data contamination risks and explore the potential for using LLMs as text-based explainers for next-location predictions. Our results indicate that, irrespective of model size, LLMs can both predict and justify their decisions effectively."
  },
  {
    "year": "2025",
    "abstract": "The interpretation of intermediate representations in deep neural networks is critical for enhancing the transparency, trustworthiness, and applicability of artificial intelligence (AI) systems. In this paper, we propose SymbolNet, a framework that extracts mid-level features from trained models and transforms them into human-interpretable symbolic representations. SymbolNet constructs a symbolic graph composed of nodes and edges that capture both the semantic meaning and relational structure within the model’s internal reasoning process. This symbolic decoding bridges the model’s internal computations with human cognitive understanding, enabling structured and meaningful interpretation of AI behavior. Experimental results on the GTSRB dataset demonstrate that SymbolNet improves classification accuracy by 4% over the baseline and significantly enhances robustness against various noise conditions and adversarial attacks. Our work contributes to the field of explainable AI by introducing a novel approach that reveals the internal learning dynamics of non-interpretable models through symbolic reasoning."
  },
  {
    "year": "2025",
    "abstract": "With the rapid development of high-voltage direct current (HVdc) transmission technology, the demand for monitoring the DC total electric field at ground level has increased significantly. The methods of the traditional electric field measurement are susceptible to noise interference, which affect the accuracy of measurement. This paper investigates the sources of noise interference in electric field measurements and proposes a signal processing method based on amplifier parallel optimisation of the signal conditioning circuit and Morlet wavelet decomposition. By improving the signal-to-noise ratio during the measurement of the device, the anti-interference capability and measurement accuracy of the field mill sensor are significantly enhanced. The experimental results show that the proposed signal processing methods of amplifier parallel optimisation signal conditioning circuit and Morlet wavelet decomposition can effectively eliminate the interfering signals during the measurement process, improve the signal-to-noise ratio of the measurement circuit, and retain the details and response speed of the signals, which improves the accuracy of the measurement of the ground electric field of the ultra-high-voltage direct current transmission."
  },
  {
    "year": "2025",
    "abstract": "Building fast and reliable maps of the environment is a fundamental task for autonomous navigation. However, this process offers several challenges such as accurate registration of 3D point clouds. Recently, non-repetitive scanning LiDAR sensors have emerged as a promising alternative for 3D data acquisition, leveraging some of these challenges. In this paper, we present a 3D point cloud registration method that exploits the unique scanning pattern of such a sensor to register successive 3D scans. Errors accumulated over larger distances due to drift as well as registration errors due to the presence of dynamic objects in the scenes were improved by re-enforcing the registration method by first segmenting and classifying static and dynamic objects by analyzing the deformation in the unique, non-repetitive, Spirograph-type, scanning pattern of the sensor and then incorporating a fast NDT (Normal Distribution Transform) based registration method as well as loop closure detection for fine alignment. The novel method is then extended to build and update fast dynamic maps of the environment for trajectory planning for autonomous navigation. The proposed method is evaluated on three real and different datasets and compared with other state-of-the-art methods. The results not only demonstrates the suitability of these types of sensors for such applications but also show that the proposed method is comparable with other methods in terms of accuracy and surpasses them in performance in terms of processing time, making it suitable for real time applications."
  },
  {
    "year": "2025",
    "abstract": "This paper presents an optimization approach for managing the charging and discharging of electric vehicles (EVs) in parking lots using the Harmony Search (HS) and Differential Evolution (DE) algorithms. The study is conducted on a standard IEEE 33-bus grid considering three EV penetration levels: 11.3%, 35%, and 45%. The objective is to minimize operational costs while improving grid performance. Simulation results indicate that increasing EV penetration slightly raises overall expenses due to the higher cost of vehicle charging compared to the revenue from discharging. However, EV participation significantly reduces ohmic losses and improves the grid load profile. The proposed HS algorithm outperforms the DE algorithm by achieving lower microgrid costs and better convergence efficiency. Specifically, HS reduces energy losses by up to 40%, demonstrating its effectiveness in optimizing energy management for microgrids with high EV integration."
  },
  {
    "year": "2025",
    "abstract": "The increasing penetration of renewable energy sources (RESs) has led to the proliferation of small-scale distributed energy resources (DERs) in modern power systems. Effective coordination of these DERs in active distribution systems benefits both utilities and consumers. This paper introduces a novel distributed active voltage and operation cost control (DAVOCC) framework designed to minimize node voltage deviations and operation costs. The proposed framework employs a multi-objective optimization approach, integrating three advanced algorithms: multi-agent proximal policy optimization (MAPPO), multi-agent asynchronous actor-critic (MAA2C), and multi-agent twin delayed deep deterministic policy gradient (MATD3). Battery energy storage systems (BESSs) and diesel generators (DGs) are used as heterogeneous agents, with their actions being constrained within predefined limits to ensure safe operation. The proposed framework is trained and tested on real-world data in a modified IEEE 33-node distribution system by featuring centralized training and decentralized execution (CTDE) framework. The obtained results demonstrate that three algorithms effectively maintain node voltage deviations within acceptable limits, with the MATD3-based algorithm achieving superior performance. Specifically, it delivers node voltage deviations close to nominal values, with an average deviation of 0.0042 p.u. and a standard deviation of 0.0065 p.u. Furthermore, the MATD3 algorithm reduces operational costs to 56,837.85 THB/day while generating the highest net profit of 725,943.71 THB/day from energy trading. These findings underscore the potential of the developed DAVOCC framework in optimizing the power management of BESSs and DGs, reducing the dependence on external grid energy and ensuring effective voltage regulation in active distribution systems."
  },
  {
    "year": "2025",
    "abstract": "This study examines the influence of Fear of Missing Out (FoMO) on continuous usage of social commerce platforms (SCPs) and explores its psychological and behavioral ramifications within the context of attention economy. Drawing on Self-Determination Theory (SDT) and Information Overload Theory (IOT), a survey of 872 active social commerce platform (SCP) users was conducted. Structural Equation Modeling (SEM) in SmartPLS 4 was utilized to analyze direct, indirect, and moderating relationships among key constructs, including Psychological Anxiety (PA), Nomophobia (NOMO), and Problematic Social Media Use (PSMU). The results indicate that FoMO substantially drives compulsive platform usage (β=0.453, p < 0.001), strongly predicts PSMU (β=0.826, p < 0.001), and indirectly increases psychological anxiety, nomophobia, phubbing behavior, and social network fatigue. Furthermore, informational incentives (e.g., personalized content, real-time updates) significantly amplify users’ anxiety, fatigue, and compulsive digital behaviors by exacerbating cognitive overload (interaction effects ranging fromβ=0.059to 0.178, p < 0.001). Overall, the findings underscore the dual role of SCPs as both facilitators of engagement and sources of psychological strain, emphasizing the necessity of sustainable digital marketing strategies that prioritize user well-being. These insights offer valuable implications for academic researchers and industry practitioners, suggesting that integrating SDT and IOT can advance our understanding of the multifaceted relationships among FoMO, platform usage, and psychological health in the digital era."
  },
  {
    "year": "2025",
    "abstract": "The enormous benefits of Internet of Things (IoT) technology have driven its deployment in various applications. Additionally, the development of quantum computers has directed attention towards lattice-based cryptography. Consequently, the computational capabilities of quantum computers pose a threat to the security of the existing IoT signature mechanisms. Quantum computers are proficient at unraveling the complexity bound of computationally hard problems like the integer factorization problem (IFP) and the discrete logarithm problem (DLP). As a result, security is an essential requirement for the IoT communication network against quantum attacks. The amalgamation of certificateless public key cryptosystems (CL-PKC) and lattice-based cryptography (LBC) is one of the solution for alleviating these security menaces. Lucidly, CL-PKC prevents key escrow issues and key management problems; LBC prevents quantum attacks. The Shortest Integer Solution (SIS) problem, which the NTRU lattices offer, serves as the basis for this paper’s introduction of a certificateless signature mechanism for IoT environments. By adopting the Random Oracle Model, we demonstrated the security of the suggested mechanism against Type 1 and Type 2 attackers. Furthermore, security analysis and performance evaluation demonstrate robust communication, as evidenced by metrics such as the computational cost of CL-Sign and CL-Verify phases at536μs,376.81μsand communication cost of KGC at 418 bits, CL-Sign at 532 bits and CL-Verify at 446 bits. Also, we calculate the cost of single-message signature generation and verification on an IoT device. These results show that the suggested mechanism’s security and computational efficiency are more reliable, and efficient than other relevant competing frameworks."
  },
  {
    "year": "2025",
    "abstract": "With the increasing accuracy of machine-learning models in recent years, explainable artificial intelligence (XAI), which allows for an understanding of the internal decisions made by these models, has become essential. However, many explanation methods are vulnerable to outliers and noise, and the results may be distorted by extreme values. This study devised a new method named HuberAIME, which is a variant of approximate inverse model explanations (AIME) and is robust to the Huber loss. HuberAIME limits the impact of outliers by weighting with iterative reweighted least squares and prevents the feature importance estimation of AIME from being degraded by extreme data points. Comparative experiments were conducted using the Wine dataset, which has almost no outliers, the Adult dataset, which contains extreme values, and the Statlog (German Credit) dataset, which has moderate outliers, to demonstrate the effectiveness of the proposed method. SHapley Additive exPlanations, AIME, and HuberAIME were evaluated using six metrics (explanatory accuracy, sparsity, stability, computational efficiency, robustness, and completeness). HuberAIME was equivalent to AIME on the Wine dataset. However, it outperformed AIME on the Adult dataset, exhibiting high fidelity and stability. On the Germain Credit dataset, AIME itself showed a certain degree of robustness, and there was no significant difference between AIME and HuberAIME. Overall, HuberAIME is useful for data that include serious outliers and maintains the same explanatory performance as AIME in cases of few outliers. Thus, HuberAIME is expected to improve the reliability of actual operations as a robust XAI method."
  },
  {
    "year": "2025",
    "abstract": "In the field of short-term power load prediction, the current prediction methods have low prediction accuracy. To address this issue, this study introduces level processing method and improved grey wolf genetic algorithm to predict short-term power load and optimize the power load prediction accuracy. The genetic algorithm is applied to optimize the traditional grey wolf algorithm. Then, combined with the level set algorithm in the level processing algorithm, a genetic grey wolf hybrid model that integrates level processing is constructed. The variables in the load data are processed and analyzed through the level set algorithm. The final position of the population is determined based on the improved grey wolf genetic algorithm. Comparative experiments are conducted among the proposed model, the long short-term memory model, as well as the variational mode decomposition model. The average prediction accuracy remained within 0.652-0.859, significantly higher than the other two comparative models. The mean absolute error was 1.869, significantly lower than the other two models. The F1 score and accuracy were 0.891 and 90.32%, demonstrating that its predictive performance was significantly better than the other two models. Precision-recall curve, accuracy, mean absolute error, F1 score and other indicators are applied to evaluate the performance of the three models. The proposed model can accurately perform load prediction analysis in short-term power load prediction, and its prediction performance exceeds the other two prediction models. The prediction method can accurately predict short-term power load, providing useful references and inspirations for future researchers in power load prediction, and promoting the continuous development and progress of short-term power load prediction technology."
  },
  {
    "year": "2025",
    "abstract": "Text similarity is a crucial area of study that evaluates how similar texts are both semantically and syntactically. As data volumes increase, understanding the similarities and relationships between texts becomes essential, particularly in natural language processing (NLP) tasks such as text generation, summarization, and classification. This study examines the similarities between human-written scientific abstracts, AI-paraphrased abstracts, and AI-generated abstracts. Various methods, including cosine similarity, Word2Vec, and BERT, were evaluated based on mean, median, and standard deviation metrics. Among these, Word2Vec and FastText achieved the highest mean similarity scores (0.930), while BERT demonstrated superior performance with the highest median (0.841) and the lowest standard deviation (0.019) in the ‘Human-Paraphrased’ category, showing consistent results across datasets. Additionally, the research investigates the implications of these similarities for text analysis and ethical standards, comparing various techniques for measuring text similarity and analysing their effectiveness. The findings offer valuable insights into the application areas of text similarity analysis."
  },
  {
    "year": "2025",
    "abstract": "Wind power has emerged as a vital renewable energy source. However, its inherent temporal variability and non-stationarity pose significant challenges for accurate forecasting. To solve this problem, this study proposes a novel multi-step wind power forecasting model based on an encoder-decoder architecture. It incorporates a multi-frequency attention mechanism into a multi-layer long short-term memory (LSTM) network. The former increases the ability of the model to capture long-term dependencies and global features, while the later focuses on short-term internal dynamics. Together, they allow the model to accurately extract critical frequency information across various time scales, and adaptively emphasize key features within the temporal domain. The experimental results show that the proposed model outperforms different benchmark methods in terms of many performance indicators, including the mean absolute error, mean squared error, and root mean squared error. This demonstrates its high potential to provide technical support for the precise wind power forecasting, and to contribute to the efficient integration of wind energy into power grids."
  },
  {
    "year": "2025",
    "abstract": "Inverter-based Distributed Energy Resources (DERs) third-party compliance testing has been widely required by most grid codes to guarantee interoperability with the electrical power system. However, most grid code certification procedures only accept the evaluation of the whole product under full-power environments. For high-power equipment, this procedure is costly, time-intensive, and complex to be performed. Due to this, many efforts have been made to make possible using Controller Hardware-in-the-Loop (CHIL) testing for validation of the inverter firmware from early product development through final certification, facilitating the identification of early issues and reducing debugging time and costs. On the other hand, since most CHIL tests are performed in environments distinct from full power laboratory testing, both approaches often follow different procedures and do not take into account the same metrics, which can result in low fidelity between CHIL and power laboratory results. In order to make possible to use CHIL for compliance testing, model validation has to be performed, guaranteeing that model fidelity is satisfactory. In this context, this paper presents a comprehensive methodology to validate CHIL models and to clearly identify, measure, and reduce differences between the results obtained with CHIL and with power laboratory testing environments. The methodology is based on standardized quantitative test procedures applied to both CHIL and power laboratory testing. The proposed methodology is extensively validated through experimental results carried out on a commercial single- phase photovoltaic inverter. Results demonstrate the validity of CHIL testing methodology and propose an alternative method for grid code compliance testing and certification."
  },
  {
    "year": "2025",
    "abstract": "Many international manufacturers of infant incubators use IoT technology, presenting tough competition for local manufacturers. This research examines methods to fulfill parents’ need to monitor their babies directly when they are lying inside an incubator. This bridges the gap present in neonatal care units. As such, this study proposes a prototype for an incubator that employs IoT along with different sensors to monitor babies occupying these incubators in real time and send the data to a remote server. With the different technologies used in this monitoring system, parents have the ability to listen to their babies remotely through a mobile application. A convolutional neural network (CNN) algorithm is used to take neonatal care a step further. It then goes beyond monitoring by interpreting the nature of a baby’s cries inside the specified incubator. The proposed prototype represents a step forward in the applications of Industry 4.0 in healthcare, especially those related to infant care and, more specifically, incubators for babies. This research is part of advancements in the use of IoT and handheld applications for the future development of baby incubators, fulfilling the needs of parents to constantly monitor their infants and neonatal care, specifically within modern healthcare."
  },
  {
    "year": "2025",
    "abstract": "With the advent of advancements in future sixth-generation (6G) communication systems, Internet of Things (IoT) devices, characterized by their limited computational and communication capacities, have become integral in our lives. These devices are deployed extensively to gather vast amounts of data in real-time applications. However, their restricted battery life and computational resources present significant challenges in meeting the requirements of advanced communication systems. Mobile Edge Computing (MEC) has emerged as a promising solution to these challenges within the IoT realm in recent years. Despite its potential, securing MEC infrastructure in the context of IoT remains an open task. This study explores the operational dynamics of a secured IoT-enabled MEC infrastructure, focusing on providing real-time, on-demand, secure computational resources to low-powered IoT devices. It outlines a joint optimization problem to maximize computational throughput, minimize device energy consumption, reduce computational latency, and mitigate security overhead. An optimization algorithm is introduced to address these challenges by jointly allocating resources, thereby optimizing throughput, conserving energy, and meeting latency benchmarks through dynamic system adaptation. The effectiveness of the proposed model and algorithm is demonstrated through comparisons with relevant benchmark schemes, highlighting its efficiency in various scenarios. This work showcases the potential of advancements in encryption to deliver scalable security solutions with reduced resource consumption as the number of devices increases."
  },
  {
    "year": "2025",
    "abstract": "Cardiovascular diseases (CVDs), particularly coronary artery disease (CAD), remain the leading cause of global mortality, necessitating advanced diagnostic solutions. Accurate deformable image registration plays a crucial role in enhancing segmentation precision and classification performance in cardiovascular imaging. However, existing registration methods, including VoxelMorph, face limitations in computational efficiency and memory usage, restricting their real-time applicability for high-resolution cardiac imaging. This study proposes the Mamba-Optimized VoxelMorph framework, which leverages GPU-based parallelization and memory optimization to address these challenges. The framework achieves superior registration accuracy, yielding a Dice Similarity Coefficient (DSC) of 0.95 and Normalized Cross-Correlation (NCC) of 0.90, while reducing computational time by 40% and memory usage to 800 MB. These advancements ensure efficient alignment of complex cardiac structures, thereby improving segmentation accuracy and classification reliability. By addressing these critical limitations, the Mamba-Optimized VoxelMorph framework significantly enhances cardiovascular imaging, enabling precise, scalable, and real-time deformable image registration for improved CAD diagnosis and treatment planning."
  },
  {
    "year": "2025",
    "abstract": "Aiming at the problem of low accuracy in solder joint defect detection caused by the complex background and difficult to extract defect features of circuit boards using through-hole technology (THT), an improved YOLOv8 solder joint defect target detection algorithm was proposed. Firstly, the FasterNet module was used to improve the C2f module of the baseline model, and the Efficient Multi-Scale Attention (EMA) attention mechanism was integrated to reduce model parameters and make the algorithm pay more attention to the solder joint targets. Secondly, the neck network of the baseline model was reconstructed and the Slide Loss function was introduced. The fusion of bidirectional cross scale connections and weighted features improved the feature extraction ability of the model and the detection accuracy of solder joint defects. Finally, the improved algorithm was experimentally validated on the target detection dataset of solder joint defect, and its generalization ability was also verified. Results indicate that the algorithm not only has a good detection performance on solder joint defects, but also has strong generalization ability and robustness."
  },
  {
    "year": "2025",
    "abstract": "Android malware poses a significant cybersecurity threat, enabling unauthorized data access, financial fraud, and device compromise. Although deep learning methods are widely used for malware detection, they often struggle with stability and adaptability in the face of evolving threats. While large language models (LLMs) have shown promise in this area, their application to Android malware detection remains underexplored, particularly with regard to optimizing the semantic relationships within Android application packages (APKs). To address this gap, we introduce LLM-MalDetect, a novel framework that improves LLM-based APK analysis by explicitly modeling semantic dependencies and leveraging structured prompt engineering for optimized detection. Our approach formalizes LLM adaptation through a robust string-based feature extraction method and a tailored fine-tuning strategy to enhance precision. Evaluations on benchmark datasets demonstrate that LLM-MalDetect achieves up to 98.97% accuracy, outperforms existing methods in terms of robustness, and enables real-time analysis."
  },
  {
    "year": "2025",
    "abstract": "Constrained Application Protocol (CoAP) is a widely used communication protocol in Internet of Things (IoT) networks. Congestion is a major concern in IoT networks because it affects the performance of applications and network reliability. Congestion control (CC) must be employed by the application since CoAP is based on User Datagram Protocol (UDP). IoT devices transfer a burst of data upon event detection. There are suitable features in Non-confirmable (NON) message type of CoAP for burst data transfer. The absence of a CC method for NON message type in CoAP hinders its applicability. OBSERVE defines static rate control for NON messages which is inappropriate for dynamic needs. The Block-wise Transfer also employs static rate control for NON message blocks, resulting in the same limitation. CoAP simple congestion control/advanced (COCOA) provides a dynamic CC method for the NON message type. COCOA employs reliable packets inside the NON message burst at regular intervals to capture network dynamics. Infringement of reliable packets adds up overhead and periodic monitoring caters to insufficient vigilance. In this paper, we propose a window-based dynamic congestion control method called Win CoAP to regulate the burst traffic based on the window of packets. The window size is additively increased on successful delivery and adaptively decreased otherwise. Win CoAP is implemented and validated against COCOA using the Cooja simulator in Contiki OS. We performed extensive simulations using various topologies and burst rates. Win CoAP outperforms COCOA in all analyzed scenarios and can improve the efficiency of event-based applications."
  },
  {
    "year": "2025",
    "abstract": "This paper investigates a novel approach to improve the temperature profile prediction of furnaces in foundation industries, crucial for sustainable manufacturing. While existing methods like the Hottel Zone model are accurate, they lack real-time inference capabilities. Deep learning methods excel in speed and prediction but require careful generalization for real-world applications. We propose a regularization technique that leverages the Hottel Zone method to make deep neural networks physics-aware, improving prediction accuracy for furnace temperature profiles. Our approach demonstrates effectiveness on various neural network architectures, including Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM), Extended LSTM (xLSTM) and Kolmogorov-Arnold Networks (KANs). We also discussion the data generation involved."
  },
  {
    "year": "2025",
    "abstract": "An effective temporal modeling approach is crucial for improving traffic flow prediction accuracy. Traditional traffic flow prediction methods have certain limitations in capturing long-term dependencies and enhancing computational efficiency. This is especially true when dealing with long-sequence data, where the prediction accuracy of these methods often falls short of expectations. This paper proposes a hybrid model that combines the Bidirectional Gated Recurrent Unit (BiGRU) and Temporal Convolutional Network (TCN) with a Self-Attention (SA) mechanism to enhance prediction performance. The BiGRU captures bidirectional temporal dependencies, while the TCN enhances training efficiency and models long-sequence dependencies through parallel computation. The self-attention mechanism further improves the model’s ability to capture long-term dependencies, enhancing overall prediction performance. The model is validated on several real-world traffic datasets and its performance is compared with traditional methods. Results show that the BiGRU-TCN-SA model reduces Mean Absolute Error (MAE) by 30.04%, 23.09%, 20.84%, 14.94%, and 11.57%, compared to LSTM, TCN, LSTM-TCN, BiLSTM-TCN, and BiGRU-TCN models, respectively. Root Mean Square Error (RMSE) is reduced by 20.91%, 15.39%, 11.99%, 9.27%, and 6.24%, respectively. We further validate the BiGRU-TCN-SA model using Akaike Information Criterion (AIC) and Schwarz’s Bayesian Information Criterion (SBIC) on ablation experiments, the proposed model achieves the lowest AIC (34.35) and SBIC (121.63) values compared to baseline models, demonstrating the superior performance of the BiGRU-TCN-SA model in traffic flow prediction tasks."
  },
  {
    "year": "2025",
    "abstract": "The accurate characterization of signal propagation is critical for optimizing wireless network performance and supporting applications such as electromagnetic field (EMF) exposure assessment and the development of Radio Environmental Maps (REMs). This study proposes a novel, explainable machine learning system to predict electric field strength across diverse urban, semi-urban, and rural environments in Cyprus. The system is trained on a rich dataset comprising 6,543 EMF measurements collected in 2023 at mobile phone and digital TV stations, following CEPT/ECC/REC/(02)04 recommendations. The dataset includes geospatial and environmental features such as antenna distance, population density, urbanization level, and detailed built environment characteristics (e.g., volume, surface, and height). We evaluate multiple machine learning models—kNN, neural networks, decision trees, random forests, XGBoost, and LightGBM—using a two-semester split for training and assessment. Best performance was achieved with the Random Forest model, which yielded the lowest RMSE among all models. Gradient boosting models (XGBoost and LightGBM) also performed well, with RMSE values slightly higher than RF while offering flexible and scalable configurations. In contrast, k-NN and neural networks showed higher RMSE values, indicating they were less effective for this specific task. Across all models, confidence intervals were narrow, demonstrating stable and reliable predictions. Explainable AI techniques revealed that antenna distance, building volume, and population density are the most influential predictors of EMF intensity. Our approach outperforms traditional signal models by incorporating urban morphology and demographic context. As part of this system, we also create a Geographic Information System (GIS) that displays electromagnetic field strength maps derived from our explainable machine learning models. This contributes a scalable, interpretable framework for EMF exposure mapping t..."
  },
  {
    "year": "2025",
    "abstract": "Face recognition (FR) is one of the most widely used biometric methods for identity authentication. Although most of the recently proposed methods demonstrate remarkable performance on high-quality datasets, such as LFW, their effectiveness is limited when assessed on low-resolution images. To address this challenge, knowledge distillation and super-resolution techniques have been applied, primarily using the ResNet architecture. However, the performance of deep learning approaches depends in part on the architecture used. In this study, we use neuroevolution with a genetic algorithm (GA) to design Convolutional Neural Networks (CNNs) automatically for low-resolution (LR) FR. To reduce the search time, a binary classifier is used to identify which generated architectures should be trained and which should not. The selected architectures are then trained and evaluated using QUMUL-TinyFace (training partition), a native LR dataset, to obtain their fitness, while the remaining architectures are assessed using a performance predictor model to estimate their fitness, bypassing the training stage. The classifier and performance predictor are trained using the CNN architectures evaluated from previous generations, with the architecture encoding used as a feature vector. The proposed method was assessed on both the QMUL-TinyFace (for face identification) and QMUL-SurvFace (for face verification) datasets, achieving a rank-1 recognition rate of 74.7% and a mean verification accuracy rate of 85.1%, respectively, outperforming results from previously published methods."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes an adaptive hybrid-tripping-based protection strategy for microgrids (MGs) that enables a fast and reliable response to faults by leveraging phase voltage and current measurements from relay locations. The protection coordination problem was addressed by optimizing the relay settings for different MG operating scenarios, ensuring proper coordination between the primary and backup relays. Comprehensive performance evaluation using PSCAD simulations demonstrated that the proposed protection scheme operates with 50% of faults cleared within 41.5 ms, while 90% of cases are cleared within 530.8 ms across various fault conditions in both grid-connected and islanded operating conditions. The backup relays exhibited a minimum trip time of 230 ms and a median trip time of 299.6 ms, while the coordination time intervals remained within safe margins (50% of cases maintaining a margin of 246.7 ms), ensuring selectivity. Moreover, real-time hardware-in-the-loop (HIL) tests using TMSF28335 microcontrollers validated the scheme’s practical applicability, showing a strong correlation between simulated and experimental results. The mean difference between the simulated and experimental trip times was 29 ms, with maximum deviations below 7.2% (64 ms) and a minimum deviation of 5 ms. The results confirm the effectiveness of the proposed strategy in reducing tripping times while maintaining coordination, making it a promising solution for both islanded and grid-connected MG operating modes."
  },
  {
    "year": "2025",
    "abstract": "Tire-road friction coefficient information is an essential factor in the driving stability and safety of a vehicle. In recent years, there has been a lot of research on using the vibration characteristic of tires to estimate the road surface condition from its features. However, since tire vibration characteristics vary depending on conditions such as tire pressure, load, and driving status, it is still difficult to develop a road surface classification algorithm that is robust to various situations. To overcome this limitation, this paper proposes a road surface classification algorithm using a one-dimensional convolutional neural network (CNN) based on acceleration signals obtained through an intelligent tire sensor attached inside the tire. Moreover, a time series data augmentation method is applied to ensure that the learning network has the robustness to perform well under different tires and driving conditions than that in the training dataset. A road surface classification algorithm is trained using a dataset of accelerations measured on dry asphalt, wet asphalt, and basalt tile roads, and the performance of the trained algorithm is validated through test scenarios considering different tire conditions and vehicle types. Furthermore, the performance of different CNN architectures is compared and the algorithm with the best performance is suggested. The robustness to different tires and driving conditions makes the proposed algorithm practical for estimating road surface conditions in real vehicles."
  },
  {
    "year": "2025",
    "abstract": "Autonomous aerial vehicle (commonly known as UAV) wireless communications have become widespread in military and civilian applications, partly due to its inherent line-of-sight (LoS) air-to-ground channels, easy deployment and high mobility. They have been adopted for data collection in the Internet of Things (IoT). For a communication scenario with a single UAV data collector in a delay-sensitive application, authentication is an important procedure which prevents illegal or malicious sensors from sending fake data to the data collector. However, traditional authentication schemes depend on cryptography, which is energy and time consuming. Thus, they are unsuitable for latency-intolerable applications and energy-constrained UAVs. This work aims to design a keyless, energy-efficient authentication scheme suitable for high-speed mobility scenarios. To this end, we propose an Orthogonal Time Frequency Space (OTFS)-based lightweight physical layer authentication (PLA) scheme. We begin by deriving the relationship between the location of the transmitter and normalized OTFS Doppler shift to develop the hypothesis test. Henceforth, we derive the probability density function (PDF) expressions of false alarm and missed detection. The PDF of the false alarm and missed detection are the basis for setting an optimal detection threshold for the authentication hypothesis test. Numerical results demonstrate that the proposed scheme holds well to fading effects for a robust and secure authentication scheme, and outperforms Orthogonal Frequency Division Multiplexing (OFDM) for PLA. The advantages of OTFS over OFDM for PLA are well elaborated."
  },
  {
    "year": "2025",
    "abstract": "Mobile Edge Computing (MEC) is a key technology for delivering low-latency services to mobile and edge devices, supporting applications like autonomous vehicles and smart cities. However, traditional hardware-based middleboxes limit flexibility and scalability, leading to the adoption of Network Function Virtualization (NFV). NFV enables the deployment of network functions as software, optimizing resource allocation and reducing costs. This study proposes a proactive failure prediction and migration strategy for MEC environments. Using a Long Short-Term Memory (LSTM) algorithm optimized by Super SAPSO (Simulated Annealing Particle Swarm Optimization), the model forecasts server failures with improved accuracy, reducing False Alarm Rates and improving Failure Detection Rates. For migration, the Improved Sparrow Search Algorithm (ISSA) is applied, factoring in CPU, memory, and server security thresholds to identify suitable migration servers for Virtual Network Functions (VNFs). ISSA’s fitness function balances migration cost and time, minimizing the impact of security constraints on migration efficiency. Results show that ISSA with a security check improves migration success ratios, especially at lower Service Function Chaining (SFC) arrival rates, while keeping migration times consistent across arrival rates of SFCs. This approach ensures high success rates, and reduced costs offering a resilient and efficient solution for dynamic MEC environments and laying the groundwork for adaptive, secure, and resource-efficient edge computing systems."
  },
  {
    "year": "2025",
    "abstract": "Real-time analysis of ultrasound videos using embedded terminals enables the rapid detection of breast masses and plays a crucial role in early breast cancer screening and diagnosis. However, as a paired organ with a large area, the breast consists of interwoven fatty layers, mammary ducts, glandular tissues, and masses, leading to a high false-positive rate in target detection. Unlike standard imaging modalities such as computed tomography, X-ray, and magnetic resonance imaging, ultrasound detection heavily depends on the sonographer’s techniques and expertise, which can lower detection accuracy, particularly in identifying small masses. This paper proposes a novel architecture, LEW-YOLO, to address the real-time detection demands of embedded terminal devices for breast ultrasound. First, we introduce an efficient multiscale convolutional (EMSC) module to improve feature extraction from complex backgrounds and enhance multiscale representation. Unlike traditional methods, EMSC employs multiple convolution branches with varying kernel sizes, enabling more effective multiscale feature capture. Second, the detection head of YOLOv8 is replaced with a lightweight shared detail-enhanced convolutional detection head (LSDECD) to improve the model’s ability to detect small masses. Finally, a weighted intersection-over-union (WIoU) loss function is integrated to better capture the complex boundaries of malignant masses. Experiments on the public BUSI dataset demonstrate that LEW-YOLO achieves an mAP50 of 91.6%, surpassing the YOLOv8n baseline (89.0%) by 2.6%. On the BUET dataset, LEW-YOLO attains an mAP50 of 83.3%, outperforming YOLOv8 (72.3%) by 11.0%. Moreover, the parameter count and GFLOPs are reduced by 26.6% and 22.2%, respectively. Thus, the proposed model effectively balances detection performance and lightweight design, making it well-suited for real-time applications on resource-constrained computing devices."
  },
  {
    "year": "2025",
    "abstract": "This study proposes a novel algorithm for effectively estimating partial upper and lower body movements in a Virtual Reality (VR) environment using only head movements and synchronized head rotation axes, without the need for additional hardware. The proposed algorithm calculates the angle between the avatar’s pelvis and the head rotation axis to naturally reproduce the user’s upper body inclination and lower body bending. Notably, it offers the advantage of efficiently utilizing limited computational resources in multiplayer environments. The experiment was conducted in two stages. In the first stage, the objective performance of the algorithm was evaluated by comparing it with ground truth inclination data. In the second stage, participants performed two types of games (e.g., a dodgeball game and a limbo game) to assess their sense of immersion and embodiment. The objective results demonstrated that the proposed algorithm accurately and naturally expressed upper and lower body movements. Additionally, post-experiment surveys indicated that participants reported a high level of immersion and a natural interaction experience. This study presents a cost-effective solution for tracking upper and lower body movements in VR environments without requiring additional hardware, significantly enhancing the immersion of the VR experience. Future research will explore the expansion of the method to include upper body rotation estimation and full-body motion tracking, incorporating user locomotion."
  },
  {
    "year": "2025",
    "abstract": "The integration of Internet of Things (IoT) devices into smart environments has become increasingly prevalent, resulting in the collection of valuable user and service data. However, effectively utilizing this data often requires its aggregation on a central server to train algorithms capable of identifying and preventing malicious attacks, such as reconnaissance, DoS (Denial of service), DDoS (Distributed denial of service) within IoT networks. This transmission of raw data not only incurs substantial bandwidth costs but also raises significant privacy concerns. In this paper, we propose a federated learning framework for intrusion detection on IoT networks that incorporates a distributed storage system based on the Ethereum blockchain, enhancing the security of the federated learning process. This design offers several key benefits, including scalability, high availability, redundancy, and the capacity to process large datasets. Despite these advantages, relying solely on federated learning may not yield accurate results, particularly when dealing with highly imbalanced datasets. To address this challenge, we have integrated a diffusion model for data augmentation at each local node, which strengthens model robustness. Furthermore, to protect data privacy at each local node, we utilize transmitting and averaging model parameters instead of raw data. The proposed framework is trained and evaluated in two datasets. The MNIST (Modified National Institute of Standards and Technology) dataset and BoT-IoT dataset. Our results indicate significant improvements in detecting zero-day attacks, achieving an average F1-score of 98.3% on the short version of the BoT-IoT dataset as well."
  },
  {
    "year": "2025",
    "abstract": "This study introduces Composable Enterprise Architecture (CEA) as a strategic approach to address the inherent rigidity and operational constraints of traditional enterprise systems, which often impede adaptability to fast-changing market conditions. By implementing a modular, cloud-native framework centered on Packaged Business Capabilities (PBCs), CEA enhances system reusability, autonomy, and scalability. Based on semi-structured interviews with industry stakeholders and extensive operational data analysis, the study reports significant benefits achieved through CEA adoption, including a 55% reduction in system downtime, an increase in deployment frequency from quarterly to monthly, and a 60% decrease in time-to-market for new features. These structural improvements streamline updates, reduce operational risks, and empower organizations to respond dynamically to market changes. As such, CEA offers a valuable architectural strategy to drive digital transformation and enhance agility across varied industries."
  },
  {
    "year": "2025",
    "abstract": "This paper, a model is proposed that generates descriptive sentences for input images visually impaired individuals. For this purpose, a novel image captioning approach is introduced, integrating the principles of human visual Understanding mechanisms with the Vision Transformer (ViT) architecture, further enhanced by deep reinforcement learning. First, features are extracted from the image based on human visual perception. Second, the image features are encoded through the encoding block of ViT and input into the long short-term memory (LSTM) network to generate annotations for the image. Finally, reinforcement learning is optimized to further enhance the accuracy of the generated captions. Evaluations were performed utilizing the MSR-VTT benchmark dataset, which is widely used for image captioning tasks. Experimental results on the MSR-VTT benchmark dataset demonstrate that the proposed model achieves BLEU-4 of 43.0, METEOR of 29.1, ROUGE-L of 62.7, and CIDEr-D of 54.9, surpassing state-of-the-art baseline models across all evaluation metrics. The proposed model can be applied to video annotation applications for the visually impaired. In contrast to prior works that primarily rely on conventional convolutional architectures, the proposed model uniquely incorporates human-inspired visual perception principles and Vision Transformer-based global encoding, offering a novel and interpretable framework tailored for assistive image captioning."
  },
  {
    "year": "2025",
    "abstract": "Scene understanding and multisource data fusion are critical challenges in autonomous self-driving systems.In particular, optimizing information fusion strategies for three-dimensional Bird’s Eye View (BEV) scene recognition tasks is crucial for accurate perception and decision-making in dynamic environments. This study proposes a novel architecture that integrates multiscale feature extraction and crossmodal structural alignment to enhance the representation and detection capabilities of BEV features. Specifically, we employ a DCN-based block for visual feature extraction, comprising layer normalization (LN), feedforward networks (FFNs), and the Gaussian Error Linear Unit (GELU) activation function, aligned with the Vision Transformer (ViT) paradigm to improve feature modeling. To fully utilize multiscale information, a dedicated multiscale feature fusion block is introduced to extract expressive scene features within the feature space. Furthermore, we leverage LiDAR to generate LIDAR BEV features and propose a feature alignment block to enhance the complementarity between camera and LiDAR BEV features. The proposed architecture effectively supports precise scene recognition and adaptive decision-making in multi-sensor fusion environments, providing robust perception capabilities for autonomous driving in complex scenarios."
  },
  {
    "year": "2025",
    "abstract": "Digital media art has a wide application in the field of image caption generation. In digital media art exhibitions or online works displays, some complex image works may have multiple layers of meanings or abstract expressions, which can help viewers better understand the works. It can also serve as another auxiliary element besides sound, collaborating with visual elements to provide a richer experience for the audience. The purpose of picture captioning is to provide textual descriptions that correlate to input images. The CLIP paradigm is highly versatile to resolve vision-text difficulties. In the field of picture description, the standard Transformer architecture has also exhibited good effects, which uses an image encoder and a text decoder. Large parameter numbers and the demand for further data preprocessing are still significant difficulties. In order to replace the fundamental features of conventional multi-modal fusion models, we propose a New Multi-modal Fusion Attention module (NMFA), which efficiently decreases parameter sizes and computational complexity in half. Expanding upon this, we propose the Transformer Fusion CLIP (TFC) model, which minimizes parameter sizes and processing demands while getting remarkable assessment scores. Additionally, we strengthen the mechanism for cumulative points and reward sequence length to encourage the construction of larger sequences. Finally, we combine the enhanced beam search technique to further train the TFC model. Results from our testing on the MSCOCO dataset reveal that we have not only greatly improved the efficiency of the TFC model but also speeded up its runtime by eight times and reduced model parameters by over 50%."
  },
  {
    "year": "2025",
    "abstract": "The selection of the team captain is an essential decision in team-based sports and professional situations, and it requires an optimized option across multiple criteria. Many existing approaches fail to summarize the difficulties of player behaviors and leadership qualities. In this article, we established a novel model by combining diffusion-based player behavior synthesis with multi-criteria decision-making (MCDM) approach; purposely, we use Dombi aggregation operators (AOs), analytical hierarchy process (AHP), and preference ranking organization method for enrichment evaluation (PROMETHEE) based on an intuitionistic rough fuzzy (IRF) framework. We presented a detailed case study for suitable caption selection based on defined alternatives such as leadership skills, game performance metrics, psychological stability, and tactical awareness. To show the applicability of our methodologies, we discuss numerical examples based on caption selection for football teams. To use the AHP approach, compute the weight vector for criteria. Then, we use our proposed approach, such as intuitionistic rough fuzzy Dombi weighted averaging (IRFDWA) operators and PROMETHEE, to rank candidates. The analysis of Dombi-AHP is an advanced modification of the AHP. It handles the complex MCDM elaborate in captain selection. AHP is selected due to its structured pairwise comparison method, which improves decision accuracy by systematically quantifying subjective decisions. We comprehensively compare our approach with other existing aggregation methods and discuss the sensitive analysis of the proposed theory. Then, provide a solid conclusion."
  },
  {
    "year": "2025",
    "abstract": "Recent papers in the cybersecurity research field of Domain Generation Algorithms (DGAs) detection show the increase of performances associated with the introduction of unsupervised neural vectorized representation of domain names in the supervised classification process. In this paper we explore the effectiveness of this approach by proposing a novel mixed pre-trained neural embeddings model which integrates different vectorized representations of domain names: n-grams streams and words. We used the embeddings with two different classifiers, both based on ensemble architectures: a stacking model and an end-to-end multi-input neural architecture. We trained and tested the classifiers with two datasets, differing both in the distribution of domain names between real and DGAs and in the number and type of DGAs. The obtained results show that our solution provides considerable advantages with respect to state-of-the-art single classifiers both in classification accuracy and in the detection of challenging DGAs, such as those based on word dictionaries. The improvement of performance is significant in a particularly relevant operating condition, known as few-shot-learning, where only few examples of DGA-generated domain names are available for the classifier training."
  },
  {
    "year": "2025",
    "abstract": "The rapid growth of the Internet of Healthcare Things (IoHT) has led to challenges in real-time processing, prioritization, and resource allocation of heterogeneous healthcare data. Existing edge-fog-cloud approaches often fail to effectively handle critical medical events and ensure timely interventions. This paper presents a novel IoHT framework that integrates an M/M/C/K priority queue model (M: Markovian arrival/service rates, C: servers, K: capacity) with a three-tier edge-fog-cloud architecture. The proposed approach introduces a dynamic priority assignment mechanism that leverages real-time patient data for swift processing of critical events and an adaptive resource allocation strategy that optimizes performance under varying workloads. Simulations and real-world case studies demonstrate the framework’s superiority, achieving a 30% reduction in average response time for critical events and a 25% improvement in resource utilization compared to state-of-the-art methods. Contributions include: 1) a novel M/M/C/K priority queue model integrated with edge-fog-cloud architecture; 2) dynamic priority assignment and adaptive resource allocation strategies; and 3) comprehensive evaluation through simulations and case studies. By addressing key challenges in IoHT data processing and prioritization, this work enables the development of efficient, responsive, and reliable IoHT systems for timely and personalized healthcare interventions, ultimately improving patient outcomes and quality of care."
  },
  {
    "year": "2025",
    "abstract": "Portfolio optimization continues to be a complex and challenging task within the fields of finance and management. Two critical factors that can improve the performance of traditional models are incorporating the effects of both financial and operational performance of companies and addressing the inherent uncertainty surrounding expected returns. This article addresses these two challenges. To evaluate the financial and operational efficiency of firms, we analyze their quarterly reports using the FinBERT model, incorporating their influence into the optimization framework through adjusted returns. To address the unpredictability linked to anticipated returns, we utilize fuzzy trapezoidal numbers in our methodology. Furthermore, conventional risk measurement systems, which rely based on probability-based assumptions and past data, often find it challenging to address the unique dynamics and inherent uncertainties of the market. In contrast, our suggested approach utilizes a credibilistic conditional value at risk (CCVaR) framework to evaluate portfolio risk. The approach additionally factors in transaction costs and incorporates practical constraints like cardinality and upper and lower bounds, maintaining the portfolio’s diversification, well-balanced, and reflective of practical scenarios. We apply the proposed approach to real-world data from DJIA stocks. Experimental findings highlight the approach’s efficacy in creating mixed portfolios that effectively create an equilibrium between risk and return. This research enhances the domain of investiture management by developing advanced portfolio optimization methods for stock market assets and offering a reliable approach for handling risk in today’s increasingly complex financial landscape."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces a novel framework of Directed Edge q-Rung Orthopair Fuzzy Graphs (DEq-ROFGs), where graph vertices are crisp, and edges are characterized by q-rung orthopair fuzzy numbers (q-ROFNs). This structure captures the uncertainty in edge relationships while retaining deterministic node identities, making it ideal for applications in uncertain environments such as social networks, supply chains, healthcare systems, and recommendation systems. The paper defines foundational properties of DEq-ROFGs including subgraphs, completeness, and various degree-based metrics, and it establishes a proposition regarding the balance between in-degrees and out-degrees. The core contribution is a novel path-finding algorithm based on Hamacher operators and an improved score function, which identifies optimal paths between nodes under uncertainty. Unlike classical algorithms, it considers the suitability of a path, not just its length. Applied to an emergency road network scenario, the algorithm successfully determines the optimal route for service vehicles, and the choice between these routes can be made based on the score of the resulting path length. Comparative simulations show their effectiveness over traditional methods. Further analysis shows that increasing the q-value reduces both path score and length, and that Einstein operators yield higher destination scores than Hamacher and Dombi, confirming the model’s adaptability and robustness."
  },
  {
    "year": "2025",
    "abstract": "Using copulas in statistics evaluates the dependence between random variables. Copula modeling has significantly been used in many areas, especially in the search for multivariate distributions. As wind energy rapidly becomes an important renewable energy source, it is very important to deeply evaluate any potential existing dependencies among the data. This study introduces a comprehensive application of vine copulas in modeling multi-site wind speed dependencies for different sizes of datasets, offering a more flexible approach than traditional correlation-based methods. Unlike previous studies, this work systematically evaluates the impact of dataset sizes on the selection of the best-performing vine copula structures, providing valuable insights for improving wind forecasting and grid stability. These evaluations are studied using R-vine, C-and D-vine models by applying pair copulas families and the pairwise empirical Kendall’sτvalues, where the appropriate model is selected based on the Akaike Information Criteria (AIC), the Bayesian Information Criteria (BIC), and the likelihood method (Log-likelihood). This study finds out the best vine copula model for three different wind speed datasets, namely hourly (large), daily (medium), and small (weekly). Also, using all pair copulas families (Clayton, Frank, Gumbel, Student’s t, and Gaussian), vine copula simulations provide guidelines for conceptual understanding of mutual impacts and correlations among multi-site wind farms. Simulations also show that the R-vine copula is the best structure for both large and small datasets, while the C-vine copula is the best structure for medium datasets."
  },
  {
    "year": "2025",
    "abstract": "In autonomous driving, achieving rapid detection of target categories and locations is a key technology. However, the data volume of radar point clouds is enormous, and processing efficiency becomes a limiting factor, so the balance between speed and accuracy is crucial. To address this challenge, this paper proposes a 3D object detection algorithm SP-Pillars that can effectively learn point cloud features. Firstly, a Pillar Feature Weighted Network (PFWNet) is proposed for processing point cloud information, which divides the point cloud into pillar structures and uses SPCV feature attention network to focus on its multi-level feature information. After feature extraction and dimensionality reduction, pseudo images are generated. Subsequently, before extracting pseudo image features, a multi-core perception network (PKINet) is introduced to further mine local contextual information and reduce computational complexity, enabling the backbone network to effectively learn features. The experimental evaluation results on the KITTI dataset indicate that the proposed algorithm is reliable and effective. Compared with other related algorithms, this algorithm exhibits excellent detection performance, slightly improving detection speed while maintaining high accuracy, meeting the requirements of real-time processing, and has important application value in optimizing autonomous driving technology."
  },
  {
    "year": "2025",
    "abstract": "Deep neural networks (DNNs) are increasingly being applied in critical domains such as healthcare and autonomous driving. However, their predictive capabilities can degrade in the presence of transient hardware faults, which can lead to potentially catastrophic and unpredictable errors. Consequently, various techniques have been proposed to enhance DNN fault tolerance by modifying the network structure or training procedure, thereby reducing the need for costly hardware redundancy. However, there are design or training choices whose impact on fault propagation has been overlooked in the literature. Specifically, self-supervised learning (SSL) as a pre-training technique has been shown to enhance the robustness of learned features, resulting in improved performance on downstream tasks. This study investigates the error tolerance of different DNN and SSL techniques in image classification and segmentation tasks, including those relevant to Earth Observation. Experimental results suggest that SSL pretraining, whether used alone or in combination with error mitigation techniques, generally enhances DNN fault tolerance. We complement these findings with an in-depth analysis of the fault tolerance of quantized networks. In this context, the use of standard SSL techniques leads to a decrease in accuracy. However, this issue can be partially addressed by employing methods that, during the pretraining phase, incorporate the quantization error into the loss function."
  },
  {
    "year": "2025",
    "abstract": "Breast cancer is one of the most common cancers among women, with its heterogeneity posing significant challenges for diagnosis and treatment, profoundly impacting patient prognosis and quality of life. Whole Slide Imaging (WSI) in digital pathology provides high-resolution images that enable a comprehensive examination of the tumor microenvironment, offering advanced tools for breast cancer diagnosis and prognostic evaluation. However, manually reviewing whole slide images (WSIs) for tissue segmentation is time-consuming and prone to errors, highlighting the need for multi-target deep learning models to automate the segmentation of these complex structures. Multi-target segmentation offers distinct advantages by simultaneously processing multiple interrelated tissue regions within a single image, thereby enhancing accuracy and efficiency. Despite the potential of deep learning techniques in automating pathological analysis, their clinical adoption faces significant challenges. To address these, this paper proposes six criteria focused on clinical acceptability of deep learning methods: inherent limitations of WSIs, feature extraction, annotation requirements, efficiency, automated quantification, and interpretability. A rigorous review of publicly available datasets and deep learning methods identifies key challenges for clinical adoption. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, this review analyzes 29 core articles, highlighting the critical role of multi-target segmentation in breast cancer digital pathology while assessing the limitations of these techniques in clinical applications. Based on this analysis, this paper proposes six criteria to enhance the diagnostic performance of deep learning methods in multi-target segmentation for breast cancer digital pathology and to improve the clinical acceptability of deep learning methods."
  },
  {
    "year": "2025",
    "abstract": "Cancer of the lung system is arguably the second largest factor in the worldwide fatality explosion. It originates from smoking too much and tobacco use. Uncontrolled cell growth in the lung region will hurt human survival. The exponential increase in medical reports might challenge the manual interpretation of disease prediction. Therefore, using Computer-Aided Diagnosis (CAD) approaches, a tumor might be detected early from an appropriate appearance. This study thoroughly evaluates various lung cancer detection methods for classifying a nodule. The area of lung cancer prediction is becoming increasingly popular due to the many benefits of automated medical diagnosis using Deep Learning techniques. This study discusses potential deep learning (DL) strategies for lung disease applications, an overview of DL approaches, and novel elements of the methods under investigation. Classification and segmentation are the two main deep learning techniques for lung cancer detection and screening, which are the focus of this review. We will also talk about the benefits and drawbacks of contemporary deep learning models. The resulting study demonstrates the significant potential of deep learning approaches for exact and efficient computerized lung cancer monitoring and detection employing CT scans. Following this study, an overview of prospective further studies is given, focused on enhancing deep learning to advance automated techniques for diagnosing lung cancer."
  },
  {
    "year": "2025",
    "abstract": "Currently, modern permanent magnet synchronous motor diagnostic systems based on artificial neural networks are designed to detect selected types of damage. Changing the type of failure requires the repeated training and implementation of a new neural structure. The main point in the development of new diagnostic applications is the extraction of damage symptoms, which significantly extends system implementation. Therefore, it is important to find a solution to implement universal diagnostic patterns that ensure the detection of various types of damage. Furthermore, the diagnostic application should be precise and characterized by a short reaction time to problems that occur. Such possibilities are now offered by transfer learning techniques used for deep neural networks. This article presents the concept of applying the transfer learning of a deep convolutional neural network to the diagnosis of damage to the electrical and magnetic circuits of a permanent magnet synchronous motor using the information obtained from the mathematical model. This research utilizes information derived from a mathematical model, particularly the field-circuit model of the PMSM, focusing on stator and permanent magnet failures."
  },
  {
    "year": "2025",
    "abstract": "This paper presents the initial foundations of a new Global approach to Artificial Intelligence based on the modeling of global intelligence and the development of artificial cooperative systems to support this. The research work brings numerous investigations and some recent creations to develop intelligent systems in urgent global, cooperative domains. The investigations present an overall view of current issues like true natural i.e. global intelligence. The creations include several results in global solutions explorations as well as new models, services, architectures and processes which could be of special interest for global organizations that urgently need to achieve intelligent cooperation. The major aim of the approach is to help these organizations, and other related institutions, to succeed in their complex daily duties where true thinking, more natural intelligence and new global artificial systems are required. Further, the paper provides some guidelines for the next evolutions of the work in the form of a brief, open research agenda and, some general actions for deploying Global Artificial Intelligence into our organizations, suggesting how to build new global artificial intelligent systems in real and virtual ecosystems."
  },
  {
    "year": "2025",
    "abstract": "Controlling autonomous vehicles in adverse weather conditions poses unique challenges, particularly in reconstructing images from diverse adverse environments—such as rain, snow, fog and night light—into clear, normal-appearing visuals. Although StarGAN has been successfully applied to multi-domain conversion, its design typically focuses on transforming a single image into multiple styles rather than converting images from multi-domains into a unique representation. To address this limitation, we propose an inverse version of StarGAN that processes images captured by the vehicle’s camera and transforms them into clear visuals simulating normal conditions. Initially, the model is trained with explicit weather domain labels and later with shuffled labels, a strategy that reduces dependence on specific label severities and enhances the model’s adaptability in dynamic environments. Since CNNs often overfit when dealing with multi-domain tasks, we incorporate Capsule Neural Networks to mitigate overfitting, capture spatial hierarchies and improve sensitivity to object orientation. Furthermore, a perceptual loss function is employed to preserve fine image details. Our extensive dataset comprises over 100,000 samples collected from the AVIS ENGINE simulator along with real-world validation from the BDD100k dataset under rain, snow, fog, and nightlight conditions. Results indicate an average PSNR of 22.21 and an SSIM of 0.92 in closed-loop simulations, demonstrating robust and real-time performance. This work represents a significant step forward in enhancing the safety, reliability, and overall robustness of autonomous systems operating in challenging and unpredictable weather conditions."
  },
  {
    "year": "2025",
    "abstract": "The proposed motion cueing algorithm (MCA), based on a reinforcement learning algorithm using gradient information to directly update the control policy, introduces three significant enhancements. First, transform the complex simulator environment into a differentiable simulator environment that provides gradient information at each time step and use this gradient information to directly update the control policy. Second, the network architecture is reconfigured into a concurrent controller format, similar to Model Predictive Control (MPC). This controller processes a sequence of vehicle motion reference signals over a future period, utilizing a multi-layer perceptron to generate the simulator’s motion reference control signal sequences for the same duration. Unlike the online optimization employed in MPC, this algorithm as an offline optimization method, providing substantial computational advantages when integrated into the driving simulator. As the prediction horizon increases, the algorithm demonstrates superior computational efficiency, which helps reduce the incidence of motion sickness during the use of the driving simulator. Third, a loss function specifically designed for the motion simulator is proposed. This function incorporates constraints derived from the MPC framework to address workspace limitations and applies them to workspace management. These constraints restrict the platform’s acceleration and speed near the workspace boundaries, allowing for better utilization of the available space. The algorithm is validated using Carla’s autonomous driving simulation software as the dataset generator. During the training process, the proposed algorithm in this paper achieves an order-of-magnitude improvement in convergence speed compared to conventional training methods of PPO and DDPG. Simulations with a 10-step prediction horizon indicate that the Root Mean Square Error (RMSE) produced by this algorithm is comparable to that of the MCA based on MPC (MPC-MC..."
  },
  {
    "year": "2025",
    "abstract": "Future carrier networks for the sixth generation of mobile communications are expected to guarantee performance across heterogeneous networks that cover multiple technologies. This integration requires the effective verification of network performance under unpredictable traffic conditions. To address this challenge, a router modeling approach defined as the data-driven estimation of actual router performance has been proposed to facilitate router performance verification. However, the creation of router models has been limited by the high cost and difficulty of acquiring the extensive real-world datasets for various traffic patterns required to train actual router models. Our motivation is to enable the digital verification of router performance with limited real-world datasets. This paper proposes a meta learner-based transfer learning method to estimate actual router metrics using models trained on network simulation data. The proposed method aims to build a model of actual router metrics based on limited real-world datasets by supplementing them with different ranges and types of simulation data. The proposed method addresses the differences in these datasets by utilizing Neural Processes as a meta-learner combined with Partial Least Squares analysis to capture and bridge representations between simulation and real-world datasets for packet multiplexing tasks for transfer learning. The results show that the proposed method improves the estimated accuracy of actual router metrics: throughput, packet loss rate, and packet delay. Additionally, the proposed method demonstrates robustness and effectiveness in scenarios where real-world data is limited while maintaining lower computational complexity compared to conventional methods. Our results suggest that this approach may assist network operators in estimating network performance, even with limited real-world data."
  },
  {
    "year": "2025",
    "abstract": "Rehabilitation robots, particularly lower-limb exoskeletons, are transforming healthcare by assisting individuals with mobility impairments. This study introduces a novel Sliding Mode Control (SMC) system based on a fractional-order reaching law, designed to enhance control performance and robustness. The proposed approach effectively manages the exoskeleton’s dynamic behavior, particularly during the transient regime, by reducing initial torque energy demand during start-up, ensuring precise trajectory tracking, and prioritizing patient safety and comfort. The method’s effectiveness is validated through MATLAB simulations and supported by a rigorous dual stability analysis, demonstrating asymptotic and finite-time convergence of the system in the reaching and sliding phases. A Comparison study with traditional SMC techniques proves that the FO-RL-SMC significantly improves energy efficiency during the transient phase and the overall dynamical behavior of the system. These results highlight the potential of the proposed FO-RL-SMC system to advance the performance of rehabilitation robots, emphasizing its value in addressing complex control challenges and improving patient outcomes."
  },
  {
    "year": "2025",
    "abstract": "Currently, early rumor detection has garnered significant attention due to the rapid dissemination of information on social media. Many existing studies approach rumor detection as a traditional classification task, disregarding the existence of unverified rumors that require future verification. To address this limitation, we present T3-ERD, a novel framework that employs an improved BigBird transformer-based model for detecting rumors of specific types while concurrently leveraging reinforcement learning to determine early time checkpoints and categorize unverified rumors. And we introduce a novel bucket strategy, Online Dynamic, which dynamically clusters comments and processes them in batches, demonstrating remarkable effectiveness. The T3-ERD achieves F1 score, accuracy, and early rate of 0.830, 0.837, and 0.220 on the Twitter15 dataset, and 0.837, 0.844, and 0.205 on the Twitter16 dataset, respectively."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces a novel control strategy to ensure safety in the navigation of a mobile manipulator comprising a fixed-base manipulator mounted on a mobile platform. The approach initially addresses the trajectory tracking problem of a non-holonomic mobile manipulator (NH-MM) by employing decoupling dynamic control through model predictive control-optimizable control barrier function (MPC-OCBF). This allows for independent control of the end-effector and mobile platform trajectories, obstacle avoidance, and simultaneously adjusting the joint and control input limitations. The objective is to leverage the system’s redundancy to enable the mobile platform to effectively navigate feasible obstacle avoidance scenarios without affecting the primary task performance of the end-effector. Additionally, the method aims to perform obstacle avoidance when the redundancy of the manipulator is insufficient, addressing non-feasible obstacle avoidance scenarios. Through this approach, the mobile manipulator effectively avoids obstacles, allowing the end-effector to autonomously carry out its intended task. The effectiveness of the proposed method is validated through simulations and comparison with existing approaches. Additionally, a quantitative analysis is provided to evaluate and compare the performance of the controllers."
  },
  {
    "year": "2025",
    "abstract": "Cloud computing technologies offer significant advantages in scalability and performance, enabling rapid deployment of applications. The adoption of microservices-oriented architectures has introduced an ecosystem characterized by an increased number of applications, frameworks, abstraction layers, orchestrators, and hypervisors, all operating within distributed systems. This complexity results in the generation of vast quantities of logs from diverse sources, making the analysis of these events an inherently challenging task, particularly in the absence of automation. To address this issue, Machine Learning techniques leveraging Large Language Models (LLMs) offer a promising approach for dynamically identifying patterns within these events. In this study, we propose a novel anomaly detection framework utilizing a microservices architecture deployed on Kubernetes and Istio, enhanced by an LLM model. The model was trained on various error scenarios, with Chaos Mesh employed as an error injection tool to simulate faults of different natures, and Locust used as a load generator to create workload stress conditions. After an anomaly is detected by the LLM model, we employ a dynamic Bayesian network to provide probabilistic inferences about the incident, proving the relationships between components and assessing the degree of impact among them. Additionally, a ChatBot powered by the same LLM model allows users to interact with the AI, ask questions about the detected incident, and gain deeper insights. The experimental results demonstrated the model’s effectiveness, reliably identifying all error events across various test scenarios. While it successfully avoided missing any anomalies, it did produce some false positives, which remain within acceptable limits."
  },
  {
    "year": "2025",
    "abstract": "Multivariate time series (MTS) clustering has become a critical research area. Current methods typically rely on space projection or representation learning for clustering but tend to overlook the significance and contribution of MTS dimensions, leading to a failure in accurately modeling the intricate correlations and dependencies among dimensions. Meanwhile, the lack of adaptive regulation for MTS dimensions in distance measures significantly impacts clustering accuracy. In view of these issues, we propose a data-adaptive dynamic time warping (DTW) based fuzzy clustering method for MTS. This method utilizes locally weighted DTW as the kernel distance measure, enabling the adaptive regulation of MTS dimensions. To address the non-convex optimization problem associated with DTW-based clustering, we formulate a comprehensive objective function and present an efficient optimization method based on closed-form solutions. This unsupervised learning method significantly improves the precision of DTW, leading to more accurate and interpretable clustering outcomes. Extensive experiments conducted on eight public datasets, along with comparisons to 10 benchmark methods, demonstrate the competitive performance of our method in terms of both accuracy and efficiency."
  },
  {
    "year": "2025",
    "abstract": "Recommendation systems serve as fundamental elements of contemporary technology by reshaping how users find content in all fields including educational applications. Academic English literature benefits strongly from recommendation systems because these systems enable customized learning opportunities to help students discover relevant content according to personal learning needs. English literature represents features challenging recommendation systems because it consists of extensive text content combined with multiple stylistic attributes and extensive metadata structures. The study presents a deep learning framework called HMSTNet to manage complex recommendation scenarios. Novel architecture integrates metadata datasets alongside stylistic information and BERT-powered text-based embeddings for understanding of content and user systemic preferences. Through its multi-branch structure Hybrid Multimodal Semantic Text Neural Network (HMSTNet) based on LSTM model to recognize difficult meta-relations between text components while utilizing user embeddings to maintain context awareness. This research serves to unite conventional recommendation algorithms with English literature reading requirements. The complex nature of literary data poses challenges to k-Nearest Neighbors (kNN) and Singular Value Decomposition (SVD) whereas conventional methods show limited success in both context understanding and accuracy. The model HMSTNet outperforms others with outstanding results reaching 95.23% accuracy. Multiple metrics demonstrate the efficiency of this model because they measure highest MBD with KNN model of 6.8m along with Theil’s U-statistic of 0.04 and 90th percentile error is 8.41 to confirm minimized prediction errors and enhanced accuracy and fail-safe capability. Through its reliable framework HMSTNet both delivers personalized content recommendations and supports educational technology development which deepens student engagement with literature and promotes lifel..."
  },
  {
    "year": "2025",
    "abstract": "The widespread use of large language models (LLMs) and voice-based agents has rapidly expanded Human-Computer Interaction (HCI) through spoken dialogue. To achieve more natural communication, nonverbal cues—especially those tied to emotional states—are critical and have been studied via deep learning. However, three key challenges persist in existing emotion recognition datasets: 1) most assume human-to-human interaction, neglecting shifts in speech patterns when users address a machine, 2) many include acted emotional expressions that differ from genuine internal states, and 3) even non-acted datasets often rely on third-party labels, creating potential mismatches with speakers’ actual emotions. Prior studies report that agreement between external labels and speakers’ internal states can be as low as 60–70%. To address these gaps, we present the VR-Self-Annotation Emotion Dataset (VSAED), consisting of 1,352 naturally induced and non-acted Japanese utterances (1.5 hours). Each utterance is labeled with self-reported internal emotional states spanning six categories. We investigated: 1) how effectively non-acted, machine-oriented speech conveys internal emotions, 2) whether speakers alter expressions when aware of an emotion recognition system, and 3) whether specific conditions yield notably high accuracy. In experiments using a HuBERT-based classifier, we achieve around 40% recognition accuracy, underscoring the complexity of capturing subtle internal emotions. These findings highlight the importance of domain-specific datasets for human-machine interactions."
  },
  {
    "year": "2025",
    "abstract": "Gallium Nitride (GaN)-based Gate Stack (GS) Gate-All-Around Field Effect Transistors (GAA FETs) are promising candidates for next-generation energy-efficient electronics due to their exceptional material properties, such as high electron mobility, wide bandgap, and superior thermal stability. This study focuses on the performance evaluation of GaN-based GAA FETs for both DC and AC explorations incorporating high-k dielectric spacers and source/drain underlap engineering. The DC analyses parameters such as subthreshold slope, threshold voltage, drain current, leakage current and current ratio. ~95% reduction in off-state leakage current and ~606% increase in switching ratio is acquired in comparison to proposed 2nm technology node IRDS2025. Additionally, the subthreshold swing is optimized around ~65mV/decade indicating superior leakage control and switching performance. AC analysis evaluates key figures of merits, including transconductance, cut-off frequency, and parasitic capacitances. It is observed that the high-k spacer significantly enhances electrostatic control reducing short-channel effects (SCEs) and improving device stability. The optimized underlap minimizes parasitic capacitance, leading to ~103% increase in cut-off frequency and ~163% improvement in transconductance, resulting in enriched high-frequency performance. These findings underscore the potential of GaN-based GAA FETs with high-k spacer and underlap designs for low-power, high-speed applications in green and sustainable electronics, particularly for IoT systems and 5G technologies. The integration of gate underlap with high-k dielectric spacer region effectively reduces SCEs and parasitic resistances. By controlling the electric field distribution and improving electrostatics integrity this design achieves augmented switching speed while suppresses leakage significantly, making the device a strong candidate for next-generation digital and RF applications."
  },
  {
    "year": "2025",
    "abstract": "Image segmentation, a fundamental problem in image processing, involves distinguishing the foreground from the background. Traditional image segmentation methods are typically divided into local and global approaches. Local methods often result in blurred segmentation due to their reliance on overly localized color sampling models. Conversely, global methods, which depend on the overall color distribution, struggle with images where the foreground and background share similar global characteristics. To overcome these limitations, a novel image segmentation method that integrates nonlocal criteria with graph cut theory is proposed. Initially, the method transforms the image’s color space to the HSV color space, enhancing color contrast. Following this, nonlocal criteria are utilized to compute the data term within the graph cut model, which is then incorporated into the traditional graph cut framework for final segmentation. This approach broadens the neighborhood sampling range in local models, allowing the model to identify more valuable nonlocal samples while mitigating the impact of color similarity in global models. Experimental results across various datasets indicate a marked improvement in segmentation quality achieved by the proposed method."
  },
  {
    "year": "2025",
    "abstract": "With the continuous integration of large-scale distributed energy resources into distribution networks, numerous challenges arise regarding security, stability, and economic performance, particularly voltage violations and increased network losses. Furthermore, existing deep reinforcement learning (DRL) methods often rely on extensive real-world operational data for agent training. Yet, the lack of diversity in the collected data can significantly limit the generalization ability of agents under varying operating conditions. This paper proposes a regional voltage optimization control strategy for distribution networks to address these issues based on DRL supported by large language model (LLM). By integrating LLM technologies with DRL, the approach leverages prompt engineering to guide large-language models in generating customized datasets for DRL agent training, enabling data augmentation. This reduces the dependence on real-world data while improving the generalizability of agents. The proposed control strategy was validated on modified IEEE 33-bus and 123-bus distribution systems. The experimental results effectively mitigate voltage violations and reduce network losses while exhibiting strong robustness and generalization under various operating conditions."
  },
  {
    "year": "2025",
    "abstract": "Cross-modal research has long been a critical pillar for the future development of human-computer interaction. With deep learning achieving remarkable results in computer vision and natural language processing, image captioning has emerged as a key focus area in artificial intelligence research. Traditionally, most image captioning studies have focused on the English context; however, interdisciplinary efforts should not be confined to monolingual environments. Instead, it is essential to expand into multiple languages, given that Chinese is one of the world’s most widely used logographic languages. The study of Chinese image captioning holds immense value but presents significant challenges due to the complexity of Chinese semantic features. To address these difficulties, we propose a Deep Fusion Feature Encoder, which enables the model to extract more detailed visual features from images. Additionally, we introduce Swi-Gumbel Attention and develop a Feature Filtering Block based on it, aiding the model in accurately capturing core semantic elements during caption generation. Experimental results demonstrate that our method achieves superior performance across multiple Chinese datasets. Specifically, in the experimental section of this paper, we compared our proposed model with those based on recurrent neural networks and transformer, demonstrating both its advantages and limitations. Additionally, we provided insights into future research directions for Chinese image captioning. Through ablation experiments, we validated the effectiveness of the Deep Fusion Feature Encoder, Swi-Gumbel Attention, and Triple-Layer Feature Filtering Block. We also explored the impact of different architectural configurations within the Multi-Layer Feature Filtering Block on caption accuracy."
  },
  {
    "year": "2025",
    "abstract": "Array manifold, constructed from the received signals by incoming waves in antenna arrays, serves as a fundamental framework for characterizing electromagnetic behavior in direction finding systems. For densely arrayed 2-D planar antenna systems, strong inter-element mutual coupling distorts the array manifold, which directly degrading direction finding performance. While electromagnetic numerical techniques can be used to analyze mutual coupling effects in receiving antenna systems, large computational costs are required for 2-D array structures. This paper presents a fast reciprocal analysis method, based on a directional decomposition approach, for mutual coupling characterization of 2-D receiving antenna systems. The proposed method incorporates antenna current Green’s function theory to analyze the reciprocal property between transmit and receive modes of 2-D array antennas. Through directional decomposition, 2-D array problem is transformed into two separate 1-D array analyses, reducing computational complexity fromO(M2B(N3xN3y))toO(M2B(N3x+N3y)). Building upon previous work that effectively characterized transmit-mode behavior, this study validates the directional decomposition approach in receiving modes based on reciprocity. The approach accurately predicts both receive-mode antenna current Green’s function and array manifolds while preserving mutual coupling and truncation effects. Validation is performed through direction finding scenarios. Validation through comparison with full-wave analysis demonstrates high correlation in array manifold components across all observation angles (θ:−63∘to 63°,ϕ:−126∘to 126°). In direction of arrival estimation applications with various multiple-source scenarios, the method achieves angular resolution comparable to conventional full-wave analysis while reducing computation time to 0.18% of the original requireme..."
  },
  {
    "year": "2025",
    "abstract": "The manufacturing quality of printed circuit boards (PCBs) significantly influences the functionality and life expectancy of electronic devices. This paper introduces a YOLO-WWBi based on improved YOLO11 framework method for the detection of surface defects. First, an improved weighted and re-parameterized ghost multi-scale feature aggregation module (WRGMSFA) is designed. This module focuses more on defect information channels, enhancing multi-scale feature extraction capabilities while suppressing redundant information. Then, BiFPN is integrated into the neck to enhance the quality of fused features and deepen the interaction of feature information. Finally, the WIoU loss function was employed to optimize the localization performance of defect positions, thereby enhancing robustness in highly similar PCB background interference. The experimental results indicate that YOLO-WWBi has an mAP of 96.6%, surpassing YOLO11 by 5.4 points. Its performance metrics indicate that the requirements for the high-precision, real-time detection of PCB defects are satisfactorily met."
  },
  {
    "year": "2025",
    "abstract": "Phased array ultrasound technology has demonstrated its capability in detecting lead seal defects within high-voltage cable terminals. However, conventional ultrasound quantitative methods often fall short in accurately measuring the dimensions of these defects. This paper introduces a novel method for the detection and quantification of lead seal defects in high-voltage cable terminals. By focusing on the longitudinal wave fan scan images of these defects and integrating threshold segmentation with corrosion algorithms, the method provides real-time information on defect characteristics, including cross-sectional area and height. The findings reveal significant improvements over the traditional −6dB method: a 5% reduction in distance error, a 10% enhancement in defect size accuracy, and an overall accuracy rate exceeding 85%. This research holds substantial reference value for the engineering application of lead sealing defect detection in high-voltage cables, contributing to the advancement of lead sealing technology and ensuring the reliability and safety of power grid operations."
  },
  {
    "year": "2025",
    "abstract": "The rapid advancement of technology in the post-COVID-19 era has positioned immersive learning as a transformative approach to enhance educational experiences. Despite its vast potential, recent research developments reveal persistent challenges and gaps that impede widespread adoption. This study conducts a scoping review using the PRISMA methodology to systematically analyze current literature, identify research gaps, seek the challenge, and propose future research directions. From an initial pool of 414 papers, 75 were selected, comprising 60 research studies and 15 review papers. Notably, 55 studies focus on immersive virtual reality (IVR) purely for educational enhancement in traditional academic settings, while 20 explore the implementation of IVR in education with gaming activities. The analysis indicates a predominance of mixed-methods research within education, computer engineering, and computer science. Most studies are limited by short durations (typically 30 minutes) and small participant groups (under 50), raising concerns about the generalizability of findings. Key themes identified include learning context (21 papers), learning design strategies (ten papers), and immersion elements such as avatars and haptic feedback (six papers). While positive impacts like increased satisfaction, motivation, engagement, knowledge enhancement, and usability are reported, negative effects such as motion sickness (13 papers) and dizziness (11 papers) persist. Crucially, only 11 studies exhibit high statistical power, underscoring the need for more robust research designs. Challenges identified encompass participant limitations, homogeneity, user discomfort, hardware unfamiliarity, and cognitive load—all intricately linked to design strategies. The implications of this review highlight the necessity for future research to focus on long-term studies, optimize user experience, develop cost-effective content creation methods, and integrate gamification into learning design..."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces a generalized Virtual Load Theory (VLT) for mitigating mutual coupling in antenna arrays through digital signal preprocessing. The method employs Coupling Compensation Matrices (CCMs) derived from generalized Thévenin-Helmholtz equivalent circuits, formulated using impedance and scattering matrices. A key finding reveals that the scattering matrix-based CCM does not always align with the impedance matrix-based solution; this discrepancy is analyzed and resolved to ensure theoretical consistency. Unlike traditional compensation techniques, VLT enables effective coupling mitigation without requiring physical modifications to the array or continuous recalculations. We define two major antenna elements as current-driven (CD), such as a dipole antenna, and voltage-driven (VD), such as a patch antenna. In receiving arrays, we demonstrate that the open-circuit voltage,Voc, for CD elements and short-circuit current,Isc, for VD elements are inherently immune to mutual coupling. Simulation results show that the method successfully recovers embedded element patterns, closely matching isolated patterns even under severe coupling conditions. Experimental validation using a two-monopole prototype array with0.13λelement spacing further confirms the effectiveness of VLT in eliminating mutual coupling effects in far-field radiation patterns."
  },
  {
    "year": "2025",
    "abstract": "Chronic Kidney Disease (CKD) is a progressive condition that requires accurate diagnosis and staging for effective clinical management. Conventional CKD diagnosis relies on estimated Glomerular Filtration Rate (eGFR), a measure of kidney function derived from serum biomarkers such as serum creatinine (SCr) and cystatin C (SCysC). However, eGFR calculations may be inaccurate when applied to diverse patient populations. This study proposes a machine learning (ML) system that integrates regression-based eGFR estimation, metaheuristic optimization using the Grey Wolf Optimizer (GWO), and multi-class classification with various ML models to enhance CKD staging and classification. The model estimates eGFR using three established CKD Epidemiology Collaboration (CKD-EPI) equations incorporating SCr, SCysC, and their combined values. Regression models assess predictive performance, specifically Linear Regression (LR) and Support Vector Regression (SVR). SVR demonstrates superior performance compared to LR forCKD-EPISCr-SCysCachieved a root mean squared error (RMSE) of 3.03, a mean absolute percentage error (MAPE) of 2.97%, and a coefficient of determination (R2) score of 0.97. The application of GWO for hyperparameter tuning has resulted in a 37.3% reduction in root mean square error (RMSE), a 37.4% drop in mean absolute percentage error (MAPE), and a 2.06% improvement inR2to improve the precision of prediction. Once the model fine-tunes the eGFR estimations, it feeds them into various algorithms for CKD stage classification, including Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). Among these, XGBoost achieves the highest classification accuracy of 97.76%, along with an F1-score of 97.45%, demonstrating its effectiveness in CKD staging. Shapley Additive Explanations (SHAP) provide global and local feature importance insights, enhancing clinical decision-m..."
  },
  {
    "year": "2025",
    "abstract": "The main purpose of the study is to investigate and demonstrate the feasibility and practicality of using a haptically-enabled remotely controlled ultrasound examination system (HERCULES) to perform point-of-care ultrasound. Robotic ultrasound is an emerging and important technology. This technology can help in performing ultrasound imaging in potentially contagious patients while minimizing risks of infections for sonographers (persons who perform ultrasound). This study assesses whether the robotic ultrasound system can reduce the musculoskeletal injuries sonographers endure. We developed a haptically-enabled robotic ultrasound system, which provides sonographers with a sense of touch throughout the scan. The system has haptic capabilities in which the sonographer can feel the contact force remotely and would be able to apply pressure appropriately to safeguard the patient. The system is equipped with various force thresholds. The sonographer can view the patient as well as the transducer’s position and orientation. More than 500 robotic images were captured, and a supplementary evaluation by expert radiologists was conducted to provide initial insights into image quality. In total, 56 subjects, 31 female and 25 male, aged from 21 to 55 years, participated in the clinical trials. An assessment is also carried out on the stimulation of the sonographer’s muscles during conventional vs. robotic scanning. As a result, the sonographer experienced substantial relief in back and neck muscles, right abductor pollicis brevis and right C4 paraspinal, by 88.12%, 89.19%, 93.57%, 82.0%, 72.83%, and 75.1% reduction from manual to teleoperated scenario, respectively. Subjects also reported a much more comfortable experience during robotic ultrasound scans."
  },
  {
    "year": "2025",
    "abstract": "Phishing remains a critical security threat, involving the creation of fraudulent websites to capture sensitive information. Despite existing detection systems, sophisticated attackers have developed advanced evasion techniques that undermine these defenses. This paper highlights the significant challenge of these novel methods, focusing on how attackers manage to prolong the operational lifespan of phishing sites. Our research investigates how attackers circumvent traditional security layers by employing a combination of target filtering mechanisms, bot detection evasion, blacklisting avoidance, and honeypots. Our experimental findings indicate that these evasion strategies can achieve an effectiveness rate of 80% to 85% in extending the viability of phishing sites. We have empirically demonstrated the exposure of current systems to these attacks, revealing specific vulnerabilities and exploitation points. These results underscore the urgent need for enhanced detection frameworks that address the layered and adaptive nature of modern phishing tactics. Our work highlights a critical gap in current security measures and poses a challenge to solution providers: there is a pressing need for novel mitigations to safeguard users against these sophisticated phishing threats."
  },
  {
    "year": "2025",
    "abstract": "The skip list is a popular in-memory index in modern database systems. It maintains multiple levels of lists, which makes it efficient in traversing sorted data. In addition, it is flexible in inserting and deleting data, while avoiding the restructuring overhead of tree-based structures. However, there are considerable challenges in the conventional skip list design. First, the linked list structure has a drawback in utilizing microarchitecture features such as cache, pipeline, and SIMD (Single Instruction Multiple Data) capability. Second, the skip list randomly selects the level of a new node. That is, the skip list runs based on probability rather than data distribution, which can lead to suboptimal lookup performance. Unlike balanced tree structures, the worst-case lookup performance of a skip list remains O(n). This paper proposes a new data structure called DASL (Deterministic Arrayed Skip List). It follows the algorithm of the skip list, but seamlessly integrates the array and devises a new deterministic raise operation in order to obtain flexibility, microarchitecture-friendliness, and reduced tail latency. In specific, a node in DASL consists of an array structure with multiple elements instead of a single element, taking advantage of the array within a list structure. Additionally, the raise operation is conducted deterministically instead of probabilistically, allowing data to be more balanced in multiple lists. Furthermore, we devise two optimization techniques, utilization-based adaptive intra-node search and uneven split operation. Experimental results with various synthetic and real-world workloads demonstrate that DASL outperforms other state-of-the-art in-memory indexes, including skip list, B+tree, and ART."
  },
  {
    "year": "2025",
    "abstract": "Software Defined Networking (SDN) has emerged as a promising paradigm for network management. However, in energy-effective task scheduling and security, the centralized control architecture of SDN brings challenges. This research proposes a new approach for blockchain-based secure resource allocation with controller selection in SDN, utilizing the Entropy Oppositional Based Learning-Interpolation Blue Monkey Optimization Algorithm (EOBL-IBMOA). By establishing a blockchain-centric secure resource allocation with controller selection, the proposed technique addresses challenges in SDN. Here, user registration, load balancing, attack detection, controller selection, and resource allocation phases are included. Utilizing XOR Left Shift (XORLS), the user details are secured by IP traceback and hash codes are generated using the Mid Square-based KECCAK 512 (MS-KECCAK 512) algorithm. For effective traffic balancing, the load balancer uses the Minshev-KMeans algorithm. Attack classification is attained through the Quantile Transformer Scaling based SoftmaxGELU Gated Recurrent Units (QTS-SGGRU) approach. EOBL-IBMOA is used by controller selection and resource allocation for optimal Virtual Machine (VM) selection. The proposed technique’s superiority is described by experimental comparisons. The proposed approach attains effective resource allocation with reduced response time and high throughput, outperforming the prevailing works."
  },
  {
    "year": "2025",
    "abstract": "Genetic programming (GP) and fuzzy logic are used to automatically segment mammography images. GP allows the evolution of optimized segmentation models, guided by a fuzzy logic-based fitness function that incorporates medical criteria to improve the consistency and accuracy of the segmentation process. Unlike conventional approaches, this function optimizes the segmentation and provides a descriptive representation of the breast tissue, allowing a closer evaluation to that performed by specialists. The proposed method was evaluated in the INbreast and BCDR databases, obtaining a Jaccard index of 0.82 and 0.78, respectively, and a comparative analysis was performed using ROC curves, reaching an AUC of 0.91 in INbreast and 0.89 in BCDR, demonstrating the model’s ability to discriminate between fibroglandular and fat tissue. Its performance was compared with state-of-the-art methods, such as LIBRA, hybrid segmentation with Fuzzy C-Means, and NASGP-Net, showing that integrating fuzzy logic in genetic programming to lead the search allows competitive results with a lower computational burden. These results demonstrate the impact of fuzzy fitness functions in the evolution of segmentation models, highlighting the effectiveness of this approach in improving the segmentation and classification of medical images, in addition to the descriptive capabilities inherent to the fuzzy fitness function."
  },
  {
    "year": "2025",
    "abstract": "Recently, tremendous growth in e-business has arisen in an increasing number of online transactions. Such widespread adaptation of e-payments has been going along with the increase in deceitful activities, which results in tremendous losses in the financial sector. This led to a novel research paradigm using statistical and auto-data-driven techniques to detect anomalies and fraud. Thus, traditional techniques fail to provide a secure medium for online transactions. Consequently, building a credit card fraud (CCF) detector is essential for secure online operations. Therefore, based on the abovementioned constraints, this paper presents a comprehensive study incorporating heterogeneous machine learning (ML) techniques for CCF detection. The proposed framework utilizes a multi-stage classification system that employs multiple classifiers, i.e., logistic regression, support vector machine (SVM) XGBoost, Random Forest, K-Nearest Neighbors (KNN), and Deep Neural Network (DNN). Furthermore, to accomplish the intensive class imbalance, the proposed technique uses a sampling technique with an internal features selection technique implemented based on voting among different methods. The key finding indicates that the proposed model surpasses the existing DNN simple voting, traditional stacking framework with a fraud recall value of 0.901, a legitimate recall value of 0.995, and a model cost value of 0.421."
  },
  {
    "year": "2025",
    "abstract": "Multilayer ceramic capacitors (MLCCs) are electronic components constructed with alternating layers of electrode and dielectric materials. Nevertheless, few studies have examined reliability issues during the manufacturing process, leaving a gap in understanding how production conditions impact MLCC performance. The manufacturing process of MLCCs utilizes isostatic pressing to laminate and compress these layers to form an MLCC bar. However, due to the heterogeneous multilayered structure of the bar, non-uniform deformation occurs after the procedure. To address this issue, this study aims to optimize the design of MLCC bar to minimize non-uniform deformation and reduce subsequent failure rates of MLCC production under isostatic pressing condition. Finite Element Analysis (FEA) is employed as the primary research tool, incorporating a homogenization method to simplify the geometry while maintaining analytical accuracy. The findings indicate that the design of the index regions is a critical design parameter in determining the deformation patterns and failure rates. Particularly, the stiffness of the side and corner index regions influences the curvature observed along the edges. Through a design sensitivity analysis on these regions, the study successfully optimized the MLCC bar design, reducing the failure rate to 0% from a previous high of 30%."
  },
  {
    "year": "2025",
    "abstract": "In electric vehicles (EVs), the noise and vibration of the traction motors are key indicators of vehicle quality. The dynamic characteristics of the stator core assembly of the traction motor are crucial in this regard. This study introduces a methodology to predict the dynamic characteristics of self-bonding stator core assemblies with bar-type windings at the design stage, without experimental tuning. The dynamic characteristics of the stator core assemblies were analyzed after using the homogenization method, which considers lateral contractions, to derive the equivalent material properties of the individual components. The stator core assemblies were modeled following the sequence of steps in the actual manufacturing process. Additionally, the study considers the asymmetric mass and stiffness distribution caused by bar-type windings and their boundary interactions with the stator core, and proposes a modeling approach that enables these effects to be reflected in dynamic predictions. Comparisons with experimental modal analysis showed that the proposed method predicted the natural frequencies with deviations of less than 2.8% for the stator core and 3.5% for the stator core assembly. The average MAC values were 0.965 and 0.910, respectively, confirming the accuracy of mode shape prediction. This demonstrates the proposed method can be effective in improving the dynamic performance of the traction motors used in EVs."
  },
  {
    "year": "2025",
    "abstract": "The score is an indispensable element in competitive sports, playing a crucial role in determining the outcome of a match. However, the importance of scores in table tennis remains unexplored, as the hundreds of possible score scenarios in a single set make it especially challenging to assess their significance scientifically. This study is the first attempt to quantify the relevance of all possible scores in table tennis matches through probabilistic computing and empirical verification. Depending on the overall winning probability, relevance values were determined for the 121 possible scores. An extensive dataset consisting of 1,364 matches and 103,772 individual scores from top-level table tennis was examined to test the empirical winning probabilities of each score. The results highlight a significant correlation between the theoretical score relevance and players’ empirical winning probabilities. Winners perform better at more relevant scores, such as close scores or crunch time, with this trend being more pronounced among male players. Z-tests were used to identify scores with positive or negative deviations from the average scoring rate. Individual players show considerable variation in scoring performance across different score situations. These findings provide significant implications for players’ training and competition. The approach presented in this study can also be applied to other scoring games and sports."
  },
  {
    "year": "2025",
    "abstract": "Single-capacitor coupled wireless energy transmission has been widely noticed due to its advantages of simple coupling mechanism and absence of cross-coupling capacitance. However, because of its lack of traditional electrical circuit, the coupling mechanism electrical energy transmission mechanism and the establishment of equivalent model are not completely unified by theory and experiment at present. And the efficiency of the existing single capacitor coupled wireless energy transmission systems are relatively low. In this paper, for the single-capacitor coupling mechanism, based on the self-capacitance theory, an equivalent model of the coupling mechanism is proposed for the case where both the transmitter and receiver have a stable ground, and a single-capacitor wireless energy transmission system based on a class E inverter is designed. The resonant circuit is selected as a CLC-LC-LC high-order resonant network. The paper firstly describes the system topology design and the equivalent capacitance of the coupling mechanism, and then the whole circuit topology is equivalent to a classical Class E inverter for parameter design. The feasibility of the selected parameters is verified by simulation. Finally, an experimental prototype is built based on the parameter design, and the experiment shows that the system has high voltage gain, with an efficiency up to 77%; it can still provide high output power with half of the lateral offset of the pole plate; and it possesses high load range, with an efficiency of more than 70% in the load range of160Ω-220Ω."
  },
  {
    "year": "2025",
    "abstract": "Contribution: This study addresses the gap in understanding the practical context of corporate education for Digital Transformation (DT) within the semiconductor industry. Background: The COVID-19 pandemic accelerated global digital transformation initiatives, with South Korea’s semiconductor industry implementing comprehensive DT education programs since 2020. However, its practical and empirical influence and limitations have never been rigorously examined. Research Question: What impact, barriers and improvement strategies do DT education programs have on individual and organizational DT competencies in the semiconductor industry? Methodology: Employing a qualitative research design, in-depth interviews were conducted with 20 employees from diverse job roles and educational backgrounds within the semiconductor industry. Findings: The research reveals that while general DT education improves digital literacy and fosters individual and team-level innovation, this is often realized through small-scale digital transformation initiatives. However, significant challenges hinder further potential, including short-term performance evaluation frameworks, restrictive IT policies, a lack of advanced, role-specific training, and insufficient understanding of DT concepts and strategies among organizational leaders. To address these challenges, the study recommends refining evaluation systems, easing policy constraints, and tailoring training programs to specific roles. Additionally, it emphasizes the importance of leadership-focused DT education to enhance leaders’ understanding of digital transformation, enabling them to better guide and support organizational initiatives. These measures aim to amplify the practical applications of DT efforts, fostering sustained organizational growth and innovation. Limitation and Future Work: This study faces several limitations, including an industry bias toward semiconductors, a short observation period, subjective self-reported data, in..."
  },
  {
    "year": "2025",
    "abstract": "The advancement in computing power has significantly reduced the training times for deep learning, enabling the rapid development of networks designed for object recognition. However, the exploration of object utility, the object’s affordance, as opposed to object recognition, has received comparatively less attention. Existing object affordance models exhibit shortcomings, including limited robustness across diverse architectures and insufficient performance in complex environments. This work focuses on using pre-trained networks trained on object classification datasets to explore object affordances. While these networks have proven instrumental in transfer learning for classification tasks, the presented approach in this study diverges from conventional object classification methods by labeling affordances without modifying the final layers. Instead, pre-trained networks are employed to learn affordance labels without requiring specialized classification layers. Two approaches are tested: the Subspace Projection Method and the Manifold Curvature Method, which facilitate the determination of affordance labels without such modifications. Both the Subspace Projection Method and the Manifold Curvature Method were evaluated using nine distinct pre-trained networks across two different affordance datasets. The Subspace Projection Method achieved a True Positive Rate of up to 94% and 96% for the best-performing networks on each dataset, while the Manifold Curvature Method attained True Positive Rates exceeding 98% and 99% with its top-performing networks. Furthermore, both methods identify affordance labels that are not marked in the ground truth but are present in various cases. The robustness of the Manifold Curvature Method and the exploration capability of both methods highlight the effectiveness of proposed techniques for affordance labeling."
  },
  {
    "year": "2025",
    "abstract": "Traffic signal control (TSC) is a part of intelligent transportation systems to reduce traffic congestion and emissions. Recently, dynamic traffic signal control systems using artificial intelligence and reinforcement learning have been studied to achieve these goals. Although verification of TSC algorithms is ideally performed in a real environment, traffic simulation tools are widely used due to safety issues. However, existing simulation tools have limitations in real-time result analysis, making it difficult to analyze the strengths and weaknesses of each algorithm according to each traffic situation. In this paper, we propose RTASS, a real-time analysis simulation system for TSC algorithms that enables real-time comparison and result analysis, to improve the problems of such a simulation environments. To validate RTASS, we experiment using actual intersection data. As a result of comparing the traffic volume of the actual intersection data and the simulation, we confirmed that the error rate was maintained within 2% on average. In addition, we evaluate the performance of each TSC algorithm using RTASS and verify the results by comparing two existing methods and two proposed TSC methods. We confirmed that real-time comparison of traffic analysis and algorithms is possible using the proposed simulation system."
  },
  {
    "year": "2025",
    "abstract": "Time-division multiple access schemes such as time-slot coding (TSC) provide an effective and simple multi-user access framework for indoor free-space optical communications (FSO) with limited inter-user interference. For realistic multi-user scenarios employing TSC, clock data recovery is indispensable to achieve timing synchronization for different users, which lacks investigation in the previous study on TSC. In this paper, for the first time, we experimentally demonstrate a time-slot coded multi-user FSO system employing clock data recovery, in which a sum data rate of 40-Gb/s with bit-error-rate (BER) of each user around the 7% hard-decision forward error correction (HD-FEC) limit can be achieved. Moreover, to further improve the system performance, we propose a novel clock data recovery scheme for multi-user FSO systems employing TSC. Experimental results show that more than 3dB received optical power gain can be obtained to achieve the reference BER level of the 7% HD-FEC limit as compared to the system employing the conventional clock data recovery scheme. Higher-precision timing synchronization and ultra-fast convergence speed can also be achieved via our proposed clock data recovery scheme."
  },
  {
    "year": "2025",
    "abstract": "In industrial production, defect detection of steel materials is critical for maintaining quality. However, traditional inspection methods are labor-intensive and error-prone, while existing deep learning-based detection approaches generally suffer from poor performance in industrial defect detection and insensitivity to small defects. This paper presents YOLO-SAFD, an advanced framework based on YOLOv5, designed to address these challenges. The proposed model incorporates two key innovations: 1) the Squeezed and Excited Asymptotic Feature Pyramid Network (SAFPN), which enhances multi-scale feature fusion and improves the detection of small defects, increasing the mean Average Precision (mAP) from 0.78 (YOLOv5 baseline) to 0.84; 2) the Diverse Branch Block (DBB), which replaces conventional convolutions to enrich feature diversity while reducing computational complexity, cutting the model parameters from 13.8M to 4.82M. Experimental results on the NEU-DET dataset demonstrate that YOLO-SAFD achieves a detection precision of 0.83, a recall of 0.75, and an mAP50:95 of 0.43, outperforming the baseline YOLOv5 and highlighting its superior detection accuracy and efficiency for real-time industrial applications."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a snubber circuit for SSCB that performs voltage clamping operation in two stages to reduce surge voltage. The surge voltage is suppressed in the first stage using a MOV with low operating initiation and clamping voltages. Then, the fault current gradually rises with a gentle slope and reaches the clamping voltage of the second MOV, which shows the effect of reducing the surge voltage. By adding RC circuits connected in series and parallel to two MOVs, fast dissipation of energy generated by fault current, high interrupting capacity, and low energy loss are ensured. Theoretical analysis is performed on the operational mode of the proposed snubber circuit, and its validity is verified through simulation and experiment. The effects of dissipated energy due to fault current, energy dissipation time, surge voltage reduction rate, voltage ringing, and stray inductance are analyzed, and compared with the prior snubber circuit, the proposed snubber circuit is evaluated to be suitable for SSCB of electric propulsion ships."
  },
  {
    "year": "2025",
    "abstract": "Educational timetabling, a principal branch of operations research, presents challenging combinatorial optimization problems widely encountered in educational institutions. Meta-heuristics have commonly been applied to these problems and managed to attain promising performance in terms of optimality. However, their general applicability has been overlooked, hindering their effectiveness as versatile solvers. The limited generalizability of current approaches is the primary hurdle between the literature and real-world applications. This paper addresses this gap by introducing a generality taxonomy and conducting comprehensive theoretical and empirical analyses. This study highlights the adverse impact of extreme parameter tuning on generality, emphasizing the need for more generalized approaches. Furthermore, it introduces a performance assessment framework, penalizing problem-tailored solutions. It also examines the optimality vs. generality performance of the state-of-the-art approaches of the latest university course timetabling benchmark to further reinforce our claim and validate the efficacy of our framework. Our findings indicate that the current literature prioritizes optimality over generality. We believe adopting the proposed assessment framework is crucial for bridging the gap between research and practical applications, enabling fairer comparisons, and encouraging more adaptable approaches."
  },
  {
    "year": "2025",
    "abstract": "Public attitudes towards energy sources and climate change are increasingly complex. This paper explores Americans’ perceptions of energy sources including renewables, Electric Vehicles (EVs), government policies and climate change. A survey conducted by the Pew Research Center (PRC), comprising over 10,000 responses to 52 questions on energy sources and climate change, is analyzed. In this paper, we propose a data analysis framework that consists of Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA), cluster analysis and Principal Component Analysis (PCA) to segment respondents and identify key variables. Furthermore, the Structural Equation Model (SEM) is created to examine relationships between latent and observed variables, using maximum likelihood estimation. The results validated the identified factors, with high loading on key variables indicating strong contributions to attitudes towards energy and climate policies."
  },
  {
    "year": "2025",
    "abstract": "A compact cylindrical-shaped flat dielectric lens (FDL) antenna, partially sandwiched within a parallel-plate waveguide (PPW), is presented. The design elegantly combines uniform FDL functionality within a PPW with a wideband rectangular waveguide-based feed network, resulting in a streamlined, highly manufacturable design suited for commercial beam-steering applications. In the feed network, an array of probe-fed rectangular waveguides, each accompanied by a symmetric E-plane step discontinuity and a partial-height conducting post, is employed to enable the launch of multiple beams over a wide operating frequency band. The lens design follows the procedure of partially sandwiching the cylindrical uniform dielectric between parallel conducting plates, allowing the dielectric extension beyond the plates to improve free-space matching and acting as a dielectric rod antenna to enhance directivity. The overall radiation performance of the antenna versus the feed network positions along the focal length of the FDL is precisely optimized through the use of the ray-tracing technique and genetic algorithm. This synergy yields a streamlined and highly manufacturable architecture specifically tailored to meet the demanding requirements of commercial beam-steering applications. The proposed FDL antenna with a nine-element feed network is designed to achieve azimuthal beam steering between ±33°. The results show that the gain remains almost constant within this range, with nearly 0.1 dB measured fluctuation. To validate the performance, the proposed FDL antenna is fabricated and measured. The measurements agree with the simulation results, demonstrating a wide operational bandwidth of 50% spanning from 24 to 40 GHz with a stable beam-steering capability. The antenna maintains consistent radiation characteristics throughout the operating range, with sidelobe levels below −15 dB and a peak gain of 16.7 dBi at the central frequency of 32 GHz. These features make the antenna suitab..."
  },
  {
    "year": "2025",
    "abstract": "High temporal and spatial resolution Earth observation data are crucial in remote sensing, but it is difficult to acquire images that guarantee high temporal and spatial resolution simultaneously due to satellite, technology and budget constraints. In this paper, time series image data with 10 m resolution are generated by spatio-temporal fusion of Modis, Landsat and Sentinel data, which reduces the temporal resolution to 1-2 days, while the existing EDCSTFN model is improved in order to overcome the problem of difficulty in global information extraction due to convolution limitation. The encoder and residual encoder use multi-scale convolution to capture more information from raw Landsat data and enhance feature extraction. In addition, a channel attention module (SE) is introduced to model the nonlinear relationship across channels, which improves the nonlinear capability of the model and reduces the sensitivity to the quality of input data. This approach not only improves the fusion accuracy, but also increases the computational efficiency, leading to the proposal of a new architecture, MIEDCSTFN. 10m-resolution data for the corresponding dates are generated using the output Landsat data from the improved EDCSTFN model as input to the DSTFN model. Comparative validation with several models shows that the improved model has higher accuracy and robustness, and the obtained 10m data are very close to the real data. Compared with the original model, SSIM improves 12.54%, RMSE improves 46.38%, SAM improves 15.46%, ERGAS improves 15.74%, and the experimental results show that the improved model has excellent performance and significant advantages in improving image fusion effect."
  },
  {
    "year": "2025",
    "abstract": "Effective student management is crucial for fostering productive learning environments. This study presents a hybrid framework integrating machine learning (ML) techniques with rough set theory to enhance student management by identifying at-risk students and enabling personalized interventions. The model combines classification algorithms with rough set-based decision rules to analyze complex student data, including academic performance, behavior patterns, and levels of engagement. The ML layered approach detects patterns and outliers, supporting data-driven decisions to improve student well-being and educational outcomes. Evaluation on the Open University Learning Analytics Dataset (OULAD) demonstrated high accuracy (97.85%) in predicting student outcomes and precision (94.62%) in identifying students needing support. The hybrid approach outperformed conventional methods by approximately 15%, showcasing its transformative potential. This framework effectively monitors student performance and enables customized interventions to meet individual learning needs, fostering a more supportive educational environment."
  },
  {
    "year": "2025",
    "abstract": "Predicting student performance in Virtual Learning Environments (VLEs) has become increasingly important with the growth of online education. Early identification of at-risk students allows timely interventions to improve academic outcomes. This study evaluates the performance of several Deep Learning (DL) models for tabular data, including ResNet, NODE, AutoInt, TabNet, TabTransformer (TT), SAINT, and GatedTabTransformer (GTT). Moreover, it examines the role of resampling techniques, including SMOTE, ROS, ADASYN, RUS, and Tomek Links, in addressing class imbalance. Using the OULA dataset, eight experiments were conducted for binary and multi-class classification tasks, testing different feature combinations: 1) behavioral, 2) demographic and behavioral, 3) academic and behavioral, and 4) demographic, academic, and behavioral. The results indicate that incorporating a comprehensive set of characteristics can significantly enhance the model’s performance, with academic characteristics proving more predictive than demographic characteristics. The SAINT model achieved the highest performance in binary classification (94.33% accuracy), leveraging its ability to capture meaningful yet straightforward feature interactions. For multi-class classification, SAINT again outperformed other models, achieving an accuracy of 73.22% when using the Tomek Links method, excelling in managing complex feature interactions and underrepresented classes such as “Distinction.” Statistical analysis was done using the Friedman aligned ranks test and the Nemenyi post-test to compare how well the models performed based on F1-scores from several experiments. The non-parametric Friedman test revealed significant differences among the models (p=0.00013). SAINT and AutoInt consistently outperformed the other approaches, while ResNet and TT demonstrated the weakest performance. Post-hoc analysis using the Nemenyi test did not show statistically significant differences among mid-tier models (T..."
  },
  {
    "year": "2025",
    "abstract": "Autoencoders are a type of deep neural network and are widely used for unsupervised learning, particularly in tasks that require feature extraction and dimensionality reduction. While most research focuses on compressing input data, less attention has been given to reducing the size and complexity of the autoencoder model itself, which is crucial for deployment on resource-constrained edge devices. This paper introduces a layer-wise pruning algorithm specifically for multilayer perceptron-based autoencoders. The resulting pruned model is referred to as a Shapley Value-based Sparse AutoEncoder (SV-SAE). Using cooperative game theory, the proposed algorithm models the autoencoder as a coalition of interconnected units and links, where the Shapley value quantifies their individual contributions to overall performance. This enables the selective removal of less important components, achieving an optimal balance between sparsity and accuracy. Experimental results confirm that the SV-SAE reaches an accuracy of 99.25%, utilizing only 10% of the original links. Notably, the SV-SAE remains robust under high sparsity levels with minimal performance degradation, whereas other algorithms experience sharp declines as the pruning ratio increases. Designed for edge environments, the SV-SAE offers an interpretable framework for controlling layer-wise sparsity while preserving essential features in latent representations. The results highlight its potential for efficient deployment in resource-constrained scenarios, where model size and inference speed are critical factors."
  },
  {
    "year": "2025",
    "abstract": "The rapid growth of the crypto asset industry has led to the adoption of proof of reserves (PoR) protocols for transparency in centralized exchanges (CEXs). By providing proofs to users that the exchange’s total reserves equal or exceed its total liabilities, PoR allows these exchanges to demonstrate that they have enough funds. This paper identifies a vulnerability in current PoR methods, where malicious CEXs can manipulate snapshots to F understate liabilities, making reserves appear larger. To address this, we propose a framework where users take their own snapshots during a strategic trading pause, allowing the validation of the PoR result. The framework is compatible with existing PoR methods. We also propose a user-driven handshake (UDH) pause model to minimize disruptions. We evaluate the effectiveness of the framework in preventing snapshot cherry-picking as well as its practicality in minimizing trade pauses."
  },
  {
    "year": "2025",
    "abstract": "The increasing energy demand and rising fossil fuel prices are accelerating the transition to renewable energy, supported by government initiatives due to their environmental and economic advantages. However, challenges such as limited capacity and stability constraints hinder the widespread adoption of distributed energy resources (DERs). Virtual Power Plants (VPPs) enhance market participation by aggregating DERs, while electric vehicles (EVs) contribute to environmental sustainability by reducing emissions. Additionally, integrating distribution static compensators (DSTATCOMs) within VPPs improves microgrid stability and reactive power support. This study proposes a two-stage optimization approach to enhance network resilience and VPP profitability in a radial distribution network (RDN). The first stage focuses on minimizing resilience-related costs and energy not supplied (ENS) during natural disasters, while the second stage optimizes VPP profit using a three-phase bidding strategy, which includes the day-ahead market, real-time market, and overall market. A hybrid improved grey wolf optimization-particle swarm optimization (IGWO-PSO) algorithm is developed to solve this complex optimization problem. To demonstrate the effectiveness of the proposed approach, IGWO-PSO is compared with other hybrid optimization algorithms. Validation on a modified IEEE 33-bus RDN confirms that the proposed model enhances VPP placement and sizing, leading to improved economic, operational, and resilience metrics. Furthermore, the model accounts for uncertainties in load demand, renewable generation, energy prices, and equipment availability, ensuring a robust and adaptable energy management strategy."
  },
  {
    "year": "2025",
    "abstract": "This study introduces an effective control strategy for interconnected doubly-fed induction generator-based wind energy systems with model-in-loop validation. Using an adaptive neuro-fuzzy inference system, the proposed controller employs an improved fuzzy rule set and membership function configuration. While existing ANFIS controllers typically use between 9 and 25 fuzzy rules for the grid side and rotor side converter in a doubly-fed induction generator-based wind energy system, this research extends to 49 rules with 7 associated membership functions and considering two inputs to the ANFIS controller for the grid as well as rotor side, resulting in higher precision and control performance Real-time simulations conducted on the OPAL RT OP5700 platform validate the controller’s effectiveness under varying wind conditions, specifically at 15 m/s and 10 m/s. Furthermore, dynamic and transient performances are thoroughly assessed in the presence of grid-side faults such as single-line-to-ground and three-phase-to-ground faults. A comparative analysis with traditional PI and fuzzy logic controllers reveals that the proposed ANFIS controller attains a 14% acceleration in fault recovery under LG and LLLG fault conditions. This result suggests that the proposed ANFIS controller performs better than its traditional counterparts. The enhanced ANFIS demonstrated robustness and adaptability, significantly improving resilience during variations in wind speed and fault tolerance in real-time wind energy systems."
  },
  {
    "year": "2025",
    "abstract": "Immune checkpoint inhibitors (ICIs) have become essential in managing metastatic Renal Cell Carcinoma (mRCC), although selecting the most suitable patients for each specific treatment remains an unmet medical need. In this work, we aimed to create and evaluate a treatment response prediction machine learning model based on tumor gene expression data of patients with mRCC. More specifically, we designed and developed a graph-based prediction model, including information about potential protein-protein interactions (PPI) between the considered expressed genes. For this work, we extracted the expression data collected in two different ICIs treatments (nivolumab and avelumab+axitinib) and organized them into two different graph datasets (considering two initial PPI networks: BioGrid and kidney-specific PPT-Ohmnet). Then, we compressed these four different graph datasets with a graph embedding technique (Graph2Vec) and evaluated the embeddings as input for a supervised classification model (Random Forest) to predict the binarized progression-free survival (PFS). Results showed that the Nivolumab and PPT-Ohmnet graph dataset obtained the highest classification performance, with an AUC of 74%. These results suggested that our pipeline could accurately model the response to the drugs, especially those modeling a short-term response (in this case, nivolumab), and that this graph-based approach benefits from tissue-specific networks (kidney-specific PPT-Ohmnet PPI). This work is presented as a data-driven solution towards improving drug selection and identifying different responses to immunotherapy treatments, including poor responses that should be offered alternative therapeutic options."
  },
  {
    "year": "2025",
    "abstract": "The rapid development of artificial intelligence has significantly advanced the field of computer vision, particularly in image analysis and understanding. This paper provides a comprehensive review of the current state of the field, key technologies, and their applications across various real-world scenarios. It delves into the value of image analysis in critical areas such as personalized art, healthcare and medical image analysis, security monitoring and recognition technology, autonomous driving and traffic management, as well as industrial automation and quality control. This paper not only highlights the challenges and limitations, including dataset constraints, algorithm generalization, real-time computational costs, and privacy and ethical concerns, but also offers a forward-looking analysis of development trends such as interdisciplinary integration, weakly supervised and unsupervised learning, algorithm optimization and hardware advancements, and the protection of personal privacy and information. These insights provide a profound perspective on the future trajectory of computer vision and AI-driven image analysis."
  },
  {
    "year": "2025",
    "abstract": "A path planning method based on Particle Differential Optimization-Ant Colony Optimization (PDO-ACO) algorithm for library management robots is proposed in the study, aiming to solve the problem of low efficiency of current path planning methods in complex environments. The method combines the negative feedback improved ant colony algorithm and particle difference optimization algorithm to enhance the accuracy, stability and environmental adaptability of path planning. The study innovatively introduces the negative feedback mechanism to improve the ant colony algorithm, which effectively avoids the problem that the traditional algorithm is prone to fall into the local optimum, and combines with the particle difference optimization algorithm to be applied to the path planning of the library management robot, which demonstrates high adaptability and robustness. The experimental results show that the method outperforms other common path planning methods in terms of error rate and redundant path rate, and the average path lengths are 54.507m and 57.456m, respectively, and the convergence speed and accuracy are improved by 57% and 45.5%, respectively. The method shows high accuracy, stability and robustness in the actual library management environment, which can effectively avoid the risks in path planning, reduce the management cost, and provide a new technical solution for the construction of intelligent library system."
  },
  {
    "year": "2025",
    "abstract": "This research demonstrated the machine learning (ML) classifiers with regression learning to improve an optical system’s quality of transmission (QoT). In Optical Communication, the data can be communicated from source to destination through the established lightpaths. However, as the signal traverses the optical links and devices, its QoT may deteriorate due to various impairments. The QoT is an essential component that determines the connectivity of an optical network. Therefore, ensuring a QoT guarantee is necessary to establish a successful lightpath. Predicting the QoT before establishing lightpaths can guide the routing and allocation of resources required for the lightpaths. In this research, using ML models an appropriate QoT analytical prediction model is developed computationally. Simulations were conducted at a 10 Gbps data rate per channel for 64-channel DWDM systems. The proposed model significantly improves in detecting fiber nonlinearity, and performance was studied using Q-factor, BER, and noise power. The results indicate that the SVM-based classifier with regression learning performs better than any other classifiers discussed in this research. This study assesses the efficiency of the proposed ML models in predicting the QoT for established lightpaths. Results indicate that all the ML classifiers with Regression models can accurately predict the transmission quality for over 90% of lightpaths. However, the proposed SVM-based classifier with a regression model demonstrates superior generalization, with a nearly perfect QoT prediction rate of around 99% for the established lightpaths. In the network planning stage, residual margins are added to compensate for inaccuracies, which ensures accurate signal reception. The proposed ML model achieved a lightpath residual margin with a 0.7dB error."
  },
  {
    "year": "2025",
    "abstract": "Deep Learning (DL) techniques provide a powerful tool enhancing the learning capabilities of the neural networks (NN), and are increasingly applied in the field of electric power systems. In particular, the long short-term memory (LSTM) and the gated recurrent unit (GRU) networks allow improvements on signal processing. The relevance of suppressing electrical disturbances justifies the efforts to apply new control algorithms to the active power filters (APF). Despite the existence of many control techniques, the NN-based proposals generally present significant shortcomings. Therefore, in this work, a new neural controller is presented for further improvement, using previously trained NNs, without need of adaptive algorithms. The generation of the three-phase APF reference currents is based on LSTM and GRU networks, that extract the full necessary information from currents and voltages, thus avoiding the need of an additional phase synchronization control. It is a novel proposal comprising FCE (fundamental Fourier coefficients estimation) and FE (frequency estimation) along with a simple computation process, for harmonic distortion and reactive power compensation. It has been tested with many practical loads and conditions through simulation and experimental platforms. Its general high performance confirms a substantial progress compared to other NN controllers, and it could be an alternative to other techniques."
  },
  {
    "year": "2025",
    "abstract": "Telerehabilitation systems leveraging depth video analysis provide an effective solution for remote physiotherapy, particularly for individuals with physical disabilities. This study presents an advanced exercise classification framework that integrates multi-modal feature extraction and attention-based transformation to enhance rehabilitation monitoring. The proposed pipeline begins with depth image preprocessing, followed by human detection using a pre-trained Histogram of Oriented Gradients (HOG)-Support Vector Machine (SVM) model. The human silhouette is segmented using the GrabCut algorithm, enabling robust region-of-interest extraction. We propose a novel Lightweight Two-tier Key Body Point Detection (LT-KBPD) algorithm to efficiently and accurately identify key skeletal points, which are then used to extract both static and dynamic kinematic features. In parallel, silhouette-based analysis is performed, where shape descriptors, dense optical flow, Gaussian Mixture Model (GMM)-based body part segmentation, and contour analysis extract spatial and motion-related features. The extracted feature sets are fused into a comprehensive feature vector and further refined using an attention-based transformation mechanism to highlight salient features relevant to exercise classification. Finally, a Long Short-Term Memory (LSTM) network is employed to model temporal dependencies and classify exercises with high accuracy. The proposed approach is validated on three benchmark depth-video datasets: Kimore, K3DA and MEx - Multi-modal Exercise Dataset, achieving classification accuracies of 92.19%, 91.35%, and 85.51%, respectively. These results demonstrate the system’s effectiveness in accurately recognizing rehabilitation exercises for individuals with physical disabilities. Future work aims to enhance the adaptability of the system through personalized rehabilitation feedback and improved temporal modeling techniques."
  },
  {
    "year": "2025",
    "abstract": "Tumor segmentation is crucial for cancer diagnosis, treatment planning, and surgical interventions. However, traditional manual delineation methods are time-consuming, labor-intensive, and prone to subjective variability, highlighting the need for automated approaches. The significant variability in lesion shape and size within medical images further complicates segmentation tasks, necessitating models that can effectively capture both local and global features to achieve accurate results. To address these challenges, we propose MMEFU-Net, a novel deep learning framework designed for efficient and accurate tumor segmentation in medical CT images. The architecture integrates a multi-encoder structure comprising a detail branch, a context branch, and a Mamba-guided branch to extract complementary features, addressing the limitations of single-encoder models. Key innovations include the Mamba-Guided Fusion Attention (MGFA) module for balancing local details and global context, the Pixel Attention Feature Fusion (PAFF) module for enhancing detail branch features with complementary information from the context branch, the Dilated Multi-Scale Fusion (DMSF) module for robust multi-scale feature modeling, and the introduction of the lightweight DySample operator for precise and efficient dynamic upsampling. Comprehensive experiments on five public and private benchmark datasets, encompassing both liver tumors and lung cancers, demonstrate that MMEFU-Net outperforms state-of-the-art U-Net, Transformer-based, and Mamba-based architectures. The model achieves superior Dice Similarity Coefficients (DSC) and Intersection over Union (IoU) scores while significantly reducing computational costs. Notably, MMEFU-Net improves the DSC by 2.16% compared to nnU-Net on the LiTS2017 dataset, with a35×reduction in parameters and a25×reduction in computational complexity. These findings suggest that MMEFU-Net has the potential to become a scalable and efficient solut..."
  },
  {
    "year": "2025",
    "abstract": "This study presents the fabrication and optimization of top-emitting organic light-emitting diodes (TEOLEDs) on stainless steel (SS) substrates, aiming to address challenges in surface roughness, hole injection efficiency, and light extraction. Due to the dual-sided conductivity of SS foil, a solution-type organic material (TOC 100) was spin-coated as an insulating and planarization layer, reducing the surface roughness from 8.61 nm to 0.46 nm, as measured by atomic force microscopy (AFM). The device structure was SS/Al/HATCN/TAPC/BH-08(host):OD-01(dopant)/TPBi/LiF/Al/Ag, with electro-optical characteristics comparable to TEOLEDs on glass substrates. However, the current density was slightly lower due to the roughness of the aluminum anode. The device optimizations included adding a gold layer (3 nm) to the aluminum anode, which increased hole injection efficiency and improved luminance from 4.99 cd/m2 to 24.65 cd/m2 at 14 V when the hole transport layer (TAPC) thickness was reduced from 20 nm to 10 nm. Adjusting cathode thicknesses (Al/Ag at 6/8 nm versus 12/10 nm) enhanced light output significantly, with luminance increasing from 9.5 cd/m2 to 24.7 cd/m2 at 15 V. Furthermore, using Ytterbium/Silver (Yb/Ag) cathodes improved current efficiency to 6.3 cd/A at 8 V compared to 4.5 cd/A for Liq/Al/Ag cathodes. Encapsulation extended TEOLED lifetime from 365 minutes to 490 minutes for luminance decay from 800 to 400 cd/m2. Flexibility tests demonstrated that the TEOLEDs maintained functionality under bending radii of 0.5 cm with brightness of 142 cd/m2 at 5 V. Additionally, thermal imaging revealed superior heat dissipation on SS substrates compared to glass substrates, with backside temperatures of24.6∘C versus33.9∘C when biased at 10 V."
  },
  {
    "year": "2025",
    "abstract": "Nowadays, Internet of Things (IoT) devices are widely deployed and how to power such massive IoT devices has become a significant challenge. Especially for the battery-powered IoT devices, limited energy storage and continuous energy consumption result in frequent battery replacement and potential environmental pollution. Because radio frequency (RF) signals carry not only information but also energy, Wireless Power Transfer (WPT) in RF domain has been proved to be a reliable and controllable technology to deal with this problem. A typical Data and Energy Integrated Network (DEIN) commonly conceives one DEIN base station and numerable DEIN devices. The DEIN base station is capable of transmitting data and energy integrated signals to the DEIN devices with Simultaneous Wireless Information and Power Transfer (SWIPT) technology, and the DEIN devices are capable of harvesting energy from the downlink RF signals for uplink data transmission. In order to coordinate the wireless data and energy transmission and avoid conflicts, a transmission protocol based on the Time-Division Multiple Access (TDMA) scheme is designed. Furthermore, an optimization problem of minimizing the energy consumption of the DEIN base station is formulated. In order to address this problem, this paper proposes an energy-efficient algorithm by jointly optimizing of the transmission power of the DEIN base station, the uplink and downlink time slots and power splitting factors of the IoT devices. Both the effectiveness and efficiency of the proposed joint optimization algorithm have been validated with the simulation."
  },
  {
    "year": "2025",
    "abstract": "Brain-computer interfaces (BCIs) have received considerable attention in gaming, enabling innovative interactions with digital environments. Visual Evoked Potentials (VEPs)—robust, noninvasive neural responses to visual stimuli—offer high information transfer rates, making them particularly promising. This systematic review, guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, examines VEP-based BCIs in gaming. We searched the Web of Science and Google Scholar, identifying 16 347 studies from the past decade, with 46 selected for in-depth analysis after rigorous screening. The review explores VEP response modeling, electroencephalography (EEG) signal acquisition and processing, stimulation paradigms, and their gaming applications. These systems enhance accessibility for players with physical or cognitive impairments, support adaptive difficulty scaling, personalize gameplay, aid neurorehabilitation, and enable multiplayer interactions. However, challenges remain, including technical limitations, complex data interpretation, user adaptability, and ergonomic issues. Advances in signal processing, personalized calibration, and hybrid multimodal approaches could improve usability. Future research should focus on integrating VEP-based BCIs with emerging technologies, optimizing user comfort, and developing adaptive interaction models to enhance immersion and accessibility. By addressing these challenges and utilizing neuroscience and computational advancements, VEP-based BCIs promise to transform gaming into a more inclusive and immersive experience for diverse users."
  },
  {
    "year": "2025",
    "abstract": "The Internet of Things (IoT) has raised significant security concerns, especially with regard to secure data transfer among resource-constrained devices. While effective, traditional encryption techniques are often computationally expensive and easily identifiable, making them unsuitable for many IoT applications. Steganography is an intriguing approach that allows hiding sensitive information within seemingly ordinary data, preventing unauthorized parties from detecting and accessing it. Existing studies on IoT security lack a comprehensive analysis of steganographic techniques tailored for IoT-specific constraints. This study bridges this gap by providing a comprehensive review of steganographic methods for IoT, exploring approaches across many domains such as spatial, frequency, and hybrid methods used in images, videos, audio, text, network traffic, hybrid approaches, and quantum-based methods. We evaluated and validated the techniques employed using key metrics such as imperceptibility, robustness, and embedding capacity while emphasizing the computational restrictions, real-time processing requirements of IoT devices, and the vital requirement for energy-efficient algorithms. This survey also investigates the integration of steganography and cryptographic approaches, as well as advances in Machine Learning (ML), Deep Learning (DL), and quantum techniques that could revolutionize the field. The study ends with future research directions that underscore the importance of innovative steganographic techniques that strike a compromise between security, efficiency, and scalability in IoT applications."
  },
  {
    "year": "2025",
    "abstract": "The rapid proliferation of connected vehicles has significantly expanded the attack surface of the Internet of Vehicles (IoV), introducing severe security risks. In such resource-constrained environments, developing lightweight solutions is crucial to ensuring real-time detection and efficient deployment. To address these challenges, this study proposes ConvGRU, a lightweight vehicular network intrusion detection model that integrates a shallow Convolutional Neural Network (CNN) with a Gated Recurrent Unit (GRU). By employing optimizations such as small convolutional kernels and depthwise separable convolutions, the model significantly reduces the number of parameters and computational overhead, making it well-suited for resource-limited IoV environments. The shallow CNN effectively captures spatial features, while the GRU extracts temporal dependencies, enhancing the model’s generalization ability. ConvGRU achieves an accuracy, precision, recall, and F1-score exceeding 0.99 on the HCRL-Car-hacking, OTIDS, and CICIDS-2018 datasets, with only 112.55K parameters and a memory footprint of merely 0.43 MB. Experimental results demonstrate that this intrusion detection solution substantially improves malicious traffic detection accuracy while ensuring efficient operation in resource-constrained vehicular environments."
  },
  {
    "year": "2025",
    "abstract": "The choice of basketball players and their playing field selection represents a vital decision-making (DM) process that determines team success and game results. The selection of top players requires evaluating skills, physical attributes, and team dynamics, and selecting an appropriate field demands examination of environmental elements and infrastructure. The sports industry needs advanced decision-support methodologies to optimize its selection processes because these decisions prove complex. The multi-criteria group DM (MCDM) technique allows a panel of decision-makers (DMks) to establish a methodical system to identify the best alternative among competing criteria that produce conflicting results. The extended weighted aggregated sum product assessment (WASPAS) method serves as an effective technique because it combines the weighted sum model (WSM) and weighted product model (WPM) to evaluate and rank alternatives. The research investigates how the extended WASPAS method operates within an IFS environment to boost the processes of sports industry DM. The research selects basketball players and suitable basketball fields to maximize performance through an evaluation process that includes various performance and environmental factors. The proposed model utilizes IFS capabilities to assess decision alternatives by evaluating player skills and physical attributes, team compatibility, court surface, and environmental conditions. The extended WASPAS method produces findings comparable to traditional MCGDM approaches in establishing their effectiveness. The extended WASPAS integrated with IFS improves decision reliability and accuracy when supporting basketball player selection and venue assessments."
  },
  {
    "year": "2025",
    "abstract": "Locomotor injuries in horses are a major cause of underperformance and serious welfare issue. Veterinarians typically investigate horses’ lameness through visual examination at separate gaits (walk, trot, gallop). To evaluate lameness objectively, Inertial Measurement Units (IMU) based systems have been developed. It is necessary to accurately identify the gait of each stride as vertical displacement symmetry is assessed at a defined gait, essentially trot. This study aimed to classify gaits into six classes and to assess the training sample size required to maximize the performance. Unlike previous methods, we used raw IMU data without manually preselecting specific signal segments. Seven sensors were strategically placed on the limbs, head, withers, and pelvis of horses. 1440 horses were used in our unsupervised model and the gait of 110 horses was labelled using IMU data for our supervised models. We divided the six gaits classification task into two subtasks: a four-gaits classification and a gallop-specific classification. In the first subtask, we compared the performance of a machine learning (XGBoost), a deep learning (LSTM) and a transfer learning (ENCOD-CNN) model, depending on the labelled training sample size. Our results show that the transfer learning approach outperformed the other models, achieving test accuracy of 91.9%. Our gallop classification task achieves 97.1% accuracy and the total pipeline reaches 91.2% accuracy. Beyond improving gait classification in a real clinical setting, this research demonstrates the potential of transfer learning for time-series datasets and provides a quantitative assessment of the required labeled sample size for effective implementation."
  },
  {
    "year": "2025",
    "abstract": "Long-horizon tasks in unstructured environments are notoriously challenging for robots because they require the prediction of extensive action plans with thousands of steps while adapting to ever-changing conditions by reasoning among multimodal sensing spaces. Humans can efficiently tackle such compound problems by breaking them down into easily reachable abstract sub-goals, significantly reducing complexity. Inspired by this ability, we explore how we can enable robots to acquire sub-goal formulation skills for long-horizon tasks and generalize them to novel situations and environments. To address these challenges, we propose the Zero-shot Abstract Sub-goal Framework (ZAS-F), which empowers robots to decompose overarching action plans into transferable abstract sub-goals, thereby providing zero-shot capability in new task conditions. ZAS-F is an imitation-learning-based method that efficiently learns a task policy from a few demonstrations. The learned policy extracts abstract features from multimodal and extensive temporal observations and subsequently uses these features to predict task-agnostic sub-goals by reasoning about their latent relations. We evaluated ZAS-F in radio frequency identification (RFID) inventory tasks across various dynamic environments, a typical long-horizon task requiring robots to handle unpredictable conditions, including unseen objects and structural layouts. Our experiments demonstrated that ZAS-F achieves a learning efficiency 30 times higher than previous methods, requiring only8kdemonstrations. Compared to prior approaches, ZAS-F achieves a 98.3% scanning accuracy while significantly reducing the training data requirement. Further, ZAS-F demonstrated strong generalization, maintaining a scan success rate of 99.4% in real-world deployment without additional fine-tuning. In long-term operations spanning 100 rooms, ZAS-F maintained consistent performance compared to short-term tasks, highlighting its robustness against compoun..."
  },
  {
    "year": "2025",
    "abstract": "The integration of renewable energy in the power supply chain of Electric Vehicles (EVs) is fundamental in order to decarbonize the transportation sector. Yet, this poses additional threats to the smooth functioning of power systems. In the case of e-bikes, the load is modest and it becomes conceivable to exploit as much as possible distributed renewable power generation coupled with storage. For this reason, attention has recently been growing towards the development of off-grid charging stations for Light EVs (LEVs) powered by renewables. For this kind of charging stations, the power supply for the e-bikes can arrive solely from renewable power production or storage and it is not guaranteed that there is power available for the recharge whenever the demand occurs. Hence, the design of such systems needs to consider two conflicting objectives, which are the minimization of the costs and of the number of not served e-bikes. Based on such premise, this work contributes to the multi-objective optimization of off-grid charging stations for e-bikes. A Genetic Algorithm is employed to determine the most appropriate rated power of the installed PhotoVoltaic (PV) systems and of the energy storage, by incorporating statistical methods to estimate the daily number of e-bikes requiring charging, hence making the optimization process more reflective of actual usage patterns. Under the assumed conditions, the optimized solution guarantees a high quality of service, as the number of uncharged e-bikes is less than the 5%. The Capital Expenditure (CapEx) and Operational Expenditure (OpEx) are estimated for the identified optimized charging station and compared against the grid-connected case and it arises that the off-grid system is slightly more profitable after 3 years, due to the savings in the energy costs."
  },
  {
    "year": "2025",
    "abstract": "We propose a system to enhance electrolaryngeal speech naturalness using automatically extracted phoneme representations. Phonemes provide sufficient information for predicting reasonably natural fundamental frequency patterns. Previous studies using forced-aligned phoneme labels to create shared features between electrolaryngeal and normal speech for fundamental frequency prediction are limited by their reliance on transcriptions, thereby restricting real-time use. To overcome this, our system leverages phonetic posteriorgrams from an automatic speech recognition system. By transforming these phonetic posteriorgrams into clustered phoneme embeddings, we predict natural fundamental frequency patterns without requiring transcriptions. Our experiments demonstrate that this approach not only provides a robust, real-time solution for electrolaryngeal speech enhancement but also enables effective training with limited electrolaryngeal speech data and large, publicly available normal speech datasets."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we propose a novel model, the Linear Inverted Pendulum with Cart-Plate Model (LIPCPM), which combines the Linear Inverted Pendulum Model (LIPM) with a mass-spring-damper model to simultaneously control both the legged robot and the sloshing phenomenon. A legged robot transporting liquid-filled container exhibits significant nonlinearities due to the sloshing dynamics of fluid movement within a confined container and the dynamics of legged robot itself. Therefore, controlling the legged robot and sloshing phenomenon together will bring challenges. Since the robot receives the reaction forces by the sloshing dynamics, simply implementing LIPM on the robot carrying a liquid container would not be enough. So, we analyzed how the reaction forces affect the robot with actual experiments and tabulated the system parameters that can be integrated with the LIPM. The experimental results show that the reaction forces by the sloshing dynamics are similar to those of a second-order response. The proposed model could be utilized with the Model Predictive Control (MPC), and predicted future states of the robot and liquid were controlled as we desired. Finally, we demonstrate the effectiveness of the proposed system in simulation with experimental-based system parameters for reliability. According to the results, the Root Mean Square Error (RMSE) of sloshing phenomenon under various conditions was decreased by approximately 70 %."
  },
  {
    "year": "2025",
    "abstract": "The transformer model is excellent at handling time series signals (such as electroencephalography: EEG) because it can extract information from long-term dependencies effectively. This work combines binarization of EEG connectivity features, cognitive state classification using the vision transformer (ViT), and identifying graphical connectivity patterns for each cognitive state of the mental arithmetic task. The common spatial pattern (CSP) filter coefficient-based channel selection method selects the optimum EEG channels from the input channel set. Then, the Singular Value Decomposition (SVD) method is applied to prepare the binarized connectivity feature matrices, eliminating noisy connections between the optimum channels. The binarized functional-effective connectivity features are passed to the ViT model for cognitive state classification. The ViT model achieves the maximum classification accuracy of 94.86% with the phase-based connectivity feature. The proposed model improves classification accuracy by 6.15% compared to the state-of-the-art studies. This study also suggests a robust brain connectivity network to build a graphical connectivity pattern for each cognitive state. My findings of the EEG-based graphical patterns will bring further understanding of the scalp-level EEG channel patterns among different brain regions for other cognitive tasks."
  },
  {
    "year": "2025",
    "abstract": "This study addresses the challenge of fair spectrum sharing in unlicensed bands for Licensed Assisted Access (LAA) and Wi-Fi coexistence. Existing methods, particularly the 3GPP Category 4 Listen Before Talk (Cat 4 LBT) algorithm, fail to fully meet the fairness criteria due to limitations in dynamic Contention Window (CW) adjustments. To improve spectrum efficiency, we propose an Enhanced Fixed Waiting Time (Enhanced FWT) approach, which leverages a theoretical model of Wi-Fi ON periods to determine fixed waiting times for LAA networks. By employing theβdistribution to represent Wi-Fi activity more accurately, this model avoids the need for dynamic CW adjustments. Simulation results demonstrate that Enhanced FWT method significantly enhances throughput compared to both the Cat 4 LBT and traditional empirical FWT methods, especially in dense network conditions. This approach, compliant with 3GPP fairness standards, shows promise for robust spectrum sharing, promoting fair LAA/Wi-Fi coexistence in unlicensed bands."
  },
  {
    "year": "2025",
    "abstract": "In this study, we propose a new method for constrained combinatorial optimization using variational quantum circuits. Quantum computers are considered to have the potential to solve large combinatorial optimization problems faster than classical computers. Variational quantum algorithms, such as Variational Quantum Eigensolver (VQE), have been studied extensively because they are expected to work on noisy intermediate scale devices. Unfortunately, many optimization problems have constraints, which induces infeasible solutions during VQE process. Recently, several methods for efficiently solving constrained combinatorial optimization problems have been proposed by designing a quantum circuit so as to output only the states that satisfy the constraints. However, the types of available constraints are still limited. Therefore, we have started to develop variational quantum circuits that can handle a wider range of constraints. The proposed method utilizes a forwarding operation that maps from feasible states for subproblems to those for larger subproblems. As long as appropriate forwarding operations can be defined, iteration of this process can inductively construct variational circuits outputting feasible states even in the case of multiple and complex constraints. In this paper, the proposed method was applied to facility location problem. As a result, feasible solutions were obtained with 100%, and the probability of obtaining optimal solutions was over 22 times higher than that of conventional VQEs. Nevertheless, the cost of the obtained circuit was comparable to that of conventional circuits."
  },
  {
    "year": "2025",
    "abstract": "A synergic cooperation between terrestrial and non-terrestrial networks is a pivotal feature for achieving global wireless coverage. In this framework, the satellite swarm-based massive array represents one of the most promising key enabling technologies in coping with the ever-increasing system requirements for beyond 5G (B5G) and 6G systems. In this paper, a novel strategy for the synthesis of satellite massive arrays with reconfigurable antenna units (SMART-U) is presented. The radiative performance of the proposed configuration are analysed for low-earth and geostationary orbiting satellites and assess a remarkable robustness and flexibility of the new synthesis architecture. A remarkable scanning range improvement and peak side lobe level (PSLL) lowering of the addressed concentric ring array (CRA) is achieved by exploiting a multiobjective optimization based on the Pareto front. The proposed SMART-U phased array can efficiently cope with adverse satellite attitudes by tailoring the circularly polarized (CP) field radiated by each unit offering a clear advantage with respect to conventional swarm-based arrays with a static antenna element factor."
  },
  {
    "year": "2025",
    "abstract": "Underwater optical communications have been proposed for various applications, ranging from coastal protection to short-range submarine communications. The development of dedicated communication systems requires intensive simulation of use cases with efficient methods, both in terms of accuracy and computational time. However, these simulations are challenging due to the complexity of the physical mechanisms of light propagation in water, which involves numerous scattering events on the various particles constituting the propagation medium. Previous tools have primarily relied on the Prahl algorithm, based on Monte Carlo simulation, and are therefore difficult to improve. Recently, a new framework, hereafter referred to as Xiao1, has been developed using an integral formalization of the propagation and Monte Carlo integration for its computation, achieving improved computational times compared to older Prahl techniques for the same level of accuracy. This paper builds upon this framework and proposes to incorporate further importance sampling into the Monte Carlo integration algorithm. It calculates a sub-domain around the receiver for each scattering point and selects a connecting sample with importance within this sub-domain. This paper presents the complete derivation of this new method. It then presents several case studies in which the simulations demonstrate that this new method performs significantly better. Depending on the configuration, these simulations exhibit a reduction in computational times by a factor ranging from 1.09 to 4048 compared with Prahl and from 1.07 to 2134 compared with Xiao1."
  },
  {
    "year": "2025",
    "abstract": "This research work introduces a clustering-based in-place sorting algorithm, cluster sort. It is designed in such a way that it improves sorting efficiency by using data locality. It works in two phases: first, data elements are clustered based on the similarity in the values and then each of these clusters is sorted independently using comb or shell sort. This is a hybrid approach, and it helps minimize multiple comparisons within the clusters, which in turn improves performance, especially in large datasets with specific distributions. The traditional algorithms were selected due to their well-known efficiency and widespread use in sorting large datasets. This experiment of ours includes ordered, reverse-ordered, Gaussian, repeated values, same values, and uniform distributions. The results acquired from this experiment show that Cluster Sort (comb) outperforms Cluster Sort (shell) by 88% in ordered datasets and is 92.32% faster than Merge Sort. For reverse-ordered datasets, Cluster Sort (Comb) is 70.79% faster than Bucket Sort and 90.69% faster than Cluster Sort (Shell). In Gaussian distributions, Cluster Sort (Shell) improves by 25.88% over Bucket Sort and 74.41% over Merge Sort. In repeated-value datasets, although Quick Sort is faster, Cluster Sort (Shell) surpasses Bucket Sort by 13.64%. For uniform distributions, Cluster Sort (Shell) is 30.28% faster than Bucket Sort and 75% faster than Merge Sort. The reduction in unwanted comparisons through clustering is essentially what made Cluster Sort significantly outperform traditional algorithms in these datasets with inherent patterns, making Cluster Sort a coherent choice for practical applications."
  },
  {
    "year": "2025",
    "abstract": "Fire and smoke detection is an important measure to ensure the safety of people’s lives and property, as well as a crucial link in maintaining ecological balance and supporting scientific research. Traditional object detection methods rely more on manually designed features and rules. Although they are relatively simple to implement, their performance is limited in complex and variable practical applications. In contrast, deep learning-based methods can automatically learn deep features in data and have higher accuracy and stronger generalization ability. However, complex backgrounds, large environmental changes, and data requirements pose great challenges to high-precision outdoor smoke detection. To address these issues, this paper proposes an improved model, YOLOV11-DH3, based on YOLOV11. In this paper, the core DCN2 (Deformable Convolutional Networks2) of the YOLOV11 Head is replaced with the DCN3 module to form a new detection head. In addition, the loss function CIOU in YOLOV11 is replaced with IOU to consider the irregular shape of fire and smoke and the problem of multi-scale targets. To evaluate the performance of the algorithm, comprehensive experiments were conducted on two distinct datasets: a public fire and smoke dataset provided by Baidu Paddle featuring close-range views and a public wildfire smoke dataset from the YOLO official website with distant outdoor perspectives. The experimental results show that on the Baidu Paddle dataset, the average accuracy of the model is improved by 1.4% compared to the original model, reaching 58%, the F1 score is improved by 2%, reaching 58%, with a precision of 91.6% and recall of 90%. Our cross-dataset analysis provides valuable insights into model performance across different detection scenarios. The proposed model demonstrates the ability to accurately detect fire and smoke in complex backgrounds, and this progress is of great significance for protecting people’s lives and maintaining ecological balance."
  },
  {
    "year": "2025",
    "abstract": "A Session-Based Recommendation (SBR) identifies correlations among session interactions to understand user preferences and generate appropriate recommendations. A key challenge in this context is the dynamic change in user preferences, particularly when preferences disappear and reappear within a session, a phenomenon referred to as Recurrent User Interest Drift (RUID). Effectively capturing RUID is significant for aligning recommendations with ongoing user preferences. Existing SBR approaches often misclassify user preferences that differ from other session interactions as noise (unintentional interactions), relying on dwell time (the amount of time a user spends viewing an item) or neighboring sessions, thereby overlooking their potential reappearance as RUID later in the session. To the best of our knowledge, this work is the first to address the challenge of identifying RUID in SBR. The proposed approach assigns probabilistic scores to each interaction by considering its similarity to the immediate previous interaction, its inclusion among popular items (items with a higher number of interactions), its similarity to previous interactions, and the dwell time. As user preference may reappear anytime during the session, and RUID identification requires analyzing subsequent interactions, a list-based approach is used to retain these interactions until the session ends, enabling effective RUID identification. The matrix factorization-based attentive session encoder incorporates both short-term (ongoing) preferences and long-term (historical) preferences to generate personalized recommendations. Experimental results on three benchmark datasets, Yoochoose, Last.fm, and Gowalla, show that our method outperforms 14 state-of-the-art baselines, achieving an improvement of 2.28% in recall@20 and 1.39% in Mean Reciprocal Rank (MRR@20) on Yoochoose, 3.58% in recall@20 and 2.70% in MRR@20 on Last.fm, and 5.35% in recall@20 and 4.17% in MRR@20 on Gowalla datasets."
  },
  {
    "year": "2025",
    "abstract": "Network security faces escalating challenges from sophisticated cyber threats, necessitating advanced Intrusion Detection Systems (IDS) capable of both detecting attacks and classifying their patterns. This paper introduces GateIDS, a pioneering single-network architecture that integrates binary attack detection and multi-class attack pattern classification within a unified framework. Leveraging Deep Neural Networks (DNN), Long Short-Term Memory (LSTM), and Transformer backbones, GateIDS employs a bifurcated design trained end-to-end to address these dual tasks efficiently. To mitigate class imbalance in the UNSW-NB15 dataset, a class-specific oversampling strategy is applied, enhancing the detection of minority attack types. Experimental results demonstrate that the DNN variant achieves superior performance, with a binary classification accuracy of 98.30% and a pattern classification accuracy of 86.68%, alongside an inference time of 0.1752 seconds, outperforming LSTM (89.17%, 46.71%) and Transformer (90.63%, 45.79%) variants. This work marks the first unified dual-task IDS, offering computational efficiency and scalability over traditional separate-model approaches. GateIDS establishes a robust baseline for future IDS research, with potential enhancements through clustering and real-world deployment."
  },
  {
    "year": "2025",
    "abstract": "Retinopathy of Prematurity (ROP) is a severe disease that occurs in premature babies due to abnormal development of retinal vessels and can lead to permanent vision loss. Fundus images are critical in the diagnosis of ROP; however, the examination of fundus images is a subjective, time-consuming, and error-prone process that requires experience. This situation can lead to delayed diagnosis and inaccurate evaluations. Therefore, the need for computer-aided diagnosis (CAD) systems is increasing day by day. Deep learning (DL) methods have a high potential in analyzing such complex images. In this study, a total of 50 DL models, 25 Convolutional Neural Network (CNN), and 25 Vision Transformer (ViT) models were tested to diagnose ROP from fundus images. Furthermore, the ROPGCViT model based on the Global Context Vision Transformer (GCViT) was proposed. GCViT was enhanced with Squeeze-and-Excitation (SE) block and Residual Multilayer Perceptron (RMLP) structures to effectively learn local and global context information. With a dataset of 1099 fundus images, the performance of the model was evaluated in terms of accuracy, precision, recall, f1-score, and Cohen’s kappa score. To enhance explainability, the Gradient-Weighted Class Activation Mapping (Grad-CAM) method was utilized to visualize the regions of fundus images the model focused on during classification, providing insights into its decision-making process. ROPGCViT outperformed both 50 DL models and methods in the literature with 94.69% accuracy, 94.84% precision, 94.69% recall, 94.60% f1-score, and Cohen’s kappa score of 93.10%. Additionally, the Grad-CAM visualizations demonstrated the ability of the model to focus on clinically relevant regions, enhancing trust and interpretability for experts. The proposed ROPGCViT model provides a robust solution for ROP diagnosis with high accuracy, flexibility, and generalization capacity."
  },
  {
    "year": "2025",
    "abstract": "Open biomechanical datasets play a critical role in advancing scientific research, particularly with the growing use of machine learning, which requires a large amount of data for training and validation. However, the availability and characteristics of such datasets, particularly in the context of upper limb motion, are still underexplored. This systematic review aims to identify, assess, and categorize existing open datasets related to upper limb motion, focusing on the tasks analyzed, subject demographics, and data collection methods employed. We conducted a comprehensive search across multiple databases, including Scopus, Zenodo, PubMed, Xplore, and Google Dataset Search, selecting publicly accessible datasets that focus on upper limb motion based on predefined inclusion and exclusion criteria. Additional datasets were identified through manual searches. A total of 63 datasets met the criteria for further analysis, and their quality was assessed based on subject types, data collection methods, and sample sizes. The majority of the datasets centered on activities of daily living, with 69.8% of the studies involving healthy subjects. Marker-based motion capture was the most common data collection method, though the use of markerless systems (e.g., inertial sensors, video cameras) is on the rise. Key limitations included the absence of standardized movement protocols and small subject sample sizes across studies. In contrast to lower limb gait analysis, there is no single dominant task for studying upper limb motion. Standardizing movement protocols and incorporating a broader range of daily activities into datasets could enhance the development of assistive technologies and rehabilitation programs. Future research should focus on creating more standardized, diverse datasets to improve the accuracy and generalizability of biomechanical analyses."
  },
  {
    "year": "2025",
    "abstract": "Maximizing the output power of photovoltaic (PV) systems is crucial in all PV applications to improve energy efficiency and system performance. Maximum power point tracking (MPPT) is utilized in PV systems to track the voltage that maximizes their output power under varying conditions. In this paper, an enhanced MPPT estimation algorithm is proposed based on the H-adaptive extended Kalman filter (EKF). The proposed method adapts to possible changes in the system’s noise statistics due to variations in irradiance, operating temperature, and system’s aging. The approach is compared to common MPPT estimation techniques; namely the Perturb and Observe (P&O) method and the EKF. The method was validated using experimental data collected from a PV array, to demonstrate practical applicability. Results showcase the adaptability of the proposed approach to variations in the process noise covariance, measurement noise covariance, and the dynamic system scaling factor parameter. These attributes are essential for a sustained extraction of the maximum power from the PV system."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel hybrid framework that integrates machine learning (ML) techniques with Sequential Monte Carlo Simulation (SMCS) to enhance the reliability assessment of modern power systems incorporating renewable energy resources (RER) and plug-in hybrid electric vehicle (PHEVs) integration. While PHEVs can leverage RER to significantly reduce greenhouse gas emissions, the increased energy demand from large PHEVs fleets poses potential challenges to power system reliability. To address these issues, this research presents an advanced mixed-integer linear programming (MILP)-based algorithm for optimizing EV charging. The algorithm prioritizes clean energy utilization through intelligent power allocation strategies while considering cost-revenue trade-offs. A probabilistic model is developed to account for factors such as driving distance, charging times, locations, battery state of charge, and charging needs of PHEVs. The proposed approach is tested on the IEEE RTS-79 test system and evaluates multiple ML architectures, including Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and Transformer models, often combined with boosting algorithms, across three scenarios: base case, uncontrolled charging, and intelligent charging. Results highlight that ML-based approaches, particularly the Transformer model, achieve computational time reductions of up to 49% compared to traditional SMCS methods while maintaining comparable accuracy. The Transformer model identified 1,788 loss-of-load states compared to 1,510 actual instances, requiring only 176 minutes of computation. Among all models, the BiLSTM with Adaptive Boosting (BiLSTM+AB) achieved the lowest overestimation, exceeding actual instances by just 256 states. Performance metrics such as Loss of Load Probability (LOLP) and Expected Demand Not Supplied (EDNS) validate the effectiveness of the proposed ML approaches in balancing accuracy and computational efficiency."
  },
  {
    "year": "2025",
    "abstract": "Blockchain has found many uses beyond cryptocurrency trading. However, this technology faces the challenge of low transactions per second (TPS), which hinders it from competing at scale with other established digital payment technologies. This low TPS problem is worsened by occasional block generation delays, which usually hike transaction fees as transactors must compete using transaction fees to have their transactions added to a block in a blockchain. These block delays can also be indicative of other underlying issues, such as dishonest mining. This study focuses on the prediction of such delays in a Bitcoin blockchain. Such predictions can help transactors strategically place transactions at moments when delays are unlikely to occur, and the predictions can also help avoid resulting higher transaction fees and potential dishonest miner behavior. The problem is modeled as a prediction of a binary outcome, that is, block delay or block-on-time. Three approaches for training the logistic regression model were compared: frequentist maximum likelihood estimation (MLE), Bayesian Hamiltonian Monte Carlo (HMC), and Bayesian Gibbs sampler. The precision-recall (PR) area under the curve (AUC) was chosen as the main comparison metric because the dataset exhibited a class imbalance problem. The PR AUC values showed that the fitted models performed better than the random classifier, with the Gibbs sampler model performing the best among the three. The PR AUC values also showed that there was a big room for improvement on all the fitted models."
  },
  {
    "year": "2025",
    "abstract": "Integrating Artificial Intelligence (AI) into the Software Development Life Cycle (SDLC) has become necessary to enhance efficiency, scalability, and performance in modern software systems. Instead of incorporating the AI functionality into their SDLC, traditional SDLC models typically add-on the AI software functionality after they have integrated AI functionality into their application or software process. Because of this, developers undergo inefficiencies in their development workflows, experience performance bottlenecks during testing, and experience challenges of incorporating AI to improve an application’s performance through optimization. This paper proposes a new AI-Optimized Software Development Life Cycle (AI-SDLC), which is a holistic and comprehensive framework that encases the embedded AI capabilities and optimization strategies throughout the SDLC process during every stage of the system development, so that requirements-gathering, development, testing, and maintenance are hybrid software processes and not dictated by AI vs. traditional software development processes. AI-SDLC presents new development roles, such as AI Integration Specialist, Code Optimizer, and UX Optimization Specialist, which helps developers work across disciplines and increases collaborative interaction between traditional developers and AI engineers. AI-SDLC also utilizes an AI-driven automated hybrid software process in areas such as requirement elicitation, design/architecture validation, testing, deployment monitoring, and scalability to produce robust high-performance systems in all areas of practicing software development life cycle work. The discourse includes a rich case study based on a Smart Logistics Management System to demonstrate practical implementation of the AI-SDLC and how it facilitates improvement in system efficiency and improved user experience. Additionally, the discussion also highlights the possibilities of AI-SDLC practical implementation in other industri..."
  },
  {
    "year": "2025",
    "abstract": "In electronic noses (e-Noses), the employed sensors’ responses consist of overlapping clusters leading to inaccurate analysis. Larger intra-cluster distances and smaller inter-cluster distances within the dataset cause overlapping clusters. The lack of well-separated clusters hinders pattern recognition techniques from excelling and requires effective isolation for optimal performance. This work proposes recursive shrinking towards effective cluster isolation utilizing the synergy of principal component analysis and the bisection method. The clusters shrink towards their centers on each recursion by optimizing an objective function, effective inter-cluster distance (EICD). Overlapping characterizes negative EICD. The experimental findings demonstrate the effectiveness of the suggested approach on a dataset that includes responses from five different alcohol categories: 1-octanol, 1-propanol, 2-butanol, 2-propanol, and 1-isobutanol. The used dataset exhibits highly overlapped clusters with negative-valued EICD. Clusters of 1st, 2nd, 3rd, and 4th alcohol overlap with subsequent peers (i.e., 1-2, 3, 4, 5; 2-3, 4, 5; 3-4, 5; 4-5) and achieve negative EICD. Recursive shrinking produces completely isolated clusters with positive EICD values. The results depict the effectiveness of isolation numerically and graphically."
  },
  {
    "year": "2025",
    "abstract": "To improve the performance of the dual-vector model predictive torque control (MPTC) scheme for SPMSM, for sectors II, IV, and VI, this paper attempts to improve the traditional dual-vector modulation with three-segment symmetrical sequences from two aspects: switching loss and synthesis accuracy. First, the switching state of the zero vector is changed from 000 to 111, thereby reducing the number of switching actions by half within a PWM cycle. However, theoretical analysis and simulation results indicate that this dual-vector modulation will introduce more switching actions and losses between two consecutive PWM cycles. Therefore, the traditional dual-vector modulation has the minimum switching actions and cannot be further improved in switching loss. Then, the commutation instants are modified to increase another applied active vector, and the three-vector modulation with five-segment symmetrical sequences and no vector synthesis error is adopted in sectors II, IV, and VI. For other sectors, the dual-vector modulation with three-segment symmetrical sequences is adopted, which has only one switching action within a PWM cycle. Therefore, a hybrid-vector MPTC is formed. Finally, the feasibility and effectiveness of the proposed hybrid-vector MPTC for PMSM are verified by the experimental results, compared to the dual-vector MPTC with three-segment symmetrical sequences and the three-vector MPTC with five-segment symmetrical sequences, under the same switching frequency, the best control performance can be obtained with the minimum switching losses."
  },
  {
    "year": "2025",
    "abstract": "This study aims to enhance the control performance of four-wheel independent steering vehicles (4WIS), which are increasingly recognized as a key innovation in electric vehicle technology. 4WIS provides a high degree of freedom and dynamic performance by enabling the independent steering of each wheel. However, as an over-actuated system, it requires the allocation of four steering angles from a single driver input, making control allocation critical. Existing methods often fail to fully consider the friction limits of individual tires, potentially compromising vehicle stability, especially under severe driving conditions. To address this, a grip margin-based control allocation (GMCA) technique is proposed, which distributes control forces according to each tire’s available friction, minimizing yaw rate error and side-slip angle while maintaining stability. GMCA is formulated using computationally efficient algebraic operations, enabling real-time implementation. Validation through Simulink/CarMaker co-simulation confirms that GMCA improves maneuverability and lateral stability over conventional methods, offering practical benefits for precise control of 4WIS vehicles under severe road conditions."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a magnetic-geared permanent magnet synchronous motor (MG-PMSM), which is an integrated structure composed of a permanent magnet synchronous motor (PMSM) and a magnetic gear (MG) for autonomous underwater vehicles (AUVs). The MG-PMSM features a dual rotor structure: a high-speed permanent magnet rotor (PMR) and a low-speed pole piece rotor (PPR). To meet the required load conditions of the single propeller of the AUV, the PPR, directly connected to the output shaft, operates under load conditions, while the PMR operates under no-load conditions. The aim of this study is to use finite element analysis (FEA) to investigate the overall electromagnetic performance of the proposed MG-PMSM with different gear ratios and slot/pole combinations. Subsequently, a structural analysis of the PPR and its support structure is conducted using FEA to validate the strength of the PPR structure. Furthermore, thermal analysis is performed using computational fluid dynamics. The results of the structural and thermal analyses demonstrate sufficient structural strength and thermal stability, respectively. Finally, the electromagnetic performances of the proposed MG-PMSM are compared with the PMSM and MG configuration. The results show that, although the MG-PMSM exhibits nearly identical efficiency, it achieves an 11.4% increase in volumetric torque density per unit active volume compared to the PMSM and MG configuration. Moreover, when accounting for the inactive volume of the integrated underwater propulsion system, the volumetric torque density is expected to increase further."
  },
  {
    "year": "2025",
    "abstract": "The evolution of wireless communication has brought great benefits to society, such as multi-connectivity, increased connection speed, low latency, and elevated throughput. However, it has also raised concerns regarding security and the procedures of network swaps, more known as handovers. This paper proposes using machine learning in 5G mobile networks, employing a Logistic Regression algorithm to predict handovers. Considering selection criteria like Reference Signal Received Power, Signal-to-Interference-Plus-Noise Ratio, Received Signal Strength Indicator, and distance, our proposal shows that it can significantly reduce the consequences of frequent handovers and provide a better quality of service to the user, together with low computational complexity. The presented results prove the viability of this proposal."
  },
  {
    "year": "2025",
    "abstract": "This review article covers the multidisciplinary challenges shaping hydropower development within a broader energy transition. Classical hydropower generation facilities are moving toward flexible operations to adapt to and facilitate the integration of variable renewable energy sources (VRES). This review article explores the paradigm shift in terms of machine design considerations, power plant operation, and grid regulator implications. Machine designers, consider magnetic saturation, energy efficiency estimation, and mechanical wear and tear. This could involve, high flux densities in certain core regions, lower weighted average efficiencies, and higher machine failures owing to insulation degradation. Moreover, power plant operators must consider the effects of the flexible power production caused by VRES. In some cases, hydropower ramping ranges from 1 to 5 megawatts (MW) per second for large hydropower plants, which pose technical challenges for operators. Moreover, transmission system operators must strengthen reactive power mandates and system-bearing ancillary service markets to ensure grid stability. In certain regions, there could be longer periods with a significant reduction in physical inertia and short-circuit grid strength owing to the lower share of classical non-inverter-based generation facilities in VRES-rich power systems."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel permanent magnet traction machine with a non-uniform air-gap rotor topology specifically designed for high-speed rail applications exceeding 400 km/h. The innovative rotor configuration could effectively suppress air-gap magnetic field distortion during high-speed operation, thereby reducing harmonic components in the magnetic field and minimizing core losses while enhancing overall efficiency. Firstly, the basic topology of the proposed non-uniform air-gap rotor is studied and the main design parameters of the traction machine used for high-speed rail train with speed over than 400km/h are analyzed. Secondly, the influence of main design parameters of the proposed rotor with non-uniform air gap on the key electromagnetic characteristics such as no-load characteristics, rated operating characteristics, losses, and efficiency is analyzed. Then, the no-load back electromotive force (EMF), rated torque, losses, efficiency and inductance of the proposed traction machine with non-uniform air gap are comprehensively analyzed based on the optimized structure. Finally, experimental validation through prototype testing confirms that the proposed non-uniform air-gap permanent magnet traction machine could successfully meet the operational requirements of high-speed rail train exceeding 400 km/h."
  },
  {
    "year": "2025",
    "abstract": "Recent memory-sharing approaches, e.g., based on the Compute Express Link (CXL) standard, allow the flexible high-speed sharing of data (i.e., data communication) among multiple hosts. In information systems for sensitive data, the data sharing between hosts, must be closely controlled. Security policies may require strict isolation, so-called air-gapping. However, strict isolation mechanisms are currently lacking in data communications based on shared memory. We propose the novel COntrolled Shared Memory (COSM) framework for strictly and dynamically controlling the data communication via shared memory approaches. We introduce the novel concept of COSM isolation, which restricts data communication via shared memory regions with first-level isolation based on a write-and-read permission matrix and second-level isolation based on data inspection. These isolation levels are enforced by the memory controller on an externally-attached shared memory device (ESMD). COSM isolation is thus generally more secure than the existing software-based isolation (e.g., virtual machine isolation of a hypervisor) and existing hardware-assisted isolation (e.g., single-root input/output virtualization). We implement COSM host-to-host isolation in a testbed with an ESMD built on a Field Programmable Gate Array (FPGA). We evaluate the host data write and read rates [bit/s] and latencies under various ESMD loads as well as write-and-read permission configurations. The introduced COSM isolation can serve as the foundation for a new sub-field of research within the information technology (IT) security research field."
  },
  {
    "year": "2025",
    "abstract": "Factorization machines (FMs) are widely employed as supervised predictors in collaborative recommendation. FMs can efficiently model second-order feature interactions through inner products, which is beneficial for mitigating the negative effects of data sparsity. However, existing research has largely overlooked the potential correlations and attributes among features in FMs. These inherent relationships between features can enhance our understanding and facilitate the modeling of meaningful feature representations. To address this gap and capture intrinsic correlation information in the data, we propose a novel model named Feature Reweighting-based Factorization Machine (FRFM) in this paper. Specifically, we incorporate similarity into FM and quantify the strength of interactions between features using a similarity calculation method based on mutual information. We then introduce a feature reweighting strategy to effectively learn latent representations, ensuring that similar features exhibit comparable first-order weights and second-order embedding vectors based on their similarity. By assigning different weights to different feature pairs, FRFM adeptly captures the potential correlations and attributes among features within the model. Furthermore, FRFM can be seamlessly integrated into other models to enhance their performance. Extensive experiments conducted on six real-world datasets demonstrate the advantages of our proposed FRFM compared to the state-of-the-art methods."
  },
  {
    "year": "2025",
    "abstract": "A vital issue faced by the distribution network is the occurrence of unintentional islanding. The failure to identify unintentional islanding results in significant implications for both the power system and human lives. In this paper, a novel machine learning islanding detection method (IDM) based on image classification utilizing the histogram of oriented gradient (HOG) feature is proposed. In particular, the set of parameters are utilized, namely total harmonic distortion (THD) of both three phase currents and voltages, and rate of change of negative sequence voltage, are first transformed into time-frequency representations (i.e., spectrograms via the short time Fourier transform, and scalograms through continuous wavelet transform). Then, the HOG features are extracted from these images and used to train the machine learning (ML) algorithms to distinguish between occurrences of islanding and non-islanding events. Performance metrics including F1 score, recall, accuracy, precision and misclassification error are employed in the assessment process. Numerical results show that our image-based detector achieves faster detection times and higher detection accuracy versus state-of-art methods, thus confirming the validity of such approach for identifying islanding events."
  },
  {
    "year": "2025",
    "abstract": "The recognition of modulation types in received signals is essential for signal detection and demodulation, with broad applications in telecommunications, defense, and wireless communications. This paper introduces a pioneering approach to automatic modulation recognition (AMR) through the development of a highly optimized long short-term memory (LSTM) network. The proposed framework is engineered to capture intricate temporal dependencies within modulated signals, leveraging a gated architecture that effectively mitigates the vanishing gradient problem. This innovation markedly improves recognition accuracy, particularly in low-SNR conditions where traditional methods are often limited. A defining contribution of this work is the introduction of a novel, adaptive temporal-spectral feature learning mechanism, which seamlessly integrates both temporal and spectral characteristics of the signal. This paradigm eliminates the need for manual feature extraction, enhances interpretability, and significantly boosts classification efficiency. Furthermore, the proposed framework is designed for low-complexity deployment, ensuring its scalability and suitability for next-generation wireless networks and real-time communication systems. The proposed architecture is capable of distinguishing between seven modulation classes: BASK, 4-ASK, BFSK, 4-FSK, BPSK, 4-PSK, and 16-QAM. Performance is evaluated across a broad range of signal-to-noise ratios (SNR), from −10 dB to +30 dB, through extensive simulations. Experimental results demonstrate that the model achieves a recognition accuracy of 99.87% at an SNR of -5 dB, outperforming several conventional machine learning techniques, including multi-layer perceptron (MLP), radial basis function (RBF) networks, adaptive neuro-fuzzy inference systems (ANFIS), decision trees (DT), naïve Bayes (NB), support vector machines (SVM), probabilistic neural networks (PNN), k-nearest neighbors (KNN), and ensemble learning models, as well as recurr..."
  },
  {
    "year": "2025",
    "abstract": "Given the increasing complexity of maritime traffic, particularly with the growing integration of autonomous vessels alongside conventional vessels, the need for enhanced coordination and decision support systems has become critical to ensure safety and efficiency. This article presents a concept for a centralised decision support system for local maritime traffic and can be used in centres for remote operations or vessel traffic services. By formalising a non-zero-sum asymmetric polymatrix game, we achieve collision and grounding avoidance of non-cooperative agents. Time-varying and state-dependent payoff matrices are constructed using a reward framework that combines metrics for compliance with maritime traffic rules, global collision risk, grounding risk, and an operational efficiency metric for speed and route optimisation. A pure Nash equilibrium is reached in a polymatrix game, a fully connected graph of traffic participants on vertices with bimatrix games on the edges. Strategy probability distributions in infinite populations located on the graph’s vertices are updated with the replicator revision protocol. The equilibrium constitutes a control message consisting of advised speed and heading commands broadcast to all traffic participants. To validate the proposed idea, we have developed a scalable multi-agent system simulator and present results from a collision avoidance scenario with three vessels and 49 strategies available to each. Engaged vessels achieved safe and efficient passage, guided by the advised speed and heading changes."
  },
  {
    "year": "2025",
    "abstract": "Accurately identifying security bug reports remains a key challenge in software development. Due to the varying expertise of bug reporters, many security bug reports are incorrectly labeled as non-security bug reports, this increases the security risk of the software and the workload of developers to identify these incorrectly labeled reports from bug reports. This study aims to improve the prediction of security bug reports by addressing the class imbalance problem and enhancing the generalization ability of the model across projects. To achieve this goal, we propose a deep learning-based prediction method combined with a novel data augmentation method based on cross-project text similarity. The bug report data is collected from four open-source projects: Ambari, Camel, Derby, and Wicket, where the number of security bug reports is 56, 74, 179, and 47, respectively, and the number of non-security bug reports is significantly higher. To alleviate the imbalance phenomenon and leverage cross-project knowledge, we augment the dataset by identifying and merging semantically similar security bug reports from other projects. We evaluate 5 deep learning models, including CNN, LSTM, GRU, Transformer, and BERT. Our approach achieved F1 scores between 0.60 and 0.98, with the best performance using LSTM and GRU models, especially LSTM on Ambari, GRU on Camel and Ambari, they both achieved an F1 score of 0.98. The overall average F1 score is 0.77, a significant improvement over the baseline classification. The results show that data augmentation based on cross-project similarities is an effective strategy to improve security bug report prediction, especially in imbalanced datasets. This approach can help developers detect security-related issues more effectively, reduce the risk of misclassification, and enhance overall software security."
  },
  {
    "year": "2025",
    "abstract": "The integration of Artificial Intelligence (AI) and Machine Learning (ML) is revolutionizing precision medicine by enabling the customization of therapeutic strategies to individual patient profiles. The study proposed Personalized AI-Driven Therapeutic Framework (PAI-DTF) combines real-time multi-modal data fusion, deep architectures, and Patient-In-the-Loop Reinforcement Learning (PIL-RL) to enforce adaptive personalized therapeutic strategies. Here, genomic data integrated with EHR coupled with the metering from wearable devices are combined using an adaptive temporal-fusion mechanism to ensure it is context-aware and timely. The Hierarchical Deep Neural Network (HDNN) structure is the combination of autoencoders and task-specific sub-networks. A new module called Dynamic Biomarker Importance (DBI) that adjusts biomarker priorities based on evolving patient data to permit adaptive precision. PIL-RL adds feedback and adherence behavior into treatment optimization, achieving higher precision, recall, F1 score, and more advanced measures MCC and Cohen’s Kappa. The further robustness also enhances consistency of predictions across 94.8% cases with different hybrid models aggregated by a combination of ensemble learning and meta-reinforcement strategies."
  },
  {
    "year": "2025",
    "abstract": "Phishing attacks are among the persistent threats that are dynamically evolving and demand advanced detection mechanisms to counter more sophisticated techniques. Traditional detection approaches are usually based on single-modal features or static analysis, failing to capture the complex, multi-faceted nature of phishing websites and their dynamic behaviors. Thus, we present a robust Multi-Modal and Temporal Graph Fusion Framework integrating advanced learning paradigms that enhance accuracy and adaptability in phishing detection. Our work proposes four brand-new methods: Multi-Modal Hypergraph Fusion Network (MM-HFN), Temporal Graph Neural Network with Attention (TGNN-Att), Federated Graph Contrastive Learning Network (FGCL-Net), and Multi-Modal Temporal Hypergraph Fusion Network (MMTHF-Net). MM-HFN leverages hypergraphs to capture complex, high-order relationships at textual levels (BERT) and graph-based features versus visual ones (CNNs) for an accuracy in the 95-97% range. TGNN-Att addresses temporal variations in phishing behavior by using attention-enhanced temporal graph networks and LSTMs, providing dynamic detection with 94-96% accuracy. FGCL-Net ensures privacy-preserving learning across decentralized datasets through federated contrastive learning, achieving 93-95% accuracy while safeguarding data privacy. Finally, MMTHF-Net fuses multi-modal and temporal features into a dynamic hypergraph framework, achieving state-of-the-art accuracy of 96-98% with an F1-score of 0.97. These approaches together allow for exact, real-time phishing detection by capturing static and temporal behaviors, high-order relationships, and cross-modal features. The framework proposed demonstrates significant improvements compared to the state of the art, eliminating the shortcomings of single-modality and static analysis while offering scalability, privacy, and adaptability levels."
  },
  {
    "year": "2025",
    "abstract": "The Metaverse is rapidly evolving into a transformative digital ecosystem, bringing with it unprecedented opportunities and a complex array of ethical challenges. This narrative review, based on an in-depth analysis of 105 full publications, explores the key ethical themes associated with the Metaverse, including privacy and data security, identity and behavior, digital inclusivity, mental and physical health, ethical AI, content moderation, intellectual property, governance, environmental sustainability, harassment, cultural representation, and economic implications. Proposed solutions for these challenges encompass privacy-by-design frameworks, robust identity verification systems, equitable access initiatives, explainable AI, and blockchain-based intellectual property protections. Additionally, the review examines governance and legal initiatives, such as frameworks developed by the World Economic Forum, European Commission, United Nations, and IEEE standards. These efforts aim to enhance transparency, ensure universal accessibility, promote ethical AI, and foster safety within the Metaverse. By synthesizing insights from this extensive body of literature, this review offers a thorough exploration of the ethical dimensions of the Metaverse and presents practical recommendations for fostering responsible and inclusive digital ecosystems."
  },
  {
    "year": "2025",
    "abstract": "Sequential recommendation models are used to predict users’ next top-K preferred items based on their historical interactions. However, these models often struggle in “fuzzy areas” where recommendation scores are near decision thresholds, leading to false positives and false negatives. To overcome this limitation, we proposeSERLogic, an innovative framework that incorporates logic rules, termedTIE+s, into existing sequential recommendation models to enhance their accuracy without the need for training a new machine learning model.TIE+srepresent a novel class of graph prediction rules characterized by a dual graph patternQand a dependencyX→(x,likes,y), whereQexhibits a dual star structure, and X extends ML sequential recommendation models and 1-WL test as predicates. WithSERLogic, we show 1) validation problem forTIE+sis in polynomial time (PTIME), enabling efficient verification of whether a graph satisfies a set ofTIE+s; 2) creator-critic algorithm that iteratively learns high-qualityTIE+s; 3) parallel algorithm that applies the discoveredTIE+sto generate recommendations efficiently. Empirical evaluation on real-world datasets reveals thatSERLogicsignificantly enhances the performance of sequential recommendation models in terms of Recall@K and NDCG@K, while also achieving superior computational efficiency."
  },
  {
    "year": "2025",
    "abstract": "Hologram calculations pose a significant challenge for future holographic displays with extensive fields of view and wide viewing angles. Classical computers may encounter difficulties with these owing to immense computational demands. This study introduces quantum computer-generated holography (QGH) as a viable solution. QGH employs a point-cloud algorithm in which point-cloud data are represented by the superposition states of qubits, and lightwave interactions on the hologram are calculated using principles of quantum mechanics. QGH can accelerate hologram computation by a factor of106in a 1 tera-pixel hologram from 1 tera-object points, compared to classical computer-generated holography. The study discusses advantages, limitations, and future directions."
  },
  {
    "year": "2025",
    "abstract": "This paper presents an efficient in-memory hyperdimensional computing (HDC) design based on spin transfer-torque magnetoresistive RAM (STT-MRAM), named STT-HDC. A novel time-domain sense amplifier circuit is proposed that significantly simplifies Hamming distance computation of HDC models while dramatically improving energy efficiency. Our design is evaluated using HSPICE simulation under the 28nm FD-SOI technology PDK (Process Design Kit). Simulation results indicate that our approach delivers an energy efficiency of 3.12(fJ) per bit, achieving a significant reduction in energy consumption relative to previous implementations. This substantial enhancement in energy performance, coupled with the simplified computation model, paves the way for more practical and scalable HDC systems in resource-constrained environments. The influence of variations in different process corners, and temperature is also thoroughly covered in the analysis."
  },
  {
    "year": "2025",
    "abstract": "Distributed flexible job shops are increasingly becoming the predominant production method in manufacturing due to their advantages in low-cost production and high customization. In practical production environments, jobs arrive randomly but follow a regular pattern. This paper addresses the scheduling problem of the Distributed Flexible Job shop Scheduling Problem (DFJSP) with random job arrivals. The DFJSP consists of three sub-problems: factory selection, job assignment, and operation sequencing. To tackle this issue, the DFJSP is modeled as a Markov Decision Process (MDP), and a multi-agent approach based on deep reinforcement learning (DRL) is proposed. This approach includes a Distribute Agent (DA) and a Sequence Agent (SA). For the MDP of the DA, we designed 12 state features, 5 candidate actions, and a reward based on the current state of production tardiness. The SA is configured with 7 state features, 6 candidate actions, and rewards that reflect delay conditions. A deep Q-network (DQN) framework that incorporates a linearly decreasing threshold probability was designed to effectively balance exploration and exploitation during the training phase. Comparative experiments conducted on randomly generated instances demonstrate the effectiveness of the DA when used both independently and in conjunction with the SA."
  },
  {
    "year": "2025",
    "abstract": "An effective warranty policy not only fulfills a manufacturer’s or vendor’s obligations but also plays a crucial role in enhancing customer confidence and encouraging future purchases. To attract more customers and drive sales, companies may extend the service life of their products. However, they cannot offer unlimited warranties to dominate the market, as the associated warranty costs will ultimately outweigh the profits. Therefore, manufacturers must strike a balance between the advantages of providing longer warranties to foster customer trust and the potential financial implications involved. Despite the significance of this issue, there has been limited research on hybrid deteriorating systems that encompass both maintainable and non-maintainable failure modes. Furthermore, conducting preventive maintenance analyses is challenging when historical failure data is insufficient. To address these gaps, this study introduces a Bayesian statistical approach to handle preventive maintenance challenges. The system’s deterioration is modeled using Non-Homogeneous Poisson processes (NHPP) with power-law failure intensity functions. A mathematical model, along with a solution algorithm, has been developed to assist manufacturers in making informed decisions regarding pricing, production, and warranty strategies. Furthermore, to facilitate the practical application of these models, the study offers solution algorithms and a computerized framework that enables decision-makers to implement automated decision-making processes."
  },
  {
    "year": "2025",
    "abstract": "Large railway vision models (LRVMs) have exhibited remarkable performance in tackling diverse railway-related vision-based tasks, attributed to their capacity for in-context learning (ICL). However, in terms of speed and memory usage, these models suffer from inefficient hardware utilization, particularly when training from scratch with suboptimal batch sizes. Consequently, LRVMs face challenges in achieving high throughput compared to state-of-the-art, task-specific railway models. To address this problem, we propose a novel framework with cross-block feature union (CBFU) designed to optimize the computation time and GPU memory allocations for LRVMs, in both the training and inference phases while preserving accuracy. Our key innovation lies in the synergistic integration of CBFU with cascaded group attention (CGA) and multi-level feature concatenation, which collectively address the inefficiencies of prior LRVMs—a challenge unresolved in existing work. Drawing inspiration from Efficient-ViT, we incorporate the CGA layer as part of the LRVM’s building blocks to alleviate computational bottlenecks of the multi-head self-attention (MHSA). Additionally, we implement a multi-level feature concatenation technique to enhance transferability across different railway-related tasks and reduce the computation cost. Compared to existing LRVMs, our model demonstrates significant improvement in computational efficiency, achieving a 19-fold reduction in FLOPs. Furthermore, the size of our model is about9×smaller and runs 4.1 and27×faster during training and inference, respectively. These advancements uniquely position our framework as the first to balance accuracy, speed, and memory efficiency for railway vision systems, enabling real-world deployment where prior LRVMs failed. Overall, the proposed advancements enable the usage of LRVMs in resource-limited railway scenarios."
  },
  {
    "year": "2025",
    "abstract": "Efficient management of resources such as CPU, RAM, and disk storage is a critical challenge for object detection systems that rely on multi-camera video streaming, especially for resource-constrained devices. These constraints frequently result in the risk of overheating and potential system failure during high workloads. This paper presents a novel Resource-Aware Framework (RA-Framework), designed to optimize resource allocation using dynamic adaptation mechanisms. The RA-Framework dynamically manages CPU, RAM, and disk storage resources for YOLO-based object detection, supporting multiple camera streams and scheduling mechanisms. The framework was implemented in resource-constrained environments using various YOLO models with single and dual-camera setups. Experimental results showed that the RA-Framework successfully reduced average CPU usage by up to 68.62%, decreased RAM consumption by approximately 13.47%, and extended the time for disk usage to increase by 1% by more than 500% in specific scenarios. In contrast, systems without the RA-Framework experienced higher resource utilization and greater susceptibility to resource scarcity or even overheating."
  },
  {
    "year": "2025",
    "abstract": "This study presents acoustic-based methods for the formation control of multiple autonomous underwater vehicles (AUVs). This study proposes two different models for implementing boundary and path control on low-cost AUVs using acoustic communication and a single central acoustic beacon. Both models are based on the history of relative range and do not rely on the full knowledge of the AUVs states based on a centralized beacon system. Two methods are presented: the Range Variation-Based (RVB) model completely relies on range data obtained by acoustic modems, whereas the Heading Estimation-Based (HEB) model uses ranges and range rates to estimate the position of the central boundary beacon and perform assigned behaviors. The models are tested on two formation control behaviors: Fencing and Milling. Fencing behavior ensures AUVs return within predefined boundaries, while Milling enables the AUVs to move cyclically on a predefined path around the beacon. Models are validated by successfully performing the boundary control behaviors in simulations, pool tests, including artificial underwater currents, and field tests conducted in the ocean. All tests were performed with fully autonomous platforms, and no external input or sensor was provided to the AUVs during validation. Quantitative and qualitative analyses are presented in the study, focusing on the effect and application of a multi-robot system."
  },
  {
    "year": "2025",
    "abstract": "Existing integrations of augmented reality (AR) into surgical navigation systems heavily depend on external tracking systems prone to occlusion and increased complexity of setting up the devices. These issues can compromise the accuracy and usability of AR navigation systems in a clinical operating room. Additionally, the impact of illumination exposure on AR system performance in a surgical room remains underexplored. Current methods for addressing the misalignment issue of AR contents in optical-see-through head-mounted displays (OST-HMDs) also lack sufficient precision, particularly for depth orientation. This study evaluated two inside-out tracking systems, the monocular tracker and stereo trackers, using the RGB and grayscale cameras of Microsoft HoloLens 2. Experimental assessments showed that the proposed stereo tracker achieved superior accuracy, with translational and rotational error of 0.73 mm and 0.15°, respectively, outperforming the proposed monocular tracker and existing reported literature. The proposed automated method to mitigate the impact of excessive light exposure can maintain a 98% marker detection rate across various lighting conditions and marker configurations. These results showed that the proposed techniques can eliminate the dependence on external trackers by providing robust performance in any surgical setting. A phantom study on AR-guided needle insertion further validated the efficacy of the proposed system, achieving an accuracy of1.65±0.16mm and2.69±0.19∘. These results meet the precision requirements for clinical surgeries, highlighting the potential of the proposed AR system to improve surgical outcomes."
  },
  {
    "year": "2025",
    "abstract": "Safety is paramount in every aspect of human concern. In situations where violence occurs beyond the control of observers, it is essential for trained professionals to intervene. These scenarios can be detected by advanced surveillance systems equipped with cameras or sensors. The performance of these systems is highly dependent on the models they incorporate. Although various machine learning and deep learning models have been explored to address these challenges, significant work remains in handling a diverse range of images. This study aims to bridge this gap by training four models—VGG16, MobileNetV2, Yolov6 and Ensemble Model, and a vision Transformer model (‘google/vit-base-patch16-224-in21k’) —with tuned parameters on publicly available video frames. Our analysis established that the Transformer model achieved the highest accuracy, making it the most suitable for applications involving the detection of violent incidents. This research introduces a novel application of AI for semi-automated violence recognition, demonstrating AI’s significant potential in improving public safety. It also emphasizes the superior performance of the Transformer model in accurately detecting violent frames. Semi-automated violence recognition refers to a system where AI models assist in identifying violent incidents within video footage, but human intervention is still required for certain tasks, such as verification or decision-making. The AI system automatically detects potential violent events, flagging them for further review by human operators, who then confirm or act upon these alerts. The Transformer model achieved outstanding results: for the Violence Dataset, it attained a precision of 99%, recall of 99%, F1 score of 99%, and accuracy of 99%. To further verify the performance of the Transformer model, we tested it on the Road-Anomaly Dataset, which presents a challenging scenario with imbalanced classes. For this dataset, the Transformer model achieved a precision of 98%,..."
  },
  {
    "year": "2025",
    "abstract": "Knowledge Graphs (KGs), with their intricate hierarchies and semantic relationships, present unique challenges for graph representation learning, necessitating tailored approaches to effectively capture and encode their complex structures into useful numerical representations. The fractal-like nature of these graphs, where patterns repeat at various scales and complexities, requires specialized algorithms that can adapt and learn from the multi-level structures inherent in the data. This similarity to fractals requires methods that preserve the recursive detail of knowledge graphs while facilitating efficient learning and extraction of relational patterns. In this study, we explore the integration of similarity group with attention mechanisms to represent knowledge graphs in complex spaces. In our approach, SimE, we make use of the algebraic (bijection) and geometric (similarity) properties of the similarity transformations to enhance the representation of self-similar fractals in KGs. We empirically validate the capability of providing representations of bijections and similarities in benchmark KGs. We also conducted controlled experiments that captured one-to-one, one-to-many, and many-to-many relational patterns and studied the behavior of state-of-the-art models including the proposed SimE model. Because of the lack of benchmark fractal-like KG datasets, we created a set of fractal-like testbeds to assess the subgraph similarity learning ability of models. The observed results suggest that SimE captures the complex geometric structures of KGs whose statements satisfy these algebraic and geometric properties. In particular, SimE is competitive with state-of-the-art KG embedding models and is able to achieve high values of Hits@1. As a result, SimE is capable of effectively predicting correct links and ranking them with the highest ranks. SimE is publicly available on GitHubhttps://github.com/NIMI-research/SimE."
  },
  {
    "year": "2025",
    "abstract": "Recent advancements in deep learning and large-scale language models have driven interest in creating conversational robots capable of heartful interactions with humans. However, most existing systems are tailored for specific contexts and lack a comprehensive framework to assist humans in daily activities. Developing a fully autonomous robot that can operate alongside humans and interact with them in dynamic environments is a complex task that requires addressing particular software and hardware demands. These demands often conflict, resulting in trade-offs based on the intended application. To overcome this challenge, we propose a body design that leverages passive dynamics. We illustrate how the essential devices for computation, sensing, and actuation can be integrated into the robot without compromising its embodiment requirements. Conversely, we utilize the weight and placement of these devices to achieve the physical characteristics needed for a robotic body that is well-suited for coexistence with humans. We validate this approach through the development of Indy, a mobile communication robot platform designed to coexist with humans. The employed mechanisms enable Indy to maintain an upright posture without active control and ensure compliance during physical interactions. Experimental results indicate that the generated body movement positively impacts users’ perceptions, promoting a sense of anthropomorphism and enhancing the interaction experience. This confirms that the selected design approach not only provides mechanical advantages but also improves the natural appearance of the robot’s movements."
  },
  {
    "year": "2025",
    "abstract": "Spectrum sensing is a fundamental aspect of cognitive radio technology, tasked with detecting spectrum holes and unknown signal sources to improve spectrum management and resource utilization. While the energy detection (ED) method is widely used for spectrum sensing, it struggles with noise uncertainty (NU) and in low signal-to-noise ratio (SNR) environments. To address these challenges, we present a novel spectrum sensing approach called FDED-DBSCAN, which combines frequency domain energy detection (FDED), frequency domain noise estimation (FDNE), and the density-based spatial clustering of applications with noise (DBSCAN) algorithm; The DBSCAN algorithm clusters signals based on their time-frequency two-dimensional feature space. The proposed method was implemented using the GNU Radio toolkit for efficient acquisition and processing of in-phase and quadrature (I/Q) data from software-defined radio (SDR) hardware, and transformed this data into power spectral density (PSD) for analysis. The FDED algorithm detects signal occupancy in sub-channels, while FDNE calculates an adaptive threshold based on noise variance estimates. Multiple rounds of FDED detection are compiled into a two-dimensional signal detection matrix, which is subsequently analyzed by the DBSCAN algorithm to identify signal clusters. This integrated approach facilitates accurate detection of multiple unknown signals and their bandwidths over a given frequency range, even under low SNR conditions. Experimental validation across three scenarios—single-signal comparison with ED (Scenario I), Orthogonal Frequency Division Multiplexing (OFDM)/Narrowband signal detection (Scenario II), and real-world multi-signal acquisition including FM bands (Scenario III)—confirm FDED-DBSCAN’s superiority over conventional ED, particularly in unsupervised detection of unknown signals. This method demonstrates robust potential for practical applications in complex radio environments."
  },
  {
    "year": "2025",
    "abstract": "Solar power is a clean, renewable energy source with minimal greenhouse gas emissions, combating climate change and increasing energy self-sufficiency. Early fault detection like Shading, cracking, or electrical malfunctions is crucial for maximum efficiency and system failure prevention. This work presents SparkNet, a deep learning model developed for the identification of faults due to contaminants on the surface of solar panels. SparkNet uses Fire Modules architecture, which comprises Squeeze and Expand layers. It is used to extract features and detect panel surface abnormalities, trained on a comprehensive dataset of clean and faulty solar panels under various environmental conditions, and improve computational efficiency by minimizing channel sizes while preserving rich feature representations. SparkNet, when implemented with a dataset of images of solar panels and different weather conditions, achieves an average of 95% in the quantitative performance metrics, including accuracy, precision, recall, and F1 score, better than the other state-of-the-art models. Through comprehensive ablation experiments, SparkNet features are added with best-in-class machine learning (ML) classifiers to test robustness in detecting faults, and results confirm the effectiveness of SparkNet features in detecting accurate fault detection without the use of ML classifiers."
  },
  {
    "year": "2025",
    "abstract": "The density peaks clustering (DPC) algorithm is a density-based clustering method that effectively identifies clusters with uniform densities. However, if the datasets have uneven density, clusters with lower densities tend to have lower decision values, which often leads to the cluster centers being overlooked. To address this limitation, a novel density peaks clustering algorithm incorporating neighborhood radius and membership degree is proposed. The method begins by introducing k-nearest neighbor density estimation to establish a density threshold, segmenting datasets into high-density and low-density regions. In the high-density region, the DPC algorithm is applied to perform initial clustering, identifying prominent cluster structures. For low-density points, neighborhood radius and density criteria are employed to assign these points to appropriate high-density clusters, thereby reducing misclassification. In addition, the membership degree concept is incorporated to improve the accuracy of low-density point assignments. Low-density points that remain unassigned undergo secondary clustering using the DPC algorithm. The proposed approach is evaluated on eight synthetic datasets and eleven real-world datasets, with comparisons to DPC-KNN, DPC, K-means, and DBSCAN. The experimental results demonstrate that the proposed algorithm consistently outperforms these methods in clustering performance, highlighting its effectiveness and robustness."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a novel Hierarchical Deep Reinforcement Learning (HRL) framework for wake homing torpedo guidance, applying the Discrete Event System Specification (DEVS) formalism to design high-level policies and reward shaping functions. Wake homing torpedo guidance generates course commands to enable the torpedo to follow the wake trajectory of a target ship. When the target ship evades the incoming torpedo, the wake trajectory becomes curved, often causing the torpedo to lose track due to the narrow detection range of the wake detection sensor. This necessitates a sophisticated algorithm to consistently track the target ship, particularly in scenarios where the torpedo exits and re-enters the wake trajectory in noisy environments. While heuristic algorithms can handle typical wake trajectories, developing a robust solution for unknown trajectories remains a significant challenge. To address this, we apply a novel reinforcement learning approach to develop the guidance logic and compare its performance with a conventional algorithm-based method. The performance and effectiveness of the proposed approach are demonstrated through numerical simulations."
  },
  {
    "year": "2025",
    "abstract": "Super-resolution (SR) imaging involves converting low-resolution images into corresponding high-resolution data in specific scenarios. Recent advances in intelligent image reconstruction algorithms have been accompanied by impressive visual outcomes in SR generative adversarial networks (GANs). However, existing research has methodological limitations owing to the constraints posed by the model architecture and loss guidance used for optimization. Consequently, unnatural artifacts often appear in the complex backgrounds of images, leading to unappealing visual results. To address these problems, we propose an enhanced U-Net, called the handwritten W-Net (HW-Net) architecture, as well as a loss function that uses high-frequency components for guidance. The former improves the best approximate representation of image regions, whereas the latter guides the generation of SR images with more detailed features. We experimentally implemented a biased strategy called parameter transfer, which is suitable for hybrid parameter models. This approach facilitates the blending of weight parameters between similar but different models, significantly improving the peak signal-to-noise ratio and structural similarity index measure metrics without sacrificing the learned perceptual image patch similarity. Across nine SR benchmark datasets, the proposed combinations, with and without parameter transfer, demonstrated excellent performance across multiple evaluation metrics, surpassing the state-of-the-art SRGAN. The code is available athttps://github.com/DaHuaSen/H2SR."
  },
  {
    "year": "2025",
    "abstract": "Integration of photovoltaic (PV) systems increases demand for DC microgrids (DCMGs). Stability of PV-based DCMG is enhanced by integrating battery storage into it. Addition of another energy storage element, i.e., supercapacitor (SC) further ameliorates battery’s longevity and dynamic stability of DC microgrid. Combination of battery and SC is known hybrid energy storage system (HESS). Control and power sharing of battery and SC play a significant role in HESS operation. Conventional constant frequency low pass filter-based HESS control can share dynamic power between battery and SC. However, the constant and slow dynamics of HESS control affect DC bus regulation and battery’s state-of-charge (SoC). To improve dynamic performance of HESS, this paper proposes, a SoC-based variable frequency low pass filter-based energy management strategy (EMS). Proposed EMS controls power splitting between battery and SC and reduces battery’s sluggishness under necessary conditions. Proposed strategy enhances dynamic DC bus stability, battery life and utilizes SC effectively. Proposed EMS is validated with Matlab simulation and real-time digital simulation."
  },
  {
    "year": "2025",
    "abstract": "The paper presents the evaluation study to enhance the design of the motor’s permanent magnet (PM), with the goal of increasing the performance of the segmented stator Permanent Magnet Synchronous Motor (PMSM). The rotor is externally mounted and embedded permanent magnet placed into the groove. By adjusting the width, tip angle, ratio dimension and skew angle of the PMs optimize the magnetic flux flow inside the motor thereby improving performance of the motor under considerations. Finite Element Method (FEM) is used to evaluate for optimizing the parameters to reach the maximum torque through parametric optimization. The numerical results are compared in terms of static torque, cogging torque, iron losses, torque-to-detent torque ratio, and torque constant parameter variations of the models. The findings with optimized flux flow evolve a new type of outer rotor embedded PMSM structure that is fabricated and tested for practical adoption for static and dynamic characteristics. The proposed new type of segmented rotor exhibits low cogging torque with torque ratio of 62 against the conventional structure with value of 14. The proposed model is fabricated and evaluated for its performance against the numerical results and are in close agreement."
  },
  {
    "year": "2025",
    "abstract": "We propose a fault diagnosis approach that integrates symbolic regression and information theory to optimize inferential sensors, which, along with traditional detection techniques and hard sensors, contribute to a comprehensive fault detection and diagnosis algorithm. Additionally, we introduce an advanced predictive scheme to estimate time-dependent fault evolution functions that enable us to compute the remaining useful life (RUL) of the system. Our methodology employs symbolic regression for parameter trending via a genetic programming algorithm, integrating the system model to discover the fault’s dependence on time. This relation analytically describes the fault progression, providing valuable insights into predicting system health. For comparison, we apply a dynamic degradation-based regression model using the inferential sensors as health indicators. The effectiveness, robustness and superiority of the proposed diagnosis and prognosis methods over traditional power function-based degradation models are demonstrated through experiments on a dynamic cross-flow plate-fin heat exchanger system with varying levels of fault progression, measurement noise, and uncertainty."
  },
  {
    "year": "2025",
    "abstract": "The field of Soft Robotics proposes the use of flexible and compliant materials in the fabrication of soft actuators that can interact with humans in a safer way than conventional robots. While soft pneumatic actuators operate with positive pressure inflating their chambers and creating movement, vacuum actuators operate with negative pressure collapsing their chambers to generate movement. The latter have the benefit that they do not burst due to excessive pressure during contraction and since they shrink in size when activated, they can fit into tight spaces and are therefore more compact, aside from possibly being able to expand with positive pressure. This work presents a soft pneumatic linear actuator designed as a bellow-shaped structure made of silicone rubber that operates with negative pressure to contract and with positive pressure to extend. A Finite Element Method dynamic analysis was performed, using the SIMULIA Abaqus software, to predict the actuator’s behavior. From the definition of the geometry, molds composed of modular pieces were designed and 3D printed to fabricate the actuator prototype. A test platform was designed to perform tests to characterize the actuator and then implement a position and pressure cascade control system, designed with a fuzzy pressure controller in the inner loop and a PI position controller in the outer loop, to regulate both the contraction and the extension of the actuator."
  },
  {
    "year": "2025",
    "abstract": "Diabetic Retinopathy (DR) is one of the leading causes of blindness worldwide, where early detection is critical to preventing irreversible vision loss. Traditional diagnostic methods primarily rely on single-modality data, such as retinal images, or the analysis of image features, which may limit diagnostic accuracy. To overcome these limitations, we propose Diabetic Retinopathy Diagnosis, namely “DRdiag”, a novel model proposed for the early diagnosis of DR. DRdiag integrates multiple modalities: the Fundus images and the duration of disease evolution which is an important factor in the diagnosis of DR as the duration of the disease directly influences the onset and progression of retinal lesions, leveraging two distinct models: a Convolutional Neural Network (CNN) based on DenseNet121 for image feature extraction and a Graph Neural Network (GNN) for capturing complex relationships between patient features. By combining the strengths of these advanced models, DRDiag aims to provide a more comprehensive and accurate diagnostic system, ultimately supporting timely intervention and improved patient outcomes. The experiments are conducted using two datasets, APTOS2019 and Messidor-2, which provide diverse retinal images for robust evaluation. The proposed model achieves high performance on diabetic retinopathy classification. On Messidor-2, it attains 0.976 accuracy, 0.957 kappa, 0.961 F1-score, 0.958 recall, 0.965 precision, and 0.990 specificity. On APTOS2019, it achieves 0.980 accuracy, 0.960 kappa, 0.963 F1-score, 0.959 recall, 0.968 precision, and 0.995 specificity. These results confirm its robustness and reliability."
  },
  {
    "year": "2025",
    "abstract": "Microarray data-based cancer detection advances early diagnosis and personalized medicine by utilizing gene expression data to develop comprehensive cancer profiles, measuring thousands of genes simultaneously. However, the inherent high-dimensional nature of microarray data introduces substantial challenges in data analysis and interpretation. To resolve these issues, gene selection techniques such as filter, wrapper, and embedded methods have been implemented to remove irrelevant genes and reduce the dimensionality of the data. Even with such usefulness, these methods are bound to restrictive elements individually that could compromise the precision of cancer detection systems. More recently, the focus of research has shifted to hybrid approaches that merge several feature selection techniques to mitigate the weaknesses of one method while maximizing the strengths of others. This paper offers an extensive review on feature selection techniques for microarray data and focuses on evaluating the performance of different hybrid methods as an important research gap. The research assesses various combinations of Filter, Wrapper, and Embedded techniques to determine how such hybrid approaches enhance classification accuracy. Hybrid approaches, those that integrate several techniques, have the ability to enhance diagnostic accuracy as well as improve understanding at the biological level. This paper provides a comparative evaluation of hybrid feature selection methods to enhance microarray-based cancer classification. It aims to guide researchers in choosing appropriate strategies that optimize the dataset analysis."
  },
  {
    "year": "2025",
    "abstract": "AI-generated virtual digital humans are profoundly reshaping digital innovation and consumer ecosystems. However, the dynamic evolution of their application scenarios, inherent conceptual ambiguities, and continuously advancing technological features may collectively engender negative consumer perceptions. It is imperative to systematically examine the comprehensive impact, inherent technological limitations, and emergent challenges associated with virtual digital humans. Employing the Theory, Context, Characteristics, and Metrics (TCCM) analytical framework, this study conducts a systematic review of 51 authoritative journal articles published through January 2025. The findings reveal the negative effects of AI-generated virtual digital humans on consumers and compare the relationship between hallucinations and serendipity. Additionally, this study further explores the dimensions of assessing these negative impacts. Finally, we outline the potential avenues for future research."
  },
  {
    "year": "2025",
    "abstract": "Component-based software systems (CBSS) have gained significant traction among researchers and practitioners because of their numerous advantages. By assembling software from reusable components, CBSS can reduce time-to-market and maintenance costs while enhancing productivity, quality, and reusability. This modular approach allows developers to focus on specific functionalities, thereby leading to more efficient and manageable codebases. However, estimating the reliability of a CBSS poses challenges because the factors influencing reliability are complex, and often only their effects are observable. The interactions between the individual components, their integration into the overall architecture, and varying operational profiles contribute to this complexity. Traditional reliability estimation methods may not adequately address these intricacies, thus necessitating more sophisticated approaches. To address this, a new approach has been developed that considers individual component reliabilities, overall software architecture, and real-world usage patterns to estimate the total reliability of CBSS. This approach integrates component-level data with system-level interactions to provide a more accurate reliability assessment. By accounting for the unique behaviors and dependencies of each component within the system architecture, this approach offers a holistic view of software reliability. This approach was validated through a large-scale case study that demonstrated its high accuracy, applicability, and practical utility. The case study involved analyzing a complex CBSS in a real-world environment, where the proposed reliability estimation approach was applied and its predictions were compared with the actual system performance. The results confirmed the effectiveness of the approach in accurately estimating the system reliability, highlighting its potential for broader application in CBSS development and maintenance."
  },
  {
    "year": "2025",
    "abstract": "Proximity searches within metric spaces are critical for numerous real world applications, including pattern recognition, multimedia information retrieval, and spatial data analysis, among others. With the exponential increase in data volume, the demand for memory efficient structures to store and process information has become increasingly important. In this paper, we present an alternative algorithm for efficient computation of the K-nearest neighbors (KNN) query using thek2-tree compact data structure, using the incremental radius technique. This approach offers an alternative to the existing algorithm that utilizes a priority queue overk2-trees. Through both theoretical and experimental analysis, we demonstrate that our proposed algorithm is up to 2 times faster compared to the priority queue based solution, while also providing substantial improvements in memory efficiency."
  },
  {
    "year": "2025",
    "abstract": "Accurate network intrusion detection requires extracting relevant semantic features to minimize mis-classification and identify various kinds of attacks. Traditional models often struggle with uncertain traffic patterns, reducing their reliability. This work presents a Novel Semantic-Driven Meta-Learning Model - a hybrid framework that systematically refines categorization decisions. It uses advanced learning techniques to improve detection through a two-stage verification process. Our approach enhances intrusion detection by integrating an attention-based model for semantic feature extraction and the Simple Neural Attentive Meta-Learner (SNAIL) for rare attack class detection. In the first phase, machine learning classifiers perform macro-classification to distinguish between normal and attack traffic. To reduce mis-classification, an additional classifier verifies the predicted class label using a refined subset of features. In the second phase, the SNAIL model conducts micro-classification, further differentiating attack classes with high precision. This dual-phase strategy is particularly effective in addressing the challenge of detecting rare classes in highly imbalanced network intrusion datasets. Using the NSL-KDD, CSE-CIC-IDS 2018, and CIC-ToN-IoT datasets, we assess our model, showing its better performance in precisely detecting unusual attack types while preserving a low false alarm rate with semantic characteristics. The proposed model demonstrates a higher detection rate for most of the rare classes considered in our study compared to state-of-the-art methods."
  },
  {
    "year": "2025",
    "abstract": "Machine learning has evolved from a lab curiosity to a widely used technology that is fundamentally reliant on ground truth data for model training and evaluation. This research addresses the challenges in obtaining accurate ground truth data due to limited domain expertise, sparse and unrepresentative datasets, and the high costs associated with data acquisition. The quality of this data significantly influences the reliability of machine learning models, prompting research into methods to improve ground-truth reliability. This research proposes a framework that utilize blockchain-based crowdsourcing for ground-truth data annotation. Blockchain technology, with its decentralized immutable ledger system, offers a secure method for data verification and collection from decentralized entities. The proposed framework was implemented in an Ethereum network environment using blockchain technology and smart contracts. Next, we evaluated the collected ground truth by measuring the inter-rater agreement among the participants. The experimental results indicate that blockchain can enhance annotation consistency, showing a higher reliability of crowd-sourced data compared to expert opinions. Most annotator pairs demonstrated moderate to strong agreement, confirming the potential of blockchain technology in improving ground truth data annotation."
  },
  {
    "year": "2025",
    "abstract": "This paper focuses on the peak-to-average power ratio (PAPR) reduction in symbol repetition-based orthogonal frequency division multiplexing (SR-OFDM) systems, and a discrete Fourier transform (DFT)-based scheme is proposed to reduce the PAPR of SR-OFDM signals. It is demonstrated that an SR-OFDM system exhibits a larger PAPR than a classical orthogonal frequency division multiplexing (OFDM) system because of the signal superposition of multiple branches, although the cyclic prefix (CP) overhead can be reduced in SR-OFDM systems. Besides, it is shown that the high PAPR is mainly because of the inverse DFT operation at the SR-OFDM transmitter. Therefore, a DFT-based scheme is proposed in this paper to compensate for the inverse DFT operation, without requiring side information or causing signal distortion. To verify the proposed scheme, a theoretical analysis is provided for the signal characteristics, and simulation results of the complementary cumulative distribution function are also given, together with the bit error ratio."
  },
  {
    "year": "2025",
    "abstract": "High-power antennas have emerged as a critical area of focus for researchers in recent design efforts, particularly for high-power microwave (HPM) technologies. The increasing demand for gigawatt power handling microwave systems in directed energy and electronic warfare applications necessitates the integration of innovative high-power design strategies into traditional antenna design procedures, where the emphasis is on developing wideband and high-gain antennas. Owing to the lack of a comprehensive study of recently proposed antennas for high-power applications, this review paper provides an in-depth discussion, comparison, and examination of the latest advancements in HPM antenna technology. In addition, this review provides a qualitative and quantitative assessment of HPM antennas using widely used antenna metrics such as the center frequency, electrical size, bandwidth, peak gain, and power handling capability. Moreover, this review provides a comprehensive overview of the methodology employed in designing high-power microwave antennas and discusses the outcomes obtained. In addition, the employment of special types of gases, low-loss dielectric materials, and smoothly varying structures to minimize charge buildups, air breakdown, and arching has proven to help improve power handling capability. Using the quantitative antenna metric information published in the open literature, we compiled a table showing performance comparisons between various antenna types and created figures depicting inter- and intra-antenna relationships and tradeoffs. Among the various HPM antennas, the horn antenna can be determined as a versatile and state-of-the-art HPM antenna element demonstrating 10s – 100s of megawatts (MWs) of peak power per element, narrow-to-ultrawideband operating bandwidth, small-to-large electrical size, and medium-to-high gain values. Antennas such as the cavity, impulse radiating, leaky-wave, reflectarray, and other array antennas have achieved state-of-the..."
  },
  {
    "year": "2025",
    "abstract": "Stock market forecasting demands models that balance high accuracy with interpretability, particularly when handling highly volatile and uncertain data. This study introduces a novel interpretable forecasting framework that integrates the Fuzzy Time Series (FTS) model with the Linear Fuzzy Information Granule (LFIG) method. The proposed model addresses two major limitations: the inability of conventional FTS models to effectively capture trend dynamics, and the limited capacity of the LFIG method to account for the influence of recent data. The core contributions of this work are threefold: 1) a variable-sized interval partitioning technique optimized via fuzzy C-means clustering and the principle of justifiable granularity, achieving adaptive data segmentation that balances coverage and specificity; 2) a trend extraction mechanism based on LFIG approach, which applies time-dependent linear functions within sliding windows to quantify short-term trends and associated uncertainties; and 3) a fusion of FTS and LFIG outputs via the ordered weighted averaging operator, which emphasizes trend-consistent predictions to enhance forecasting accuracy. Experimental evaluation on five benchmark datasets from Yahoo Finance demonstrates that the proposed model outperforms eight state-of-the-art forecasting methods in terms of predictive performance. Furthermore, it maintains interpretability through transparent fuzzy rules and explicit trend representations, providing a robust and explainable framework for stock market forecasting."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we introduce Vox Calculi, a system designed to solve mathematical problems using voice transcriptions. By leveraging state-of-the-art pretrained Automatic Speech Recognition (ASR) models, we accurately transcribe users’ voice recordings. Additionally, we develop a specialized mathematical parser that converts natural language mathematical expressions into symbolic representations and numerical values while preserving the remainder of the transcription. We utilize Transformer and TP-Transformer models, trained on DeepMind’s Mathematics dataset, to generate an appropriate mathematical answer from the provided input sequence. An in-depth evaluation of both the ASR and Transformer models demonstrates highly satisfactory results. Furthermore, we propose potential future improvements to enhance the system’s performance."
  },
  {
    "year": "2025",
    "abstract": "This study proposes an optimized dispatch model for integrated energy systems (IES) incorporating electric vehicles (EVs) and carbon emission trading (CET) to analyze their dynamic interactions. The model aims to minimize IES operating costs by systematically evaluating the impacts of EV penetration levels and CET parameters on economic and environmental performance. Methodologically, Monte Carlo simulations characterize stochastic EV behaviors, a stepwise CET mechanism is developed with emission thresholds, and piecewise linearization combined with convex relaxation transforms nonlinear constraints into tractable formulations. The YALMIP/GUROBI solver is employed to compare eight dispatch scenarios. Key results demonstrate that integrating EVs with carbon capture under CET reduces operating costs by 7.64% and emissions by 17.68%. System emissions exhibit a U-shaped relationship with EV penetration, reaching a minimum at 9.20%. Maximum emission reductions from EV charging optimization occur when CET prices range 250-300 CNY/ton and EV penetration spans 12.31%-19.43%, providing critical thresholds for policy design."
  },
  {
    "year": "2025",
    "abstract": "Road networks represent an essential factor in economic prosperity and well-being. Assorted damages and defects on the road surface mainly impact the transportation efficiency of road networks and driving safety. In current traditions, it may take weeks or even months before competent government departments repair such road conditions due to their lack of timely awareness. This research proposes a framework for collecting data and analysis using supervised machine learning (ML) techniques, more specifically Long/Short-Term Memory (LSTM), Random Forest (RF), and networked sensor-enhanced vehicles for effective and efficient monitoring and assessment of road surface conditions. Data collected in four different scenarios and multiple vehicle data help to discover abnormal defects and verify automated detection. ML techniques were developed to identify bumps and potholes automatically, which are the two significant types of road defects. The experiment results of both LSTM and RF models can automatically identify bumps and pothole defects with an accuracy rate of up to 99.8% and a good detection effect. Cross-validation was set to validate the accuracy of the two decision-making strategies, LSTM and RF. Automation technology is expected to provide qualitative and quantitative information about road defect conditions, enabling timely maintenance to improve transportation efficiency and driving safety."
  },
  {
    "year": "2025",
    "abstract": "This research investigated the determinants affecting the adoption of m-government services through the framework of the Value-Based Adoption Model. This study bridges the gap in the literature in two aspects: first relating to the moderating influence of mobility and security respectively on the relationship between benefits (usefulness and enjoyment) and perceived value of m-government services. Second the moderating effect of mobility and security respectively on the interaction between perceived value and the adoption intention of m-government services. The analysis utilizing a dataset comprising 467 Chinese citizens was processed with Smart Partial Least Squares software, employing structural equation modeling techniques. The findings indicate that perceived usefulness, enjoyment, technical aspects, and perceived costs directly influence the perceived value of m-government services. Furthermore, the perceived value associated with m-government was identified as influencing the adoption behavior of m-government services. The moderation analysis showed that mobility played a significant role in influencing the relationship between the benefits of usefulness and enjoyment and the perceived value of m-government services. Moreover, mobility was a key factor in moderating the influence of perceived value on the adoption of m-government services. In addition, security played a crucial role in influencing the relationship between enjoyment and the perceived value of m-government. It also had a significant moderating effect on the relationship between perceived value and the intention to adopt m-government services. Also, the findings of the study revealed that security does not play a significant moderating role in the effect of usefulness on the perceived value of m-government services. These results provide insights into the implications of these findings for the development of value-oriented m-government services."
  },
  {
    "year": "2025",
    "abstract": "The increasing trend in efficiency and performance requirements of electric trains is leading to the deployment of more onboard energy storage elements. Hydrogen fuel cells along with battery systems are being considered by several train manufacturers. Control of the dc-link connecting all energy sources and loads can be challenging due to the need to guarantee reliable operation in all possible scenarios. This paper presents a dc-link control strategy for trains with multiple energy sources. The proposed method combines the advantages of dc bus signalling and droop methods, and allows smooth enabling and disabling of power sources by voltage command modification without any change in the overall control structure. Further, it is fault tolerant to communication loss between the battery and the central control. The proposed concepts are validated in multiple scenarios by means of simulation, as well as experimentally using a down-scaled test bench."
  },
  {
    "year": "2025",
    "abstract": "The utilization of the non-dominant hand contributes to improving the efficiency of hand movements. However, traditional training methods require substantial time to master, making it important to find more efficient ways to improve drawing ability within a limited timeframe. Therefore, this study aimed to improve the efficiency of training by developing a device that improves the accuracy of the non-dominant hand drawing on shape drawing tasks. The device is worn on the user’s finger and provides vibration feedback to guide flexion and extension of the finger, encouraging the user to adopt the optimal fingertip posture for their individual needs. The optimal posture of the fingertip is determined based on the movements of the dominant hand. To evaluate the effectiveness of the device, an experimental shape-tracing task was performed with 44 participants. The participants were tasked with tracing 30 shapes accurately and quickly, and the shifts of the traced lines from the reference lines were quantified. The results of the experiment showed that, while the group without the device experienced a 4.243% increase in Total Shifts, the group that used the device successfully reduced Total Shifts by 4.689%, demonstrating an improvement in drawing accuracy. These results indicate that the proposed device effectively enhances drawing ability within a fixed period and is effective in shortening the training time for the non-dominant hand."
  },
  {
    "year": "2025",
    "abstract": "3D human pose estimation is a crucial task in computer vision with extensive applications, yet it remains challenging due to depth ambiguity and constraints on computational efficiency. In this paper, we propose DCT-DiffPose, a novel framework that integrates a diffusion model with Confidence and Consistency-based Multi-Hypothesis Aggregation (CCMA). Moreover, it incorporate the Discrete Cosine Transform (DCT) for frequency-domain feature extraction. Specifically, the diffusion model generates diverse and plausible hypotheses, and CCMA aggregates them based on confidence and consistency, effectively addressing depth ambiguity. Additionally, we incorporate DCT into the self-attention mechanism to transform input data into the frequency domain, thereby enhancing feature extraction while significantly reducing computational complexity. To validate DCT-DiffPose, we conducted extensive experiments on the Human3.6M and MPI-INF-3DHP datasets. Our method achieves a 19% lower Mean Per Joint Position Error (MPJPE) and a 55% reduction in FLOPs compared to D3DP. The results demonstrate its excellent trade-off between accuracy and complexity."
  },
  {
    "year": "2025",
    "abstract": "Modern electrical distribution networks encounter significant challenges due to DC offsets, harmonics from nonlinear loads, and distorted grid voltages. These issues lead to increased total harmonic distortion (THD), reduced power factor, degraded power quality, and potential instability. Conventional controllers, such as second order generalized integrator (SOGI) and enhanced SOGI (ESOGI), are able to mitigate these issues but involve a trade off between harmonic filtering performance and dynamic response. Moreover, the gain magnitudes achieved for rejecting DC offsets, lower order harmonics, and higher order harmonics are relatively low. To address these limitations, this work introduces a modified second order generalized integrator with a notch filter (MSOGI) in a photovoltaic generator fed unified active power filter (PVG-UAPF) framework. By combining SOGI with a notch filter, the proposed approach leverages their complementary characteristics, achieving both superior harmonic filtering and a fast dynamic response. Furthermore, the proposed control structure effectively suppresses DC offsets and compensates for grid side and load side abnormalities while maintaining a unity power factor in the grid. The effectiveness of the proposed controller in a grid synchronized PVG-UAPF system is evaluated through MATLAB simulations under diverse operating conditions and further validated via real time simulation using the OPAL-RT 5700 platform. Compared to SOGI and ESOGI, the proposed method enhances harmonic filtering accuracy and dynamic response, achieving lower THD values of 1.85% for grid currents and 2.04% for load voltages, ensuring compliance with IEEE-519 standards."
  },
  {
    "year": "2025",
    "abstract": "As the Metaverse and Mixed Reality (MR) technologies continue to evolve, enabling natural and intuitive user interfaces is crucial. However, supporting low-resource languages in these advanced systems presents unique challenges. This article explores the development and deployment of an on-device Automatic Speech Recognition (ASR) system for Galician, a low-resource language spoken by less than 3 million people, implemented on the Microsoft HoloLens 2 MR glasses. The system prioritizes data privacy and security by eliminating the need for Internet connectivity or external processing. Key implementation choices, including software and libraries, are detailed, along with optimization strategies for minimizing latency. Performance evaluations, taking into account noise-simulated environments, demonstrate the high accuracy and low latency of the system, proving its effectiveness as an on-device ASR system for current and future Metaverse applications. In order to demonstrate the effectiveness of the developed system, it has been incorporated in an electrical outfitting application for Navantia, one of the largest shipbuilding companies in the world, illustrating its practical utility in an industrial scenario like a shipyard. The results obtained show a Character Error Rate (CER) below 6% and a latency of under 3 seconds using an ARM64 quantized model, which validates the effectiveness of the system for real-time voice control in industrial MR environments."
  },
  {
    "year": "2025",
    "abstract": "With autonomous robots becoming increasingly integrated into human society, the efficiency of their path optimization is of paramount importance. To address the issue of redundant states in the application of the policy iteration algorithm in the environmental model optimization process and to accelerate the convergence speed of the algorithm, this paper proposes a pseudo-target optimization algorithm based on the policy iteration algorithm in combination with the Manhattan distance. The proposed algorithm prioritizes updating the surrounding state policy centered on the pseudo-target state, the set composed of these states is called a local state set. Once the state policies within the aforementioned set have converged, the next pseudo-target state is identified through the use of the Manhattan distance, and the reward distribution is subsequently changed. Furthermore, the objective of quantifying the inflection point can be accomplished by regulating the length parameter n of the local state set, which corresponds to the different steering characteristics of robots in practical applications. Finally, the superiority of the algorithm is validated through experimental simulation. The optimized algorithm increases the convergence speed by more than 50 % when the parameter n is small, and gradually approaches the convergence speed before optimization when the parameter n is large. The maximum difference in the number of inflection points corresponding to different n values is nine. With the efficiency inversely proportional to the inflection point, this enables a balance between the steering characteristics of autonomous robots and the convergence speed of the algorithm in practical applications."
  },
  {
    "year": "2025",
    "abstract": "This study established a subjective-objective combination of emotional demands and an experimental research approach to address the hurdles to smart device use in the elderly caused by deterioration in their perceptual abilities. We used a neck massager as the research object. This product is a regularly used item for the elderly to alleviate neck soreness, but the experience is unsatisfactory in terms of human-computer interfaces, such as button usage. 1) Proposing to analyze product user needs from an emotional perspective, this study designed and implemented visual-tactile perception experiments involving 12 elderly users, including experiments on button shape, button size, button spacing, button material, button texture, and product material. The impact of button specifications and product materials on elderly users’ emotional preferences was objectively investigated by evaluating theα- andβ-band power characteristics of the participants’ electroencephalography frontal lobe electrodes (FP1, FP2, F3, F4) and central zone electrodes (FPZ, FZ). 2) Aging-friendly design suggestions for smart products were proposed, and neck massage for the elderly was designed. The findings indicate that the button parameters of round shape, 15 mm diameter, 4.6 mm pitch, and 1 mm depth of concave pattern, as well as the product contact surface material of velvet, are ideal. This study offers a scientific approach to product design and a design reference for aging comparable products in terms of button specifications and material selection."
  },
  {
    "year": "2025",
    "abstract": "Attribute value extraction (AVE) is critical in transforming unstructured text into structured data for various applications. While existing datasets for AVE predominantly focus on e-commerce and English language data, there is a lack of publicly available datasets tailored to other domains. This paper introduces the Real Estate Attribute Value Extraction (RAVE) dataset, specifically designed for extracting structured attributes from unstructured real estate advertisements. The RAVE dataset consists of manually annotated Slovak real estate listings, which have been translated into English for broader applicability. The paper evaluates the performance of multiple publicly available large language models in solving the AVE task on RAVE. Through extensive experimentation, we analyse the impact of additional attribute descriptions, selecting relevant sentences, and using ground-truth-based attribute definition in structured output generation. The findings indicate that providing a schema with only relevant attributes (Oracle Attributes) significantly enhances performance and reduces computational overhead while improving the F1 score. Under basic conditions without modifications at the input, the largest model tested, Qwen2.5:32b, achieved a micro F1 score of 10.04%. Applying all tested input modifications (Oracle Attributes, Oracle Sentences, and Additional Descriptions) allowed the largest model tested to achieve a micro F1 score of 97.92%, demonstrating the effectiveness of these techniques in improving extraction accuracy and efficiency. The RAVE dataset is publicly available, facilitating further research in AVE and real estate information extraction."
  },
  {
    "year": "2025",
    "abstract": "The Single Source Capacitated Facility Location Problem (SSCFLP) stands as a pivotal yet highly complex challenge in facility location science, underpinning real-world supply chains where single-sourcing constraints are critical for service quality and operational efficiency. This study introduces a hybrid solution framework that merges a Binary Crow Search Algorithm (BinCSA) with an exact method, leveraging XOR logic, bit-flip mechanisms, and a dynamic awareness probability (AP) scheme to prevent premature convergence. Across medium-, large-, and extreme-scale benchmark instances, the enhanced BinCSA demonstrates accelerated convergence relative to the original BinCSA. By decomposing the SSCFLP into two subproblems, the proposed approach eases the burden on the exact solver and circumvents the need for transfer functions. A Markov chain analysis underpins BinCSA’s theoretical convergence guarantees, supported by computational results that confirm irreducibility and convergence within a finite solution space. Experiments on benchmark datasets show that BinCSA yields high-quality solutions with efficient runtimes, performing competitively against existing heuristics as well as a CPLEX baseline. To the best of our knowledge, although the Crow Search Algorithm (CSA) has been applied to uncapacitated facility location problems (UFLP), the present work is among the first to adapt CSA-based methods to SSCFLP, thereby extending the algorithm’s scope of applicability. Overall, these findings highlight BinCSA’s robustness and efficiency in tackling large-scale, NP-hard optimization problems, paving the way for broader applications in supply chain design, telecommunication networks, and other high-tech domains."
  },
  {
    "year": "2025",
    "abstract": "The quality of tobacco leaves significantly influences cigarette flavor and market value, with chemical composition serving as a critical quality indicator. However, existing tobacco quality prediction studies mainly rely on physical leaf samples, resulting in significant time lags and limited applicability for early decision-making. To address this, we construct a153×6climate factor matrix covering the tobacco growth period (May 1 to September 30), incorporating daily maximum temperature, minimum temperature, mean temperature, precipitation, mean sunlight intensity, and atmospheric pressure. Notably, atmospheric pressure is introduced for the first time to enhance model generalizability. We develop and compare five predictive models: multiple linear regression (MLR), eXtreme Gradient Boosting (XGBoost), long short-term memory (LSTM), gated recurrent unit (GRU), and convolutional neural network combined with LSTM (CNN+LSTM). The models are trained and validated using climate and chemical composition data from 98 tobacco-growing counties in Yunnan Province (2013-2021). Experimental results demonstrate that the CNN+LSTM model achieves superior predictive accuracy, effectively capturing complex spatiotemporal interactions in climate factors. The mean absolute percentage errors (MAPE) for total sugar, reducing sugar, and total nitrogen remain within 10%-20%, while nicotine and potassium exhibit errors in the range of 20%-30%. Furthermore, Integrated Gradients (IG) analysis is employed to interpret the CNN+LSTM model, revealing the contribution of individual climate factors to chemical accumulation patterns. Our approach improves on the time lag issue of existing studies, helps producers plan resources in advance, and provides a data-driven approach for optimizing tobacco cultivation and quality management."
  },
  {
    "year": "2025",
    "abstract": "Image segmentation plays an important role in automating various inspection procedures that are still performed manually. In the production of electric motors, a relevant inspection task involves examining the air gap between the rotor and the stator to identify common defects. This paper introduces an intelligent approach based on a self-organizing map (SOM) that is trained individually for each image to automatically segment the air gap region in electric motor images. This procedure eliminates the need for a large dataset of manually segmented images, which is typically required by most of the intelligent segmentation methods in the literature. The procedure begins with a polar transformation of the motor image, which helps to identify the region of interest for segmentation. The selected region is then used to build a training dataset for the SOM. Each training example consists of a frame extracted around every pixel in the region. Once map training is complete, an automated procedure extracts the air gap segment from the map output by selecting the pixel cluster that corresponds to the air gap. Three configurations of this approach were evaluated, exploring the impact of using different color spaces (RGB, LAB, and HSV). To evaluate the proposed approach, six motor samples were tested, using different illumination conditions. The results were compared with two unsupervised segmentation methods: Otsu’s method and K-Means. The proposed approach outperformed both baseline methods in terms of evaluated metrics, achieving a 65% higher intersection-over-union score than the best baseline method (K-Means). This study demonstrates the efficacy of the proposed image segmentation method, particularly in scenarios where only a limited number of images are available, making it impractical to train a supervised model."
  },
  {
    "year": "2025",
    "abstract": "Quantum computers may solve some computing tasks more efficiently than classical com- puters, but to do so requires the design of appropriate quantum circuits. However, it is hard to design even simple quantum programs. Recent results have shown that deep learning augmented search has the potential to discover good circuits for a problem, but it is not yet sufficiently understood how well deep learning is able to model such a complex domain: the search space and output space grow exponentially. This work explores the ability of neural networks to encode quantum circuits for tasks that require knowledge about the unitary representation of the circuit. To this end, we trained neural networks to directly learn to predict the unitary of a circuit and applied reinforcement learning to train neural networks to solve circuit based quantum state preparation. This work finds that encoding quantum circuits is quite difficult especially with regards to the amount of entanglement applied in both application domains. The use of intermediate states and structure in quantum circuits combined with a reasonable inductive bias, where applicable, can alleviate these problems to some extent. The use of intermediate states also greatly improves the results of Deep Reinforcement Learning for quantum state preparation. Based on these results, we discuss the next set of challenges to address if we are to design neural network-based approaches for the automatic generation of quantum circuits."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes a new variable gain robust state observer for a class of linear uncertain systems. The variable gain robust state observer proposed in this paper consists of fixed observer gain matrices and nonlinear modification functions which are determined by appropriate updating rules. It is shown that sufficient conditions for the existence of the proposed variable gain robust state observer can be reduced to solvability of Linear Matrix Inequalities (LMIs). Finally, we give simple numerical examples so as to illustrate the effectiveness of the proposed variable gain robust state observer."
  },
  {
    "year": "2025",
    "abstract": "Ball bearings are prone to faults in their inner and outer rings and rolling elements. Timely detection of these faults is crucial, especially when adversarial perturbations are present, as deep learning-based fault diagnosis models may misclassify these faults. To address this issue, this study proposes a hybrid adversarial learning method that combines convolutional neural networks with a generative adversarial network framework. In this method, the generator introduces perturbations and adaptively adjusts them based on their magnitude and gradient information. The discriminator was used to verify the effectiveness of adversarial perturbations. The goal of this hybrid adversarial learning method is to improve the fault recognition accuracy of a model when subjected to perturbation attacks. The experimental results show that under adversarial perturbation attacks, the proposed method outperforms other deep learning models and defence methods, demonstrating the effectiveness of this approach."
  },
  {
    "year": "2025",
    "abstract": "In the field of target detection, algorithms are challenged with multi-objective optimization problems in identifying detection targets, and it is also crucial to improve the recognition of small and insignificant targets. In this study, the Feffol network model is proposed to achieve excellent performance in complex detection tasks. In the feature extraction stage, the Feffol network model carefully chooses Efficient-v2 as the backbone network structure, which can provide a solid foundation for subsequent detection by taking advantage of its efficient feature extraction capability. In addition, an Ebifpn feature pyramid module with an spatial pyramid pooling-cross-stage partial connections(SppCSP) structure was innovatively introduced. This design not only effectively expands the feature sensing field, but also greatly enhances the fusion and expression of feature information of different sizes, so that the model can capture the target features more comprehensively. In addition, to solve the key problems in the detection process, the Feffol model adopts the Focal Loss and CIoU Loss functions. The former can effectively balance the positive and negative samples to avoid over-learning of easy-to-classify samples during the training process; the latter successfully solves the problem of the failure of the detection method when there is no intersection between the prediction frame and the real detection frame, which significantly improves the robustness of the model. The experimental results show that the Feffol network model has excellent performance, with a detection accuracy as high as 90.09% and a detection speed of 9.75it/s. Compared with other mainstream networks, the detection accuracy of Feffol network has been significantly improved, which fully proves its advancement and effectiveness in the task of target detection, and provides new ideas and methods for the further development of this field."
  },
  {
    "year": "2025",
    "abstract": "Stroke occurs when the blood flow to a certain region of the brain is disrupted. It is a leading cause of long-term disability and can result in cognitive impairments, speech difficulties, and motor dysfunction. Regular monitoring and timely intervention are critical to minimizing the damage and improving outcomes. This article presents a novel Radio Frequency (RF) sensing and Artificial Intelligence (AI) based Digital Twin (DT) model for effective detection of stroke. Through backscattering RF signals, the proposed Ultra Wide Band (UWB) antenna provides stroke detection. The implementation of Machine Learning (ML) and Deep Learning (DL) technologies for stroke classification provides the necessary decision support to healthcare professionals in DT stroke patient monitoring. The statistical and autonomous (AutoEncoders (AE) and Stacked AutoEncoders (SAE) with structure 32-16-32, 64-32-16-32-64, and 128-64-32-16-32-64-128) feature data is enlarged through Gaussian noise feature data augmentation. The Fine KNN algorithm provides the 93.4% and 92.3% classification accuracies of binary and multi-class classification respectively. Out of the 4 autonomous feature extraction methods, the Fine KNN algorithm with SAE structure 64-32-16-32-64 provided the highest accuracies of 88.2% and 74.8% for binary and multi-class classification."
  },
  {
    "year": "2025",
    "abstract": "Accurate localization of picking points and depth estimation is critical for implementing a robotic strawberry harvesting system. Due to the delicate nature of strawberries, harvesting must be performed without bruising or damage, typically by grasping and cutting the peduncle of the ripe strawberry. However, accurately detecting and localizing the thin peduncle in a cluttered environment is a significant challenge. This study proposed depth fused Mask R-CNN (DF-Mask R-CNN), which integrates depth information of the scene with the RGB image to enhance the detection, localization, and segmentation of strawberries and their peduncles in a greenhouse environment. To generate a dense depth map, a cutting-edge monocular depth estimator, ZoeDepth was used. The proposed DF-Mask R-CNN with ResNet101-FPN exhibited superior instance segmentation performance, with an overall mAP of 81.9%, with mAPsmall at 33.3%, mAPmedium at 78.79%, mAPlarge at 88.8 and APIOU=0.5at 98.1%. In tests with 300 ripe strawberry samples, the method demonstrated a robust picking point detection, with a mean absolute error and root mean square error of 1.98 cm and 2.12 cm, respectively. These results highlight the effectiveness of the DF-Mask R-CNN model combined with the ZoeDepth estimator in enhancing the detection, localization, and segmentation of strawberries and their peduncles. This approach enables precise picking point localization and depth estimation for efficient vision systems for robotic strawberry harvesting."
  },
  {
    "year": "2025",
    "abstract": "This paper presents two new VCII-based Kerwin-Huelsman-Newcomb (KHN) equivalent biquad circuits, each comprising three second-generation voltage conveyors (VCIIs), two grounded capacitors, and five resistors. Either voltage mode (VM) or trans-impedance mode (TIM) can operate in each proposed circuit configuration. Transfer function analysis using a VM inverting bandpass (IBP) filter yields two additional non-inverting/inverting KHN biquad transfer functions for the two proposed VM/TIM KHN-equivalent biquads. The first proposed VM/TIM KHN-equivalent biquad can simultaneously implement an IBP filter, a non-inverting low-pass (NLP) filter, and an inverting high-pass (IHP) filter. In contrast, the second proposed VM/TIM KHN-equivalent biquad can simultaneously implement an IBP filter, an inverting low-pass (ILP) filter, and a non-inverting high-pass (NHP) filter. Each proposed VM/TIM KHN-equivalent biquad features three low-impedance voltage outputs in the designed circuit, eliminating the need for additional voltage buffers (VBs) in the circuit measurements. The two proposed KHN-equivalent biquads are integrated into a single chip, occupying a total area of 1.44 mm2. This technology uses the TSMC0.18μm 1P6M CMOS process, with the chip operating at a supply voltage of ±0.9 V. The measured power dissipation of the first KHN-equivalent biquad is 2.7 mW, while the measured power dissipation of the second one is 3.24 mW. The measured spurious-free dynamic range (SFDR) of the first KHN-equivalent biquad is 41.18 dBc, while the measured SFDR of the second one is 40.94 dBc. With an input voltage of 1.2 Vpp, the measured total harmonic distortion (THD) values for both KHN-equivalent biquads are below 1 %. The proposed two KHN-equivalent biquads have the advantages of high density, system integration, efficiency, low cost, low power consumption, and effective utilization of chip layout area. Simulations and on-chip measurements are carried out for both KHN-equivalent bi..."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we study the extension of 5G New Radio (NR) to Non-Terrestrial Networks (NTN). For terrestrial ones, Hybrid Automatic Repeat reQuest (HARQ) is the main retransmission solution used by 5G NR at the physical and MAC layers, enhancing decoding performance through diversity and coding gain. However, for NTN, its implementation faces challenges due to the significant delays caused by the long distances of satellites. In the first part, we begin by investigating the minimum number of HARQ processes required for various LEO scenarios, as well as the relationship between the number of processes and the coherence time of the satellite link. Next, while the performance of 5G retransmission schemes over AWGN and terrestrial channels is well explored, this is not the case for realistic satellite channel models. To address this, we have developed an open-source simulator that accurately implements all the blocks of the data channel transmission and reception chain, including the retransmission schemes and the Land Mobile Satellite (LMS) channel. We consider the 5G NR Physical Downlink Shared Channel (PDSCH) and we present and discuss a number of results over the LMS channel, which are important to understand the HARQ performance for the NTN satellite scenario. In the second part, we consider the 5G NR alternative retransmission solution, RLC ARQ, which is available at the Radio Link Control (RLC) layer. This method might be interesting for satellite links, because it adds minimal complexity to the receiver side, but it provides less enhancement to signal reception capabilities and more latency. We first present an analytic model to compute its performance over the LMS channel, then we analyze its behavior. Finally, we provide a detailed comparison and discussion of HARQ and RLC ARQ performance in terms of block error rate, spectral efficiency, and latency. This extensive analysis provides valuable insights for researchers and space agencies interested in applying ..."
  },
  {
    "year": "2025",
    "abstract": "The precise identification of the iris centre is essential for numerous applications, such as biometrics, telemedicine, and ocular health diagnostics. This paper presents a novel approach that combines Mediapipe’s keypoint detection for accurate eye area identification with a deep regression framework based on the Xception architecture, specifically aimed at predicting the coordinates and radius of the iris centre. The model utilizes a manually annotated dataset from the Columbia Gaze dataset, incorporating an Xception backbone with three distinct regression outputs to estimate the x and y coordinates of the iris centre and its radius. Comprehensive testing was undertaken to refine critical parameters, such as the depth of the backbone layers, selection of optimizer, and resolution of input images, with training conducted over 200 epochs via the Huber loss function. The optimal configuration—comprising a 130-layer backbone, Adam optimizer, and an input resolution of186×186pixels—produced a mean Euclidean distance (μED) of 0.736 and a standardized Euclidean distance (SED) of 2.208 on the GI4E dataset. Upon evaluation using the BioID dataset, it attainedμEDandSEDscores of 1.560 and 3.045, respectively. The model exhibited near real-time performance, achieving an average frame processing time of 0.056 seconds (about 17.7 frames per second) on a MacBook Air M3. These findings highlight the method’s enhanced efficacy relative to current methodologies, offering an effective and reliable alternative for real-time iris localization and analysis."
  },
  {
    "year": "2025",
    "abstract": "The aim of the paper presented herein is to propose a new mixed integer formulation and an efficient metaheuristic for the Biobjective Cumulative Capacitated Vehicle Routing Problem that incorporates Priority Indexes, an extension of the classical capacitated vehicle routing problem (CCVRP) in which customers are served according to a certain level of preferences by a fixed fleet of heterogeneous vehicles. In this problem, the objectives to minimize consist of (i) the total latency and (ii) the total tardiness of the system. The proposed formulation is based on the multilevel network model for the single objective CCVRP and is implemented via AUGMECON -II. The exact approach proved effective by solving instances of up to 15 nodes in reasonable computational times. In addition, an NSGA-II scheme was designed to deal with larger instances at competitive computational times. This algorithm displayed efficient performance by providing high-quality solutions for instances of up to 100 nodes. Likewise, a comparative analysis was conducted between the proposed approaches and a Particle Swarm Optimization algorithm already presented in the literature. The results indicate the superiority of both of our proposed approaches in providing high-quality Pareto fronts in competitive computational times."
  },
  {
    "year": "2025",
    "abstract": "Embeddings remain the best way to represent image features, but do not always capture all latent information. This is still a problem in representation learning, and computer vision descriptors struggle with precision and accuracy. Improving image embedding with other features is necessary for tasks like image geolocation, especially for indoor scenes where descriptive cues can have less distinctive characteristics. This work proposes a model architecture that integrates image N-dominant colours and colour histogram vectors in different colour spaces with image embedding from deep metric learning and classification perspectives. The results indicate that the integration of colour features improves image embedding, surpassing the performance of using embedding alone. In addition, the classification approach yields higher accuracy compared to deep metric learning methods. Interestingly, different saturation points were observed for image colour-improved embedding features in models and colour spaces. These findings have implications for the design of more robust image geolocation systems, particularly in indoor environments."
  },
  {
    "year": "2025",
    "abstract": "Enterprise Resource Planning (ERP) systems digitize all business processes within companies in order to enhance automation and optimize efficiency. These solutions integrate data and processes across multiple functions such as sales, marketing, finance, supply chain, manufacturing, services, procurement, and human resources, serving as a central repository of information for numerous organizations. ERP systems typically encompass tens of thousands of business processes and manage data across thousands of tables, creating significant opportunities for the integration of Generative Artificial Intelligence (AI) for increasing process automatization and optimization. Nonetheless, embedding Generative AI into ERP solutions is a complex task due to the intricate nature of these systems, which consist of hundreds of millions of lines of code and cater to a wide array of industry-specific and regional requirements. Consequently, the key research question addressed in this paper is: How to systematically develop and operate Generative AI business applications in ERP systems? This article aims to answer this question by conducting a use case analysis, deriving business requirements, designing and implementing a solution framework, and evaluating its effectiveness through real-world ERP use cases."
  },
  {
    "year": "2025",
    "abstract": "People with disabilities face significant barriers in using public transport, limiting their access to healthcare, employment, education, and daily life activities. A comprehensive review of existing research critically identifies these barriers, analyzes efficient interventions, and uses modern technology to create inclusive public transport systems that empower people with disabilities and foster a more equitable society. The current review systematically identifies the key barriers and prospects of disability-inclusive public transportation. It also highlights the policy shortcomings, accessibility gaps, and current technological advancements to foster inclusivity and improve mobility needs for disabled individuals. Searching scientific databases Scopus and Web of Science yielded 1100 articles; 35 met the inclusion criteria. The selected studies were conducted in various countries, emphasizing the topic’s geographical importance. Several studies in the last five years indicated the topic’s growing interest and potential impact. The present study categorized the key barriers into five types: inaccessible infrastructure, information and communication, attitudinal, economic, and safety and security. Case studies from diverse geographical and social settings correlated the barriers with the satisfaction levels of people with disabilities. The case studies highlighted the critical problems disabled people face that should be considered while designing successful transportation systems and travel chains. The study also illustrates the key features of a successful transportation system for disabled people based on best practices adopted worldwide. The prospects of using advanced technology, such as machine learning and modern imagery techniques, are also discussed."
  },
  {
    "year": "2025",
    "abstract": "This study identifies the determinants of cloud computing adoption and its effect on the performance of Sri Lankan small and medium-sized enterprises (SMEs). The Technology-Organization-Environment (TOE) framework, Technology Acceptance Model (TAM), and individual context were used to derive the study variables. This quantitative cross-sectional study adopted items from previous validated studies. Google Form was employed to collect data, and 418 responses were received from Sri Lankan SMEs. Partial Least Squares Structural Equation Modelling (PLS-SEM) via SmartPLS 4 and Artificial Neural Network (ANN) analysis via IBM SPSS 29 were used for data analysis. Based on the results, all hypotheses are confirmed except for one, and SME performance is significantly affected by cloud computing adoption. This study adds to the existing empirical evidence on cloud computing adoption by introducing an all-inclusive model that integrates the TOE, TAM, and individual factors. This demonstrates the effectiveness of the PLS-SEM/ANN hybrid methodology in analysing the determinants of cloud computing adoption. The significance of top management as a factor is highlighted by providing training and education to employees. Managers can benefit from this result by improving cloud computing adoption among SMEs in Sri Lanka. This is the first study of its kind in Sri Lanka, integrating the TOE, TAM, and individual variables and using a hybrid methodology combining PLS-SEM and ANN."
  },
  {
    "year": "2025",
    "abstract": "The landscape of control centre technologies is dynamically adapting to the swift transformations in the physical world, specifically targeting wide-area monitoring, control, and protection in energy systems. In response to these changes, Cyber-Physical Power System (CPPS) has emerged as a promising solution to develop control centre technologies and is gaining significant attention from scholars and researchers with similar interests. However, the widespread adoption of CPPS technology faces several challenges, such as the need for methodologies to develop further CPPS or the detailed deployment of multiple functions within the CPPS framework. To address these challenges, a specialised CPPS testbed within a laboratory environment is presented in this study. In addition, this paper delves into various functions integrated into CPPS, involving critical aspects such as real-time monitoring, digital communication protocol, state estimation, outlier detection, optimal power flow and self-healing capabilities. By implementing a co-simulation platform based on two real-time simulators, Typhoon HIL, the physical and cyber layers can exchange data through Ethernet LAN within the laboratory environment through communication protocols, IEEE C37.118.1 and IEC 61850. This research lays the foundation for a deeper understanding of the potential applications of the CPPS testbed for future control centre technology as well as serves as a catalyst for further innovations, driving a paradigm toward smart, flexible energy infrastructure."
  },
  {
    "year": "2025",
    "abstract": "Tensegrity structures have been utilised in soft robotics due to their flexible and lightweight nature. However, unlike traditional robots, these structures lack joint angles, which makes it challenging to use conventional angle sensors, and thus estimating the posture of the robot remains a challenge. To overcome this, we propose a data-driven approach for posture control of a redundant tensegrity manipulator using inclination angles of all struts, these angles are calculated relative to the gravitational direction. Specifically, we train a simple feedforward neural network (NN) to approximate a mapping from the inclination angles to the control inputs with a conditioning layer-wise averaged pressures. This network acts as a posture controller, mapping the desired inclination angles to the corresponding control inputs with conditioning by average pressure in the layer. The desired inclination angles corresponding to the desired posture can be obtained by demonstrating the robot in a direct teaching manner. We used the tensegrity manipulator consisting of 20 struts and 40 actuators to validate our approach. The experimental results showed that the tensegrity manipulator can reproduce the desired demonstrated postures."
  },
  {
    "year": "2025",
    "abstract": "The Metaverse has rapidly emerged as a transformative technological frontier, accelerated by key events such as the COVID-19 pandemic and Facebook’s rebranding as Meta. However, the factors influencing Generation Y’s adoption of Metaverse services remain underexplored. This study investigates the psychological, motivational, and social drivers shaping Generation Y’s adoption intentions, positioning the Metaverse as a bridge between the pre-digital and post-digital eras. Applying the Decomposed Theory of Planned Behavior, the findings reveal that perceived behavioral control and attitude significantly influence adoption, highlighting the roles of self-efficacy, user confidence, and positive perceptions of the technology. In contrast, subjective norms, central to traditional adoption models, exert no significant effect, suggesting a generational shift toward digital autonomy. Based on a survey of 341 Generation Y respondents in Taiwan, the findings provide practical insights for developers to prioritize user-friendly interfaces, immersive features, and customization options. Marketers are advised to leverage influencer-driven strategies and personalized digital interactions. The research contributes to theoretical advancements by challenging established models, such as the Unified Theory of Acceptance and Use of Technology, and calls for further research on cross-cultural differences and digital communities."
  },
  {
    "year": "2025",
    "abstract": "The coordination of directional overcurrent relays (DOCRs) plays a critical role in ensuring the reliability and robustness of modern electrical power protection systems. Achieving optimal relay coordination in multi-loop power networks is a complex optimization challenge requiring the minimization of relay operating times and achieve optimal tuning of time dial settings (TDS) and plug settings (PS) while considering the impact of DG integration. The proposed method employs a Quantum-Inspired Adaptive Walrus Optimization Algorithm (QIAWOA), a modified swarm-based artificial intelligence technique (AI) that incorporate rates quantum-inspired principles, such as adaptive quantum rotation gates, to enhance search dynamics and facilitate precise relay coordination. The performance of QIAWOA is validated using the IEEE 3, 8, and 15-bus systems, as well as the CEC 2020 benchmark suite, which includes multimodal and multi-objective optimization functions (MMOOF). QIAWOA demonstrates superior capabilities in identifying globally optimal solutions, significantly reducing relay operating times, and achieving robust coordination. Comprehensive statistical analyses, including empirical cumulative distribution functions (CDF), boxplots, histograms, probability plots, and quantile-quantile (QQ) plots, underscore the reliability and efficiency of the proposed method. Comparative evaluations with state-of-the-art nature-inspired techniques further highlight the enhanced performance of QIAWOA, establishing it as a powerful tool for improving the protection system performance in complex power networks."
  },
  {
    "year": "2025",
    "abstract": "The ability to reconstruct acoustic field is essential for applications such as particle manipulation, medical therapy, and ultrasonic imaging. Conventional acoustic field reconstruction algorithms are limited in both speed and accuracy when generating acoustic holograms, which further constrains the practical applications of acoustic holography. In this study, we propose an acoustic field reconstruction method that achieves both speed and accuracy by leveraging an acoustic model tailored for diffraction. A unit transducer is integrated with an acoustic lens, utilizing lens thickness and acoustic velocity variations to produce accurate phase maps at specific frequencies. To reduce the dependence on labeled datasets, we propose a deep learning framework with an autoencoder structure for unsupervised training without relying on any a priori information. Additionally, a novel loss function is designed for the framework to realize the energy efficiency constraint. The proposed method is compared with traditional Angular Spectrum Method (ASM) and Automatic Differentiation (Diff-PAT). Experimental results show that the Peak Signal-to-Noise Ratio (PSNR) of this method reaches 21.59, which is 24.1% higher than that of ASM and 19.2% higher than that of Diff-PAT. After network training, the proposed method generates phase holograms hundreds of times faster than ASM and Diff-PAT. Under the same network architecture, our newly designed loss function improves energy efficiency to 2.1 times that of the original method."
  },
  {
    "year": "2025",
    "abstract": "Parkinson’s Disease (PD) is a neurodegenerative disorder that requires correct diagnosis and continuous monitoring of the disease severity. The state-of-the-art methods tend to be unimodal or lack robustness in generalizing between modalities, and hence cannot be applied clinically in diverse populations. A comprehensive approach is a multi-modal framework that overcomes these limitations by integration of brain Magnetic Resonance Imaging (MRI) data, gait analysis, and speech signals for enhanced classification and severity estimation of PD. A Hierarchical Attention-based Multi-modal Fusion (HAMF) model is developed in this paper to employ hierarchical attention mechanism at feature and decision levels to help the model learn representations at various levels. This leads to richer feature extraction, besides fusing different data modalities with accurate integration. Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) methods are used in optimizing the model, by which the convergence speed raised by 15–20 %. An accuracy of 94.2 % was achieved, thus improving by 4–5 %, compared to the existing methodologies. Temporal Convolutional Network (TCN) which can capture long-range temporal dependencies, was used in the longitudinal severity estimation task, achieving a Mean Squared Error (MSE) of 0.12 in disease progression forecasting. Beyond this, Domain-Adversarial Neural Network (DANN) enables improved cross-domain generalization and maintains a consistent classification accuracy of 90-93% on diversified datasets. Finally, SHapley Additive exPlanations - Class Activation Maps (SHAP-CAM) further enhanced the model explainability. During the conduct of this work, 85% of all cases provided clinically interpretable insights that allowed clinicians to conduct personalized treatment planning in a more robust and interpretable way. This work substantially extends current multi-modal diagnosis and analysis of PD progression by offering a robust and interpretable tool to..."
  },
  {
    "year": "2025",
    "abstract": "Steam boilers present complex control challenges due to their nonlinear dynamics and fluctuating load conditions. This study proposes a novel hybrid adaptive control framework that significantly enhances system performance by synergizing off-policy deep reinforcement learning, model reference adaptive control (MRAC), and optimized PID control through a weighted fusion strategy. Three innovative hybrid controllers, Weighted-Fusion-DDPG-MRAC-PID, Weighted-Fusion-TD3-MRAC-PID, and Weighted-Fusion-SAC-MRAC-PID, are developed and rigorously benchmarked against standalone MRAC and optimized PID for precise steam flow and drum pressure regulation in a two-state boiler system under four diverse operational conditions. The adaptive fusion mechanism dynamically modulates control actions (feedwater flow and applied heat) in response to system variations, ensuring superior stability. Furthermore, a novel nonlinear settling time algorithm is introduced to accurately assess transient responses in complex signals, addressing the limitations of conventional methods. Extensive experimental validation confirms the superiority of hybrid controllers, achieving significantly faster settling times, peak overshoot reductions to(≤2%), and lower error metrics than MRAC alone. While optimized PID serves as a baseline, hybrid controllers consistently achieve faster settling times and improved robustness under most nonlinear operating conditions. Weighted Fusion-DDPG-MRAC-PID offers the best trade-off between performance and computational efficiency. These findings underscore the practical flexibility of the proposed framework for advanced steam boiler control."
  },
  {
    "year": "2025",
    "abstract": "Ship hull inspection is crucial for assessment of hull damage, biological fouling, and for detection of foreign objects (mines, illegal drug packages, etc.). These inspections require advanced planning, long periods of time, resources (people, facilities, equipment), and cost (time and money) to conduct. With this in mind, the purpose of this review is to provide an assessment of the state of the art technologies and techniques for ship hull inspection; identifying the key challenges and the directions for further research and development. This review first discusses platform types for inspection and imaging types, this discussion proposes that ship hull inspection could be completed quicker by using multiple imaging nodes, it also proposes that inspection complexity and resource could be reduced through use of autonomous vehicles. These proposals are the basis for the next sections of review where localization techniques and methods for node organization to achieve full coverage of the vessel being imaged become the focus. The review identifies that current techniques could be utilized, however require adaption and combination together for this specific use case. The conclusions from this review lead into what future research directions are required, focusing around the localization and organization issues."
  },
  {
    "year": "2025",
    "abstract": "In lighting projects, cost and energy consumption are often the primary selection criteria for LED lamps. However, additional technical factors such as electromagnetic emissions, harmonic current emissions, overvoltage susceptibility, visual flicker and photometric performance are crucial for ensuring system reliability and long-term regulatory compliance. Ignoring these factors results into power quality issues, electromagnetic interference, flicker, biological hazards and reduced lamp lifespan- particularly in commercial and hospitality environments where lighting operates extensively. This study introduces a comprehensive evaluation framework that extends beyond cost and energy efficiency, incorporating in a versatile and scalable manner technical performance criteria into the selection process. Within a market surveillance study, ten commercially available LED lamps were assessed through measurements and tests in an accredited laboratory. While all tested lamps currently meet harmonized Standards, a large number would exceed the stricter harmonic current limits of EN IEC 61000-3-2 (2019), once harmonized. A weight-based ranking methodology addressing installation-specific requirements is proposed as a tool for identifying the optimum lighting solution. The results showcase that the best performing lamps are not necessarily the most expensive. Additionally, the study explores various electrical environments and lighting scenarios in relation to key UN Sustainable Development Goals 1, 3, 7, 9, 11, 13, 15 and 17."
  },
  {
    "year": "2025",
    "abstract": "This work focuses on the design of a solar-powered wire-traversing robot for environmental monitoring in remote areas, where solar power harvesting ensures continuous operation without frequent external charging. This paper presents an integrated power electronics design, emphasizing system-level considerations for efficient energy management and enhanced battery life, extending operational time and reliability. Experimental results showed the RaccoonBot could dynamically locate maximum solar exposure with 0.134[mm] resolution, maintain up to 7.5[W] of charging power, and consume just 0.025[A] in standby. These features, combined with the bio-inspired solar-tracking features and fail-safe design, enable over a week of autonomous operation, extending runtime from 5 hours to weeks. The findings validate the V-model’s effectiveness in creating efficient, reliable systems, demonstrated by the RaccoonBot for environmental monitoring."
  },
  {
    "year": "2025",
    "abstract": "Computed tomography (CT) is essential for diagnosing and managing various diseases, with contrast-enhanced CT (CECT) offering higher contrast images following contrast agent injection. Nevertheless, the usage of contrast agents may cause side effects. Therefore, achieving high-contrast CT images without the need for contrast agent injection is highly desirable. The main contributions of this paper are as follows: 1) We designed a GAN-guided CNN-Transformer aggregation network called GCTANet for the CECT image synthesis task. We propose a CNN-Transformer Selective Fusion Module (CTSFM) to fully exploit the interaction between local and global information for CECT image synthesis. 2) We propose a two-stage training strategy. We first train a non-contrast CT (NCCT) image synthesis model to deal with the misalignment between NCCT and CECT images. Then we trained GCTANet to predict real CECT images using synthetic NCCT images. 3) A multi-scale Patch hybrid attention block (MSPHAB) was proposed to obtain enhanced feature representations. MSPHAB consists of spatial self-attention and channel self-attention in parallel. We also propose a spatial channel information interaction module (SCIM) to fully fuse the two kinds of self-attention information to obtain a strong representation ability. We evaluated GCTANet on two private datasets and one public dataset. On the neck dataset, the PSNR and SSIM achieved were35.46±2.783dB and0.970±0.020, respectively; on the abdominal dataset,25.75±5.153dB and0.827±0.073, respectively; and on the MRI-CT dataset,29.61±1.789dB and0.917±0.032, respectively. In particular, in the area around the heart, where obvious movements and disturbances were unavoidable due to the heartbeat and breathing, GCTANet still successfully synthesized high-contrast coronary arteries, demonstrating its potential for assisting in coronary artery disease diagnosis. The results demonstrate that GCTANet outperforms ex..."
  },
  {
    "year": "2025",
    "abstract": "As the development of electric vertical takeoff and landing (eVTOL) aircraft rapidly progresses, efficient, lightweight, and high-torque-density drive motors have emerged as a critical technology. This study focuses on designing a drive motor suitable for eVTOLs, emphasizing improvements in torque density and efficiency to meet the needs of urban low-altitude operations. In response to the impact of winding cross-sectional area changes during motor optimization design, we have developed a design method for permanent magnet synchronous motors based on fixed current density, and analyzed the optimal main dimensions, air gap length, and magnet thickness of the motor. Additionally, the enhancement effects of Halbach magnets and a 30-degree phase shift arrangement on motor performance were examined. To address the strong coupling issue of stator structural parameters, a multi-objective optimization algorithm was introduced to achieve a balance between high torque density and high efficiency. The optimization results were validated through finite element simulation, with the motor’s torque density and efficiency reaching 56.5 N⋅m/kg and 93.5%, respectively. Further experimental results indicate that the prototype’s torque density is 55 N⋅m/kg with a peak efficiency of 92.5%, confirming the effectiveness and reliability of the optimized design. Moreover, simulations of a single set of three-phase winding fault conditions demonstrate the motor’s excellent fault tolerance. This research provides innovative design approaches for the efficiency and lightweighting of eVTOL motors, offering broad application prospects."
  },
  {
    "year": "2025",
    "abstract": "A common AC and DC ground bridgeless power converter topology is presented that performs the near-unity power factor function with low harmonic distortion of a single-phase rectifier with sinusoidal input line voltage. The operation principle and design-oriented analysis are presented, along with the transfer functions and closed-loop input current control strategy. A non-optimized experimental prototype was developed and tested in the laboratory to validate the operating principle and the results of theoretical analysis. The distinctive feature of the proposed rectifier is that it eliminates the leakage current that circulates through the parasitic capacitances existing between the power semiconductor and heatsink, which causes common-mode electromagnetic interference in conventional boost-based PFC rectifiers."
  },
  {
    "year": "2025",
    "abstract": "Edge computing-based image recognition applications face significant challenges, including increased latency and network load when transmitting large volumes of images to edge servers. To address these issues, this study proposes a novel solution that involves sending compressed data from a front-end device over a network and subsequently reconstructing the images on the server side for recognition purposes. The proposed framework places the image recognition model directly after the image reconstruction model. The reconstruction model is based on a recurrent neural network, and ResNet-18 is used for recognition. This reduction in image quality results in lower recognition performance when using reconstructed images compared with original images. To mitigate this issue, we propose an end-to-end learning framework that jointly optimizes image reconstruction and recognition, specifically optimizing the reconstruction model for the recognition task. The proposed method achieves approximately 99% data compression without degrading classification performance. It improves image quality by 2.1 dB and classification accuracy by 11.2% over the baseline. The proposed method not only significantly improves the quality of reconstructed images without any loss in the image compression rate but also enhances the classification accuracy of these images."
  },
  {
    "year": "2025",
    "abstract": "Segmenting individual trees from airborne LiDAR point cloud data is critical for forest management, urban planning, and ecological monitoring but remains challenging due to complex natural environments, diverse tree architectures, and dense canopies. Traditional supervised methods rely on extensive, manually annotated datasets that are often impractical to obtain. In this study, we propose a novel self-supervised learning framework that eliminates the need for manual labeling by integrating transformation-invariant feature extraction, an energy-based segmentation loss, and soft clustering. The framework operates in two stages: a pretext task applies geometric transformations—rotation (from –45° to +45°), translation (between –1 and 1 units), and scaling (between 0.5 and 2.0)—to learn robust features, while an unsupervised segmentation step leverages an energy function that combines height, density, and slope attributes to cluster points corresponding to individual trees. We evaluated our approach on a high-density LiDAR dataset acquired from the Estonian Land Board (LAS format, version 1.4) comprising over 850,000 points. Our method achieves up to 87% convexity, 78% solidity, and an elliptical fit error as low as 0.12, substantially reducing over-segmentation compared to baseline clustering techniques. These results demonstrate that our self-supervised framework offers a scalable, label-free solution for precise tree segmentation, with significant advantages in accuracy and efficiency over traditional supervised methods."
  },
  {
    "year": "2025",
    "abstract": "The automatic detection of pedestrian heads in crowded environments is essential for crowd analysis and management tasks, particularly in high-risk settings such as high dense railway platforms and event entrances. These environments, characterized by dense crowds and dynamic movements, are underrepresented in public datasets, posing challenges for existing deep learning models. To address this gap, we introduce the Railway Platforms and Event Entrances-Heads (RPEE-Heads) dataset, a novel, diverse, high-resolution, and accurately annotated resource. It includes 109,913 annotated pedestrian heads across 1,886 images from 66 video recordings, with an average of 56.2 heads per image. Annotations include bounding boxes for visible head regions. In addition to introducing the RPEE-Heads dataset, this paper evaluates eight state-of-the-art object detection algorithms using the dataset and analyzes the impact of head size on detection accuracy. The experimental results show that You Only Look Once v9 and Real-Time Detection Transformer outperform the other algorithms, achieving mean average precisions of 90.7% and 90.8%, with inference times of 11 and 14 milliseconds, respectively. Moreover, the findings underscore the need for specialized datasets like RPEE-Heads for training and evaluating accurate models for head detection in railway platforms and event entrances. The dataset and pretrained models are available athttps://doi.org/10.34735/ped.2024.2."
  },
  {
    "year": "2025",
    "abstract": "Various robot arms have been introduced in factories, and their control is facilitated by numerous cables, which can have drawbacks such as limiting the arm’s range of motion. Therefore, wireless control of motors is desirable. This study proposed a wireless relay method for controlling all motors with low latency, even in an environment with poor propagation. Packet error rates (PERs) of wireless communication between a central controller outside a robot arm frame and a wireless module inside the robot arm frame were evaluated, revealing that some angles of the robot arm frame resulted in markedly higher PERs. When each motor is controlled via its own wireless module, all the wireless modules must communicate with a central controller having low latency. To resolve this problem, some wireless modules relay control signals to the poorest-performing wireless module while others relay the state signals of the poorest-performing wireless module to the central controller. State signals include the encoder value of the motor. Low-latency relay is achieved by regulating the timing of transmission for each wireless module. This paper assumes that the central controller must control the robot arm in a closed loop with a response time within a control cycle of 10 ms. When using the proposed method for six axes with wireless LAN, the response time was less than 10 ms. Furthermore, the proposed method reduced the maximum value of the overshoot by a factor of around 15 compared with the method without using any relay."
  },
  {
    "year": "2025",
    "abstract": "Beyond Visual Range (BVR) air combat is an essential part of modern aerial warfare, relying on advanced radar, missile systems, and decision-support technologies. This survey provides a comprehensive overview of how simulation and Machine Learning (ML) tools have been used to analyze BVR combat, covering key methodologies, applications, and challenges. We examine how ML enables adaptive tactics to improve behavior recognition and threat assessment to enhance situational awareness. The paper also traces the historical evolution of BVR combat, outlining key engagement phases such as detection, missile launch, and post-engagement assessment. A key focus is on the role of simulation environments in modeling realistic combat scenarios, supporting pilot training, and validating AI-driven decision-making strategies. We analyze state-of-the-art simulation tools, comparing their capabilities and limitations for studying multi-agent coordination and real-time adaptability. This survey’s main contributions include descriptions of ML applications in BVR air combat, evaluations of simulation tools, identifications of research gaps, and insights into future research directions. This work provides an overview of how traditional simulation approaches merge with artificial intelligence to enable advanced, effective human and autonomous decision-making systems in dynamic and contested environments."
  },
  {
    "year": "2025",
    "abstract": "Lithium-ion batteries play a pivotal role in enabling eco-friendly mobility, particularly in electric vehicles, but optimizing their charging process to improve battery lifespan, safety, and overall efficiency remains a significant challenge. Traditional predictive control methods are limited by their reliance on precise models, which are often hindered by uncertainties in battery parameters due to aging, production variability, and operational conditions. While stochastic predictive control policies can address these uncertainties by incorporating them directly into the optimization process, they typically introduce considerable computational complexity. In response to this challenge, this paper presents a novel approach that adapts imitation learning to efficiently approximate stochastic predictive control strategies, thus significantly reducing the computational burden through offline training. Specifically, the proposed method leverages the Dataset Aggregation algorithm to overcome the issue of distributional shift, a common limitation in imitation learning frameworks. Simulations based on a detailed electrochemical model demonstrate the effectiveness of the method, adhering to probabilistic constraints while offering a scalable and computationally efficient solution for advanced battery management systems."
  },
  {
    "year": "2025",
    "abstract": "Translating spoken speech in videos from one language to another is known as audio-visual translation (AVT). This paper describes the implementation of an automated AVT and lip-synced dubbing application. It addresses the difficulty of synchronizing mouth movements with translated speech by building a web application that synthesizes the speaker’s lip movements to match translated audio. Using ASR models, the speech from the source video is converted to text, translated into several languages, and then automatically synthesized into speech in the target language. A lip synchronization model, Wav2Lip, is used to alter the mouth movements in the video to correspond to the target language. We compare our work with two well-known ASR systems: Wav2vec 2.0 and Google Speech Recognition. Wav2vec 2.0 performs better with the lesser average WER% of 15.38 and is used in our final web application. The performance of the video dubbing component is discussed with the generated speech in Tamil, Telugu, Hindi, and English, and we determine that our generated videos outperform the existing ones. Our proposed AVT application is user-friendly for a wide variety of speakers, utilizing readily available TTS systems instead of training on an individual speaker’s voice."
  },
  {
    "year": "2025",
    "abstract": "Mobile IoT networks face major problems in completing efficient task offloading and allocating resources effectively, as all major actions require ample energy consumption and service delays. This paper proposes a solution in the form of a reinforcement learning-based framework that is capable of dynamically optimizing these activities with the help of Group Relative Policy Optimization (GRPO). The new method outcompetes traditional heuristic-nometric methods by being able to adjust device inactivity, network activity, and available resources. Devices are structured into mobility groups and task offloading is defined as Markov Decision Process (MDP). An ample amount of offloading strategies can be obtained by introducing declaration of tasks and corresponding computers, network throughput, and queueing delays. Additionally, GRPO aids in the allocation of computing power, network bandwidth, or storage to maximize resource allocation without breaking task deadlines and other resource limitations. Comparing the GRPO-based method to traditional methods via simulation showed increased performance and reduced service delay. The results clearly demonstrate that GRPO helps reduce service delay and consumption of energy significantly in high load with high dynamism conditions. With the inclusion of decision-making processes along with constraint-tolerance and reinforcement learning, this research aids in IoT frameworks that require low energy output with less delay. The recommended method helps build a strong base for efficient task delegation alongside increased performance and scalability, which subsequently enhances AI edge computing and smart management of IoT systems."
  },
  {
    "year": "2025",
    "abstract": "Model-based sensorless control, which estimates the position and speed of a motor via mathematical analysis, has been studied using various methods because of its simple formula and adequate performance without additional power consumption. Model-based sensorless control estimates the position and speed of an actual motor by interpreting the error between the values calculated by the observer and obtaining the data from the actual motor as an error due to position and speed. Motor parameters can vary depending on temperature and current. This creates additional errors by the observer, which results in a reduction in sensorless estimation performance. To solve these problems, an online parameter estimation method using the recursive least squares (RLS) algorithm or by creating a parameter lookup table through experiments has been studied. However, these approaches have the disadvantage of requiring overly complex formulas or excessive time and effort. In this paper, we propose a new adjustable model that includes parameter errors and adopt a sensorless method that compensates for additional parameter errors via funnel control. This method is more accurate and stable than the existing methods when parameter errors exist. The stability criterion of the algorithm is based on the theory of hyperstability in nonlinear feedback systems. The effectiveness and verification of the proposed algorithm are achieved through simulations and experiments in MATLAB."
  },
  {
    "year": "2025",
    "abstract": "Early warning for learning performance requires to identify the maximum number of at-risk students as early as possible within a semester. However, educational data often suffer from the issue of data imbalance, making it challenging to simultaneously achieve both high precision (accurate identification) and high recall (comprehensive coverage) in at-risk student detection. Deep generative models and oversampling models are effective methods to solve data imbalance issues, which can improve classification performance. This paper proposes a method that combines the advantages of deep generative models and oversampling models to build a blending model for dealing with imbalanced educational data, which can effectively improve the precision, recall, F1-score and AUC for online learning early warning. First, we compare baseline models to select the best classifier, then choose the highest-precision deep generative model and the highest-recall oversampling model to construct blending models, which are shown to improve early warning prediction metrics. Finally, interpretable models are used to analyze differences in at-risk student prediction between the blending model, deep generative model, and oversampling model. The proposed models are validated on both extremely imbalanced datasets and new semester datasets. Results show that: (1) Compared to the baseline model, both the base learners built by the deep generative model and the oversampling model can improve the evaluation metrics of the model, the deep generative base learners achieve higher precision than the oversampling model, while the oversampling base learners achieve higher recall than the deep generative base learners. (2) The blending model composed of deep generative base learner and oversampling base learner can further improve the F1-score and AUC based on their individual strengths, the proposed blending model can also conduct effective early warning three units earlier than baseline models. (3) Compared..."
  },
  {
    "year": "2025",
    "abstract": "The increasing reliance on deep models as black-box solutions raises critical concerns, particularly in media forensics, where explainability and robustness are essential. These models often fail to address biases in experimental design, potentially yielding misleading conclusions. To combat these risks, we advocate for rigorous hypothesis-driven methodologies that define and test competing explanatory hypotheses to reduce biases and improve reliability. We present a case study on device identification, focusing on a method proposed by Manisha et al., which claims exceptional performance using a hybrid ResNet101-SVM classifier. Our investigation reveals that this performance is likely attributable to dataset biases rather than true device-specific fingerprints. To systematically decouple content- and device-specific features, we introduce a novel “Sybil” approach, which partitions datasets based on image content. Our Sybil experiments strongly suggest that the classifier exploits content-specific biases, rather than intrinsic device fingerprints, to achieve high accuracy. We demonstrate that even datasets like FloreView, which are carefully crafted to limit biases due to the acquisition, are not immune to these biases. This analysis highlights the dangers of black-box methodologies and highlights the necessity of hypothesis-driven experimental designs in media forensics."
  },
  {
    "year": "2025",
    "abstract": "The integration of smart devices and advanced communication infrastructure has turned power systems into cyber-physical systems (CPS), introducing cyber vulnerabilities. One such vulnerability arises from the use of the address resolution protocol (ARP), which is commonly employed in power systems’ information technology (IT) infrastructure to assign internet protocol (IP) addresses to devices such as relays, controllers, and meters. Due to the lack of authentication in ARP, attackers can exploit it to infiltrate substation automation systems (SAS). To detect and locate ARP spoofing attacks, a novel network intrusion detection system (NIDS) was developed using Snort3, TShark, and Python scripts to monitor ARP broadcast messages. This detection method was tested on a dedicated, real-time multi-agent CPS testbed, where a microgrid is simulated as the physical layer using a real-time digital simulator (RTDS), while the cyber layer consists of a multi-agent control implemented in a graphical network simulator (GNS3) together with Raspberry Pi devices. The real-time operator’s view is developed in Grafana visualization, mimicking the real-world microgrid operation. Two common practical ARP attacks, known as man-in-the-middle (MITM) and false data injection (FDI) attacks, were conducted to evaluate the performance of the proposed NIDS method. Both MITM and FDI attacks were implemented using IT network testing tools, such as Ettercap and the Scapy library in Python. The results have shown that the proposed NIDS system can detect, localize, and publish the IP address of the attacker in both MITM and FDI attack scenarios. In addition, the impact analysis results indicated that for an identical malicious payload, the FDI attack is more severe when compared to MITM due to the intermittent nature of false data injection."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a novel load balancing algorithm tailored for deeply programmable networks, offering a decentralized approach to optimizing packet forwarding and load distribution. Unlike conventional systems reliant on centralized controllers or manual configurations, this algorithm operates entirely within the data plane, leveraging controlled flooding to dynamically discover and reroute traffic based on real-time congestion data. By detecting latency spikes indicative of congestion, switches autonomously select alternative paths to maintain optimal traffic flow. Implemented in the P4 data plane programming language, the algorithm is rigorously evaluated against existing load balancing methods for self-organized networks. The results demonstrate significant reductions in data transmission times, improved path symmetry, and enhanced scalability under various network conditions, making it a robust solution for modern, self-organized, and high-performance networks."
  },
  {
    "year": "2025",
    "abstract": "The lane-keeping assistance system (LKAS) is one of the core functions of advanced driver assistance systems (ADAS) that prevents unintended lane departures. LKAS widely utilizes shared steering control, in which both the driver and the vehicle controller share lane-keeping control by integrating the driver into the control loop. The shared control approach can be formulated as a multi-objective optimization problem that optimizes between maintaining driver control and reducing driving burden, while preventing unintended lane departures. A model predictive control (MPC)-based method effectively can address multi-objective optimization problems in shared control. In addition, it provides the advantage of switching the operational mode by adjusting the weights in the cost function according to assessed risk. However, an abrupt transition between operational modes can cause unstable motion such as severe lateral jerk or hysteresis, resulting in driver discomfort. To address this issue, we propose a shared control framework that ensures smooth transitions between operational modes by applying a softly switched MPC method, in which the weights are modulated over the prediction horizon. Unlike existing approaches, the proposed method with the soft-switching scheme could enhance path-tracking accuracy, maintain steering stability, and suppress unstable lateral motion while improving driver comfort during switching between operational modes. Simulation experiments with various maneuvers and road curvatures demonstrated that the proposed framework could substantially suppress unstable lateral motion during mode transitions, even in severe cases, while complying with safety regulations."
  },
  {
    "year": "2025",
    "abstract": "Disease detection from leaf images has been among the popular studies in recent years. Classifying leaf diseases using computational methods provides great convenience for farming. In the studies carried out in this field, systems that work with high accuracy and are least affected by environmental factors that can be used in agricultural lands come to the fore. This study investigates the application of deep learning architectures for accurate and efficient plant disease detection within the context of the ongoing digital transformation of the agricultural sector. Recognizing the critical role of AI in modernizing agriculture, this research focuses on enhancing the accuracy of the classification of plant diseases. To facilitate this research, a novel dataset, “EruCauliflowerDB”, was meticulously curated, comprising high-resolution images of cauliflower plants infected with Alternaria Leaf Spot and Black Rot. The obtained EruCauliflower dataset contains 114 images from the Alternaria Leaf Spot disease class and 99 images from the Black Rot disease class. A novel integrated classification system was developed, encompassing three key stages. First, a novel segmentation method, “BorB,” was introduced to effectively isolate diseased leaf regions. This segmentation method enables us to extract features of leaf images in Lab and RGB formats. Combining the features obtained from the two image formats with the OR logical operation separates the leaf region from the background. Second, data augmentation techniques, including geometric transformations, were applied to the segmented images to enhance data diversity and improve model robustness. Finally, four state-of-the-art deep learning models—VGG16, ResNet50, EfficientNetB3, and MobileNetV3 Large—were employed for disease classification. The proposed integrated system demonstrated exceptional performance, achieving 100% classification accuracy on the EruCauliflowerDB dataset across all four models. To assess the system’s ro..."
  },
  {
    "year": "2025",
    "abstract": "Patrol robots in hospital wards are expected not only to ensure the safety of their movements, but also to perform gait measurement as part of their monitoring functions. In this study, we present a system that enables a patrol robot to perform a 5-meter walk test (5mWT) on passing pedestrians in a corridor. The pedestrian’s position and velocity are measured sequentially, and the robot’s trajectory is generated based on the results using a nonlinear programming method, followed by Model Predictive Control tracking. This allows for adaptive gait measurement during passing interactions, taking into account arbitrary pedestrian trajectories. Furthermore, a parameter estimation method tailored to the characteristics of the acquired data, namely whole-body, continuous and multi-view measurements, is proposed. Through simulation and experiments, we confirmed the feasibility of the measurement operation and accuracy of the derived gait parameters. The proposed method can not only be used anywhere, but also measure gait over a long distance with high accuracy using a single sensor. Moreover, it could contribute to the realization of gait measurement without pedestrian’s tension."
  },
  {
    "year": "2025",
    "abstract": "Identifying asphyxia using computer vision in real-world settings poses challenges due to varying video quality, diverse lighting conditions, and subtle color changes in the newborn’s skin. This study presents an end-to-end framework for automated neonatal asphyxia detection using time series video analysis and makes three key contributions. First, the proposed framework integrates YOLOv8-based instance segmentation with advanced feature extraction across multiple color spaces and texture analysis to detect neonatal asphyxia through the multi-modal analysis of skin features in video streams. Second, we introduce a new quality-aware temporal analysis framework that includes adaptive quality assessment for evaluating frames in real time, multi-stage feature stability tracking across temporal windows, hysteresis-based decision logic for ensuring temporal consistency, and LightGBM classification with comprehensive feature engineering to assess severity. Third, we provide a curated time series video dataset of 12,973 frames from 45 neonates, of which some were healthy, and some had asphyxia of varying severity. The findings show that the YOLOv8-based instance segmentation achieved a mean average precision (mAP@0.5) of 0.925 for accurate skin region isolation, and the LightGBM classifier outperformed traditional models with an accuracy of 0.998 and an F1-score of 0.998. The system maintains real-time processing at 30 FPS for normal and mild asphyxia cases with a minor reduction to 20 FPS in more challenging scenarios and exhibits robust temporal stability across severity levels, with consistency scores above 0.90. This framework has the potential to enhance neonatal care through continuous monitoring and timely intervention."
  },
  {
    "year": "2025",
    "abstract": "The rapid spread of false information on social media has become a major challenge in today’s digital world. This has created a need for an effective rumor detection system that can identify and control the spread of false information in real-time. The proposed work introduces a rumor detection system by integrating transformer-based models such as BERT, DistilBERT, and TinyBERT with traditional Machine Learning (ML) techniques. The classifiers include Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF) and Naïve Bayes (NB) help in categorizing content as either rumor or non-rumor based on the patterns. The proposed work evaluated BERT, DistilBERT, TinyBERT combined with ML models (SVM, DT, RF, NB) across PHEME dataset using 70:30, 60:40, and 80:20 splits. Overall, BERT + DT and TinyBERT + SVM provided significant results, with BERT + RF and DistilBERT + NB demonstrating better classification capabilities across various events and split ratios on the dataset."
  },
  {
    "year": "2025",
    "abstract": "Arabic nouns can be marked for definiteness or indefiniteness. The definite article is the prefix “Al-,” which confines the determiner class to a single element “Al-.” This topic is generally discussed under noun inflections, such as Gender, Number, Definiteness, and Case (GNDC), in grammar textbooks. The primary aim of this paper is to expand the Arabic determiner class (DET) by incorporating additional lexical items and providing a detailed description of their syntactic context within noun phrases (NPs). In traditional grammar, these lexical items are typically classified as noun adjectives and, at best, are referred to as noun specifiers since they modify the head noun. However, these “nouns” exhibit limited inflection compared to regular adjectives and occupy a specific position within the NP sequence. Additionally, the modified head nouns are constrained in their inflectional attributes, Number, and Definiteness. Our approach is qualitative and guided by morpho-syntactic considerations. We conduct an in-depth analysis of the grammatical features of ten lexical items, focusing particularly on the dependencies between the determiner and the following noun. This analysis also addresses some semantic properties. By focusing on context-sensitive grammatical rules, the study shows how these methods can enhance precision in parsing and reduce ambiguity in NLP tasks, highlighting the potential for developing more refined grammar for Arabic. This work is a prototype for comprehensive studies in linguistics and NLP."
  },
  {
    "year": "2025",
    "abstract": "Agile software engineering emphasizes collaboration, adaptability, and team cohesion, where Leadership and interpersonal dynamics are critical for project success. Emotional Intelligence (EI), the ability to recognize, understand, and manage emotions, has been theorized to enhance communication, conflict resolution, and team performance in Agile environments. However, empirical evidence on its direct and mediated impacts remains underexplored. This study examines how EI influences leadership effectiveness and team dynamics in Agile software projects, focusing on quantifying these relationships to inform actionable strategies. A quantitative approach was employed, utilizing structured surveys from 51 Agile professionals (Scrum Masters, developers, and product owners) actively engaged in frameworks such as Scrum, Kanban, and Extreme Programming (XP). Validated instruments—the Emotional Intelligence Scale (EIS), Multifactor Leadership Questionnaire (MLQ), and Team Climate Inventory (TCI) measured EI competencies, leadership behaviors, and team dynamics. Data were analyzed using correlation, regression, and mediation analyses. Results revealed significant positive correlations between EI and leadership effectiveness (r=0.504, p<0.01) and EI and team dynamics (r=0.434, p<0.01). Mediation analysis demonstrated that leadership effectiveness fully mediates the relationship between EI and team outcomes (β=0.290, p<0.01), highlighting the pivotal role of emotionally intelligent leaders in fostering trust and adaptability. Teams led by individuals with high EI reported a 20% increase in trust and marked improvements in collaboration and decision-making. These findings underscore EI as a critical catalyst for Agile success. Organizations are urged to prioritize EI development through targeted leadership training programs and integrate Digital Emotional Intelligence (DEQ) tools (Zoom and Microsoft Teams) to bridge emotional gaps in distributed teams. This study provides..."
  },
  {
    "year": "2025",
    "abstract": "The reasonable scheduling of production processes in polymetallic mines is crucial for comprehensively utilizing mineral resources and ensuring economic benefits. The simultaneous mining of high- and low-grade ores, scientific ore transportation, and reasonable ore blending are prerequisites for stable polymetallic beneficiation and guaranteed concentrate quality. Therefore, establishing an optimization model for this problem and designing algorithms to solve it have great significance in the theory of optimization algorithms and in production practices for polymetallic mining enterprises. Based on the production processes of polymetallic mines, this paper establishes a two-stage optimization model for mining, ore transportation, and ore blending production scheduling considering the vehicle routing problem in a truck transportation process. An improved imperialist competition algorithm is designed to solve the vehicle routing problem for the second stage model. The computational results show that the proposed algorithm reduces ore transportation costs by no less than 0.83% compared to other algorithms, which translates to an annual cost saving of at least 100,000 yuan for the mining enterprise of this case study. By solving the model, the Pareto front between unit cost and total grade fluctuation in the entire production process, as well as the rules for making decisions on production scheduling schemes, are obtained. The relevant numerical results of the production scheduling scheme corresponding to the “inflection point” on the final Pareto front are also provided."
  },
  {
    "year": "2025",
    "abstract": "This paper presents the development and evaluation of a calibration methodology for pressure-resistive sensors, implemented within a specialised diagnostic laboratory. The approach utilises algorithmic correction, structured measurement routines, and real-time signal processing to perform sensor calibration exclusively at the software level, without requiring hardware intervention. A custom sensor profiling framework has been designed to enable precise analysis of sensor characteristics, degradation, and long-term behaviour. The calibration algorithm employs mathematical interpolation and dataset synchronisation techniques to enhance accuracy and reduce measurement uncertainty. Experimental validation demonstrated a reduction in average deviation from 18.1% to 1.1%, with an overall tolerance range of just 2.6%. These results confirm the effectiveness of the proposed methodology in improving sensor precision and stability. The system is particularly suited for industrial environments where reliable pressure sensing is essential for safety, efficiency, and predictive maintenance."
  },
  {
    "year": "2025",
    "abstract": "A novel visualization method for interpreting the resultant design from topology optimization (TO) is proposed. We employ a pre-trained deep learning (DL) model to predict the degree of influence of transitions from air to magnetic materials, and build an interpretable linear model to display the visualization result. The proposed method, Design-LIME, is applied for visualizing the impact of effective regions on the torque characteristics of interior permanent magnet synchronous motors (IPMSMs). Compared to conventional visualization methods based on explainable artificial intelligence (XAI), Design-LIME presents accurate and simple visualization results. Furthermore, a novel multistep TO method is proposed. The proposed TO utilizes Design-LIME to efficiently address the electromagnetic and mechanical characteristics of IPMSMs by extracting the effective region of the IPMSM characteristics. The proposed TO method improves search performance by 18.7% when compared with the conventional single-step optimization method. The proposed method enables more efficient motor designs with improved electromagnetic and mechanical performance. The proposed method contributes to the streamlining of the design process not only for motors but also for various electrical devices."
  },
  {
    "year": "2025",
    "abstract": "A broadside aperture coupling was utilized instead of end-wall aperture coupling for millimeter wave inline waveguide-to-microstrip transition (WMT), allowing a larger misalignment tolerance of ±250 um in the vertical direction and ±300 um in the horizontal direction within the insertion loss degradation of 0.1 dB. Additionally, a simple wedge waveguide configuration eliminated the necessity for complex taper or ridge waveguide sections. It simplifies manufacturing and testing procedures by eliminating the need for E-plane or H-plane splits. Furthermore, the transition exhibits broadband and low-loss performance. The fractional bandwidth reached as high as 44%, while the insertion loss of the back-to-back transition was measured at 8.5 dB, which includes the loss from the 1-meter-long waveguide (5.5 dB). The transition is well-suited for microwave and sub-millimeter frequencies due to its low loss, broad bandwidth, compact design, and ease of integration with MMICs."
  },
  {
    "year": "2025",
    "abstract": "This study introduces a System for Calculating Open Data Re-identification Risk (SCORR), a framework for quantifying privacy risks in tabular datasets. SCORR extends conventional metrics such as k-anonymity, l-diversity, and t-closeness with novel extended metrics, including uniqueness-only risk, uniformity-only risk, correlation-only risk, and Markov Model risk, to identify a broader range of re-identification threats. It efficiently analyses event-level and person-level datasets with categorical and numerical attributes. Experimental evaluations were conducted on three publicly available datasets: OULAD, HID, and Adult, across multiple anonymisation levels. The results indicate that higher anonymisation levels do not always proportionally enhance privacy. While stronger generalisation improves k-anonymity, l-diversity and t-closeness vary significantly across datasets. Uniqueness-only and uniformity-only risk decreased with anonymisation, whereas correlation-only risk remained high. Meanwhile, Markov Model risk consistently remained high, indicating little to no improvement regardless of the anonymisation level. Scalability analysis revealed that conventional metrics and Uniqueness-only risk incurred minimal computational overhead, remaining independent of dataset size. However, correlation-only and uniformity-only risk required significantly more processing time, while Markov Model risk incurred the highest computational cost. Despite this, all metrics remained unaffected by the number of quasi-identifiers, except t-closeness, which scaled linearly beyond a certain threshold. A usability evaluation comparing SCORR with the freely available ARX Tool showed that SCORR reduced the number of user interactions required for risk analysis by 59.38%, offering a more streamlined and efficient process. These results confirm SCORR’s effectiveness in helping data custodians balance privacy protection and data utility, advancing privacy risk assessment beyond existing tools."
  },
  {
    "year": "2025",
    "abstract": "The study utilizes text classification (TC) to observe “interpretese” in simultaneous interpreting (SI) at United Nations Security Council conferences. “Interpretese” is a term coined to describe the distinctive linguistic patterns interpreters employ. A text vectorization method known as TF-IDF is improved with Shannon’s entropy and used to convert interpreted and non-interpreted target language speeches into vectors. Subsequently, stacking ensemble learning classifies the vectors reduced in dimensions into two labeled categories: interpreted speech and non-interpreted speech. Accurate classifications would support the interpretese hypothesis. To explore the universality of interpretese, this study detects interpretese in bidirectional SI when interpreters work from their first to second languages in one direction and from their second to first languages in the other direction. The results demonstrate successful classifications in the two interpreting directions, thereby supporting the interpretese hypothesis. Notably, a higher classification accuracy score is yielded when the interpreters work into their first language than into their second language, suggesting interpretese is more pronounced in the former direction, and interpreting directions impact interpreters’ language processing. Different classification algorithms vary in terms of their performance in the classification tasks, underscoring the importance of using stacking for ensemble learning to achieve reliable results and justify algorithm selection."
  },
  {
    "year": "2025",
    "abstract": "Electronic Health Records (EHRs), which include demographic information, clinical notes, vital signs, laboratory test results, and others, provide rich information for clinical outcome prediction. In this work, we propose a novel attention embedded residual long short-term memory (LSTM) fully Convolutional Network (FCN) to perform the clinical predictions of inpatients’ length of stay (LoS) and mortality. The proposed model is uniquely composed of a convolutional neural network (CNN) layer, three residual blocks, an LSTM unit, an FCN module, and a self-attention module. This innovative architecture allows for comprehensive feature extraction, where the CNN and residual blocks enhance clinical data features, the FCN and LSTM separately extract spatial and temporal features, and the self-attention mechanism focuses on pertinent information while filtering out noise. By optimizing the loss function to address class imbalance and overfitting, our model ensures robust and accurate predictions. Experimental results demonstrate that the proposed model outperforms state-of-the-art methods, validating its effectiveness and feasibility in inpatient length of stay and mortality prediction."
  },
  {
    "year": "2025",
    "abstract": "Restoring fine motor skills in individuals with upper extremity sensory-motor post-stroke impairments necessitates repetitive, task-specific exercises to promote functional recovery. Given the substantial time commitment required for therapy, rehabilitation tools must be not only effective but also engaging by adopting a game-based approach to mitigate the monotony of prolonged repetitive exercises. This paper presents a user-friendly finger-thumb mechanism designed to support the index and middle fingers as well as the thumb, specifically for patients with hand injuries. The device establishes a wireless connection to a gaming platform enabling patients to engage with computer games in real-time through purposeful thumb and finger movements. This connectivity is established through two Raspberry Pi boards utilizing a server-client network. Additionally, the device incorporates assistive or resistive forces during gameplay to adjust the level of assistance or challenge based on the individual’s motor control proficiency. With a minimal data transfer delay of 10 ms, and a 50 ms delay for game event updates, patients can seamlessly participate in the gaming experience and modify events in real-time through the newly developed wearable device. In the experiments, assistive mode achieved a 100% success rate, while resistive mode dropped to 37-45%. Movement errors varied across modes, with assistive mode showing the lowest errors, indicating more accurate and consistent performance."
  },
  {
    "year": "2025",
    "abstract": "Steganography is the practice of concealing secret information within a non-secret medium, such as an image or audio file, to prevent detection by unauthorised observers. Currently, there is a shortage of solutions for audio-in-image storage, with a complete absence of methods that do not rely on deep learning approaches. This is problematic because learning models often plateau at a certain level of accuracy, making further improvements difficult. Audio steganography, like other forms of steganography, is vulnerable to data malleability and requires solutions that offer customisable security features while maintaining robustness. This paper presents a novel approach for audio-in-image steganography involving the analysis and resynthesis of sound spectrographs (ARSS). This framework ensures efficient and secure data storage using a simplistic, multi-channel, and non-lossy approach to embed an audio spectrograph in a high-resolution image file. It allows for minimal pre-processing and post-processing to conceal one or more sound spectrographs within a single cover image while focusing on maintaining high fidelity in sound resynthesis during retrieval. Referred to as ASA, this proposed approach achieves a mean PSNR value of 42.54 dB for the stego-image and 45.02 dB for the reconstructed image, outperforming most existing methods while also offering high storage efficiency and infrastructure for additional security measures."
  },
  {
    "year": "2025",
    "abstract": "This research investigates the application of Recurrent Neural Networks (RNNs), specifically Long Short-Term Memory (LSTM) networks, paired with gradient-based optimization techniques for dynamic pricing in e-commerce. The primary objective is to develop a pricing model that effectively balances profitability with customer satisfaction by leveraging sequential data, such as time-series and customer behavior patterns. The approach utilizes LSTM’s ability to capture long-term dependencies in sequential data, while optimization methods like Stochastic Gradient Descent (SGD) enhance model convergence and performance. Key findings include the superior predictive accuracy of LSTM-based models over traditional approaches like Linear Regression and Decision Trees, particularly in real-time data updates and price elasticity scenarios. Additionally, the analysis revealed that LSTM models could efficiently adapt pricing strategies in response to market dynamics, significantly improving profitability while maintaining customer satisfaction. This study provides valuable insights into the application of advanced machine learning techniques in e-commerce pricing. The results suggest that LSTM-based dynamic pricing models could optimize revenue generation, offering substantial implications for pricing strategy development in modern retail environments. Future work may explore hybrid models and multi-objective optimization techniques to further refine these models."
  },
  {
    "year": "2025",
    "abstract": "Millimeter-wave (mmWave) communication systems utilize narrow beamforming to ensure adequate signal power. However, beam alignment requires significant training overhead, especially in high-mobility scenarios. Previous research has utilized synthetic data for position-aided beam prediction, which does not fully capture real-world complexities. In this work, an Enhanced Convolutional Neural Network model (E-CNN) is proposed for optimal prediction of beam indices with the aid of real-world GPS position data. The proposed E-CNN model has been investigated across nine different scenarios from the DeepSense 6G dataset and compared against the conventional algorithms. For 64-beams Scenario 1, the E-CNN model showed an increase in average top-1 accuracy from 55.57% to 63.92%, and in case of 32-beams, the accuracy increased from 71.34 % to 82.06%. For 16-beams, the accuracy increased from 86.17% to 94.64 %, while for 8-beams, the accuracy increased from 90.24% to 97.11%. In addition, besides showing significant power loss reduction in various scenarios, the proposed E-CNN model has demonstrated robustness regarding real-word conditions and adaptability for various beam setups. The model realized as high as a 50% power loss reduction in arguably the most challenging graphs, which is an exercise in reliability. This research fills the existing gap between the simulated aid beam alignment and real-world position beam aided alignment, which can be useful in improving beamforming in the upcoming wireless networks."
  },
  {
    "year": "2025",
    "abstract": "The rise of Virtual Reality has highlighted eye gaze as a key interaction method. Data reliability becomes critical in this context, with gaze accuracy and precision serving as leading indicators of data quality. This study compared the spatial accuracy and precision of Meta Quest Pro and HTC Vive Focus 3 headsets using eye movement data collected during a subjective experiment involving 30 users. Participants were asked to look at visual stimuli placed in a virtual environment under both head-free and head-constrained conditions. The stimuli were positioned at various locations and distances from the users. The analysis revealed inconsistencies between manufacturer-provided data, obtained under ideal conditions, and data collected in different settings. Moreover, the results showed greater spatial accuracy for Meta Quest Pro and higher spatial precision for HTC Vive Focus 3. This study aims to offer an extensive examination of the performance of these systems, thus assisting researchers in choosing suitable eye-tracking technology for diverse applications."
  },
  {
    "year": "2025",
    "abstract": "The state-of-the-art study, Rishiwal et al. (2024) proposed a blockchain-based vehicular network framework designed to enhance communication security and protect vehicle privacy in vehicle-to-everything (V2X) communications. The proposed framework validates vehicle legitimacy using individual certificates and subsequently transmits data collected and integrated by intermediate entities to the blockchain, thereby avoiding direct exposure of vehicle privacy. However, the framework does not prevent intermediate entities from accessing vehicle privacy, leaving vehicles vulnerable to tracking and monitoring by these entities. In response to this limitation, this study proposes a key expansion method based on elliptic curve cryptography (ECC). This approach employs a two-stage key expansion process, referred to as “butterfly key expansion,” to ensure that vehicle privacy is not exposed to any device within the V2X communications. Experimental results demonstrate that the key expansion time does not significantly differ from the key generation time. Furthermore, the signature generation and verification times using the expanded keys are comparable to those of the original keys. These findings indicate that the proposed method achieves enhanced privacy protection without imposing additional computational overhead."
  },
  {
    "year": "2025",
    "abstract": "Federated Learning (FL) is a machine learning training method that leverages local model gradients instead of accessing private data from individual clients, ensuring privacy. However, the practical implementation of FL faces significant challenges. Heterogeneous clients and edge devices with varying computational abilities and unreliable communication channels introduce latency issues to the algorithm. Furthermore, the algorithm is susceptible to attacks from malicious clients, allowing them to insert unwanted updates while benefiting from the global model. These challenges severely impact the algorithm’s performance, rendering it unsuitable for real-time applications. To address these issues, we propose FedHSP, a comprehensive system that tackles device heterogeneity and protects against various forms of attacks. FedHSP incorporates multiple model complexities to accommodate heterogeneous clients. Additionally, it employs a Variational Auto Encoder with dynamic thresholding to detect and eliminate malicious clients. In this paper, we demonstrate FedHSP’s effectiveness in detecting model poisoning attacks. We also show the mitigation of malicious model updates sent to the server. The evaluation is done using the MNIST dataset under various settings. Our experiment results show the drastic performance deviation due to attacks and the successful detection and mitigation with the proposed system."
  },
  {
    "year": "2025",
    "abstract": "Visually impaired individuals face challenges in verifying Aadhaar cards due to the absence of braille, often relying on others for assistance. Despite the widespread use of Aadhaar cards across India, research on assistive technologies for such users remains limited, making this work uniquely significant. To address this, we introduce NetraAadhaar, a deep learning-based mobile application designed to assist visually impaired individuals in Aadhaar card verification. The framework consists of: (i) text region extraction from Aadhaar cards using YOLOv8, (ii) recognition of extracted text via Tesseract OCR engine, (iii) text-to-speech conversion for auditory verification, and (iv) the developed framework is fine-tuned and seamlessly integrated into an end-to-end mobile application for real-time use. NetraAadhaar achieves an mAP-50 score of 92.5% for text detection and an overall text recognition accuracy of 87. 79%, with a precision greater than 90% in key classes, demonstrating its robustness. Compared to traditional OCR-based assistive tools, NetraAadhaar offers higher accuracy, real-time performance, and an end-to-end automated pipeline making Aadhaar verification significantly more accessible and reliable for visually impaired users. NetraAadhaar empowers visually impaired users to verify their Aadhaar cards independently, reducing reliance on others and mitigating risks of identity fraud. The source code, dataset and developed application are publicly available for academic and research purposes athttps://github.com/Adinp1213/NetraAadhar."
  },
  {
    "year": "2025",
    "abstract": "Unintentional islanding occurs when a microgrid continues operating independently after disconnection from the main grid, which can lead to voltage and frequency instability, power quality degradation, and safety risks. Few local and remote methods consider islanding detection in noisy environments. Noise can interfere with measurements and cause failed or delayed islanding detection. This paper proposes a hybrid islanding detection method that utilizes a Van der Pol Duffing oscillator (VDPDO), focusing on decreasing the detection period, zero power mismatch nondetection zone, and power quality degradation. The proposed method uses the fast Fourier transform (FFT) symmetry characteristic of a hybrid VDPDO (HVDPDO) output signal and addresses the set point threshold using the Melnikov function. This method detects the changes in frequency, phase, and voltage amplitude of the point of common coupling (PCC) simultaneously to distinguish islanded operation from other faults. For the asymmetric FFT waveform of the passive HVDPDO, the islanding system sends a signal to the inverter to change the mode from grid-following to grid-forming and injects perturbations into the frequency, phase, and voltage amplitude, simultaneously. The active HVDPDO detects islanded operations with a small non-detection zone. The inverter reverts to grid-following mode for other faults, and the main grid damps the intentionally small perturbations. Simulation and experimental results validate that the proposed method meets the IEEE standard 1547 criteria."
  },
  {
    "year": "2025",
    "abstract": "Monocular 3D object detection aims to infer the 3D properties of objects from a single RGB image. Existing methods primarily rely on planar features to estimate 3D information directly. However, the limited 3D information available in 2D images often results in suboptimal detection accuracy. To address this challenge, we propose MonoDFM, an end-to-end monocular 3D object detection method based on density field modeling. By modeling the density field from the features of a single image, MonoDFM enables a more accurate transition from 2D to 3D representations, improving 3D attribute prediction accuracy. Unlike traditional depth map methods, which are limited to visible regions, MonoDFM infers geometric information from occluded regions by predicting the scene’s density field. Moreover, compared with more complex approaches like Neural Radiance Fields (NeRF), MonoDFM provides a streamlined and efficient prediction process. Experiments conducted on the KITTI dataset show that MonoDFM achievesAP3Dof (25.13, 16.61, 13.82) andAPBEVof (32.61, 22.14, 18.71) on the KITTI benchmark for the Car category under three difficulty settings (easy, moderate, and hard), achieving competitive performance. Ablation studies further validate the effectiveness of each component. As a result, MonoDFM offers an effective approach to monocular 3D object detection, demonstrating strong performance."
  },
  {
    "year": "2025",
    "abstract": "Batteries are essential for Electric Vehicles (EVs). Traditional Battery Management System (BMS) algorithms can be inadequate for State of Charge (SoC) estimation due to incorrect measurements and unobservable battery characteristics. Centralized machine learning methods are used to improve SoC estimation. Both privacy and high bandwidth requirements are the main disadvantages during the implementation. Federated Learning (FL) solves these issues by performing local learning on devices, protecting data privacy, and only aggregating model updates at the central server. While FL approaches can help preserve data privacy during model training, collaborative learning can facilitate the integration of priori data learned by the agents in the fleet with the rest of the fleet members to improve charge prediction. This study proposes a new aggregation rule named Federated Adaptive Client Momentum (FedACM) to handle data imbalance and heterogeneity in SoC estimation. The proposed method is initially validated via experimental results using the collected data from Musoshi L5 type EV. It is also tested using publicly known datasets such as NASA, BMW i3, and Standford University Battery Datasets. These experiments show that the proposed aggregation rule performs better than current state-of-the-art rules for FL."
  },
  {
    "year": "2025",
    "abstract": "Storage resources are essential in heterogeneous multi-cloud environments. In response to the growing demand for efficient storage resource management (SRM) in these environments, this paper proposes an intent-based storage management (IBSM) system powered by a fine-tuned large language model (LLM). To overcome the limitations of existing methods, the IBSM system focuses on enhancing the controllability, completeness, and reliability of SRM in multi-cloud environments. Specifically, the IBSM system employs a dual-phase joint intent classification algorithm, which leverages a fine-tuned LLM to accurately identify user intents across diverse knowledge backgrounds. Additionally, the system constructs a collaborative intent decomposition method, which guarantees the integrity of intents. Furthermore, the system integrates an automated intent deployment mechanism that supports error recovery through checkpoints. Experimental results show that the system achieves a whole end-to-end (E2E) lifecycle for managing user intents. The E2E time is reduced by at least half compared to the manual approach, with an average of 50.14% dedicated to interactive tasks. Performance metrics for intent classification, including accuracy, precision, and recall, all exceed 90%. Moreover, the recovery time is reduced by an average of 30.6%. Therefore, the system provides a valuable solution for the autonomous management of multi-cloud resources."
  },
  {
    "year": "2025",
    "abstract": "This paper proposes an advanced 3D indoor navigation system for a mobile robot. The proposed method integrates RTAB-Map with Voxel Grid Filters and Joint Probabilistic Data Association (JPDA) to generate surrounding environment map efficiency. Additionally, the local path planner combines pure pursuit with a modified Artificial Potential Field (APF) method to improve navigation capability. It generates steering commands and desired velocities and adjusts the attractive potential force equation to maintain balance and operational efficiency. This modification improves safety, pedestrian avoidance, and comfort by minimizing unnecessary rotations while ensuring smooth navigation. The proposed system improves the locomotion ability by reducing roll, pitch, and yaw fluctuations by approximately 30% compared to traditional APF methods. Voxel grid filtering enhances computational efficiency, reducing processing time per iteration by up to 73% - from 0.247 seconds (raw LiDAR) to 0.067 seconds (voxel size of 0.9) - while maintaining obstacle detection accuracy. The integration of JPDA ensures safe multi-target detection, with minimum safe distances of 0.94 meters from dynamic actors and a Threat Level Index (TLI) peaking at 0.24. In a scenario comparing two robots with different map knowledge, the robot with map knowledge reached the waypoint 20% faster, following an efficient path. However, despite lacking prior knowledge, the second robot reached the waypoint, demonstrating the system’s adaptability. These quantitative results confirm the proposed method’s capability to enhance safety, efficiency, and human comfort, making it suitable for real-time indoor navigation in dynamic environments."
  },
  {
    "year": "2025",
    "abstract": "To address this issue, this paper presents an adaptive method for removing scattering media using a mask based on wireless communication fading models. We hypothesize a similarity between light propagation and wireless communication systems, which incorporates scattering estimates through models such as the Rayleigh and Rician fading models, which are applied to process the captured images and mitigate scattering effects. Our proposed method incorporates two systems: the Scattered Image Model and the Scattering Media Model. The conventional dehazing method requires processing sequences’ approximated depth map or specific background. However, the proposed method functions regardless of the image’s depth and specific background colors. To validate the proposed method, we conducted optical experiments and tested outdoor images. The results were compared with conventional haze-removal methods, such as dark channel prior and Peplography, using various image quality metrics, e.g., the Peak Signal-to-Noise ratio, Structural Similarity Index Measurement, Tone Mapped Image Quality, and Feature Similarity Index Measurement extended to color imagery. The experimental results demonstrated significant improvements over the conventional methods across all metrics."
  },
  {
    "year": "2025",
    "abstract": "Reliability Modeling for Power Systems is a very challenging task due to the high complexity of the interactions among its various components. In this paper, we develop a simple probabilistic method for modeling power system reliability based on the knowledge of the system size, transmission line capacities, and the failure rate type of the transmission lines in the system. Using Monte Carlo Simulation, we show that the probability distribution of the system failure rate is typically similar in shape to the failure distribution of the transmission lines in the system, with variations stemming from the system size, transmission line capacity, and the type of failure rate. Our method provides a very simple formula for describing system level reliability despite the high complexity of its interconnections, and provides a mechanism to develop similar functions for other complex systems, including different types of networks or critical infrastructures, and can pave the way towards better modeling for the more intelligent future grids."
  },
  {
    "year": "2025",
    "abstract": "Transmission line parameter estimation is a critical issue for power system operation and planning studies. With the advent of synchrophasor technology, numerous new methods have been developed using PMUs (Phasor Measurement Units) based on real-time measurements from the sending and receiving ends of a transmission line. Typically, the equivalent PI section of the line is determined for the fundamental frequency only. For other harmonic orders, impedances can be measured at specific points in the electric network using a frequency scan approach. However, few studies have focused on the separate estimation of all longitudinal resistances, reactances and shunt admittances for higher harmonic orders. This paper presents a novel approach to this long-standing issue by formulating an optimization problem, where the least squares equation is minimized, subject to inequality constraints associated with the harmonic impedances of a transmission line, modeled with a quadrupole representation. The proposed optimization method allows for the estimation of line impedance parameters with reduced errors for all harmonic orders considered in the analysis. Computational simulations are carried out to demonstrate the applicability of the method, using different line models including a real Brazilian transmission line, and the impact of instrument transformers on the estimated results is also assessed."
  },
  {
    "year": "2025",
    "abstract": "Sound event detection and classification present significant challenges, particularly in noisy environments with multiple overlapping sources. This paper introduces an innovative architecture for multiple sound event detection and classification utilizing recurrent spiking neural networks (SNNs). Our method uniquely leverages temporal data to detect and classify multiple sound sources simultaneously, integrating the physical concept of signal power matching with neuronal output power and employing a binaural strategy to enhance detection accuracy in real-world scenarios. The architecture processes spatiotemporal data to dynamically update synaptic weights, enabling precise identification of sound event categories and their occurrences. Our simulations reveal substantial performance improvements, achieving the highest precision of 73% in classification tasks, including multilayer perceptrons (MLP), convolutional recurrent neural networks (CRNN), and recurrent neural networks (RNN). Statistical analysis indicates that these improvements are significant (p-value ¡ 0.05). These findings suggest practical applications in various fields such as surveillance, autonomous vehicles, and smart home systems, where robust sound event detection is critical."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a compact four-pole tunable bandpass filter (BPF) with a wide center-frequency tuning range and a wide stopband using a single control voltage. The designed filter is based on an asymmetric T-shaped dual-mode resonator (DMR) comprising three varactor-loaded stubs (VLSs) that function as series resonators. Each VLS has its own distinct resonant frequency, and the two pole frequencies of the T-shaped resonator are located between these three resonant frequencies. The proposed filter exhibits a wide tuning range from 300 to 960 MHz (over 3:1 tuning range), with an upper stopband extending to24.3fm, wherefmis the lowest center frequency within the tuning range. The core size of the filter is only0.067λg×0.067λg, whereλgis the guided wavelength at the lowest center frequency. To the best of the authors’ knowledge, this is the first four-pole tunable BPF with center-frequency control that accommodates an asymmetric DMR."
  },
  {
    "year": "2025",
    "abstract": "This study explored the possibility of using currently available data to forecast when and where a large earthquake could occur in the near future. Such forecasts require measurements and understanding of past and current three-dimensional (3D) displacement patterns. We analyzed the geometric patterns of 3D displacement using coordinate data from over 1,300 global navigation satellite system stations in Japan. We found that the monthly displacement velocities of a station were on a single flat plane, although a significantly large earthquake had occurred, and the normal planes of all stations were on a single quadratic curve surface. Moreover, the sum of the absolute differences in 15-d velocities indicated a significant displacement over a wide area after the occurrence of a large earthquake."
  },
  {
    "year": "2025",
    "abstract": "Multi-criteria decision-making (MCDM) problems are generally oriented toward strategic decisions and have a significant economic aspect, holding a special place in decision-making processes. To address these problems, specialized techniques have been developed and utilized. Electroencephalography (EEG) is a technique that measures brain activity, and the results can be used both to diagnose neurological disorders and to create more productive and healthier working conditions in a wide variety of areas. This paper discusses the collaborative nature between MCDM and EEG, focusing on how EEG and MCDM processes can enhance each other. Based on the database search results, thirty-five out of 149 papers were selected for the review process. By examining the literature on both macro and micro scales, the following were mainly retrieved: a) the MCDM techniques applied and their use in analyzing EEG data, b) EEG devices and wave types used in the MCDM process, c) the attributes of MCDM or EEG that were focused on, and d) current trends in knowledge and research opportunities. The results of this study will help identify potential future research areas, as well as provide a comprehensive overview of the existing literature. To summarize the findings, it can be concluded that EEG measurements of decision-makers’ cognitive states during the application of MCDM techniques improve the MCDM process and the presentation of these techniques, or they enhance the results obtained by MCDM based on the cognitive states of decision-makers when evaluating alternatives. Additionally, MCDM techniques contribute to improvements in the classification or feature extraction stages of data obtained through EEG."
  },
  {
    "year": "2025",
    "abstract": "This paper aims to produce in-beam images from Gadanki ionospheric radar interferometer (GIRI) data and thereby studying ionospheric irregularities. Here, multiple receiving channels are connected with collinear baselines in spaced antenna (SA) array interferometry mode. In order to obtain high-resolution images using coherent radar imaging (CRI), the backscattered signals received at the multiple receiving channels have been analysed. Generating these images is related to spectrum estimation, which has two challenges: (i) Amount of the data is limited and in some cases very small. (ii) Data is corrupted by noise in the environment. Due to statistical fluctuation and noise in the backscattered signal, visibility spectrum data is noisy and incompletely sampled. To make optimal use of data while generating the images, it is important to remove the background noise from the visibility spectrum in Fourier method. Using the active phased antenna array configuration, images produced with small time resolution allow us to observe the temporal evolution of the ionospheric irregularities inside the radiating beam."
  },
  {
    "year": "2025",
    "abstract": "The objective of this study was to develop an automated system for the identification of wanted individuals in terrestrial terminals using Convolutional Neural Networks (CNN). The research was conducted under a quantitative approach and a quasi-experimental design. A private dataset, intended for educational purposes, consisting of images and videos of individuals in dynamic environments, was employed to enable identification testing under real-world conditions. The methodology encompassed the structured loading of biometric data, facial detection using the Multi-Task Cascaded Convolutional Neural Network (MTCNN) model, and the generation of facial embeddings through the InceptionResNetV1 model. Extracted features and data were stored in a MySQL database. To optimize the search process during real-time identification, the embeddings were transferred to FAISS, a library optimized for similarity search in large-scale datasets. In FAISS, the embeddings were stored in vector format to facilitate fast and efficient querying. Subsequently, identification tasks were performed on video sequences captured in real time. The results revealed high performance of the proposed system, achieving an 89% accuracy in facial detection and 98.60% accuracy in real-time person identification when compared against the data stored in the database. Finally, the trained models were integrated into a web application that enables real-time identification using IP cameras, leveraging YOLO version 8 architecture for tracking identified individuals. These results confirm that deep learning models can be effectively incorporated into surveillance and control systems in public spaces, enhancing existing security mechanisms and offering a viable solution for real-time automatic person identification."
  },
  {
    "year": "2025",
    "abstract": "Breast cancer is the most frequent type of cancer largely experienced by women currently, although it could happen to men also. It appears when abnormal breast tissue cells grow rapidly and form tumors. Mammogram is a technique that is employed by doctors to analyse the breast in the diagnosis of early cancer. These mammograms are classified into Benign and Malignant. This research addresses the variability and potential oversight in radiologists’ manual mammogram interpretations, aiming to enhance classification accuracy by combining Convolution Neural Networks (CNNs) and Vision Transformers (ViTs). CNN is a successful image classification that uses hierarchical feature extraction, ViTs capture the global context but require substantial data and computation. In this research, we have used CLAHE-enhanced mammogram images from Kaggle for training and applied a CNN+ViT model. We have also used a few pre-trained models such as DenseNet, Inception, SE Resnet, and XceptionNet for comparative analysis. The CNN+ViT model gave us an accuracy of 90.1% showing robust performance. Although XceptionNet achieved perfect accuracy, it may indicate overfitting."
  },
  {
    "year": "2025",
    "abstract": "Compared to well-established geosynchronous equatorial orbit (GEO) satellite networks, low Earth orbit (LEO) satellites bring new challenges to overcome, such as the distortion of the satellite footprint with varying elevation angle. The impact of the elevation angle on system behavior is not sufficiently studied in literature, and guidelines to parameterize LEO systems are lacking. This paper addresses these gaps by providing a framework to analyze the satellite footprint behavior of arbitrary multi-beam satellite systems with large antenna arrays and analyzing the system behavior of a LEO satellite operating in the Ka-band (30GHz) for varying elevation angle and serving area size. The analysis considers the directivity and antenna array steering of the antenna array and the curvature of the Earth. The provided framework allows repeatable analysis and offers a means to parameterize systems in terms of serving area size, beam design, and operating elevation angles. Analysis over elevation angles confirms the strong influence of the satellite elevation angle on the system performance and indicates that elevation angle dependence of LEO systems needs to be considered in the evaluation of future technologies. It is shown that the system drifts from a noise-limited regime at high elevation angles to an interference-limited regime with decreasing elevation angle. The findings suggest a minimum elevation angle of 30° for practical systems, as lower elevation angles show excessive propagation loss and severe interference due to beam distortion. Link budget analysis further indicates that systems require highly directional antennas with large gain to serve handheld user devices."
  },
  {
    "year": "2025",
    "abstract": "In wireless localization systems, enhancing location estimation performance is critical, particularly in challenging environments, such as military urban operations and emergency response scenarios. Ultra-wideband (UWB) positioning systems using two-way-ranging (TWR) schemes avoid synchronization issues, but face challenges related to scalability, anchor selection, and poor channel characteristics. Existing methods often rely on exhaustive geometric calculations, leading to inefficiencies in dynamic and time-critical scenarios. This paper proposes a lightweight sequential branching deep network for dynamic indoor positioning (LSB-DIP Net) is proposed to address these challenges. By integrating multi-scale feature extraction, sequential learning, and advanced activation functions with the conventional linearized least squares method, the LSB-DIP Net enables robust, accurate, and dynamic UWB positioning in real-time. The model effectively mitigates non-line-of-sight (NLOS) ranging errors, evaluates anchor channel quality online, and selects optimal anchor combinations, ensuring scalability and adaptability for diverse deployment scenarios. The proposed approach demonstrates exceptional performance in dynamic setups, achieving low mean squared error (MSE) of 0.0051m2, high accuracy in identifying anchor channels of 99.44%, with a maximum positional error of less than 0.17 m in harsh environments. Validated across public datasets, the system ensures generalizability and outperforms state-of-the-art counterparts in the market, making it a reliable tool for real-time applications in communication and navigation systems."
  },
  {
    "year": "2025",
    "abstract": "Platform Engineering (PE) is a growing area of Software Engineering, with many facets, including the elusive concept of Internal Development Platforms (IDPs). They integrate various technologies and tools to support the realization of software projects, especially their managing and developing roles, fostering Agile collaboration and enhancing team productivity. In particular for the new trends of Agile remote working and for Agile applied to the Digital Transformation in the Public Sector. While proprietary IDPs abound, academic research that could naturally lead to open-source IDPs remain scarce. In particular for Scrum, a fundamental Agile methodology in the strategic area of Digital Transformation in the Public Sector, where IDP self-hosting is also appropriate. This paper addresses this gap by proposing the design and realization of the first, to the best of our knowledge, IDP supporting Scrum, being open-source and with self-hosting capabilities. The end-product of our research is the Compositional Agile System (CAS), an extendable microservice architecture-based IDP. Its design, as well as CAS, makes full use of hands-on previous successful experiences of IDP development by members of this team, specifically non-trivial tasks in Italian Public Administration and to foster remote working in University Software Engineering classes, a practice started during the pandemic but now a standard. We offer several architectural and example scenarios where CAS can be of use, concentrating on the Public Administration. Particularly relevant is the use of CAS in analyzing a pillar of Italian Digital Administration available to its citizens, i.e., AppIo. The software is available as an open resource to the research community."
  },
  {
    "year": "2025",
    "abstract": "Task scheduling in distributed cloud and fog computing applications must be efficient to optimize resource utilization, minimize latency, and comply with strict service level agreements. The dynamic and heterogeneous of fog computing challenges such as balancing performance with variable task loads, resource constraints, and energy efficiency. This paper introduces a new Federated Learning Deep Queue-Learning (FLDQN) framework that integrates reinforcement learning with federated learning to overcome these challenges. The FLDQN approach enables decentralized task scheduling because fog nodes can train their local DQN models on localized data, merging their experiences to form a global model without sensitive data sharing. It further improves task prioritization by classifying tasks based on their execution time and deadlines, ensuring that high-priority tasks are scheduled first, which reduces SLA violations and task rejection rates. The proposed model dynamically adapts to the changing conditions of the fog environment through iterative learning that continuously improves work allocation. Substantial experiments conducted on large and small sizes of dataset show that the proposed FLDQN outperforms others, including standalone DQN and graph-based GGCN. For all dataset sizes small, medium, and large datasets, it reduces makespan by up to 30%, improves throughput, and reduces energy by distributing tasks on the most efficient node based on current system states. The results demonstrate the ability of FLDQN to optimize task execution in real time, while addressing the scalability and privacy issues inherent in fog computing. Combining federated and reinforcement learning proposed framework provides a flexible solution for distributed task scheduling, which is well suited for latency-sensitive applications in industrial automation, healthcare monitoring, and smart city deployments."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces fProcessor, a tool designed for nonintrusive, on-the-fly preprocessing of data being written to files. “Nonintrusive” means that fProcessor requires no modifications to existing code, allowing applications to remain unaware of the monitoring activities. “On-the-fly” indicates that fProcessor dynamically executes preprocessing operations on file contents during the write process. It supports three common preprocessing operations: tracking, detection, and reduction. These operations are applicable in scenarios such as capturing log file content, filtering data being written, and reducing file content to conserve storage space. Traditionally, these tasks necessitate specific application-layer code. In contrast, fProcessor intercepts file content at the Linux kernel level, simplifying the development of application-layer code. The advantage of fProcessor lies in its use of eBPF technology to implement file preprocessing, demonstrating low runtime overhead and enabling efficient data processing. fProcessor is free and open source software (https://github.com/Prometheus-first/fProcessor)"
  },
  {
    "year": "2025",
    "abstract": "Machine learning algorithms face important implementation difficulties due to imbalanced learning since the Synthetic Minority Oversampling Technique (SMOTE) helps improve performance through the creation of new minority class examples in feature space before preprocessing. The underlying problem leading to performance deterioration emerges from noise and boundary instances found in the minority class rather than an excessive imbalance ratio. Noise and marginal samples become problematic during oversampling operations since they reduce the performance of classification models. This paper proposes an advanced version of Borderline-SMOTE (BL-SMOTE), called ABL-SMOT approach that utilizes INFFC for noise filtering to optimize data quality in the dataset. This improvement method for minority class sample placement and noise filtering ensures higher classifier performance through ABL-SMOTE. The proposed technique receives assessment through the usage of software defect datasets along with multiple testing classifiers against conventional data sampling procedures. The experimental outcomes show that ABL-SMOTE performs better than alternative approaches in most tested datasets because it is an effective preprocessing tool for imbalanced classification problems."
  },
  {
    "year": "2025",
    "abstract": "Acute Lymphoblastic Leukemia (ALL) is a fast-growing blood cancer that requires prompt diagnosis for effective treatment. Automated image diagnostics offer potential solutions but often lack clinical robustness. Despite their widespread use in medical imaging, Convolutional Neural Networks (CNNs) struggle to differentiate morphologically similar ALL subtypes due to limited context and feature discrimination. Moreover, integrating contrastive self-supervised learning with hierarchical attention-based models remains underexplored in hematologic malignancy classification. This study aims to develop a robust, automated classification model for ALL subtypes using peripheral blood smear images, employing advanced feature extraction through the Swin Transformer framework, combined with Momentum Contrast (MoCo) for contrastive learning and a Bidirectional Encoder Transformer for classification. The Swin Transformer’s patch-based embedding and multi-level attention enhance feature discrimination across ALL subtypes, while MoCo generates distinct embeddings, minimizing overlap between cell types. BiET is employed to classify the refined feature vectors, leveraging self-attention mechanisms to improve classification accuracy. The model achieved an overall classification accuracy of 92.5%, with the precision of 90.3%, a recall of 91.1%, and an F1-score of 90.7% across four classes (Benign, Malignant Early Pre-B, Malignant Pre-B, and Malignant Pro-B). Class-specific performance metrics indicate that Malignant Pre-B achieved the highest F1-score of 92.4%. The MoCo framework reduced contrastive loss from 0.5 to 0.097 for benign cells, enhancing feature discrimination. An ablation study revealed that omitting the dynamic queue decreased accuracy by 5%, underscoring its importance for effective feature learning. This approach can be extended to other hematologic malignancies, with potential for further improvement using larger datasets and real-time diagnostic workflows to support p..."
  },
  {
    "year": "2025",
    "abstract": "The process of taking a new semiconductor device from the lab to the factory involves a lot of time, funds and manpower, a large portion of which is spent on device yield improvement. In recent years new methods have been tried to rapidly improve yields and using machine learning (ML) algorithms is one option. However, they usually require a large dataset, which is often unavailable at the device research stage, emerging semiconductors (e.g., 2D materials) are extremely costly to pilot. In this paper, we propose a yield diagnosis and tuning scheme based on ensemble learning and Bayesian optimization, which demonstrate outstanding performance even with a limited data volume. We use real 2-D semiconductor device fabrication process data for scheme evaluation. Experimental results show that the algorithm for yield prediction has achieved regression fitting results whose mean absolute error (MAE) is no more than 8 points and explained variance (EVAR) is no less than 0.62, this indicates that the model fits well on this dataset. We also remanufactured a batch of devices based on the yield tuning recommendations to validate the effectiveness of our approach. The test results indicated a final yield score of 86 points, after evaluating several key indicators such as mobility and hysteresis, resulting in a 62% improvement."
  },
  {
    "year": "2025",
    "abstract": "Multi-input multi-output (MIMO) antennas operating in the millimeter wave (mmWave) band face challenges related to inter-element interference, limited isolation due to close spacing, and mutual coupling, all of which degrade antenna performance. To address these, this study introduces an advanced technique for enhancing inter-element isolation and minimizing mutual coupling. The proposed approach employs a combination of defective ground structures (DGS) and frequency-selective surfaces (FSS) to achieve effective isolation enhancement. Initially, a mmWave dual-band antenna was designed by incorporating a modified elliptical patch with rotating arms. Subsequently, a six-element dual-band MIMO antenna, measuring1.97×3.39λ2, was developed to operate in the 23.63–32.90 GHz and 36.68–40 GHz bands, covering both ISM and 5G NR bands. The proposed inter-element isolation technique successfully achieves a coupling reduction of 33 dB between the MIMO elements. Furthermore, the designed dual-band MIMO antenna maintains a broadside radiation pattern, with maximum realized gains of 9.12 dBi, 9.19 dBi, 8.80 dBi, and 8.77 dBi at 26 GHz, 28 GHz, 30 GHz, and 38 GHz, respectively. It also demonstrates excellent MIMO diversity performance, including a total active reflection coefficient of<−10dB, an envelope correlation coefficient of <0.04, and a diversity gain of >9.91 dB. A specific absorption rate (SAR) analysis confirmed that the design complies with safety standards for both 1g and 10g tissue models. Additionally, a communication link scenario for wireless body area network (WBAN) applications was investigated. The combination of high isolation, dual-band functionality, broadside radiation, excellent diversity performance, and acceptable link margin validates the suitability of the proposed MIMO antenna for WBAN communication applications."
  },
  {
    "year": "2025",
    "abstract": "Three-dimensional magnetic anomaly inversion is regarded as one of the most effective methods for accurately retrieving subsurface magnetization distributions. However, existing deep learning methods for magnetic anomaly inversion suffer from issues such as the lack of accuracy in some model structures, poor boundary details, and the skin effect. To address this technical challenge, we propose a magnetic anomaly inversion method based on Transformer architectures, with constraints from magnetic anomaly measurement data. Our method employs a hierarchical encoder-decoder network constructed with Transformer Blocks and introduces three key innovations: 1) We propose a Transformer Block based on cross-attention mechanism. Leveraging this mechanism, the Transformer Block can extract features from both magnetic anomaly and magnetic gradient anomaly data, thereby significantly enhancing the accuracy of boundary detection. 2) We propose a learnable Multi-Scale Feature Fusion Module. This module is devised to integrate the multi-scale features from each stage of the encoder, facilitating the decoder to achieve high-precision inversion. 3) We propose a forward constraint loss function. During network training, this loss function ensures that the inversion results adhere to geophysical principles. This methodology not only elevates the inversion accuracy but also effectively alleviates the skin effect. Experimental results show that, compared to other methods, our approach can accurately reconstruct the shape and location of the magnetization model, improve structural accuracy, enhance boundary details, and reduce the skin effect. Furthermore, the method was applied to magnetic anomaly data from a region in Tianjin, China, successfully predicting the distribution of magnetically related pipeline. This demonstrates its potential as a valuable tool for magnetic anomaly inversion."
  },
  {
    "year": "2025",
    "abstract": "This article introduces a server-centric cellular Passive Optical Network (C-PON) architecture to support the deployment of Augmented Reality (AR)/ Virtual Reality (VR) event viewing applications in edge data centers. The proposed architecture is compared with the state-of-the-art Spine-and-Leaf architecture. For fair comparison, we model production style environments based on both C-PON and Spine-and-leaf data center architectures. We developed a Mixed Integer Linear Programming (MILP) model with multi-objective function to optimize routing of AR/VR traffic on both C-PON and Spine-and-Leaf architectures. The multi-objective function considers minimizing power consumption and minimizing end-to-end delay within the network architectures. We compare hosting the AR/VR applications in C-PON and in Spine-and-Leaf in terms of the power consumption, the average delay in links, and the end-to-end delay per user. We also developed a heuristic algorithm to enhance the scalability enabling the optimization of complex and larger systems. The results show that C-PON can enable substantial savings in terms of power consumption compared to the state-of-the-art Spine-and-Leaf architecture."
  },
  {
    "year": "2025",
    "abstract": "Effective information diffusion across large-scale network is key for influence maximization. Recent research has shown a significant surge in interest in modeling, performance estimation, and seed identification across various networked systems. Moreover, a simulation of useful interactions among many significant groups within networks was developed to simulate real-world marketing and spreading information more accurately. A good diffusion model identifies the minimum number of effective seeds capable of achieving maximum diffusion effects across the network. Limited focus has been placed on measuring the strength of seeds in competitive spreading situations. There is a research gap in determining effective strategy for this purpose. This study proposes a memetic algorithm based on a community for large-scale social networks. The proposed algorithm optimizes the influence spread by identifying the most influential nodes among the communities, depending on their inter- or intra-community propagation dynamics. This algorithm combines the concept of genetic algorithm with a reachability-based local search method to accelerate the convergence process. This approach offers a robust method for maximizing the influence of network structure and interactions. An experimental evaluation on real-world social network datasets shows the performance superiority of this community-based memetic algorithm (CBMA-IM) over existing algorithms."
  },
  {
    "year": "2025",
    "abstract": "Women remain under-represented in academic science, and this is especially true in computing. While there is limited research on gender differences in research focus, there is evidence that women may be more likely to conduct applied research. We surveyed tenured and tenure-track faculty in the United States to understand perceptions of hypothetical researchers who engage in applied or theoretical work. Faculty rated researchers engaged in applied research as less likely to publish their work, receive tenure/be promoted, obtain awards, and get funding for their work. Faculty further rated these researchers as less brilliant, creative, and technically skilled than they rated their theory-focused counterparts. Data from publications, hiring, funding, and awards suggests that applied research may indeed lead to worse career outcomes. We further show that women are more highly represented in applied research areas than theoretical ones. Negative perceptions of applied researchers must now be addressed to avoid exacerbating the gender gap."
  },
  {
    "year": "2025",
    "abstract": "Edge computing has gained significant attention due to the swift development of wireless communication technology. As more smart, data-intensive applications and Internet of Things (IoT) devices are used, the amount of data traffic grows at an exponential rate. This means that we need to manage data effectively so that services can be scalable, bandwidth-efficient, and latency-sensitive. Collaborative data caching has emerged as an essential technique in this context to meet the storage and retrieval needs of edge computing systems. We thoroughly examine the current collaborative caching techniques in edge computing, with a focus on recent developments and emerging approaches. We have categorized collaborative caching strategies into four main types: models based on stochastic, game theoretic, and mathematical methods to deal with uncertainty in network conditions and optimize resource allocation; machine learning-based models that employ artificial intelligence (AI) for content popularity prediction and cache optimization; heuristic models providing lightweight solutions for cache placement and replacement; and hybrid models combining multiple strategies. Each of these models is intended to maximize performance under various network and data conditions. We conclude by looking into some of the open problems and difficulties with edge caching to promote further research in this field."
  },
  {
    "year": "2025",
    "abstract": "In this study, a novel artificial potential-driven computational framework is proposed for studying macroscopic percolation and permeation phenomena in dynamic group systems. This framework extends the traditional static percolation theory to the analysis of dynamic porous media, thereby promoting the expansion of the former to the latter. The proposed model generates links between individuals of the groups through an adaptive interaction mechanism, where the individuals exhibit time-evolving equilibrium dimensions and heterogeneous spatial constraints. This dynamic coupling spontaneously generates self-organizing interference patterns, resulting in, for example, parceling or barrier effects in the groups. These effects fundamentally affect the permeation paths of the evolving group structure. In contrast to the traditional approach, which assumes a static structure, the study reveals how the individual time-varying equilibrium radius and the collective spatial organization dynamics dominate the percolation and permeation processes of the macroscopic group. This includes key factors such as porosity evolution, permeation dynamics, and critical percolation transitions. The experimental results demonstrate that groups of agents with time-varying equilibrium radius can significantly improve the percolation characteristics of the groups, and the different structures of tightly clustered groups can also directly affect the percolation and permeation of the groups.From the perspective of dynamic porous media mechanics, the method proposed in this paper provides an innovative theoretical framework for analyzing biological communities, active substance assemblages and group dynamics."
  },
  {
    "year": "2025",
    "abstract": "The seamless and resilient operation of power grids is crucial for ensuring a reliable electricity supply. However, maintaining high operational stability is increasingly challenging due to evolving grid complexities and potential adversarial threats. This paper proposes a novel composite enhanced proximal policy optimization (CePPO) algorithm to improve power grid operation under adversarial conditions. Specifically, our approach introduces three key innovations: 1) multi-armed bandit (MAB) mechanism for dynamic epsilon-clipping that adaptively adjusts exploration-exploitation trade-offs; 2) meta-controller framework that automatically tunes hyperparameters including the activation learning rate (ALR) penalties and exploration factors; and 3) integrated gradient-based optimization approach that combines policy gradients with environmental feedback. The effectiveness of the proposed model on the IEEE 14-bus system demonstrates that the CePPO achieves approximately 50% higher average rewards and 51% longer stability periods compared to standard PPO while reducing computational overhead by 35%. CePPO demonstrates superior performance under adversarial attacks compared to baseline approaches. The simulation results validate that CePPO’s adaptive parameter tuning and enhanced exploration strategies make it particularly well-suited for the dynamic nature of power grid control. To foster further research and reproducibility, the code is available upon request athttps://github.com/Dr-Kate-Davis-s-Research-Team/DRL-CP.S"
  },
  {
    "year": "2025",
    "abstract": "This paper illustrates how a transformation technique can be used to demonstrate the relationship among e-voting, e-auction, e-cheque, and e-cash, even though they serve distinct purposes. Initially, we examine the definitions of e-cheque and e-cash schemes, along with their respective security models. Subsequently, we develop a systematic framework to transform e-cheque into e-cash, supported by formal proof demonstrating the security of the conversion. As a corollary, we further exemplify this integration with a generic transformation framework to obtain e-cash from e-voting directly by combining an existing transformation of e-voting into e-cheque and the transformation of e-cheque into e-cash which we established earlier. We apply our transformation framework to Li et al.’s transformed e-cheque scheme and Li et al.’s e-voting scheme to obtain a concrete, secure e-cash scheme that is IND-CCEA, IND-CIA, and EUF-CIA as an instance. Finally, we examine how our result contributes to the integration and relationship between e-voting, e-auction, e-cheque, and e-cash systems."
  },
  {
    "year": "2025",
    "abstract": "In order to ensure the quality of test data, the Mach number control deviation should be kept within a given range during the continuous-traverse mode force measurement test in a wind tunnel. Currently, when establishing the continuous-traverse mode force measurement test technique in a one-meter-scale sub-transonic and supersonic wind tunnel, the maximum Mach number control deviation exceeds the given range (0.003) under the conditions of sub-transonic speed, large model blockage ratio and wide angle of attack range. This deviation fails to meet the test requirements. By analyzing the process of sub-transonic Mach number adjustment, it is found that the significant Mach number control deviation arises due to two main factors: first, the static pressure fluctuates substantially as a result of changes in the angle of attack; second, the choke finger fails to adjust accurately and eliminate these static pressure fluctuations in real time. To achieve Mach number control deviation less than 0.003, a Mach number tracking control strategy has been proposed, which is based on the choke finger model predictive control algorithm with feedforward-feedback structure and choke finger compensation algorithm. The proposed strategy has been successfully implemented in continuous-traverse mode force measurement test. The test results show that the Mach number control deviation remains within the given range of 0.003 by using Mach number tracking control strategy, and the strategy has good robustness under the condition that the model blockage ratio is less than 0.69%."
  },
  {
    "year": "2025",
    "abstract": "High-pressure die casting (HPDC) is a widely adopted manufacturing process in the automotive industry, renowned for producing complex metal components with high precision and surface quality. However, HPDC is inherently susceptible to defects such as shrinkage, high porosity, and filling irregularities, which can compromise product integrity and escalate production costs through increased rework and material waste. Although effective, traditional Statistical Process Control (SPC) methods require significant statistical expertise and are often cost-prohibitive for smaller manufacturers, limiting their widespread adoption. This study introduces and validates a tailored Vision-Based Measurement (VBM) system designed to automate real-time quality control within HPDC processes, enabling 100% inspection coverage without human intervention. Utilizing a COGNEX IS7600M camera and advanced image processing techniques, including Hough Transform and Sobel edge detection, the VBM system accurately measures the critical dimensions of a metallic clamping fork, a key automotive component. The system is integrated into the manufacturing workflow using the RAMI 4.0 architectural model, ensuring seamless communication with existing software applications used in the production process. Experimental validation involved assessing measurement uncertainty and implementing SPC charts, demonstrating enhanced process stability and a significant reduction in Non-Pass Rates (NPR) from 147 to 63, representing an approximately 57% decrease. A Failure Mode and Effects Analysis (FMEA) highlighted substantial reductions in direct and indirect defect detection and handling costs, resulting in financial savings of R$2,179.50 per batch by minimizing rework and material waste. Additionally, the VBM system reduced inspection time from several minutes per component to approximately 7.7 seconds, lowering labor costs. Financial analysis revealed considerable cost savings, underscoring the system’s ec..."
  },
  {
    "year": "2025",
    "abstract": "The emergence of connected and autonomous vehicles (CAVs) has become a focal point in the literature. This study proposes a comprehensive evaluation framework integrating multi-criteria analysis (MCA) methods with traffic microsimulation modeling to assess the impacts of mixed traffic conditions, comprising CAVs and human-driven vehicles (HDVs), on urban networks from various perspectives: traffic efficiency, environmental performance, and traffic safety. To this end, findings obtained from simulations of two real urban networks are employed to evaluate the impacts of penetration rates and different driving behaviors of CAVs. Six penetration rates (15%, 30%, 45%, 60%, 75%, and 90%), and three different driving behaviors of CAVs, namely defensive, normal, and aggressive, are considered in the scope of this study. While the Criteria Importance Through Intercriteria Correlation (CRITIC) method is utilized for determining objective criteria weights, the designed scenarios are scored by means of the Combined Compromise Solution (CoCoSo) method. The findings of the study indicate that defensive driving behavior enhances traffic safety, albeit with trade-offs in reduced traffic efficiency and increased traffic emissions. On the other hand, while aggressive driving behavior improves traffic efficiency and reduces traffic emissions, it also introduces safety risks, particularly at low penetration rates. According to the outcomes of the comprehensive evaluation, scenarios comprising only HDVs lose their dominance beyond 60% and 75% penetration rates, depending on the network. The proposed approach is expected to be effective in assessing the impacts of mixed traffic conditions on urban networks and can provide valuable insights to transportation policymakers and practitioners."
  },
  {
    "year": "2025",
    "abstract": "To improve the intelligence level of badminton training and match analysis, this study discusses a badminton action recognition system based on deep learning. It optimizes spatiotemporal feature extraction, multimodal data fusion, and computational efficiency to address current issues such as insufficient recognition accuracy, high computational resource consumption, and limited real-time performance. In the experimental section, the performance of three mainstream models—Spatial-Temporal Graph Convolutional Network (ST-GCN), Vision-Attention Transformer for Real-time Motion Recognition (VATRM), and Multi-Modal Network for Sports Action Recognition (MM-Net)—is compared from two dimensions: recognition performance and computational efficiency. The experimental results show that the optimized system achieves accuracies of 0.943, 0.967, and 0.912, higher than other comparison models. Additionally, in terms of F1 score, the optimized system scores 0.902 in the defense and transition action groups, significantly outperforming MM-Net (0.864) and ST-GCN (0.878). In terms of computational efficiency, the inference times of the optimized system are 12.4ms, 10.8ms, and 13.1ms, faster than ST-GCN and MM-Net, with memory usage as low as 487MB, 452MB, and 501MB, making it suitable for real-time mobile applications. Therefore, this study contributes to intelligent sports training, sports data analysis, and badminton technique optimization."
  },
  {
    "year": "2025",
    "abstract": "Recent advancements in using FPGAs as co-processors for language model acceleration, particularly for energy efficiency and flexibility, face challenges due to limited memory capacity. This limitation hinders the deployment of transformer-based language models. To address this challenge, we propose a novel software-hardware co-optimization framework that integrates Hessian-based intra-layer mixed-precision quantization with a runtime bit-configurable FPGA accelerator. Our proposed Hessian-based row-wise weight quantization addresses hardware inefficiencies in traditional parameter-wise and channel-wise approaches by enabling mixed-precision weight matrices to be split into two uniform-precision matrices, thereby simplifying hardware requirements. Additionally, our Query-Key coupled attention activation quantization optimally aligns precision within each outer product pair in attention calculations, reducing hardware complexity and memory management overhead. Our concurrent quantization method balances the benefits of row-wise weight quantization and Query-Key coupled activation quantization while maximizing energy efficiency through multi-precision optimization. To support this algorithm, we design a multi-precision FPGA accelerator capable of handling both 2n-based and non-2n mixed-precision operations. It is implemented on a single Xilinx ZCU102 FPGA board, operating at 200MHz with a power consumption of 15.08W during inference on the 110-million-parameter BERT-Base and 345-million-parameter GPT-2 Medium transformer models. Coupled with the proposed algorithm and dataflow optimization, it enables on-chip storage of all necessary parameters, minimizing off-chip memory access. Experimental results demonstrate that our FPGA accelerator significantly outperforms existing solutions, achieving energy efficiency improvements ranging from2.22×to17.23×over state-of-the-art FPGA accelerators."
  },
  {
    "year": "2025",
    "abstract": "Modern electronic devices like smart bands, smartwatches, smartphones, and treadmills are widely used to track exertion metrics, also called energy expenditure, such as step counts, running, time, and distance. However, these devices often fail to meet the needs of individuals with mobility impairments, such as wheelchair users, for whom such metrics are hard to evaluate. This research introduces a tailored model to track and quantify exertion data for manual wheelchair users. The existing Heart Intensity Metric (HIM), which relies on parameters such as heart rate, weight, age, and time (exercise duration), is adapted with a revised Activity Intensity Assessor (AIA). The model incorporates critical factors for wheelchair users, including heart rate, adjusted movement status (1 for movement and zero for no movement), and inclination status, with new parameters, such as Metabolic Equivalent of Task (MET), and wheelchair speed. The revised AIA is then adapted for the energy expenditure formula to calculate calorie-burning estimation specifically for manual wheelchair users. The revised approach minimizes false positives commonly produced by existing approaches for manual wheelchair users, especially in scenarios involving non-movement exercises like upper limb activities. Unlike prior models, the proposed AIA ensures precise energy expenditure calculations, even during stationary activities, and reflects a zero-calorie expenditure when no exercise occurs. Results are statistically verified and demonstrate that traditional formulas yield inaccurate calorie estimations for wheelchair users, while the revised model aligns better with physiological realities. This work provides a practical framework for designing electronic tools that effectively track energy expenditure/total energy (ET), also known as exertion efforts, and estimate calories burnt by manual wheelchair users. The scope of this study is limited to examining energy expenditure exclusively for manual wheelcha..."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we propose an innovative, environmentally friendly, and efficient technology for concrete curing through induction heating. This technology is complemented by a comprehensive design methodology aimed at achieving uniform heating across the formwork surface. Induction heating concrete curing is a new approach based on the principle of electromagnetic induction for the purpose of concrete curing, and it offers improved heating efficiency and safety in formwork heating. However, the heating range of the formwork surface is limited depending on the induction heating coil. Thus, we introduce a coil structure derived from evaluations of formwork’s surface temperature distribution through finite element analysis simulations. Heating experiments were conducted on formwork without concrete and formwork with concrete, using a coil designed through simulation. In the experiment without concrete, a uniform temperature distribution was confirmed with a small temperature deviation of 4.28°C. For the experiment with concrete, induction heating experiments and steam curing experiments were conducted at low and room temperatures to compare surface temperature distribution, power consumption, and concrete strength. The experimental results show that room temperature induction heating has 11.39% higher strength and 41.86% less power consumption than low temperature induction heating curing. It also shows 3.51% higher strength and 30.56% less power consumption than steam curing. Room temperature induction heating curing is superior to steam curing in terms of strength and power consumption. Also, although low temperature induction heating curing has lower performance than steam curing, the difference is not significant, so it can be a feasible alternative."
  },
  {
    "year": "2025",
    "abstract": "Detection of movement from electroencephalogram (EEG) signals is crucial for advancing brain-computer interface (BCI) systems, particularly in rehabilitating individuals with disabilities. This study focuses on decoding two types of ipsilateral movements (right arm and thumb) and the resting state from EEG signals—a challenging task due to the reduced signal discrimination between ipsilateral movements. To address this challenge, we propose a novel framework that combines precise segmentation of EEG signals during movement with an improved feature extraction method. First, we detect accurate segmentation of EEG signals by using the teager-kaiser energy operator for electromyographic (EMG) signals, which allows for precise detection of the onset and end of movements. Next, for feature extraction, we developed the regularized correlation-based common spatio-spectral patterns (RCCSSP) algorithm, which improves the traditional common spatial patterns (CSP) by incorporating regularization based on correlation. RCCSSP employs spatio-spectral canonical correlation analysis (SS-CCA) with an advanced regularization approach. Specifically, this method calculates the correlation between two classes for each channel, assigning higher weights to channels with lower correlation to increase their impact while minimizing the effect of noisy channels with higher correlation. Classification is then performed using distance-weighted k-nearest neighbor and support vector machine algorithms. Experimental results from 15 healthy subjects demonstrate that the proposed approach achieves an average classification accuracy of 88.94%, representing a significant 11.66% improvement over the best-reported method. This work highlights the potential of precise movement segmentation and robust feature extraction in decoding ipsilateral movements for BCI applications."
  },
  {
    "year": "2025",
    "abstract": "The increasing complexity and dynamic nature of financial data present significant challenges in accurately predicting credit risk, a critical task in the banking and finance sector. The application of machine learning (ML) in credit risk prediction has been hindered by the imbalanced nature of credit datasets. This study proposes an improved approach for predicting credit risk using a stacked ensemble method combined with a hybrid data resampling technique. The ensemble comprises random forests, logistic regression, and a convolutional neural network (CNN) as base learners, with the multilayer perceptron (MLP) serving as a meta-learner. To address the data imbalance, the Synthetic Minority Over-sampling Technique and Edited Nearest Neighbors (SMOTE-ENN) technique were applied. The proposed approach is benchmarked against other well-performing classifiers, including random forest, logistic regression, MLP, and CNN. The integration of hybrid data resampling with a robust stacking ensemble significantly enhanced credit risk prediction, with the proposed approach achieving sensitivity and specificity of 0.921 and 0.946 for the Australian dataset and 0.928 and 0.891 for the German dataset. Also, the stacked classifier achieved a sensitivity and specificity of 0.000 and 1.000 before data resampling for the Credit Risk Classification dataset with an accuracy of 0.7644. After data resampling, the accuracy, sensitivity, and specificity are 0.8056, 0.7989 and 0.8125, respectively. On the other hand, using the credit risk analysis for the extended banking loans dataset, the accuracy, sensitivity and specificity of the stacked classifier before data resampling are 0.8429, 0.6316, and 0.9216, respectively. After data resampling, the accuracy, sensitivity and specificity scores of the stacked classifier trained using the credit risk analysis for the extended banking loans dataset are 0.9632, 1.0000, and 0.9242, respectively. This shows that after data resampling, the performance..."
  },
  {
    "year": "2025",
    "abstract": "Digital Twin (DT) aims to seamlessly replicate physical objects or processes in virtual environments, garnering attention for supporting diverse intelligent management services such as monitoring, analysis, and control. Integration with technologies like artificial intelligence (AI), big data, edge computing, and the Internet of Things (IoT) has propelled the development of DTs. However, the DT may not only introduce new potential security flaws but also inherit existing vulnerabilities from the technologies they incorporate and interact with due to their integration with diverse technologies. Despite its growing impact, research addressing the security concerns of DTs remains insufficient and still in its early stages. In this article, we provide a comprehensive and in-depth review of the current state of DTs, focusing on their security aspects. We first depict an overview of DTs, including the definition of the DT and various DT applications, and then present the architecture for DTs. Subsequently, we conduct a detailed examination of security attacks and threats across the functional layers of the DT architecture. In contrast to the previous surveys on DTs, we derive security properties and security functional requirements (SFRs) based on the Common Criteria (CC) standard for mitigating these attacks and threats. We also introduce technologies that enable the achievement of SFRs with a future research perspective. By addressing these critical security aspects, our article enhances the security and trustworthiness of DTs, contributing to their safe and reliable deployment in various domains."
  },
  {
    "year": "2025",
    "abstract": "Single-view novel view synthesis, the task of generating images from new viewpoints based on a single reference image, is important but challenging in computer vision. Recent advancements in novel view synthesis have leveraged Denoising Diffusion Probabilistic Models for their exceptional ability to produce high-fidelity images. However, current diffusion-based methods typically utilize camera pose matrices to globally and implicitly enforce 3D constraints, which can lead to inconsistencies in images generated from varying viewpoints, particularly in regions with complex textures and structures. To address these limitations, we present Light Field Diffusion, a novel conditional diffusion-based approach that transcends the conventional reliance on camera pose matrices. Starting from the camera pose matrices, Light Field Diffusion transforms them into light field encodings, with the same shape as the reference image, to describe the direction of each ray. By integrating the light field encoding with the reference image, our method imposes local pixel-wise constraints within the diffusion process, fostering enhanced view consistency. Our approach not only involves training Image Light Field Diffusion on the ShapeNet Car dataset but also includes fine-tuning a pre-trained latent diffusion model on the Objaverse dataset, which enables our Latent Light Field Diffusion model to exhibit remarkable zero-shot generalization capabilities across out-of-distribution datasets like the Ray-traced multi-view synthetic dataset, Google Scanned Objects dataset, and in-the-wild images. Experiments demonstrate that Light Field Diffusion produces high-fidelity images and achieves superior consistency in complex regions, outperforming existing novel view synthesis methods."
  },
  {
    "year": "2025",
    "abstract": "Lithium-ion batteries (LIB) are the mainstream technology for energy storage in several industrial segments, such as mobility and stationary systems for solar, wind, or other alternative energy source. This technology has a long lifetime, low self-discharge, high capacity and density, and can store energy longer. Despite that, LIB is suitable to supply power for electric mobility if its state of health (SOH) is higher than 80%. Then, an alternative for batteries with SOH below that is recycling or second-life batteries (SLB). The first is expensive and complex; only some companies retain the technology. Still, the SLB can be an excellent solution to maintaining LIBs in operation for slow vehicles or stationary systems. However, SLB requires intelligent battery management systems (BMS) because the packs are composed of cells with different characteristics, which makes the operation more difficult. This work presents a system consisting of two Machine Learning (ML) layers to automatically estimate the state of charge (SOC) of SLB independent of the battery’s capacity or age. In the first phase, a Random Forest (RF) model was built and trained to discover the curve capacity of different SLB characteristics and capacities. After the capacity curve selection, in the second phase, a new RF model was built and trained for each capacity curve to make SOC inferences of the batteries. The discharge data curve of one hundred batteries was used for the development, whereas eighteen were used for the training and eighty-two for tests. The results indicated a root square mean error (RSME) below 45 mAh for the capacity estimation (phase 1), and an RSME below 0.87% was found in the second phase for the SOC estimation. Finally, the capacity and SOC models have been inserted in a Raspberry system to measure the main parameters of SLB (voltage and current) and make inferences in real time independent of the cell’s age. The results showed an RSME below 100 mAh for the first layer and b..."
  },
  {
    "year": "2025",
    "abstract": "The rapid proliferation of Internet of Things (IoT) devices has led to a substantial increase in network packet traffic, raising significant privacy concerns. Although traffic encryption is employed to protect the privacy of IoT devices, attackers can still leverage Machine Learning (ML) and Deep Learning (DL) techniques to classify device types by analyzing packet characteristics, such as size and timing. The main challenges in the state of the art are the lack of effective methods for exposing privacy violations in encrypted IoT traffic, and the absence of robust defense mechanisms to mitigate privacy breaches caused by network traffic analysis. Considering these challenges, this study presents two key contributions: (i) a novel vector-based classification method that enhances device-type identification from encrypted IoT traffic using advanced ML and DL techniques, and (ii) a robust defense mechanism based on Differential Privacy (DP) and advanced padding techniques against traffic analysis attacks. Therefore, the study examines privacy risks associated with sequential IoT device data and evaluates the effectiveness of ML algorithms using two datasets. The results demonstrate that the proposed vector-based classification method significantly improves the attacker’s classification accuracy, even when privacy-preserving techniques, such as padding, are used to obscure device-type classification. For this purpose, the study evaluates eXtreme Gradient Boosting (XGBoost), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) for IoT traffic classification, achieving an accuracy rate of 99.61% with XGBoost, 96.74% with LSTM, and 96.94% with GRU. Additionally, the Decision Tree (DT), Random Forest (RF), k-Nearest Neighbors (kNN), and GRU classification algorithms are also evaluated and compared with the XGBoost and LSTM classifiers for the proposed attack model. As a defense mechanism, DP is applied using the Fourier Perturbation Algorithm (FPA) to optimize padd..."
  },
  {
    "year": "2025",
    "abstract": "In recent years, multimodal 3D object detection methods have garnered significant attention in autonomous driving systems due to their impressive detection performance. However, most existing research seldom addresses the issues of robustness and performance degradation in dynamic environments due to the difficulty of aligning modal features. In this paper, we introduce an innovative efficient fusion method that integrates time series features to improve the accuracy of 3D object detection through multi-sensor fusion, making it more suitable for dynamic and realistic scenarios such as automated driving, and verifying its robustness. The proposed framework incorporates a Temporal Local Self-Fusion Module (TLSFM) in the LiDAR stream to enrich the representation of LiDAR BEV features. To better align BEV features in image streams and point cloud streams, a Cross-Modal Fusion Alignment (CMFA), is introduced. The Temporal Fusion-CMFA (TF-CMFA) framework which contains TLSFM and CMFA module, demonstrates state-of-the-art performance, achieving a mean average precision (mAP) score of 74.4% and a NuScenes detection score (NDS) of 75.7% on the NuScenes benchmark dataset. Performance improvements recorded on the Waymo dataset, with improvements of +2.1 and +2.3 in the ALL-L1 and ALL-L2 metrics compared to VoxelMamba. Finally, robustness experiments demonstrate the performance of proposed approach under sensor failure conditions, demonstrating its exceptional robustness under such conditions."
  },
  {
    "year": "2025",
    "abstract": "Low-resource machine translation holds significant practical importance for the translation of small languages. Currently, the primary challenge in low-resource machine translation is the scarcity of bilingual parallel corpora. To address this issue, this paper proposes a SE-Enhancer model based on enhanced SimCSE. We first introduced an embed-fusion module to integrate word embeddings and sentence embeddings, thereby enriching the feature representation of source sentences. Then, a layer fusion module based on feedforward neural networks and self-attention is integrated into the model to reduce information loss by integrating multi-layer features, enhancing the decoder’s translation capabilities and overall model performance. The experimental results demonstrate that SE-Enhancer achieves BLEU score improvements of 1.24, 1.37, and 1.11 over the Transformer baseline model on three common low-resource machine translation tasks from the IWSLT dataset. Length analysis further demonstrates that the model excels at capturing long-distance dependencies and exhibits strong generalization capabilities. In practical applications, this model can be utilized in low-resource fields such as legal, healthcare, and education translation."
  },
  {
    "year": "2025",
    "abstract": "Extracting road information from high-resolution remote sensing images has become a research hotspot in remote sensing image processing due to its cost-effectiveness and efficiency. Current road extraction methods generally face challenges such as large parameter sizes and limited accuracy when dealing with roads at different scales. To overcome these limitations, this study proposes a novel lightweight attention network model (ESLiteU2-Net) to improve both efficiency and accuracy of road extraction. Based on U2-Net, the proposed model reduces complexity by a channel reduction strategy and introduces an Efficient Spatial and Channel Attention Module (ESCA). This innovative design enables the model to better capture and reinforce road features across both spatial and channel dimensions, resulting in significant improvements in extraction accuracy and robustness while maintaining a lightweight structure. Experimental results demonstrate that ESLiteU2-Net outperforms existing methods on the CHN6-CUG and Massachusetts road datasets. Compared to U2-Net, the proposed model not only achieves superior accuracy but also reduces computational load and parameter number by 30.98% and 81.91%, respectively, achieving a balanced combination of lightweight design, efficiency, and accuracy for road extraction."
  },
  {
    "year": "2025",
    "abstract": "Millimeter wave (mmWave, 30–100 GHz) communication is essential for meeting the high data throughput demands of 5G/6G networks. However, mmWave signals are highly susceptible to attenuation and blockage, necessitating directional beamforming antennas and efficient beam tracking algorithms. Traditional machine learning-based approaches, such as centralized learning (CL) and federated learning (FL), face significant challenges. While CL achieves fast convergence, it suffers from high computational costs and privacy concerns. Conversely, FL addresses these issues by enabling distributed model training but struggles with slow convergence and suboptimal accuracy due to data heterogeneity. To overcome these limitations, this paper introduces a novel clustered federated learning (CFL) framework for beam tracking. CFL leverages the benefits of FL while grouping users with similar data distributions, enabling the training of a single model per cluster. This approach reduces communication overhead, accelerates training, and improves accuracy. We analyze key attributes influencing user clustering and their impact on learning efficiency. Numerical results demonstrate that CFL significantly outperforms traditional CL and FL methods, achieving an 18% accuracy improvement over FL (specifically, the FedAvg algorithm) and an 11% enhancement over CL. These findings highlight the potential of CFL for enhancing beam tracking in mmWave systems, offering a more adaptive and privacy-preserving solution for future wireless networks."
  },
  {
    "year": "2025",
    "abstract": "Smart agriculture has grown significantly over the last few years, particularly with the integration of advanced technologies (e.g., the Internet of Things, robots, artificial intelligence, etc.), leading to the development of intelligent agricultural systems. However, these systems often lack data integration, interoperability, and semantic explainability. Various approaches have been proposed to address these challenges. This study provides a comprehensive literature review that addresses, on the one hand, the use of semantic resources (e.g., semantic web technologies and ontologies) to tackle data integration and interoperability in smart agriculture systems and, on the other hand, the integration of explainable artificial intelligence into smart agricultural systems. Furthermore, it aims to identify limitations in existing studies and explore potential avenues for future research. This research introduces key concepts related to smart agriculture, semantic resources, and explainable artificial intelligence. Subsequently, three clusters of studies are presented, including semantic resources for smart agriculture, leveraging the explainable artificial intelligence for smart agriculture, and the role of semantic resources in the explainable artificial intelligence-based agriculture systems. Lastly, the limitations of the semantic-based smart agriculture system are examined, along with potential future research areas."
  },
  {
    "year": "2025",
    "abstract": "Model-based testing (MBT) is essential in software testing, offering automation, comprehensive coverage, and defect prevention. It uses abstract models to automatically design and generate test cases, representing the expected system behaviour, including states, transitions, inputs, and outputs. This paper explores the action-state testing modelling technique, originally introduced by the authors in Forgács and Kovács (2000). In this approach, a model step comprises an action (input), one or more responses (outputs), and an optional state. The steps can be arranged sequentially, or they may be forked and joined. Sequential steps appear within the same test case. Forked steps are distributed across different test cases. The joined steps also belong to separate test cases. In addition, the graphical model can be constructed using a text editor. This paper builds upon the concept by establishing its theoretical foundation. We demonstrate how the action-state model eliminates the need for guard conditions and coding, maintains a concise and manageable structure, and seamlessly incorporates outputs, ultimately enhancing testing efficiency. Additionally, we provide guidelines for adding new states and empirically validate the benefits of action-state testing over alternative techniques, achieving a 100% defect detection percentage (DDP). This paper marks the first instalment of the author’s Test Design Trilogy, dedicated to refining and unifying various test design techniques."
  },
  {
    "year": "2025",
    "abstract": "Quantum technologies have emerged as vital tools for enhancing mobile communication security. The Samsung Galaxy series now features a quantum random number generator (QRNG) that offers true randomness, strengthening cryptographic protection. Despite its potential, QRNG integration remains largely unexplored in practical applications. This paper investigates the QRNG chip’s integration and functionality in the Samsung Quantum Galaxy smartphone through digital forensics and reverse engineering. We identified a lack of effective QRNG utilization in existing applications and addressed this gap by developing a secure instant messaging and VoIP application that combines QRNG with post-quantum cryptography (PQC). Our solution demonstrates that leveraging QRNG-generated randomness alongside PQC significantly improves security against emerging quantum threats, establishing a foundation for enhanced mobile data protection."
  },
  {
    "year": "2025",
    "abstract": "This study explored the public’s understanding of blockchain technology and its impact on the intention to use blockchain-based services for wider acceptance of blockchain technology. 400 South Koreans in their 20s and 30s were surveyed to assess their subjective and objective knowledge of blockchain technology and their intention to use blockchain-based services. Subjective knowledge and intention to use were evaluated using a 7-point Likert scale, while objective knowledge was assessed through a multiple-choice questionnaire, encompassing four subdomains: basic concepts, building blocks, features, and practical applications. The study revealed that 1) over half of the respondents rated their knowledge level as below ‘neutral’ (1 to 3 points) (253 out of 400); 2) the majority of respondents showed a low level of objective knowledge (380 out of 400 scored under 50%), especially regarding the technology’s building blocks; 3) a moderate-to-strong monotonic relationship was observed between subjective knowledge and the intention to use blockchain-based services (rs=0.580); and 4) a weak-to-moderate monotonic relationship was found between objective knowledge and the intention to use blockchain-based services (rs=0.334). The study underscores the importance of educating individuals to enhance their subjective and objective knowledge of blockchain technology to promote its broader acceptance."
  },
  {
    "year": "2025",
    "abstract": "The increase in the elderly population globally and the prevalence of chronic diseases among the elderly have resulted in rising healthcare costs worldwide. Utilizing the Internet of Things (IoT) and smart sensors to reduce healthcare costs and enhance the quality of life for the elderly is a highly effective and valuable solution. Effective monitoring can improve resource management in IoT-based healthcare systems. We conducted a systematic literature review (SLR) for elderly healthcare on the IoT to evaluate its various facets and key areas. The taxonomy of elderly healthcare studies in the IoT comprises six categories: smart homes, security and privacy, remote healthcare system, wearable devices, smartphone, healthcare and healthcare costs. Management of chronic diseases has the highest percentage of evaluation statistics in the field of smart homes, at 61%. In addition, 26% of smart homes in healthcare are devoted to behavioral characteristics and 13% to biological characteristics. Finally, this study highlights the visions and challenges of elderly healthcare articles and future work."
  },
  {
    "year": "2025",
    "abstract": "The increasing reliance on smart grids, coupled with the integration of renewable energy and growing cyber-physical interactions, has heightened the vulnerability of power systems to both power quality (PQ) disturbances and cyber-attacks. This paper presents an innovative detection framework that combines Nonsubsampled Contourlet Transform (NSCT) with Principal Component Analysis (PCA) and Support Vector Machine (SVM) classification to accurately detect and classify PQ disturbances under the influence of cyber threats, such as False Data Injection (FDI) and Denial of Service (DoS) attacks. The proposed methodology leverages NSCT’s multiscale decomposition capabilities to extract fine-grained signal features, while PCA optimizes feature selection for enhanced computational efficiency. Comprehensive experiments conducted on synthetic and real-world datasets validate the framework’s effectiveness, demonstrating superior detection accuracy, robustness to noise, and resilience against cyber-attacks. The proposed NSCT-PCA- SVM approach represents a significant step forward in ensuring secure and reliable smart grid operations."
  },
  {
    "year": "2025",
    "abstract": "This article introduces a path tracking control method for unmanned surface vehicle (USV), which uses finite-time adaptive fuzzy technology combined with command filter. Divide the path tracking control problem into the design of line of sight (LOS) guidance law and controller. Firstly, in response to disturbances in the marine environment, a side slip angle update rate and expected guidance angle are designed. Secondly, an adaptive fuzzy control strategy is proposed to approximate and compensate for model uncertainty and changes in state variables, in order to improve system robustness. Simultaneously utilizing an improved finite-time command filter and backstepping method to control the required guidance angle for yaw angle tracking. Finally, design an improved compensation mechanism to make the tracking control of the system more precise. The effectiveness of this method is verified through MATLAB simulation results."
  },
  {
    "year": "2025",
    "abstract": "Point-of-care ultrasound (PoCUS) is a valuable diagnostic tool for pericardial effusion (PCE). However, the time constraints for trainees and experts pose significant barriers to PoCUS learning. This study aims to develop a deep learning (DL) model for detecting and localizing PCE and to investigate the learning efficacy of using this model as an adjunct in PoCUS training. A total of 101 patients with moderate/large PCE and 104 controls without PCE were included, and the images were extracted from the ultrasound (US) clips. We applied preprocessing techniques, including standardized image sizes and background removal, to reduce interference, and post-processing techniques, including adding filters to refine small effusion regions. We developed three DL models based on U-Net, Res-UNet, and UNet++ and compared their performance. Additionally, 14 emergency medicine residents were recruited to complete classification and segmentation tasks on 10% of randomly selected US images. Personalized feedback from the best-performing DL model was provided. Three months later, the residents annotated another set of images. Their learning performance was also evaluated. The UNet++ algorithm surpassed the other two, attaining an impressive sensitivity of 96%, specificity of 97%, area under the curve (AUC) of 98%, intersection over union (IOU) of 81%, and minimal latency. The overall sensitivity increased by 4% in the classification task after training with the UNet++ model, although there were no statistically significant differences in all evaluation metrics. The UNet++ model achieved a balance between high accuracy, IOU, and latency. Although there were no significant differences in the evaluation metrics after UNet++-assisted learning, the overall sensitivity increased by 4%, indicating an improved ability to recognize true positives and reduce false negatives. Our results demonstrated that AI could enhance the interpretation of rare PoCUS conditions and reduce the time demands o..."
  },
  {
    "year": "2025",
    "abstract": "Model Predictive Control (MPC) is an Advanced Process Control technique able to handle constrained multivariable processes characterized by dead times. In these processes, dead times information covers a key role for control systems design and for the associated tuning procedures. This paper aims to assess the impact of input-output dead times on tuning procedures and grouping policies associated to output soft constraints in MPC based on linear models. An MPC problem characterized by hard constraints on the inputs magnitude and on the inputs slew rate and by soft constraints on the outputs magnitude is considered for the Description of the proposed approach. Window parameters, tuning parameters associated to slack variables and grouping policies for constraints relaxation represent the key points investigated in the work. In addition, a characterization of the proposed methods based on different input-output configurations and on the control matrix to be used at each control instant is presented. Simulation results based on first-order plus deadtime models show how the proposed methods can improve the effectiveness and the efficiency of MPC systems design."
  },
  {
    "year": "2025",
    "abstract": "A high-performance, compact microwave absorber was created using Fused Deposition Modeling (FDM) 3D printing. Both a narrowband and a broadband absorber were created. The narrowband absorber was designed at 4.9 GHz, mid-band in WR-187 waveguide. The broadband absorber tried to achieve the best attenuation across the entire 3.95 to 5.85 GHz band. Two types of carbon loaded polylactic acid (PLA) plastic and one type of unloaded PLA were 3D printed with variable percentages of air to achieve different values of effective dielectric constant and loss tangent. The absorber comprised five or six rectangular pieces of these plastic materials. The thickness and fill factor values for each piece were optimized to minimize reflection through fast analytic modeling in MATLAB. The results were then verified by HFSS simulation as well. The stack progressed from the lowest loss and lowest dielectric constant to the highest at the shorting end. The final narrowband load had simulated return loss of 87 dB at 4.9 GHz with an analytic solution in MATLAB. The measured return loss of the 3D printed attenuator was 73 dB at 4.929 GHz. The total length of the absorber was 2.44 inches. A commercial absorber for WR-187 with return loss of 40 dB has length of 13 inches. The experiment proves that an effective and compact microwave absorber can be created using 3D printing."
  },
  {
    "year": "2025",
    "abstract": "Many studies have been conducted on the implementation of game theory approaches in optimizing energy trading and scheduling in multi-microgrid (MMG) systems, both in cooperative and non-cooperative games. This is because game theory is a rich field of study that can illustrate the self-interest nature of each player, in this case, each agent in the MMG system. However, there are still various issues in its implementation, both technical and non-technical. This article will focus on a systematic review of various relevant and credible literature papers on the game theory-based on-grid MMG topic using the Kitchenham method. The on-grid MMG system differs from the off-grid MMG system in that each MMG is connected with the conventional grid. This connection provides more flexibility in operation and various features, including multi-level interactions beyond peer-to-peer, asymmetric agents, the presence of distribution network operator, support and backup power from the grid, and an energy market pool. This literature review is done by collecting, analyzing, and understanding the issues and challenges in the implementation, the types of games and algorithms, techniques, and solution approaches used, as well as determining how far each game and existing solution can solve these problems. From the systematic review result, in general there are two types of games that can be played between agents: cooperative and non-cooperative, each with its own pros and cons. The technical issues and solutions in these games have been summarized with particular concern related to power systems, renewable energy, energy storage, agent interests, uncertainties, ICT, privacy and security, computation solutions, mechanisms, and cost and revenue. Research and future works recommendation related with on-grid MMG game theory subject is also described."
  },
  {
    "year": "2025",
    "abstract": "In this study, we propose a novel interaction method, TouchWIM, which combines World in Miniature (WIM) and Hybrid User Interface (HUI) to enhance the efficiency of object manipulation and reduce the workload in spatial design by using Augmented Reality (AR). WIM provides an additional overview perspective in AR by displaying a miniature representation of a room, and HUI enables an accurate and easy input by combining a head-mounted display (HMD) with a tablet. Our system allows the placement and manipulation of objects within a real space by touch interaction with the miniature representation of the room displayed on the tablet. To evaluate TouchWIM, we conducted user studies using a prototype spatial design system, comparing it with existing methods such as Hand-Ray + Direct Touch and WIM alone. The results demonstrated that TouchWIM is the most efficient and reduces the workload for the task of creating a specified spatial layout. This interaction method provides new insights into object manipulation and spatial design in AR."
  },
  {
    "year": "2025",
    "abstract": "Video streaming applications have experienced significant growth in recent years, driving an increase in global internet traffic. This rapid expansion underscores the critical need to ensure a high Quality of Experience (QoE) for users, as subpar video QoE can result in considerable financial losses for telecommunication providers. Traditional approaches, such as the Mean Opinion Score (MOS), while widely used for assessing QoE, are inherently subjective and require significant manual effort. This research addresses these limitations by introducing an advanced framework integrating multiple models and methodologies to enhance video QoE in 5G networks. The proposed framework features a novel Hybrid EnhancedXGBStackQoE (EXGBStackQoE) analytical model that applies a two-level stacking technique combined with 5-fold cross-validation to mitigate overfitting. At the initial level, various machine learning (ML) models are trained using the entire dataset, while the subsequent level leverages meta-features generated from the initial predictions to improve overall accuracy. This hybrid model demonstrates an accuracy improvement of 5–7% compared to traditional models, establishing a new standard in QoE evaluation. Additionally, the framework incorporates a Stackelberg Game-based Software-Defined Networking (SbSG) model designed for efficient data offloading in 5G Macro Base Stations (MBS). This model employs economic incentives and traffic load balancing to strategically select users for offloading, prioritizing those with lower QoS based on the Received Signal Strength Indicator (RSSI). By optimizing data distribution between MBS and Heterogeneous Networks (HetNets), the SbSG model enhances both network throughput and service quality. This comprehensive framework addresses critical challenges in video QoE optimization, providing a robust and automated solution tailored to the demands of next-generation networks."
  },
  {
    "year": "2025",
    "abstract": "Electric Vehicles (EVs) are essential to achieving the 2030 United Nations Sustainable Development Goals by reducing emissions and improving air quality. The strategic placement of Electric Vehicle Charging Stations (EVCSs) in urban areas is critical to supporting the transition to clean transportation. However, as EV adoption increases, challenges such as rising power losses, voltage profile degradation, and voltage instability emerge within microgrids. These issues can be mitigated by integrating Energy Storage Systems (ESSs) to enhance efficiency. This study presents an integrated planning approach to optimize the allocation of EVCSs based on the spatial-temporal distribution of traffic flows. A stochastic model is also introduced to determine the optimal placement of the energy storage system, accounting for uncertainty factors such as fluctuating electrical loads and the intermittency of renewable energy sources. The energy storage system allocation model is formulated as a multi-objective optimization problem aimed at improving voltage profiles, minimizing power losses, and maximizing voltage stability. The mathematical models of EVCSs and ESSs, and an economic analysis of the microgrid is included, considering the costs associated with energy storage system integration. The proposed model’s effectiveness is validated through a case study on a benchmark transportation network, with results indicating its ability to mitigate the negative effects of EV integration on microgrids. Additionally, the study introduces a stochastic framework to simulate the inherent uncertainties in electrical loads and renewable energy sources."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a comprehensive study on the application of advanced control methods to the Double Inverted Pendulum on a Cart (DIPC) system. The focus is on the design and implementation of swing-up control laws, balancing strategies, and disturbance rejection techniques to achieve robust system stability. The control scheme integrates energy-based controllers (EC) with stabilizing controllers based on sliding mode control (SMC), including a variant incorporating the H-infinity norm, to address the challenges of swinging up and stabilizing the pendulums and the overall DIPC system. Simulation results demonstrate the effectiveness of these controllers in bringing the DIPC system from the Down-Down position to the Up-Up position. During the transition from Down-Down to Up-Down, the SMC controller combined with the H-infinity norm has shown superior performance in reducing disturbance effects compared to traditional SMC controllers. The proposed control framework is expected to contribute significantly to the control of nonlinear and complex systems like DIPC, with potential applications in various fields."
  },
  {
    "year": "2025",
    "abstract": "In order for robots to navigate successfully, they need to correctly estimate the traversability of their surroundings. To do so, an orthogonal projection of the spatial obstacles perceived by the robot’s sensors is usually utilized. As the sensors can only see the surfaces closest to them, it is difficult to judge the traversability without guessing the shape of the obstacle. In this work, we introduce a novel approach that can estimate the obstacle’s 2D footprint straight from incomplete 3D data in the form of a point cloud. Unlike existing point cloud completion methods, we formulate the problem such that our approach does not require the reconstruction of the entire 3D object and subsequent projection. Instead, it focuses on rendering a 2D representation directly from segmented sensor scans, even if the available points are very sparse. At its core, we propose a lightweight, multi-modal autoencoder that takes an input of a voxelized incomplete point cloud and outputs an estimated footprint that is directly applicable to the occupancy grid. In the absence of similar methods, we validate the proposal on a real dataset coined UR, which was collected specifically for this publication, and prove the method’s applicability in real-life scenarios. The system achieves good performance even on point clouds with as few as 30 points. Additionally, we utilize an open-source synthetic dataset to compare our method, in an indirect fashion, with available point cloud completion algorithms by projecting their outputs on a 2D plane. Compared to other pipelines, our method proves superior in terms of computational resource consumption in complete robotic pipeline tests and achieves satisfactory accuracy on various test objects. We provide collected UR data to the community under the Repository."
  },
  {
    "year": "2025",
    "abstract": "Heart disease is considered as one of the leading causes of death worldwide. Predicting heart diseases from retinal fundus images is a promising approach in the early detection and monitoring of cardiovascular health conditions. The change in the retinal microvasculature is an indication towards systemic diseases such as cardiovascular diseases and hypertension. This study aims to explore the potential use of deep learning for early detection and prediction of cardiovascular health. through retinal images. The connection between the heart and the small blood vessels are called microvasculature. Imaging the retinal vessels provides a noninvasive way to study the cardiovascular system. By leveraging the potential of Convolutional Neural Network, retinal images are analyzed to identify patterns and anomalies which strongly correlates with cardiovascular conditions. Experimental results show that our method improves the accuracy in prediction of heart diseases, hence opens a novel and improved non-invasive approach to predict Cardiovascular diseases."
  },
  {
    "year": "2025",
    "abstract": "The purpose of this study was to investigate the relationship between workload and in-game technical and athletic performance. To achieve this,A modeling approach that predicts multiple numerical output variables simultaneously, particularly useful when these outputs are correlated (multi-output regression) models were used to predict 7 performance indicators based on previous training and game athletic workloads measured by Inertial Measurement Units (IMU) indicators, previous in-game actions annotated by staff members and game contextual factors. We compared 4 single-output models (kNN, regression tree, random forest and(NN) Predictive models inspired by the human brain, used in this study for multi-output prediction in sports performance analysis (neural networks)), their multi-output counterparts and aA baseline model predicting future performance as the average of each player’s past performance, serving as a simple reference for comparison with more complex models (dummy baseline) (predicting the average performance of each player over the last month) in terms of average(Root Mean Squared Error) A measure of the quadratic difference between predicted and actual values in regression models (RMSE) (aRMSE) during aAn evaluation method where past training and game data are used sequentially to predict performance of the next game (chronological evaluation) where previous trainings and games data are used to train models to predict the next game performances. Overall, the use of multi-output regression models enabled a decrease of the average predictive error (A metric for prediction error that evaluates model accuracy in terms of average squared errors across multiple outputs in a multi-output models (aRMSE) = 4.23) in regards to their single-output counterparts (aRMSE = 4.35) while providing a significant decrease of average computation times (4.75 to 0.82 seconds). Among the 4 multi-output models, only the kNN (aRMSE = 3.852) and random forest (aRMSE = 3.888) per..."
  },
  {
    "year": "2025",
    "abstract": "The mining industry is undergoing a transformational shift driven by automation and digitalization, enabling the teleoperation of machinery, improving safety, and enhancing operational efficiency in challenging underground environments. However, achieving safe and efficient teleoperation requires meeting stringent wireless communication requirements for low latency and high throughput. There is no unified consensus on the communication requirements or the most suitable technologies for different teleoperation modes, such as remote driving, assistance, and monitoring. This paper systematically reviews the literature on wireless communication challenges for underground mining teleoperation, identifying open research problems, proposed solutions, and key findings. The included studies are categorized into six thematic research areas, with teleoperation modes mapped to different levels of automation. Additionally, studies characterizing radio wave propagation in underground mine environments and evaluating various communication technologies are analyzed to define communication requirements in terms of deadlines, reliability, latency, and data rate for different teleoperation modes. The performance metrics used in the reviewed studies are also defined and attributed to the six thematic research areas. The findings of this systematic review highlight Wi-Fi, LTE, and 5G as the prevailing technologies for underground mine teleoperation. Moreover, the identified research gaps underscore the need for further research on handling communication outages, achieving low latency and high throughput for improved QoS, hybrid communication technologies, enabling a higher level of autonomy, and designing communication solutions tailored to specific teleoperation scenarios."
  },
  {
    "year": "2025",
    "abstract": "The integration of wearable sensors with artificial intelligence forms the base for analyzing physical activities through digital signal processing, numerical methods, and machine learning. Computational intelligence and communication technologies enable personalized monitoring, training, and rehabilitation, with applications in sports, neurology, and biomedicine. This paper focuses on motion analysis in alpine skiing using real accelerometric, gyroscopic, positioning, and video data to evaluate ski movement patterns. The proposed methodology employs functional transforms to estimate motion patterns and utilizes artificial intelligence for signal segmentation and feature classification related to lower limb movement. Machine learning results indicate differences in energy distribution before and after ski turns and demonstrate the feasibility of classifying associated motion patterns with accuracies of 98.1% and 90.7%, respectively, using a two-layer neural network. The interdisciplinary application of computational intelligence in this domain enhances motion analysis, injury prevention, and performance optimization. This study highlights the unifying role of digital signal processing, which uses similar mathematical tools across various applications."
  },
  {
    "year": "2025",
    "abstract": "Vehicle location prediction and the use of vehicle location tracking are increasingly important topics of discussion among connected vehicle researchers. Location tracking for mobile users is essential due to the correlated services and to improve the quality of service; however, it is challenging. On the other hand, the stateless predictive model is unsuitable due to lower accuracy and mismatched pattern analysis. This paper proposed a vehicle location prediction model using machine learning based on a case study of a campus shuttle bus scenario. Firstly, this paper comprehensively analyzes the recent research on vehicle location prediction models and provides a complete taxonomy. The proposed model uses the Support Vector Regression (SVR) based vehicle location predictive model in the implementation phase. In addition, a significant time-series predictive model, ARIMA, is configured and tested. Moreover, the seasonal ARIMA model is experimented with to predict the location of a mobile vehicle. The whole experiment is performed on a real dataset based on the university shuttle bus service. The results of the experiments, analysis, and discussions on the proposed model show the accuracy and effectiveness of its use on others. As a result, seasonal ARIMA outperformed ARIMA and SVR infractions."
  },
  {
    "year": "2025",
    "abstract": "Parkinson’s disease (PD) is a prevalent neurological disorder that significantly impacts posture and gait, leading to movement abnormalities due to malfunctions in the brain and nervous system. Gait signals are essential for identifying PD, and various techniques have been employed for classification, with a focus on spatiotemporal factors. Additionally, cognitive monitoring systems for PD symptoms have been developed. Recent advancements involve decomposing gait signals using techniques such as empirical mode decomposition (EMD), empirical wavelet transform (EWT), and variational mode decomposition (VMD) to streamline data for improved computational efficiency. Machine learning (ML) and deep learning (DL) algorithms are widely used to enhance classification accuracy. This study integrates decomposition techniques with ML algorithms such as support vector machines (SVMs), artificial neural networks (ANNs), decision trees (DTs), and k-nearest neighbors (k-NNs), as well as DL algorithms such as long short-term memory (LSTM), bidirectional long short-term memory (LSTM), and convolutional neural networks (CNNs), for PD classification. The combination of VMD with the 1D-CNN achieved the highest accuracy, sensitivity, and specificity, with values of 99.1 %, 100 %, and 100 %, respectively. This finding suggests a promising approach for further research in this field. The optimized VMD-1D-CNN combination demonstrated significant potential for accurately diagnosing PD based on gait dynamics. The successful application of these methods highlights the importance of advanced signal processing techniques in improving the detection and management of neurological disorders."
  },
  {
    "year": "2025",
    "abstract": "The zero-outage secrecy with energy harvesting is considered in short packet IoT-aided cellular cooperative networks using the inspired non-orthogonal multiple access (NOMA) strategy. The scheme ensures zero-outage secrecy through two cooperative transmissions: one for only artificial noise (AN) and another for both the artificial noise and the secure message. To ensure that only legitimate users can decode the message while the eavesdropper’s probability of success remains zero, which is so-called zero-outage secrecy, the scheme additionally employs the reverse training strategy to prevent the channel state information leakage to the eavesdroppers. The results show that the proposed scheme can achieve zero-outage secrecy for both IoT and cellular messages even in the case the eavesdroppers take advantage in their location or large number of antennas so that their channels become powerful. When forwarding the secure cellular message, the controller IoT node imposes the IoT message using such a large amount of harvested power that the IoT user can achieve the highest zero-outage secrecy throughput and energy efficiency, there is not much loss in the zero-outage secrecy throughput obtained at the cellular user. It also highlights that when the transmit power increases, the zero-outage secrecy throughput also increases, indicating the practical implementation of the proposed scheme."
  },
  {
    "year": "2025",
    "abstract": "To fully utilize the advantages of Connected and Automated Vehicles (CAV) in mixed traffic flow, this study focuses on investigating the car-following characteristics of mixed traffic flow. First, the potential car-following patterns in mixed traffic are analyzed, and an improvement to the Intelligent Driver Model (IDM) is made by incorporating dynamic response times. Next, based on the NGSIM and Gunter datasets, Genetic Algorithm (GA) are employed to calibrate and evaluate IDM parameters. Subsequently, an analysis of mixed traffic flow characteristics is conducted, including a sensitivity analysis of key parameters. Finally, the stability and safety of mixed traffic flow are analyzed. The results demonstrate that the improved numerical simulations closely match real-world data. CAV can enhance the stability of mixed traffic flow under certain conditions. The improved model provides a theoretical basis for analyzing future traffic flow characteristics."
  },
  {
    "year": "2025",
    "abstract": "Deep learning models employing the Transformer architecture have demonstrated exceptional performance in the field of multivariate time series forecasting research. However, these models often incorporate irrelevant or weakly relevant information during the processing of time series, leading to noise. This phenomenon diverts the attention mechanism from crucial features within the time series, thereby impacting the overall forecasting performance. To mitigate this issue, our study introduces DiffTST, which employs a Differential Transformer to enhance the model’s focus on relevant context within the time series, thereby mitigating the influence of noise on forecasting accuracy. The model utilizes independent channels to process time series data, ensuring that each input token contains information from a single channel exclusively. Furthermore, each channel is segmented into multiple patches to facilitate the extraction of local information. Subsequently, the Differential Transformer module is employed to process the sequence features of these patches, alleviating the tendency of Transformer-based models to allocate excessive attention to irrelevant sequence information. Ultimately, the forecast outcomes are derived through a Multi-Layer Perceptron. Our findings indicate that DiffTST achieves higher or comparable long-term forecasting accuracy compared to the current state-of-the-art Transformer-based models. On the main datasets (Weather, Traffic, Electricity), our method reduces MSE by 0.008, 0.087, and 0.023 and MAE by 0.004, 0.069, and 0.025 compared to PatchTST."
  },
  {
    "year": "2025",
    "abstract": "This study introduces a novel representation learning method to enhance unsupervised deep clustering in Human Activity Recognition (HAR). Traditional unsupervised deep clustering methods often struggle to extract effective feature representations from unlabeled data, failing to fully capture the true underlying structure of the data. As a result, classification performance is frequently suboptimal. To address this limitation, we propose leveraging an autoencoder integrated with models pre-trained on diverse HAR datasets to extract robust and transferable feature representations from target data. These representations are subsequently utilized within an unsupervised deep clustering framework, enabling effective discovery of the data’s latent structure and significantly improving clustering performance. The proposed method was evaluated on three HAR datasets and compared against conventional approaches, including autoencoder-based deep clustering and traditional classification methods such as k-means and HMM. As a result, the proposed method achieved F1 scores ranging from 0.441 to 0.781, significantly outperforming the baseline scores of 0.215 to 0.459. Furthermore, with fine-tuning using only 50 samples, the proposed method achieved even higher accuracy, with F1 scores ranging from 0.66 to 0.88. Additionally, it exhibited higher accuracy and robustness compared to traditional classification methods, highlighting its effectiveness in unsupervised learning scenarios. This study not only advances recognition accuracy in HAR but also demonstrates the potential of cross-dataset representation learning to effectively utilize unlabeled data. The proposed method offers a scalable and practical solution with broad applicability beyond HAR to other domains."
  },
  {
    "year": "2025",
    "abstract": "Writing assessment is one of the most important stages in the educational process, but it is also the most resource-demanding one. To address the challenges of scalability and inconsistency, this study proposes a Transformer-LSTM model for automated scoring and feedback generation, enhancing accuracy and reliability in assessment. Integrating the contextual reading abilities of transformers with the sequential analysis strength of LSTMs, the model analyzes significant metrics of writing quality, including grammar, coherence, and structure, while providing individualized, actionable feedback. Using annotated datasets and evaluation metrics like RMSE and feedback relevance, it was established that the model performs well overall and that improvements in grammar and coherence seemed to be the most significant contributors to writing ability. It was also demonstrated that feedback relevance enhances these outcomes, thus confirming its valuable role in promoting structural and grammatical accuracy. Understanding that most existing systems do not encourage significant human feedback, this work demonstrates a scalable approach with potential alignment with human evaluation standards. Finally, this study shows hybrid models’ promise for automated writing assessment as promising scalable, equitable, impact-based tools for global enhancement of educational outcomes."
  },
  {
    "year": "2025",
    "abstract": "4D millimeter-wave radar demonstrates considerable potential in the field of autonomous driving. It facilitates stable perception in adverse weather conditions and complex lighting environments, in addition to featuring low cost and high data-processing efficiency. The realization of Novel view synthesis (NVS) for 4D radar is of significant practical importance. However, due to the substantial disparities in the principles of point cloud generation between LiDAR and 4D radar, existing methods for NVS of LiDAR point clouds are not applicable to 4D radar. Specifically, during the process of projecting radar point clouds into cylindrical coordinates, radar produces irregular point distributions, in contrast to LiDAR’s regular angular resolution. This phenomenon results in range map that are filled with numerous empty pixels. Furthermore, the intrinsic irregularity in imaging and the prevalence of empty pixels compromise inter-frame geometric consistency, presenting a challenge that is distinct from LiDAR-based systems. To address these challenges, we associate ray-drop probability with viewpoints and utilize a U-Net architecture to learn the distribution of radar point clouds, effectively addressing data sparsity in a viewpoint-dependent manner. Extensive experiments demonstrate that our method achieves superior reconstruction results on both the publicly available VOD dataset, K-RaDAR dataset and Dual-Radar dataset."
  },
  {
    "year": "2025",
    "abstract": "In recent years, incidents involving drones have increased significantly, raising concerns over security and privacy, especially concerning civilian and military facilities. Vision-based approaches, especially those employing deep convolutional neural networks (DCNNs), show great promise in addressing the need for an accurate and cost-effective drone detection system. However, DCNNs rely heavily on extensive and well-labeled datasets, which are essential for achieving high accuracy and effectiveness. For drone detection tasks, a dataset of high-resolution images is especially valuable, as it provides more contextual information for DCNNs, enabling more accurate drone detection. This work presents a new drone detection dataset composed of 4K resolution images named University of Engineering and Technology Taxila 4K Anti-UAV (UETT4K Anti-UAV). The dataset is created by obtaining real-world videos of different types of drones in diverse environmental and challenging conditions. A custom dataset of 33601 images, manually annotated with hand-labeled bounding boxes, is created from these videos. We used our dataset to train, validate, and test eight state-of-the-art YOLOv6v3 algorithm models. The test results and qualitative analysis guide selecting the most suitable model for drone detection applications. The proposed extensive 4K dataset offers a valuable resource for effectively training deep learning models to detect drones across diverse conditions accurately."
  },
  {
    "year": "2025",
    "abstract": "Edge computing allows to do AI processing on devices with limited resources, but the challenge remains high computational costs followed by the energy limitations of such devices making on-device machine learning inefficient, especially for Support Vector Machine (SVM) classifiers. Although SVM classifiers are generally very accurate, they require solving a quadratic optimization problem, making their implementation in real-time embedded devices challenging. While Sequential Minimal Optimization (SMO) has enhanced the efficiency of SVM training, traditional implementations still suffer from high computational cost. In this paper, we propose Parallel SMO, a new algorithm that selects multiple violating pairs in each iteration, allowing batch-wise updates that enhance convergence speed and optimize parallel computation. By buffering kernel values, it minimizes redundant computations, leading to improved memory efficiency and faster SVM training on FPGA architectures. In addition, we present a embedded hardware-efficient FPGA architecture for the integrated SVM learning based on Parallel SMO with SVM inference. It consists of SVM controller that schedules the operations of each clock cycle such that computations and memory access happen concurrently. The dynamic pipeline scheduling employ parameterized modules to schedule linear or nonlinear kernels and produce dimension-based reconfigurable blocks. A configuration signal turns on corresponding sub-blocks and clock-gating unused ones, thus enhancing resource utilization efficiency, energy efficiency, and overall performance. In several benchmarking data sets, the scheme reduces clock cycles per iteration consistently and improves throughput (up to 2427 iterations per second). It achieves up to 98% accuracy in classification with low power consumption, as reflected by training power of47mWand high energy efficiency (up to51.64e+3iterations per joule). With the assistance of an adaptive kernel datapath, para..."
  },
  {
    "year": "2025",
    "abstract": "Searchable encryption, also known as secure search, is a technology that enables search operations on encrypted data while maintaining confidentiality. Extensive research has been conducted on searchable encryption utilizing public key and symmetric encryptions. However, public key encryption incurs significant computational expenses and is inefficient for querying large databases, particularly in cloud settings. Hence, we focus on searchable encryption using a secret sharing scheme (also known as searchable secret sharing), which is recognized for its minimal computational complexity. A secret sharing scheme is a method for transforming secret inputs into several distinct values known as shares. Kamal et al. (2021) introduced a simple searchable encryption method utilizing secret sharing schemes, yet did not include user access control capabilities. In this study, we introduce a secure search method with user access control that employs secure computation based on a(k,n)threshold secret sharing scheme, where every piece of data stored in the cloud has an owner, and owners grant access to users at their discretion. We assume a client-server model to perform secure computation between the owner, player, andn≥kcloud servers. Furthermore, we provide an in-depth analysis of the security aspects of our proposed distribution, query generation, and search processes, demonstrating that our approach is resilient to honest-but-curious adversaries with information from up tok−1computing servers. Moreover, we include an improved and efficient method using an(n,n)additive secret sharing scheme when assumingn=kcomputing servers. We compare the proposed methods in terms of their computational and communication costs. Finally, we present a detailed performance analysis using Python, including a comparison with conventional secret sharing-based methods."
  },
  {
    "year": "2025",
    "abstract": "This study examines the role of Technology Anxiety (TA), age, past use, and cybersickness in the adoption of Virtual Reality (VR) technology. Using an extended Technology Acceptance Model (TAM), the research integrates age and past use as antecedents of TA and evaluates their influence on perceived ease of use (PEoU), perceived enjoyment (PENJ), and user attitudes. Data from 206 participants were analysed using Partial Least Squares Structural Equation Modelling (PLS-SEM) following a VR pilgrimage experience. The findings challenge conventional assumptions, revealing that past VR use increased TA, contradicting prior studies that associate familiarity with reduced anxiety. Additionally, older users exhibited lower TA levels than younger participants, highlighting a potential shift in how age influences technology adoption. TA significantly enhanced PENJ, indicating that anxiety may amplify emotional engagement in immersive settings, rather than solely acting as a barrier. While TA enhanced PEoU, it had a negative correlation with cybersickness, suggesting that anxious users might interact with VR more cautiously, thereby limiting sensory mismatches. Moreover, cybersickness did not significantly influence attitudes toward the system, emphasizing the dominance of engagement over physical discomfort in emotionally significant experiences. Attitude toward the system strongly predicted use intention, highlighting the necessity of designing VR experiences that balance usability with emotional engagement. This study provides new insights into the psychological and demographic factors influencing VR adoption and offers practical strategies for optimizing user experience, particularly in religious and cultural applications."
  },
  {
    "year": "2025",
    "abstract": "Coffee cultivation is of extreme economic importance in many regions of the world, but productivity is hampered by the various diseases and pests that affect the leaves of the plants, damaging both the quality and yield of the harvest. In this context, deep learning presents itself as a promising solution for the automatic identification of plant diseases, reducing dependence on human inspection and increasing efficiency in crop management. In this sense, this study proposes a novel two-stage approach, detecting the diseased region of the coffee leaf and classifying the diseases into Miner, Rust, Cercospora and Phoma on coffee leaves. A new dataset, derived from the BRACOL and Diseases and Pests in Coffee Leaves datasets, was created and used to improve class balance and robustness. In the first stage, the YOLOv8 model is being used to detect the diseased regions. For the second stage, the InceptionResNetv2, DenseNet169, Resnet50 and ShuffleNet models are being trained and used to classify the detected region, and a modification to a low computational cost classification architecture called SmallPavicNet-MC is being proposed. The results obtained are compared and the performance analysis of the detection models shows that YOLOv8 obtained the best performance with a mAP (Mean Average Precision) of 85.1% and for classification the DenseNet169 model obtained the highest average accuracy with 97.93%. The SmallPavicNet-MC model presents itself as the best alternative with reduced complexity and an accuracy of 97.77%. The combination of promising performance and reduced computational cost suggests that SmallPavicNet-MC can be integrated into plantation monitoring systems, contributing to more effective management of diseases and pests affecting coffee production."
  },
  {
    "year": "2025",
    "abstract": "As time progresses, the use of higher frequencies becomes increasingly necessary due to the growing issue of frequency congestion. While discussions are ongoing regarding the potential use of millimeter-wave (mmWave) frequencies introduced in 5G for the Beyond 5G (B5G) / 6G era, the deployment of 5G mmWave networks has remained limited and less widespread. In addition, some countries and regions have already halted mmWave frequency allocations or paused base station installations. The primary reasons for this are the limited coverage of mmWave, which makes widespread deployment cost-ineffective, and the limited availability of mmWave-compatible devices. Therefore, this paper addresses the coverage challenges associated with mmWave to encourage the future adoption of higher frequencies. One promising technology for expanding coverage is analog relay stations (RSs), which offer a relatively low-cost and efficient approach to network area design. This technology has been extensively studied. However, in the mmWave band, the propagation environment is particularly challenging due to factors such as beamforming, blockage, and scattering caused by obstacles like trees and foliage. In this study, we conduct experimental evaluations of coverage enhancement and communication quality improvement by installing analog RSs within the B5G demonstration field at the Ookayama Campus of the Institute of Science Tokyo (formerly Tokyo Institute of Technology). The evaluations include a comprehensive assessment of the impacts of NLOS coverage enhancement using various relay topologies and improved tolerance against blockage, providing practical guidelines for deploying RSs in real-world environments."
  },
  {
    "year": "2025",
    "abstract": "With the continuous evolution of advanced large language models like GPT, the proliferation of AI-generated fake news presents growing challenges to information dissemination. Traditional text classification methods face difficulties in accurately detecting such content, due to their limited capacity to differentiate between authentic and fabricated news. To address this issue, this paper introduces a novel “Global-Local News Detection Model”, which combines BERT, Bidirectional Long Short-Term Memory (BiLSTM) networks, Text Convolutional Neural Networks (TextCNN), and attention mechanisms to enhance the detection of AI-generated fake news. A new dataset, generated using GPT-4 and covering 42 news categories, was developed to serve as a comprehensive and diverse foundation for training and evaluating the model. Experimental results indicate that the proposed model achieves an accuracy and F1 score of 0.82, surpassing traditional approaches."
  },
  {
    "year": "2025",
    "abstract": "Previous studies have revealed that the relationship between bike-sharing and the bus system in connecting metro stations is substitution and supplement. However, the choice integration mode of users between bike-sharing and bus for the last-mile connection to the urban metro has not been sufficiently studied. This paper aims to address this gap and explore to promote stable connection integration while easing the financial pressure of governments. To achieve this, evolutionary game theory was employed to examine the complex behavior interaction between governments and operations, taking into account subsidy policy phase-outs. This paper defined the ideal event and analyzed the impact of critical factors on the dynamic evolution process, and gained valuable insights. Subsequently, the game models and primary conclusions using actual traffic data were validated. Additionally, a sensitivity analysis of factors based on the dynamics simulation model was conducted. The results demonstrate that the adjustment of factors can promote the integration model optimization on subsidy phasing-out. The integration decision of factors with real data provides a valuable reference for governments and operations. The findings hold significant meaning in promoting connection integration and enhancing the overall attractiveness of metro transportation."
  },
  {
    "year": "2025",
    "abstract": "Computer simulations are ubiquitous in many scientific communities analyzing complex phenomena, such as physics, material science, medicine, and others. For simulations to yield credible insight, they must accurately represent key aspects of their real-world counterparts, making the calibration of simulation parameters crucial. Often, manual calibration is time-consuming, error-prone, and dependent on expert knowledge. Therefore, many algorithmic approaches have been explored, from heuristic-based and Bayesian methods to search and genetic algorithms. Such attempts often obtain good parameters, though at a high computational cost, as they require running the simulation many times to explore the parameter space. In contrast, the recently proposed model-bridge framework significantly speeds up this process by machine learning on a set of previous observations. In model-bridge framework, a complex simulation is represented by a simpler, uninterpretable surrogate; then, using past simulation data, a bridge model is trained to map predictions of the uninterpretable surrogate model to calibrated, interpretable simulation parameters. However, this approach introduces another problem: designing surrogate models and choosing their parameters. In this paper, we evaluate cross-validation and information theory-based model selection strategies for choosing the optimal surrogate models. Through experiments on synthetic signal and fluid dynamics simulations based on the finite element method, we show that model selection and the choice of the surrogate are essential to enabling high model-bridge performance, comparable to and surpassing established calibration approaches, at a fraction of the computational cost and time. Further, our experiments show that information theory-based methods such as Akaike information criterion (AIC) can obtain close to optimal models several orders of magnitude faster than cross-validation strategies. Finally, we discuss theoretical requirements whi..."
  },
  {
    "year": "2025",
    "abstract": "In the realm of face image quality assessment (FIQA), methods based on sample relative classification have shown impressive performance. However, the quality scores used as pseudo-labels assigned from images of classes with low intra-class variance could be unrelated to the actual quality in such methods. To address this issue, we present intra-class variance guidance for FIQA (IG-FIQA), a novel approach to guide FIQA training, introducing a weight parameter to alleviate the adverse impact of these classes. This method involves estimating sample intra-class variance at each iteration during training, ensuring minimal computational overhead and straightforward implementation. Furthermore, this paper proposes an on-the-fly data augmentation methodology for improved generalization performance in FIQA. Across various benchmark datasets, our proposed method, IG-FIQA, achieved notable accuracy improvements compared to conventional state-of-the-art (SOTA) FIQA methods and ensures stable performance in face recognition systems."
  },
  {
    "year": "2025",
    "abstract": "Sedimentary facies recognition plays a crucial role in geological exploration and oil-gas resource evaluation. However, traditional recognition methods are limited by their ability to extract local features and efficiently utilize unlabeled data, making it difficult to effectively handle complex sedimentary facies characteristics. To address this, this paper proposes an efficient sedimentary facies recognition method based on Vision Transformer (ViT) and weakly supervised deep multi-view clustering. First, we use ViT for feature extraction from sedimentary facies images, capturing global information through the self-attention mechanism, thereby enhancing the ability to recognize complex sedimentary facies patterns. Secondly, we introduce deep multi-view clustering, which integrates multi-angle features such as color, texture, and shape, improving the model’s robustness and classification accuracy. Additionally, we apply weak supervision, combining a small amount of labeled data with a large amount of unlabeled data, and use strategies like pseudo-labeling to enhance the model’s generalization ability and reduce the cost of data labeling. Experimental results show that this method achieves higher accuracy and robustness across multiple sedimentary facies datasets, significantly outperforming traditional Convolutional Neural Networks methods in recognition performance. This research provides a novel solution for sedimentary facies recognition, especially suited for scenarios with limited labeled data and complex, diverse features, and offers new research directions for future deep learning-based geological data analysis."
  },
  {
    "year": "2025",
    "abstract": "Augmented reality (AR) in the internet of things requires ultra-low latency, high-resolution video, and fairness in multi-user environments, which pose challenges for traditional cloud and edge computing. To address this shortcoming, we studied AR subtask offloading and resource allocation in a multi-hop, multi-access edge computing federation. Our approach improves the quality of experience (QoE) by optimizing video quality and reducing delay while ensuring fairness, which is modeled as the ratio between provided and required quality. Instead of sequential execution, we adopt parallel AR subtask dependency processing to minimize latency. We propose an improved deep deterministic policy gradient algorithm for efficient solution exploration. Additionally, we implement strict training process monitoring to optimize resource usage and ensure sustainability. Experiments demonstrate that our method improves QoE by nearly 8% compared with TD3 while cutting training time in half."
  },
  {
    "year": "2025",
    "abstract": "The rapid proliferation of IoT devices like smartphones, smartwatches, etc. has significantly elevated the quantity of data requiring execution. It poses challenges for centralized Cloud computing servers, such as latency overhead and increased consumption of energy. To address this, Fog computing has been incorporated in this research as a complementary paradigm to the Cloud-based computing model. It thereby reduces the huge distance between end-user IoT gadgets and the Cloud computing servers. In order to improve the latency and waiting time this research employs a Multi-Level Queue (MLQ) for classifying tasks based on their priority. For parallel processing, a Self-adaptive Fuzzy C-means++ (SaFCm++) approach has been applied to cluster the Fog computing nodes depending on the heterogeneity of the computational nodes. For efficient scheduling, a Dynamic Energy-and-Latency-aware Task scheduling (DELTa) approach has been proposed to optimize latency, makespan, and utilization of resources. Extensive simulations are carried out for different test cases considering task and machine heterogeneity, followed by a statistical analysis. The overall improvements of the proposed method over other baselines are 9.75% for makespan, 64.59% for service latency, 13.90% for resource utilization, and 12.75% for energy consumption. The proposed energy-efficient scheduling method effectively manages diverse tasks and resources, enhancing task processing efficiency while minimizing energy consumption and maximizing resource utilization. Furthermore, the value of the Friedman statisticsFFfor the proposed model is estimated at 5.44, which shows superiority over the crucial value for four methodologies and four evaluation matrices."
  },
  {
    "year": "2025",
    "abstract": "The grid-connected converter (GCC) in a grid-connected DC microgrid performs an important role in stabilising the interaction of the AC and DC sections. With the development of DC microgrids, the DC section will gradually integrate more distributed energy resources and be compatible with various system operations, so it will be increasingly challenging to design the controller of GCCs to ensure the whole-system stability. To address this problem, this paper proposes a hybrid impedance-based controller design from the whole-system stabilisation perspective. Based on the concept of hybrid impedance, a stability criterion considering the AC and DC coupling dynamics is proposed as a benchmark for the controller design of GCCs. In addition, with the help of linear matrix inequalities, a step-by-step algorithm is developed to automatically and efficiently tune the control parameter to achieve the desired design criterion. The effectiveness of the proposed method is verified through case studies including simulation and hardware-in-loop experiment. The further comparison study also shows that the proposed method has a stronger whole-system stabilisation ability compared to some reviewed methods. In some specific tests, the proposed method can limit the current THD to about 2% compared to other methods that cause the THD to exceed 20%."
  },
  {
    "year": "2025",
    "abstract": "The fibrillation index is a critical metric in paper manufacturing, quantifying the degree of fibrillation achieved during the pulp refining process. Optimizing this metric enhances both paper quality and production efficiency. However, traditional measurement methods—such as manual visual examination of pulp samples under microscopy—are slow, error-prone, and labor-intensive, limiting their scalability in industrial applications. This study proposes a novel method that integrates deep learning with image processing techniques to automate fibril detection and fibrillation index computation. The proposed method leverages the discriminative capabilities of convolutional neural networks (CNNs) with adaptive image processing techniques to overcome key challenges such as low contrast, image noise, and variability in fibril morphology. The patch-based classification approach effectively filters out irrelevant objects, especially those whose features visually resemble fibrils, thus improving fibril segmentation accuracy. The method was comprehensively validated against expert-labeled ground truth images and achieved a promising average error rate of0.4494±0.4187. Experimental results also demonstrate the strong robustness of the proposed method, with consistent performance across diverse refining conditions and image qualities, making it suitable for real-world application in the pulp and paper industry. Furthermore, this study paves the way for broader applications in materials science and biomedical imaging, where precise feature detection in microscopic images is essential."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a novel algorithm that leverages cutting-edge machine-learning techniques to accurately and efficiently detect AI-generated texts. Rapid advancements in natural language processing models have led to the generation of text closely resembling human language, making it increasingly difficult to differentiate between human and AI-generated content. However, misuse of such texts presents a serious and imminent threat to the quality of academic publishing. This underscores the urgent need for robust detection mechanisms to ensure information quality, maintain trust, and preserve the integrity of research publications. Our proposed model outperformed existing algorithms for accuracy with less computational complexity. The proposed model is a feature-based hybrid deep learning network that leverages part-of-speech tagging and integrates Bidirectional Long Short-Term Memory (Bi-LSTM) networks with Attention modules. The initial module extracts local contextual features using convolutional layers, followed by Bi-LSTM layers that capture long-term dependencies from past and future sequences. An attention mechanism highlights critical sequence components, enhancing the model’s focus on relevant data. The outputs from the attention and initial modules are concatenated through a residual connection, ensuring comprehensive feature representation. This combination is then fed into dense layers for final classification, effectively balancing feature richness and computational efficiency. The proposed model was evaluated on two benchmark datasets, achieving 85.00% and 88.00% accuracy, respectively."
  },
  {
    "year": "2025",
    "abstract": "Tunnel cracks, as one of the early indicators of tunnel damage, have a significant impact on the safe operation of tunnels. However, due to the complex lighting conditions, background noise, and diverse nature of cracks inside tunnels, traditional image segmentation algorithms often struggle to achieve sufficient accuracy in crack segmentation tasks. To address these challenges, this paper proposes a tunnel crack detection method. Firstly, a novel Dynamic Feature Enhancement Network (DFEN) module is designed to extract preliminary features using a feature extractor and selectively enhance feature representations through a gating mechanism. Additionally, a new Multi-Head Interaction Learning (MHIL) is introduced, facilitating feature sharing by incorporating information exchange across different attention heads, thereby improving feature representation capabilities. Lastly, the Adaptive Switchable Atrous Convolution (ASAC) module is introduced, combining the advantages of adaptive convolution and deformable convolution while incorporating Switchable Atrous Convolution (SAC) to enhance multi-scale feature capturing capabilities. Ablation experiments, through both qualitative and quantitative evaluations, demonstrate the effectiveness of the proposed method. Comparative analysis with existing semantic segmentation methods further confirms the superiority of the proposed method in tunnel crack detection."
  },
  {
    "year": "2025",
    "abstract": "A decision support system (DSS) is a computer-based tool used to improve decision-making capabilities for any organization by analyzing the available data. The heart-kidney (HK) model proposed in this paper, as a DSS, simulates the physiological processes of the heart and kidneys in the human body to support cancer detection. The first part of the HK algorithm is inspired by the functions of the heart, where blood molecules (solutions) are sent to the heart, simulating the processes of oxygenation and the pumping of oxygenated blood to the kidneys as a local search. The solutions generated by the heart are then fed into the kidney-inspired algorithm (KA), which performs filtration, reabsorption, secretion, and excretion. The heart component enhances the KA’s local search capability, guiding the algorithm toward optimal solutions. The HK model is evaluated on eight test functions, with results compared to those of the heart algorithm and KA alone. Additionally, the HK algorithm’s effectiveness as a decision support system is tested on benchmark classification and time series prediction problems, with statistical analysis against existing methods in the literature. Finally, the HK algorithm is applied to cancer detection from microRNA data, demonstrating its potential in optimizing decision-making processes in healthcare."
  },
  {
    "year": "2025",
    "abstract": "Digital twin cities integrated road damage inspection to support smart road infrastructure. The road’s condition was assessed using road damage survey metrics, and the issue was resolved manually. Real-time, automatically, and precisely employing artificial intelligence (AI) is needed to improve road safety and reduce maintenance costs. This research on road defect detection utilizes improved YOLOV7 (iYOLOV7) while multilevel hyperparameter optimization using combination of the Tree-Structured Parzen Estimator (TPE) and Search Space (SS). This model we call TPE-SS. The iYOLOV7 provides real-time processing on edge devices that have limited storage, low-speed processors, and memory. The research investigates how leveraging multilevel hyperparameter optimization using the TPE-SS model improves system performance where road damage is detected. The results of iYOLOV7 model demonstrate the smallest total loss of 0.1, indicating a significant performance improvement where a precision value of 0.986, an average recall (AR) of 0.970, a mean average precision mAP@0.5 of 0.988, a mean average precision mAP@0.5-0.9 of 0.806, and an F1-score of 0.978. The measurement results and analysis findings reveal that our proposed method is accurate enough. The embedded system employs NVIDIA Jetson Nano for inference, which takes only 0.135 seconds and has a scalability performance of 7.470 FPS to recognize things associated with road damage. Although the employed NVIDIA AGX Orin edge device may produce a higher FPS of 67.034 and a faster inference time of 0.014 seconds. This means that the iYOLOV7 model is extremely feasible and practical for usage on edge devices to identify road damage."
  },
  {
    "year": "2025",
    "abstract": "Due to the problems faced by autonomous driving scenarios in complex scenarios, generalized target detectors are challenged, especially the detection accuracy of occluded and small targets. In order to solve this problem, a target detection algorithm for complex scenes BT-YOLO11 is proposed based on the latest YOLO11. In the feature extraction stage, Bi-level Routing Attention is introduced to enhance the model’s ability to capture feature information. The Tri-directional Feature Pyramid Net is used in the feature fusion stage, which adequately fuses different levels of feature information and improves the accuracy and robustness of the algorithm. By introducing an Adaptive Threshold Focus Loss function, the model focuses more on detection targets that are difficult to classify, the model generalization ability is improved. The experimental results show that the improved algorithm exhibits very competitive performance on the KITTI dataset. Specifically, it achieves a mAP50 metric of 95% and 77% under the more challenging mAP50:95 evaluation criterion. Compared to the YOLOv11s model, the algorithm proposed in this study improves the mAP50 by 2.6% and the mAP50:95 by 4.4%."
  },
  {
    "year": "2025",
    "abstract": "This paper describes three methods for analyzing electroencephalography (EEG) signals to classify users’ brain responses to exposure to art. The first two methods exploit classical machine learning approaches based on various sets of features extracted using different techniques for EEG analysis. In particular, the first method analyzes features extracted from time and frequency domains using an ensemble classifier, while the second one analyzes the Phase Locking Values of different channels using a classifier based on K-Nearest Neighbors. The third method retrains a well-known Convolutional Neural Network, namely VGG16, for image classification to analyze the scalograms obtained by applying the continuous wavelet transform to the EEG. These methods are evaluated employing a public dataset collected using mobile tools from museum visitors at an art exhibit. The dataset suffers from the problem of unbalanced classes, and this work also evaluates the impact of mitigation actions. The results reveal a significant difference between models tailored to the subject being tested, that achieve up to 95.43% of accuracy, and those trained without data from that subject (leave-one-subject-out strategy), that achieve up to 65.35% of accuracy. This suggests that, at this stage, customized approaches are more appropriate for the neuroaesthetics field, whereas models with general applicability need further development. We also conducted an analysis to assess whether age influenced the performance of the models. We split the visitors into three groups based on their age: adolescents, young adults, and adults. The analysis performed with a leave-one-subject-out strategy revealed higher accuracy for adolescents (73.21%) and adults (66.98%) than young adults (60%)."
  },
  {
    "year": "2025",
    "abstract": "As gravitational wave astronomy has advanced, the need for effective and quick signal processing has never been more critical. New detectors such as Laser Interferometer Gravitational-Wave Observatory (LIGO) produces huge volumes of data, which poses a significant challenge to identify genuine astrophysical events amidst transient noise. With this in view, this study proposes a new, efficient deep-learning architecture designed to process gravitational wave signals. Motivated by the WaveNet model, our method uses dilated convolutions to precisely model long-term dependencies in the data ensuring that subtle characteristics are captured. In addition, higher-order recurrent layers like Long Short-Term Memory(LSTM) networks are also used to precisely model temporal characteristics so that accuracy is preserved with enhanced anomaly detection and noise removal. Our experimental validation shows that this method has achieved a Root Mean Square Error (RMSE) of 0.00228, a Residual Signal Ratio (RSR) of 0.08798, a Peak Signal-to-Noise Ratio (PSNR) of 33.34 dB, and an average volume error of 0.03965. These performance metrics show the framework’s ability to operate in real time with minimal computational overhead is a key requirement given the massive datasets involved in gravitational wave science. Also, by an explicit consideration of initial and boundary conditions, our scheme exhibits not only stability for the current missions but also scalability for future detection missions, like Laser Interferometer Space Antenna (LISA), allowing these missions to enhance their sensitivity and reliability. Our study demonstrates the development of state-of-the-art deep learning methods to surmount the specific obstacles concerning gravitational wave detection, paving the way for real-time processing of astrophysical data and an improved understanding of the Universe."
  },
  {
    "year": "2025",
    "abstract": "The rapid growth in HVDC (High Voltage Direct Current) grids has shown the falls of point-to-point connections. Several challenges such as the requirement of DC (Direct Current) fault blocking capability, interfacing of different grounding schemes, offering multi-vendor interoperability, and difficult to achieve high DC voltage stepping, represent serious issues to deployment of HVDC grids. DC-DC converters are considered the optimum candidate to overcome these challenges in HVDC grids interconnection. In this paper, a novel isolated hybrid monolithic modular DC-DC converter is proposed that interconnects LCC/VSC (Line Commutated Converter/Voltage Source Converter) based HVDC networks. It achieves smaller count of semiconductors, lower conduction losses and DC fault blocking. Detailed mathematical analysis, design, and control of the proposed DC-DC converter are illustrated. Also, both simulation model and experimental test rig are built to validate the proposed DC-DC converter under different normal operational and fault scenarios."
  },
  {
    "year": "2025",
    "abstract": "TCP is the default transport protocol of choice, namely for message-oriented middleware protocols (e.g., ZMTP, AMQP, MQTT) or distributed language runtimes (e.g., distributed Erlang), where exactly-once (EO) messaging is paramount. However, EO is only guaranteed within the TCP session, since reality shows that TCP connections can fail under many circumstances. Ensuring EO delivery ends up at the middleware layer, at the cost of higher complexity and lack of obliviouness—due to the use of permanent per-peer state. Moreover, using TCP at scale in highly concurrent systems leads to the need for TCP connection multiplexing, and possibly drastic performance loss due to head-of-line blocking. This paper introduces Exon, an oblivious exactly-once messaging protocol, and a corresponding lightweight (requiring no persistent storage, minimal memory, and low computation) library implementation over UDP. Exon uses a novel strategy of a per-message four-way protocol to ensure oblivious exactly-once messaging, with on-demand protocol-level “soft half-connections”, established when needed and safely discarded. Obliviousness here refers to the protocol’s ability to discard connection-specific state between incarnations, although some global information is retained. Exon achieves simultaneously: correctness with no timing assumptions, obliviousness, and performance through merging and pipelining basic protocol messages. Exon also employs a reliable delegation technique to handover the sending responsibility to a mediating node, without violating EO, when the sender the receiver are directly unreachable to each other and even if the message had already been delivered. The empirical evaluation of Exon demonstrates significant improvements (40%) over TCP in throughput and latency under packet loss, while maintaining a negligible (8%) overhead in healthy networks."
  },
  {
    "year": "2025",
    "abstract": "The Raft consensus algorithm is widely used in private networks as an alternative to the energy-intensive PoW consensus algorithm in blockchains. The Raft consensus algorithm’s voting mechanism performs well in reliable and well-planned networks with optimized timeouts. However, in unreliable or poorly configured networks, it encounters several challenges. These include multiple candidacies, repeated election cycles, insufficient or failed leader elections during network splits, prolonged leader election times and vulnerability to Sybil attacks. In this study, a novel Hybrid Raft-PoW consensus algorithm is introduced. It integrates the hash puzzle-based competition of the PoW consensus algorithm with the fast leader election mechanism of the Raft consensus algorithm. This combination ensures both speed and certainty in leader election, ensuring that leadership is delegated to the most capable nodes. At the same time, it promotes decentralization by ensuring a fair distribution across nodes, achieving at least 80% leadership distribution. Therefore, the proposed Hybrid Raft-PoW consensus algorithm improves or eliminates problems caused by Raft consensus algorithm’s leader election mechanism."
  },
  {
    "year": "2025",
    "abstract": "In times of ubiquitous data collection and processing, the need for privacy and control is stronger than ever. The implementation of informed consent is becoming increasingly important. The obligation to obtain informed consent and the user’s right to information and to refuse or withdraw consent is already defined in the GDPR. Particularly within the mHealth sector, where the collection of particularly sensitive health data occurs, the realisation of informed consent presents an important challenge. However, many applications are still not compliant, and companies seem to struggle with the implementation of effective informed consent. This scoping review analyses how the technical implementation of informed consent has been addressed in the literature to date, what challenges need to be overcome when implementing informed consent, and what solutions are proposed and discussed in the current literature on the implementation of informed consent."
  },
  {
    "year": "2025",
    "abstract": "The classification of musical emotions is crucial for the indexing, structuring, searching, and recommending of tracks and albums across various music platforms. Consequently, the automated categorization of musical emotions has become a vital element in nearly all music applications. Recent studies have mainly concentrated on utilizing textual, audio, or multimodal data for genre classification, frequently neglecting the impact of singers, composers, and listener preferences. In practice, composers possess unique compositional styles, listeners have varied musical preferences, and singers focus on particular music genres. These different viewpoints offer significant insights into the classification of musical emotions, greatly enhancing the effectiveness of classification performance. In this paper, we introduce a novel heterogeneous graph neural network (HGN) that models the relationships of music emotion preferences among singers, composers, and listeners, in order to generate accurate node feature representations for downstream tasks. The experimental results show that our model significantly outperforms current state-of-the-art (SOTA) methods on two datasets for music emotion classification."
  },
  {
    "year": "2025",
    "abstract": "In recent years, the Digital Twin has attracted significant attention in academia and industry as a powerful technology for creating virtual replicas of physical systems tailored to specific purposes. Digital Twins can be developed at various levels of maturity, accommodating different system types and scopes. Consequently, diverse domain-specific approaches to Digital Twins development exist, yet no standardized method defines, verifies, and validates their requirements. This is essential for a consistent and reliable implementation of Digital Twins. This paper explores the application of Model-Based Systems Engineering in the design, development, verification, and validation of a Digital Twin System. It presents a comprehensive methodology that encompasses all phases of a Digital Twin System’s life cycle. The methodology was applied to model the requirements and the functional, behavioral, and structural aspects of a Digital Twin System for an aircraft seat testbench, supporting its design, implementation, and operation at the prototype level. The Digital Twin replicates the seat testbench, enabling simulations for early system validation under various conditions. Integrating Model-Based Systems Engineering with Digital Twin technologies enhances the clear definition of scope and technical requirements, contributing to more effective testing and development processes in the aeronautical industry. This work underscores the benefits of a model-driven approach for Digital Twin design, laying the foundation for future applications in complex engineering systems due to its repeatability."
  },
  {
    "year": "2025",
    "abstract": "In sports, identifying athletes with high potential to excel in sports schools is pivotal. In the literature, this process is called Talent Identification (TID) and is defined as “to know the players participating in the sport with the potential to be perfect.” The problem discussed in this paper focuses on the early identification of an athlete’s talented sports branch before they are assigned to a specific branch. This determination process is based on the evaluation of general performance tests and assessments. TID solutions in the literature use AI-driven methods (i.e., Machine Learning, Neural Nets, etc.). However, they could not beat the following deficiencies: they cannot be used with the dataset features having complex and non-linear relationships, are not scalable in the number of features, are not adaptable to hierarchical data, cannot generalize the solution, depend on any predefined thresholds or prior assumptions, are not adaptable to the other datasets, are not tolerable to the incomplete inputs. A two-stage TID solution has been introduced to address the deficiencies above and resolve the TID challenge. In the first stage (TID1), the admitted athletes are determined. In the second stage (TID2), athletes are classified into their talented branches (Football, basketball, volleyball, or athletics). TID1 uses our Shallow Deep learning (SDL) model to classify the admitted. In this stage, a remarkable performance was obtained with 98.85%. In TID2, nine different feature selection methods (four RFE-related methods, three SelectKBest-related methods, and Lasso and Boruta) are applied to reduce the number of features. After feature selection, our novel SCM-DL deep learning classifier model (apart from the architectures in literature, this model is constructed internally with parallel layers and carries a combinatorial layer that is beyond the combination of existing techniques) is applied and compared with Random Forest, Decision Tree, Extra Tree, and Support ..."
  },
  {
    "year": "2025",
    "abstract": "Harmonic distortions are major power quality issues observed in distribution systems, causing overloading, overheating, increased losses, reduced equipment lifespan, malfunctioning of devices, and, in extreme cases, service interruptions and shutdowns of industrial processes. Since determining the causes of voltage harmonic distortions is challenging, and responsibility is not always easily assigned, this paper proposes mitigating this power quality phenomenon in distribution feeders by modifying their impedance matrix for the h-th harmonic order through frequency scanning process, without the need to assign responsibility or require the installation of harmonic filters. This approach suggests that the feeder’s frequency response can be adjusted to improve voltage harmonic levels solely by relocating existing capacitor banks. Applying this concept to a real case study, the appropriate locations for relocating capacitor banks were identified, and power quality measurements taken at an affected consumer’s point of service confirmed the effectiveness of this approach, ensuring the original reactive power compensation of the feeder."
  },
  {
    "year": "2025",
    "abstract": "Effective discriminative spectral-spatial feature representation is crucial for hyperspectral image classification (HSIC). Some current methods typically extract spectral and spatial information directly from spectral-spatial 3D patches, without considering the correlation between features, resulting in a high number of misclassifications at the boundaries of land cover classes. This article proposed a spectral-spatial two-branch feature fusion network (TFFN). The spatial branch utilizes distance similarity metrics to capture the spatial relationships between central and neighboring pixels, and utilizes multiscale convolutional modules to expand the receptive field, capturing different levels of features and contextual information, resulting in more robust spatial information. The spectral branch utilizes a bidirectional long short-term memory (Bi-LSTM) network and linear attention mechanism to capture spectral features. In the end, the fused feature information from both branches serves as the basis for classification, enabling high-precision categorization. Experimental results on the datasets of four public demonstrate that the overall classification accuracy of the TFFN model exceeds 97%, especially on the Indian Pines dataset with an imbalanced distribution of ground objects."
  },
  {
    "year": "2025",
    "abstract": "Traditional speech disorders (SD) detection relies on subjective analysis, resulting in inconsistent outcome. Direct voice classification lacks effective approaches to capture temporal dependencies. Machine learning (ML) models face challenges in extracting the complex temporal and spectral variations in speech signals. Advanced deep learning (DL) and transfer learning techniques offer a foundation for early screening of SD. However, the lack of interpretability reduces the generalization capabilities of these models. Addressing these shortcomings is essential in order to improve the accuracy of SD detection and clinical trustworthiness. Thus, the proposed study introduces a novel image-based SD classification model to classify healthy and pathological speech with high accuracy and robustness. The raw speech signals are transformed into Mel-Spectrograms to overcome the limitations of direct voice classification. To facilitate the model’s interpretability, the statistical and handcrafted acoustic features are extracted from the raw speech signals. Hybrid MobileNet V3-EfficientNet B7and Linformer-Performer are employed to extract diverse features from the Mel-Spectrograms. An attention-based feature fusion is used to identify critical features indicating the SD patterns from the extracted features. The XGBoost classifier is optimized using Bayesian Optimization and HyperBand (BOHB) to classify the healthy and pathological speech. SHapley Additive exPlanations (SHAP) values is employed to offer valuable insights into the model’s decisions. The proposed model obtains an exceptional performance on two benchmark datasets. On the Saarbruecken Voice Database (SVD), it achieves an accuracy of 98.1% with loss of 0.13. It yields a remarkable generalization accuracy of 98.2% on the VOICE dataset, outperforming the state-of-the-art models. In addition, it contributes a significant advancement in SD detection, setting the stage for future research endeavors."
  },
  {
    "year": "2025",
    "abstract": "Alzheimer’s disease (AD), a leading neurodegenerative disorder, progresses from an intermediary stage known as Mild Cognitive Impairment (MCI), characterized by measurable cognitive decline with retained functional independence. Accurate prediction of MCI progression to AD is critical for timely interventions. Existing deep learning-based methods for structural MRI (sMRI) analysis predominantly utilize either Convolutional Neural Networks (CNNs), which effectively capture local features but neglect global context, or Transformer architectures that model global dependencies yet require extensive data and computational resources. Additionally, many methods inadequately leverage longitudinal imaging data, limiting their sensitivity to subtle temporal changes in brain morphology. To overcome these limitations, we introduce EffiSwin-MCI, a novel hybrid deep learning framework integrating EfficientNet and Swin Transformer architectures, specifically designed for longitudinal sMRI analysis. The primary novelty of EffiSwin-MCI lies in its sliding-window attention mechanism, inspired by the Swin Transformer, which effectively integrates localized spatial dependencies within 2D sMRI slices, combined with temporal attention blocks that fuse spatial-temporal features across longitudinal scans at two distinct time points (T1 and T2). EfficientNet-B2 serves as a computationally efficient backbone, extracting hierarchical spatial features crucial for detailed morphological characterization. This alternating spatial and temporal attention strategy uniquely captures progressive local and global structural changes indicative of cognitive decline. Comprehensive experiments conducted on the Alzheimer’s Disease ADNI dataset demonstrate the proposed model’s superior performance compared to state-of-the-art CNN and Transformer-based approaches, achieving an accuracy of 81.69%, recall of 80.27%, precision of 84.35%, and F1-score of 82.27%. EffiSwin-MCI’s interpretability is further validat..."
  },
  {
    "year": "2025",
    "abstract": "Rice is a vital staple food for billions of people worldwide, especially in Asia, Africa, and Latin America, where it plays a key role in daily caloric intake and nutrition. With numerous varieties differing in size, shape, colour, texture, and nutritional content, accurate rice variety identification is critical for optimizing production and ensuring food quality. Environmental factors such as soil type and climate further influence these variations, making precise identification essential for improving productivity and reducing waste. However, traditional manual methods of identification, relying on visual characteristics, are prone to human error, resulting in variety mixing, reduced quality, and higher costs. This study addresses these challenges by employing the DENS-INCEP model, a transfer learning approach that integrates DenseNet-201 with the Inception module. DenseNet-201 serves as the backbone for feature extraction, while the Inception module enhances the model’s ability to capture multi-scale shape-related features, significantly improving classification accuracy. The model achieved remarkable performance, with an average accuracy of 99.94% across multiple rice varieties. By implementing the DENS-INCEP model, this study contributes to Sustainable Development Goal (SDG) 2 by improving food security through enhanced rice production and supply chain stability. Additionally, it supports SDG 9 by fostering innovation and advancing sustainable agricultural technologies. Furthermore, by reducing errors, waste, and inefficiencies in production and distribution, the model aligns with SDG 12, which emphasizes sustainable consumption and production. Overall, the DENS-INCEP model offers a robust and efficient solution to rice variety identification, addressing global food security challenges while promoting sustainability."
  },
  {
    "year": "2025",
    "abstract": "Text-to-image generation is trending in the generative artificial intelligence (GenAI) field. Among open-sourced image generation projects, Stable Diffusion is the state-of-the-art. Many artists and service providers customize the diffusion model to generate featured high-quality images. However, there is no protection to the privacy of the input text prompt, output image, and customized model. Privacy is very important since it can increase users’ willingness to use the service and protect the service provider’s intellectual property. Existing privacy-preserving diffusion model require fully homomorphic encryption (FHE) to ensure its privacy and security. Nonetheless, FHE is very time-consuming and may reduce accuracy due to approximations and deteriorate image quality. In this research, we propose Privacy-Diffusion, a privacy-preserving diffusion framework without FHE. By utilizing the irreversible property of neural network layers and the property that the predicted noise in the diffusion process is a normalized Gaussian distribution. Our framework can be applied to all kinds of diffusion models to protect clients’ input text prompt and the generated image from being learned by the server, as well as customized models from being learned by the clients. Our protocol is secure and efficient. Compared with existing research, HE-diffusion, which spent 200% extra time and visible quality loss, our protocol can reach the same security level with only 19% extra time and has no quality loss. To the best of our knowledge, our Privacy-Diffusion is the first protocol that achieves this goal without using FHE and maintain the same high-quality image output as the original model."
  },
  {
    "year": "2025",
    "abstract": "An ontology is a scheme for structuring relationships between concepts in a domain, promoting data interoperability and system integration. However, poorly designed ontologies can lead to errors and performance issues. While systems engineering has standardized evaluation guidelines (e.g., ISO/IEC), ontology engineering lacks such standards, leading to various independent evaluation methods. One frequent issue among novice developers is the misuse of ontology restrictions, particularly ‘allValuesFrom’ and ‘someValuesFrom’, which can significantly impact the correctness and reliability of ontologies. However, existing studies have not adequately addressed effective methods for detecting such errors. To address this gap, we propose a context-aware verification framework utilizing large language models to detect and correct misuse in ontology restrictions. Unlike conventional methods, our framework integrates contextual descriptions derived from ontological axioms, enabling more accurate verification. Additionally, we introduce a clustering-based description generation method that systematically organizes contextual information, further enhancing verification accuracy. Experimental evaluation conducted on diverse ontology datasets suggests that contextual integration improves verification performance. Moreover, the clustering-based description generation improves restriction misuse detection and correction compared to traditional approaches. By automating ontology restriction verification, this study contributes significantly to enhancing the reliability of ontology evaluation and provides a foundation for developing more scalable and standardized verification techniques."
  },
  {
    "year": "2025",
    "abstract": "In this study, we propose a real-time contrasts control chart based on reinforcement learning (RL-RTC). Effective process monitoring, which directly influences productivity and yield, has become increasingly important. The traditional RTC control chart offers a promising approach to process monitoring by transforming the monitoring problem into a real-time classification task, enabling more timely and accurate detection of issues. However, the parameters of the traditional RTC control chart are typically set based on empirical methods, which limits the ability to fine-tune them effectively. To address this limitation and improve the performance of the RTC method, we propose the RL-RTC control chart, which leverages reinforcement learning for more adaptive parameter control. The proposed method takes the data itself as a state of reinforcement learning (RL) and adaptively decides the parameter of the RTC control chart in real-time. In this paper, the control of the moving window size is defined as an action taken by the RL agent. By automatically learning an optimal policy, the RL-RTC method eliminates the need for manual parameter tuning and enhances adaptability in dynamic process environments. The RL-RTC approach can detect shifts more quickly while maintaining the ability to identify the causes of faults. Compared to a conventional RTC control chart, experimental results demonstrate that the RL-RTC method offers improved performance by fine-tuning the window size in response to changing process conditions. Therefore, a wide scope of applications is expected for adaptively controlling the other RTC control chart parameters."
  },
  {
    "year": "2025",
    "abstract": "In an era of diminishing water resources, Atmospheric Water Generators (AWG) offer an innovative solution to address the global water crisis by harnessing alternative local water sources. Recent advances in AWG technology have demonstrated the feasibility of converting atmospheric moisture into potable water, making AWGs suitable for use as domestic appliances and positioning them as key players in tackling the water-energy nexus. Inethis context, efficient data collection and management from AWG systems are critical for improving technological capabilities and performance optimization. This work presents an Internet of Things (IoT) ecosystem that integrates IoT-enabled AWG machines, utilizing a biopolymer for water generation, and an IoT platform to collect, store, and manage data from these devices. Weeenhance existing AWG machines with IoT functionalities, allowing for remote monitoring and control of a fleet of units. Additionally, weedemonstrate the implementation of this ecosystem in a real-world scenario, enabling the management and oversight of operational AWG machines. Communication tests were conducted to evaluate transmission performance. Since AWGs may be located in remote regions, weetested the scenario in which AWGs are connected to the Internet via Low Earth Orbit Satellites Internet Service Providers (e.g. Starlink). The results showed that latency reached values around 100ems, and less than 1es even for the extreme scenario of total network congestion, guaranteeing that the data transmission latency is within acceptable limits for this application, ensuring effective monitoring and control of the AWG systems."
  },
  {
    "year": "2025",
    "abstract": "In recent years, deep learning technologies have rapidly transformed various sectors, particularly in fields such as healthcare, finance, and education. These advancements have led to significant achievements in predictive modeling, data analysis, and decision-making processes. However, there remains a need for more sophisticated models that can accurately capture complex relationships in dynamic, real-world datasets. To address this, this paper proposed a novel deep neural network (DNN) model designed to predict soft power based on educational factors. The proposed method involves collecting global educational data, including international student enrollment, research output, and the presence of top-ranked universities, and using this data to train a DNN model for soft power prediction. First, we preprocess the data by standardizing the features and handling missing values. Secondly, we build and train a DNN with multiple hidden layers to capture nonlinear relationships between educational factors and soft power scores. Thirdly, we evaluate the model’s performance using several performance metrics, such as accuracy, RMSE, MAE, and precision. Finally, we compare the performance of our proposed DNN model with other machine learning algorithms, such as Random Forest and Support Vector Machines, demonstrating superior predictive accuracy. The experimental results indicate that the DNN model outperforms others, achieving the highest accuracy of 95.83%, exceptional sensitivity (94.45%), and specificity (96.26%). Its F1 Score of 95.56%, precision (95.87%), and recall (94.43%) reflect balanced and robust classification. The model also shows superior reliability with an MCC of 0.923 and an AUC of 0.978. Low error rates, including MAE (0.11), MSE (0.05), and RMSE (0.22), highlight its accuracy and predictive precision. The experimental results show that the DNN model significantly outperforms traditional machine learning models, providing a more accurate and robust predictio..."
  },
  {
    "year": "2025",
    "abstract": "This study explores the influence of multiple luminaire arrangements on the dual functionality of visible light communication systems (VLC), focusing on their impact on illumination uniformity and communication performance. A comprehensive analysis of various luminaire distributions, ranging from single to multiple luminaires, is performed to identify configurations that optimize lighting quality and data transmission efficiency. In particular, the study examines three luminaire arrangements—circular, square, and circular-square—implemented in configurations of 1 to 12 luminaires, and includes theoretical modeling and experimental validation in indoor environments, covering single-input single-output (SISO), multiple-input single-output (MISO), and multiple-input multiple-output (MIMO) configurations up to3×2systems. Orthogonal frequency division multiplexing (OFDM) with repetition coding (RC) is employed, which distributes data across subcarriers while replicating signals across transmitters to enhance spatial diversity. Key performance metrics, such as illumination, uniformity, quality factor (Fa), and coefficient of variation (CV(RMSE)), are evaluated for illumination, while communication performance is assessed using bit error rate (BER) metrics. The results demonstrate that the overall performance is improved as the number of luminaries increases, however a saturation point exists beyond which additional luminaires yield diminishing returns. Our findings highlight the complex interplay between illumination uniformity and communication performance in VLC systems, providing valuable insights for designing high-performance MIMO systems in smart indoor environments."
  },
  {
    "year": "2025",
    "abstract": "Managing modern data centre operations is increasingly complex due to rising workloads and numerous interdependent components. Organizations that still rely on outdated, manual data management methods face a heightened risk of human error and struggle to adapt quickly to shifting demands. This inefficiency leads to excessive energy consumption and higher CO2 emissions in cloud data centres. To address these challenges, integrating advanced automation within Infrastructure as a Service (IaaS) has become essential for IT industries, representing a significant step in the ongoing transformation of cloud computing. For data centres aiming to enhance efficiency and reduce their carbon footprint, intelligent automation provides tangible benefits, including optimized resource allocation, dynamic workload balancing, and lower operational costs. As computing resources remain energy-intensive, the growing demand for AI and ML workloads is expected to surge by 160% by 2030 (Goldman Sachs). This heightened focus on energy efficiency has driven the need for advanced scheduling systems that reduce carbon emissions and operational expenses. This study introduces a deployable cloud-based framework that incorporates real-time carbon intensity data into energy-intensive task scheduling. By utilizing AWS services, the proposed algorithm dynamically adjusts high-energy workloads based on regional carbon intensity fluctuations, using both historical and real-time analytics. This approach enables cloud service providers and enterprises to minimize environmental impact without sacrificing performance. Designed for seamless integration with existing cloud infrastructures—including AWS, Google Cloud, and Azure—this scalable solution utilizes Kubernetes-based scheduling and containerized workloads for intelligent resource management. By combining automation, real-time analytics, and cloud-native technologies, the framework significantly enhances energy efficiency compared to traditional sche..."
  },
  {
    "year": "2025",
    "abstract": "Cervical cancer continues to be a significant global health issue, ranking as the fourth most prevalent cancer affecting women. Enhancing population screening programs by refining the examination of cervical samples conducted by skilled pathologists offers a compelling alternative for early detection of this disease. Deep Learning facilitates the development of automatic classification models to aid experts in this task. However, it is increasingly important to bring explainability to the model both to understand how the network learns to identify pathology and to bring confidence to the diagnosis. In this paper, we design an automatic segmentation masks for the classification of cervicovaginal cell images. This automatic segmentation is combined in a classification model that allows the models to improve their performance thanks to the morphological information provided by the combined segmentation in a Global Average Pooling layer with the convolutional network analysis of the original image. The models will be trained with real data so that learning can recognize the diversity of colors, shapes and sizes of human cell nuclei. The results show a robust and explainable model with satisfactory results, obtaining an F1 Score value of 0.935 in binary classification of revisable and non-revisable cell."
  },
  {
    "year": "2025",
    "abstract": "Role-based access control (RBAC) systems have become a widely used and accepted method by many organizations today due to their efficiency and ease of management. However, to truly benefit from RBAC systems, the roles in the relevant system must be well defined. Bottom-up, top-down, and hybrid approaches exist to accurately define the roles to be included in access control systems. Even if RBAC systems are designed carefully, the role privilege assignments tend to wear out and become chaotic after some time. This study demonstrates a role mining approach to reconfiguring such existing client specific RBAC systems by identifying clusters of similar roles using the assigned privileges. In this study, masked RBAC data of 10 clients of a software company are used. The approach creates role clusters via Agglomerative Hierarchical Clustering, an unsupervised clustering algorithm that works in a bottom-up technique. The experiment results show that it is better using the resulting candidate clusters as a reference in reconfiguring the RBAC systems, instead of using them to replace the existing roles. Additionally, it has been observed that in some client tables with a limited number of unique roles, the pairwise F1 score was remarkably high, indicating a strong correspondence between the candidate and expected roles."
  },
  {
    "year": "2025",
    "abstract": "Healthcare fraud is a critical challenge, contributing significantly to rising healthcare costs and financial losses. This article proposes a hybrid architecture for healthcare fraud detection, combining deep learning-based feature representation with gradient boosting classification and explainable AI techniques. The framework integrates convolutional neural networks (CNNs), transformers, and XGBoost to capture intricate patterns in claims data while maintaining interpretability through Shapley additive explanations. The model we proposed was tested on two datasets: the Medicare Provider Fraud dataset and the Healthcare Providers dataset. On the Medicare dataset, the framework achieved an F1-score of 0.95 on the training set and 0.92 on the test set, with an AUC-ROC of 0.98 and 0.97, respectively, outperforming state-of-the-art models such as LightGBM and CatBoost. On the Healthcare Providers dataset, the framework attained a test F1-score of 0.92 and an AUC-ROC of 0.96, consistently surpassing traditional models like Support Vector Machines and Random Forest. Key contributions include integrating domain-specific features, such as provider-patient interaction graphs and temporal patterns, and using explainability techniques to enhance trustworthiness. Furthermore, the framework demonstrated computational efficiency, with a training time of 150 seconds on the primary dataset, making it suitable for real-world deployment."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we firstly construct a new chaotic map by compounding a couple of chaotic maps and, using specific mathematical tools (i.e., Lyapunov exponent), we prove its sensitivity to the initial conditions and the underlying chaotic behavior. Secondly, using this chaotic map, we propose a new chaotic keyed hash function which involves each byte of the message in calculation of the chaotic map initial point and the compounded maps control parameters. Corroborating this method with the proven sensitivity of the used chaotic map, we obtain an avalanche effect in the hashing process and the guarantee that all the bits of the message will be related to the hash value. Moreover, the exhaustive numerical simulations show that the proposed hash function has very good confusion and diffusion capabilities, strong collision resistance, high level of security and good speed, being suitable for applications regarding data integrity or authentication, such as ciphers or blockchain applications."
  },
  {
    "year": "2025",
    "abstract": "Elevated temperature is the main cause of electronic circuits failures, thus a proper thermal management is indispensable. The heat from operating circuits is dissipated by conduction, radiation and convection. Several papers related to the impact of air relative humidity on natural convection cooling of electronic circuits, based on theoretical analysis, suggesting such impact, were published so far. The goal of the presented research was to investigate the problem experimentally. A dedicated measurement setup composed of a cubic enclosure placed inside a climatic chamber was built. A bipolar transistor placed inside the enclosure was used as a controlled heat source. To assess the cooling efficiency, the transistor junction temperature was maintained constant using a custom build controller circuit and the power dissipated in the device was measured. Additionally, the surface temperature of the transistor was measured using a thermographic camera and a MWIR optical fiber. The measurements were repeated for different temperature and relative humidity combinations. Based on obtained measurement results and their analysis, backed-up by simulations, it was found that air relative humidity has no impact on electronic circuits cooling efficiency in the natural convection scenario. The theoretical background of the results was also explained."
  },
  {
    "year": "2025",
    "abstract": "Unreported position data of fishing vessels significantly hinder the accurate identification of their behaviors. AIS (Automatic Identification System) data—a self-reporting tool used for vessel tracking—is often incomplete because IUU fishing vessels deliberately turn it off to evade detection. In this paper, we propose BlindFG, a novel framework for unreported fishing gear classification that leverages a fishing-conditioned latent space to overcome the limitations imposed by AIS-off periods. BlindFG integrates a Fishing-Conditioned Generative Model (FCGen) with a Fishing Context Sommelier (FCSom) to both reconstruct missing trajectory data and classify vessel fishing types under partial AIS availability. FCGen employs a conditional variational architecture, incorporating fishing context embeddings derived from one-hot encoded fishing gear labels to guide the generation of AIS-Off trajectories. FCSom utilizes the completed trajectories within a 1D convolutional classification framework. By aggregating candidate predictions across multiple fishing type hypotheses, the system effectively discriminates among various fishing behaviors, even in the presence of partial AIS data. Experimental results on global datasets demonstrate that BlindFG significantly improves the accuracy of fishing type classification and offers a robust solution for enhancing maritime situational awareness and combating IUU fishing activities. Experimental evaluations demonstrate that our method significantly enhances the prediction of vessel trajectories and the accurate classification of AIS-off fishing practices worldwide."
  },
  {
    "year": "2025",
    "abstract": "The Internet of Medical Things (IoMT) connects medical devices to enable real-time monitoring and personalized care, significantly enhancing patient health and well-being. However, this connectivity also introduces substantial cybersecurity risks, including various attack types that compromise data integrity and availability, jeopardizing patient safety and healthcare service reliability. This study addresses these challenges by proposing a real-time anomaly detection model based on machine learning (ML) techniques, designed to detect and mitigate diverse cyber threats effectively. This paper proposes a new medical dataset for anomaly detection, inspired by the UNSW-NB15 dataset, and enriched with healthcare-relevant attack types, including falsification and DoS attacks, to reflect real-world IoMT scenarios. The dataset comprises 253680 records, with 60% anomalous data distributed across multiple attack types, offering a more challenging and realistic environment for evaluating ML models. Seven machine learning algorithms, including Random Forest, XGBoost, and Artificial Neural Networks (ANN), were rigorously tested, leading to the development of a novel stacking ensemble model. This model integrates XGBoost as the meta-learner with Random Forest and ANN as base models, leveraging their strengths to optimize anomaly detection. The proposed model was evaluated on both the UNSW-NB15 and the new medical dataset, achieving significant improvements across key metrics such as accuracy, precision, recall, and F1-score. A real-time prediction analysis further demonstrated its ability to detect anomalies efficiently during live data transmission, validating its suitability for detecting anomalies in real-time scenarios."
  },
  {
    "year": "2025",
    "abstract": "This paper addresses the verification of neural network robustness against perturbations of input data in vision-based end-to-end autonomous driving systems. The main contributions of this work are: i) We provide a comprehensive analysis of current neural-network-based perception and decision-making components in autonomous vehicles, highlighting their susceptibility to attacks or perturbation. ii) We develop and implement a novel framework for systematically evaluating and verifying the robustness of neural networks against such perturbations, focusing on imperceptible image modifications. iii) We present empirical results demonstrating our verification framework’s effectiveness in identifying weaknesses and providing probabilistic guarantees on network behavior. Our work underscores the critical need for robust verification methods to ensure the reliability and safety of autonomous driving systems, paving the way for safer integration of neural networks in autonomous vehicles."
  },
  {
    "year": "2025",
    "abstract": "Recent advancements in autonomous vehicle research have heightened the need for precise pedestrian pose tracking to ensure safe navigation. Utilizing LiDAR sensors, conventional bounding box (BB) methods are generally used but are sensitive to limb motion. The previous moving horizon-based maximum likelihood estimation sample consensus (MHESAC) study addressed this robustness limitation but suffered from extensive point cloud (PC) sampling, limiting real-time applications. This paper proposes an elliptical pedestrian model tracking within a sequential bi-level MHESAC (B-MHESAC) framework that combines random sampling consensus (RANSAC) for local model fitting per time step and maximum likelihood estimation sample consensus (MLESAC) for optimal model sequence selection throughout the horizon, significantly reducing PC sampling while preserving accuracy. Under significant outlier contamination, B-MHESAC requires less trials than MHESAC for multiple horizons and samples. Moreover, at long horizon lengths, B-MHESAC required trial’s exponential growth is at least reduced to the fifth root of MHESAC, allowing real-time estimations. The proposed method was evaluated in an indoor single pedestrian tracking experiment. Experimental results demonstrate that B-MHESAC is more robust than conventional RANSAC in model fitting. Additionally, the elliptical model-based B-MHESAC’s tracking performance is competitive with the MHESAC method’s and superior to other Kalman filter-based BB and circle model methods."
  },
  {
    "year": "2025",
    "abstract": "Machine translation (MT) for low-resource languages continues to face significant challenges because of limited digital resources and parallel corpora, despite remarkable developments in neural machine translation (NMT). Addressing these challenges requires a thorough review of existing research to identify effective strategies and methods. To achieve this, a systematic literature review (SLR) is conducted following PRISMA guidelines and systematically analysing studies published in various academic databases in the last five years (between 2020 and 2024). A total of 69 relevant articles were examined to evaluate the performance of MT, explore persistent challenges and assess the effectiveness of proposed or used solutions. The analysis shows that while NMT has emerged as the predominant approach, its effectiveness is often reduced by the scarcity of training data and the structural complexity of low-resource languages. Strategies such as active learning, data augmentation, multilingual models and transfer learning are identified as critical for improving translation performance. Additionally, emerging research trends, including data pre-processing, optimization of decoder and rule-based approach demonstrate promising directions for addressing existing limitations. In terms of evaluation, most of the studies used Character n-gram F-score (ChrF), Translation Edit Rate (TER), Metric for Evaluation of Translation with Explicit Ordering (METEOR), Word Error Rate (WER) and Bilingual Evaluation Underscore (BLEU) as techniques’ validation metrics. This review provides a detailed evaluation of the current state of MT for low-resource languages and emphasizes the need for further research into underrepresented languages and the development of comprehensive datasets."
  },
  {
    "year": "2025",
    "abstract": "Conversational Aspect-Based Sentiment Analysis (DiaASQ) aims to extract fine-grained sentiment quadruples {target, aspect, opinion, polarity} from multiple segments of dialogue. The composition of these quadruples is often not limited to a single utterance but may span across the entire conversation. Therefore, the analysis needs to consider both the syntactic structure of individual utterances and the interactions between different views. However, previous studies often lack modeling of dialogue features and overlook the interdependence between utterances. To address this, this paper introduces the Syntax and Consecutive Multi-View Network. This model captures the syntactic dependencies among utterances using Graph Convolutional Networks (GCN) and employs multi-view interactions along with three consecutive multi-head attention modules to construct contextual connections within the dialogue. Finally, a triple scorer is used to decode the quadruples, thereby enhancing the weakly labeled relationships within the quadruples. Extensive experiments on standard datasets demonstrate that the proposed model significantly outperforms baseline methods across multiple dimensions."
  },
  {
    "year": "2025",
    "abstract": "Edge computing (EC) environments are increasingly essential in ensuring low latency and high throughput for modern applications and in smart cities. Scheduling applications in EC environments should be designed to address challenges such as uneven workload distribution, high latency, and frequent request retransmissions, which are not well addressed by current state-of-the-art solutions. In this work, we propose a smart Kubernetes scheduling solution that embeds a machine learning model into the Kube-scheduler for more effective application deployment. By analyzing application keywords and edge server metrics, such as geographic location, workload, and keyword-based request frequency, the proposed solution dynamically selects the optimal edge server for application deployment. The simulation results depict substantial improvements, including reduced latency, better workload equilibrium, increased achievable throughput, and minimized retransmissions between servers. Compared to existing approaches, the proposed model provides a more robust solution to the complex and dynamic requirements of edge computing environments."
  },
  {
    "year": "2025",
    "abstract": "Diabetes and its complications, especially Diabetic Retinopathy (DR) and Diabetic Nephropathy (DN) is a big challenge to the global healthcare system and needs accurate predictive models to help in early diagnosis and intervention. In this study we used a dataset from a reputed medical center in India with 767 patient records and 22 attributes including demographic details, clinical markers and treatment plans. We used a suite of advanced machine learning algorithms—Random Forest, XGBoost, LightGBM, CatBoost, Neural Networks and ensemble approaches like Voting and Stacking Classifiers to see their performance on original, oversampled and undersampled datasets. Through feature engineering, sampling strategies and hyperparameter tuning the models performed well on all the datasets. Surprisingly the models performed well even on the original imbalanced dataset which can be attributed to the power of the models and hyperparameter tuning. Ensemble methods like Voting and Stacking Classifiers performed better and achieved near perfect metrics (AUC = 1.0) in oversampled datasets. Hyperparameter tuning further improved the performance, reduced RMSE and log loss and increased accuracy and recall in all the configurations. This shows the importance of model optimization in real world clinical datasets which are imbalanced and noisy. This paper shows the possibility of machine learning based frameworks in diabetic complication management by predicting accurately and in time. These models can be integrated into clinical decision support systems (CDSS) to give insights to clinicians, improve patient outcomes through personalized interventions and optimize resource allocation. Future work will be to validate this on different populations, include longitudinal patient data and integrate real time electronic health records (EHR) for deployment in hospitals."
  },
  {
    "year": "2025",
    "abstract": "In recent years, due to the exponential growth in the applicability of biometric authentication systems, it has become essential to address the privacy and security concerns of user biometric information. The cancellable biometric template generation is one of the promising solutions in this situation which protects both the system and the user’s biometric data from unauthorized access. The complexity of such a system which sustains improved performance while maintaining the anonymity of users by introducing non-invertibility, unlinkability, and encapsulation of encrypted templates is a difficult task. The random projection-based cancellable biometric template generation is one of the efficient techniques to secure the information of users. But still, this approach suffers from the adversary attack where an attacker can obtain the original template by performing repeated random projections on the stored template. In this paper, we proposed a technique: MCC Encoded Random Triangle Hashing which protects the biometric template by encoding the projection matrix with the minutiae cylindrical codes obtained from the minutiae information. This technique addresses the problem where the projection matrix is leaked to an attacker which can lead to the reconstruction of the original biometric template. The performance of the proposed technique is evaluated using FMR, FAR, GAR, ROC Curve, and EER parameters on six FVC fingerprint databases FVC2000 DB1, FVC2000 DB2, FVC2002 DB1, FVC2002 DB3, FVC2004 DB1, and FVC2004 DB3 which is publicly available."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a hybrid radome panel that features a controllable radar cross section (RCS) reduction band. To achieve RCS suppression, the structure combines periodic frequency selective surfaces (FSSs) and dielectric loadings of different compositions, which leads to wave cancellation due to propagation delays of opposite phases. By modifying the thickness of the radome and the relative permittivity ratio, the RCS reduction band can be adjusted and optimized to obtain a wider reduction bandwidth. Furthermore, the evaluation method implemented in this work, that is, summing up the reflectivity of each radome segment, can rapidly assess the radome’s RCS reduction performance. Simulation and measurement results of the 75 mm×150mm radome panel are in good agreement. They validate that the panel provides substantial RCS reduction in X- and Ku-bands, while the C-band antenna operation is unperturbed."
  },
  {
    "year": "2025",
    "abstract": "With the increasing number of connected devices, the demand for mobile data has grown exponentially. The existing legacy 4G/LTE network has been unable to meet the demands and keep up with the expectations in terms of speed, latency, number of connected devices and quality of service. The situation demands a transition to 5G network; however, the transition comes with significant challenges for telecom operators, requiring substantial initial investments in infrastructure, technology, and human resources. This paper presents a novel two-phased approach to facilitate efficient 5G migration using machine learning and evolutionary game theory. This study primarily focuses on the development of a simulation-based analysis and a mathematical framework. In the first phase, a machine learning model is trained on Long Term Evolution (LTE) network simulation data to predict upgradability scores for existing 4G base stations, enabling a data-driven approach based on quality of service to prioritize Radio Access Network (RAN) migration. The second phase employs evolutionary game theory to observe the migration patterns for both core and RAN components of interconnected telecom operators in three distinct scenarios over a span of five years. The simulation considers critical factors such as revenue, customer retention/acquisition, traffic volume, coverage area, 5G based service demand, and human resources requirements, providing a framework for future network migration. Our research addresses the growing strain on legacy 4G networks caused by exponential growth in mobile data traffic and connected devices. By combining machine learning and game theoretic modeling, we offer telecom operators an approach to make informed decision regarding optimal migration strategies. This study contributes to the body of knowledge on network migration strategies and provides practical insights for telecom operators navigating the complex landscape of 5G deployment and migration."
  },
  {
    "year": "2025",
    "abstract": "This study develops a novel software architecture for Open Source Intelligence (OSINT). The primary architectural drivers of the OSINT architecture are identified using the Quality Attribute Workshop (QAW), and an end-to-end OSINT software architecture design is implemented in accordance with Attribute-Driven Design (ADD). The architecture is extensively analyzed with metric evaluations and the Architecture Tradeoff Analysis Method (ATAM), confirming critical quality attributes such as performance, reliability, functional suitability, and security. The design decisions taken within this architectural framework are detailed in the article through module view, component and connector view, and allocation view representations. The proposed architecture uses an on-premise Large Language Model (LLM) to explore the potential for deeper and more reliable information processing capabilities in OSINT analyses and presents a framework that enhances semantic depth and analytical capabilities. The architecture not only amplifies the semantic and analytical capabilities of OSINT systems but also sets a precedent for future architectural endeavors in intelligence systems design. This paper presents a framework that not only meets contemporary needs but also anticipates future demands in the rapidly evolving field of OSINT."
  },
  {
    "year": "2025",
    "abstract": "In recent years, power electronic technology has been widely applied in energy conversion in the fields of renewable energy and information and communication technology. Magnetic components play a crucial role in voltage stabilization, conversion, and filtering, conventional loss models struggle to accurately characterize the nonlinear loss characteristics under multi-physics coupling and complex operating conditions. To achieve high efficiency and high power density designs, it is essential to study core loss characteristics and optimize operating parameters. This paper proposes a core loss prediction model based on an improved deep forest algorithm and information entropy-enhanced genetic algorithm. First, a multi-factor analysis of variance (ANOVA) and Bayesian inference are employed to explore the effects of temperature, material, and excitation waveform on core losses, as well as their optimal combinations. Subsequently, a temperature correction factor is introduced into the conventional Steinmetz equation, and the ridge regression regularization technique is applied to improve the goodness-of-fit from 0.954 to 0.986. Next, the deep forest algorithm is employed to perform multi-granularity scanning for feature extraction from the samples, which are then fed into an enhanced cascade forest (with two random forests replaced by XGBoost and LightGBM), key parameters (maximum tree depth and number of trees) are optimized via grid search, constructing a highly accurate and robust core loss prediction model. The model’s superiority is validated from multiple perspectives, accompanied by feature importance analysis using SHAP values. Finally, an information entropy and game theory-based genetic algorithm is utilized to optimize the operating conditions of magnetic components, yielding an optimal combination of low losses and high magnetic energy transfer efficiency."
  },
  {
    "year": "2025",
    "abstract": "Accurate classification of pollen grains is crucial for various fields, including ecology and food engineering. However, current approaches often face challenges due to limited data and the morphological variability of pollen grains. This study proposes a novel methodology emphasizing the separation of pollen images into equatorial and polar views, resulting in a significant improvement in classification accuracy. Using pseudo-labeling techniques, the dataset was segmented into these views, enabling the creation of customized datasets for classification. Experiments conducted with the Cretan Pollen Dataset, using a hybrid neural network combining of VGG19 and the CBAM attention mechanism, trained from scratch with data augmentation, demonstrated remarkable performance compared to previous studies. The VGG19+CBAM network achieved an accuracy of 98.78% and a precision of 98.72% with the dataset in its original format, and a precision of 98.06% with the view-separated dataset. This work highlights the fundamental role of view separation in enhancing classification results and advancing automated pollen analysis."
  },
  {
    "year": "2025",
    "abstract": "Metal corrosion detection is essential for ensuring structural safety and minimizing economic losses. While deep learning (DL)-based image segmentation has improved corrosion detection accuracy and efficiency, its high computational demands hinder deployment on resource-constrained edge devices. This study investigates lightweight DL models for corrosion segmentation by applying structured pruning to reduce computational costs while maintaining accuracy. We evaluate five segmentation architectures (U-Net, U-Net++, FPN, LinkNet, and MA-Net) and three pruning strategies (linear, automated gradual pruning, and movement pruning) on two corrosion image datasets (NEA and SSCS). Detailed trade-off analysis between model size, computational cost (MAC), and segmentation performance (IoU) reveals that pruning up to 90% sparsity leads to a≤10%IoU drop on SSCS and≤5%on NEA, demonstrating that significant compression is possible with minimal accuracy loss. However, some architectures (e.g., LinkNet) and pruning strategies (e.g., movement pruning) show significant performance deterioration, suggesting that pruning effectiveness varies across models. These findings provide insights into optimizing corrosion segmentation models for efficient deployment on edge devices, balancing accuracy and resource constraints."
  },
  {
    "year": "2025",
    "abstract": "Simultaneous wireless information and power transfer (SWIPT) provides an efficient approach towards prolonging the lifespan of wireless systems in 5G and beyond 5G communications by minimizing the reliance of devices on batteries and power sources. This paper suggests a SWIPT-assisted cooperative nonorthogonal multiple access (C-NOMA) network where a SWIPT enabled energy harvesting (EH) relay harvests energy from the source and utilizes it to forward the information to the end-user devices in the downlink. In order to obtain a realistic analysis, we aim to utilize a non-linear energy harvesting model and imperfect successive interference cancellation (imp-SIC) at the end user. The closed form expressions of outage probability (OP) and throughput are derived by considering multiple interfering signals at relay. Subsequently, the impact of the number of interferers on harvested energy and the OP, the power splitting (p.s.) ratio, distance between the nodes, and power allocation (p.a) factors are discussed in detail, and a comparison is presented against the traditional orthogonal multiple access (OMA) under the same conditions. The analysis clearly depicts that the proposed SWIPT-based C-NOMA system outperforms OMA in all aspects. Monte Carlo simulations are performed to corroborate the accuracy of the proposed analytical framework."
  },
  {
    "year": "2025",
    "abstract": "Palmprint recognition is a challenging task due to the variability in image quality, scale, and angle. Traditional methods often rely on single line features, which may not effectively capture the local bifurcation information critical for accurate recognition. To address these challenges, this paper proposes the Bifurcation Line Direction Coding (BLDC) method, which better captures the local bifurcation characteristics of palmprint images. Our approach leverages an improved Gabor filter for image preprocessing, where the main direction guides the branch direction. By considering both the maximum and minimum direction subscripts of the main direction, we generate robust feature codes that accurately represent the palmprint’s unique structure. Extensive experiments across five challenging palmprint datasets demonstrate that BLDC outperforms existing methods in recognition rate and feature extraction speed, providing a more effective solution for palmprint recognition in practical applications."
  },
  {
    "year": "2025",
    "abstract": "The imbalance due to increasing energy demand and the depletion of energy resources leads to an unstable power system. In conventional microgrids, the surplus heat of micro-turbines is wasted as electrical energy is used for various loads. Demand-side management scheduling the shiftable appliances based on cost-per-unit, overlooking consumer preferences and comfort. To address these challenges, a unified framework for managing and trading energy within renewable integrated combined cooling heating and power microgrids is proposed. Within this framework, each combined cooling heating and power microgrid initially employs demand-side management to fulfill its energy requirements while adhering to different constraints. If the load demands of any combined cooling heating and power microgrid are not fulfilled by its local renewable energy generation, then energy can be procured from nearby connected combined cooling heating and power microgrids or from the utility. Conversely, excess energy can be sold out to nearby combined cooling heating and power microgrids or to the utility. Additionally, in emergency situations, diesel generators can supplement the energy needs of any microgrids. Simulation results demonstrate 34.01% and 32.98% reductions in system costs and peak power demand while considering user preferences and comfort. Reducing the peak power demand will improve the system’s performance and efficiency."
  },
  {
    "year": "2025",
    "abstract": "This study introduces a novel model for predicting control variables in end-to-end autonomous driving by leveraging polynomial and differential networks. Recent advancements in autonomous driving have predominantly focused on methods that incorporate additional supervisory data, such as attention mechanisms and bird’s-eye view images. However, these approaches are often hindered by issues related to computational efficiency and the high costs of data acquisition for real-world applications. In contrast, the proposed method enhances the performance by integrating polynomial and differential networks, facilitating efficient learning while accounting for the physical properties inherent in the data. The results of experiments conducted using the CARLA simulator demonstrate that the proposed model outperforms existing state-of-the-art approaches. The model weights and training code used in these experiments are available athttps://github.com/choys0401/polydiff."
  },
  {
    "year": "2025",
    "abstract": "Small and medium-sized unmanned aerial vehicles (UAVs) often experience loss of texture detail and edge blurring in aerial images due to limitations in flight altitude and payload capacity. To enhance image quality, this paper proposes a multilayer residual network super-resolution reconstruction method that utilizes an attention mechanism. This method effectively extracts high-frequency feature information from images and improves detail recovery through a nested residual network structure and a channel attention mechanism. The network employs a deeply parallel architecture to fuse multilayer features, further enhancing reconstruction accuracy. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art techniques in terms of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) metrics on the Set5, Set14, and various open-source aerial imagery datasets. The reconstructed images exhibit significantly improved texture details and edge clarity. This method offers an effective solution for the high-quality reconstruction of UAV aerial images. We have named this method MARNet (Multilayer Attention Residual Network), which utilizes nested residual blocks and channel attention to achieve high-fidelity reconstruction."
  },
  {
    "year": "2025",
    "abstract": "Worker resources exhibit high flexibility, adaptability, and individual differences. It is critical to complete manufacturing tasks with a suitable worker resource allocation plan, given the increasing labor costs and the dynamic changes in production demands. It is often assumed in studies on traditional flexible job shop scheduling problems that the attributes of manufacturing resources, such as the number of workers and their skill levels, are known and fixed. This paper focuses on achieving resource allocation via personnel flexibility quantification and dual-resource collaborative scheduling optimization. A method based on the worker ability matrix, proficiency, and skill level coefficients is introduced to quantify and evaluate worker flexibility and individual differences. On this basis, an integrated optimization model for worker allocation and production scheduling is established considering the maximum completion time, total manufacturing cost, and worker load balancing. An algorithm based on a two-level decision model is proposed to solve this problem. The upper-level model for worker skill optimization configuration is based on a rule-based greedy algorithm, and the lower-level collaborative model for production scheduling is based on a hybrid genetic-simulated annealing algorithm. In the proposed algorithm, population initialization and neighborhood search strategies based on mixed multi-rules and critical paths are designed. A feasible production guidance scheme for the job shop is obtained by iteratively solving the two-level decision model, which provides the foundation for subsequent production. Test case results validate that the proposed algorithm can determine multi-skilled worker configuration strategies and achieve excellent scheduling solutions, completing the production tasks quicker, with lower costs and a more balanced task distribution."
  },
  {
    "year": "2025",
    "abstract": "With the spread of Web service technology, developers in heterogeneous communities have aimed to address the sharing and use of services on the Web in a growing and disorganized service description infrastructure. Service-oriented computing has proven to be essential, although it requires a set of appropriate supporting technologies. The RESTful service approach has replaced the typical Web service protocol stack introduced by W3C. RESTful style can be used by companies to expose data on the Internet, but to adopt this paradigm, developers must change how they implement and share services on the Web. RETSTful style adopts a uniform interface and the correct use of HTTP verbs and their semantics; these choices require replacing the traditional stack of constructors and parameters used by W3C’s Web services. The problem with RESTful design is that it uses human-readable formats to publish descriptions. Current methods of addressing this issue lack an agreed machine-readable semantic model to define service descriptions that support complex automatic operations via the services. This paper presents a semantic model for describing RESTful services based on the OWL-S ontology, which can store service descriptions in a repository that represents all RESTful objects with a semantic machine-readable language, OWL-DL. The authors considered the context of worldwide civil aviation, through the ICAO SWIM program, to build an application context for the proposed method. The results obtained indicate the usefulness of the proposed model."
  },
  {
    "year": "2025",
    "abstract": "This study proposes a neurosymbolic ERP architecture (NSEA) incorporating post-quantum cryptographic protocols to enable real-time cybersecurity and adaptive operational optimization. NSEA integrates CRYSTALS-Kyber lattice-based post-quantum cryptography with temporal graph neural networks and symbolic rule engines to enhance cybersecurity, decision automation, and legacy system compatibility. On industrial IoT (IIoT) edge devices, Kyber-512 achieves sub-5μs encryption latency and mitigates 72% of phishing attacks through dynamic response mechanisms. In demand forecasting tasks, the hybrid reasoning model reduced mean absolute percentage error (MAPE) to 6.8% and resolved 89% of inventory stockout alerts within 15 minutes. Field validation in air conditioning and automotive supply chains demonstrated a 63.4% improvement in disruption recovery time and a 62.9% reduction in logistics cost overruns, compared to baseline systems. A resilience metric based on Kolmogorov-Sinai entropy (DRE=0.81±0.05) quantifies the system’s robustness under simultaneous cyber and operational stress. Backward compatibility testing showed 92% schema alignment with legacy ERP modules through API translation, enabling a low-risk migration path. NSEA offers a unified and future-proof ERP solution that integrates security, intelligence, and interoperability in complex industrial environments."
  },
  {
    "year": "2025",
    "abstract": "Reinforcement Learning (RL) has shown great potential in a wide range of applications, including robotics, autonomous vehicles, and communication systems. However, deploying RL on edge devices poses significant challenges due to limited computational resources and the complexity of real-time decision-making. This paper proposes a novel hardware accelerator architecture for Deep Q-Networks (DQN) tailored to edge computing environments. The design supports both inference and training modes and utilizes shared hardware modules, approximate activation functions, and lightweight multipliers to reduce area and power consumption. The system also enables flexible configuration of neural network parameters and the execution of key RL components—such as policy generation, environment modeling, and reward calculation—via software on the processing system (PS). Quantization techniques, including Piecewise Linear (PWL) approximations and fixed-point representation, are employed to maintain computational accuracy and model convergence. The proposed accelerator, implemented on an Ultra96 FPGA at 70 MHz, achieves671×and287×speedups for inference and training, respectively, with only 13 mW power consumption. This architecture provides an efficient and scalable solution for deploying RL-based autonomous systems in resource-constrained edge environments."
  },
  {
    "year": "2025",
    "abstract": "Distributed photovoltaic (DPV) power sites in industrial parks are characterized by dispersed layouts, practical fault detection environments, and high safety requirements. Conventional manual DPV O&M systems using handheld sensors are inefficient, expensive, and struggle with fault detection due to sparse industrial data and uni-modal information limitations. To this, this paper proposes an innovative advanced algorithm for DPV fault detection in industrial parks, utilizing a new sparse industrial dataset, “SolarPark,” collected via multi-modal UAVs and annotated through a multi-expert process with uncertainty scoring. By fusing the Convolutional Block Attention Module (CBAM), Bidirectional Feature Pyramid Network (BiFPN), Ghost modules, the algorithm enhances attention to critical photovoltaic fault-related channel information, strengthens multi-scale photovoltaic fault feature fusion, and achieves lightweight efficiency. Combined with multi-modal UAV videos, the proposed industrial DPV fault detection algorithm achieves a precision of 95.4%, effectively ensuring the efficiency of DPV power sites in data-scarce industrial scenarios. Extensive experiments on the developed cloud platform confirm the proposed algorithm’s efficient, cost-effective, and easy to deploy for aerial inspections of DPV O&M systems."
  },
  {
    "year": "2025",
    "abstract": "The Poisson multi-Bernoulli mixture (PMBM) filter is capable of estimating the states of multiple targets based on available measurements. To address the limitations of the traditional PMBM filter, which involves the enumeration of assumptions that increases computational time and leads to inaccurate state estimates under noisy conditions, we propose the dual-label PMBM (DLPMBM) filter. This paper enhances the PMBM filter by incorporating labels for both measurements and targets. In the prediction and update phases, the filter is divided into a labeled Poisson point process (LPPP) and a labeled multi-Bernoulli mixture (LMBM) process, which predict and update undetected targets, potential targets, and surviving targets. During the measurement generation phase, each measurement is assigned a unique label, and an improved elliptical gate is used to filter the measurements, embedding them into the LPPP and LMBM measurement update processes. This approach reduces the enumeration of global hypotheses. Furthermore, to address the imprecise estimates of the conventional PMBM filter, an optimization method and its implementation are proposed in this study. To mitigate the uncertainties of conventional filters under nonlinear conditions, we develop an implementation of the Gaussian mixture DLPMBM filter using the square-root cubature Kalman filter (SCKF). The covariance matrix of unknown process noise is improved by integrating the Sage-Husa filter. To ensure the positive definiteness of the estimated covariance, Cholesky decomposition is employed in both the prediction and update phases of the DLPMBM filter. Finally, multitarget tracking experiments are conducted to demonstrate the performance of the proposed DLPMBM filter."
  },
  {
    "year": "2025",
    "abstract": "Traditional geometric methods estimate camera motion trajectories by analyzing image feature points or pixel information, demonstrating robust performance in certain scenarios. However, these approaches struggle in low-texture and highly dynamic environments. In contrast, end-to-end neural networks can directly predict camera motion trajectories from consecutive image frames, eliminating the need for complex feature extraction and matching processes. Nonetheless, the accuracy of this end-to-end approach still has a significant gap compared to traditional methods. We designed GD-MVO, a monocular visual odometry system that combines the strengths of two approaches. Our system uses both monocular and stereo image pairs to train a deep neural network for depth prediction, then integrates this depth information with geometric features extracted from sequential images to achieve more accurate visual positioning. In this work, we propose 1) a novel integration of geometric methods and deep learning for robust visual odometry; 2) an effective strategy to mitigate the impact of dynamic feature points on prediction outcomes; 3) a fly-out mask technique to resolve the fly-out padding issue in monocular depth prediction networks. Experimental results show that our GD-MVO not only exhibits excellent stability in high-dynamic scenes but also maintains reliable running performance on our specially customized low-texture dataset. In the KITTI odometry benchmark, GD-MVO outperforms both DF-VO and TSformer-VO across all metrics. Most impressively, it achieves a translation error of merely 1.778%, surpassing DF-VO (6.747%) and RAUM-VO (3.676%). Source code available athttps://github.com/lilili996/GD-MVO"
  },
  {
    "year": "2025",
    "abstract": "With the proliferation of meteorological sensor networks, ensuring data quality and reliability has become increasingly challenging. Traditional validation methods often fail to handle complex sensor behaviors, environmental variations, and real-time data verification requirements. This paper presents an innovative approach that leverages blockchain technology with a custom Multidimensional Sensor Validation Algorithm (MDSVA) to comprehensively address these challenges. Our enhanced MDSVA introduces a sophisticated five-component validation function that simultaneously addresses drift and noise compensation, environmental adaptation, periodic variations, dynamic thresholds, and transient adjustments. These components work multiplicatively, ensuring that significant issues in any single aspect substantially affect the overall validation result, while minor variations across multiple components have a more moderate combined effect. The mathematical model employs weighted exponential decay for noise reduction, temperature-based environmental scaling, sinusoidal periodic compensation, logistic threshold transitions, and temporal adaptation functions. This holistic approach significantly improves traditional validation methods by providing more nuanced and context-sensitive data validation. Integration with Hyperledger Fabric blockchain technology is achieved through smart contracts that implement this advanced validation algorithm, ensuring immutable record keeping and distributed consensus on data quality. The experimental results show that our implementation achieved a precision of 94.7% in sensor drift detection, with consistent performance (±1.2% variation) in diverse environments over 24 weeks. The system maintained 99.99% uptime with 4.2 second recovery time and demonstrated robust resilience by handling up to 30% simultaneous node failures while keeping resource utilization below 85%. This research contributes to the field of meteorological data quality assurance..."
  },
  {
    "year": "2025",
    "abstract": "Underwater terrain-aided navigation system can effectively correct the drift error of inertial navigation system that gradually increases with the accumulation of time, among which, underwater terrain suitability analysis is an important part of underwater terrain-aided navigation system. Traditional approaches view terrain matching and terrain suitability analysis as separate processes, which leaves terrain suitability analysis devoid of the knowledge used through navigation and terrain matching in particular. Whereas terrain matching can often provide useful information for TSA. This study attempts to use a deep learning model to deal with the terrain matching problem and terrain suitability analysis problem in the dimension of abstract features using a unified feature encoder. We propose a framework for sharing knowledge during the terrain analysis and matching phases, and construct a fitted probabilistic nonlinear classification network for matching. We validate the effectiveness of the method by performing suitability analysis in terrain regions with different geomorphic differences. After that, the good performance of the method is further verified by the navigation results in regions with different suitability. Finally, the feasibility and effectiveness of the terrain-assisted navigation system proposed in this paper are verified and analyzed as a whole in the form of semi-physical simulation."
  },
  {
    "year": "2025",
    "abstract": "Wireless Sensor Networks (WSNs) offer a powerful technology for sensing and transmitting data across vast geographical regions. However, limitations inherent to WSNs, such as low-power sensor units, communication constraints, and limited processing capabilities, can significantly impact their lifespan. To address these limitations and enhance the energy efficiency of WSNs, it is often necessary to divide sensors into clusters and establish routing to conserve energy. Machine learning algorithms can potentially automate these processes, minimizing energy consumption and extending network lifetime. This research investigates the application of machine learning algorithms, specifically Q-learning and K-means clustering, to propose the Energy-Efficient Machine Learning-based Clustering and Routing (EEMLCR) method for WSNs. This method facilitates cluster formation and routing path selection. The proposed method is compared with the well-established LEACH algorithm and two multi-hop variants, DMHT LEACH and EDMHT LEACH to validate its effectiveness. Our experimental results demonstrate the effectiveness of EEMLCR compared to LEACH and its multi-hop variants (DMHT LEACH and EDMHT LEACH). After 600 rounds in networks comprising 400 nodes, EEMLCR showed significant improvements in key performance metrics. These include increased alive nodes, reduced average energy consumption, higher remaining energy levels, and improved packet reception. Additionally, we compared EEMLCR with recent state-of-the-art algorithms such as EECDA and CMML, where our method demonstrated comparable or superior performance in terms of network lifetime and energy efficiency. By optimizing clustering and routing strategies, WSNs can reduce energy consumption, leading to more efficient utilization of the limited energy resources available to sensor nodes. The primary objective of this research is to contribute to the development of energy-efficient WSNs by leveraging machine learning algorithms for dat..."
  },
  {
    "year": "2025",
    "abstract": "Generative Neural Radiance Fields (NeRFs) have recently enabled efficient synthesis of 3D scenes by training on unposed real image sets. However, existing methods for generating multi-view images of specific input images have limitations, such as requiring camera parameters or additional components for estimating them. In this paper, we propose ZIGNeRF, a novel learning-based approach for zero-shot 3D Generative Adversarial Network (GAN) inversion that generates multi-view images from a single input image without requiring camera parameters. Our method introduces a novel inverter that maps out-of-distribution images into the latent space of the 3D generator without needing additional training steps. We demonstrate the efficacy of ZIGNeRF on multiple real-world image datasets, including Cats, AFHQ, CelebA-HQ, CompCars, and CUB-200-2011. For example, ZIGNeRF achieves an FID of 14.77 for face image generation when trained on the CelebA-HQ dataset. Furthermore, ZIGNeRF is capable of performing 3D operations such as 360-degree rotation and spatial translations by disentangling objects from the background. It can also generate style-mixed images by combining characteristics from two distinct input images, which is a pioneering attempt in 3D-scene synthesis. Our approach opens up new possibilities for flexible and controllable 3D image generation from real-world data."
  },
  {
    "year": "2025",
    "abstract": "The main contribution of this paper is to propose a methodology for the electromagnetic design of split axial segmentation switched reluctance generators (SRGs) to optimize power and torque. This paper investigates the impact of generator geometry segmentation on performance, addressing the longstanding challenges of torque ripple and power density. The hypothesis suggests that dividing the stator magnetization at each rotor angle can counteract the opposing machine torque, thereby improving torque ripple and enhancing power density. A mixed-methods approach combining literature review, simulation, and experimental validation was used to evaluate torque retarding effects and machine power density. The results demonstrate a significant reduction in torque ripple (59.3%) and an increase in power density603.3kWm3across all four segments. Specifically, axial separation segmentation markedly enhanced power density and design efficiency compared to conventional SRGs designs. This paper provides novel insights into improving torque ripple and power output while maintaining the same overall machine dimensions at 1206.6 W. Additionally, the simpler fabrication process of axial segmentation—where each segment maintains the same diameter—offers distinct advantages over radial segmentation, making it more practical for manufacturing. These findings highlight the potential for harvesting low-power driving energy from natural sources, contributing to advancing renewable energy technologies. So, the improvements in torque ripple reduction and power density provide valuable directions for optimizing SRGs, with further potential for enhancing driving turbine performance and utilizing better materials for greater energy harvesting efficiency."
  },
  {
    "year": "2025",
    "abstract": "The widespread adoption of microservices-based architectures in native cloud systems has amplified the need for robust observability strategies to ensure system reliability and performance. Microservices, while enabling scalability and flexibility, introduce complexities such as distributed failure points, performance bottlenecks, and resource mismanagement. This paper provides a comprehensive review of state-of-the-art observability frameworks and tools designed for microservices architecture. It focuses on key aspects of observability at the system, service, and network levels, utilizing logs, traces, and metrics as core data sources. A thematic taxonomy is proposed, classifying the diverse approaches to monitoring microservices based on implementation paradigms, deployment platforms, and architecture patterns. The study compares existing solutions in terms of their capabilities, limitations, and effectiveness in addressing observability challenges in cloud, edge, and fog environments. Furthermore, open research issues are identified, and practical recommendations are provided to optimize observability in complex, distributed microservices ecosystems. This work aims to serve as a valuable resource for system architects, DevOps engineers, and researchers striving to enhance the reliability and performance of modern cloud-native systems."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces the Susceptible-Infected-Removed Optimizer (SIRO), a novel learned heuristic inspired by biological systems and deep learning techniques. SIRO models its search process after the SIR epidemiological compartmental model, predicting the susceptibility, infection, and recovery dynamics of solutions. SIRO integrates deep learning into its initialization and parameter setting to enhance its efficiency, enabling intelligent and adaptive behavior. This hybridization improves solution quality, accelerates convergence, enhances robustness, and reduces computational costs. The algorithm’s performance was evaluated using CEC 2017 benchmark functions, demonstrating superior results in hybrid functions (C1-C28) despite moderate performance on traditional CEC1-CEC14 functions. Friedman’s test ranked SIRO 4th overall, with SSA as the top-performing algorithm. Additionally, SIRO was tested on real-world optimization problems, including mechanical engineering design, hyperparameter tuning, and feature selection for medical image classification. In the classification task, SIRO-enhanced CNN achieved an accuracy of 0.86 at the 5th epoch, outperforming CNN (0.66), CNN-GA (0.76), and CNN-WOA (0.75). Furthermore, SIRO reported a precision of 0.96, recall of 1.0, and F1-score of 0.98, highlighting its effectiveness. These results validate the benefits of integrating a learning mechanism into SIRO, yielding superior precision, computational efficiency, and performance over conventional optimization approaches."
  },
  {
    "year": "2025",
    "abstract": "Despite the United States’s major role as a rice exporter with significant economic and environmental impacts, most remote sensing and machine learning research on rice yield prediction has focused on Asian production regions. Moreover, while rice cultivation generates substantial methane emissions, few studies have explored the trade-offs between productivity and environmental impact. This study leverages remote sensing and machine learning techniques to predict U.S. county-level rice yields and methane emissions from 2008 to 2022 across 67 counties in six major rice-producing states. We use eight different machine learning models for predictions. XGBoost and EBM emerge as top performers, accurately predicting yields and emissions, individually, without overfitting. A key finding reveals that these models excel at out-of-season forecasts, accurately predicting yields as early as April-June of the growing season. Feature importance analysis highlights soil properties, particularly pH and texture at various depths, as critical predictors for both yield and emissions. Most importantly, this study advances an integrated economic-environmental modeling in agriculture by analyzing yield-emissions trade-offs through the Non-dominated Sorting Genetic Algorithm II (NSGA-II), revealing an unexpected synergy where practices that improve economic productivity also reduce environmental impact, as higher yields correlate with lower methane emissions."
  },
  {
    "year": "2025",
    "abstract": "The quality evaluation of three deep learning-based coding solutions for point cloud geometry, notably ADLPCC, PCC GEO CNNv2, and PCGCv2, is presented. The MPEG G-PCC was used as an anchor. Furthermore, LUT SR, which uses multi-resolution Look-Up tables, was also considered. A set of six point clouds representing landscapes and objects was used. As point cloud texture has a great influence on the perceived quality, two different subjective studies that differ in the texture addition model are reported and statistically compared. In the first experiment, the dataset was first encoded with the identified codecs. Then, the texture of the original point cloud was mapped to the decoded point cloud using the Meshlab software, resulting in a point cloud with both geometry and texture information. Finally, the resulting point cloud was encoded with G-PCC using the lossless-geometry-lossy-atts mode, while in the second experiment the texture was mapped directly onto the distorted geometry. Moreover, both subjective evaluations were used to benchmark a set of objective point cloud quality metrics. The two experiments were shown to be statistically different, and the tested metrics revealed quite different behaviors for the two sets of data. The results reveal that the preferred method of evaluation is the encoding of texture information with G-PCC after mapping the texture of the original point cloud to the distorted point cloud. The results suggest that current objective metrics are not suitable to evaluate distortions created by machine learning-based codecs. Finally, this paper presents a study on the compression performance stability of the tested machine learning-based codecs using different training sessions. The obtained results show that the tested codecs revealed a high level of stability across all training sessions for most of the content, although some undesirable exceptions may be found."
  },
  {
    "year": "2025",
    "abstract": "In this study, we introduce a new approach to secure computing by implementing a platform that utilizes a non-volatile memory express (NVMe)-based system with an FPGA-based Torus fully homomorphic encryption (TFHE) accelerator, solid state drive (SSD), and middleware on the host-side. Our platform is the first to offer completely secure computing capabilities for TFHE by using an FPGA-based accelerator. We defined secure computing instructions to evaluate 14-bit to 14-bit functions using TFHE. Our middleware allows for the communication of ciphertexts, keys, and secure computing programs while invoking secure computing programs through NVMe commands with metadata. Our performance evaluation demonstrates that our secure computing platform outperforms CPU-based and GPU-based platforms by 15 to 120 times and 2.5 to 3 times, respectively, in gate bootstrapping execution time. Additionally, our platform uses 7 to 12 times less electric energy consumption during the gate bootstrapping execution time than CPU-based platforms and 4.95 times less than a GPU-based platform. The performance of a machine learning application running on our platform shows that bootstrapping accounts for more than 80% of ciphertext learning time."
  },
  {
    "year": "2025",
    "abstract": "This paper explores a novel leakage-based capacity enhancement scheme in an orbital angular momentum (OAM) integrated multiuser MIMO system, where the leakage refers to the signal interference affecting other users. We aim to optimize a precoder using signal-to-leakage-and-noise ratio (SLNR) to maximize capacity and minimize interference and noise. The proposed SLNR-based precoding is compared to regularized zero-forcing (RZF), block-diagonalization (BD), and zero-forcing (ZF) techniques, all of which focus on interference mitigation or regularization. This comparison is conducted in indoor multiuser OAM-MIMO systems utilizing a uniform circular array for OAM mode generation. Simulation results show that the SLNR-based multiuser OAM-MIMO outperforms the traditional multiuser MIMO, RZF, BD, and ZF-based multiuser OAM-MIMO in the context of capacity. Notably, the SLNR method achieves capacity improvements of approximately 26% over ZF, 12% over BD, and 7% over RZF."
  },
  {
    "year": "2025",
    "abstract": "In recent years, Federated Learning applied to neural networks has garnered significant attention, yet applying this approach to other machine learning algorithms remains underexplored. Support Vector Machines (SVMs), in particular, have seen limited exploration within the federated context, with existing techniques often constrained by the necessity to share the weight vector of the linear classifier. Unfortunately, this constraint severely limits the method’s utility, restricting its application to linear feature spaces. This study addresses and overcomes this limitation by proposing an innovative approach: instead of sharing weight vectors, we advocate sharing support vectors while safeguarding client data privacy through vector perturbation. Simple random perturbation works remarkably well in practice, and indeed we provide a bound on the approximation error of the learnt model which goes to zero as the number of input features grows. We also introduce a refined technique that involves strategically moving the support vectors along the margin of the decision function, which we empirically show to slightly improve the performances. Through extensive experimentation, we demonstrate that our proposed approach achieves state-of-the-art performance and consistently enables the federated classifier to match the performance of classifiers trained on the entire dataset."
  },
  {
    "year": "2025",
    "abstract": "Fault detection is a critical process in ensuring the reliability and safety of modern power systems. With the evolvement of the grid in the modern paradigm, the detection of faults has become complex, particularly due to the incorporation of renewable based distributed generation. Thus, a detailed study of the available fault detection methods needs to be addressed while developing a fault detection model for the modern power system. In line with this, the paper provides a comprehensive overview of different fault detection techniques. The fundamentals of each technique have been elucidated in detail. Moreover, a through comparative analysis of each technique has been done on the basis of several terms to highlight the strengths and shortcomings of each method. Based on the review of these techniques, several prospective research gaps have been identified which will help the researchers to advance the study of power system protection."
  },
  {
    "year": "2025",
    "abstract": "Radio Frequency Identification (RFID) technology has become integral in various industries for automating processes and tracking items in real-time. However, efficiently offloading the large volume of data generated by RFID tags to readers poses significant challenges, particularly in dynamic environments where static or rule-based offloading methods fall short. This paper presents a novel approach for dynamically offloading data using deep reinforcement learning, specifically employing the Proximal Policy Optimization (PPO) algorithm. The proposed method utilizes a central controller equipped with the PPO model to make intelligent, real-time reader selection decisions based on environmental factors such as reader load, tag mobility, and network conditions. The reward function is designed to minimize data processing latency while maintaining balanced reader utilization, resulting in enhanced system efficiency. Extensive experiments demonstrate that the proposed PPO-based strategy significantly reduces average data processing latency by 30% and improves reader load balancing by 16% compared to conventional scheduling methods compared to conventional scheduling methods."
  },
  {
    "year": "2025",
    "abstract": "Accurately identifying aberrant issues on transmission lines is crucial to guaranteeing the power system operates safely and steadily. Transmission lines are a crucial part of the power system. In response to the current issues of low recognition accuracy and low image contrast in abnormal detection of power transmission lines. This paper develops a transmission line anomaly detection and real-time monitoring system combining edge computing and improved Efficient Det based on the characteristics of foreign object images. Firstly, by collecting abnormal images of transmission channels, the Retinex algorithm is used to enhance the input images. Secondly, in order to improve the speed of model detection, the convolution operation process for obtaining data features based on Ghost lightweight module is reconstructed. In the target recognition part, an improved EfficientDet algorithm is adopted as the main body, and the aspect ratio of anchor boxes in the algorithm is optimized using K-means clustering algorithm. At the same time, a gradient equalization mechanism is added to the loss function. The experimental results show that the proposed method effectively improves recognition accuracy and recall rate, achieving over 88% on different types of transmission lines. The ablation experiment shows that adding K-means clustering algorithm and gradient equalization mechanism can significantly improve recognition accuracy."
  },
  {
    "year": "2025",
    "abstract": "In recent years, generative adversarial networks (GANs) have made significant progress in generating audio sequences. However, these models typically rely on bandwidth-limited mel-spectrograms, which constrain the resolution of generated audio sequences, and lead to mode collapse during conditional generation. To address this issue, we propose Deformable Periodic Network based GAN (DPN-GAN), a novel GAN architecture that incorporates a kernel-based periodic ReLU activation function to induce periodic bias in audio generation. This innovative approach enhances the model’s ability to capture and reproduce intricate audio patterns. In particular, our proposed model features a DPN module for multi-resolution generation utilizing deformable convolution operations, allowing for adaptive receptive fields that improve the quality and fidelity of the synthetic audio. Additionally, we enhance the discriminator network using deformable convolution to better distinguish between real and generated samples, further refining the audio quality. We trained two versions of the model: DPN-GAN small (38.67 M parameters) and DPN-GAN large (124M parameters). For evaluation, we use five different datasets, covering both speech synthesis and music generation tasks, to demonstrate the efficiency of the DPN-GAN. The experimental results demonstrate that DPN-GAN delivers superior performance on both out-of-distribution and noisy data, showcasing its robustness and adaptability. Trained across various datasets, DPN-GAN outperforms state-of-the-art GAN architectures on standard evaluation metrics, and exhibits increased robustness in synthesized audio."
  },
  {
    "year": "2025",
    "abstract": "Filter bank multicarrier (FBMC) is a crucial complementary waveform to orthogonal frequency-division multiplexing (OFDM) in future communication systems. However, FBMC systems also suffer from the drawback of an excessively high peak-to-average power ratio (PAPR). Moreover, PAPR reduction methods designed for OFDM systems cannot be directly applied to FBMC systems due to the overlapping nature of FBMC symbols. In this paper, we propose a novel deep learning (DL)-based PAPR reduction scheme for FBMC systems. This innovative approach employs a deep denoising autoencoder (DAE) network in the time domain to suppress the PAPR of FBMC signals and reconstruct the ideal signal. Simulation results demonstrate that the proposed DAE-PAPR scheme achieves a PAPR reduction gain of approximately 2.3 dB to 4.5 dB compared to conventional state-of-the-art methods, while maintaining excellent bit error rate (BER) performance and out-of-band energy leakage characteristics."
  },
  {
    "year": "2025",
    "abstract": "Current approaches in face image generation typically focus on preserving identity or attributes exclusively. Identity preservation techniques maintain facial identity while enabling attribute manipulation, primarily serving personalized image generation applications. Conversely, attribute preservation methods retain facial characteristics while altering identity, commonly employed in face de-identification or dataset anonymization tasks. This dichotomy has created a significant gap in applications that require the simultaneous preservation of both aspects. In this paper, we present FaceArchive, a novel face tokenization framework that successfully disentangles and preserves both identity and attribute information from face images. Our architecture enables unprecedented control over face generation, allowing for either identity-preserving or attribute-preserving generation while maintaining high fidelity in both domains."
  },
  {
    "year": "2025",
    "abstract": "Inductive dynamic wireless power transfer (WPT) for moving objects, such as automated guided vehicles (AGVs), has become of special interest. For efficient and leakage-flux-reduced WPT for an AGV, only one transmitting coil (or a small array of transmitting coils) should be energized simultaneously; therefore, the position of the receiving coil should be detected precisely. Conventional AGV position detection techniques are often based on position detection sensors (magnetic or optical) placed near or inside each transmitting coil. However, this approach is expensive, relatively unreliable and it has high level of complexity. Therefore, in this study, a less expensive, more reliable and less complex technique for position detection of low-speed and moderate-speed AGVs (speed <1.5 m/s) is proposed and verified experimentally using a scaled-down AGV prototype. The technique is based on the ultrasonic distance measurement of a moving AGV to energize the correct transmitting coil. As shown in the comparative measurements, the performance of the dynamic WPT system with the proposed detection technique for low-to-moderate-speed AGVs is similar to that of the dynamic WPT system with conventional position detection techniques. However, the cost and level of complexity of the position detection system are moderately lower and the proposed position detection system is immune to optical radiation and magnetic fields. To extend applications of the ultrasonic techniques to high-speed AGVs, another AGV position detection technique based on the combined application of the maximum transmitting coil current detection and ultrasound-based AGV motion direction detection was also proposed."
  },
  {
    "year": "2025",
    "abstract": "Road damage detection is crucial for ensuring road safety and maintaining infrastructure durability, especially as increasing traffic and aging road networks create growing challenges for transportation systems worldwide. This process typically involves detecting irregularities on the road surface, such as cracks and potholes, from images. Current methods, integrating Single Shot Detector with MobileNet and Faster R-CNN, have successfully detected large potholes and long, deep cracks. However, detecting smaller, shallower cracks and minor potholes remains a challenge. Additionally, the appearance of road damage can vary under different weather conditions, making consistent detection difficult. To address these challenges, three modules are proposed. The Weather Trim Augment module leverages stable diffusion to generate weather-specific road damage datasets by adjusting prompt words and parameters, ensuring crack location and type remain unchanged, thus improving detection under various weather conditions. The Flexi Corner Block module enhances road damage detection by combining deformable convolutions with lightweight MLP and Learnable Local Attention, improving feature learning in corner areas. Moreover, the HXIOU loss function uses weighted calculations to effectively mine difficult samples, enhancing detection capabilities for challenging damages such as blurry potholes and fine cracks. Experimental results on the RDD2020 and CNRDD datasets demonstrate improved performance. On one hand, the proposed method achieves 64.9 on Test1 and a 40.6 F1-Score, demonstrating strong detection capabilities. On the other hand, the model exhibits robust generalization under adverse weather conditions, such as rain and snow, further validating its effectiveness in diverse environments."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a novel computer vision system, which enables real-time pathfinding for individuals with visual impairments. The navigation experience for visually impaired individuals has significantly improved “in traditional segmentation methods and deep learning techniques”. Traditional methods usually focus on the detection of specific patterns or objects, requiring custom algorithms for each object of interest. In contrast, deep learning models such as instance segmentation and semantic segmentation allow for independent recognition of different elements within a scene. In this research, deep convolutional neural networks are employed to perform semantic segmentation of camera images, thereby facilitating the identification of patterns across the image’s feature space. Motivated by a unique concept of a two-branch core architecture, we propose utilizing semantic segmentation to support navigation for visually impaired individuals. The “demarcation path” captures spatial details with wide channels and shallow layers, while the “path with rich features” extracts categorical semantics using deep layers. By providing awareness of both “obstacles” and “paths” in the surrounding vicinity, this method enhances the perceptual understanding of visually impaired individuals. We try to prioritize real-time performance and low computational overhead to ensure timely and responsive assistance. With a wearable assistive system, we demonstrate that semantic segmentation provides a comprehensive understanding of the surroundings to those with visual impairments. The experimental results showcase an impressive accuracy of 72.6% in detecting paths, path objects, and path boundaries."
  },
  {
    "year": "2025",
    "abstract": "Enhancing mono-channel speech signals in scenarios involving complex spectral mapping poses a formidable challenge in the domain of audio signal processing. To tackle this challenge head-on, this paper introduces a novel rapid speech enhancement network that harnesses the combined strengths of Convolutional Neural Networks (ConvNets) and Transformers. The proposed network seamlessly integrates ConvNets for robust feature extraction and Transformers for comprehensive long-term sequence modeling, resulting in a substantial enhancement in speech quality. In the encoding-decoding layers of the network, we introduce the Unified Discovery Unit (UDU), employing cooperative learning techniques to augment feature extraction. Through collaborative learning across network layers, the UDU facilitates the extraction of richer feature spaces from speech data, thereby enhancing the network’s ability to capture pertinent information. Building upon recent advancements, we introduce the Temporal-Spectral Cross-Attention Component (TSCAC) in the transference layer. This innovative component, comprising temporal and spectral attention Transformers, adeptly processes both subband and entire band speech information, effectively capturing temporal and spectral dependencies to preserve crucial speech characteristics. Recognizing the significance of channel-specific features in speech signals, we integrate a channel attention segment and develop the teachable Twin-Segment Attention Integration Component (TSAIC). This component extracts semantic features from a spatial-channel perspective, further bolstering the network’s capacity to attend to relevant information. Additionally, we introduce a Gaussian-Weighted Progressive Structure (GWPS) to compensate for any lost detailed features in deeper network layers, thereby enhancing the fidelity of the enhanced speech signal and mitigating information loss. Extensive experimental evaluations conducted on datasets of varying scales and languages un..."
  },
  {
    "year": "2025",
    "abstract": "Accurate tracking of surgical instruments is critical for the effectiveness of computer-assisted interventions to enhance visual information and reduce tissue injury risks. Previous approaches often modeled instrument trajectories rigidly, failing to capture the dynamic nature of surgical procedures, particularly in scenarios where instruments move outside the camera’s field of view or temporarily exit the body. Addressing these challenges, multi-instrument tracking is essential in the domain of surgical instrument detection and tracking. It plays a pivotal role in ensuring precise localization and identity preservation of instruments throughout surgical procedures. However, traditional multi-object tracking (MOT) methods, which decouple the detection and re-identification (re-ID) processes, frequently suffer from long-term reID in non-gaussian movement. To mitigate these issues, we propose SurgTrackNet, a unified framework specifically designed for surgical instrument tracking that integrates detection and tracklet association using transformer-based models. SurgTrackNet leverages a spatiotemporal memory network that stores previous observations of tracked surgical instruments, enhancing the system’s capacity to maintain consistent instrument identities and accurately predict their trajectories over time. The framework’s Instrument sequence creation network, utilizes a transformer encoder-decoder to generate instrument candidates, while a memory decoder integrates these proposals with track vectors to predict instrument locations and class, significantly minimizing the need for extensive post-processing. The memory encoding-decoding mechanism aggregates instrument features and associates them across frames, enabling consistent and robust detection and identity preservation of instruments throughout the surgical procedure. SurgTrackNet outperforms existing models, including other Transformer-based approaches, with a 78.7 MOTA and 75.5 IDF1 score on the CholecTrack20..."
  },
  {
    "year": "2025",
    "abstract": "Tropical cyclone is a sea storm that causes important life and economic losses in the coastal regions in the tropical zone around the equator of the earth. Tropical cyclone intensity is an important characteristic used to estimate the strength of the tropical cyclone. This study aims to improve the tropical cyclone intensity prediction by concatenating the spatial and temporal features of tropical cyclones. The proposed methodology utilized the deep learning based approach for handling 3D and 2D features for 24h early intensity prediction. In the first phase, a dynamic grid-based approach is utilized to extract the spatial features in a (3×3) grid format from the eye of the TC. These spatial features are extracted for four different components (u,v,t,r) and 37 different isobaric planes. In the second step, multiple convolutional layers are used to process each spatial component separately, and a fusion method is used to combine the spatial and temporal features. The proposed method achieved state-of-the-art results by reducing the MAE up to 3.31% overall and 8.5%,14.78%, 5.67% for u,v, and (u,v) add fusion components, respectively. The proposed methodology outperformed the state-of-the-art Saf-net model by 8.5 %,14.78%,5.67% for u,v, and (u,v) add fusion, respectively. A performance comparison on four real-time tropical cyclones (Bavi 2015, AERE 2016, NANMADOL 2017, HECTOR 2018) is also performed. The proposed model achieved MAE 2.92, 2.99, 2.46, 3.95 that are 10.08%, 34.35%, 23.65%, and 3.2% lower than state-of-the-art spatio-temporal models, respectively."
  },
  {
    "year": "2025",
    "abstract": "Autonomous mobile robots (AMRs) face challenges in navigating complex environments efficiently. To manoeuvre through both narrow and wide spaces, AMRs require two essential design features: a compact form for tight areas as well as a large configuration with omnidirectional movement for wide spaces. This study utilizes inhouse designed Expand and Collapse Variable Width Robot (ECVWR) to demonstrate effective area coverage. These ECVWR can contract to navigate constrained spaces and expand to optimize coverage in open areas. Existing methods for achieving complete area coverage do not account for the reconfiguration or the change in footprint. To address this issue, we propose the Depth-First Search (DFS) for Complete Coverage Path Planning Strategy (CCPPS) for ECVWRs. This method allows adjustments to the generation of waypoints in CCPPS, minimizing the path length. The simulation study shows that our proposed CCPPS outperforms contemporary state-of-the-art CCPPS, namely, GBNN, exhibiting superior expanded area coverage, reduced travel distance, and enhanced computational efficiency. Moreover real-world experiment to further benchmark the efficacy of our proposed algorithm. The proposed CCPPS is generic and can be extended to other variable footprint robots."
  },
  {
    "year": "2025",
    "abstract": "During colonoscopy procedures, gastroenterologists operate equipment with both hands, making real-time documentation of abnormal findings impractical. This reliance on memory increases the risk of missed details and prolongs report generation. Speech recognition technology offers a potential solution, but existing models struggle with Thai-English code-switching and suffer from overfitting when fine-tuned on small datasets. To address these challenges, we propose an Automatic Speech Recognition (ASR) model enhanced with the Mixture of Experts (MoE) technique within Transformer decoder layers. This approach enables domain specialization in gastroenterology (GI) while preserving Thai language knowledge, improving code-switching performance and mitigating catastrophic forgetting. Additionally, our Named Entity Recognition (NER) model extracts and categorizes GI terms from transcriptions to streamline colonoscopic reporting. Experimental results show that our MoE-ASR model achieves low word error rates (WER) (GI: 1.31%, Thai: 2.06%), with high medical term recall (MTR: 96.53%) and non-medical term recall (NTR: 95.85%), outperforming baseline models. The NER model also demonstrates strong performance, achieving precision (96.16%), recall (96.06%), and F1-score (95.11%). These results highlight the effectiveness of our approach in improving real-time documentation, reducing reliance on memory, and enhancing the efficiency of colonoscopic reporting."
  },
  {
    "year": "2025",
    "abstract": "This review paper explores the pivotal role of digital twin (DT) technology in advancing nuclear fusion research and its potential to address key challenges in achieving fusion energy as a sustainable power source. Whilst DTs have been developed to tackle complex issues in data analysis, real-time control, optimisation, and simulation, existing efforts are largely fragmented and constrained to isolated applications due to the experimental and evolving nature of fusion reactors. To bridge this gap, there is a pressing need for an integrated, end-to-end DT framework that can unify these capabilities, enabling a more holistic approach to reactor design and operation. This paper systematically reviews the current state of DT development, focusing on its application to critical components such as the divertor, breeder blanket, and magnets, which serve as ideal candidates for modular DT instances. By leveraging high-performance computing and vast datasets generated by fusion experiments worldwide, we identify opportunities to create scalable, data-driven surrogate models that can continuously refine live DT systems. The findings highlight the potential for centralised storage of the data and models to accelerate simulation-based testing (in silico) and optimisation of reactor components, ultimately contributing to the faster realisation of commercially viable fusion reactors. This integration of DT technology promises to significantly reduce the need for costly, iterative physical testing, paving an efficient pathway to achieving fusion as a reliable energy source."
  },
  {
    "year": "2025",
    "abstract": "Advancements in ultrasonic imaging sensors (UISs), such as improvements in cost-effectiveness, low power consumption, and suitability for challenging environments, have been useful for drone navigation. However, existing microelectromechanical systems (MEMS) transducer arrays suffer from limitations due to the non-uniform stress distribution of the thin-film layers, which changes the resonant frequency of devices. To address this, a novel sector slitted transducer design was proposed, which enhances the acoustic pressure output while maintaining mechanical stability and reduces the sensitivity of the resonant frequency to residual stresses. In this study, finite element analysis was used to model the slitted transducer design, which demonstrated minimal variation in resonant frequencies under different stress conditions. The MEMS transducer array simulations have displayed effective beam-steering capabilities using different phase profiles and validation of performance metrics through the Fresnel and Fraunhofer diffraction propagations. Both the imaging resolution and signal-to-noise ratio (SNR) of the array were evaluated over various distances. The figures-of-merit (FoM) of the sector-slitted design indicate that the transducer array is 1.6 to 30 times smaller than existing designs while being able to generate 26 to 965 times greater acoustic pressure than the other designs reported in the literature. Thus, the array promises enhanced performance in 3D range-finding and imaging applications for drones and mobile devices, offering compactness and efficiency. Future applications could leverage these advancements to improve autonomous navigation and environmental sensing in complex scenarios."
  },
  {
    "year": "2025",
    "abstract": "With the rapid development of big data and generative artificial intelligence (AI), education in the apparel industry is evolving beyond traditional theoretical instruction. This study explores the application of Smart Action Learning (SAL) and generative AI tools in the “Functional Clothing and Materials” course to enhance student engagement, problem-solving abilities, and practical skill acquisition. SAL, a student-centered learning approach, incorporates blended learning, flipped learning, and problem-based learning (PBL) methodologies to foster self-directed and cooperative learning. The study was conducted over an eight-week period with second-year students in an apparel major, integrating AI-based problem-solving techniques into coursework. The course design included a five-stage instructional framework: instructor-led lectures, problem identification, AI-assisted research, collaborative solution development, and final presentations. The effectiveness of this approach was evaluated through surveys measuring self-directed learning ability, cooperative learning ability, problem-solving ability, and academic achievement. Results indicate that students demonstrated high levels of engagement, improved problem-solving abilities, and increased learning satisfaction through AI-assisted collaborative projects. The findings suggest that incorporating generative AI into fashion education enhances creative thinking, industry readiness, and adaptability to emerging trends."
  },
  {
    "year": "2025",
    "abstract": "A novel measurement technique has been developed to enhance the accuracy of insertion loss measurements using vector network analyzers (VNAs), addressing the challenge of data fluctuations — a critical factor in determining circuit bandwidth and ensuring high-frequency signal integrity. The proposed method employs a Point-wise Least Squares (PLS) approach, eliminating the need for manual selection of smoothing bandwidth and simplifying the measurement process with a dedicated flowchart. This technique accurately differentiates insertion loss variations in microstrip lines, even across the Ka-band frequency range, ensuring reliable and consistent data by reducing deviations, particularly at band edges. The improved measurement accuracy supports the design and optimization of high-performance communication systems."
  },
  {
    "year": "2025",
    "abstract": "Despite advancements in imaging technologies, traditional diagnostic methods relying on manual interpretation by clinicians remain prone to errors. This underscores the need for robust automated segmentation techniques. Accurate three-dimensional (3D) Magnetic Resonance Imaging (MRI) brain tumor segmentation is critical for effective diagnosis in neuroimaging. Given the complexity of brain tumors, deep learning approaches have emerged as more suitable than traditional methods for efficient and precise segmentation. The dual difficulties of high computing needs in 3D convolutional networks and the necessity of more precise brain tumor diagnosis are addressed by this work. We provide an artificial intelligence (AI) framework combining bi-directional convolutional long short-term memory (ConvLSTM) layers with densely connected convolutions (DCC). Our method enhances spatial feature learning employing dense connections, and catches complex temporal links across MRI slices. Particularly for the identification of the Enhancing Tumor (ET) region, this novel combination solves the complexity limitation of convolutional techniques, hence improving segmentation robustness. Our approach is validated by extensive testing on the Brain Tumor Segmentation (BraTS) 2020 and 2021 datasets. On the BraTS 2021 dataset, the proposed M-BDCU-Net model beats many state-of-the-art approaches for particular tumor sub-regions with Dice Similarity Coefficient (DSC) scores of 0.81 for Tumor Core (TC), 0.85 for Enhancing Tumor (ET), and 0.82 for Whole Tumor (WT). With 8.81 million parameters and 60.34 GFLOPs, our model also greatly lowers complexity by up to 15% and balances accuracy with efficiency. It is thus much lighter than current models. These results highlight how rapid, more dependable, and exact brain tumor detection our system could allow. This work fills important voids in present research by combining methodological innovation with exhaustive evaluation and provides a useful answer f..."
  },
  {
    "year": "2025",
    "abstract": "Generating human motion within 3D scenes from textual descriptions remains a challenging task because of the scarcity of hybrid datasets encompassing text, 3D scenes, and motion. Existing approaches suffer from fundamental limitations: a lack of datasets that integrate text, 3D scenes, and motion, and a reliance on end-to-end methods, which constrain the diversity and realism of generated human-scene interactions. In this paper, we propose a novel method to generate motions of humans interacting with objects in a 3D scene given a textual prompt. Our key innovation focuses on decomposing the motion generation task into distinct steps: 1) generating key poses from textual and scene contexts and 2) synthesizing full motion trajectories guided by these key poses and path planning. This approach eliminates the need for hybrid datasets by leveraging independent text-motion and pose datasets, significantly expanding action diversity and overcoming the constraints of prior works. Unlike previous methods, which focus on limited action types or rely on scarce datasets, our approach enables scalable and adaptable motion generation. Through extensive experiments, we demonstrate that our framework achieves unparalleled diversity and contextually accurate motions, advancing the state-of-the-art in human-scene interaction synthesis."
  },
  {
    "year": "2025",
    "abstract": "Panoramic dental X-ray images are crucial tools in dental diagnosis, and accurate detection of teeth and related lesions is essential for clinical decision-making. However, the complexity of tooth structures, variability in image quality, and scarcity of annotated data make achieving precise automatic target detection challenging in this field. In this study, a dental X-ray disease target detection framework based on feature selection and enhanced reuse was proposed to address these challenges. An improved convolutional neural network architecture was designed and implemented by combining selective receptive field fusion with shape-sensitive multi-scale feature extraction modules to enhance the ability to detect targets of different scales and shapes. In addition, a novel feature reuse and skip fusion technique was introduced to further improve the utilization of features by the backbone network. To address the current lack of annotation for impacted teeth positions, an impacted tooth location image dataset named DENIMPACT is also presented, which significantly addresses the shortcomings of current deep learning object detection algorithms in the clinical diagnosis of dental impacted teeth on panoramic X-rays. Through experiments on our dataset, our method achieved a significant improvement in detection accuracy, with the mAP50 increasing from 0.410 to 0.631. The experimental results demonstrate that our model achieves state-of-the-art performance in tooth and lesion detection tasks, providing new solutions for the automated analysis of oral medical images. The dataset will be released at:https://github.com/hexiaomo624/DENIMPACT."
  },
  {
    "year": "2025",
    "abstract": "We present a novel UWB-based positioning system that incorporates a deep learning-based non-line-of-sight (NLOS) classifier and a switching tracking filter. Unlike conventional methods, the proposed classifier determines whether a measured distance was obtained under LOS or NLOS conditions by using not only the channel impulse response (CIR) but also the distance measurement and a previously estimated distance sequence. This combination enhances the detection of abrupt changes in distance, thereby improving classification accuracy. Additionally, we propose switching filters that operate using different noise statistics based on the classification result. Specifically, we explore combinations of a particle filter and a robust Kalman filter to mitigate the impact of significant errors in NLOS signals. In experiments, the proposed classifier significantly outperformed conventional classifiers. Furthermore, the switching filter-based methods demonstrated substantial improvements in localization performance compared to traditional approaches. Among the switching filters, the switching particle filter provided the best localization performance, though at the cost of higher computational complexity, whereas the switching robust Kalman filter was the fastest, albeit with slightly lower localization performance."
  },
  {
    "year": "2025",
    "abstract": "Percutaneous nephrolithotomy (PCNL) is a minimally invasive procedure to remove large renal calculi through a small incision in the patient’s back. Ultrasound (US) imaging is commonly used to guide the needle to the kidney during this procedure. However, it requires an advanced level of dexterity to coordinate the US probe and the needle to keep the needle visible in the images at all times. Failure to maintain needle-probe alignment can result in inadvertent injury, bleeding, and other complications. The use of robotic assistance can alleviate the surgeon’s cognitive workload by enabling autonomous positioning of the US probe and accurate needle tracking. This paper presents a new US-guided visual servoing (VS) algorithm for needle tracking using longitudinal US images of a needle subjected to out-of-plane motion. The ultrasound probe can move in 4 degrees-of-freedom (DOF), that is, two translations and one rotation in the imaging plane, and one rotation out of the imaging plane. Unlike previously reported VS algorithms, 4-DOF tracking is achieved using only 2D-US images and without any additional position sensor or prior knowledge of the needle trajectory. The algorithm is validated extensively in three different experimental scenarios using a water tank, a tissue phantom, and ex-vivo porcine tissue. Results obtained from several trials confirm the algorithm’s ability to track the needle and maintain needle-probe alignment with an average error of 1.5 mm, despite an out-of-plane average needle deflection of 7 mm along a 60 mm insertion depth."
  },
  {
    "year": "2025",
    "abstract": "Numerous government entities have implemented digital strategies to manage the COVID-19 crisis throughout the pandemic. Malaysia has enhanced its initiatives through its official mobile applications (apps), MySejahtera. MySejahtera plays an essential role in managing COVID-19, providing valuable preferences to guide health strategies, and has remained the principal application endorsed by the Ministry of Health of Malaysia. In contrast to over 200 other applications created by various Malaysian government agencies, MySejahtera stands out as the most extensively downloaded and persistently utilized application among users, suggesting a marked discrepancy in user adoption and engagement levels with other government apps in Malaysia. Existing research is deficient in examining valuable data resources and user experience in government app optimization. This study undertakes a comprehensive evaluation of MySejahtera through the meticulous analysis of application analytics and user feedback, aiming to assess its operational efficacy, patterns of user engagement, and performance indicators. Through the implementation of both statistical and thematic analyses, this study presents critical factors that affect the app’s sustainability and its effectiveness within the realm of Malaysia digital governmental services. By integrating the Technology Acceptance Model (TAM) with sustainability theories, this study offers a basis for appraising user engagement and application efficacy. Furthermore, this comprehensive study endeavor meticulously proposes a variety of optimization strategies that are fundamentally rooted in the best practices that have been observed and documented in the MySejahtera application, and these strategies encompass a wide array of enhancements to its key feature insights, emphasizing key feature insights, frequent updates, response to app reviews, user engagement, emerging technology adoption, geographical, demographic, and language diversity, enhanced secur..."
  },
  {
    "year": "2025",
    "abstract": "Traceability in the supply chain of perishable products faces significant challenges due to the limitations of traditional systems, such as centralized databases and conventional blockchain technologies. These solutions are often insufficient to ensure fast response times, energy efficiency, and scalability in dynamic scenarios, negatively impacting the quality and safety of food products. Furthermore, compliance with international regulations, such as those of the FDA and the European Union, requires implementing more efficient and transparent systems. This work proposes an innovative system that combines lightweight blockchain with IoT devices for traceability in the food industry. The system architecture is based on blockchain nodes optimized using lightweight consensus mechanisms, such as Proof of Authority, and integration with IoT sensors through efficient protocols such as MQTT. This combination ensures the collection and immutable recording of real-time data, including critical parameters such as temperature and location. The results show that the system reduces average response times to 105 ms in configurations with 10 nodes and 50 sensors, achieving transaction rates per second of up to 720. It also features an average energy consumption of 9.6 mJ per transaction and failure recovery times of just 5 seconds. These metrics highlight the system’s ability to operate in demanding environments with high data density, significantly improving existing technologies."
  },
  {
    "year": "2025",
    "abstract": "This work introduces a novel vision-based sensing approach for self-adaptable soft fingers using an embedded camera, demonstrating proprioceptive and exteroceptive capabilities. The system achieves normal force estimation, Z-displacement estimation, slip detection, and force application position classification by integrating the Pi Camera V3 sensor into the structure of an additively manufactured self-adaptable soft finger. Our approach avoids the deformation disambiguation required in elastomer-based sensors by enabling direct deformation sensing without additional sensing layers like a silicon pad that alters the finger’s compliant characteristics. The system also overcomes the occlusion limitations inherent in external camera-based methods by observing structural changes through strategically placed dot patterns within the finger’s internal geometry, which are visible to the embedded camera. The camera mounting position was verified using Finite Element Analysis (FEA) while ensuring finger compliance and as much deformation as possible without touching the camera. We combined two algorithms: an optical flow-based method for reliably detecting slip events and a Convolutional Neural Network (CNN) for force, displacement estimation, and position classification. The slip detection algorithm uses a dual-threshold approach that combines the Median Absolute Deviation (MAD) and standard deviation. Customized rigs integrated with a Universal Testing Machine (UTM) were used for sensor characterization, dataset acquisition, and slip detection parameter optimization. Furthermore, the system was validated through integration with an industrial gripper in an experimental sequence on different object types to mimic real-world manipulation, where both algorithms were integrated and deployed on Raspberry Pi 5 to achieve proprioceptive and exteroceptive sensing. Reliable performance was achieved with slip detection operating at 28.5 Hz and CNN update rate of 8 Hz. The experimental..."
  },
  {
    "year": "2025",
    "abstract": "This review paper systematically explores the use of Federated Learning (FL) in Connected Autonomous Vehicles (CAVs) to improve vehicle performance, safety and user experience. FL presents a decentralized infrastructure that allows collaborative learning, while also ensuring data privacy, as CAVs increasingly rely on machine learning to process large amounts of sensor data. FL has been demonstrated to contribute to cooperative perception, vehicle trajectory prediction, traffic flow optimization, predictive maintenance, personalized in vehicle experiences, and advanced driver assistance systems (ADAS) through recent advances. Secondly, FL speeds up anomaly and intrusion detection, critical safety and security matters in CAV ecosystems. However, despite all these advancements, there are still challenges of data heterogeneity, communication overhead, security vulnerabilities, model convergence as well as regulatory compliance that constitute major barriers to FL deployment. This paper synthesizes recent contributions on this topic, identifies some gaps in the current research, and proposes future directions to fill those gaps. Federated Learning is a promising technology path towards driving innovations and improving the power and effectiveness of Autonomous Transportation Systems."
  },
  {
    "year": "2025",
    "abstract": "Current clinical methods for quantifying blood loss have limitations, often leading to inaccurate assessments, such as overestimations caused by non-blood fluids mixing with blood. Given blood’s ability to absorb Near Infrared (NIR) light, this wavelength is widely utilized in blood spectroscopy and advanced techniques incorporating computer vision and machine learning. This study then investigates a multi-wavelength approach that extracts and integrates features from images captured under visible (Vis) light, NIR light, and a combination of both (Vis-NIR), which leverages unique information provided by individual wavelengths. The findings reveal that using color features from the multi-wavelength method significantly reduced errors by 56% compared to relying on a single wavelength. Further incorporating spectral and spatial features alongside hyperparameter tuning decreased errors by an additional 23%. A mean absolute percentage error (MAPE) of 8.475% was achieved, falling well within the acceptable error threshold of 20% in clinical blood loss estimations. Lastly, an individualized interpretation for each surgical test gauze is provided, a useful tool to understand how the machine learning model predicts the absorbed blood volume."
  },
  {
    "year": "2025",
    "abstract": "During the past decade, blind source separation (BSS) method has become an effective tool to characterize and identify modal parameters of linear systems. However, in practical engineering, the assumptions of guaranteeing conventional BSS method successful application cannot be frequently satisfied, which often lead to some challenging issues. One of these challenges is how to tackle the challenge of modal identification in situations of under-determination, which means that the total sensors should be not more than that of the active modals. In this paper, we explore an efficient under-constrained BSS approach called sparse BSS (SBSS) for addressing this problem. The drawbacks of conventional BSS are first listed and an improved SBSS method is proposed to deal with the above mentioned problem, which is shown to be more suitable for engineering applications. A 5-degrees-of-freedom numerical system and two analyses are employed to confirm the effectiveness of the suggested approach. The identified outcomes of modal parameters show highly satisfied accuracy via comparative analysis, which illustrates that the proposed technique has a potential application in structural engineering."
  },
  {
    "year": "2025",
    "abstract": "This paper addresses the issues of insufficient model accuracy and poor control performance in traditional unmanned aerial vehicle (UAV) lifting operations by proposing an improved control strategy for multi-UAV cooperative lifting operations and optimizing the dynamic model. Firstly, the efficiency of the operation is enhanced, by introducing multi-UAV cooperative lifting control. On this basis, the traditional dynamic model is improved, with a focus on the impact of variable rope length, analyzing the dynamic coupling relationship between rope length and swing angle, and constructing related coupling error functions to improve the stability and control accuracy of the system. At the same time, the interaction between the load and the swing is studied, considering the velocity relationship between the suspension point and the load, and taking into account the coupled effect of the load attitude. Finally, a Lagrangian dynamic model that includes multiple-UAV, variable rope length, and load-coupled effects is established. Based on the improved model, this paper proposes a coupled error function, designs a nonlinear controller based on the Lyapunov method, which is non-passive, and realizes precise position tracking of the UAV and suppression of the load swing, while maintaining the rope length within the desired range. Finally, the stability and convergence of the closed-loop system are proven through Lyapunov stability analysis and the LaSalle invariance principle. The simulation results show that the proposed method exhibits significant advantages in UAVs’ position, rope length tracking, and load swing suppression compared to the traditional lifting control strategy, and has strong robustness against uncertain parameters and external disturbances, verifying the effectiveness and practical value of the proposed method."
  },
  {
    "year": "2025",
    "abstract": "Accurately predicting dry matter intake (DMI) in lactating crossbred cows under semi-arid conditions is a critical challenge in dairy farming. Precise DMI predictions are essential for optimizing nutrient utilization and enhancing animal performance, particularly in semi-arid environments, where complex and dynamic conditions prevail. This paper introduces a novel Error-Based Evolving Takagi-Sugeno (EBETS) Fuzzy Model designed to address these challenges by dynamically adapting to real-time data and leveraging both current and historical information to enhance prediction accuracy. The EBETS model employs fuzzy set theory and multivariate Gaussian functions to model complex, nonlinear relationships between variables, offering a more robust and flexible approach to DMI prediction. In experiments involving data from 114 crossbred cows under semi-arid conditions, the EBETS model was compared to traditional models and an artificial neural network. It achieved a mean squared error of 0.25, which is more than 90% lower than that of all the other models, while demonstrating a higher correlation coefficient with the expected values, indicating superior predictive performance and reliability. These results underscore the EBETS model’s substantial superiority over existing methods, highlighting its potential to significantly improve dairy farming productivity by providing precise and reliable DMI predictions in challenging environmental conditions. The model’s ability to continuously learn and adapt to changing conditions makes it a promising tool for various applications in agricultural science."
  },
  {
    "year": "2025",
    "abstract": "Deep learning has become a cornerstone of modern Artificial Intelligence (AI), enabling machines to process and interpret complex visual information with unprecedented accuracy. As AI-generated content becomes more realistic, the ability to distinguish between machine-created and human-created images is increasingly important. This challenge extends beyond technical concerns, influencing digital media credibility, intellectual property rights, and the integrity of visual communication. Developing robust classification models to accurately attribute image origins is crucial for ensuring transparency, preventing misinformation, and upholding artistic authenticity in an era of rapidly evolving generative AI technologies. This study addresses the critical need to differentiate between AI-generated and human-generated aesthetic images through the application of advanced deep learning models. We investigate the effectiveness of advanced deep learning architectures including High Resolution Networks (HRNet), and Vision Transformers (ViT) which are generally accurate when used to infer the creative characteristics of human visual art. The proposed model ViT, employing a mechanism of self-attention to process images as sequences of patches for feature extraction, is examined for its potential to capture global contextual relationships within images, which is essential for recognizing the nuanced differences between AI and human artistry. ViT achieves 97% accuracy shows that superior performance validates its ability, using its transformer structure, to analyze and learn about the complex features of images which disclose their origin as compared to HRNet model of 95%. This research highlights the potential of using sophisticated deep learning techniques to address the challenges of content authenticity in digital media. By leveraging the unique strengths of each model, we provide insights into their applicability and effectiveness in distinguishing between different forms of..."
  },
  {
    "year": "2025",
    "abstract": "Blockchain is influencing the social media platforms by promising to solve the biggest issues of today, such as privacy concerns and content moderation, and the ability to provide a decentralized system for the management of social media platforms through cryptographic techniques and distributed structures. Conventionally, social media systems are based on central architectures that may indirectly solve the problems of data privacy and platform responsibility since there are increased threats, including identity theft and fake news spread across such systems. Blockchain has stepped up as an anti-centralized platform that allows multiple numbers of users to transact securely and authentically through P2P channels without a middleman. Here in this survey, we introduce a brief overview of the latest trends of the blockchain protocols and the interactions with the social media platforms, as well as present a systematic review of the related area. Specifically, the use case we consider and elaborate on is how blockchain can be applied to various types of social media services: smart contract-based content moderation platforms, user incentives using token economics, social media governance through decentralized autonomous organizations, and cross-chain connections. We then go further and offer a comprehensive literature review of blockchain incorporating main social media applications that cutting across them include identity, tokenization, and self-governance. The key points that can be derived from this review of the blockchain-enabled social media services and applications are also underlined here. We conclude this survey by listing the existing issues in the field, including scalability and compliance with the existing regulations, and suggesting the possible areas of research in this ever-evolving field."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a distributed fixed-time nonsingular terminal sliding mode (FxTNTSM) time-varying formation control scheme based on a hierarchical control mechanism (HCM) for autonomous surface vessels (ASVs) with model parameter uncertainties and unknown environment disturbances. The HCM includes a distributed estimation layer and a local time-varying formation control layer. Specifically, in the distributed estimation layer, a distributed fixed-time estimator (DFxTEO) is designed to estimate the leader’s state information. In the local time-varying formation control layer, a fixed-time integral sliding mode disturbance observer (FxTISMDO) is designed to estimate the compound disturbances lumped by uncertain dynamics and unknown ocean environment disturbances within a fixed settling time. A distributed time-varying formation control law for multiple ASVs is developed by incorporating the DFxTEO and the FxTISMDO into the FxTNTSM technique. Theoretical analyses and simulation studies show that the developed formation control law enables the multiple ASVs to achieve the desired formation control, and the formation errors can converge to the origin within a fixed settling time."
  },
  {
    "year": "2025",
    "abstract": "The L-LLC resonant converters have excellent performance to realize bi-directional power flow due to the symmetrical circuit structure of the resonant tank. The traditional frequency-domain based design approach of L-LLC converter suffers inaccuracies, and the traditional time-domain based design approach usually utilizes discrete process to find the optimal resonant parameters, which requires large computation and cannot ensure the actual optimization. Therefore, an optimal design method of the L-LLC converter based on data-driven model is proposed in this paper. Based on the numerical calculation method in bidirectional power flow, a closed resonant parameter space is established by satisfying the constraints including soft switching, operational mode, switching frequency and resonant capacitor voltage stress. The optimization objective is to minimize the overall losses of the converter. To reduce computational complexity, the adaptive polynomial approximation (APA) method is employed to fit the constraints and optimization objectives, thus the surrogate model is constructed. Then, the nondominated sorting genetic algorithm (NSGA-II) is employed to search the pareto-based optimal solution, which guarantees the synthetical minimal power losses in bi-direction power flow. Finally, a 400V/1000W experimental prototype was built to validate the effectiveness of the proposed design method."
  },
  {
    "year": "2025",
    "abstract": "The lower limbs, which have multiple degrees of freedom, can be used to manipulate a robot or an object in a virtual environment. Such manipulation can be achieved by measuring the direction of force exerted by the lower limbs using an isometric device equipped with a force sensor. This study experimentally investigates the differences between the intended and actual directions of force exerted by the lower limbs when operating an isometric device. The results of experiments conducted using 48 force directions indicate that there are five prominent characteristics in the differences between the intended and actual force directions. For example, when the intended force is the backward direction, an upward force component is also generated. In addition, we conducted a musculoskeletal analysis to analyze the causes of the differences between the intended and actual force directions and calculated the metabolic energy consumption (Em). The results confirm that some force directions result in lowerEmand show that the actual force directions measured in the experiment tend to be close to the force directions that resulted in lowerEm. This suggests that reducingEmis one of the causes of the differences between the intended and actual force directions."
  },
  {
    "year": "2025",
    "abstract": "Precise positioning, navigation, and timing (PNT) capabilities are essential for numerous critical infrastructure systems and advanced location-dependent applications. The challenges related to the reliability and accuracy of traditional Global Navigation Satellite Systems (GNSS) have driven the pursuit of innovative alternative PNT methodologies. This paper presents a novel approach inspired by the concept of biological symbiosis and leveraging the advanced capabilities of Reconfigurable Intelligent Surfaces (RISs). The proposed framework establishes a cooperative interaction between targets with unknown positions and collaborator nodes with approximate location estimates. These interactions are supported by the RISs and the anchor nodes with known positions. The objective is to minimize errors in positioning and timing for both the targets and the collaborators. This challenge is modeled as a non-cooperative game, and the existence of a Nash Equilibrium is demonstrated using potential game theory. To solve the game, Best Response Dynamics and a log-linear Reinforcement Learning (RL)-based approach are developed to identify the equilibrium state. The proposed system is thoroughly evaluated through simulations, in order to demonstrate its performance and the key trade-offs between game-theoretic strategies and the RL-based solutions."
  },
  {
    "year": "2025",
    "abstract": "This study introduces a dual-band absorptive bandpass filter that employs a dual-behavior matching section. The proposed design utilizes a filter methodology based on a low-pass filter prototype, enabling the development of higher-order distributed dual-band absorptive bandpass filters with the control of two center frequencies and bandwidths. The proposed filter requires fewer resonators than the existing dual-band absorptive filters owing to the dual-band matching section design based on an image parameter method. The proposed configuration is implemented to design and fabricate two filter prototypes with center frequencies of 1.3 GHz and 1.6 GHz on a substrate characterized by a relative permittivityεr=3.42and a thicknessh=30mil. The first filter (two-pole configuration) demonstrated a measured return loss exceeding 11.3 dB at 0.8–2.2 GHz, and the second filter with three-pole exhibited a measured return loss exceeding 10.2 dB at 0.8–2.2 GHz. These dual-band absorptive bandpass filters are suitable for application in cognitive radio and carrier aggregation systems."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we study Internet of Things (IoT) domain names, the domain names of backend servers on the Internet that are accessed by IoT devices. We investigate how they compare to non-IoT domain names based on their statistical and DNS properties and the feasibility of classifying these two classes of domain names using machine learning (ML). We construct a dataset of IoT domain names by surveying past studies that used testbeds with real IoT devices. For the non-IoT dataset, we use two lists of top-visited websites. We study the statistical and DNS properties of the domain names. We also leverage machine learning and train six models to perform the classification between the two classes of domain names. The word embedding technique we use to get the real-valued vector representation of the domain names is Word2vec. Our statistical analysis highlights significant differences in domain name length, label frequency, and compliance with typical domain name construction guidelines, while our DNS analysis reveals notable variations in resource record availability and configuration between IoT and non-IoT DNS zones. As for classifying IoT and non-IoT domain names using machine learning, Random Forest achieves the highest performance among the models we train, yielding the highest accuracy, precision, recall, andF1score. Our work offers novel insights to IoT, potentially informing protocol design and aiding in network security and performance monitoring."
  },
  {
    "year": "2025",
    "abstract": "Renewable Energy Communities (RECs) are envisaged as a key enabler for a citizen-driven energy transition. The pooling of renewable energy resources at a local level and the active involvement of public entities, Small and Medium-sized Enterprises (SMEs) and private customers can lower the energy costs of end-consumers and increase public acceptance of renewable projects. At the same time, the RECs can support power system operation by leveraging their flexibility and providing ancillary services to the grid. While a significant amount of research has focused on optimizing the operation of existing RECs to maximize their performance and economic benefits, fewer studies have analysed the forecast of future REC performance to support the planning of new communities. The present paper tackles this research gap by developing a novel tool for the forecast of techno-economic performance of REC. The tool relies on two different techniques (based on statistical random sampling and neural networks, respectively) to predict the energy behaviour of RECs on the basis of their fundamental planning parameters (type/number of members, installed generation, geographical location). In order to reach a larger audience of practitioners, a web-based open-source implementation of the tool has been developed and made available to the general public, designing a graphical interface that facilitates the use of the tool by non-technical experts."
  },
  {
    "year": "2025",
    "abstract": "This article introduces a new single-stage boost five-level inverter with minimum components, consisting of six switches, one diode and two capacitors. The proposed topology has benefits, such as boosted output voltage, compactness, and lower impulse charge currents due to soft charging. The benefits of the proposed topology are elucidated through a comparative analysis with recently developed single-stage boost five-level inverter topologies. The required switching sequence pattern is generated by single-carrier pulse-width modulation. Through simulation and a laboratory prototype model, the proposed 400 W topology is validated, demonstrating its suitability across a range of modulation indices and dynamically changing loads."
  },
  {
    "year": "2025",
    "abstract": "Abnormal classification of metal components plays an important role in industrial product manufacturing. However, it is difficult to detect metal anomalies due to the following issues: 1) Some defects of metal parts areas are small; 2) The abnormal metal regions are relatively similar to the normal ones. To address these problems, a Manhattan Correlation Attention Network (MCA-Net) is proposed for anomaly classification from the metal part, where the Manhattan Retentive Attention (MRA) module is designed to search for small anomaly regions by global information modeling, and the Structural Contextual Attention (SCA) module is devised to discriminate the similar abnormal regions from the normal ones by aggregating contextual structured dependency. Experiments on the benchmark verify the effectiveness of the proposed MCA-Net for metal part anomaly classification, achieving the performance of 91.76%, 91.76%, 91.69%, 91.35% on the accuracy, precision, specificity, and F1-score, respectively, further assisting in metal part classification in manufacturing."
  },
  {
    "year": "2025",
    "abstract": "This study aims to systematically review the current literature regarding security concerns in multi-cloud environments. The main objective is to identify critical security issues, current solutions, investigate challenges, and propose recommendations for future research. This study uses a systematic literature review methodology adopting the Kitchenham method, which includes a literature search across leading academic databases including IEEE Xplore, ScienceDirect, ACM, SpringerLink, Emerald Insight, Nature, Taylor & Francis, Scopus, and ProQuest. A formal protocol was followed to conduct an automated search of relevant articles published between 2021 and 2024, and filters were applied. Based on the initial search results, 2038 studies were found, then the selection criteria process (inclusion and exclusion) and quality assessment were carried out, and finally 30 studies were selected for further research. The results show that most of the multi-cloud security issue trends fall into the areas of data, cryptography, authentication and authorization, followed by areas of service availability, confidential computing, and non even fall into the area of virtualization. In addition, this study systematically analyzes the relevant literature and identifies problems, solutions, challenges, and recommendations for future research. The findings of this review are expected to provide a strong overall picture for further research in multi-cloud environments."
  },
  {
    "year": "2025",
    "abstract": "The study presents H-UDMIR, a novel hybrid medical unsupervised deep learning (DL) framework for deformable image registration (DIR) that integrates U-Net architecture and Spatial Transformer Networks (STNs). The U-Net initially predicts coarse deformation fields, which are then enhanced by cascaded STNs to dynamically register local image regions while tolerating a loss function to effectively balance deformation smoothness and image fidelity. This hybrid approach exhibits enhanced registration performance and resilience without the necessity for annotated training data. Experimental results using H-UDMIR highlight its precise registration capabilities across varied anatomical structures and imaging modalities: kidney computed tomography (CT) scans and brain magnetic resonance imaging (MRI) datasets. Notably, H-UDMIR achieves a Dice similarity coefficient of 92.72% and a Hausdorff distance of 881.9244 on low- and high-dose kidney CT scans, surpassing VoxelMorph’s 84.04% Dice score. A comparative analysis against state-of-the-art approaches such as VoxelMorph underscores H-UDMIR’s superior performance."
  },
  {
    "year": "2025",
    "abstract": "Presents corrections to the paper, (Corrections to “Gradual Variation-Based Dual-Stream Deep Learning for Spatial Feature Enhancement With Dimensionality Reduction in Early Alzheimer’s Disease Detection”)."
  },
  {
    "year": "2025",
    "abstract": "Uncrewed aerial vehicle (UAV)-assisted multi-access edge computing (MEC) is increasingly being adopted to meet the rising demand for low-latency and efficient data processing, particularly in environments with limited ground infrastructure. However, optimizing task offloading and resource allocation in such networks remains a significant challenge as the number of UAVs and connected devices grows. To address this, we propose a Trajectory-Based Task Offloading in UAV-Assisted MEC (TB-TUAV) scheme, which leverages UAV mobility to enhance resource utilization and reduce latency. Unlike existing methods, TB-TUAV integrates a deep reinforcement learning (DRL) framework based on a Markov Decision Process (MDP) to dynamically optimize task offloading and resource allocation in multi-UAV networks. Our approach effectively balances exploration and exploitation, improving learning stability and ensuring fast convergence. By incorporating trajectory optimization through random path exploration, the proposed scheme efficiently distributes computational tasks while mitigating processing delays. Simulation results demonstrate that TB-TUAV significantly improves resource efficiency and reduces latency compared to state-of-the-art baseline methods. This research presents a scalable and adaptive solution for real-time MEC applications in dynamic multi-UAV environments, ensuring improved performance even under resource constraints."
  },
  {
    "year": "2025",
    "abstract": "The increasing penetration of electric vehicles (EVs) and photovoltaic (PV) systems poses significant challenges to distribution grid performance and reliability. Battery energy storage systems (BESS) offer a promising solution to mitigate these challenges; however, most existing BESS optimization strategies fail to simultaneously enhance grid performance and maximize economic benefits for BESS owners. This research proposes an optimized BESS dispatch strategy that balances both grid performance and BESS bid pricing in the transactive energy (TE) market through a multi-criteria decision-making (MCDM) method. The strategy aims to reduce energy procurement costs and create a more favorable system for EV users by minimizing their charging expenses. Using the DIgSILENT PowerFactory power system software for modeling and simulation, the active and reactive power dispatch of BESS is optimized via a differential evolution (DE) algorithm. The experimental validation of the proposed approach demonstrates significant improvements in grid performance, reduced energy costs, and enhanced flexibility for distribution network operators (DNOs) in prioritizing either grid performance or financial considerations, or both. Overall, this novel approach provides an effective framework for DNOs to enhance grid performance while strategically incorporating the economic aspects of BESS, ultimately lowering EV charging costs compared to existing methods."
  },
  {
    "year": "2025",
    "abstract": "Analyzing fetal electrocardiograms (fECG) to classify fetal arrhythmia is a challenging task; still, it is indispensable for evaluating fetal cardiac health status. This study intends to develop a framework for the effective discernment of fetal arrhythmia that assists obstetricians in diagnosing whether the fetuses have any abnormality in cardiac rhythm. In this work, authors aim to develop a three-stage fetal arrhythmia detection framework comprised of 1) fECG extraction from abdominal Electrocardiogram (aECG) signal based on functional link neural network adaptive filter, 2) denoising of extracted fECG exploiting a generative adversarial network where the generator and the discriminator follow robust architectures, and 3) fetal arrhythmia detection based on FAViTNet architecture. The proposed work deeply focuses on the last stage, where we have unfolded a deep convolutional architecture that detects fetal arrhythmia utilizing high-resolution spectral images acquired from the Stockwell transform. The classification stage demonstrates an architecture involving spectral image tokenization and transformer encoder blocks. The spectral image tokenization module involves ghost bottleneck blocks, which are utilized to generate feature maps from the spectral images, subsequently transformed into 1D token embeddings. Channel-wise calibration is utilized to attain more attention to the deep feature maps acquired from the ghost network. The transformer encoder block effectively attains the long-term dependencies from the 1D embedded features with gated linear unit (GLU)-based multi-head self-attention where deep features are learned to discern fetal arrhythmia effectively. The proposed algorithm shows an accuracy of 96.85%, sensitivity of 96.69%, specificity of 96.98%, and precision of 96.48%."
  },
  {
    "year": "2025",
    "abstract": "As more people and devices come online with the rapid growth of the internet, the need for secure and efficient network resource management becomes increasingly important. The boom of these connections on Next Generation Wireless Networks through the advent of technologies like the Internet of Things has changed the landscape of traditional edge networks. This necessitates a drastic change in the existing edge network infrastructure. As these devices come online, make requests, and go offline, the allocation and management of edge network resources become paramount. Blockchain, with its growing popularity, presents itself as a potential solution. The inherent features of blockchain, such as decentralization, transparency, security, and immutability, make it possible for network providers to manage network resources efficiently. This survey paper delves into the diverse applications of blockchain in edge network resource management, offering a comprehensive discussion of its potential to revolutionize network infrastructure. Unlike other surveys, we focus this work on three specific contexts of blockchain integration for network resource management: Cloud and Edge Computing, Radio Access Networks in Next Generation Wireless Networks, Reinforcement Learning, and Federated Learning. We provide an extensive analysis of recent research advances in these areas, and the main findings are highlighted. Understanding the current use of blockchain and network resource management opens the door to new research and more efficient and secure networks. The open research issues that arise from the combination of blockchain with the management of edge network resources are identified. Finally, the future directions to fuel innovative research are presented in this survey."
  },
  {
    "year": "2025",
    "abstract": "Multilevel inverter topologies with cascaded H-bridges fed by asymmetrical direct-current (DC) voltage sources have higher output voltage levels than symmetrical ones and are preferred in electric vehicles (EVs). However, these converters are difficult to incorporate in electric vehicles because the system requires a significant number of isolated DC supplies. This study presents a novel multilevel inverter drive topology, which is powered by a single battery source and uses a small, affordable high-frequency link (HFL) to generate isolated DC sources across H-bridges. The HFL consists of a Single-Input Multiple-Output (SIMO) flyback converter and a Bidirectional DC-DC (BDC) converter, which enables dynamic voltage control with a finite number of levels. This study focuses on a 27-level inverter fed induction motor drive with a cross-regulated DC link. In addition, the proposed multilevel drive system enables a smooth transition from motoring to regenerative charging of the battery with three-level rectifier operation of the cascaded H-bridge converter. The hybrid nearest level control (HNLC) modulation scheme is deployed in the proposed drive to control the inverter voltage over a wide range of speed variations without compromising the number of voltage levels. The proposed topology was simulated using MATLAB/Simulink and validated using hardware experiments."
  },
  {
    "year": "2025",
    "abstract": "Healthcare-associated infections are a significant public health concern. This study presents the Spatiotemporal Epidemiological Similarity based on Patient Trajectories (StESPT) method to provide clinicians with support in investigating the epidemiological relationships between infected patients, making detecting outbreaks and identifying possible transmission routes. To this end, the StESPT retrieves the movements of infected patients through the hospital and transforms them into trajectories. Then, a Trajectory Distance Measure Algorithm (TDMA) was used to quantify the spatiotemporal similarity between the trajectories of each pair of patients. Finally, based on the results of each TDMA, the k-means clustering algorithm was used to group patients, which can help understand the spread of the infection. We compared the suitability of three commonly used TDMAs (Dynamic Time Warping (DTW), Spatiotemporal Linear Combine similarity (STLC), and Spatiotemporal Longest Common Subsequence (ST-LCSS)) that were modified to measure similarity instance of distance. For each TDMA, we also proposed a version that adapts better to the semantics of our problem. The StESPT method was tested with a synthetic simulation of Clostridium difficile infection in a hospital. The results of the modified version of the ST-LCSS-WTW best reflected the spatiotemporal relationships between patients and led to the k-means clustering revealing two potential outbreaks."
  },
  {
    "year": "2025",
    "abstract": "Data set bias not only compromises the fairness, accuracy and effectiveness of trained models, but also leads to a lower performance in real-world scenarios compared to the evaluation results obtained with a specific data set. This issue is especially evident in the estimation of head pose, as current data sets suffer from a limited number of images, imbalanced data distributions, the high cost of annotation, and ethical concerns. Synthetic data offers a promising solution to address these challenges, but current semi-synthetic data sets fail to deliver satisfactory results, likely due to the limited realism of the generated faces and the heavily skewed pose distribution. In this paper, we report the existence of data set biases in the most widely used head pose estimation benchmarks, which lead to an optimistic estimation of model performance in real-world scenarios. To mitigate this issue, we create a synthetic image data set using a generative model with explicit control over the head pose. Our experiments demonstrate that incorporating our synthetic images leads to improved generalization and accuracy."
  },
  {
    "year": "2025",
    "abstract": "The choice of activation function—particularly non-linear ones—plays a vital role in enhancing the classification performance of deep neural networks. In recent years, a variety of non-linear activation functions have been proposed. However, many of these suffer from drawbacks that limit the effectiveness of deep learning models. Common issues include the dying neuron problem, bias shift, gradient explosion, and vanishing gradients. To address these challenges, we introduce a new activation function: Softsign-based Piecewise Parametric Linear Unit (Sb-PiPLU). This function offers improved non-linear approximation capabilities for neural networks. Its piecewise, parametric design allows for greater adaptability and flexibility, which in turn enhances overall model performance. We evaluated Sb-PiPLU through a series of image classification experiments across various Convolutional Neural Network (CNN) architectures. Additionally, we assessed its memory usage and computational cost, demonstrating that Sb-PiPLU is both stable and efficient in practical applications. Our experimental results show that Sb-PiPLU consistently outperforms conventional activation functions in both classification accuracy and computational efficiency. It achieved higher accuracy on multiple benchmark datasets, including CIFAR-10, CINIC-10, MWD, Brain Tumor, and SVHN, surpassing widely-used functions such as ReLU and Tanh. Due to its flexibility and robustness, Sb-PiPLU is particularly well-suited for complex image classification tasks."
  },
  {
    "year": "2025",
    "abstract": "The doubly salient electromagnetic generator (DSEG) has the advantages of simple structure, high-temperature and high-speed environment adaptability, high reliability, which can build a competitive aerospace brushless DC starting/generation system. The dynamic response of the power generation system with diode rectifier (DR) is limited by the DC-link capacitor and the large time constant of the excitation winding. The adoption of active rectifier (AR) can increase the output power, reduce the copper loss, and improve the system efficiency. Either the excitation current or the armature current can be adjusted to control the output voltage in the generation system with AR. However, adjusting only one of the two currents cannot achieve optimal performance in terms of dynamic response and copper loss. This paper proposes an optimal current distribution control (OCDC) strategy for the active rectifier power generation system, which is based on the back electromotive force (EMF) oriented vector control (BEFOVC) strategy. By using an armature current inner loop to replace the excitation current inner loop and controlling the excitation current according to the minimum copper loss trajectory (MCLT), the OCDC strategy improves the dynamic performance and reduces the copper loss of the DSEG system. Simulations and experiments comparing the traditional voltage control strategy with the proposed strategy verify the feasibility and superiority of the OCDC strategy."
  },
  {
    "year": "2025",
    "abstract": "This systematic literature review (SLR) analyzes the various applications of artificial intelligence (AI) in healthcare, with a particular emphasis on the integration of emotive and cognitive analytical frameworks. The primary aim of this investigation is to thoroughly evaluate the influence of AI technology on patient care by analyzing emotional processes and enabling patient-centered solutions. In this research, we investigate the cognitive and emotional approaches to sentiment analysis and other modeling and forecasting methods using AI. Primary sources include patients’ reviews, online health exchanges and doctors’ narratives. Key aspects of the present state of affairs are advances in the development of machine learning algorithms for emotion recognition, intracellular fusion of cognitive and affective modes of analysis, and the application of artificial intelligence for the enhancement of clinical support systems. Moreover, these technologies have significantly improved individualized clinical approaches, expedited the early identification of mental health problems, and strengthened the rationale for therapeutic treatments. Despite recent advancements, the discipline still faces numerous persistent obstacles. Pressing issues include the ethical implications of using artificial intelligence, the need to protect patient privacy, and the complexity of detecting biases in algorithms. Nevertheless, the impact of AI on healthcare practices is indisputable, indicating a future marked by a more intelligent, efficient, empathetic, and patient-centered healthcare system. This study examines the consequences of artificial intelligence in healthcare by analyzing its importance in emotional and cognitive computing, tracking ongoing developments, and promoting the use of AI in healthcare while considering individual requirements."
  },
  {
    "year": "2025",
    "abstract": "Nonintrusive electrical monitoring enables fault detection and diagnostics for power systems from an aggregate monitoring point. Faulty electromechanical equipment often produces unrecognizable electrical signatures that confound data-driven techniques. Fault signatures are typically unknown during training. For some loads, analytical models and simulation can predict fault signatures, facilitating their inclusion in the training set. However, this approach scales unfavorably with the number of parameters associated with faults. An alternate outlook recognizes that faults often change the power system conditions and the quality of power delivered. Assumptions about the character and quality of the local grid should be called into question during faulty load behavior. The objectives of this work are to correlate these changing grid behaviors with load and fault signatures as a step towards automatic fault detection. Our methodology involves creating supplemental “derived” data streams distilled from nonintrusive electrical measurements that can correlate changes in grid conditions and quality with load operation. Using real fault data from shipboard microgrids, our key findings illustrate that combining these derived streams with nonintrusive power data enables both nonintrusive load identification and fault diagnosis. Finally, this work presents a vision for implementing an integration of these streams with physics-based fault models in an automatic fault detection system."
  },
  {
    "year": "2025",
    "abstract": "This article proposes a miniaturized, low-loss, and continuously tunable slow-wave (SW) liquid crystal (LC) phase shifter, designed specifically for the 60 GHz millimeter-wave band. The 60 GHz frequency range, with its wide bandwidth and short wavelength, enables compact and high-performance designs, making it ideal for next-generation communication systems. A three-parallel-stub slow-wave unit, incorporating fine rectangular branches and gaps, is proposed to enhance the slow-wave effect. A rectangular defected ground structure (DGS) is introduced to increase the bandwidth, while gradient stubs in the coplanar waveguide (CPW) are employed to improve impedance matching between the CPW port and the inverted microstrip line (IMSL) port. The equivalent circuit model of the proposed slow-wave unit is analyzed, and the evolutionary process of the structural design, along with its impact on phase velocity, is examined through comparison. Measurement results indicate that the structure achieves a phase shift of up to250∘/λand a figure of merit (FoM) of41.7∘/dB, with an insertion loss of more than -6 dB. The simulation and measured results are in good agreement, demonstrating the feasibility of the proposed design in the 60 GHz band."
  },
  {
    "year": "2025",
    "abstract": "Recurrent fragility fractures are a big challenge in managing bone health, especially in older adults and people with osteoporosis or related disorders. The prediction of such fractures depends on the overall understanding of various clinical and lifestyle factors contributing to bone fragility. The goal of this analysis is to carry out advanced predictive analytics related to the problem of recurrent fragility fractures concerning several key features about each patient: age, sex, body mass index, physical activities, smoking status, and several others: T-score, along with biomarkers such as Vitamin D3, calcium levels, and the rest. Indeed, the results show that the features most indicative of recurrent fractures include age, T-score, physical activity, and glucocorticoid usage; greater emphasis has been laid on bone mineral density and lifestyle factors. The detailed feature importance analysis showed that age and T-score have the highest important values for fracture recurrence prediction, followed by physical activity and glucocorticoid treatment. The study finds that the proposed models achieved an accuracy of 91.3% (LLaMA 7GB) and 90.2% (Gamma 7GB), with ROC AUC scores of 93% and 92%, respectively. The study highlights that age, T-score, and glucocorticoid usage were the most significant predictive factors. These findings enable improved clinical decision-making for fracture prevention. This model can facilitate the identification of high-risk patients with recurrent fragility fractures by clinicians, thus allowing for targeted intervention and personalized treatment to reduce the risk of future fractures. The findings contribute to the development of fracture prediction, incorporating a wide array of clinical data that, in turn, will improve patient outcomes and their quality of life."
  },
  {
    "year": "2025",
    "abstract": "Age-related macular degeneration (AMD) is a prevalent retinal disorder in the elderly, often leading to significant vision impairment. The diagnosis of AMD is confirmed through various medical imaging modalities, with color fundus photography (CFP) being a primary tool. The detection and staging of AMD severity depend on several factors, including the number and size of drusen, the presence of pigmentary changes, geographic atrophy, and neovascularization, all of which are identifiable through CFP. In this study, we introduce an innovative dual-vision transformer-based network designed to automatically detect AMD and classify its severity into either dry AMD or wet AMD using CFP. Early diagnosis and accurate staging of AMD are crucial in mitigating the progression of the disease, making this work particularly valuable. Our proposed model, Seg-Swin, leverages a dual attention-based transformer network architecture, comprising two key stages. The first stage employs the SegFormer transformer model for the precise detection of AMD-related lesions, while the second stage utilizes the Swin transformer model to classify the detected lesions into dry or wet AMD. Our extensive experimental results demonstrate that the Seg-Swin model outperforms existing approaches, achieving remarkable diagnostic accuracy with metrics such as 98.7% accuracy, 99% sensitivity, 97.95% F1-score, and 98.24% specificity. By combining the strengths of advanced transformer models in both identification and classification tasks, the Seg-Swin model offers a comprehensive and powerful solution for detecting and staging AMD. The integration of these dual attention mechanisms allows the model to more precisely interpret complex retinal images, which is crucial for early diagnosis and accurate staging of AMD."
  },
  {
    "year": "2025",
    "abstract": "This paper introduces the Proof-of-Diversity (PoD) protocol, a new consensus mechanism that enhances decentralization, security, and energy efficiency using demographic, geographic, and computational diversity in validator selection. By using a multi-dimensional entropy-based approach, PoD shows high resistance to Sybil attacks, fosters inclusion, and ensures fair participation. Comparative analysis with Tendermint Proof-of-Stake (PoS) and Algorand Proof-of-Stake (Algorand) shows that PoD is more effective in various key metrics, including transaction finality, validator engagement, diversity entropy, energy use, and adaptability. In particular, PoD achieves a shortest average transaction finality time of 72.84 ms over a given period, a notable improvement compared to both Algorand at 215.37 ms and Tendermint PoS at 278.42 ms. In addition, PoD achieves a validator engagement of 85.42%, strengthening its ability to maintain decentralization. PoD also achieves a diversity score of 0.79, better than Tendermint PoS and Algorand, indicating a more fair and inclusive validator selection process. In terms of energy use, PoD achieves a mere 0.0132 kWh per transaction per second (TPS), a considerable improvement compared to its counterparts. In addition, PoD shows better adaptability to changes in step parameters and changes in benefit-cost ratios, further improving validator selection and network optimization. Overall, these results make PoD a scalable and sustainable consensus system that balances diversity, security, and performance in blockchain networks."
  },
  {
    "year": "2025",
    "abstract": "Biomimetic robots have the advantage of propulsion efficiency and maneuverability. Manta ray robots with soft, flexible, and distributed multi-stage pectoral fins have been proposed. Robots with flexible fins can be propelled by varying the phase difference and amplitude of each pectoral fin. However, it is still difficult to uniquely define the state of soft, flexible fins, which are passively controlled. Robots with soft and flexible fins are susceptible to various water conditions. In this study, we designed a manta ray robot with multi-rigid link pectoral fins that can actively reproduce uniquely define bending. To actively reproduce the bending and propulsion of the manta ray, we propose a virtual spring-damper system. The validity of this design and control method was verified through experiments on the movement trajectories and swimming. It was found that the manta ray robot using the proposed design and control reproduced bending and achieved high speed and turning performance. This shows that the proposed design and control methods exhibit the same or better performance than the soft fins. These methods expected to be further applications for biomimetics robots, enabling active control, with uniquely defined bending and fin performance."
  },
  {
    "year": "2025",
    "abstract": "The escalating effects of climate change have heightened the urgency of ecosystem conservation efforts worldwide. In this context, pollinators such as honeybees play a critical role in maintaining ecosystem health. However, they face appreciable threats, including the proliferation of invasive alien species (IAS) and colony collapse disorder. In this study, we propose a novel tracking system that uses unmanned aerial vehicles (UAVs) equipped with rotational directional antennas and radio telemetry systems. This approach, which represents an improvement over our previous works, aims to protect biodiversity and ecosystem resilience by mitigating the adverse impacts of IAS on pollinator populations. To implement the proposed tracking strategy, a motor-based directional antenna that can rotate 360° is attached to a UAV, and the received signal strength indicator (RSSI) value is used to localize the hornets to which sensors are attached. The proposed tracking system was verified in a simulated field environment that was constructed by considering the RSSI values obtained in a forest. In addition, the robustness and field applicability of the tracking system were improved by applying it to scenarios consisting of different paths that were constructed considering the dynamic nature of hornets."
  },
  {
    "year": "2025",
    "abstract": "Clustering is a fundamental task in data analysis with applications across a wide range of fields, such as computer vision, pattern recognition, and data mining. Real-world use cases include social network analysis, medical imaging, market segmentation, and anomaly detection, to name a few. In this paper, we propose an acceleration of the exact k-means++ algorithm using geometric information, specifically the Triangle Inequality and additional norm filters, along with a two-step sampling procedure. Our experiments demonstrate that the accelerated version outperforms the standard k-means++ version in terms of the number of visited points and distance calculations, achieving greater speedup as the number of clusters increases. The version utilizing the Triangle Inequality is particularly effective for low-dimensional data, while the additional norm-based filter enhances performance in high-dimensional instances with greater norm variance among points. Additional experiments show the behavior of our algorithms when executed concurrently across multiple jobs and examine how memory performance impacts practical speedup."
  },
  {
    "year": "2025",
    "abstract": "Ego vehicle speed estimation is critical for autonomous driving and advanced driver-assistance systems (ADAS), but traditional methods often fail in accuracy and computational efficiency under dynamic conditions. To address these challenges, we propose FlexiNet, a novel adaptive feature synthesis network that leverages monocular camera data to perform real-time speed estimation. FlexiNet integrates five key components, the Contextual Motion Analysis Block, Adaptive Feature Transformer, Spatial Feature Extraction Module, Motion Feature Extraction Module, and Dynamic Integration Gate, to effectively extract and fuse spatial and temporal features, thereby overcoming limitations of previous approaches by mitigating noise and capturing subtle motion dynamics. Comprehensive evaluations on the KITTI and nuImages datasets demonstrate FlexiNet’s superior performance. On the nuImages dataset, our model achieves an RMSE of 1.1358 m/s and an MAE of 0.9599 m/s, while on the KITTI dataset it records an RMSE of 1.9542 m/s and an MAE of 1.0610 m/s—reductions in error of up to 27.6% and 75.5% compared to baseline methods. These results validate the technical soundness and real-time capability of FlexiNet for deployment on embedded automotive platforms. By addressing critical gaps in previous research, FlexiNet makes a significant contribution toward the development of safer and more efficient autonomous vehicle technologies. The source code for FlexiNet is publicly available at herehttps://github.com/Geekgineer/FlexiNet"
  },
  {
    "year": "2025",
    "abstract": "Chronic tinnitus is a subjective condition where individuals experience persistent noise or ringing without external stimuli, impacting daily life, sleep, and mental health. It affects over 10% of the global population, with 2% of adults experience severe distress. To better understand its neural mechanisms, we propose a novel approach combining co-occurrence matrix with EEG microstate analysis. Specifically, we quantified EEG microstate stability and transition frequences using co-occurrence probability (CP) and calculated the relative difference proportion of CP (DPCP) to compare tinnitus and healthy subjects under opening-eye (OE) and closing-eye (CE) conditions. Results show that tinnitus patients exhibit increased stability of microstate D (DPCP =112.2%, CP =74.67%, p < 0.01) and stronger interactions between microstates C and D (DPCP≥91.43%, p < 0.05), indicating abnormal salience and executive control network activity. Meanwhile, microstates A and B decrease significantly (DPCP<−34.78%, p < 0.01), suggesting impaired auditory/visual processing and default mode network function. In contrast, under CE, tinnitus patients show reduced microstate C stability (DPCP=−51.72%, CP=−25.97%, p < 0.05) and increased occurrence of microstates A and B (DPCP >45%, p < 0.05), reflecting altered network adaptability. Unlike healthy individuals, tinnitus patients exhibit minimal changes between OE and CE, indicating the reduction of brain flexibility. This study advances EEG microstate analysis by integrating co-occurrence matrix algorithms, offering a direct and comprehensive assessment of microstate stability and interactions. The findings provide new insights into tinnitus-related brain network dysfunction and suggest EEG microstates co-occurrence probabilities as potential neurophysiological markers for diagnosis and intervention."
  },
  {
    "year": "2025",
    "abstract": "Stable operations of modern power networks depend on the reliability of smart grids. The expansion of modern power systems combined with renewable energy applications and decentralized networks creates difficulties for traditional fault detection methods because of high-dimensional data combined with measurement noise and delayed fault identification processes. A deep learning solution based on Phasor Measurement Unit (PMU) image data detection for smart grid faults is presented in this work. The proposed method achieves accurate and efficient fault classification through the conversion of PMU data to images and then utilization of advanced deep learning models VGG16 combined with Convolutional Neural Networks (CNNs). The experimental findings show that VGG16 reaches 98.75% accuracy in fault classification while surpassing CNNs that delivered 94.44% accuracy. In addition to reporting high classification accuracy, the study proposes a new hybrid deep learning framework that combines transfer learning and adaptive thresholding techniques. The image-based deep learning system extracts features automatically, reducing the need for human preprocessing to effectively detect fault patterns. The methodology enables immediate fault detection, allowing operators to make critical decisions to avoid major power outages. According to the research, artificial intelligence has the potential to significantly improve smart grid resilience, reduce economic losses, and improve power system operational efficiency. The research advances AI developments in energy management by developing advanced, powerful fault detection methods that will guide future changes to power system networks."
  },
  {
    "year": "2025",
    "abstract": "Off-grid energy projects particularly solar mini-grids, play a crucial role in electrifying remote areas with limited access to centralized grids. This paper presents an economic assessment of a 20.46kWp solar mini-grid project using the model for financial analysis of electric sector expansion plans (FINPLAN) model, a financial planning tool used in energy project financial evaluation. The study aims to analyse the financial viability, risks, and economic benefits of off-grid solar solutions. Key indicators such as Net Present Value (NPV), Internal Rate of Return (IRR), Break-even Point (BEP), and Exchange Risk and Debt Service Coverage Ratio (DSCR) are evaluated to determine the project viability and sustainability. The FINPLAN model approach allows detailed cash flow analysis and risk assessments under various scenarios of energy demand, capital expenditure, operational costs, and subsidy frameworks. The case study of a 20.46kWp Solar PV-Battery Energy Storage System (BESS) project highlights the impact of key financial parameters, such as interest rates and inflation, on project returns. The study reveals that an additional equity investment of=N189.06 million is needed for procurement in 2025 and early operational costs in 2026, with a positive Net Present Value of=N15497.33 and an equity Internal Rate of Return (IRR) of 27.66%. The financial ratios show a Working Capital Ratio (WCR) of 1.35-4.0, exchange risk of 0.1-15, break-even point value >0.8 between 2026 and 2036, and a Debt Service Coverage Ratio of 0.3-1.2 between 2026 and 2036. The Best-Case scenario results showed a more balanced case with no flow from the stand-by facility, a positive NPV of=N17,805.71, and an Equity IRR of 26.96%. The paper recommends the adoption of the FINPLAN tool for appraising off-grid energy projects and power infrastructure expansions."
  },
  {
    "year": "2025",
    "abstract": "Aiming at the problem of poor recommendation effect caused by data sparsity in traditional collaborative filtering algorithm in book recommendation, this study proposes a personalized recommendation model (BCF-UAI) that combines book category features and user attribute information, aiming to improve the accuracy and generalization ability of the recommendation system. By introducing user attribute information (gender, age, occupation) and book category features, Embedding technology is used to map discrete attributes into continuous low-dimensional vectors to construct feature representations of users and books. A feature fusion strategy is designed to vectorize and fuse the multi-dimensional attributes of users and the multi-category features of books to generate a unified high-dimensional feature vector. Based on cosine similarity, the potential correlation between users and books is calculated to generate a personalized recommendation list. The experiment uses the Douban book dataset to compare the UCF, ICF and MF, and verifies the effectiveness of the feature module through ablation experiments. The results show that the proposed method is significantly better than the traditional method in RMSE and MAE, and the ablation experiment shows that the contribution of book category features is higher (Precision increased by 3.38%). The research proves that the fusion of user attributes and book categories can effectively mine the deep association of data and alleviate the problem of data sparsity. The research verifies the necessity of attribute information to capture users’ personalized needs, and provides theoretical and practical reference for the optimization of intelligent book recommendation system."
  },
  {
    "year": "2025",
    "abstract": "The personal mobility of wheelchair users is pivotal to their overall well-being. Navigating electric wheelchairs through confined spaces poses notable challenges, particularly for individuals with disabilities. In response, this research introduces a pioneering vision-based approach for sidewalk navigation that leverages tactile paving features and advanced machine learning models. While many existing solutions rely on expensive sensors or GPU-accelerated deep networks, we address this limitation by employing only a low-cost monocular camera and a lightweight GP model. Running at 7 Hz on a Raspberry Pi, our approach offers real-time autonomy without requiring specialized or high-end hardware. The proposed methodology includes creating a specialized dataset, formulating a custom control law, and deploying a lightweight real-time Gaussian Process (GP) model on a Raspberry Pi platform. Thorough experimentation substantiates the efficacy of the presented approach, demonstrating accurate and dependable autonomous wheelchair navigation on sidewalks. Beyond its technical contributions, the proposed solution offers a cost-effective alternative to conventional sensor-dependent systems, profoundly enhancing user mobility and quality of life. By equipping wheelchair users with enhanced navigation capabilities, this research strives to foster greater independence and inclusion in their daily lives."
  },
  {
    "year": "2025",
    "abstract": "Given the challenges of high loss density and heat dissipation in high-speed switched reluctance motors (HSRMs), this paper proposes a thermal analysis and cooling design method based on electromagnetic-thermal-flow (EM-TF) coupling. A 3 kW, 20,000 r/min HSRM is investigated. Accurate models of AC copper and windage losses are developed using fine 3-D winding modeling and full-domain CFD, enabling realistic heat source distribution. The total losses, including copper, core, and windage losses, are used as inputs for thermal simulation. Three cooling structures are compared in terms of thermal and flow field performance, and the spiral waterway is identified as optimal. To improve prediction accuracy, both unidirectional and bidirectional EM-TF coupling methods (UEMTFC and BEMTFC) are employed. The latter considers temperature-dependent properties of materials and internal air. Results show that BEMTFC significantly improves thermal prediction, with winding temperature deviations under4∘C compared to experimental results. These results confirm the effectiveness of the proposed method in improving the accuracy of thermal analysis for high-speed electrical machines."
  },
  {
    "year": "2025",
    "abstract": "This work highlights advances in the torque estimation method for Switched Reluctance Machines (SRMs), focusing on a high-precision torque estimator that integrates classical and modern modeling techniques. The employed method uses cubic splines and Lagrange polynomials to model the inductance surfaces in order to optimize the estimated instantaneous torque. This approach optimizes drive systems, making SRMs more efficient for critical industrial applications, such as electric vehicle propulsion and renewable energy systems. The method, validated through simulations and experiments, presents an accuracy of about 97% in the reconstruction of the inductance surface, which guarantees the high performance of the estimated torque. The presented results indicate that the high detail of the inductance variations in SRMs contributes positively to the real-time and low-computation torque estimation. Thus, this work contributes to the development of more efficient electric drive control systems, which allow advances in sustainable, accurate and effective industrial applications."
  },
  {
    "year": "2025",
    "abstract": "In this paper, we propose a multiphysics analysis of thermal deformation effects on the frequency response of a Chebyshev bandpass filter designed for C-band satellite communications (SATCOM). Indeed, the design of microwave devices for SATCOM must account for the effects of thermal gradients on frequency response and incorporate suitable compensation techniques. The proposed analysis consists of appropriate sequence of electromagnetic, thermal, and mechanical simulations to evaluate the filter thermal profile as a function of input power, the resulting mechanical deformations, and the consequent effect on the filter frequency response. The results obtained are related to the filter equivalent circuit model to obtain deeper insight of the involved physical phenomena and useful information for the design of the most suitable compensation strategy. Finally, to demonstrate the effectiveness of multiphysics analysis in the optimal design of devices robust to thermal gradients, a thermally compensated bandpass filter using passive heat sinks is designed and validated."
  },
  {
    "year": "2025",
    "abstract": "Surface water quality is of utmost significance to ensure public health and facilitate sustainable economic development. Traditional water quality assessment methods are typically time-consuming and labor-intensive and require numerous field measurements and laboratory analyses, which are costly and impractical to implement in large-scale water quality monitoring. Recent advances in machine learning (ML) have brought new approaches to predicting water quality index (WQI) and classifying water quality in real time to enhance decision-making in environmental management. In this study, we propose a novel gated liquid neural network (gated-LNN) that can predict WQI and classify water quality with high accuracy. As opposed to typical ML models, the proposed gated-LNN includes a gating mechanism that enhances temporal learning and noise robustness, making it well-suited for dynamic environmental data. For ascertaining the effectiveness of the proposed approach, we conducted rigorous experiments on a publicly available water quality dataset with 1897 examples collected from varied water bodies of India between the years 2005 and 2014. The dataset comprises seven most significant parameters of water quality, i.e., dissolved oxygen, pH, conductivity, biological oxygen demand, nitrate, fecal coliform, and total coliform. The proposed gated-LNN model achieved a high R2 of 0.9995 for WQI prediction and 99.74% accuracy for three-class water quality classification into “Good,” “Poor,” and “Unsuitable” classes, outperforming state-of-the-art models in both regression and classification tasks. While these results highlight the model’s potential as a highly accurate and efficient tool for real-time water quality assessment, its generalizability to different regions remains an important consideration. Future work will focus on enhancing computational efficiency and conducting generalization tests on datasets from diverse geographic regions and time periods to evaluate adaptability."
  },
  {
    "year": "2025",
    "abstract": "In this paper, a novel guidance law is proposed for interception of various types of targets at desired impact angle in three-dimensional coupled dynamics. Impact angles are defined using velocity vectors of missile and target, rather than line-of-sight (LOS) angles in azimuth and elevation planes. The proposed guidance law is derived using deep latent reinforcement meta-learning. Different from existing online gradient descent-based reinforcement meta-learning method, the proposed approach is aware of environment variations through latent context vector inferred with amortized variational inference. Target acceleration is also estimated with the latent context vector to facilitate guidance law design. In addition, the proposed approach is built as an adaptive guidance law with range-adaptive hyperbolic tangent function to attenuate control effort. Numerical simulation results with different initial condition and measurement noise validate the effectiveness and robustness of proposed guidance law."
  },
  {
    "year": "2025",
    "abstract": "Resource-constrained wearable photoplethysmography (PPG) monitoring devices highly demand energy consumption reduction strategies to maximize the battery lifetime under continuous health monitoring applications. In this paper, we present a digital compressed PPG sensing (DCS-PPG) framework with a resource-efficient sensing matrix, sparse recovery algorithm, and best sparsifying matrix for wearable and edge PPG analysis devices in achieving a higher compression ratio (CR) with low waveform distortion and enabling data encryption or parameter extraction without reconstruction. We consider four sensing matrices (deterministic block binary diagonal (DBBD), random sparse fixed binary (RSFB), random Bernoulli (RBe), and random Gaussian (RG)), four sparsifying matrices (discrete cosineΨ=[C], a combination of discrete cosine and discrete sineΨ=[CS], a combination of impulse, discrete cosine and discrete sineΨ=[ICS]and Haar wavelet), and six sparse recovery algorithms (orthogonal matching pursuit (OMP), approximate message passing (AMP), L1-minimization (L1-min), compressive sampling matching pursuit (CoSaMP), iterative hard thresholding (IHT) and iterative soft thresholding (IST)). On a wide variety of normal and abnormal PPG signals and five distortion measures, results show that the DCS-PPG framework based on the DBBD sensing matrix and OMP-based recovery algorithm with the sparsifying matrixΨ=[ICS]achieved a lower percentage root mean square difference (PRD) of1.86±1.65% at a higher CR of 3 with a lesser recovery time as compared to the results of other algorithms. Results show that the DBBD-based DCS-PPG sensing encoder can enable simultaneous data reduction and parameter extraction in the CS domain. The RSFB-based DCS-PPG sensing encoder can enable simultaneous data reduction and encryption with a lower recovery time and PRD of2.55±1.19% at a CR of 2.4 using AMP-based reconstruction with the sparsifying mat..."
  },
  {
    "year": "2025",
    "abstract": "The integration of LiDAR and cameras with an efficient data fusion approach significantly improves Enhanced Situational Awareness (ESA) for small-sized Unmanned Surface Vehicles (USVs). This is critical for early obstacle detection, particularly when maritime obstacles are only 5 to 10 seconds away. This is important to ensure effective collision avoidance in regions without reliable Global Positioning System (GPS) and Automatic Identification System (AIS), while maintaining low computational requirements and real-time performance. This paper presents a system aimed at ESA using an unsupervised approach and a trained deep learning model to detect multiple maritime obstacles in denied GPS zones. The proposed system incorporates a technical mechanism that uses a compact hardware system with an integrated advanced computing module and sensors for small-sized USVs. It addresses the challenges of achieving peak performance on an edge machine learning computer integration to reduce computational overhead. Further, it minimizes temporal detection variations using sophisticated filters and clustering in dynamic maritime environments with synchronized LiDAR and camera data fusion. The detection model, trained using Maritime Federated Large Dataset (MFLD2), achieved over 99% operational accuracy with the proposed data fusion approach. The system’s capacity to precisely identify obstacle location and distance is validated by experimental findings, enabling real-time situational awareness."
  },
  {
    "year": "2025",
    "abstract": "In an era where technology shapes education, effectively engaging students remains a cri- tical challenge. Student engagement significantly impacts academic performance, yet traditional assessment methods fail to capture its multidimensional nature. This study proposes a novel Engagement Level Classification Framework (ELCF) that employs deep learning models to classify engagement into five distinct levels (H1, H2, M, L2, L1) based on behavioral indicators, emotional cues, and academic performance. A multi-modal dataset (N entries), integrating facial expressions, student behaviors, and cognitive performance, enables a holistic engagement assessment. The system further employs real-time AI-driven analysis to personalize course recommendations, adapting dynamically to student engagement states. The proposed framework was evaluated using deep learning architectures such as EfficientNetB0, CNN, and ensemble models, achieving up to 94% accuracy in engagement classification. The adaptive recommendation system attained an F1-score of 84% and a 92% hit rate, demonstrating its effectiveness in aligning content with student engagement levels. However, certain limitations remain, including potential biases in facial emotion recognition, privacy concerns in real-time monitoring, and dataset scalability constraints. Future research will focus on bias mitigation, expanding dataset diversity, and refining adaptive interventions to enhance system reliability and inclusivity. These findings contribute to the academic discourse on AI-driven student engagement monitoring, offering quantifiable evidence for the development of fair, transparent, and ethically responsible technology-enhanced learning environments."
  },
  {
    "year": "2025",
    "abstract": "Image matching aims to establish correspondences between images and estimate relative transformations, serving as a critical component in many geometric computer vision tasks. However, due to the limitations of descriptors and the presence of moving objects in the target region, results from nearest-neighbor matching often include numerous outliers. Recently, significant efforts have focused on effectively filtering these outliers to improve image matching performance. In this paper, we propose Globally-and-Locally-Affine Matching (GaLAM), a two-stage outlier detection method. In the first stage, GaLAM optimizes the edge features of Adaptive Locally Affine Matching (AdaLAM) and replaces the statistical neighborhood-based approach with classical geometric deviation metrics. In the second stage, Progressive Sample Consensus (PROSAC) is used to sample seed points that align with the fundamental matrix, followed by filtering outliers based on projection deviation. This approach enhances the model’s robustness in complex scenes, particularly in scenarios with moving objects in the target region. We evaluated GaLAM on diverse datasets, and the results demonstrate that our method achieves significant improvements over AdaLAM in most scenarios."
  },
  {
    "year": "2025",
    "abstract": "Phase change memory cells are outstanding candidates for processing-in-memory and neuromorphic computing. The high endurance, low cycle-to-cycle variability, and low read noise especially suit many applications, whereas the high cell-to-cell variability poses a challenge, since each cell serves slightly different results. Therefore, automated characterization is necessary to create a sufficient statistical database to thoroughly study the switching behavior. This paper introduces a sophisticated algorithm for the endurance measurement of phase change memory cells using the aixMATRIX setup by aixACCT Systems. The algorithm is able to perform endurance measurements on devices over an entire sample, adjusting the biasing parameters according to the switching behavior of each cell and sorting out nonfunctional cells. The stepping between the cells is performed automatically. We highlight the benefits of our algorithm by providing an in-depth analysis of all devices on one phase change memory in a bridge geometry sample."
  },
  {
    "year": "2025",
    "abstract": "The use of photovoltaic (PV) arrays in smart grid systems is growing due to the increasing energy demand and greenhouse gas emissions. However, due to the intermittent nature of PV arrays, the Maximum Power Point Tracking (MPPT) algorithm is typically employed to optimize the system’s energy production. In the past, the conventional perturb and observe (P&O) method was proposed for solar PV MPPT control. While the P&O method can estimate the PV maximum power under uniform irradiation, it often exhibits sluggish tracking and unstable steady-state oscillations and fails to track the global maximum power point (GMPP) under partial shading conditions (PSCs). These problems have been addressed using deep reinforcement learning algorithms, such as the deep deterministic policy gradient (DDPG) algorithm. However, due to the DDPG’s intrinsic drawbacks, such as unstable training, Q-value overestimation, brittle convergence, and hyperparameter sensitivity, it often produces steady-state power oscillations near the GMPP under PSCs, resulting in power loss. This paper presents a soft actor-critic (SAC) algorithm for solving PV MPPT control problems under PSCs. Unlike DDPG, which utilizes only one Q-network in the critic, SAC utilizes two Q-networks in the critic and maximum entropy policy in the reward function, which guarantees its training stability and improves its exploration and robustness in the presence of “estimation and model errors”. Despite its potential, the SAC-based MPPT approach has not been extensively explored or compared with DDPG to determine the superior method for PV MPPT control. This paper provides a comprehensible comparative analysis of DDPG and SAC, including their optimal hyperparameter configurations for PV MPPT control. To solve the MPPT control problem, the mathematical model of the boost converter and the solar PV system were developed. Then, a Markov Decision Process model was formulated, which represents the PV system’s behavior. For completenes..."
  },
  {
    "year": "2025",
    "abstract": "The advanced camera systems developed for property security prove inadequate when faced with the ease of disabling the cameras. Therefore, incorporating sound data from potential threats can also play a significant role in ensuring property security. This sound event-based approach enables a more compact installation and allows for the use of affordable microphones, offering an alternative to visual-based security systems. We propose deep learning based on a convolutional neural network (CNN) algorithm for classification of footstep sound events. The study includes two consecutive stages: ReaLISED dataset and refined ReaLISED supported by Epidemic Sound data. Sound event files are transformed into Mel-Frequency Cepstral Coefficients (MFCC) and a CNN is fed with the represented images of MFCC. By optimizing the model parameters, our unique model detected footstep sound events with 98% accuracy among 17 other sound events. Validation through Repeated Stratified K-Fold Cross-Validation (5 folds, 10 repetitions) and comparisons with state-of-the-art architectures demonstrated robust performance, with F1-Scores ranging from 0.905 to 0.992 and a mean of 0.960. The strategic incorporation of diverse open-source data fosters transparency and reproducibility, enhancing the model’s adaptability and reliability in handling real-world audio patterns, as evidenced by its commendable 1% error rate in precise identification."
  },
  {
    "year": "2025",
    "abstract": "This paper presents a performance analysis of grid-forming (GFM) inverter technology, which is essential to ensure stable and reliable operation of power systems with high penetration of inverter-based resources (IBRs). Recognizing that IBR operational constraints are distinct from those of synchronous generators, this study develops advanced PQ capability models and algorithmic frameworks that accurately characterize GFM inverter operational constraints across various coupling filter configurations (L, LC, and LCL). Electromagnetic transient (EMT) simulations show that the Enhanced Voltage Regulation (EVR) and Controlled Proportional-Integral Droop (CPID) strategies proposed in this paper improve voltage and frequency stability under dynamic loading and fault conditions, outperforming conventional droop methods. Real-time hardware validation confirms the robustness of the proposed approaches and their effectiveness in suppressing harmonics and recovering from faults. Key contributions include the derivation of practical PQ capability boundaries under realistic constraints, identification of superior control strategies for robust power quality (PQ), and successful GFM and grid-following (GFL) integration in parallel operations. These findings provide actionable insights for optimizing GFM inverter design and ensuring IEEE 1547 compliance in low-inertia grids."
  },
  {
    "year": "2025",
    "abstract": "The Digital Twin (DT) technology is considered as a backbone in the Industrial 4.0 revolution as it is playing a vital role in the digitization of various industries. A DT is a virtual representation of a physical entity, thus having the ability to simulate real data generated at physical space to optimize, estimate, control, monitor and forecast states/configurations. Despite enormous benefits, DT technology has several implementation challenges. Although deploying DT on edge or cloud platforms yields a plethora of services, its implementation in both spaces faces certain limitations. These limitations include latency, data communication overload, transmission energy consumption, privacy concerns, and communication inefficiencies. It is evident that these shortcomings could significantly impact real-time monitoring and control. Therefore, when considering whether to deploy DT on the edge or on the cloud, it is necessary to make a trade-off, or alternatively, adopt a hybrid approach. However, it is important to acknowledge that even with a hybrid approach, the aforementioned issues will persist to some extent. To address these challenges, this article introduces two innovative approaches. Local DT (LDT) and Distributed DT (DDT). These deployment strategies are designed to mitigate latency, minimize data communication overload, reduce energy consumption, improve communication efficiency, and strengthen privacy measures. Thus, resulting in environmental and economic sustainability. Consequently, these advancements facilitate superior real-time monitoring and control capabilities. Through the utilization of LDT and DDT methodologies, organizations can harness the full potential of DT technology, thereby maximizing its benefits."
  },
  {
    "year": "2025",
    "abstract": "Lung cancer surgery presents significant challenges due to its complexity and the need for precise risk stratification to improve patient outcomes. This study presents a Transformer-based multi-scale deep learning framework that integrates imaging, clinical, and genomic data to optimize decision-making surrounding surgery. By using the self-attention mechanism in Transformers and multi-scale feature extraction, the model expertly explores different data modalities. Therefore, it enables a precise prediction of surgical risks, such as delayed extubation and mortality; besides, it further performs risk stratification, having the model improve resource utilization by identifying high- and low-risk patients, ensuring that intervention is matched accordingly and resources are not wasted on unnecessary measures. Thorough evaluations, including ablation experiments, case analyses, and error analyses, prove the model’s robustness and practical applicability in a clinical setting. This study demonstrates the game-changing potential of advanced deep learning techniques in the field of precision medicine and provides a concrete framework for personalized treatment in lung cancer surgery, laying the foundation for broader healthcare applications."
  },
  {
    "year": "2025",
    "abstract": "In recent years, the intersection of cognitive neuroscience and software engineering has sparked significant interest, particularly in understanding developers’ mental activities. This systematic literature review (SLR) investigates the current methodologies for measuring and analyzing mental activity, particularly using EEG when reviewing code and paintings. The research addresses four key questions: (1) What methods are available to measure mental activity when reviewing code and pictures? (2) What are the methods for analyzing brain activity data especially extracted using EEG? (3) How do brain activity patterns differ when studying code and pictures obtained with EEG? and (4) Are there any differences in stress levels when reviewing code and drawing obtained with EEG? Our findings reveal various techniques for capturing and analyzing EEG data, yet highlight a significant gap in the empirical research addressing the last two questions. This underscores the need for targeted experiments to explore these specific brain activity patterns and stress level differences. These are crucial for advancing our understanding of cognitive processes in software engineering and related fields."
  },
  {
    "year": "2025",
    "abstract": "The novel deep learning-based time domain single channel speech source separation methods have shown remarkable progress. Recent studies achieve either successful global or local context modeling for monaural speaker separation. Existing CNN-based methods perform local context modeling, and RNN-based or attention-based methods work on the global context of the speech signal. In this paper, we proposed two models which parallelly combine CNN-RNN-based and CNN-attention-based separation modules and perform parallel local and global context modeling. Our models keep maximum global or local context value at a particular time step. These values help our models to separate the speaker signals more accurately. We have conducted the experiments on Libri2mix and Libri3mix datasets. The experimental data demonstrates that our proposed models have outperformed the state-of-the-art methods. Our proposed models remarkably improve SDR and SI-SDR values on Libri2mix and Libri3mix datasets. The proposed parallel CNN-RNN-based and CNN-attention-based separation models achieve average SDR improvement of 2.10 dB and 2.21 dB, respectively, and SI-SDR improvement of 2.74 dB and 2.78 dB, respectively, on the Libri2mix dataset. However, on the Libri3mix dataset, the proposed models achieve 0.57 dB and 0.87 dB average SDR improvement for parallel CNN-RNN-based separation module, and 0.88 dB and 1.4 dB average SI-SDR improvement for CNN-attention-based separation models. Our work indirectly contributes to SDG Goal 10 (Reduced Inequalities) by improving communication tools for diverse linguistic communities. Furthermore, this technology aids SDG Goal 9 (Industry, Innovation, and Infrastructure) by advancing AI-powered assistive technologies, fostering innovation, and building resilient communication systems."
  },
  {
    "year": "2025",
    "abstract": "Aiming at the problem that existing knowledge graph-based recommendation algorithms do not fully utilize the interaction information between users and items, this paper proposes a recommendation algorithm called Gated Adaptive and Knowledge-Enhanced Recommendation (GAKR) that integrates an adaptive gating mechanism with knowledge graph enhancement. First, GAKR uses a Multilayer Perceptron (MLP) in the recommendation module to process the user’s initial feature vector and extract potentially compressible features. Then, for the item feature vector, the model dynamically adjusts the weights of Collaborative Filtering (CF) and Knowledge Graph (KG) through the gating mechanism, generating a more expressive item representation. The gating mechanism calculates the gating value through the sigmoid function, allowing user’s behavioral characteristics in different scenarios to more accurately impact item recommendation. Next, in the Knowledge Graph Embedding (KGE) module, an embedding interaction mechanism is designed, which updates the entity embeddings by using Mobius addition and mapping, capturing higher-order interaction information between entities and relations. To prevent overfitting, GAKR employs L2 regularization during the optimization process, which enhances the model’s generalization ability when handling complex interactions. Finally, a normalized inner product operation is used as an evaluation function to predict the user’s preferences for items. The experimental results on three public datasets from different domains-MovieLens-1M, Book-Crossing and Last. FM-show that the GAKR model outperforms other benchmark models in terms of the evaluation metrics such as AUC, F1-score and recall rate in the CTR (Click Through Rate) and Top-K recommendation scenarios."
  },
  {
    "year": "2025",
    "abstract": "This study proposes a new detection method Kans-Unet, which combines Kans and U-net architecture. Specifically, the method embeds a convolution module based on Kans (Kan-Conv) in the encoder. The module applies a learnable activation function at the edge of the network, which not only reduces the number of model parameters but also significantly improves the generalization performance of the network. Secondly, in the transition region between encoder and decoder, the Feature Pyramid Attention (FPA) module is introduced to enhance the ability of the model to capture and analyze multiple scale features. In the decoder part, the CBAM attention mechanism module is integrated to effectively enhance the network’s attention to key information, and to improve the expression ability of image features. It is found that a wide range of patch-shaped anomaly regions are distributed in the VLF band power spectrum image of the space ionospheric electric field, and these patch-shaped anomaly regions are effectively detected by using the Kans-Unet model. The experimental results show that the KANs-Unet algorithm exhibits better detection performance compared to current mainstream semantic segmentation algorithms in the task of detecting abnormal speckle areas. It solves the problem of long model training time caused by insufficient computing power and provides a new method for the detection and analysis of abnormal features in power spectrum images."
  },
  {
    "year": "2025",
    "abstract": "Computed Torque Control is a widely used control strategy for ensuring precise trajectory tracking and impedance behavior in robotic manipulators. However, because it relies on feedback linearization using the robot’s dynamic model, any inaccuracies in the model can adversely affect tracking performance. This effect is even more visible when low feedback gains are used to impose compliance in the robot’s behavior. Adaptive Computed Torque Control addresses this issue by updating the dynamic model parameters to achieve asymptotic stability. Nevertheless, the classical update law requires the inversion of the estimated mass matrix, potentially leading to numerical stability problems. Several approaches, such as Adaptive Inertia-Related Control, were proposed to overcome this problem. However, they have problems in guaranteeing the desired impedance behaviour. In this work, we present a novel adaptive computed torque control law formulated both in joint space and Cartesian space, and we provide theoretical proofs of its asymptotic stability. We validate the proposed controller through simulations and real-robot experiments involving various dynamic motions. Finally, we demonstrate its effectiveness in a real dynamic task: throwing an unknown object."
  },
  {
    "year": "2025",
    "abstract": "While handwritten notes offer valuable insights into students’ knowledge retention, traditional analysis methods are often time-consuming and limited in scope. This study introduces an efficient approach for educational data analysis by combining image segmentation with generative AI to extract learning insights from students’ handwritten notes. Leveraging the Attention Multi-task U-Net for accurate segmentation and GPT-4o for content analysis, our method precisely identifies and categorizes text, charts, and formulas within notes. The extracted data provides educators with a detailed view of students’ knowledge retention, highlights the areas students focus on, and identifies critical knowledge points that may be missing from notes. Our experiments on student notes from a Digital Signal Processing course demonstrate the method’s high accuracy and significant efficiency improvements in teachers’ review of student notes. This research contributes to educational technology and data mining by introducing an automated, scalable method that supports more personalized and effective educational strategies."
  }
]