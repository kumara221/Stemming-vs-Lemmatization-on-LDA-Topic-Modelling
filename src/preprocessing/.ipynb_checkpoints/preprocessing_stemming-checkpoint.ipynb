{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95dae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c7a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = './../../data/raw/abstracts_only.json'\n",
    "clean_path = './../../data/cleaned/cleaned_abstracts_stemming.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ec8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65379b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "if 'abstract' not in df.columns:\n",
    "    raise KeyError(\"'abstract' column not found in JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245e435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44780cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stemmed_tokens = [\n",
    "        stemmer.stem(word)\n",
    "        for word in tokens\n",
    "        if word.isalpha() and word not in stop_words\n",
    "    ]\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa15597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_abstract'] = df['abstract'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daeae02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Before and After Preprocessing ---\n",
      "\n",
      "Data 1:\n",
      "Raw       : Technical progress in the open-source self replicating rapid prototyper (RepRap) community has enabled a distributed form of additive manufacturing to expand rapidly using polymer-based materials. However, the lack of an open-source metal alternative and the high capital costs and slow throughput of proprietary commercialized metal 3-D printers has severely restricted their deployment. The applications of commercialized metal 3-D printers are limited to only rapid prototyping and expensive finished products. This severely restricts the access of the technology for small and medium enterprises, the developing world and for use in laboratories. This paper reports on the development of a<$2000open-source metal 3-D printer. The metal 3-D printer is controlled with an open-source micro-controller and is a combination of a low-cost commercial gas-metal arc welder and a derivative of the Rostock, a deltabot RepRap. The bill of materials, electrical and mechanical design schematics, and basic construction and operating procedures are provided. A preliminary technical analysis of the properties of the 3-D printer and the resultant steel products are performed. The results of printing customized functional metal parts are discussed and conclusions are drawn about the potential for the technology and the future work necessary for the mass distribution of this technology.\n",
      "Cleaned   : technic progress self replic rapid prototyp reprap commun enabl distribut form addit manufactur expand rapidli use materi howev lack metal altern high capit cost slow throughput proprietari commerci metal printer sever restrict deploy applic commerci metal printer limit rapid prototyp expens finish product sever restrict access technolog small medium enterpris develop world use laboratori paper report develop metal printer metal printer control combin commerci arc welder deriv rostock deltabot reprap bill materi electr mechan design schemat basic construct oper procedur provid preliminari technic analysi properti printer result steel product perform result print custom function metal part discuss conclus drawn potenti technolog futur work necessari mass distribut technolog\n",
      "\n",
      "Data 2:\n",
      "Raw       : Abstractive dialogue summarization is a challenging task for several reasons. First, most of the key information in a conversation is scattered across utterances through multi-party interactions with different textual styles. Second, dialogues are often informal structures, wherein different individuals express personal perspectives, unlike text summarization, tasks that usually target formal documents such as news articles. To address these issues, we focused on the association between utterances from individual speakers and unique syntactic structures. Speakers have unique textual styles that can contain linguistic information, such as voiceprint. To do this, we used ad-hoc analysis to explore speakers’ text styles and constructed a syntax-aware model by leveraging linguistic information (i.e., POS tagging), which alleviates the above issues by inherently distinguishing utterances from individual speakers. Our approach allows for both data and model-centric investigation. Also, we employed multi-task learning of both syntax-aware information and dialogue summarization. To the best of our knowledge, our approach is the first method to apply multi-task learning to the dialogue summarization task. Experiments on a SAMSum corpus (a large-scale dialogue summarization corpus) demonstrated that our method improved upon the vanilla model. Consequently, we found that our efforts of syntax-aware approach have been reflected by the model.\n",
      "Cleaned   : abstract dialogu summar challeng task sever reason first key inform convers scatter across utter interact differ textual style second dialogu often inform structur wherein differ individu express person perspect unlik text summar task usual target formal document news articl address issu focus associ utter individu speaker uniqu syntact structur speaker uniqu textual style contain linguist inform voiceprint use analysi explor speaker text style construct model leverag linguist inform po tag allevi issu inher distinguish utter individu speaker approach allow data investig also employ learn inform dialogu summar best knowledg approach first method appli learn dialogu summar task experi samsum corpu dialogu summar corpu demonstr method improv upon vanilla model consequ found effort approach reflect model\n",
      "\n",
      "Data 3:\n",
      "Raw       : The electromagnetic (EM) properties of two-component mixtures involving many disordered regularly and irregularly shaped crystals are studied. The effective relative permittivities are calculated utilizing the time-domain finite integration technique. The effective permittivity of disordered mixtures deviates from established mixing theories especially in cases of high permittivity contrast between inclusions and matrix material, and is strongly correlated to the cross-sectional area of the inclusion crystals. Electric energy density localizes at the edges and corners of inclusions in a manner independent of inclusion shape and influenced by EM propagation direction and surrounding inclusions. For mixtures with both disordered irregular and more organized cube inclusions, energy localization increases as the EM signal travels through the mixture before decreasing due to attenuation of the propagating EM signal. With a large number of inclusion crystals (here in the hundreds), it is found that the impact on effective permittivity from differences in individual inclusion shapes is negligible.\n",
      "Cleaned   : electromagnet em properti mixtur involv mani disord regularli irregularli shape crystal studi effect rel permitt calcul util finit integr techniqu effect permitt disord mixtur deviat establish mix theori especi case high permitt contrast inclus matrix materi strongli correl area inclus crystal electr energi densiti local edg corner inclus manner independ inclus shape influenc em propag direct surround inclus mixtur disord irregular organ cube inclus energi local increas em signal travel mixtur decreas due attenu propag em signal larg number inclus crystal hundr found impact effect permitt differ individu inclus shape neglig\n",
      "\n",
      "Data 4:\n",
      "Raw       : To fulfil the tight area and memory constraints in IoT applications, the design of efficient Convolutional Neural Network (CNN) hardware becomes crucial. Quantization of CNN is one of the promising approach that allows the compression of large CNN into a much smaller one, which is very suitable for IoT applications. Among various proposed quantization schemes, Power-of-two (PoT) quantization enables efficient hardware implementation and small memory consumption for CNN accelerators, but requires retraining of CNN to retain its accuracy. This paper proposes a two-level post-training static quantization technique (DoubleQ) that combines the 8-bit and PoT weight quantization. The CNN weight is first quantized to 8-bit (level one), then further quantized to PoT (level two). This allows multiplication to be carried out using shifters, by expressing the weights in their PoT exponent form. DoubleQ also reduces the memory storage requirement for CNN, as only the exponent of the weights is needed for storage. However, DoubleQ trades the accuracy of the network for reduced memory storage. To recover the accuracy, a selection process (DoubleQExt) was proposed to strategically select some of the less informative layers in the network to be quantized with PoT at the second level. On ResNet-20, the proposed DoubleQ can reduce the memory consumption by 37.50% with 7.28% accuracy degradation compared to 8-bit quantization. By applying DoubleQExt, the accuracy is only degraded by 1.19% compared to 8-bit version while achieving a memory reduction of 23.05%. This result is also 1% more accurate than the state-of-the-art work (SegLog). The proposed DoubleQExt also allows flexible configuration to trade off the memory consumption with better accuracy, which is not found in the other state-of-the-art works. With the proposed two-level weight quantization, one can achieve a more efficient hardware architecture for CNN with minimal impact to the accuracy, which is crucial for IoT applicati...\n",
      "Cleaned   : fulfil tight area memori constraint iot applic design effici convolut neural network cnn hardwar becom crucial quantiz cnn one promis approach allow compress larg cnn much smaller one suitabl iot applic among variou propos quantiz scheme pot quantiz enabl effici hardwar implement small memori consumpt cnn acceler requir retrain cnn retain accuraci paper propos static quantiz techniqu doubleq combin pot weight quantiz cnn weight first quantiz level one quantiz pot level two allow multipl carri use shifter express weight pot expon form doubleq also reduc memori storag requir cnn expon weight need storag howev doubleq trade accuraci network reduc memori storag recov accuraci select process doubleqext propos strateg select less inform layer network quantiz pot second level propos doubleq reduc memori consumpt accuraci degrad compar quantiz appli doubleqext accuraci degrad compar version achiev memori reduct result also accur work seglog propos doubleqext also allow flexibl configur trade memori consumpt better accuraci found work propos weight quantiz one achiev effici hardwar architectur cnn minim impact accuraci crucial iot applicati\n",
      "\n",
      "Data 5:\n",
      "Raw       : Enterprises exist in a competitive manufacturing environment. To reduce production costs and effectively use production capacity to improve competitiveness, a hybrid production system is necessary. The flexible job shop (FJS) is a hybrid production system, and the FJS problem (FJSP) has drawn considerable attention in the past few decades. This paper examined the FJSP and, like previous studies, aimed to minimize the total order completion time (makespan). We developed a novel method that involves encoding feasible solutions in the genes of the initial chromosomes of a genetic algorithm (GA) and embedding the Taguchi method behind mating to increase the effectiveness of the GA. Two numerical experiments were conducted for evaluating the performance of the proposed algorithm relative to that of the Brandimarte MK1–MK10 benchmarks. The first experiment involved comparing the proposed algorithm and the traditional GA. The second experiment entailed comparing the proposed algorithm with those presented in previous studies. The results demonstrate that the proposed algorithm is superior to those reported in previous studies (except for that of Zhang et al.: the results in experiment MK7 were superior to those of Zhang, the results in experiments MK6 and MK10 were slightly inferior to those of Zhang, and the results were equivalent in other experiments) and effectively overcomes the encoding problem that occurs when a GA is used to solve the FJSP.\n",
      "Cleaned   : enterpris exist competit manufactur environ reduc product cost effect use product capac improv competit hybrid product system necessari flexibl job shop fj hybrid product system fj problem fjsp drawn consider attent past decad paper examin fjsp like previou studi aim minim total order complet time makespan develop novel method involv encod feasibl solut gene initi chromosom genet algorithm ga embed taguchi method behind mate increas effect two numer experi conduct evalu perform propos algorithm rel brandimart benchmark first experi involv compar propos algorithm tradit second experi entail compar propos algorithm present previou studi result demonstr propos algorithm superior report previou studi except zhang et al result experi superior zhang result experi slightli inferior zhang result equival experi effect overcom encod problem occur ga use solv fjsp\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Before and After Preprocessing ---\")\n",
    "for i, row in df.head(5).iterrows():\n",
    "    print(f\"\\nData {i+1}:\")\n",
    "    print(\"Raw       :\", row['abstract'])\n",
    "    print(\"Cleaned   :\", row['cleaned_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b13f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing finished, saved to: ./../../data/cleaned/cleaned_abstracts_stemming.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.dirname(clean_path), exist_ok=True)\n",
    "df[['cleaned_abstract']].to_json(clean_path, orient=\"records\", lines=False, indent=2)\n",
    "\n",
    "print(\"Preprocessing finished, saved to:\", clean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946df55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
